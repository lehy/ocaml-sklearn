


<!doctype html>
<html lang="en" class="no-js">
  <head>
    
      <meta charset="utf-8">
      <meta name="viewport" content="width=device-width,initial-scale=1">
      
      
      
      <link rel="shortcut icon" href="../assets/images/favicon.png">
      <meta name="generator" content="mkdocs-1.1, mkdocs-material-5.1.0">
    
    
      
        <title>Decomposition - OCaml scikit-learn interface</title>
      
    
    
      <link rel="stylesheet" href="../assets/stylesheets/main.89dc9fe3.min.css">
      
        <link rel="stylesheet" href="../assets/stylesheets/palette.ecd4686e.min.css">
      
      
        
        
        <meta name="theme-color" content="#3f51b5">
      
    
    
    
      
        <link href="https://fonts.gstatic.com" rel="preconnect" crossorigin>
        <link rel="stylesheet" href="https://fonts.googleapis.com/css?family=Roboto:300,400,400i,700%7CRoboto+Mono&display=fallback">
        <style>body,input{font-family:"Roboto",-apple-system,BlinkMacSystemFont,Helvetica,Arial,sans-serif}code,kbd,pre{font-family:"Roboto Mono",SFMono-Regular,Consolas,Menlo,monospace}</style>
      
    
    
    
    
      
    
    
  </head>
  
  
    
    
    <body dir="ltr" data-md-color-primary="indigo" data-md-color-accent="indigo">
  
    <input class="md-toggle" data-md-toggle="drawer" type="checkbox" id="__drawer" autocomplete="off">
    <input class="md-toggle" data-md-toggle="search" type="checkbox" id="__search" autocomplete="off">
    <label class="md-overlay" for="__drawer"></label>
    <div data-md-component="skip">
      
        
        <a href="#module-sklearndecompositiondictionarylearning" class="md-skip">
          Skip to content
        </a>
      
    </div>
    <div data-md-component="announce">
      
    </div>
    
      <header class="md-header" data-md-component="header">
  <nav class="md-header-nav md-grid" aria-label="Header">
    <a href=".." title="OCaml scikit-learn interface" class="md-header-nav__button md-logo" aria-label="OCaml scikit-learn interface">
      
  
  <svg xmlns="http://www.w3.org/2000/svg" viewBox="0 0 24 24"><path d="M12,8A3,3 0 0,0 15,5A3,3 0 0,0 12,2A3,3 0 0,0 9,5A3,3 0 0,0 12,8M12,11.54C9.64,9.35 6.5,8 3,8V19C6.5,19 9.64,20.35 12,22.54C14.36,20.35 17.5,19 21,19V8C17.5,8 14.36,9.35 12,11.54Z" /></svg>

    </a>
    <label class="md-header-nav__button md-icon" for="__drawer">
      <svg xmlns="http://www.w3.org/2000/svg" viewBox="0 0 24 24"><path d="M3,6H21V8H3V6M3,11H21V13H3V11M3,16H21V18H3V16Z" /></svg>
    </label>
    <div class="md-header-nav__title" data-md-component="header-title">
      
        <div class="md-header-nav__ellipsis">
          <span class="md-header-nav__topic md-ellipsis">
            OCaml scikit-learn interface
          </span>
          <span class="md-header-nav__topic md-ellipsis">
            
              Decomposition
            
          </span>
        </div>
      
    </div>
    
      <label class="md-header-nav__button md-icon" for="__search">
        <svg xmlns="http://www.w3.org/2000/svg" viewBox="0 0 24 24"><path d="M9.5,3A6.5,6.5 0 0,1 16,9.5C16,11.11 15.41,12.59 14.44,13.73L14.71,14H15.5L20.5,19L19,20.5L14,15.5V14.71L13.73,14.44C12.59,15.41 11.11,16 9.5,16A6.5,6.5 0 0,1 3,9.5A6.5,6.5 0 0,1 9.5,3M9.5,5C7,5 5,7 5,9.5C5,12 7,14 9.5,14C12,14 14,12 14,9.5C14,7 12,5 9.5,5Z" /></svg>
      </label>
      
<div class="md-search" data-md-component="search" role="dialog">
  <label class="md-search__overlay" for="__search"></label>
  <div class="md-search__inner" role="search">
    <form class="md-search__form" name="search">
      <input type="text" class="md-search__input" name="query" aria-label="Search" placeholder="Search" autocapitalize="off" autocorrect="off" autocomplete="off" spellcheck="false" data-md-component="search-query" data-md-state="active">
      <label class="md-search__icon md-icon" for="__search">
        <svg xmlns="http://www.w3.org/2000/svg" viewBox="0 0 24 24"><path d="M9.5,3A6.5,6.5 0 0,1 16,9.5C16,11.11 15.41,12.59 14.44,13.73L14.71,14H15.5L20.5,19L19,20.5L14,15.5V14.71L13.73,14.44C12.59,15.41 11.11,16 9.5,16A6.5,6.5 0 0,1 3,9.5A6.5,6.5 0 0,1 9.5,3M9.5,5C7,5 5,7 5,9.5C5,12 7,14 9.5,14C12,14 14,12 14,9.5C14,7 12,5 9.5,5Z" /></svg>
        <svg xmlns="http://www.w3.org/2000/svg" viewBox="0 0 24 24"><path d="M20,11V13H8L13.5,18.5L12.08,19.92L4.16,12L12.08,4.08L13.5,5.5L8,11H20Z" /></svg>
      </label>
      <button type="reset" class="md-search__icon md-icon" aria-label="Clear" data-md-component="search-reset" tabindex="-1">
        <svg xmlns="http://www.w3.org/2000/svg" viewBox="0 0 24 24"><path d="M19,6.41L17.59,5L12,10.59L6.41,5L5,6.41L10.59,12L5,17.59L6.41,19L12,13.41L17.59,19L19,17.59L13.41,12L19,6.41Z" /></svg>
      </button>
    </form>
    <div class="md-search__output">
      <div class="md-search__scrollwrap" data-md-scrollfix>
        <div class="md-search-result" data-md-component="search-result">
          <div class="md-search-result__meta">
            Type to start searching
          </div>
          <ol class="md-search-result__list"></ol>
        </div>
      </div>
    </div>
  </div>
</div>
    
    
      <div class="md-header-nav__source">
        
<a href="https://github.com/lehy/ocaml-sklearn/" title="Go to repository" class="md-source">
  <div class="md-source__icon md-icon">
    
    <svg xmlns="http://www.w3.org/2000/svg" viewBox="0 0 448 512"><path d="M439.55 236.05L244 40.45a28.87 28.87 0 0 0-40.81 0l-40.66 40.63 51.52 51.52c27.06-9.14 52.68 16.77 43.39 43.68l49.66 49.66c34.23-11.8 61.18 31 35.47 56.69-26.49 26.49-70.21-2.87-56-37.34L240.22 199v121.85c25.3 12.54 22.26 41.85 9.08 55a34.34 34.34 0 0 1-48.55 0c-17.57-17.6-11.07-46.91 11.25-56v-123c-20.8-8.51-24.6-30.74-18.64-45L142.57 101 8.45 235.14a28.86 28.86 0 0 0 0 40.81l195.61 195.6a28.86 28.86 0 0 0 40.8 0l194.69-194.69a28.86 28.86 0 0 0 0-40.81z"/></svg>
  </div>
  <div class="md-source__repository">
    lehy/ocaml-sklearn
  </div>
</a>
      </div>
    
  </nav>
</header>
    
    <div class="md-container" data-md-component="container">
      
        
      
      
        
      
      <main class="md-main" data-md-component="main">
        <div class="md-main__inner md-grid">
          
            
              <div class="md-sidebar md-sidebar--primary" data-md-component="navigation">
                <div class="md-sidebar__scrollwrap">
                  <div class="md-sidebar__inner">
                    <nav class="md-nav md-nav--primary" aria-label="Navigation" data-md-level="0">
  <label class="md-nav__title" for="__drawer">
    <a href=".." title="OCaml scikit-learn interface" class="md-nav__button md-logo" aria-label="OCaml scikit-learn interface">
      
  
  <svg xmlns="http://www.w3.org/2000/svg" viewBox="0 0 24 24"><path d="M12,8A3,3 0 0,0 15,5A3,3 0 0,0 12,2A3,3 0 0,0 9,5A3,3 0 0,0 12,8M12,11.54C9.64,9.35 6.5,8 3,8V19C6.5,19 9.64,20.35 12,22.54C14.36,20.35 17.5,19 21,19V8C17.5,8 14.36,9.35 12,11.54Z" /></svg>

    </a>
    OCaml scikit-learn interface
  </label>
  
    <div class="md-nav__source">
      
<a href="https://github.com/lehy/ocaml-sklearn/" title="Go to repository" class="md-source">
  <div class="md-source__icon md-icon">
    
    <svg xmlns="http://www.w3.org/2000/svg" viewBox="0 0 448 512"><path d="M439.55 236.05L244 40.45a28.87 28.87 0 0 0-40.81 0l-40.66 40.63 51.52 51.52c27.06-9.14 52.68 16.77 43.39 43.68l49.66 49.66c34.23-11.8 61.18 31 35.47 56.69-26.49 26.49-70.21-2.87-56-37.34L240.22 199v121.85c25.3 12.54 22.26 41.85 9.08 55a34.34 34.34 0 0 1-48.55 0c-17.57-17.6-11.07-46.91 11.25-56v-123c-20.8-8.51-24.6-30.74-18.64-45L142.57 101 8.45 235.14a28.86 28.86 0 0 0 0 40.81l195.61 195.6a28.86 28.86 0 0 0 40.8 0l194.69-194.69a28.86 28.86 0 0 0 0-40.81z"/></svg>
  </div>
  <div class="md-source__repository">
    lehy/ocaml-sklearn
  </div>
</a>
    </div>
  
  <ul class="md-nav__list" data-md-scrollfix>
    
      
      
      


  <li class="md-nav__item">
    <a href=".." title="scikit-learn for OCaml, version 0.22-0.1.0" class="md-nav__link">
      scikit-learn for OCaml, version 0.22-0.1.0
    </a>
  </li>

    
      
      
      


  <li class="md-nav__item">
    <a href="../base/" title="Base" class="md-nav__link">
      Base
    </a>
  </li>

    
      
      
      


  <li class="md-nav__item">
    <a href="../calibration/" title="Calibration" class="md-nav__link">
      Calibration
    </a>
  </li>

    
      
      
      


  <li class="md-nav__item">
    <a href="../cluster/" title="Cluster" class="md-nav__link">
      Cluster
    </a>
  </li>

    
      
      
      


  <li class="md-nav__item">
    <a href="../compose/" title="Compose" class="md-nav__link">
      Compose
    </a>
  </li>

    
      
      
      


  <li class="md-nav__item">
    <a href="../conftest/" title="Conftest" class="md-nav__link">
      Conftest
    </a>
  </li>

    
      
      
      


  <li class="md-nav__item">
    <a href="../covariance/" title="Covariance" class="md-nav__link">
      Covariance
    </a>
  </li>

    
      
      
      


  <li class="md-nav__item">
    <a href="../cross_decomposition/" title="Cross decomposition" class="md-nav__link">
      Cross decomposition
    </a>
  </li>

    
      
      
      


  <li class="md-nav__item">
    <a href="../datasets/" title="Datasets" class="md-nav__link">
      Datasets
    </a>
  </li>

    
      
      
      

  


  <li class="md-nav__item md-nav__item--active">
    
    <input class="md-nav__toggle md-toggle" data-md-toggle="toc" type="checkbox" id="__toc">
    
    
      <label class="md-nav__link md-nav__link--active" for="__toc">
        Decomposition
        <span class="md-nav__icon md-icon">
          <svg xmlns="http://www.w3.org/2000/svg" viewBox="0 0 24 24"><path d="M3,9H17V7H3V9M3,13H17V11H3V13M3,17H17V15H3V17M19,17H21V15H19V17M19,7V9H21V7H19M19,13H21V11H19V13Z" /></svg>
        </span>
      </label>
    
    <a href="./" title="Decomposition" class="md-nav__link md-nav__link--active">
      Decomposition
    </a>
    
      
<nav class="md-nav md-nav--secondary" aria-label="Table of contents">
  
  
  
    <label class="md-nav__title" for="__toc">
      <span class="md-nav__icon md-icon">
        <svg xmlns="http://www.w3.org/2000/svg" viewBox="0 0 24 24"><path d="M20,11V13H8L13.5,18.5L12.08,19.92L4.16,12L12.08,4.08L13.5,5.5L8,11H20Z" /></svg>
      </span>
      Table of contents
    </label>
    <ul class="md-nav__list" data-md-scrollfix>
      
        <li class="md-nav__item">
  <a href="#module-sklearndecompositiondictionarylearning" class="md-nav__link">
    module Sklearn.​Decomposition.​DictionaryLearning
  </a>
  
    <nav class="md-nav" aria-label="module Sklearn.​Decomposition.​DictionaryLearning">
      <ul class="md-nav__list">
        
          <li class="md-nav__item">
  <a href="#create" class="md-nav__link">
    create
  </a>
  
</li>
        
          <li class="md-nav__item">
  <a href="#fit" class="md-nav__link">
    fit
  </a>
  
</li>
        
          <li class="md-nav__item">
  <a href="#fit_transform" class="md-nav__link">
    fit_transform
  </a>
  
</li>
        
          <li class="md-nav__item">
  <a href="#get_params" class="md-nav__link">
    get_params
  </a>
  
</li>
        
          <li class="md-nav__item">
  <a href="#set_params" class="md-nav__link">
    set_params
  </a>
  
</li>
        
          <li class="md-nav__item">
  <a href="#transform" class="md-nav__link">
    transform
  </a>
  
</li>
        
          <li class="md-nav__item">
  <a href="#components_" class="md-nav__link">
    components_
  </a>
  
</li>
        
          <li class="md-nav__item">
  <a href="#error_" class="md-nav__link">
    error_
  </a>
  
</li>
        
          <li class="md-nav__item">
  <a href="#n_iter_" class="md-nav__link">
    n_iter_
  </a>
  
</li>
        
          <li class="md-nav__item">
  <a href="#to_string" class="md-nav__link">
    to_string
  </a>
  
</li>
        
          <li class="md-nav__item">
  <a href="#show" class="md-nav__link">
    show
  </a>
  
</li>
        
          <li class="md-nav__item">
  <a href="#pp" class="md-nav__link">
    pp
  </a>
  
</li>
        
      </ul>
    </nav>
  
</li>
      
        <li class="md-nav__item">
  <a href="#module-sklearndecompositionfactoranalysis" class="md-nav__link">
    module Sklearn.​Decomposition.​FactorAnalysis
  </a>
  
    <nav class="md-nav" aria-label="module Sklearn.​Decomposition.​FactorAnalysis">
      <ul class="md-nav__list">
        
          <li class="md-nav__item">
  <a href="#create_1" class="md-nav__link">
    create
  </a>
  
</li>
        
          <li class="md-nav__item">
  <a href="#fit_1" class="md-nav__link">
    fit
  </a>
  
</li>
        
          <li class="md-nav__item">
  <a href="#fit_transform_1" class="md-nav__link">
    fit_transform
  </a>
  
</li>
        
          <li class="md-nav__item">
  <a href="#get_covariance" class="md-nav__link">
    get_covariance
  </a>
  
</li>
        
          <li class="md-nav__item">
  <a href="#get_params_1" class="md-nav__link">
    get_params
  </a>
  
</li>
        
          <li class="md-nav__item">
  <a href="#get_precision" class="md-nav__link">
    get_precision
  </a>
  
</li>
        
          <li class="md-nav__item">
  <a href="#score" class="md-nav__link">
    score
  </a>
  
</li>
        
          <li class="md-nav__item">
  <a href="#score_samples" class="md-nav__link">
    score_samples
  </a>
  
</li>
        
          <li class="md-nav__item">
  <a href="#set_params_1" class="md-nav__link">
    set_params
  </a>
  
</li>
        
          <li class="md-nav__item">
  <a href="#transform_1" class="md-nav__link">
    transform
  </a>
  
</li>
        
          <li class="md-nav__item">
  <a href="#components__1" class="md-nav__link">
    components_
  </a>
  
</li>
        
          <li class="md-nav__item">
  <a href="#loglike_" class="md-nav__link">
    loglike_
  </a>
  
</li>
        
          <li class="md-nav__item">
  <a href="#noise_variance_" class="md-nav__link">
    noise_variance_
  </a>
  
</li>
        
          <li class="md-nav__item">
  <a href="#n_iter__1" class="md-nav__link">
    n_iter_
  </a>
  
</li>
        
          <li class="md-nav__item">
  <a href="#mean_" class="md-nav__link">
    mean_
  </a>
  
</li>
        
          <li class="md-nav__item">
  <a href="#to_string_1" class="md-nav__link">
    to_string
  </a>
  
</li>
        
          <li class="md-nav__item">
  <a href="#show_1" class="md-nav__link">
    show
  </a>
  
</li>
        
          <li class="md-nav__item">
  <a href="#pp_1" class="md-nav__link">
    pp
  </a>
  
</li>
        
      </ul>
    </nav>
  
</li>
      
        <li class="md-nav__item">
  <a href="#module-sklearndecompositionfastica" class="md-nav__link">
    module Sklearn.​Decomposition.​FastICA
  </a>
  
    <nav class="md-nav" aria-label="module Sklearn.​Decomposition.​FastICA">
      <ul class="md-nav__list">
        
          <li class="md-nav__item">
  <a href="#create_2" class="md-nav__link">
    create
  </a>
  
</li>
        
          <li class="md-nav__item">
  <a href="#fit_2" class="md-nav__link">
    fit
  </a>
  
</li>
        
          <li class="md-nav__item">
  <a href="#fit_transform_2" class="md-nav__link">
    fit_transform
  </a>
  
</li>
        
          <li class="md-nav__item">
  <a href="#get_params_2" class="md-nav__link">
    get_params
  </a>
  
</li>
        
          <li class="md-nav__item">
  <a href="#inverse_transform" class="md-nav__link">
    inverse_transform
  </a>
  
</li>
        
          <li class="md-nav__item">
  <a href="#set_params_2" class="md-nav__link">
    set_params
  </a>
  
</li>
        
          <li class="md-nav__item">
  <a href="#transform_2" class="md-nav__link">
    transform
  </a>
  
</li>
        
          <li class="md-nav__item">
  <a href="#components__2" class="md-nav__link">
    components_
  </a>
  
</li>
        
          <li class="md-nav__item">
  <a href="#mixing_" class="md-nav__link">
    mixing_
  </a>
  
</li>
        
          <li class="md-nav__item">
  <a href="#mean__1" class="md-nav__link">
    mean_
  </a>
  
</li>
        
          <li class="md-nav__item">
  <a href="#n_iter__2" class="md-nav__link">
    n_iter_
  </a>
  
</li>
        
          <li class="md-nav__item">
  <a href="#whitening_" class="md-nav__link">
    whitening_
  </a>
  
</li>
        
          <li class="md-nav__item">
  <a href="#to_string_2" class="md-nav__link">
    to_string
  </a>
  
</li>
        
          <li class="md-nav__item">
  <a href="#show_2" class="md-nav__link">
    show
  </a>
  
</li>
        
          <li class="md-nav__item">
  <a href="#pp_2" class="md-nav__link">
    pp
  </a>
  
</li>
        
      </ul>
    </nav>
  
</li>
      
        <li class="md-nav__item">
  <a href="#module-sklearndecompositionincrementalpca" class="md-nav__link">
    module Sklearn.​Decomposition.​IncrementalPCA
  </a>
  
    <nav class="md-nav" aria-label="module Sklearn.​Decomposition.​IncrementalPCA">
      <ul class="md-nav__list">
        
          <li class="md-nav__item">
  <a href="#create_3" class="md-nav__link">
    create
  </a>
  
</li>
        
          <li class="md-nav__item">
  <a href="#fit_3" class="md-nav__link">
    fit
  </a>
  
</li>
        
          <li class="md-nav__item">
  <a href="#fit_transform_3" class="md-nav__link">
    fit_transform
  </a>
  
</li>
        
          <li class="md-nav__item">
  <a href="#get_covariance_1" class="md-nav__link">
    get_covariance
  </a>
  
</li>
        
          <li class="md-nav__item">
  <a href="#get_params_3" class="md-nav__link">
    get_params
  </a>
  
</li>
        
          <li class="md-nav__item">
  <a href="#get_precision_1" class="md-nav__link">
    get_precision
  </a>
  
</li>
        
          <li class="md-nav__item">
  <a href="#inverse_transform_1" class="md-nav__link">
    inverse_transform
  </a>
  
</li>
        
          <li class="md-nav__item">
  <a href="#partial_fit" class="md-nav__link">
    partial_fit
  </a>
  
</li>
        
          <li class="md-nav__item">
  <a href="#set_params_3" class="md-nav__link">
    set_params
  </a>
  
</li>
        
          <li class="md-nav__item">
  <a href="#transform_3" class="md-nav__link">
    transform
  </a>
  
</li>
        
          <li class="md-nav__item">
  <a href="#components__3" class="md-nav__link">
    components_
  </a>
  
</li>
        
          <li class="md-nav__item">
  <a href="#explained_variance_" class="md-nav__link">
    explained_variance_
  </a>
  
</li>
        
          <li class="md-nav__item">
  <a href="#explained_variance_ratio_" class="md-nav__link">
    explained_variance_ratio_
  </a>
  
</li>
        
          <li class="md-nav__item">
  <a href="#singular_values_" class="md-nav__link">
    singular_values_
  </a>
  
</li>
        
          <li class="md-nav__item">
  <a href="#mean__2" class="md-nav__link">
    mean_
  </a>
  
</li>
        
          <li class="md-nav__item">
  <a href="#var_" class="md-nav__link">
    var_
  </a>
  
</li>
        
          <li class="md-nav__item">
  <a href="#noise_variance__1" class="md-nav__link">
    noise_variance_
  </a>
  
</li>
        
          <li class="md-nav__item">
  <a href="#n_components_" class="md-nav__link">
    n_components_
  </a>
  
</li>
        
          <li class="md-nav__item">
  <a href="#n_samples_seen_" class="md-nav__link">
    n_samples_seen_
  </a>
  
</li>
        
          <li class="md-nav__item">
  <a href="#to_string_3" class="md-nav__link">
    to_string
  </a>
  
</li>
        
          <li class="md-nav__item">
  <a href="#show_3" class="md-nav__link">
    show
  </a>
  
</li>
        
          <li class="md-nav__item">
  <a href="#pp_3" class="md-nav__link">
    pp
  </a>
  
</li>
        
      </ul>
    </nav>
  
</li>
      
        <li class="md-nav__item">
  <a href="#module-sklearndecompositionkernelpca" class="md-nav__link">
    module Sklearn.​Decomposition.​KernelPCA
  </a>
  
    <nav class="md-nav" aria-label="module Sklearn.​Decomposition.​KernelPCA">
      <ul class="md-nav__list">
        
          <li class="md-nav__item">
  <a href="#create_4" class="md-nav__link">
    create
  </a>
  
</li>
        
          <li class="md-nav__item">
  <a href="#fit_4" class="md-nav__link">
    fit
  </a>
  
</li>
        
          <li class="md-nav__item">
  <a href="#fit_transform_4" class="md-nav__link">
    fit_transform
  </a>
  
</li>
        
          <li class="md-nav__item">
  <a href="#get_params_4" class="md-nav__link">
    get_params
  </a>
  
</li>
        
          <li class="md-nav__item">
  <a href="#inverse_transform_2" class="md-nav__link">
    inverse_transform
  </a>
  
</li>
        
          <li class="md-nav__item">
  <a href="#set_params_4" class="md-nav__link">
    set_params
  </a>
  
</li>
        
          <li class="md-nav__item">
  <a href="#transform_4" class="md-nav__link">
    transform
  </a>
  
</li>
        
          <li class="md-nav__item">
  <a href="#lambdas_" class="md-nav__link">
    lambdas_
  </a>
  
</li>
        
          <li class="md-nav__item">
  <a href="#alphas_" class="md-nav__link">
    alphas_
  </a>
  
</li>
        
          <li class="md-nav__item">
  <a href="#dual_coef_" class="md-nav__link">
    dual_coef_
  </a>
  
</li>
        
          <li class="md-nav__item">
  <a href="#x_transformed_fit_" class="md-nav__link">
    x_transformed_fit_
  </a>
  
</li>
        
          <li class="md-nav__item">
  <a href="#x_fit_" class="md-nav__link">
    x_fit_
  </a>
  
</li>
        
          <li class="md-nav__item">
  <a href="#to_string_4" class="md-nav__link">
    to_string
  </a>
  
</li>
        
          <li class="md-nav__item">
  <a href="#show_4" class="md-nav__link">
    show
  </a>
  
</li>
        
          <li class="md-nav__item">
  <a href="#pp_4" class="md-nav__link">
    pp
  </a>
  
</li>
        
      </ul>
    </nav>
  
</li>
      
        <li class="md-nav__item">
  <a href="#module-sklearndecompositionlatentdirichletallocation" class="md-nav__link">
    module Sklearn.​Decomposition.​LatentDirichletAllocation
  </a>
  
    <nav class="md-nav" aria-label="module Sklearn.​Decomposition.​LatentDirichletAllocation">
      <ul class="md-nav__list">
        
          <li class="md-nav__item">
  <a href="#create_5" class="md-nav__link">
    create
  </a>
  
</li>
        
          <li class="md-nav__item">
  <a href="#fit_5" class="md-nav__link">
    fit
  </a>
  
</li>
        
          <li class="md-nav__item">
  <a href="#fit_transform_5" class="md-nav__link">
    fit_transform
  </a>
  
</li>
        
          <li class="md-nav__item">
  <a href="#get_params_5" class="md-nav__link">
    get_params
  </a>
  
</li>
        
          <li class="md-nav__item">
  <a href="#partial_fit_1" class="md-nav__link">
    partial_fit
  </a>
  
</li>
        
          <li class="md-nav__item">
  <a href="#perplexity" class="md-nav__link">
    perplexity
  </a>
  
</li>
        
          <li class="md-nav__item">
  <a href="#score_1" class="md-nav__link">
    score
  </a>
  
</li>
        
          <li class="md-nav__item">
  <a href="#set_params_5" class="md-nav__link">
    set_params
  </a>
  
</li>
        
          <li class="md-nav__item">
  <a href="#transform_5" class="md-nav__link">
    transform
  </a>
  
</li>
        
          <li class="md-nav__item">
  <a href="#components__4" class="md-nav__link">
    components_
  </a>
  
</li>
        
          <li class="md-nav__item">
  <a href="#n_batch_iter_" class="md-nav__link">
    n_batch_iter_
  </a>
  
</li>
        
          <li class="md-nav__item">
  <a href="#n_iter__3" class="md-nav__link">
    n_iter_
  </a>
  
</li>
        
          <li class="md-nav__item">
  <a href="#bound_" class="md-nav__link">
    bound_
  </a>
  
</li>
        
          <li class="md-nav__item">
  <a href="#doc_topic_prior_" class="md-nav__link">
    doc_topic_prior_
  </a>
  
</li>
        
          <li class="md-nav__item">
  <a href="#topic_word_prior_" class="md-nav__link">
    topic_word_prior_
  </a>
  
</li>
        
          <li class="md-nav__item">
  <a href="#to_string_5" class="md-nav__link">
    to_string
  </a>
  
</li>
        
          <li class="md-nav__item">
  <a href="#show_5" class="md-nav__link">
    show
  </a>
  
</li>
        
          <li class="md-nav__item">
  <a href="#pp_5" class="md-nav__link">
    pp
  </a>
  
</li>
        
      </ul>
    </nav>
  
</li>
      
        <li class="md-nav__item">
  <a href="#module-sklearndecompositionminibatchdictionarylearning" class="md-nav__link">
    module Sklearn.​Decomposition.​MiniBatchDictionaryLearning
  </a>
  
    <nav class="md-nav" aria-label="module Sklearn.​Decomposition.​MiniBatchDictionaryLearning">
      <ul class="md-nav__list">
        
          <li class="md-nav__item">
  <a href="#create_6" class="md-nav__link">
    create
  </a>
  
</li>
        
          <li class="md-nav__item">
  <a href="#fit_6" class="md-nav__link">
    fit
  </a>
  
</li>
        
          <li class="md-nav__item">
  <a href="#fit_transform_6" class="md-nav__link">
    fit_transform
  </a>
  
</li>
        
          <li class="md-nav__item">
  <a href="#get_params_6" class="md-nav__link">
    get_params
  </a>
  
</li>
        
          <li class="md-nav__item">
  <a href="#partial_fit_2" class="md-nav__link">
    partial_fit
  </a>
  
</li>
        
          <li class="md-nav__item">
  <a href="#set_params_6" class="md-nav__link">
    set_params
  </a>
  
</li>
        
          <li class="md-nav__item">
  <a href="#transform_6" class="md-nav__link">
    transform
  </a>
  
</li>
        
          <li class="md-nav__item">
  <a href="#components__5" class="md-nav__link">
    components_
  </a>
  
</li>
        
          <li class="md-nav__item">
  <a href="#inner_stats_" class="md-nav__link">
    inner_stats_
  </a>
  
</li>
        
          <li class="md-nav__item">
  <a href="#n_iter__4" class="md-nav__link">
    n_iter_
  </a>
  
</li>
        
          <li class="md-nav__item">
  <a href="#iter_offset_" class="md-nav__link">
    iter_offset_
  </a>
  
</li>
        
          <li class="md-nav__item">
  <a href="#random_state_" class="md-nav__link">
    random_state_
  </a>
  
</li>
        
          <li class="md-nav__item">
  <a href="#to_string_6" class="md-nav__link">
    to_string
  </a>
  
</li>
        
          <li class="md-nav__item">
  <a href="#show_6" class="md-nav__link">
    show
  </a>
  
</li>
        
          <li class="md-nav__item">
  <a href="#pp_6" class="md-nav__link">
    pp
  </a>
  
</li>
        
      </ul>
    </nav>
  
</li>
      
        <li class="md-nav__item">
  <a href="#module-sklearndecompositionminibatchsparsepca" class="md-nav__link">
    module Sklearn.​Decomposition.​MiniBatchSparsePCA
  </a>
  
    <nav class="md-nav" aria-label="module Sklearn.​Decomposition.​MiniBatchSparsePCA">
      <ul class="md-nav__list">
        
          <li class="md-nav__item">
  <a href="#create_7" class="md-nav__link">
    create
  </a>
  
</li>
        
          <li class="md-nav__item">
  <a href="#fit_7" class="md-nav__link">
    fit
  </a>
  
</li>
        
          <li class="md-nav__item">
  <a href="#fit_transform_7" class="md-nav__link">
    fit_transform
  </a>
  
</li>
        
          <li class="md-nav__item">
  <a href="#get_params_7" class="md-nav__link">
    get_params
  </a>
  
</li>
        
          <li class="md-nav__item">
  <a href="#set_params_7" class="md-nav__link">
    set_params
  </a>
  
</li>
        
          <li class="md-nav__item">
  <a href="#transform_7" class="md-nav__link">
    transform
  </a>
  
</li>
        
          <li class="md-nav__item">
  <a href="#components__6" class="md-nav__link">
    components_
  </a>
  
</li>
        
          <li class="md-nav__item">
  <a href="#n_iter__5" class="md-nav__link">
    n_iter_
  </a>
  
</li>
        
          <li class="md-nav__item">
  <a href="#mean__3" class="md-nav__link">
    mean_
  </a>
  
</li>
        
          <li class="md-nav__item">
  <a href="#to_string_7" class="md-nav__link">
    to_string
  </a>
  
</li>
        
          <li class="md-nav__item">
  <a href="#show_7" class="md-nav__link">
    show
  </a>
  
</li>
        
          <li class="md-nav__item">
  <a href="#pp_7" class="md-nav__link">
    pp
  </a>
  
</li>
        
      </ul>
    </nav>
  
</li>
      
        <li class="md-nav__item">
  <a href="#module-sklearndecompositionnmf" class="md-nav__link">
    module Sklearn.​Decomposition.​NMF
  </a>
  
    <nav class="md-nav" aria-label="module Sklearn.​Decomposition.​NMF">
      <ul class="md-nav__list">
        
          <li class="md-nav__item">
  <a href="#create_8" class="md-nav__link">
    create
  </a>
  
</li>
        
          <li class="md-nav__item">
  <a href="#fit_8" class="md-nav__link">
    fit
  </a>
  
</li>
        
          <li class="md-nav__item">
  <a href="#fit_transform_8" class="md-nav__link">
    fit_transform
  </a>
  
</li>
        
          <li class="md-nav__item">
  <a href="#get_params_8" class="md-nav__link">
    get_params
  </a>
  
</li>
        
          <li class="md-nav__item">
  <a href="#inverse_transform_3" class="md-nav__link">
    inverse_transform
  </a>
  
</li>
        
          <li class="md-nav__item">
  <a href="#set_params_8" class="md-nav__link">
    set_params
  </a>
  
</li>
        
          <li class="md-nav__item">
  <a href="#transform_8" class="md-nav__link">
    transform
  </a>
  
</li>
        
          <li class="md-nav__item">
  <a href="#components__7" class="md-nav__link">
    components_
  </a>
  
</li>
        
          <li class="md-nav__item">
  <a href="#n_components__1" class="md-nav__link">
    n_components_
  </a>
  
</li>
        
          <li class="md-nav__item">
  <a href="#reconstruction_err_" class="md-nav__link">
    reconstruction_err_
  </a>
  
</li>
        
          <li class="md-nav__item">
  <a href="#n_iter__6" class="md-nav__link">
    n_iter_
  </a>
  
</li>
        
          <li class="md-nav__item">
  <a href="#to_string_8" class="md-nav__link">
    to_string
  </a>
  
</li>
        
          <li class="md-nav__item">
  <a href="#show_8" class="md-nav__link">
    show
  </a>
  
</li>
        
          <li class="md-nav__item">
  <a href="#pp_8" class="md-nav__link">
    pp
  </a>
  
</li>
        
      </ul>
    </nav>
  
</li>
      
        <li class="md-nav__item">
  <a href="#module-sklearndecompositionpca" class="md-nav__link">
    module Sklearn.​Decomposition.​PCA
  </a>
  
    <nav class="md-nav" aria-label="module Sklearn.​Decomposition.​PCA">
      <ul class="md-nav__list">
        
          <li class="md-nav__item">
  <a href="#create_9" class="md-nav__link">
    create
  </a>
  
</li>
        
          <li class="md-nav__item">
  <a href="#fit_9" class="md-nav__link">
    fit
  </a>
  
</li>
        
          <li class="md-nav__item">
  <a href="#fit_transform_9" class="md-nav__link">
    fit_transform
  </a>
  
</li>
        
          <li class="md-nav__item">
  <a href="#get_covariance_2" class="md-nav__link">
    get_covariance
  </a>
  
</li>
        
          <li class="md-nav__item">
  <a href="#get_params_9" class="md-nav__link">
    get_params
  </a>
  
</li>
        
          <li class="md-nav__item">
  <a href="#get_precision_2" class="md-nav__link">
    get_precision
  </a>
  
</li>
        
          <li class="md-nav__item">
  <a href="#inverse_transform_4" class="md-nav__link">
    inverse_transform
  </a>
  
</li>
        
          <li class="md-nav__item">
  <a href="#score_2" class="md-nav__link">
    score
  </a>
  
</li>
        
          <li class="md-nav__item">
  <a href="#score_samples_1" class="md-nav__link">
    score_samples
  </a>
  
</li>
        
          <li class="md-nav__item">
  <a href="#set_params_9" class="md-nav__link">
    set_params
  </a>
  
</li>
        
          <li class="md-nav__item">
  <a href="#transform_9" class="md-nav__link">
    transform
  </a>
  
</li>
        
          <li class="md-nav__item">
  <a href="#components__8" class="md-nav__link">
    components_
  </a>
  
</li>
        
          <li class="md-nav__item">
  <a href="#explained_variance__1" class="md-nav__link">
    explained_variance_
  </a>
  
</li>
        
          <li class="md-nav__item">
  <a href="#explained_variance_ratio__1" class="md-nav__link">
    explained_variance_ratio_
  </a>
  
</li>
        
          <li class="md-nav__item">
  <a href="#singular_values__1" class="md-nav__link">
    singular_values_
  </a>
  
</li>
        
          <li class="md-nav__item">
  <a href="#mean__4" class="md-nav__link">
    mean_
  </a>
  
</li>
        
          <li class="md-nav__item">
  <a href="#n_components__2" class="md-nav__link">
    n_components_
  </a>
  
</li>
        
          <li class="md-nav__item">
  <a href="#n_features_" class="md-nav__link">
    n_features_
  </a>
  
</li>
        
          <li class="md-nav__item">
  <a href="#n_samples_" class="md-nav__link">
    n_samples_
  </a>
  
</li>
        
          <li class="md-nav__item">
  <a href="#noise_variance__2" class="md-nav__link">
    noise_variance_
  </a>
  
</li>
        
          <li class="md-nav__item">
  <a href="#to_string_9" class="md-nav__link">
    to_string
  </a>
  
</li>
        
          <li class="md-nav__item">
  <a href="#show_9" class="md-nav__link">
    show
  </a>
  
</li>
        
          <li class="md-nav__item">
  <a href="#pp_9" class="md-nav__link">
    pp
  </a>
  
</li>
        
      </ul>
    </nav>
  
</li>
      
        <li class="md-nav__item">
  <a href="#module-sklearndecompositionsparsecoder" class="md-nav__link">
    module Sklearn.​Decomposition.​SparseCoder
  </a>
  
    <nav class="md-nav" aria-label="module Sklearn.​Decomposition.​SparseCoder">
      <ul class="md-nav__list">
        
          <li class="md-nav__item">
  <a href="#create_10" class="md-nav__link">
    create
  </a>
  
</li>
        
          <li class="md-nav__item">
  <a href="#fit_10" class="md-nav__link">
    fit
  </a>
  
</li>
        
          <li class="md-nav__item">
  <a href="#fit_transform_10" class="md-nav__link">
    fit_transform
  </a>
  
</li>
        
          <li class="md-nav__item">
  <a href="#get_params_10" class="md-nav__link">
    get_params
  </a>
  
</li>
        
          <li class="md-nav__item">
  <a href="#set_params_10" class="md-nav__link">
    set_params
  </a>
  
</li>
        
          <li class="md-nav__item">
  <a href="#transform_10" class="md-nav__link">
    transform
  </a>
  
</li>
        
          <li class="md-nav__item">
  <a href="#components__9" class="md-nav__link">
    components_
  </a>
  
</li>
        
          <li class="md-nav__item">
  <a href="#to_string_10" class="md-nav__link">
    to_string
  </a>
  
</li>
        
          <li class="md-nav__item">
  <a href="#show_10" class="md-nav__link">
    show
  </a>
  
</li>
        
          <li class="md-nav__item">
  <a href="#pp_10" class="md-nav__link">
    pp
  </a>
  
</li>
        
      </ul>
    </nav>
  
</li>
      
        <li class="md-nav__item">
  <a href="#module-sklearndecompositionsparsepca" class="md-nav__link">
    module Sklearn.​Decomposition.​SparsePCA
  </a>
  
    <nav class="md-nav" aria-label="module Sklearn.​Decomposition.​SparsePCA">
      <ul class="md-nav__list">
        
          <li class="md-nav__item">
  <a href="#create_11" class="md-nav__link">
    create
  </a>
  
</li>
        
          <li class="md-nav__item">
  <a href="#fit_11" class="md-nav__link">
    fit
  </a>
  
</li>
        
          <li class="md-nav__item">
  <a href="#fit_transform_11" class="md-nav__link">
    fit_transform
  </a>
  
</li>
        
          <li class="md-nav__item">
  <a href="#get_params_11" class="md-nav__link">
    get_params
  </a>
  
</li>
        
          <li class="md-nav__item">
  <a href="#set_params_11" class="md-nav__link">
    set_params
  </a>
  
</li>
        
          <li class="md-nav__item">
  <a href="#transform_11" class="md-nav__link">
    transform
  </a>
  
</li>
        
          <li class="md-nav__item">
  <a href="#components__10" class="md-nav__link">
    components_
  </a>
  
</li>
        
          <li class="md-nav__item">
  <a href="#error__1" class="md-nav__link">
    error_
  </a>
  
</li>
        
          <li class="md-nav__item">
  <a href="#n_iter__7" class="md-nav__link">
    n_iter_
  </a>
  
</li>
        
          <li class="md-nav__item">
  <a href="#mean__5" class="md-nav__link">
    mean_
  </a>
  
</li>
        
          <li class="md-nav__item">
  <a href="#to_string_11" class="md-nav__link">
    to_string
  </a>
  
</li>
        
          <li class="md-nav__item">
  <a href="#show_11" class="md-nav__link">
    show
  </a>
  
</li>
        
          <li class="md-nav__item">
  <a href="#pp_11" class="md-nav__link">
    pp
  </a>
  
</li>
        
      </ul>
    </nav>
  
</li>
      
        <li class="md-nav__item">
  <a href="#module-sklearndecompositiontruncatedsvd" class="md-nav__link">
    module Sklearn.​Decomposition.​TruncatedSVD
  </a>
  
    <nav class="md-nav" aria-label="module Sklearn.​Decomposition.​TruncatedSVD">
      <ul class="md-nav__list">
        
          <li class="md-nav__item">
  <a href="#create_12" class="md-nav__link">
    create
  </a>
  
</li>
        
          <li class="md-nav__item">
  <a href="#fit_12" class="md-nav__link">
    fit
  </a>
  
</li>
        
          <li class="md-nav__item">
  <a href="#fit_transform_12" class="md-nav__link">
    fit_transform
  </a>
  
</li>
        
          <li class="md-nav__item">
  <a href="#get_params_12" class="md-nav__link">
    get_params
  </a>
  
</li>
        
          <li class="md-nav__item">
  <a href="#inverse_transform_5" class="md-nav__link">
    inverse_transform
  </a>
  
</li>
        
          <li class="md-nav__item">
  <a href="#set_params_12" class="md-nav__link">
    set_params
  </a>
  
</li>
        
          <li class="md-nav__item">
  <a href="#transform_12" class="md-nav__link">
    transform
  </a>
  
</li>
        
          <li class="md-nav__item">
  <a href="#components__11" class="md-nav__link">
    components_
  </a>
  
</li>
        
          <li class="md-nav__item">
  <a href="#explained_variance__2" class="md-nav__link">
    explained_variance_
  </a>
  
</li>
        
          <li class="md-nav__item">
  <a href="#explained_variance_ratio__2" class="md-nav__link">
    explained_variance_ratio_
  </a>
  
</li>
        
          <li class="md-nav__item">
  <a href="#singular_values__2" class="md-nav__link">
    singular_values_
  </a>
  
</li>
        
          <li class="md-nav__item">
  <a href="#to_string_12" class="md-nav__link">
    to_string
  </a>
  
</li>
        
          <li class="md-nav__item">
  <a href="#show_12" class="md-nav__link">
    show
  </a>
  
</li>
        
          <li class="md-nav__item">
  <a href="#pp_12" class="md-nav__link">
    pp
  </a>
  
</li>
        
          <li class="md-nav__item">
  <a href="#dict_learning" class="md-nav__link">
    dict_learning
  </a>
  
</li>
        
          <li class="md-nav__item">
  <a href="#dict_learning_online" class="md-nav__link">
    dict_learning_online
  </a>
  
</li>
        
          <li class="md-nav__item">
  <a href="#fastica" class="md-nav__link">
    fastica
  </a>
  
</li>
        
          <li class="md-nav__item">
  <a href="#non_negative_factorization" class="md-nav__link">
    non_negative_factorization
  </a>
  
</li>
        
          <li class="md-nav__item">
  <a href="#randomized_svd" class="md-nav__link">
    randomized_svd
  </a>
  
</li>
        
          <li class="md-nav__item">
  <a href="#sparse_encode" class="md-nav__link">
    sparse_encode
  </a>
  
</li>
        
      </ul>
    </nav>
  
</li>
      
    </ul>
  
</nav>
    
  </li>

    
      
      
      


  <li class="md-nav__item">
    <a href="../discriminant_analysis/" title="Discriminant analysis" class="md-nav__link">
      Discriminant analysis
    </a>
  </li>

    
      
      
      


  <li class="md-nav__item">
    <a href="../dummy/" title="Dummy" class="md-nav__link">
      Dummy
    </a>
  </li>

    
      
      
      


  <li class="md-nav__item">
    <a href="../ensemble/" title="Ensemble" class="md-nav__link">
      Ensemble
    </a>
  </li>

    
      
      
      


  <li class="md-nav__item">
    <a href="../exceptions/" title="Exceptions" class="md-nav__link">
      Exceptions
    </a>
  </li>

    
      
      
      


  <li class="md-nav__item">
    <a href="../experimental/" title="Experimental" class="md-nav__link">
      Experimental
    </a>
  </li>

    
      
      
      


  <li class="md-nav__item">
    <a href="../externals/" title="Externals" class="md-nav__link">
      Externals
    </a>
  </li>

    
      
      
      


  <li class="md-nav__item">
    <a href="../feature_extraction/" title="Feature extraction" class="md-nav__link">
      Feature extraction
    </a>
  </li>

    
      
      
      


  <li class="md-nav__item">
    <a href="../feature_selection/" title="Feature selection" class="md-nav__link">
      Feature selection
    </a>
  </li>

    
      
      
      


  <li class="md-nav__item">
    <a href="../gaussian_process/" title="Gaussian process" class="md-nav__link">
      Gaussian process
    </a>
  </li>

    
      
      
      


  <li class="md-nav__item">
    <a href="../impute/" title="Impute" class="md-nav__link">
      Impute
    </a>
  </li>

    
      
      
      


  <li class="md-nav__item">
    <a href="../inspection/" title="Inspection" class="md-nav__link">
      Inspection
    </a>
  </li>

    
      
      
      


  <li class="md-nav__item">
    <a href="../isotonic/" title="Isotonic" class="md-nav__link">
      Isotonic
    </a>
  </li>

    
      
      
      


  <li class="md-nav__item">
    <a href="../kernel_approximation/" title="Kernel approximation" class="md-nav__link">
      Kernel approximation
    </a>
  </li>

    
      
      
      


  <li class="md-nav__item">
    <a href="../kernel_ridge/" title="Kernel ridge" class="md-nav__link">
      Kernel ridge
    </a>
  </li>

    
      
      
      


  <li class="md-nav__item">
    <a href="../linear_model/" title="Linear model" class="md-nav__link">
      Linear model
    </a>
  </li>

    
      
      
      


  <li class="md-nav__item">
    <a href="../manifold/" title="Manifold" class="md-nav__link">
      Manifold
    </a>
  </li>

    
      
      
      


  <li class="md-nav__item">
    <a href="../metrics/" title="Metrics" class="md-nav__link">
      Metrics
    </a>
  </li>

    
      
      
      


  <li class="md-nav__item">
    <a href="../mixture/" title="Mixture" class="md-nav__link">
      Mixture
    </a>
  </li>

    
      
      
      


  <li class="md-nav__item">
    <a href="../model_selection/" title="Model selection" class="md-nav__link">
      Model selection
    </a>
  </li>

    
      
      
      


  <li class="md-nav__item">
    <a href="../multiclass/" title="Multiclass" class="md-nav__link">
      Multiclass
    </a>
  </li>

    
      
      
      


  <li class="md-nav__item">
    <a href="../multioutput/" title="Multioutput" class="md-nav__link">
      Multioutput
    </a>
  </li>

    
      
      
      


  <li class="md-nav__item">
    <a href="../naive_bayes/" title="Naive bayes" class="md-nav__link">
      Naive bayes
    </a>
  </li>

    
      
      
      


  <li class="md-nav__item">
    <a href="../neighbors/" title="Neighbors" class="md-nav__link">
      Neighbors
    </a>
  </li>

    
      
      
      


  <li class="md-nav__item">
    <a href="../neural_network/" title="Neural network" class="md-nav__link">
      Neural network
    </a>
  </li>

    
      
      
      


  <li class="md-nav__item">
    <a href="../pipeline/" title="Pipeline" class="md-nav__link">
      Pipeline
    </a>
  </li>

    
      
      
      


  <li class="md-nav__item">
    <a href="../preprocessing/" title="Preprocessing" class="md-nav__link">
      Preprocessing
    </a>
  </li>

    
      
      
      


  <li class="md-nav__item">
    <a href="../random_projection/" title="Random projection" class="md-nav__link">
      Random projection
    </a>
  </li>

    
      
      
      


  <li class="md-nav__item">
    <a href="../semi_supervised/" title="Semi supervised" class="md-nav__link">
      Semi supervised
    </a>
  </li>

    
      
      
      


  <li class="md-nav__item">
    <a href="../setup/" title="Setup" class="md-nav__link">
      Setup
    </a>
  </li>

    
      
      
      


  <li class="md-nav__item">
    <a href="../svm/" title="Svm" class="md-nav__link">
      Svm
    </a>
  </li>

    
      
      
      


  <li class="md-nav__item">
    <a href="../tests/" title="Tests" class="md-nav__link">
      Tests
    </a>
  </li>

    
      
      
      


  <li class="md-nav__item">
    <a href="../tree/" title="Tree" class="md-nav__link">
      Tree
    </a>
  </li>

    
      
      
      


  <li class="md-nav__item">
    <a href="../utils/" title="Utils" class="md-nav__link">
      Utils
    </a>
  </li>

    
  </ul>
</nav>
                  </div>
                </div>
              </div>
            
            
              <div class="md-sidebar md-sidebar--secondary" data-md-component="toc">
                <div class="md-sidebar__scrollwrap">
                  <div class="md-sidebar__inner">
                    
<nav class="md-nav md-nav--secondary" aria-label="Table of contents">
  
  
  
    <label class="md-nav__title" for="__toc">
      <span class="md-nav__icon md-icon">
        <svg xmlns="http://www.w3.org/2000/svg" viewBox="0 0 24 24"><path d="M20,11V13H8L13.5,18.5L12.08,19.92L4.16,12L12.08,4.08L13.5,5.5L8,11H20Z" /></svg>
      </span>
      Table of contents
    </label>
    <ul class="md-nav__list" data-md-scrollfix>
      
        <li class="md-nav__item">
  <a href="#module-sklearndecompositiondictionarylearning" class="md-nav__link">
    module Sklearn.​Decomposition.​DictionaryLearning
  </a>
  
    <nav class="md-nav" aria-label="module Sklearn.​Decomposition.​DictionaryLearning">
      <ul class="md-nav__list">
        
          <li class="md-nav__item">
  <a href="#create" class="md-nav__link">
    create
  </a>
  
</li>
        
          <li class="md-nav__item">
  <a href="#fit" class="md-nav__link">
    fit
  </a>
  
</li>
        
          <li class="md-nav__item">
  <a href="#fit_transform" class="md-nav__link">
    fit_transform
  </a>
  
</li>
        
          <li class="md-nav__item">
  <a href="#get_params" class="md-nav__link">
    get_params
  </a>
  
</li>
        
          <li class="md-nav__item">
  <a href="#set_params" class="md-nav__link">
    set_params
  </a>
  
</li>
        
          <li class="md-nav__item">
  <a href="#transform" class="md-nav__link">
    transform
  </a>
  
</li>
        
          <li class="md-nav__item">
  <a href="#components_" class="md-nav__link">
    components_
  </a>
  
</li>
        
          <li class="md-nav__item">
  <a href="#error_" class="md-nav__link">
    error_
  </a>
  
</li>
        
          <li class="md-nav__item">
  <a href="#n_iter_" class="md-nav__link">
    n_iter_
  </a>
  
</li>
        
          <li class="md-nav__item">
  <a href="#to_string" class="md-nav__link">
    to_string
  </a>
  
</li>
        
          <li class="md-nav__item">
  <a href="#show" class="md-nav__link">
    show
  </a>
  
</li>
        
          <li class="md-nav__item">
  <a href="#pp" class="md-nav__link">
    pp
  </a>
  
</li>
        
      </ul>
    </nav>
  
</li>
      
        <li class="md-nav__item">
  <a href="#module-sklearndecompositionfactoranalysis" class="md-nav__link">
    module Sklearn.​Decomposition.​FactorAnalysis
  </a>
  
    <nav class="md-nav" aria-label="module Sklearn.​Decomposition.​FactorAnalysis">
      <ul class="md-nav__list">
        
          <li class="md-nav__item">
  <a href="#create_1" class="md-nav__link">
    create
  </a>
  
</li>
        
          <li class="md-nav__item">
  <a href="#fit_1" class="md-nav__link">
    fit
  </a>
  
</li>
        
          <li class="md-nav__item">
  <a href="#fit_transform_1" class="md-nav__link">
    fit_transform
  </a>
  
</li>
        
          <li class="md-nav__item">
  <a href="#get_covariance" class="md-nav__link">
    get_covariance
  </a>
  
</li>
        
          <li class="md-nav__item">
  <a href="#get_params_1" class="md-nav__link">
    get_params
  </a>
  
</li>
        
          <li class="md-nav__item">
  <a href="#get_precision" class="md-nav__link">
    get_precision
  </a>
  
</li>
        
          <li class="md-nav__item">
  <a href="#score" class="md-nav__link">
    score
  </a>
  
</li>
        
          <li class="md-nav__item">
  <a href="#score_samples" class="md-nav__link">
    score_samples
  </a>
  
</li>
        
          <li class="md-nav__item">
  <a href="#set_params_1" class="md-nav__link">
    set_params
  </a>
  
</li>
        
          <li class="md-nav__item">
  <a href="#transform_1" class="md-nav__link">
    transform
  </a>
  
</li>
        
          <li class="md-nav__item">
  <a href="#components__1" class="md-nav__link">
    components_
  </a>
  
</li>
        
          <li class="md-nav__item">
  <a href="#loglike_" class="md-nav__link">
    loglike_
  </a>
  
</li>
        
          <li class="md-nav__item">
  <a href="#noise_variance_" class="md-nav__link">
    noise_variance_
  </a>
  
</li>
        
          <li class="md-nav__item">
  <a href="#n_iter__1" class="md-nav__link">
    n_iter_
  </a>
  
</li>
        
          <li class="md-nav__item">
  <a href="#mean_" class="md-nav__link">
    mean_
  </a>
  
</li>
        
          <li class="md-nav__item">
  <a href="#to_string_1" class="md-nav__link">
    to_string
  </a>
  
</li>
        
          <li class="md-nav__item">
  <a href="#show_1" class="md-nav__link">
    show
  </a>
  
</li>
        
          <li class="md-nav__item">
  <a href="#pp_1" class="md-nav__link">
    pp
  </a>
  
</li>
        
      </ul>
    </nav>
  
</li>
      
        <li class="md-nav__item">
  <a href="#module-sklearndecompositionfastica" class="md-nav__link">
    module Sklearn.​Decomposition.​FastICA
  </a>
  
    <nav class="md-nav" aria-label="module Sklearn.​Decomposition.​FastICA">
      <ul class="md-nav__list">
        
          <li class="md-nav__item">
  <a href="#create_2" class="md-nav__link">
    create
  </a>
  
</li>
        
          <li class="md-nav__item">
  <a href="#fit_2" class="md-nav__link">
    fit
  </a>
  
</li>
        
          <li class="md-nav__item">
  <a href="#fit_transform_2" class="md-nav__link">
    fit_transform
  </a>
  
</li>
        
          <li class="md-nav__item">
  <a href="#get_params_2" class="md-nav__link">
    get_params
  </a>
  
</li>
        
          <li class="md-nav__item">
  <a href="#inverse_transform" class="md-nav__link">
    inverse_transform
  </a>
  
</li>
        
          <li class="md-nav__item">
  <a href="#set_params_2" class="md-nav__link">
    set_params
  </a>
  
</li>
        
          <li class="md-nav__item">
  <a href="#transform_2" class="md-nav__link">
    transform
  </a>
  
</li>
        
          <li class="md-nav__item">
  <a href="#components__2" class="md-nav__link">
    components_
  </a>
  
</li>
        
          <li class="md-nav__item">
  <a href="#mixing_" class="md-nav__link">
    mixing_
  </a>
  
</li>
        
          <li class="md-nav__item">
  <a href="#mean__1" class="md-nav__link">
    mean_
  </a>
  
</li>
        
          <li class="md-nav__item">
  <a href="#n_iter__2" class="md-nav__link">
    n_iter_
  </a>
  
</li>
        
          <li class="md-nav__item">
  <a href="#whitening_" class="md-nav__link">
    whitening_
  </a>
  
</li>
        
          <li class="md-nav__item">
  <a href="#to_string_2" class="md-nav__link">
    to_string
  </a>
  
</li>
        
          <li class="md-nav__item">
  <a href="#show_2" class="md-nav__link">
    show
  </a>
  
</li>
        
          <li class="md-nav__item">
  <a href="#pp_2" class="md-nav__link">
    pp
  </a>
  
</li>
        
      </ul>
    </nav>
  
</li>
      
        <li class="md-nav__item">
  <a href="#module-sklearndecompositionincrementalpca" class="md-nav__link">
    module Sklearn.​Decomposition.​IncrementalPCA
  </a>
  
    <nav class="md-nav" aria-label="module Sklearn.​Decomposition.​IncrementalPCA">
      <ul class="md-nav__list">
        
          <li class="md-nav__item">
  <a href="#create_3" class="md-nav__link">
    create
  </a>
  
</li>
        
          <li class="md-nav__item">
  <a href="#fit_3" class="md-nav__link">
    fit
  </a>
  
</li>
        
          <li class="md-nav__item">
  <a href="#fit_transform_3" class="md-nav__link">
    fit_transform
  </a>
  
</li>
        
          <li class="md-nav__item">
  <a href="#get_covariance_1" class="md-nav__link">
    get_covariance
  </a>
  
</li>
        
          <li class="md-nav__item">
  <a href="#get_params_3" class="md-nav__link">
    get_params
  </a>
  
</li>
        
          <li class="md-nav__item">
  <a href="#get_precision_1" class="md-nav__link">
    get_precision
  </a>
  
</li>
        
          <li class="md-nav__item">
  <a href="#inverse_transform_1" class="md-nav__link">
    inverse_transform
  </a>
  
</li>
        
          <li class="md-nav__item">
  <a href="#partial_fit" class="md-nav__link">
    partial_fit
  </a>
  
</li>
        
          <li class="md-nav__item">
  <a href="#set_params_3" class="md-nav__link">
    set_params
  </a>
  
</li>
        
          <li class="md-nav__item">
  <a href="#transform_3" class="md-nav__link">
    transform
  </a>
  
</li>
        
          <li class="md-nav__item">
  <a href="#components__3" class="md-nav__link">
    components_
  </a>
  
</li>
        
          <li class="md-nav__item">
  <a href="#explained_variance_" class="md-nav__link">
    explained_variance_
  </a>
  
</li>
        
          <li class="md-nav__item">
  <a href="#explained_variance_ratio_" class="md-nav__link">
    explained_variance_ratio_
  </a>
  
</li>
        
          <li class="md-nav__item">
  <a href="#singular_values_" class="md-nav__link">
    singular_values_
  </a>
  
</li>
        
          <li class="md-nav__item">
  <a href="#mean__2" class="md-nav__link">
    mean_
  </a>
  
</li>
        
          <li class="md-nav__item">
  <a href="#var_" class="md-nav__link">
    var_
  </a>
  
</li>
        
          <li class="md-nav__item">
  <a href="#noise_variance__1" class="md-nav__link">
    noise_variance_
  </a>
  
</li>
        
          <li class="md-nav__item">
  <a href="#n_components_" class="md-nav__link">
    n_components_
  </a>
  
</li>
        
          <li class="md-nav__item">
  <a href="#n_samples_seen_" class="md-nav__link">
    n_samples_seen_
  </a>
  
</li>
        
          <li class="md-nav__item">
  <a href="#to_string_3" class="md-nav__link">
    to_string
  </a>
  
</li>
        
          <li class="md-nav__item">
  <a href="#show_3" class="md-nav__link">
    show
  </a>
  
</li>
        
          <li class="md-nav__item">
  <a href="#pp_3" class="md-nav__link">
    pp
  </a>
  
</li>
        
      </ul>
    </nav>
  
</li>
      
        <li class="md-nav__item">
  <a href="#module-sklearndecompositionkernelpca" class="md-nav__link">
    module Sklearn.​Decomposition.​KernelPCA
  </a>
  
    <nav class="md-nav" aria-label="module Sklearn.​Decomposition.​KernelPCA">
      <ul class="md-nav__list">
        
          <li class="md-nav__item">
  <a href="#create_4" class="md-nav__link">
    create
  </a>
  
</li>
        
          <li class="md-nav__item">
  <a href="#fit_4" class="md-nav__link">
    fit
  </a>
  
</li>
        
          <li class="md-nav__item">
  <a href="#fit_transform_4" class="md-nav__link">
    fit_transform
  </a>
  
</li>
        
          <li class="md-nav__item">
  <a href="#get_params_4" class="md-nav__link">
    get_params
  </a>
  
</li>
        
          <li class="md-nav__item">
  <a href="#inverse_transform_2" class="md-nav__link">
    inverse_transform
  </a>
  
</li>
        
          <li class="md-nav__item">
  <a href="#set_params_4" class="md-nav__link">
    set_params
  </a>
  
</li>
        
          <li class="md-nav__item">
  <a href="#transform_4" class="md-nav__link">
    transform
  </a>
  
</li>
        
          <li class="md-nav__item">
  <a href="#lambdas_" class="md-nav__link">
    lambdas_
  </a>
  
</li>
        
          <li class="md-nav__item">
  <a href="#alphas_" class="md-nav__link">
    alphas_
  </a>
  
</li>
        
          <li class="md-nav__item">
  <a href="#dual_coef_" class="md-nav__link">
    dual_coef_
  </a>
  
</li>
        
          <li class="md-nav__item">
  <a href="#x_transformed_fit_" class="md-nav__link">
    x_transformed_fit_
  </a>
  
</li>
        
          <li class="md-nav__item">
  <a href="#x_fit_" class="md-nav__link">
    x_fit_
  </a>
  
</li>
        
          <li class="md-nav__item">
  <a href="#to_string_4" class="md-nav__link">
    to_string
  </a>
  
</li>
        
          <li class="md-nav__item">
  <a href="#show_4" class="md-nav__link">
    show
  </a>
  
</li>
        
          <li class="md-nav__item">
  <a href="#pp_4" class="md-nav__link">
    pp
  </a>
  
</li>
        
      </ul>
    </nav>
  
</li>
      
        <li class="md-nav__item">
  <a href="#module-sklearndecompositionlatentdirichletallocation" class="md-nav__link">
    module Sklearn.​Decomposition.​LatentDirichletAllocation
  </a>
  
    <nav class="md-nav" aria-label="module Sklearn.​Decomposition.​LatentDirichletAllocation">
      <ul class="md-nav__list">
        
          <li class="md-nav__item">
  <a href="#create_5" class="md-nav__link">
    create
  </a>
  
</li>
        
          <li class="md-nav__item">
  <a href="#fit_5" class="md-nav__link">
    fit
  </a>
  
</li>
        
          <li class="md-nav__item">
  <a href="#fit_transform_5" class="md-nav__link">
    fit_transform
  </a>
  
</li>
        
          <li class="md-nav__item">
  <a href="#get_params_5" class="md-nav__link">
    get_params
  </a>
  
</li>
        
          <li class="md-nav__item">
  <a href="#partial_fit_1" class="md-nav__link">
    partial_fit
  </a>
  
</li>
        
          <li class="md-nav__item">
  <a href="#perplexity" class="md-nav__link">
    perplexity
  </a>
  
</li>
        
          <li class="md-nav__item">
  <a href="#score_1" class="md-nav__link">
    score
  </a>
  
</li>
        
          <li class="md-nav__item">
  <a href="#set_params_5" class="md-nav__link">
    set_params
  </a>
  
</li>
        
          <li class="md-nav__item">
  <a href="#transform_5" class="md-nav__link">
    transform
  </a>
  
</li>
        
          <li class="md-nav__item">
  <a href="#components__4" class="md-nav__link">
    components_
  </a>
  
</li>
        
          <li class="md-nav__item">
  <a href="#n_batch_iter_" class="md-nav__link">
    n_batch_iter_
  </a>
  
</li>
        
          <li class="md-nav__item">
  <a href="#n_iter__3" class="md-nav__link">
    n_iter_
  </a>
  
</li>
        
          <li class="md-nav__item">
  <a href="#bound_" class="md-nav__link">
    bound_
  </a>
  
</li>
        
          <li class="md-nav__item">
  <a href="#doc_topic_prior_" class="md-nav__link">
    doc_topic_prior_
  </a>
  
</li>
        
          <li class="md-nav__item">
  <a href="#topic_word_prior_" class="md-nav__link">
    topic_word_prior_
  </a>
  
</li>
        
          <li class="md-nav__item">
  <a href="#to_string_5" class="md-nav__link">
    to_string
  </a>
  
</li>
        
          <li class="md-nav__item">
  <a href="#show_5" class="md-nav__link">
    show
  </a>
  
</li>
        
          <li class="md-nav__item">
  <a href="#pp_5" class="md-nav__link">
    pp
  </a>
  
</li>
        
      </ul>
    </nav>
  
</li>
      
        <li class="md-nav__item">
  <a href="#module-sklearndecompositionminibatchdictionarylearning" class="md-nav__link">
    module Sklearn.​Decomposition.​MiniBatchDictionaryLearning
  </a>
  
    <nav class="md-nav" aria-label="module Sklearn.​Decomposition.​MiniBatchDictionaryLearning">
      <ul class="md-nav__list">
        
          <li class="md-nav__item">
  <a href="#create_6" class="md-nav__link">
    create
  </a>
  
</li>
        
          <li class="md-nav__item">
  <a href="#fit_6" class="md-nav__link">
    fit
  </a>
  
</li>
        
          <li class="md-nav__item">
  <a href="#fit_transform_6" class="md-nav__link">
    fit_transform
  </a>
  
</li>
        
          <li class="md-nav__item">
  <a href="#get_params_6" class="md-nav__link">
    get_params
  </a>
  
</li>
        
          <li class="md-nav__item">
  <a href="#partial_fit_2" class="md-nav__link">
    partial_fit
  </a>
  
</li>
        
          <li class="md-nav__item">
  <a href="#set_params_6" class="md-nav__link">
    set_params
  </a>
  
</li>
        
          <li class="md-nav__item">
  <a href="#transform_6" class="md-nav__link">
    transform
  </a>
  
</li>
        
          <li class="md-nav__item">
  <a href="#components__5" class="md-nav__link">
    components_
  </a>
  
</li>
        
          <li class="md-nav__item">
  <a href="#inner_stats_" class="md-nav__link">
    inner_stats_
  </a>
  
</li>
        
          <li class="md-nav__item">
  <a href="#n_iter__4" class="md-nav__link">
    n_iter_
  </a>
  
</li>
        
          <li class="md-nav__item">
  <a href="#iter_offset_" class="md-nav__link">
    iter_offset_
  </a>
  
</li>
        
          <li class="md-nav__item">
  <a href="#random_state_" class="md-nav__link">
    random_state_
  </a>
  
</li>
        
          <li class="md-nav__item">
  <a href="#to_string_6" class="md-nav__link">
    to_string
  </a>
  
</li>
        
          <li class="md-nav__item">
  <a href="#show_6" class="md-nav__link">
    show
  </a>
  
</li>
        
          <li class="md-nav__item">
  <a href="#pp_6" class="md-nav__link">
    pp
  </a>
  
</li>
        
      </ul>
    </nav>
  
</li>
      
        <li class="md-nav__item">
  <a href="#module-sklearndecompositionminibatchsparsepca" class="md-nav__link">
    module Sklearn.​Decomposition.​MiniBatchSparsePCA
  </a>
  
    <nav class="md-nav" aria-label="module Sklearn.​Decomposition.​MiniBatchSparsePCA">
      <ul class="md-nav__list">
        
          <li class="md-nav__item">
  <a href="#create_7" class="md-nav__link">
    create
  </a>
  
</li>
        
          <li class="md-nav__item">
  <a href="#fit_7" class="md-nav__link">
    fit
  </a>
  
</li>
        
          <li class="md-nav__item">
  <a href="#fit_transform_7" class="md-nav__link">
    fit_transform
  </a>
  
</li>
        
          <li class="md-nav__item">
  <a href="#get_params_7" class="md-nav__link">
    get_params
  </a>
  
</li>
        
          <li class="md-nav__item">
  <a href="#set_params_7" class="md-nav__link">
    set_params
  </a>
  
</li>
        
          <li class="md-nav__item">
  <a href="#transform_7" class="md-nav__link">
    transform
  </a>
  
</li>
        
          <li class="md-nav__item">
  <a href="#components__6" class="md-nav__link">
    components_
  </a>
  
</li>
        
          <li class="md-nav__item">
  <a href="#n_iter__5" class="md-nav__link">
    n_iter_
  </a>
  
</li>
        
          <li class="md-nav__item">
  <a href="#mean__3" class="md-nav__link">
    mean_
  </a>
  
</li>
        
          <li class="md-nav__item">
  <a href="#to_string_7" class="md-nav__link">
    to_string
  </a>
  
</li>
        
          <li class="md-nav__item">
  <a href="#show_7" class="md-nav__link">
    show
  </a>
  
</li>
        
          <li class="md-nav__item">
  <a href="#pp_7" class="md-nav__link">
    pp
  </a>
  
</li>
        
      </ul>
    </nav>
  
</li>
      
        <li class="md-nav__item">
  <a href="#module-sklearndecompositionnmf" class="md-nav__link">
    module Sklearn.​Decomposition.​NMF
  </a>
  
    <nav class="md-nav" aria-label="module Sklearn.​Decomposition.​NMF">
      <ul class="md-nav__list">
        
          <li class="md-nav__item">
  <a href="#create_8" class="md-nav__link">
    create
  </a>
  
</li>
        
          <li class="md-nav__item">
  <a href="#fit_8" class="md-nav__link">
    fit
  </a>
  
</li>
        
          <li class="md-nav__item">
  <a href="#fit_transform_8" class="md-nav__link">
    fit_transform
  </a>
  
</li>
        
          <li class="md-nav__item">
  <a href="#get_params_8" class="md-nav__link">
    get_params
  </a>
  
</li>
        
          <li class="md-nav__item">
  <a href="#inverse_transform_3" class="md-nav__link">
    inverse_transform
  </a>
  
</li>
        
          <li class="md-nav__item">
  <a href="#set_params_8" class="md-nav__link">
    set_params
  </a>
  
</li>
        
          <li class="md-nav__item">
  <a href="#transform_8" class="md-nav__link">
    transform
  </a>
  
</li>
        
          <li class="md-nav__item">
  <a href="#components__7" class="md-nav__link">
    components_
  </a>
  
</li>
        
          <li class="md-nav__item">
  <a href="#n_components__1" class="md-nav__link">
    n_components_
  </a>
  
</li>
        
          <li class="md-nav__item">
  <a href="#reconstruction_err_" class="md-nav__link">
    reconstruction_err_
  </a>
  
</li>
        
          <li class="md-nav__item">
  <a href="#n_iter__6" class="md-nav__link">
    n_iter_
  </a>
  
</li>
        
          <li class="md-nav__item">
  <a href="#to_string_8" class="md-nav__link">
    to_string
  </a>
  
</li>
        
          <li class="md-nav__item">
  <a href="#show_8" class="md-nav__link">
    show
  </a>
  
</li>
        
          <li class="md-nav__item">
  <a href="#pp_8" class="md-nav__link">
    pp
  </a>
  
</li>
        
      </ul>
    </nav>
  
</li>
      
        <li class="md-nav__item">
  <a href="#module-sklearndecompositionpca" class="md-nav__link">
    module Sklearn.​Decomposition.​PCA
  </a>
  
    <nav class="md-nav" aria-label="module Sklearn.​Decomposition.​PCA">
      <ul class="md-nav__list">
        
          <li class="md-nav__item">
  <a href="#create_9" class="md-nav__link">
    create
  </a>
  
</li>
        
          <li class="md-nav__item">
  <a href="#fit_9" class="md-nav__link">
    fit
  </a>
  
</li>
        
          <li class="md-nav__item">
  <a href="#fit_transform_9" class="md-nav__link">
    fit_transform
  </a>
  
</li>
        
          <li class="md-nav__item">
  <a href="#get_covariance_2" class="md-nav__link">
    get_covariance
  </a>
  
</li>
        
          <li class="md-nav__item">
  <a href="#get_params_9" class="md-nav__link">
    get_params
  </a>
  
</li>
        
          <li class="md-nav__item">
  <a href="#get_precision_2" class="md-nav__link">
    get_precision
  </a>
  
</li>
        
          <li class="md-nav__item">
  <a href="#inverse_transform_4" class="md-nav__link">
    inverse_transform
  </a>
  
</li>
        
          <li class="md-nav__item">
  <a href="#score_2" class="md-nav__link">
    score
  </a>
  
</li>
        
          <li class="md-nav__item">
  <a href="#score_samples_1" class="md-nav__link">
    score_samples
  </a>
  
</li>
        
          <li class="md-nav__item">
  <a href="#set_params_9" class="md-nav__link">
    set_params
  </a>
  
</li>
        
          <li class="md-nav__item">
  <a href="#transform_9" class="md-nav__link">
    transform
  </a>
  
</li>
        
          <li class="md-nav__item">
  <a href="#components__8" class="md-nav__link">
    components_
  </a>
  
</li>
        
          <li class="md-nav__item">
  <a href="#explained_variance__1" class="md-nav__link">
    explained_variance_
  </a>
  
</li>
        
          <li class="md-nav__item">
  <a href="#explained_variance_ratio__1" class="md-nav__link">
    explained_variance_ratio_
  </a>
  
</li>
        
          <li class="md-nav__item">
  <a href="#singular_values__1" class="md-nav__link">
    singular_values_
  </a>
  
</li>
        
          <li class="md-nav__item">
  <a href="#mean__4" class="md-nav__link">
    mean_
  </a>
  
</li>
        
          <li class="md-nav__item">
  <a href="#n_components__2" class="md-nav__link">
    n_components_
  </a>
  
</li>
        
          <li class="md-nav__item">
  <a href="#n_features_" class="md-nav__link">
    n_features_
  </a>
  
</li>
        
          <li class="md-nav__item">
  <a href="#n_samples_" class="md-nav__link">
    n_samples_
  </a>
  
</li>
        
          <li class="md-nav__item">
  <a href="#noise_variance__2" class="md-nav__link">
    noise_variance_
  </a>
  
</li>
        
          <li class="md-nav__item">
  <a href="#to_string_9" class="md-nav__link">
    to_string
  </a>
  
</li>
        
          <li class="md-nav__item">
  <a href="#show_9" class="md-nav__link">
    show
  </a>
  
</li>
        
          <li class="md-nav__item">
  <a href="#pp_9" class="md-nav__link">
    pp
  </a>
  
</li>
        
      </ul>
    </nav>
  
</li>
      
        <li class="md-nav__item">
  <a href="#module-sklearndecompositionsparsecoder" class="md-nav__link">
    module Sklearn.​Decomposition.​SparseCoder
  </a>
  
    <nav class="md-nav" aria-label="module Sklearn.​Decomposition.​SparseCoder">
      <ul class="md-nav__list">
        
          <li class="md-nav__item">
  <a href="#create_10" class="md-nav__link">
    create
  </a>
  
</li>
        
          <li class="md-nav__item">
  <a href="#fit_10" class="md-nav__link">
    fit
  </a>
  
</li>
        
          <li class="md-nav__item">
  <a href="#fit_transform_10" class="md-nav__link">
    fit_transform
  </a>
  
</li>
        
          <li class="md-nav__item">
  <a href="#get_params_10" class="md-nav__link">
    get_params
  </a>
  
</li>
        
          <li class="md-nav__item">
  <a href="#set_params_10" class="md-nav__link">
    set_params
  </a>
  
</li>
        
          <li class="md-nav__item">
  <a href="#transform_10" class="md-nav__link">
    transform
  </a>
  
</li>
        
          <li class="md-nav__item">
  <a href="#components__9" class="md-nav__link">
    components_
  </a>
  
</li>
        
          <li class="md-nav__item">
  <a href="#to_string_10" class="md-nav__link">
    to_string
  </a>
  
</li>
        
          <li class="md-nav__item">
  <a href="#show_10" class="md-nav__link">
    show
  </a>
  
</li>
        
          <li class="md-nav__item">
  <a href="#pp_10" class="md-nav__link">
    pp
  </a>
  
</li>
        
      </ul>
    </nav>
  
</li>
      
        <li class="md-nav__item">
  <a href="#module-sklearndecompositionsparsepca" class="md-nav__link">
    module Sklearn.​Decomposition.​SparsePCA
  </a>
  
    <nav class="md-nav" aria-label="module Sklearn.​Decomposition.​SparsePCA">
      <ul class="md-nav__list">
        
          <li class="md-nav__item">
  <a href="#create_11" class="md-nav__link">
    create
  </a>
  
</li>
        
          <li class="md-nav__item">
  <a href="#fit_11" class="md-nav__link">
    fit
  </a>
  
</li>
        
          <li class="md-nav__item">
  <a href="#fit_transform_11" class="md-nav__link">
    fit_transform
  </a>
  
</li>
        
          <li class="md-nav__item">
  <a href="#get_params_11" class="md-nav__link">
    get_params
  </a>
  
</li>
        
          <li class="md-nav__item">
  <a href="#set_params_11" class="md-nav__link">
    set_params
  </a>
  
</li>
        
          <li class="md-nav__item">
  <a href="#transform_11" class="md-nav__link">
    transform
  </a>
  
</li>
        
          <li class="md-nav__item">
  <a href="#components__10" class="md-nav__link">
    components_
  </a>
  
</li>
        
          <li class="md-nav__item">
  <a href="#error__1" class="md-nav__link">
    error_
  </a>
  
</li>
        
          <li class="md-nav__item">
  <a href="#n_iter__7" class="md-nav__link">
    n_iter_
  </a>
  
</li>
        
          <li class="md-nav__item">
  <a href="#mean__5" class="md-nav__link">
    mean_
  </a>
  
</li>
        
          <li class="md-nav__item">
  <a href="#to_string_11" class="md-nav__link">
    to_string
  </a>
  
</li>
        
          <li class="md-nav__item">
  <a href="#show_11" class="md-nav__link">
    show
  </a>
  
</li>
        
          <li class="md-nav__item">
  <a href="#pp_11" class="md-nav__link">
    pp
  </a>
  
</li>
        
      </ul>
    </nav>
  
</li>
      
        <li class="md-nav__item">
  <a href="#module-sklearndecompositiontruncatedsvd" class="md-nav__link">
    module Sklearn.​Decomposition.​TruncatedSVD
  </a>
  
    <nav class="md-nav" aria-label="module Sklearn.​Decomposition.​TruncatedSVD">
      <ul class="md-nav__list">
        
          <li class="md-nav__item">
  <a href="#create_12" class="md-nav__link">
    create
  </a>
  
</li>
        
          <li class="md-nav__item">
  <a href="#fit_12" class="md-nav__link">
    fit
  </a>
  
</li>
        
          <li class="md-nav__item">
  <a href="#fit_transform_12" class="md-nav__link">
    fit_transform
  </a>
  
</li>
        
          <li class="md-nav__item">
  <a href="#get_params_12" class="md-nav__link">
    get_params
  </a>
  
</li>
        
          <li class="md-nav__item">
  <a href="#inverse_transform_5" class="md-nav__link">
    inverse_transform
  </a>
  
</li>
        
          <li class="md-nav__item">
  <a href="#set_params_12" class="md-nav__link">
    set_params
  </a>
  
</li>
        
          <li class="md-nav__item">
  <a href="#transform_12" class="md-nav__link">
    transform
  </a>
  
</li>
        
          <li class="md-nav__item">
  <a href="#components__11" class="md-nav__link">
    components_
  </a>
  
</li>
        
          <li class="md-nav__item">
  <a href="#explained_variance__2" class="md-nav__link">
    explained_variance_
  </a>
  
</li>
        
          <li class="md-nav__item">
  <a href="#explained_variance_ratio__2" class="md-nav__link">
    explained_variance_ratio_
  </a>
  
</li>
        
          <li class="md-nav__item">
  <a href="#singular_values__2" class="md-nav__link">
    singular_values_
  </a>
  
</li>
        
          <li class="md-nav__item">
  <a href="#to_string_12" class="md-nav__link">
    to_string
  </a>
  
</li>
        
          <li class="md-nav__item">
  <a href="#show_12" class="md-nav__link">
    show
  </a>
  
</li>
        
          <li class="md-nav__item">
  <a href="#pp_12" class="md-nav__link">
    pp
  </a>
  
</li>
        
          <li class="md-nav__item">
  <a href="#dict_learning" class="md-nav__link">
    dict_learning
  </a>
  
</li>
        
          <li class="md-nav__item">
  <a href="#dict_learning_online" class="md-nav__link">
    dict_learning_online
  </a>
  
</li>
        
          <li class="md-nav__item">
  <a href="#fastica" class="md-nav__link">
    fastica
  </a>
  
</li>
        
          <li class="md-nav__item">
  <a href="#non_negative_factorization" class="md-nav__link">
    non_negative_factorization
  </a>
  
</li>
        
          <li class="md-nav__item">
  <a href="#randomized_svd" class="md-nav__link">
    randomized_svd
  </a>
  
</li>
        
          <li class="md-nav__item">
  <a href="#sparse_encode" class="md-nav__link">
    sparse_encode
  </a>
  
</li>
        
      </ul>
    </nav>
  
</li>
      
    </ul>
  
</nav>
                  </div>
                </div>
              </div>
            
          
          <div class="md-content">
            <article class="md-content__inner md-typeset">
              
                
                  <a href="https://github.com/lehy/ocaml-sklearn/edit/master/docs/decomposition.md" title="Edit this page" class="md-content__button md-icon">
                    <svg xmlns="http://www.w3.org/2000/svg" viewBox="0 0 24 24"><path d="M20.71,7.04C21.1,6.65 21.1,6 20.71,5.63L18.37,3.29C18,2.9 17.35,2.9 16.96,3.29L15.12,5.12L18.87,8.87M3,17.25V21H6.75L17.81,9.93L14.06,6.18L3,17.25Z" /></svg>
                  </a>
                
                
                  
                
                
                  <h1>Decomposition</h1>
                
                <h2 id="module-sklearndecompositiondictionarylearning">module Sklearn.​Decomposition.​DictionaryLearning<a class="headerlink" href="#module-sklearndecompositiondictionarylearning" title="Permanent link">&para;</a></h2>
<div class="highlight"><pre><span></span><code><span class="k">type</span> <span class="n">t</span>
</code></pre></div>

<h3 id="create">create<a class="headerlink" href="#create" title="Permanent link">&para;</a></h3>
<details class="note" open="open"><summary>constructor and attributes</summary><div class="highlight"><pre><span></span><code><span class="k">val</span> <span class="n">create</span> <span class="o">:</span>
  <span class="o">?</span><span class="n">n_components</span><span class="o">:</span><span class="kt">int</span> <span class="o">-&gt;</span>
  <span class="o">?</span><span class="n">alpha</span><span class="o">:</span><span class="kt">float</span> <span class="o">-&gt;</span>
  <span class="o">?</span><span class="n">max_iter</span><span class="o">:</span><span class="kt">int</span> <span class="o">-&gt;</span>
  <span class="o">?</span><span class="n">tol</span><span class="o">:</span><span class="kt">float</span> <span class="o">-&gt;</span>
  <span class="o">?</span><span class="n">fit_algorithm</span><span class="o">:[`</span><span class="nc">Lars</span> <span class="o">|</span> <span class="o">`</span><span class="nc">Cd</span><span class="o">]</span> <span class="o">-&gt;</span>
  <span class="o">?</span><span class="n">transform_algorithm</span><span class="o">:[`</span><span class="nc">Lasso_lars</span> <span class="o">|</span> <span class="o">`</span><span class="nc">Lasso_cd</span> <span class="o">|</span> <span class="o">`</span><span class="nc">Lars</span> <span class="o">|</span> <span class="o">`</span><span class="nc">Omp</span> <span class="o">|</span> <span class="o">`</span><span class="nc">Threshold</span><span class="o">]</span> <span class="o">-&gt;</span>
  <span class="o">?</span><span class="n">transform_n_nonzero_coefs</span><span class="o">:</span><span class="kt">int</span> <span class="o">-&gt;</span>
  <span class="o">?</span><span class="n">transform_alpha</span><span class="o">:</span><span class="kt">float</span> <span class="o">-&gt;</span>
  <span class="o">?</span><span class="n">n_jobs</span><span class="o">:[`</span><span class="nc">Int</span> <span class="k">of</span> <span class="kt">int</span> <span class="o">|</span> <span class="o">`</span><span class="nc">None</span><span class="o">]</span> <span class="o">-&gt;</span>
  <span class="o">?</span><span class="n">code_init</span><span class="o">:</span><span class="nn">Ndarray</span><span class="p">.</span><span class="n">t</span> <span class="o">-&gt;</span>
  <span class="o">?</span><span class="n">dict_init</span><span class="o">:</span><span class="nn">Ndarray</span><span class="p">.</span><span class="n">t</span> <span class="o">-&gt;</span>
  <span class="o">?</span><span class="n">verbose</span><span class="o">:</span><span class="kt">bool</span> <span class="o">-&gt;</span>
  <span class="o">?</span><span class="n">split_sign</span><span class="o">:</span><span class="kt">bool</span> <span class="o">-&gt;</span>
  <span class="o">?</span><span class="n">random_state</span><span class="o">:[`</span><span class="nc">Int</span> <span class="k">of</span> <span class="kt">int</span> <span class="o">|</span> <span class="o">`</span><span class="nc">RandomState</span> <span class="k">of</span> <span class="nn">Py</span><span class="p">.</span><span class="nn">Object</span><span class="p">.</span><span class="n">t</span> <span class="o">|</span> <span class="o">`</span><span class="nc">None</span><span class="o">]</span> <span class="o">-&gt;</span>
  <span class="o">?</span><span class="n">positive_code</span><span class="o">:</span><span class="kt">bool</span> <span class="o">-&gt;</span>
  <span class="o">?</span><span class="n">positive_dict</span><span class="o">:</span><span class="kt">bool</span> <span class="o">-&gt;</span>
  <span class="o">?</span><span class="n">transform_max_iter</span><span class="o">:</span><span class="kt">int</span> <span class="o">-&gt;</span>
  <span class="kt">unit</span> <span class="o">-&gt;</span>
  <span class="n">t</span>
</code></pre></div>

<p>Dictionary learning</p>
<p>Finds a dictionary (a set of atoms) that can best be used to represent data
using a sparse code.</p>
<p>Solves the optimization problem::</p>
<div class="codehilite"><pre><span></span><code>(U^*,V^* ) = argmin 0.5 || Y - U V ||_2^2 + alpha * || U ||_1
            (U,V)
            with || V_k ||_2 = 1 for all  0 &lt;= k &lt; n_components
</code></pre></div>


<p>Read more in the :ref:<code>User Guide &lt;DictionaryLearning&gt;</code>.</p>
<h4>Parameters</h4>
<details class="info" open="open"><summary>n_components : int, default=n_features</summary><p>number of dictionary elements to extract</p>
</details>
<details class="info" open="open"><summary>alpha : float, default=1.0</summary><p>sparsity controlling parameter</p>
</details>
<details class="info" open="open"><summary>max_iter : int, default=1000</summary><p>maximum number of iterations to perform</p>
</details>
<details class="info" open="open"><summary>tol : float, default=1e-8</summary><p>tolerance for numerical error</p>
</details>
<details class="info" open="open"><summary>fit_algorithm : {'lars', 'cd'}, default='lars'</summary></details>
<details class="info" open="open"><summary>lars: uses the least angle regression method to solve the lasso problem</summary><p>(linear_model.lars_path)</p>
</details>
<details class="info" open="open"><summary>cd: uses the coordinate descent method to compute the</summary><p>Lasso solution (linear_model.Lasso). Lars will be faster if
the estimated components are sparse.</p>
<p>.. versionadded:: 0.17
   <em>cd</em> coordinate descent method to improve speed.</p>
</details>
<details class="info" open="open"><summary>transform_algorithm : {'lasso_lars', 'lasso_cd', 'lars', 'omp',     'threshold'}, default='omp'</summary><p>Algorithm used to transform the data</p>
</details>
<details class="info" open="open"><summary>lars: uses the least angle regression method (linear_model.lars_path)</summary></details>
<details class="info" open="open"><summary>lasso_lars: uses Lars to compute the Lasso solution</summary></details>
<details class="info" open="open"><summary>lasso_cd: uses the coordinate descent method to compute the</summary><p>Lasso solution (linear_model.Lasso). lasso_lars will be faster if
the estimated components are sparse.</p>
</details>
<details class="info" open="open"><summary>omp: uses orthogonal matching pursuit to estimate the sparse solution</summary></details>
<details class="info" open="open"><summary>threshold: squashes to zero all coefficients less than alpha from</summary><p>the projection <code>dictionary * X'</code></p>
<p>.. versionadded:: 0.17
   <em>lasso_cd</em> coordinate descent method to improve speed.</p>
</details>
<details class="info" open="open"><summary>transform_n_nonzero_coefs : int, default=0.1*n_features</summary><p>Number of nonzero coefficients to target in each column of the
solution. This is only used by <code>algorithm='lars'</code> and <code>algorithm='omp'</code>
and is overridden by <code>alpha</code> in the <code>omp</code> case.</p>
</details>
<details class="info" open="open"><summary>transform_alpha : float, default=1.0</summary><p>If <code>algorithm='lasso_lars'</code> or <code>algorithm='lasso_cd'</code>, <code>alpha</code> is the
penalty applied to the L1 norm.
If <code>algorithm='threshold'</code>, <code>alpha</code> is the absolute value of the
threshold below which coefficients will be squashed to zero.
If <code>algorithm='omp'</code>, <code>alpha</code> is the tolerance parameter: the value of
the reconstruction error targeted. In this case, it overrides
<code>n_nonzero_coefs</code>.</p>
</details>
<details class="info" open="open"><summary>n_jobs : int or None, default=None</summary><p>Number of parallel jobs to run.
<code>None</code> means 1 unless in a :obj:<code>joblib.parallel_backend</code> context.
<code>-1</code> means using all processors. See :term:<code>Glossary &lt;n_jobs&gt;</code>
for more details.</p>
</details>
<details class="info" open="open"><summary>code_init : array of shape (n_samples, n_components), default=None</summary><p>initial value for the code, for warm restart</p>
</details>
<details class="info" open="open"><summary>dict_init : array of shape (n_components, n_features), default=None</summary><p>initial values for the dictionary, for warm restart</p>
</details>
<details class="info" open="open"><summary>verbose : bool, default=False</summary><p>To control the verbosity of the procedure.</p>
</details>
<details class="info" open="open"><summary>split_sign : bool, default=False</summary><p>Whether to split the sparse feature vector into the concatenation of
its negative part and its positive part. This can improve the
performance of downstream classifiers.</p>
</details>
<details class="info" open="open"><summary>random_state : int, RandomState instance or None, default=None</summary><p>If int, random_state is the seed used by the random number generator;
If RandomState instance, random_state is the random number generator;
If None, the random number generator is the RandomState instance used
by <code>np.random</code>.</p>
</details>
<details class="info" open="open"><summary>positive_code : bool, default=False</summary><p>Whether to enforce positivity when finding the code.</p>
<p>.. versionadded:: 0.20</p>
</details>
<details class="info" open="open"><summary>positive_dict : bool, default=False</summary><p>Whether to enforce positivity when finding the dictionary</p>
<p>.. versionadded:: 0.20</p>
</details>
<details class="info" open="open"><summary>transform_max_iter : int, default=1000</summary><p>Maximum number of iterations to perform if <code>algorithm='lasso_cd'</code> or
<code>lasso_lars</code>.</p>
<p>.. versionadded:: 0.22</p>
</details>
<h4>Attributes</h4>
<details class="info" open="open"><summary>components_ : array, [n_components, n_features]</summary><p>dictionary atoms extracted from the data</p>
</details>
<details class="info" open="open"><summary>error_ : array</summary><p>vector of errors at each iteration</p>
</details>
<details class="info" open="open"><summary>n_iter_ : int</summary><p>Number of iterations run.</p>
</details>
<h4>Notes</h4>
<details class="info" open="open"><summary><strong>References:</strong></summary></details>
<p>J. Mairal, F. Bach, J. Ponce, G. Sapiro, 2009: Online dictionary learning
for sparse coding (https://www.di.ens.fr/sierra/pdfs/icml09.pdf)</p>
<h4>See also</h4>
<p>SparseCoder
MiniBatchDictionaryLearning
SparsePCA
MiniBatchSparsePCA</p>
</details>
<h3 id="fit">fit<a class="headerlink" href="#fit" title="Permanent link">&para;</a></h3>
<details class="note" open="open"><summary>method</summary><div class="highlight"><pre><span></span><code><span class="k">val</span> <span class="n">fit</span> <span class="o">:</span>
  <span class="o">?</span><span class="n">y</span><span class="o">:</span><span class="nn">Py</span><span class="p">.</span><span class="nn">Object</span><span class="p">.</span><span class="n">t</span> <span class="o">-&gt;</span>
  <span class="n">x</span><span class="o">:</span><span class="nn">Ndarray</span><span class="p">.</span><span class="n">t</span> <span class="o">-&gt;</span>
  <span class="n">t</span> <span class="o">-&gt;</span>
  <span class="n">t</span>
</code></pre></div>

<p>Fit the model from data in X.</p>
<h4>Parameters</h4>
<details class="info" open="open"><summary>X : array-like, shape (n_samples, n_features)</summary><p>Training vector, where n_samples in the number of samples
and n_features is the number of features.</p>
</details>
<details class="info" open="open"><summary>y : Ignored</summary></details>
<h4>Returns</h4>
<details class="info" open="open"><summary>self : object</summary><p>Returns the object itself</p>
</details>
</details>
<h3 id="fit_transform">fit_transform<a class="headerlink" href="#fit_transform" title="Permanent link">&para;</a></h3>
<details class="note" open="open"><summary>method</summary><div class="highlight"><pre><span></span><code><span class="k">val</span> <span class="n">fit_transform</span> <span class="o">:</span>
  <span class="o">?</span><span class="n">y</span><span class="o">:</span><span class="nn">Ndarray</span><span class="p">.</span><span class="n">t</span> <span class="o">-&gt;</span>
  <span class="o">?</span><span class="n">fit_params</span><span class="o">:(</span><span class="kt">string</span> <span class="o">*</span> <span class="nn">Py</span><span class="p">.</span><span class="nn">Object</span><span class="p">.</span><span class="n">t</span><span class="o">)</span> <span class="kt">list</span> <span class="o">-&gt;</span>
  <span class="n">x</span><span class="o">:</span><span class="nn">Ndarray</span><span class="p">.</span><span class="n">t</span> <span class="o">-&gt;</span>
  <span class="n">t</span> <span class="o">-&gt;</span>
  <span class="nn">Ndarray</span><span class="p">.</span><span class="n">t</span>
</code></pre></div>

<p>Fit to data, then transform it.</p>
<p>Fits transformer to X and y with optional parameters fit_params
and returns a transformed version of X.</p>
<h4>Parameters</h4>
<details class="info" open="open"><summary>X : numpy array of shape [n_samples, n_features]</summary><p>Training set.</p>
</details>
<details class="info" open="open"><summary>y : numpy array of shape [n_samples]</summary><p>Target values.</p>
</details>
<details class="info" open="open"><summary>**fit_params : dict</summary><p>Additional fit parameters.</p>
</details>
<h4>Returns</h4>
<details class="info" open="open"><summary>X_new : numpy array of shape [n_samples, n_features_new]</summary><p>Transformed array.</p>
</details>
</details>
<h3 id="get_params">get_params<a class="headerlink" href="#get_params" title="Permanent link">&para;</a></h3>
<details class="note" open="open"><summary>method</summary><div class="highlight"><pre><span></span><code><span class="k">val</span> <span class="n">get_params</span> <span class="o">:</span>
  <span class="o">?</span><span class="n">deep</span><span class="o">:</span><span class="kt">bool</span> <span class="o">-&gt;</span>
  <span class="n">t</span> <span class="o">-&gt;</span>
  <span class="nn">Py</span><span class="p">.</span><span class="nn">Object</span><span class="p">.</span><span class="n">t</span>
</code></pre></div>

<p>Get parameters for this estimator.</p>
<h4>Parameters</h4>
<details class="info" open="open"><summary>deep : bool, default=True</summary><p>If True, will return the parameters for this estimator and
contained subobjects that are estimators.</p>
</details>
<h4>Returns</h4>
<details class="info" open="open"><summary>params : mapping of string to any</summary><p>Parameter names mapped to their values.</p>
</details>
</details>
<h3 id="set_params">set_params<a class="headerlink" href="#set_params" title="Permanent link">&para;</a></h3>
<details class="note" open="open"><summary>method</summary><div class="highlight"><pre><span></span><code><span class="k">val</span> <span class="n">set_params</span> <span class="o">:</span>
  <span class="o">?</span><span class="n">params</span><span class="o">:(</span><span class="kt">string</span> <span class="o">*</span> <span class="nn">Py</span><span class="p">.</span><span class="nn">Object</span><span class="p">.</span><span class="n">t</span><span class="o">)</span> <span class="kt">list</span> <span class="o">-&gt;</span>
  <span class="n">t</span> <span class="o">-&gt;</span>
  <span class="n">t</span>
</code></pre></div>

<p>Set the parameters of this estimator.</p>
<p>The method works on simple estimators as well as on nested objects
(such as pipelines). The latter have parameters of the form
<code>&lt;component&gt;__&lt;parameter&gt;</code> so that it's possible to update each
component of a nested object.</p>
<h4>Parameters</h4>
<details class="info" open="open"><summary>**params : dict</summary><p>Estimator parameters.</p>
</details>
<h4>Returns</h4>
<details class="info" open="open"><summary>self : object</summary><p>Estimator instance.</p>
</details>
</details>
<h3 id="transform">transform<a class="headerlink" href="#transform" title="Permanent link">&para;</a></h3>
<details class="note" open="open"><summary>method</summary><div class="highlight"><pre><span></span><code><span class="k">val</span> <span class="n">transform</span> <span class="o">:</span>
  <span class="n">x</span><span class="o">:</span><span class="nn">Ndarray</span><span class="p">.</span><span class="n">t</span> <span class="o">-&gt;</span>
  <span class="n">t</span> <span class="o">-&gt;</span>
  <span class="nn">Ndarray</span><span class="p">.</span><span class="n">t</span>
</code></pre></div>

<p>Encode the data as a sparse combination of the dictionary atoms.</p>
<p>Coding method is determined by the object parameter
<code>transform_algorithm</code>.</p>
<h4>Parameters</h4>
<details class="info" open="open"><summary>X : array of shape (n_samples, n_features)</summary><p>Test data to be transformed, must have the same number of
features as the data used to train the model.</p>
</details>
<h4>Returns</h4>
<details class="info" open="open"><summary>X_new : array, shape (n_samples, n_components)</summary><p>Transformed data</p>
</details>
</details>
<h3 id="components_">components_<a class="headerlink" href="#components_" title="Permanent link">&para;</a></h3>
<details class="note" open="open"><summary>attribute</summary><div class="highlight"><pre><span></span><code><span class="k">val</span> <span class="n">components_</span> <span class="o">:</span> <span class="n">t</span> <span class="o">-&gt;</span> <span class="nn">Ndarray</span><span class="p">.</span><span class="n">t</span>
</code></pre></div>

<p>This attribute is documented in <code>create</code> above.</p>
</details>
<h3 id="error_">error_<a class="headerlink" href="#error_" title="Permanent link">&para;</a></h3>
<details class="note" open="open"><summary>attribute</summary><div class="highlight"><pre><span></span><code><span class="k">val</span> <span class="n">error_</span> <span class="o">:</span> <span class="n">t</span> <span class="o">-&gt;</span> <span class="nn">Ndarray</span><span class="p">.</span><span class="n">t</span>
</code></pre></div>

<p>This attribute is documented in <code>create</code> above.</p>
</details>
<h3 id="n_iter_">n_iter_<a class="headerlink" href="#n_iter_" title="Permanent link">&para;</a></h3>
<details class="note" open="open"><summary>attribute</summary><div class="highlight"><pre><span></span><code><span class="k">val</span> <span class="n">n_iter_</span> <span class="o">:</span> <span class="n">t</span> <span class="o">-&gt;</span> <span class="kt">int</span>
</code></pre></div>

<p>This attribute is documented in <code>create</code> above.</p>
</details>
<h3 id="to_string">to_string<a class="headerlink" href="#to_string" title="Permanent link">&para;</a></h3>
<details class="note" open="open"><summary>method</summary><div class="highlight"><pre><span></span><code><span class="k">val</span> <span class="n">to_string</span><span class="o">:</span> <span class="n">t</span> <span class="o">-&gt;</span> <span class="kt">string</span>
</code></pre></div>

<p>Print the object to a human-readable representation.</p>
</details>
<h3 id="show">show<a class="headerlink" href="#show" title="Permanent link">&para;</a></h3>
<details class="note" open="open"><summary>method</summary><div class="highlight"><pre><span></span><code><span class="k">val</span> <span class="n">show</span><span class="o">:</span> <span class="n">t</span> <span class="o">-&gt;</span> <span class="kt">string</span>
</code></pre></div>

<p>Print the object to a human-readable representation.</p>
</details>
<h3 id="pp">pp<a class="headerlink" href="#pp" title="Permanent link">&para;</a></h3>
<details class="note" open="open"><summary>method</summary><div class="highlight"><pre><span></span><code><span class="k">val</span> <span class="n">pp</span><span class="o">:</span> <span class="nn">Format</span><span class="p">.</span><span class="n">formatter</span> <span class="o">-&gt;</span> <span class="n">t</span> <span class="o">-&gt;</span> <span class="kt">unit</span>
</code></pre></div>

<p>Pretty-print the object to a formatter.</p>
</details>
<h2 id="module-sklearndecompositionfactoranalysis">module Sklearn.​Decomposition.​FactorAnalysis<a class="headerlink" href="#module-sklearndecompositionfactoranalysis" title="Permanent link">&para;</a></h2>
<div class="highlight"><pre><span></span><code><span class="k">type</span> <span class="n">t</span>
</code></pre></div>

<h3 id="create_1">create<a class="headerlink" href="#create_1" title="Permanent link">&para;</a></h3>
<details class="note" open="open"><summary>constructor and attributes</summary><div class="highlight"><pre><span></span><code><span class="k">val</span> <span class="n">create</span> <span class="o">:</span>
  <span class="o">?</span><span class="n">n_components</span><span class="o">:[`</span><span class="nc">Int</span> <span class="k">of</span> <span class="kt">int</span> <span class="o">|</span> <span class="o">`</span><span class="nc">None</span><span class="o">]</span> <span class="o">-&gt;</span>
  <span class="o">?</span><span class="n">tol</span><span class="o">:</span><span class="kt">float</span> <span class="o">-&gt;</span>
  <span class="o">?</span><span class="n">copy</span><span class="o">:</span><span class="kt">bool</span> <span class="o">-&gt;</span>
  <span class="o">?</span><span class="n">max_iter</span><span class="o">:</span><span class="kt">int</span> <span class="o">-&gt;</span>
  <span class="o">?</span><span class="n">noise_variance_init</span><span class="o">:[`</span><span class="nc">Ndarray</span> <span class="k">of</span> <span class="nn">Ndarray</span><span class="p">.</span><span class="n">t</span> <span class="o">|</span> <span class="o">`</span><span class="nc">None</span><span class="o">]</span> <span class="o">-&gt;</span>
  <span class="o">?</span><span class="n">svd_method</span><span class="o">:[`</span><span class="nc">Lapack</span> <span class="o">|</span> <span class="o">`</span><span class="nc">Randomized</span><span class="o">]</span> <span class="o">-&gt;</span>
  <span class="o">?</span><span class="n">iterated_power</span><span class="o">:</span><span class="kt">int</span> <span class="o">-&gt;</span>
  <span class="o">?</span><span class="n">random_state</span><span class="o">:[`</span><span class="nc">Int</span> <span class="k">of</span> <span class="kt">int</span> <span class="o">|</span> <span class="o">`</span><span class="nc">RandomState</span> <span class="k">of</span> <span class="nn">Py</span><span class="p">.</span><span class="nn">Object</span><span class="p">.</span><span class="n">t</span> <span class="o">|</span> <span class="o">`</span><span class="nc">None</span><span class="o">]</span> <span class="o">-&gt;</span>
  <span class="kt">unit</span> <span class="o">-&gt;</span>
  <span class="n">t</span>
</code></pre></div>

<p>Factor Analysis (FA)</p>
<p>A simple linear generative model with Gaussian latent variables.</p>
<p>The observations are assumed to be caused by a linear transformation of
lower dimensional latent factors and added Gaussian noise.
Without loss of generality the factors are distributed according to a
Gaussian with zero mean and unit covariance. The noise is also zero mean
and has an arbitrary diagonal covariance matrix.</p>
<p>If we would restrict the model further, by assuming that the Gaussian
noise is even isotropic (all diagonal entries are the same) we would obtain
:class:<code>PPCA</code>.</p>
<p>FactorAnalysis performs a maximum likelihood estimate of the so-called
<code>loading</code> matrix, the transformation of the latent variables to the
observed ones, using SVD based approach.</p>
<p>Read more in the :ref:<code>User Guide &lt;FA&gt;</code>.</p>
<p>.. versionadded:: 0.13</p>
<h4>Parameters</h4>
<details class="info" open="open"><summary>n_components : int | None</summary><p>Dimensionality of latent space, the number of components
of <code>X</code> that are obtained after <code>transform</code>.
If None, n_components is set to the number of features.</p>
</details>
<details class="info" open="open"><summary>tol : float</summary><p>Stopping tolerance for log-likelihood increase.</p>
</details>
<details class="info" open="open"><summary>copy : bool</summary><p>Whether to make a copy of X. If <code>False</code>, the input X gets overwritten
during fitting.</p>
</details>
<details class="info" open="open"><summary>max_iter : int</summary><p>Maximum number of iterations.</p>
</details>
<details class="info" open="open"><summary>noise_variance_init : None | array, shape=(n_features,)</summary><p>The initial guess of the noise variance for each feature.
If None, it defaults to np.ones(n_features)</p>
</details>
<details class="info" open="open"><summary>svd_method : {'lapack', 'randomized'}</summary><p>Which SVD method to use. If 'lapack' use standard SVD from
scipy.linalg, if 'randomized' use fast <code>randomized_svd</code> function.
Defaults to 'randomized'. For most applications 'randomized' will
be sufficiently precise while providing significant speed gains.
Accuracy can also be improved by setting higher values for
<code>iterated_power</code>. If this is not sufficient, for maximum precision
you should choose 'lapack'.</p>
</details>
<details class="info" open="open"><summary>iterated_power : int, optional</summary><p>Number of iterations for the power method. 3 by default. Only used
if <code>svd_method</code> equals 'randomized'</p>
</details>
<details class="info" open="open"><summary>random_state : int, RandomState instance or None, optional (default=0)</summary><p>If int, random_state is the seed used by the random number generator;
If RandomState instance, random_state is the random number generator;
If None, the random number generator is the RandomState instance used
by <code>np.random</code>. Only used when <code>svd_method</code> equals 'randomized'.</p>
</details>
<h4>Attributes</h4>
<details class="info" open="open"><summary>components_ : array, [n_components, n_features]</summary><p>Components with maximum variance.</p>
</details>
<details class="info" open="open"><summary>loglike_ : list, [n_iterations]</summary><p>The log likelihood at each iteration.</p>
</details>
<details class="info" open="open"><summary>noise_variance_ : array, shape=(n_features,)</summary><p>The estimated noise variance for each feature.</p>
</details>
<details class="info" open="open"><summary>n_iter_ : int</summary><p>Number of iterations run.</p>
</details>
<details class="info" open="open"><summary>mean_ : array, shape (n_features,)</summary><p>Per-feature empirical mean, estimated from the training set.</p>
</details>
<h4>Examples</h4>
<div class="highlight"><pre><span></span><code><span class="o">&gt;&gt;&gt;</span> <span class="kn">from</span> <span class="nn">sklearn.datasets</span> <span class="kn">import</span> <span class="n">load_digits</span>
<span class="o">&gt;&gt;&gt;</span> <span class="kn">from</span> <span class="nn">sklearn.decomposition</span> <span class="kn">import</span> <span class="n">FactorAnalysis</span>
<span class="o">&gt;&gt;&gt;</span> <span class="n">X</span><span class="p">,</span> <span class="n">_</span> <span class="o">=</span> <span class="n">load_digits</span><span class="p">(</span><span class="n">return_X_y</span><span class="o">=</span><span class="kc">True</span><span class="p">)</span>
<span class="o">&gt;&gt;&gt;</span> <span class="n">transformer</span> <span class="o">=</span> <span class="n">FactorAnalysis</span><span class="p">(</span><span class="n">n_components</span><span class="o">=</span><span class="mi">7</span><span class="p">,</span> <span class="n">random_state</span><span class="o">=</span><span class="mi">0</span><span class="p">)</span>
<span class="o">&gt;&gt;&gt;</span> <span class="n">X_transformed</span> <span class="o">=</span> <span class="n">transformer</span><span class="o">.</span><span class="n">fit_transform</span><span class="p">(</span><span class="n">X</span><span class="p">)</span>
<span class="o">&gt;&gt;&gt;</span> <span class="n">X_transformed</span><span class="o">.</span><span class="n">shape</span>
<span class="p">(</span><span class="mi">1797</span><span class="p">,</span> <span class="mi">7</span><span class="p">)</span>
</code></pre></div>

<h4>References</h4>
<p>.. David Barber, Bayesian Reasoning and Machine Learning,
    Algorithm 21.1</p>
<p>.. Christopher M. Bishop: Pattern Recognition and Machine Learning,
    Chapter 12.2.4</p>
<h4>See also</h4>
<details class="info" open="open"><summary>PCA: Principal component analysis is also a latent linear variable model</summary><p>which however assumes equal noise variance for each feature.
This extra assumption makes probabilistic PCA faster as it can be
computed in closed form.</p>
</details>
<details class="info" open="open"><summary>FastICA: Independent component analysis, a latent variable model with</summary><p>non-Gaussian latent variables.</p>
</details>
</details>
<h3 id="fit_1">fit<a class="headerlink" href="#fit_1" title="Permanent link">&para;</a></h3>
<details class="note" open="open"><summary>method</summary><div class="highlight"><pre><span></span><code><span class="k">val</span> <span class="n">fit</span> <span class="o">:</span>
  <span class="o">?</span><span class="n">y</span><span class="o">:</span><span class="nn">Py</span><span class="p">.</span><span class="nn">Object</span><span class="p">.</span><span class="n">t</span> <span class="o">-&gt;</span>
  <span class="n">x</span><span class="o">:</span><span class="nn">Ndarray</span><span class="p">.</span><span class="n">t</span> <span class="o">-&gt;</span>
  <span class="n">t</span> <span class="o">-&gt;</span>
  <span class="n">t</span>
</code></pre></div>

<p>Fit the FactorAnalysis model to X using SVD based approach</p>
<h4>Parameters</h4>
<details class="info" open="open"><summary>X : array-like, shape (n_samples, n_features)</summary><p>Training data.</p>
</details>
<details class="info" open="open"><summary>y : Ignored</summary></details>
<h4>Returns</h4>
<p>self</p>
</details>
<h3 id="fit_transform_1">fit_transform<a class="headerlink" href="#fit_transform_1" title="Permanent link">&para;</a></h3>
<details class="note" open="open"><summary>method</summary><div class="highlight"><pre><span></span><code><span class="k">val</span> <span class="n">fit_transform</span> <span class="o">:</span>
  <span class="o">?</span><span class="n">y</span><span class="o">:</span><span class="nn">Ndarray</span><span class="p">.</span><span class="n">t</span> <span class="o">-&gt;</span>
  <span class="o">?</span><span class="n">fit_params</span><span class="o">:(</span><span class="kt">string</span> <span class="o">*</span> <span class="nn">Py</span><span class="p">.</span><span class="nn">Object</span><span class="p">.</span><span class="n">t</span><span class="o">)</span> <span class="kt">list</span> <span class="o">-&gt;</span>
  <span class="n">x</span><span class="o">:</span><span class="nn">Ndarray</span><span class="p">.</span><span class="n">t</span> <span class="o">-&gt;</span>
  <span class="n">t</span> <span class="o">-&gt;</span>
  <span class="nn">Ndarray</span><span class="p">.</span><span class="n">t</span>
</code></pre></div>

<p>Fit to data, then transform it.</p>
<p>Fits transformer to X and y with optional parameters fit_params
and returns a transformed version of X.</p>
<h4>Parameters</h4>
<details class="info" open="open"><summary>X : numpy array of shape [n_samples, n_features]</summary><p>Training set.</p>
</details>
<details class="info" open="open"><summary>y : numpy array of shape [n_samples]</summary><p>Target values.</p>
</details>
<details class="info" open="open"><summary>**fit_params : dict</summary><p>Additional fit parameters.</p>
</details>
<h4>Returns</h4>
<details class="info" open="open"><summary>X_new : numpy array of shape [n_samples, n_features_new]</summary><p>Transformed array.</p>
</details>
</details>
<h3 id="get_covariance">get_covariance<a class="headerlink" href="#get_covariance" title="Permanent link">&para;</a></h3>
<details class="note" open="open"><summary>method</summary><div class="highlight"><pre><span></span><code><span class="k">val</span> <span class="n">get_covariance</span> <span class="o">:</span>
  <span class="n">t</span> <span class="o">-&gt;</span>
  <span class="nn">Ndarray</span><span class="p">.</span><span class="n">t</span>
</code></pre></div>

<p>Compute data covariance with the FactorAnalysis model.</p>
<p><code>cov = components_.T * components_ + diag(noise_variance)</code></p>
<h4>Returns</h4>
<details class="info" open="open"><summary>cov : array, shape (n_features, n_features)</summary><p>Estimated covariance of data.</p>
</details>
</details>
<h3 id="get_params_1">get_params<a class="headerlink" href="#get_params_1" title="Permanent link">&para;</a></h3>
<details class="note" open="open"><summary>method</summary><div class="highlight"><pre><span></span><code><span class="k">val</span> <span class="n">get_params</span> <span class="o">:</span>
  <span class="o">?</span><span class="n">deep</span><span class="o">:</span><span class="kt">bool</span> <span class="o">-&gt;</span>
  <span class="n">t</span> <span class="o">-&gt;</span>
  <span class="nn">Py</span><span class="p">.</span><span class="nn">Object</span><span class="p">.</span><span class="n">t</span>
</code></pre></div>

<p>Get parameters for this estimator.</p>
<h4>Parameters</h4>
<details class="info" open="open"><summary>deep : bool, default=True</summary><p>If True, will return the parameters for this estimator and
contained subobjects that are estimators.</p>
</details>
<h4>Returns</h4>
<details class="info" open="open"><summary>params : mapping of string to any</summary><p>Parameter names mapped to their values.</p>
</details>
</details>
<h3 id="get_precision">get_precision<a class="headerlink" href="#get_precision" title="Permanent link">&para;</a></h3>
<details class="note" open="open"><summary>method</summary><div class="highlight"><pre><span></span><code><span class="k">val</span> <span class="n">get_precision</span> <span class="o">:</span>
  <span class="n">t</span> <span class="o">-&gt;</span>
  <span class="nn">Ndarray</span><span class="p">.</span><span class="n">t</span>
</code></pre></div>

<p>Compute data precision matrix with the FactorAnalysis model.</p>
<h4>Returns</h4>
<details class="info" open="open"><summary>precision : array, shape (n_features, n_features)</summary><p>Estimated precision of data.</p>
</details>
</details>
<h3 id="score">score<a class="headerlink" href="#score" title="Permanent link">&para;</a></h3>
<details class="note" open="open"><summary>method</summary><div class="highlight"><pre><span></span><code><span class="k">val</span> <span class="n">score</span> <span class="o">:</span>
  <span class="o">?</span><span class="n">y</span><span class="o">:</span><span class="nn">Py</span><span class="p">.</span><span class="nn">Object</span><span class="p">.</span><span class="n">t</span> <span class="o">-&gt;</span>
  <span class="n">x</span><span class="o">:</span><span class="nn">Ndarray</span><span class="p">.</span><span class="n">t</span> <span class="o">-&gt;</span>
  <span class="n">t</span> <span class="o">-&gt;</span>
  <span class="kt">float</span>
</code></pre></div>

<p>Compute the average log-likelihood of the samples</p>
<h4>Parameters</h4>
<details class="info" open="open"><summary>X : array, shape (n_samples, n_features)</summary><p>The data</p>
</details>
<details class="info" open="open"><summary>y : Ignored</summary></details>
<h4>Returns</h4>
<details class="info" open="open"><summary>ll : float</summary><p>Average log-likelihood of the samples under the current model</p>
</details>
</details>
<h3 id="score_samples">score_samples<a class="headerlink" href="#score_samples" title="Permanent link">&para;</a></h3>
<details class="note" open="open"><summary>method</summary><div class="highlight"><pre><span></span><code><span class="k">val</span> <span class="n">score_samples</span> <span class="o">:</span>
  <span class="n">x</span><span class="o">:</span><span class="nn">Ndarray</span><span class="p">.</span><span class="n">t</span> <span class="o">-&gt;</span>
  <span class="n">t</span> <span class="o">-&gt;</span>
  <span class="nn">Ndarray</span><span class="p">.</span><span class="n">t</span>
</code></pre></div>

<p>Compute the log-likelihood of each sample</p>
<h4>Parameters</h4>
<details class="info" open="open"><summary>X : array, shape (n_samples, n_features)</summary><p>The data</p>
</details>
<h4>Returns</h4>
<details class="info" open="open"><summary>ll : array, shape (n_samples,)</summary><p>Log-likelihood of each sample under the current model</p>
</details>
</details>
<h3 id="set_params_1">set_params<a class="headerlink" href="#set_params_1" title="Permanent link">&para;</a></h3>
<details class="note" open="open"><summary>method</summary><div class="highlight"><pre><span></span><code><span class="k">val</span> <span class="n">set_params</span> <span class="o">:</span>
  <span class="o">?</span><span class="n">params</span><span class="o">:(</span><span class="kt">string</span> <span class="o">*</span> <span class="nn">Py</span><span class="p">.</span><span class="nn">Object</span><span class="p">.</span><span class="n">t</span><span class="o">)</span> <span class="kt">list</span> <span class="o">-&gt;</span>
  <span class="n">t</span> <span class="o">-&gt;</span>
  <span class="n">t</span>
</code></pre></div>

<p>Set the parameters of this estimator.</p>
<p>The method works on simple estimators as well as on nested objects
(such as pipelines). The latter have parameters of the form
<code>&lt;component&gt;__&lt;parameter&gt;</code> so that it's possible to update each
component of a nested object.</p>
<h4>Parameters</h4>
<details class="info" open="open"><summary>**params : dict</summary><p>Estimator parameters.</p>
</details>
<h4>Returns</h4>
<details class="info" open="open"><summary>self : object</summary><p>Estimator instance.</p>
</details>
</details>
<h3 id="transform_1">transform<a class="headerlink" href="#transform_1" title="Permanent link">&para;</a></h3>
<details class="note" open="open"><summary>method</summary><div class="highlight"><pre><span></span><code><span class="k">val</span> <span class="n">transform</span> <span class="o">:</span>
  <span class="n">x</span><span class="o">:</span><span class="nn">Ndarray</span><span class="p">.</span><span class="n">t</span> <span class="o">-&gt;</span>
  <span class="n">t</span> <span class="o">-&gt;</span>
  <span class="nn">Ndarray</span><span class="p">.</span><span class="n">t</span>
</code></pre></div>

<p>Apply dimensionality reduction to X using the model.</p>
<p>Compute the expected mean of the latent variables.
See Barber, 21.2.33 (or Bishop, 12.66).</p>
<h4>Parameters</h4>
<details class="info" open="open"><summary>X : array-like, shape (n_samples, n_features)</summary><p>Training data.</p>
</details>
<h4>Returns</h4>
<details class="info" open="open"><summary>X_new : array-like, shape (n_samples, n_components)</summary><p>The latent variables of X.</p>
</details>
</details>
<h3 id="components__1">components_<a class="headerlink" href="#components__1" title="Permanent link">&para;</a></h3>
<details class="note" open="open"><summary>attribute</summary><div class="highlight"><pre><span></span><code><span class="k">val</span> <span class="n">components_</span> <span class="o">:</span> <span class="n">t</span> <span class="o">-&gt;</span> <span class="nn">Ndarray</span><span class="p">.</span><span class="n">t</span>
</code></pre></div>

<p>This attribute is documented in <code>create</code> above.</p>
</details>
<h3 id="loglike_">loglike_<a class="headerlink" href="#loglike_" title="Permanent link">&para;</a></h3>
<details class="note" open="open"><summary>attribute</summary><div class="highlight"><pre><span></span><code><span class="k">val</span> <span class="n">loglike_</span> <span class="o">:</span> <span class="n">t</span> <span class="o">-&gt;</span> <span class="nn">Py</span><span class="p">.</span><span class="nn">Object</span><span class="p">.</span><span class="n">t</span>
</code></pre></div>

<p>This attribute is documented in <code>create</code> above.</p>
</details>
<h3 id="noise_variance_">noise_variance_<a class="headerlink" href="#noise_variance_" title="Permanent link">&para;</a></h3>
<details class="note" open="open"><summary>attribute</summary><div class="highlight"><pre><span></span><code><span class="k">val</span> <span class="n">noise_variance_</span> <span class="o">:</span> <span class="n">t</span> <span class="o">-&gt;</span> <span class="nn">Ndarray</span><span class="p">.</span><span class="n">t</span>
</code></pre></div>

<p>This attribute is documented in <code>create</code> above.</p>
</details>
<h3 id="n_iter__1">n_iter_<a class="headerlink" href="#n_iter__1" title="Permanent link">&para;</a></h3>
<details class="note" open="open"><summary>attribute</summary><div class="highlight"><pre><span></span><code><span class="k">val</span> <span class="n">n_iter_</span> <span class="o">:</span> <span class="n">t</span> <span class="o">-&gt;</span> <span class="kt">int</span>
</code></pre></div>

<p>This attribute is documented in <code>create</code> above.</p>
</details>
<h3 id="mean_">mean_<a class="headerlink" href="#mean_" title="Permanent link">&para;</a></h3>
<details class="note" open="open"><summary>attribute</summary><div class="highlight"><pre><span></span><code><span class="k">val</span> <span class="n">mean_</span> <span class="o">:</span> <span class="n">t</span> <span class="o">-&gt;</span> <span class="nn">Ndarray</span><span class="p">.</span><span class="n">t</span>
</code></pre></div>

<p>This attribute is documented in <code>create</code> above.</p>
</details>
<h3 id="to_string_1">to_string<a class="headerlink" href="#to_string_1" title="Permanent link">&para;</a></h3>
<details class="note" open="open"><summary>method</summary><div class="highlight"><pre><span></span><code><span class="k">val</span> <span class="n">to_string</span><span class="o">:</span> <span class="n">t</span> <span class="o">-&gt;</span> <span class="kt">string</span>
</code></pre></div>

<p>Print the object to a human-readable representation.</p>
</details>
<h3 id="show_1">show<a class="headerlink" href="#show_1" title="Permanent link">&para;</a></h3>
<details class="note" open="open"><summary>method</summary><div class="highlight"><pre><span></span><code><span class="k">val</span> <span class="n">show</span><span class="o">:</span> <span class="n">t</span> <span class="o">-&gt;</span> <span class="kt">string</span>
</code></pre></div>

<p>Print the object to a human-readable representation.</p>
</details>
<h3 id="pp_1">pp<a class="headerlink" href="#pp_1" title="Permanent link">&para;</a></h3>
<details class="note" open="open"><summary>method</summary><div class="highlight"><pre><span></span><code><span class="k">val</span> <span class="n">pp</span><span class="o">:</span> <span class="nn">Format</span><span class="p">.</span><span class="n">formatter</span> <span class="o">-&gt;</span> <span class="n">t</span> <span class="o">-&gt;</span> <span class="kt">unit</span>
</code></pre></div>

<p>Pretty-print the object to a formatter.</p>
</details>
<h2 id="module-sklearndecompositionfastica">module Sklearn.​Decomposition.​FastICA<a class="headerlink" href="#module-sklearndecompositionfastica" title="Permanent link">&para;</a></h2>
<div class="highlight"><pre><span></span><code><span class="k">type</span> <span class="n">t</span>
</code></pre></div>

<h3 id="create_2">create<a class="headerlink" href="#create_2" title="Permanent link">&para;</a></h3>
<details class="note" open="open"><summary>constructor and attributes</summary><div class="highlight"><pre><span></span><code><span class="k">val</span> <span class="n">create</span> <span class="o">:</span>
  <span class="o">?</span><span class="n">n_components</span><span class="o">:</span><span class="kt">int</span> <span class="o">-&gt;</span>
  <span class="o">?</span><span class="n">algorithm</span><span class="o">:[`</span><span class="nc">Parallel</span> <span class="o">|</span> <span class="o">`</span><span class="nc">Deflation</span><span class="o">]</span> <span class="o">-&gt;</span>
  <span class="o">?</span><span class="n">whiten</span><span class="o">:</span><span class="kt">bool</span> <span class="o">-&gt;</span>
  <span class="o">?</span><span class="n">fun_</span><span class="o">:[`</span><span class="nc">String</span> <span class="k">of</span> <span class="kt">string</span> <span class="o">|</span> <span class="o">`</span><span class="nc">Callable</span> <span class="k">of</span> <span class="nn">Py</span><span class="p">.</span><span class="nn">Object</span><span class="p">.</span><span class="n">t</span><span class="o">]</span> <span class="o">-&gt;</span>
  <span class="o">?</span><span class="n">fun_args</span><span class="o">:</span><span class="nn">Py</span><span class="p">.</span><span class="nn">Object</span><span class="p">.</span><span class="n">t</span> <span class="o">-&gt;</span>
  <span class="o">?</span><span class="n">max_iter</span><span class="o">:</span><span class="kt">int</span> <span class="o">-&gt;</span>
  <span class="o">?</span><span class="n">tol</span><span class="o">:</span><span class="kt">float</span> <span class="o">-&gt;</span>
  <span class="o">?</span><span class="n">w_init</span><span class="o">:</span><span class="nn">Py</span><span class="p">.</span><span class="nn">Object</span><span class="p">.</span><span class="n">t</span> <span class="o">-&gt;</span>
  <span class="o">?</span><span class="n">random_state</span><span class="o">:[`</span><span class="nc">Int</span> <span class="k">of</span> <span class="kt">int</span> <span class="o">|</span> <span class="o">`</span><span class="nc">RandomState</span> <span class="k">of</span> <span class="nn">Py</span><span class="p">.</span><span class="nn">Object</span><span class="p">.</span><span class="n">t</span> <span class="o">|</span> <span class="o">`</span><span class="nc">None</span><span class="o">]</span> <span class="o">-&gt;</span>
  <span class="kt">unit</span> <span class="o">-&gt;</span>
  <span class="n">t</span>
</code></pre></div>

<details class="info" open="open"><summary>FastICA: a fast algorithm for Independent Component Analysis.</summary></details>
<p>Read more in the :ref:<code>User Guide &lt;ICA&gt;</code>.</p>
<h4>Parameters</h4>
<details class="info" open="open"><summary>n_components : int, optional</summary><p>Number of components to use. If none is passed, all are used.</p>
</details>
<details class="info" open="open"><summary>algorithm : {'parallel', 'deflation'}</summary><p>Apply parallel or deflational algorithm for FastICA.</p>
</details>
<details class="info" open="open"><summary>whiten : boolean, optional</summary><p>If whiten is false, the data is already considered to be
whitened, and no whitening is performed.</p>
</details>
<details class="info" open="open"><summary>fun : string or function, optional. Default: 'logcosh'</summary><p>The functional form of the G function used in the
approximation to neg-entropy. Could be either 'logcosh', 'exp',
or 'cube'.
You can also provide your own function. It should return a tuple
containing the value of the function, and of its derivative, in the
point. Example:</p>
<p>def my_g(x):
    return x <strong> 3, (3 * x </strong> 2).mean(axis=-1)</p>
</details>
<details class="info" open="open"><summary>fun_args : dictionary, optional</summary><p>Arguments to send to the functional form.
If empty and if fun='logcosh', fun_args will take value
{'alpha' : 1.0}.</p>
</details>
<details class="info" open="open"><summary>max_iter : int, optional</summary><p>Maximum number of iterations during fit.</p>
</details>
<details class="info" open="open"><summary>tol : float, optional</summary><p>Tolerance on update at each iteration.</p>
</details>
<details class="info" open="open"><summary>w_init : None of an (n_components, n_components) ndarray</summary><p>The mixing matrix to be used to initialize the algorithm.</p>
</details>
<details class="info" open="open"><summary>random_state : int, RandomState instance or None, optional (default=None)</summary><p>If int, random_state is the seed used by the random number generator;
If RandomState instance, random_state is the random number generator;
If None, the random number generator is the RandomState instance used
by <code>np.random</code>.</p>
</details>
<h4>Attributes</h4>
<details class="info" open="open"><summary>components_ : 2D array, shape (n_components, n_features)</summary><p>The linear operator to apply to the data to get the independent
sources. This is equal to the unmixing matrix when <code>whiten</code> is
False, and equal to <code>np.dot(unmixing_matrix, self.whitening_)</code> when
<code>whiten</code> is True.</p>
</details>
<details class="info" open="open"><summary>mixing_ : array, shape (n_features, n_components)</summary><p>The pseudo-inverse of <code>components_</code>. It is the linear operator
that maps independent sources to the data.</p>
</details>
<details class="info" open="open"><summary>mean_ : array, shape(n_features)</summary><p>The mean over features. Only set if <code>self.whiten</code> is True.</p>
</details>
<details class="info" open="open"><summary>n_iter_ : int</summary><p>If the algorithm is "deflation", n_iter is the
maximum number of iterations run across all components. Else
they are just the number of iterations taken to converge.</p>
</details>
<details class="info" open="open"><summary>whitening_ : array, shape (n_components, n_features)</summary><p>Only set if whiten is 'True'. This is the pre-whitening matrix
that projects data onto the first <code>n_components</code> principal components.</p>
</details>
<h4>Examples</h4>
<div class="highlight"><pre><span></span><code><span class="o">&gt;&gt;&gt;</span> <span class="kn">from</span> <span class="nn">sklearn.datasets</span> <span class="kn">import</span> <span class="n">load_digits</span>
<span class="o">&gt;&gt;&gt;</span> <span class="kn">from</span> <span class="nn">sklearn.decomposition</span> <span class="kn">import</span> <span class="n">FastICA</span>
<span class="o">&gt;&gt;&gt;</span> <span class="n">X</span><span class="p">,</span> <span class="n">_</span> <span class="o">=</span> <span class="n">load_digits</span><span class="p">(</span><span class="n">return_X_y</span><span class="o">=</span><span class="kc">True</span><span class="p">)</span>
<span class="o">&gt;&gt;&gt;</span> <span class="n">transformer</span> <span class="o">=</span> <span class="n">FastICA</span><span class="p">(</span><span class="n">n_components</span><span class="o">=</span><span class="mi">7</span><span class="p">,</span>
<span class="o">...</span>         <span class="n">random_state</span><span class="o">=</span><span class="mi">0</span><span class="p">)</span>
<span class="o">&gt;&gt;&gt;</span> <span class="n">X_transformed</span> <span class="o">=</span> <span class="n">transformer</span><span class="o">.</span><span class="n">fit_transform</span><span class="p">(</span><span class="n">X</span><span class="p">)</span>
<span class="o">&gt;&gt;&gt;</span> <span class="n">X_transformed</span><span class="o">.</span><span class="n">shape</span>
<span class="p">(</span><span class="mi">1797</span><span class="p">,</span> <span class="mi">7</span><span class="p">)</span>
</code></pre></div>

<h4>Notes</h4>
<p>Implementation based on
<em>A. Hyvarinen and E. Oja, Independent Component Analysis:
Algorithms and Applications, Neural Networks, 13(4-5), 2000,
pp. 411-430</em></p>
</details>
<h3 id="fit_2">fit<a class="headerlink" href="#fit_2" title="Permanent link">&para;</a></h3>
<details class="note" open="open"><summary>method</summary><div class="highlight"><pre><span></span><code><span class="k">val</span> <span class="n">fit</span> <span class="o">:</span>
  <span class="o">?</span><span class="n">y</span><span class="o">:</span><span class="nn">Py</span><span class="p">.</span><span class="nn">Object</span><span class="p">.</span><span class="n">t</span> <span class="o">-&gt;</span>
  <span class="n">x</span><span class="o">:</span><span class="nn">Ndarray</span><span class="p">.</span><span class="n">t</span> <span class="o">-&gt;</span>
  <span class="n">t</span> <span class="o">-&gt;</span>
  <span class="n">t</span>
</code></pre></div>

<p>Fit the model to X.</p>
<h4>Parameters</h4>
<details class="info" open="open"><summary>X : array-like, shape (n_samples, n_features)</summary><p>Training data, where n_samples is the number of samples
and n_features is the number of features.</p>
</details>
<details class="info" open="open"><summary>y : Ignored</summary></details>
<h4>Returns</h4>
<p>self</p>
</details>
<h3 id="fit_transform_2">fit_transform<a class="headerlink" href="#fit_transform_2" title="Permanent link">&para;</a></h3>
<details class="note" open="open"><summary>method</summary><div class="highlight"><pre><span></span><code><span class="k">val</span> <span class="n">fit_transform</span> <span class="o">:</span>
  <span class="o">?</span><span class="n">y</span><span class="o">:</span><span class="nn">Py</span><span class="p">.</span><span class="nn">Object</span><span class="p">.</span><span class="n">t</span> <span class="o">-&gt;</span>
  <span class="n">x</span><span class="o">:</span><span class="nn">Ndarray</span><span class="p">.</span><span class="n">t</span> <span class="o">-&gt;</span>
  <span class="n">t</span> <span class="o">-&gt;</span>
  <span class="nn">Ndarray</span><span class="p">.</span><span class="n">t</span>
</code></pre></div>

<p>Fit the model and recover the sources from X.</p>
<h4>Parameters</h4>
<details class="info" open="open"><summary>X : array-like, shape (n_samples, n_features)</summary><p>Training data, where n_samples is the number of samples
and n_features is the number of features.</p>
</details>
<details class="info" open="open"><summary>y : Ignored</summary></details>
<h4>Returns</h4>
<details class="info" open="open"><summary>X_new : array-like, shape (n_samples, n_components)</summary></details>
</details>
<h3 id="get_params_2">get_params<a class="headerlink" href="#get_params_2" title="Permanent link">&para;</a></h3>
<details class="note" open="open"><summary>method</summary><div class="highlight"><pre><span></span><code><span class="k">val</span> <span class="n">get_params</span> <span class="o">:</span>
  <span class="o">?</span><span class="n">deep</span><span class="o">:</span><span class="kt">bool</span> <span class="o">-&gt;</span>
  <span class="n">t</span> <span class="o">-&gt;</span>
  <span class="nn">Py</span><span class="p">.</span><span class="nn">Object</span><span class="p">.</span><span class="n">t</span>
</code></pre></div>

<p>Get parameters for this estimator.</p>
<h4>Parameters</h4>
<details class="info" open="open"><summary>deep : bool, default=True</summary><p>If True, will return the parameters for this estimator and
contained subobjects that are estimators.</p>
</details>
<h4>Returns</h4>
<details class="info" open="open"><summary>params : mapping of string to any</summary><p>Parameter names mapped to their values.</p>
</details>
</details>
<h3 id="inverse_transform">inverse_transform<a class="headerlink" href="#inverse_transform" title="Permanent link">&para;</a></h3>
<details class="note" open="open"><summary>method</summary><div class="highlight"><pre><span></span><code><span class="k">val</span> <span class="n">inverse_transform</span> <span class="o">:</span>
  <span class="o">?</span><span class="n">copy</span><span class="o">:</span><span class="nn">Py</span><span class="p">.</span><span class="nn">Object</span><span class="p">.</span><span class="n">t</span> <span class="o">-&gt;</span>
  <span class="n">x</span><span class="o">:</span><span class="nn">Ndarray</span><span class="p">.</span><span class="n">t</span> <span class="o">-&gt;</span>
  <span class="n">t</span> <span class="o">-&gt;</span>
  <span class="nn">Ndarray</span><span class="p">.</span><span class="n">t</span>
</code></pre></div>

<p>Transform the sources back to the mixed data (apply mixing matrix).</p>
<h4>Parameters</h4>
<details class="info" open="open"><summary>X : array-like, shape (n_samples, n_components)</summary><p>Sources, where n_samples is the number of samples
and n_components is the number of components.</p>
</details>
<details class="info" open="open"><summary>copy : bool (optional)</summary><p>If False, data passed to fit are overwritten. Defaults to True.</p>
</details>
<h4>Returns</h4>
<details class="info" open="open"><summary>X_new : array-like, shape (n_samples, n_features)</summary></details>
</details>
<h3 id="set_params_2">set_params<a class="headerlink" href="#set_params_2" title="Permanent link">&para;</a></h3>
<details class="note" open="open"><summary>method</summary><div class="highlight"><pre><span></span><code><span class="k">val</span> <span class="n">set_params</span> <span class="o">:</span>
  <span class="o">?</span><span class="n">params</span><span class="o">:(</span><span class="kt">string</span> <span class="o">*</span> <span class="nn">Py</span><span class="p">.</span><span class="nn">Object</span><span class="p">.</span><span class="n">t</span><span class="o">)</span> <span class="kt">list</span> <span class="o">-&gt;</span>
  <span class="n">t</span> <span class="o">-&gt;</span>
  <span class="n">t</span>
</code></pre></div>

<p>Set the parameters of this estimator.</p>
<p>The method works on simple estimators as well as on nested objects
(such as pipelines). The latter have parameters of the form
<code>&lt;component&gt;__&lt;parameter&gt;</code> so that it's possible to update each
component of a nested object.</p>
<h4>Parameters</h4>
<details class="info" open="open"><summary>**params : dict</summary><p>Estimator parameters.</p>
</details>
<h4>Returns</h4>
<details class="info" open="open"><summary>self : object</summary><p>Estimator instance.</p>
</details>
</details>
<h3 id="transform_2">transform<a class="headerlink" href="#transform_2" title="Permanent link">&para;</a></h3>
<details class="note" open="open"><summary>method</summary><div class="highlight"><pre><span></span><code><span class="k">val</span> <span class="n">transform</span> <span class="o">:</span>
  <span class="o">?</span><span class="n">copy</span><span class="o">:</span><span class="kt">bool</span> <span class="o">-&gt;</span>
  <span class="n">x</span><span class="o">:</span><span class="nn">Ndarray</span><span class="p">.</span><span class="n">t</span> <span class="o">-&gt;</span>
  <span class="n">t</span> <span class="o">-&gt;</span>
  <span class="nn">Ndarray</span><span class="p">.</span><span class="n">t</span>
</code></pre></div>

<p>Recover the sources from X (apply the unmixing matrix).</p>
<h4>Parameters</h4>
<details class="info" open="open"><summary>X : array-like, shape (n_samples, n_features)</summary><p>Data to transform, where n_samples is the number of samples
and n_features is the number of features.</p>
</details>
<details class="info" open="open"><summary>copy : bool (optional)</summary><p>If False, data passed to fit are overwritten. Defaults to True.</p>
</details>
<h4>Returns</h4>
<details class="info" open="open"><summary>X_new : array-like, shape (n_samples, n_components)</summary></details>
</details>
<h3 id="components__2">components_<a class="headerlink" href="#components__2" title="Permanent link">&para;</a></h3>
<details class="note" open="open"><summary>attribute</summary><div class="highlight"><pre><span></span><code><span class="k">val</span> <span class="n">components_</span> <span class="o">:</span> <span class="n">t</span> <span class="o">-&gt;</span> <span class="nn">Py</span><span class="p">.</span><span class="nn">Object</span><span class="p">.</span><span class="n">t</span>
</code></pre></div>

<p>This attribute is documented in <code>create</code> above.</p>
</details>
<h3 id="mixing_">mixing_<a class="headerlink" href="#mixing_" title="Permanent link">&para;</a></h3>
<details class="note" open="open"><summary>attribute</summary><div class="highlight"><pre><span></span><code><span class="k">val</span> <span class="n">mixing_</span> <span class="o">:</span> <span class="n">t</span> <span class="o">-&gt;</span> <span class="nn">Ndarray</span><span class="p">.</span><span class="n">t</span>
</code></pre></div>

<p>This attribute is documented in <code>create</code> above.</p>
</details>
<h3 id="mean__1">mean_<a class="headerlink" href="#mean__1" title="Permanent link">&para;</a></h3>
<details class="note" open="open"><summary>attribute</summary><div class="highlight"><pre><span></span><code><span class="k">val</span> <span class="n">mean_</span> <span class="o">:</span> <span class="n">t</span> <span class="o">-&gt;</span> <span class="nn">Ndarray</span><span class="p">.</span><span class="n">t</span>
</code></pre></div>

<p>This attribute is documented in <code>create</code> above.</p>
</details>
<h3 id="n_iter__2">n_iter_<a class="headerlink" href="#n_iter__2" title="Permanent link">&para;</a></h3>
<details class="note" open="open"><summary>attribute</summary><div class="highlight"><pre><span></span><code><span class="k">val</span> <span class="n">n_iter_</span> <span class="o">:</span> <span class="n">t</span> <span class="o">-&gt;</span> <span class="kt">int</span>
</code></pre></div>

<p>This attribute is documented in <code>create</code> above.</p>
</details>
<h3 id="whitening_">whitening_<a class="headerlink" href="#whitening_" title="Permanent link">&para;</a></h3>
<details class="note" open="open"><summary>attribute</summary><div class="highlight"><pre><span></span><code><span class="k">val</span> <span class="n">whitening_</span> <span class="o">:</span> <span class="n">t</span> <span class="o">-&gt;</span> <span class="nn">Ndarray</span><span class="p">.</span><span class="n">t</span>
</code></pre></div>

<p>This attribute is documented in <code>create</code> above.</p>
</details>
<h3 id="to_string_2">to_string<a class="headerlink" href="#to_string_2" title="Permanent link">&para;</a></h3>
<details class="note" open="open"><summary>method</summary><div class="highlight"><pre><span></span><code><span class="k">val</span> <span class="n">to_string</span><span class="o">:</span> <span class="n">t</span> <span class="o">-&gt;</span> <span class="kt">string</span>
</code></pre></div>

<p>Print the object to a human-readable representation.</p>
</details>
<h3 id="show_2">show<a class="headerlink" href="#show_2" title="Permanent link">&para;</a></h3>
<details class="note" open="open"><summary>method</summary><div class="highlight"><pre><span></span><code><span class="k">val</span> <span class="n">show</span><span class="o">:</span> <span class="n">t</span> <span class="o">-&gt;</span> <span class="kt">string</span>
</code></pre></div>

<p>Print the object to a human-readable representation.</p>
</details>
<h3 id="pp_2">pp<a class="headerlink" href="#pp_2" title="Permanent link">&para;</a></h3>
<details class="note" open="open"><summary>method</summary><div class="highlight"><pre><span></span><code><span class="k">val</span> <span class="n">pp</span><span class="o">:</span> <span class="nn">Format</span><span class="p">.</span><span class="n">formatter</span> <span class="o">-&gt;</span> <span class="n">t</span> <span class="o">-&gt;</span> <span class="kt">unit</span>
</code></pre></div>

<p>Pretty-print the object to a formatter.</p>
</details>
<h2 id="module-sklearndecompositionincrementalpca">module Sklearn.​Decomposition.​IncrementalPCA<a class="headerlink" href="#module-sklearndecompositionincrementalpca" title="Permanent link">&para;</a></h2>
<div class="highlight"><pre><span></span><code><span class="k">type</span> <span class="n">t</span>
</code></pre></div>

<h3 id="create_3">create<a class="headerlink" href="#create_3" title="Permanent link">&para;</a></h3>
<details class="note" open="open"><summary>constructor and attributes</summary><div class="highlight"><pre><span></span><code><span class="k">val</span> <span class="n">create</span> <span class="o">:</span>
  <span class="o">?</span><span class="n">n_components</span><span class="o">:[`</span><span class="nc">Int</span> <span class="k">of</span> <span class="kt">int</span> <span class="o">|</span> <span class="o">`</span><span class="nc">None</span><span class="o">]</span> <span class="o">-&gt;</span>
  <span class="o">?</span><span class="n">whiten</span><span class="o">:</span><span class="kt">bool</span> <span class="o">-&gt;</span>
  <span class="o">?</span><span class="n">copy</span><span class="o">:</span><span class="kt">bool</span> <span class="o">-&gt;</span>
  <span class="o">?</span><span class="n">batch_size</span><span class="o">:[`</span><span class="nc">Int</span> <span class="k">of</span> <span class="kt">int</span> <span class="o">|</span> <span class="o">`</span><span class="nc">None</span><span class="o">]</span> <span class="o">-&gt;</span>
  <span class="kt">unit</span> <span class="o">-&gt;</span>
  <span class="n">t</span>
</code></pre></div>

<p>Incremental principal components analysis (IPCA).</p>
<p>Linear dimensionality reduction using Singular Value Decomposition of
the data, keeping only the most significant singular vectors to
project the data to a lower dimensional space. The input data is centered
but not scaled for each feature before applying the SVD.</p>
<p>Depending on the size of the input data, this algorithm can be much more
memory efficient than a PCA, and allows sparse input.</p>
<p>This algorithm has constant memory complexity, on the order
of <code>batch_size * n_features</code>, enabling use of np.memmap files without
loading the entire file into memory. For sparse matrices, the input
is converted to dense in batches (in order to be able to subtract the
mean) which avoids storing the entire dense matrix at any one time.</p>
<p>The computational overhead of each SVD is
<code>O(batch_size * n_features ** 2)</code>, but only 2 * batch_size samples
remain in memory at a time. There will be <code>n_samples / batch_size</code> SVD
computations to get the principal components, versus 1 large SVD of
complexity <code>O(n_samples * n_features ** 2)</code> for PCA.</p>
<p>Read more in the :ref:<code>User Guide &lt;IncrementalPCA&gt;</code>.</p>
<p>.. versionadded:: 0.16</p>
<h4>Parameters</h4>
<details class="info" open="open"><summary>n_components : int or None, (default=None)</summary><p>Number of components to keep. If <code>n_components</code> is <code>None</code>,
then <code>n_components</code> is set to <code>min(n_samples, n_features)</code>.</p>
</details>
<details class="info" open="open"><summary>whiten : bool, optional</summary><p>When True (False by default) the <code>components_</code> vectors are divided
by <code>n_samples</code> times <code>components_</code> to ensure uncorrelated outputs
with unit component-wise variances.</p>
<p>Whitening will remove some information from the transformed signal
(the relative variance scales of the components) but can sometimes
improve the predictive accuracy of the downstream estimators by
making data respect some hard-wired assumptions.</p>
</details>
<details class="info" open="open"><summary>copy : bool, (default=True)</summary><p>If False, X will be overwritten. <code>copy=False</code> can be used to
save memory but is unsafe for general use.</p>
</details>
<details class="info" open="open"><summary>batch_size : int or None, (default=None)</summary><p>The number of samples to use for each batch. Only used when calling
<code>fit</code>. If <code>batch_size</code> is <code>None</code>, then <code>batch_size</code>
is inferred from the data and set to <code>5 * n_features</code>, to provide a
balance between approximation accuracy and memory consumption.</p>
</details>
<h4>Attributes</h4>
<details class="info" open="open"><summary>components_ : array, shape (n_components, n_features)</summary><p>Components with maximum variance.</p>
</details>
<details class="info" open="open"><summary>explained_variance_ : array, shape (n_components,)</summary><p>Variance explained by each of the selected components.</p>
</details>
<details class="info" open="open"><summary>explained_variance_ratio_ : array, shape (n_components,)</summary><p>Percentage of variance explained by each of the selected components.
If all components are stored, the sum of explained variances is equal
to 1.0.</p>
</details>
<details class="info" open="open"><summary>singular_values_ : array, shape (n_components,)</summary><p>The singular values corresponding to each of the selected components.
The singular values are equal to the 2-norms of the <code>n_components</code>
variables in the lower-dimensional space.</p>
</details>
<details class="info" open="open"><summary>mean_ : array, shape (n_features,)</summary><p>Per-feature empirical mean, aggregate over calls to <code>partial_fit</code>.</p>
</details>
<details class="info" open="open"><summary>var_ : array, shape (n_features,)</summary><p>Per-feature empirical variance, aggregate over calls to
<code>partial_fit</code>.</p>
</details>
<details class="info" open="open"><summary>noise_variance_ : float</summary><p>The estimated noise covariance following the Probabilistic PCA model
from Tipping and Bishop 1999. See "Pattern Recognition and
Machine Learning" by C. Bishop, 12.2.1 p. 574 or</p>
</details>
<details class="info" open="open"><summary>http://www.miketipping.com/papers/met-mppca.pdf.</summary></details>
<details class="info" open="open"><summary>n_components_ : int</summary><p>The estimated number of components. Relevant when
<code>n_components=None</code>.</p>
</details>
<details class="info" open="open"><summary>n_samples_seen_ : int</summary><p>The number of samples processed by the estimator. Will be reset on
new calls to fit, but increments across <code>partial_fit</code> calls.</p>
</details>
<h4>Examples</h4>
<div class="highlight"><pre><span></span><code><span class="o">&gt;&gt;&gt;</span> <span class="kn">from</span> <span class="nn">sklearn.datasets</span> <span class="kn">import</span> <span class="n">load_digits</span>
<span class="o">&gt;&gt;&gt;</span> <span class="kn">from</span> <span class="nn">sklearn.decomposition</span> <span class="kn">import</span> <span class="n">IncrementalPCA</span>
<span class="o">&gt;&gt;&gt;</span> <span class="kn">from</span> <span class="nn">scipy</span> <span class="kn">import</span> <span class="n">sparse</span>
<span class="o">&gt;&gt;&gt;</span> <span class="n">X</span><span class="p">,</span> <span class="n">_</span> <span class="o">=</span> <span class="n">load_digits</span><span class="p">(</span><span class="n">return_X_y</span><span class="o">=</span><span class="kc">True</span><span class="p">)</span>
<span class="o">&gt;&gt;&gt;</span> <span class="n">transformer</span> <span class="o">=</span> <span class="n">IncrementalPCA</span><span class="p">(</span><span class="n">n_components</span><span class="o">=</span><span class="mi">7</span><span class="p">,</span> <span class="n">batch_size</span><span class="o">=</span><span class="mi">200</span><span class="p">)</span>
<span class="o">&gt;&gt;&gt;</span> <span class="c1"># either partially fit on smaller batches of data</span>
<span class="o">&gt;&gt;&gt;</span> <span class="n">transformer</span><span class="o">.</span><span class="n">partial_fit</span><span class="p">(</span><span class="n">X</span><span class="p">[:</span><span class="mi">100</span><span class="p">,</span> <span class="p">:])</span>
<span class="n">IncrementalPCA</span><span class="p">(</span><span class="n">batch_size</span><span class="o">=</span><span class="mi">200</span><span class="p">,</span> <span class="n">n_components</span><span class="o">=</span><span class="mi">7</span><span class="p">)</span>
<span class="o">&gt;&gt;&gt;</span> <span class="c1"># or let the fit function itself divide the data into batches</span>
<span class="o">&gt;&gt;&gt;</span> <span class="n">X_sparse</span> <span class="o">=</span> <span class="n">sparse</span><span class="o">.</span><span class="n">csr_matrix</span><span class="p">(</span><span class="n">X</span><span class="p">)</span>
<span class="o">&gt;&gt;&gt;</span> <span class="n">X_transformed</span> <span class="o">=</span> <span class="n">transformer</span><span class="o">.</span><span class="n">fit_transform</span><span class="p">(</span><span class="n">X_sparse</span><span class="p">)</span>
<span class="o">&gt;&gt;&gt;</span> <span class="n">X_transformed</span><span class="o">.</span><span class="n">shape</span>
<span class="p">(</span><span class="mi">1797</span><span class="p">,</span> <span class="mi">7</span><span class="p">)</span>
</code></pre></div>

<h4>Notes</h4>
<p>Implements the incremental PCA model from:
<em>D. Ross, J. Lim, R. Lin, M. Yang, Incremental Learning for Robust Visual
Tracking, International Journal of Computer Vision, Volume 77, Issue 1-3,
pp. 125-141, May 2008.</em>
See https://www.cs.toronto.edu/~dross/ivt/RossLimLinYang_ijcv.pdf</p>
<p>This model is an extension of the Sequential Karhunen-Loeve Transform from:
<em>A. Levy and M. Lindenbaum, Sequential Karhunen-Loeve Basis Extraction and
its Application to Images, IEEE Transactions on Image Processing, Volume 9,
Number 8, pp. 1371-1374, August 2000.</em>
See https://www.cs.technion.ac.il/~mic/doc/skl-ip.pdf</p>
<p>We have specifically abstained from an optimization used by authors of both
papers, a QR decomposition used in specific situations to reduce the
algorithmic complexity of the SVD. The source for this technique is
<em>Matrix Computations, Third Edition, G. Holub and C. Van Loan, Chapter 5,
section 5.4.4, pp 252-253.</em>. This technique has been omitted because it is
advantageous only when decomposing a matrix with <code>n_samples</code> (rows)</p>
<blockquote>
<p>= 5/3 * <code>n_features</code> (columns), and hurts the readability of the
implemented algorithm. This would be a good opportunity for future
optimization, if it is deemed necessary.</p>
</blockquote>
<h4>References</h4>
<p>D. Ross, J. Lim, R. Lin, M. Yang. Incremental Learning for Robust Visual
Tracking, International Journal of Computer Vision, Volume 77,
Issue 1-3, pp. 125-141, May 2008.</p>
<p>G. Golub and C. Van Loan. Matrix Computations, Third Edition, Chapter 5,
Section 5.4.4, pp. 252-253.</p>
<h4>See also</h4>
<p>PCA
KernelPCA
SparsePCA
TruncatedSVD</p>
</details>
<h3 id="fit_3">fit<a class="headerlink" href="#fit_3" title="Permanent link">&para;</a></h3>
<details class="note" open="open"><summary>method</summary><div class="highlight"><pre><span></span><code><span class="k">val</span> <span class="n">fit</span> <span class="o">:</span>
  <span class="o">?</span><span class="n">y</span><span class="o">:</span><span class="nn">Py</span><span class="p">.</span><span class="nn">Object</span><span class="p">.</span><span class="n">t</span> <span class="o">-&gt;</span>
  <span class="n">x</span><span class="o">:[`</span><span class="nc">Ndarray</span> <span class="k">of</span> <span class="nn">Ndarray</span><span class="p">.</span><span class="n">t</span> <span class="o">|</span> <span class="o">`</span><span class="nc">SparseMatrix</span> <span class="k">of</span> <span class="nn">Csr_matrix</span><span class="p">.</span><span class="n">t</span><span class="o">]</span> <span class="o">-&gt;</span>
  <span class="n">t</span> <span class="o">-&gt;</span>
  <span class="n">t</span>
</code></pre></div>

<p>Fit the model with X, using minibatches of size batch_size.</p>
<h4>Parameters</h4>
<details class="info" open="open"><summary>X : array-like or sparse matrix, shape (n_samples, n_features)</summary><p>Training data, where n_samples is the number of samples and
n_features is the number of features.</p>
</details>
<details class="info" open="open"><summary>y : Ignored</summary></details>
<h4>Returns</h4>
<details class="info" open="open"><summary>self : object</summary><p>Returns the instance itself.</p>
</details>
</details>
<h3 id="fit_transform_3">fit_transform<a class="headerlink" href="#fit_transform_3" title="Permanent link">&para;</a></h3>
<details class="note" open="open"><summary>method</summary><div class="highlight"><pre><span></span><code><span class="k">val</span> <span class="n">fit_transform</span> <span class="o">:</span>
  <span class="o">?</span><span class="n">y</span><span class="o">:</span><span class="nn">Ndarray</span><span class="p">.</span><span class="n">t</span> <span class="o">-&gt;</span>
  <span class="o">?</span><span class="n">fit_params</span><span class="o">:(</span><span class="kt">string</span> <span class="o">*</span> <span class="nn">Py</span><span class="p">.</span><span class="nn">Object</span><span class="p">.</span><span class="n">t</span><span class="o">)</span> <span class="kt">list</span> <span class="o">-&gt;</span>
  <span class="n">x</span><span class="o">:</span><span class="nn">Ndarray</span><span class="p">.</span><span class="n">t</span> <span class="o">-&gt;</span>
  <span class="n">t</span> <span class="o">-&gt;</span>
  <span class="nn">Ndarray</span><span class="p">.</span><span class="n">t</span>
</code></pre></div>

<p>Fit to data, then transform it.</p>
<p>Fits transformer to X and y with optional parameters fit_params
and returns a transformed version of X.</p>
<h4>Parameters</h4>
<details class="info" open="open"><summary>X : numpy array of shape [n_samples, n_features]</summary><p>Training set.</p>
</details>
<details class="info" open="open"><summary>y : numpy array of shape [n_samples]</summary><p>Target values.</p>
</details>
<details class="info" open="open"><summary>**fit_params : dict</summary><p>Additional fit parameters.</p>
</details>
<h4>Returns</h4>
<details class="info" open="open"><summary>X_new : numpy array of shape [n_samples, n_features_new]</summary><p>Transformed array.</p>
</details>
</details>
<h3 id="get_covariance_1">get_covariance<a class="headerlink" href="#get_covariance_1" title="Permanent link">&para;</a></h3>
<details class="note" open="open"><summary>method</summary><div class="highlight"><pre><span></span><code><span class="k">val</span> <span class="n">get_covariance</span> <span class="o">:</span>
  <span class="n">t</span> <span class="o">-&gt;</span>
  <span class="nn">Ndarray</span><span class="p">.</span><span class="n">t</span>
</code></pre></div>

<p>Compute data covariance with the generative model.</p>
<p><code>cov = components_.T * S**2 * components_ + sigma2 * eye(n_features)</code>
where S**2 contains the explained variances, and sigma2 contains the
noise variances.</p>
<h4>Returns</h4>
<details class="info" open="open"><summary>cov : array, shape=(n_features, n_features)</summary><p>Estimated covariance of data.</p>
</details>
</details>
<h3 id="get_params_3">get_params<a class="headerlink" href="#get_params_3" title="Permanent link">&para;</a></h3>
<details class="note" open="open"><summary>method</summary><div class="highlight"><pre><span></span><code><span class="k">val</span> <span class="n">get_params</span> <span class="o">:</span>
  <span class="o">?</span><span class="n">deep</span><span class="o">:</span><span class="kt">bool</span> <span class="o">-&gt;</span>
  <span class="n">t</span> <span class="o">-&gt;</span>
  <span class="nn">Py</span><span class="p">.</span><span class="nn">Object</span><span class="p">.</span><span class="n">t</span>
</code></pre></div>

<p>Get parameters for this estimator.</p>
<h4>Parameters</h4>
<details class="info" open="open"><summary>deep : bool, default=True</summary><p>If True, will return the parameters for this estimator and
contained subobjects that are estimators.</p>
</details>
<h4>Returns</h4>
<details class="info" open="open"><summary>params : mapping of string to any</summary><p>Parameter names mapped to their values.</p>
</details>
</details>
<h3 id="get_precision_1">get_precision<a class="headerlink" href="#get_precision_1" title="Permanent link">&para;</a></h3>
<details class="note" open="open"><summary>method</summary><div class="highlight"><pre><span></span><code><span class="k">val</span> <span class="n">get_precision</span> <span class="o">:</span>
  <span class="n">t</span> <span class="o">-&gt;</span>
  <span class="nn">Ndarray</span><span class="p">.</span><span class="n">t</span>
</code></pre></div>

<p>Compute data precision matrix with the generative model.</p>
<p>Equals the inverse of the covariance but computed with
the matrix inversion lemma for efficiency.</p>
<h4>Returns</h4>
<details class="info" open="open"><summary>precision : array, shape=(n_features, n_features)</summary><p>Estimated precision of data.</p>
</details>
</details>
<h3 id="inverse_transform_1">inverse_transform<a class="headerlink" href="#inverse_transform_1" title="Permanent link">&para;</a></h3>
<details class="note" open="open"><summary>method</summary><div class="highlight"><pre><span></span><code><span class="k">val</span> <span class="n">inverse_transform</span> <span class="o">:</span>
  <span class="n">x</span><span class="o">:</span><span class="nn">Ndarray</span><span class="p">.</span><span class="n">t</span> <span class="o">-&gt;</span>
  <span class="n">t</span> <span class="o">-&gt;</span>
  <span class="nn">Py</span><span class="p">.</span><span class="nn">Object</span><span class="p">.</span><span class="n">t</span>
</code></pre></div>

<p>Transform data back to its original space.</p>
<p>In other words, return an input X_original whose transform would be X.</p>
<h4>Parameters</h4>
<details class="info" open="open"><summary>X : array-like, shape (n_samples, n_components)</summary><p>New data, where n_samples is the number of samples
and n_components is the number of components.</p>
</details>
<h4>Returns</h4>
<p>X_original array-like, shape (n_samples, n_features)</p>
<h4>Notes</h4>
<p>If whitening is enabled, inverse_transform will compute the
exact inverse operation, which includes reversing whitening.</p>
</details>
<h3 id="partial_fit">partial_fit<a class="headerlink" href="#partial_fit" title="Permanent link">&para;</a></h3>
<details class="note" open="open"><summary>method</summary><div class="highlight"><pre><span></span><code><span class="k">val</span> <span class="n">partial_fit</span> <span class="o">:</span>
  <span class="o">?</span><span class="n">y</span><span class="o">:</span><span class="nn">Py</span><span class="p">.</span><span class="nn">Object</span><span class="p">.</span><span class="n">t</span> <span class="o">-&gt;</span>
  <span class="o">?</span><span class="n">check_input</span><span class="o">:</span><span class="nn">Py</span><span class="p">.</span><span class="nn">Object</span><span class="p">.</span><span class="n">t</span> <span class="o">-&gt;</span>
  <span class="n">x</span><span class="o">:</span><span class="nn">Ndarray</span><span class="p">.</span><span class="n">t</span> <span class="o">-&gt;</span>
  <span class="n">t</span> <span class="o">-&gt;</span>
  <span class="n">t</span>
</code></pre></div>

<p>Incremental fit with X. All of X is processed as a single batch.</p>
<h4>Parameters</h4>
<details class="info" open="open"><summary>X : array-like, shape (n_samples, n_features)</summary><p>Training data, where n_samples is the number of samples and
n_features is the number of features.</p>
</details>
<details class="info" open="open"><summary>check_input : bool</summary><p>Run check_array on X.</p>
</details>
<details class="info" open="open"><summary>y : Ignored</summary></details>
<h4>Returns</h4>
<details class="info" open="open"><summary>self : object</summary><p>Returns the instance itself.</p>
</details>
</details>
<h3 id="set_params_3">set_params<a class="headerlink" href="#set_params_3" title="Permanent link">&para;</a></h3>
<details class="note" open="open"><summary>method</summary><div class="highlight"><pre><span></span><code><span class="k">val</span> <span class="n">set_params</span> <span class="o">:</span>
  <span class="o">?</span><span class="n">params</span><span class="o">:(</span><span class="kt">string</span> <span class="o">*</span> <span class="nn">Py</span><span class="p">.</span><span class="nn">Object</span><span class="p">.</span><span class="n">t</span><span class="o">)</span> <span class="kt">list</span> <span class="o">-&gt;</span>
  <span class="n">t</span> <span class="o">-&gt;</span>
  <span class="n">t</span>
</code></pre></div>

<p>Set the parameters of this estimator.</p>
<p>The method works on simple estimators as well as on nested objects
(such as pipelines). The latter have parameters of the form
<code>&lt;component&gt;__&lt;parameter&gt;</code> so that it's possible to update each
component of a nested object.</p>
<h4>Parameters</h4>
<details class="info" open="open"><summary>**params : dict</summary><p>Estimator parameters.</p>
</details>
<h4>Returns</h4>
<details class="info" open="open"><summary>self : object</summary><p>Estimator instance.</p>
</details>
</details>
<h3 id="transform_3">transform<a class="headerlink" href="#transform_3" title="Permanent link">&para;</a></h3>
<details class="note" open="open"><summary>method</summary><div class="highlight"><pre><span></span><code><span class="k">val</span> <span class="n">transform</span> <span class="o">:</span>
  <span class="n">x</span><span class="o">:</span><span class="nn">Ndarray</span><span class="p">.</span><span class="n">t</span> <span class="o">-&gt;</span>
  <span class="n">t</span> <span class="o">-&gt;</span>
  <span class="nn">Ndarray</span><span class="p">.</span><span class="n">t</span>
</code></pre></div>

<p>Apply dimensionality reduction to X.</p>
<p>X is projected on the first principal components previously extracted
from a training set, using minibatches of size batch_size if X is
sparse.</p>
<h4>Parameters</h4>
<details class="info" open="open"><summary>X : array-like, shape (n_samples, n_features)</summary><p>New data, where n_samples is the number of samples
and n_features is the number of features.</p>
</details>
<h4>Returns</h4>
<details class="info" open="open"><summary>X_new : array-like, shape (n_samples, n_components)</summary></details>
<h4>Examples</h4>
<div class="highlight"><pre><span></span><code><span class="o">&gt;&gt;&gt;</span> <span class="kn">import</span> <span class="nn">numpy</span> <span class="k">as</span> <span class="nn">np</span>
<span class="o">&gt;&gt;&gt;</span> <span class="kn">from</span> <span class="nn">sklearn.decomposition</span> <span class="kn">import</span> <span class="n">IncrementalPCA</span>
<span class="o">&gt;&gt;&gt;</span> <span class="n">X</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">array</span><span class="p">([[</span><span class="o">-</span><span class="mi">1</span><span class="p">,</span> <span class="o">-</span><span class="mi">1</span><span class="p">],</span> <span class="p">[</span><span class="o">-</span><span class="mi">2</span><span class="p">,</span> <span class="o">-</span><span class="mi">1</span><span class="p">],</span> <span class="p">[</span><span class="o">-</span><span class="mi">3</span><span class="p">,</span> <span class="o">-</span><span class="mi">2</span><span class="p">],</span>
<span class="o">...</span>               <span class="p">[</span><span class="mi">1</span><span class="p">,</span> <span class="mi">1</span><span class="p">],</span> <span class="p">[</span><span class="mi">2</span><span class="p">,</span> <span class="mi">1</span><span class="p">],</span> <span class="p">[</span><span class="mi">3</span><span class="p">,</span> <span class="mi">2</span><span class="p">]])</span>
<span class="o">&gt;&gt;&gt;</span> <span class="n">ipca</span> <span class="o">=</span> <span class="n">IncrementalPCA</span><span class="p">(</span><span class="n">n_components</span><span class="o">=</span><span class="mi">2</span><span class="p">,</span> <span class="n">batch_size</span><span class="o">=</span><span class="mi">3</span><span class="p">)</span>
<span class="o">&gt;&gt;&gt;</span> <span class="n">ipca</span><span class="o">.</span><span class="n">fit</span><span class="p">(</span><span class="n">X</span><span class="p">)</span>
<span class="n">IncrementalPCA</span><span class="p">(</span><span class="n">batch_size</span><span class="o">=</span><span class="mi">3</span><span class="p">,</span> <span class="n">n_components</span><span class="o">=</span><span class="mi">2</span><span class="p">)</span>
<span class="o">&gt;&gt;&gt;</span> <span class="n">ipca</span><span class="o">.</span><span class="n">transform</span><span class="p">(</span><span class="n">X</span><span class="p">)</span> <span class="c1"># doctest: +SKIP</span>
</code></pre></div>

</details>
<h3 id="components__3">components_<a class="headerlink" href="#components__3" title="Permanent link">&para;</a></h3>
<details class="note" open="open"><summary>attribute</summary><div class="highlight"><pre><span></span><code><span class="k">val</span> <span class="n">components_</span> <span class="o">:</span> <span class="n">t</span> <span class="o">-&gt;</span> <span class="nn">Ndarray</span><span class="p">.</span><span class="n">t</span>
</code></pre></div>

<p>This attribute is documented in <code>create</code> above.</p>
</details>
<h3 id="explained_variance_">explained_variance_<a class="headerlink" href="#explained_variance_" title="Permanent link">&para;</a></h3>
<details class="note" open="open"><summary>attribute</summary><div class="highlight"><pre><span></span><code><span class="k">val</span> <span class="n">explained_variance_</span> <span class="o">:</span> <span class="n">t</span> <span class="o">-&gt;</span> <span class="nn">Ndarray</span><span class="p">.</span><span class="n">t</span>
</code></pre></div>

<p>This attribute is documented in <code>create</code> above.</p>
</details>
<h3 id="explained_variance_ratio_">explained_variance_ratio_<a class="headerlink" href="#explained_variance_ratio_" title="Permanent link">&para;</a></h3>
<details class="note" open="open"><summary>attribute</summary><div class="highlight"><pre><span></span><code><span class="k">val</span> <span class="n">explained_variance_ratio_</span> <span class="o">:</span> <span class="n">t</span> <span class="o">-&gt;</span> <span class="nn">Ndarray</span><span class="p">.</span><span class="n">t</span>
</code></pre></div>

<p>This attribute is documented in <code>create</code> above.</p>
</details>
<h3 id="singular_values_">singular_values_<a class="headerlink" href="#singular_values_" title="Permanent link">&para;</a></h3>
<details class="note" open="open"><summary>attribute</summary><div class="highlight"><pre><span></span><code><span class="k">val</span> <span class="n">singular_values_</span> <span class="o">:</span> <span class="n">t</span> <span class="o">-&gt;</span> <span class="nn">Ndarray</span><span class="p">.</span><span class="n">t</span>
</code></pre></div>

<p>This attribute is documented in <code>create</code> above.</p>
</details>
<h3 id="mean__2">mean_<a class="headerlink" href="#mean__2" title="Permanent link">&para;</a></h3>
<details class="note" open="open"><summary>attribute</summary><div class="highlight"><pre><span></span><code><span class="k">val</span> <span class="n">mean_</span> <span class="o">:</span> <span class="n">t</span> <span class="o">-&gt;</span> <span class="nn">Ndarray</span><span class="p">.</span><span class="n">t</span>
</code></pre></div>

<p>This attribute is documented in <code>create</code> above.</p>
</details>
<h3 id="var_">var_<a class="headerlink" href="#var_" title="Permanent link">&para;</a></h3>
<details class="note" open="open"><summary>attribute</summary><div class="highlight"><pre><span></span><code><span class="k">val</span> <span class="n">var_</span> <span class="o">:</span> <span class="n">t</span> <span class="o">-&gt;</span> <span class="nn">Ndarray</span><span class="p">.</span><span class="n">t</span>
</code></pre></div>

<p>This attribute is documented in <code>create</code> above.</p>
</details>
<h3 id="noise_variance__1">noise_variance_<a class="headerlink" href="#noise_variance__1" title="Permanent link">&para;</a></h3>
<details class="note" open="open"><summary>attribute</summary><div class="highlight"><pre><span></span><code><span class="k">val</span> <span class="n">noise_variance_</span> <span class="o">:</span> <span class="n">t</span> <span class="o">-&gt;</span> <span class="kt">float</span>
</code></pre></div>

<p>This attribute is documented in <code>create</code> above.</p>
</details>
<h3 id="n_components_">n_components_<a class="headerlink" href="#n_components_" title="Permanent link">&para;</a></h3>
<details class="note" open="open"><summary>attribute</summary><div class="highlight"><pre><span></span><code><span class="k">val</span> <span class="n">n_components_</span> <span class="o">:</span> <span class="n">t</span> <span class="o">-&gt;</span> <span class="kt">int</span>
</code></pre></div>

<p>This attribute is documented in <code>create</code> above.</p>
</details>
<h3 id="n_samples_seen_">n_samples_seen_<a class="headerlink" href="#n_samples_seen_" title="Permanent link">&para;</a></h3>
<details class="note" open="open"><summary>attribute</summary><div class="highlight"><pre><span></span><code><span class="k">val</span> <span class="n">n_samples_seen_</span> <span class="o">:</span> <span class="n">t</span> <span class="o">-&gt;</span> <span class="kt">int</span>
</code></pre></div>

<p>This attribute is documented in <code>create</code> above.</p>
</details>
<h3 id="to_string_3">to_string<a class="headerlink" href="#to_string_3" title="Permanent link">&para;</a></h3>
<details class="note" open="open"><summary>method</summary><div class="highlight"><pre><span></span><code><span class="k">val</span> <span class="n">to_string</span><span class="o">:</span> <span class="n">t</span> <span class="o">-&gt;</span> <span class="kt">string</span>
</code></pre></div>

<p>Print the object to a human-readable representation.</p>
</details>
<h3 id="show_3">show<a class="headerlink" href="#show_3" title="Permanent link">&para;</a></h3>
<details class="note" open="open"><summary>method</summary><div class="highlight"><pre><span></span><code><span class="k">val</span> <span class="n">show</span><span class="o">:</span> <span class="n">t</span> <span class="o">-&gt;</span> <span class="kt">string</span>
</code></pre></div>

<p>Print the object to a human-readable representation.</p>
</details>
<h3 id="pp_3">pp<a class="headerlink" href="#pp_3" title="Permanent link">&para;</a></h3>
<details class="note" open="open"><summary>method</summary><div class="highlight"><pre><span></span><code><span class="k">val</span> <span class="n">pp</span><span class="o">:</span> <span class="nn">Format</span><span class="p">.</span><span class="n">formatter</span> <span class="o">-&gt;</span> <span class="n">t</span> <span class="o">-&gt;</span> <span class="kt">unit</span>
</code></pre></div>

<p>Pretty-print the object to a formatter.</p>
</details>
<h2 id="module-sklearndecompositionkernelpca">module Sklearn.​Decomposition.​KernelPCA<a class="headerlink" href="#module-sklearndecompositionkernelpca" title="Permanent link">&para;</a></h2>
<div class="highlight"><pre><span></span><code><span class="k">type</span> <span class="n">t</span>
</code></pre></div>

<h3 id="create_4">create<a class="headerlink" href="#create_4" title="Permanent link">&para;</a></h3>
<details class="note" open="open"><summary>constructor and attributes</summary><div class="highlight"><pre><span></span><code><span class="k">val</span> <span class="n">create</span> <span class="o">:</span>
  <span class="o">?</span><span class="n">n_components</span><span class="o">:</span><span class="kt">int</span> <span class="o">-&gt;</span>
  <span class="o">?</span><span class="n">kernel</span><span class="o">:[`</span><span class="nc">Linear</span> <span class="o">|</span> <span class="o">`</span><span class="nc">Poly</span> <span class="o">|</span> <span class="o">`</span><span class="nc">Rbf</span> <span class="o">|</span> <span class="o">`</span><span class="nc">Sigmoid</span> <span class="o">|</span> <span class="o">`</span><span class="nc">Cosine</span> <span class="o">|</span> <span class="o">`</span><span class="nc">Precomputed</span><span class="o">]</span> <span class="o">-&gt;</span>
  <span class="o">?</span><span class="n">gamma</span><span class="o">:</span><span class="kt">float</span> <span class="o">-&gt;</span>
  <span class="o">?</span><span class="n">degree</span><span class="o">:</span><span class="kt">int</span> <span class="o">-&gt;</span>
  <span class="o">?</span><span class="n">coef0</span><span class="o">:</span><span class="kt">float</span> <span class="o">-&gt;</span>
  <span class="o">?</span><span class="n">kernel_params</span><span class="o">:</span><span class="nn">Py</span><span class="p">.</span><span class="nn">Object</span><span class="p">.</span><span class="n">t</span> <span class="o">-&gt;</span>
  <span class="o">?</span><span class="n">alpha</span><span class="o">:</span><span class="kt">int</span> <span class="o">-&gt;</span>
  <span class="o">?</span><span class="n">fit_inverse_transform</span><span class="o">:</span><span class="kt">bool</span> <span class="o">-&gt;</span>
  <span class="o">?</span><span class="n">eigen_solver</span><span class="o">:[`</span><span class="nc">Auto</span> <span class="o">|</span> <span class="o">`</span><span class="nc">Dense</span> <span class="o">|</span> <span class="o">`</span><span class="nc">Arpack</span><span class="o">]</span> <span class="o">-&gt;</span>
  <span class="o">?</span><span class="n">tol</span><span class="o">:</span><span class="kt">float</span> <span class="o">-&gt;</span>
  <span class="o">?</span><span class="n">max_iter</span><span class="o">:</span><span class="kt">int</span> <span class="o">-&gt;</span>
  <span class="o">?</span><span class="n">remove_zero_eig</span><span class="o">:</span><span class="kt">bool</span> <span class="o">-&gt;</span>
  <span class="o">?</span><span class="n">random_state</span><span class="o">:[`</span><span class="nc">Int</span> <span class="k">of</span> <span class="kt">int</span> <span class="o">|</span> <span class="o">`</span><span class="nc">RandomState</span> <span class="k">of</span> <span class="nn">Py</span><span class="p">.</span><span class="nn">Object</span><span class="p">.</span><span class="n">t</span> <span class="o">|</span> <span class="o">`</span><span class="nc">None</span><span class="o">]</span> <span class="o">-&gt;</span>
  <span class="o">?</span><span class="n">copy_X</span><span class="o">:</span><span class="kt">bool</span> <span class="o">-&gt;</span>
  <span class="o">?</span><span class="n">n_jobs</span><span class="o">:[`</span><span class="nc">Int</span> <span class="k">of</span> <span class="kt">int</span> <span class="o">|</span> <span class="o">`</span><span class="nc">None</span><span class="o">]</span> <span class="o">-&gt;</span>
  <span class="kt">unit</span> <span class="o">-&gt;</span>
  <span class="n">t</span>
</code></pre></div>

<p>Kernel Principal component analysis (KPCA)</p>
<p>Non-linear dimensionality reduction through the use of kernels (see
:ref:<code>metrics</code>).</p>
<p>Read more in the :ref:<code>User Guide &lt;kernel_PCA&gt;</code>.</p>
<h4>Parameters</h4>
<details class="info" open="open"><summary>n_components : int, default=None</summary><p>Number of components. If None, all non-zero components are kept.</p>
</details>
<details class="info" open="open"><summary>kernel : "linear" | "poly" | "rbf" | "sigmoid" | "cosine" | "precomputed"</summary><p>Kernel. Default="linear".</p>
</details>
<details class="info" open="open"><summary>gamma : float, default=1/n_features</summary><p>Kernel coefficient for rbf, poly and sigmoid kernels. Ignored by other
kernels.</p>
</details>
<details class="info" open="open"><summary>degree : int, default=3</summary><p>Degree for poly kernels. Ignored by other kernels.</p>
</details>
<details class="info" open="open"><summary>coef0 : float, default=1</summary><p>Independent term in poly and sigmoid kernels.
Ignored by other kernels.</p>
</details>
<details class="info" open="open"><summary>kernel_params : mapping of string to any, default=None</summary><p>Parameters (keyword arguments) and values for kernel passed as
callable object. Ignored by other kernels.</p>
</details>
<details class="info" open="open"><summary>alpha : int, default=1.0</summary><p>Hyperparameter of the ridge regression that learns the
inverse transform (when fit_inverse_transform=True).</p>
</details>
<details class="info" open="open"><summary>fit_inverse_transform : bool, default=False</summary><p>Learn the inverse transform for non-precomputed kernels.
(i.e. learn to find the pre-image of a point)</p>
</details>
<details class="info" open="open"><summary>eigen_solver : string ['auto'|'dense'|'arpack'], default='auto'</summary><p>Select eigensolver to use. If n_components is much less than
the number of training samples, arpack may be more efficient
than the dense eigensolver.</p>
</details>
<details class="info" open="open"><summary>tol : float, default=0</summary><p>Convergence tolerance for arpack.
If 0, optimal value will be chosen by arpack.</p>
</details>
<details class="info" open="open"><summary>max_iter : int, default=None</summary><p>Maximum number of iterations for arpack.
If None, optimal value will be chosen by arpack.</p>
</details>
<details class="info" open="open"><summary>remove_zero_eig : boolean, default=False</summary><p>If True, then all components with zero eigenvalues are removed, so
that the number of components in the output may be &lt; n_components
(and sometimes even zero due to numerical instability).
When n_components is None, this parameter is ignored and components
with zero eigenvalues are removed regardless.</p>
</details>
<details class="info" open="open"><summary>random_state : int, RandomState instance or None, optional (default=None)</summary><p>If int, random_state is the seed used by the random number generator;
If RandomState instance, random_state is the random number generator;
If None, the random number generator is the RandomState instance used
by <code>np.random</code>. Used when <code>eigen_solver</code> == 'arpack'.</p>
<p>.. versionadded:: 0.18</p>
</details>
<details class="info" open="open"><summary>copy_X : boolean, default=True</summary><p>If True, input X is copied and stored by the model in the <code>X_fit_</code>
attribute. If no further changes will be done to X, setting
<code>copy_X=False</code> saves memory by storing a reference.</p>
<p>.. versionadded:: 0.18</p>
</details>
<details class="info" open="open"><summary>n_jobs : int or None, optional (default=None)</summary><p>The number of parallel jobs to run.
<code>None</code> means 1 unless in a :obj:<code>joblib.parallel_backend</code> context.
<code>-1</code> means using all processors. See :term:<code>Glossary &lt;n_jobs&gt;</code>
for more details.</p>
<p>.. versionadded:: 0.18</p>
</details>
<h4>Attributes</h4>
<details class="info" open="open"><summary>lambdas_ : array, (n_components,)</summary><p>Eigenvalues of the centered kernel matrix in decreasing order.
If <code>n_components</code> and <code>remove_zero_eig</code> are not set,
then all values are stored.</p>
</details>
<details class="info" open="open"><summary>alphas_ : array, (n_samples, n_components)</summary><p>Eigenvectors of the centered kernel matrix. If <code>n_components</code> and
<code>remove_zero_eig</code> are not set, then all components are stored.</p>
</details>
<details class="info" open="open"><summary>dual_coef_ : array, (n_samples, n_features)</summary><p>Inverse transform matrix. Only available when
<code>fit_inverse_transform</code> is True.</p>
</details>
<details class="info" open="open"><summary>X_transformed_fit_ : array, (n_samples, n_components)</summary><p>Projection of the fitted data on the kernel principal components.
Only available when <code>fit_inverse_transform</code> is True.</p>
</details>
<details class="info" open="open"><summary>X_fit_ : (n_samples, n_features)</summary><p>The data used to fit the model. If <code>copy_X=False</code>, then <code>X_fit_</code> is
a reference. This attribute is used for the calls to transform.</p>
</details>
<h4>Examples</h4>
<div class="highlight"><pre><span></span><code><span class="o">&gt;&gt;&gt;</span> <span class="kn">from</span> <span class="nn">sklearn.datasets</span> <span class="kn">import</span> <span class="n">load_digits</span>
<span class="o">&gt;&gt;&gt;</span> <span class="kn">from</span> <span class="nn">sklearn.decomposition</span> <span class="kn">import</span> <span class="n">KernelPCA</span>
<span class="o">&gt;&gt;&gt;</span> <span class="n">X</span><span class="p">,</span> <span class="n">_</span> <span class="o">=</span> <span class="n">load_digits</span><span class="p">(</span><span class="n">return_X_y</span><span class="o">=</span><span class="kc">True</span><span class="p">)</span>
<span class="o">&gt;&gt;&gt;</span> <span class="n">transformer</span> <span class="o">=</span> <span class="n">KernelPCA</span><span class="p">(</span><span class="n">n_components</span><span class="o">=</span><span class="mi">7</span><span class="p">,</span> <span class="n">kernel</span><span class="o">=</span><span class="s1">&#39;linear&#39;</span><span class="p">)</span>
<span class="o">&gt;&gt;&gt;</span> <span class="n">X_transformed</span> <span class="o">=</span> <span class="n">transformer</span><span class="o">.</span><span class="n">fit_transform</span><span class="p">(</span><span class="n">X</span><span class="p">)</span>
<span class="o">&gt;&gt;&gt;</span> <span class="n">X_transformed</span><span class="o">.</span><span class="n">shape</span>
<span class="p">(</span><span class="mi">1797</span><span class="p">,</span> <span class="mi">7</span><span class="p">)</span>
</code></pre></div>

<h4>References</h4>
<p>Kernel PCA was introduced in:
    Bernhard Schoelkopf, Alexander J. Smola,
    and Klaus-Robert Mueller. 1999. Kernel principal
    component analysis. In Advances in kernel methods,
    MIT Press, Cambridge, MA, USA 327-352.</p>
</details>
<h3 id="fit_4">fit<a class="headerlink" href="#fit_4" title="Permanent link">&para;</a></h3>
<details class="note" open="open"><summary>method</summary><div class="highlight"><pre><span></span><code><span class="k">val</span> <span class="n">fit</span> <span class="o">:</span>
  <span class="o">?</span><span class="n">y</span><span class="o">:</span><span class="nn">Py</span><span class="p">.</span><span class="nn">Object</span><span class="p">.</span><span class="n">t</span> <span class="o">-&gt;</span>
  <span class="n">x</span><span class="o">:</span><span class="nn">Ndarray</span><span class="p">.</span><span class="n">t</span> <span class="o">-&gt;</span>
  <span class="n">t</span> <span class="o">-&gt;</span>
  <span class="n">t</span>
</code></pre></div>

<p>Fit the model from data in X.</p>
<h4>Parameters</h4>
<details class="info" open="open"><summary>X : array-like, shape (n_samples, n_features)</summary><p>Training vector, where n_samples in the number of samples
and n_features is the number of features.</p>
</details>
<h4>Returns</h4>
<details class="info" open="open"><summary>self : object</summary><p>Returns the instance itself.</p>
</details>
</details>
<h3 id="fit_transform_4">fit_transform<a class="headerlink" href="#fit_transform_4" title="Permanent link">&para;</a></h3>
<details class="note" open="open"><summary>method</summary><div class="highlight"><pre><span></span><code><span class="k">val</span> <span class="n">fit_transform</span> <span class="o">:</span>
  <span class="o">?</span><span class="n">y</span><span class="o">:</span><span class="nn">Py</span><span class="p">.</span><span class="nn">Object</span><span class="p">.</span><span class="n">t</span> <span class="o">-&gt;</span>
  <span class="o">?</span><span class="n">params</span><span class="o">:(</span><span class="kt">string</span> <span class="o">*</span> <span class="nn">Py</span><span class="p">.</span><span class="nn">Object</span><span class="p">.</span><span class="n">t</span><span class="o">)</span> <span class="kt">list</span> <span class="o">-&gt;</span>
  <span class="n">x</span><span class="o">:</span><span class="nn">Ndarray</span><span class="p">.</span><span class="n">t</span> <span class="o">-&gt;</span>
  <span class="n">t</span> <span class="o">-&gt;</span>
  <span class="nn">Ndarray</span><span class="p">.</span><span class="n">t</span>
</code></pre></div>

<p>Fit the model from data in X and transform X.</p>
<h4>Parameters</h4>
<details class="info" open="open"><summary>X : array-like, shape (n_samples, n_features)</summary><p>Training vector, where n_samples in the number of samples
and n_features is the number of features.</p>
</details>
<h4>Returns</h4>
<details class="info" open="open"><summary>X_new : array-like, shape (n_samples, n_components)</summary></details>
</details>
<h3 id="get_params_4">get_params<a class="headerlink" href="#get_params_4" title="Permanent link">&para;</a></h3>
<details class="note" open="open"><summary>method</summary><div class="highlight"><pre><span></span><code><span class="k">val</span> <span class="n">get_params</span> <span class="o">:</span>
  <span class="o">?</span><span class="n">deep</span><span class="o">:</span><span class="kt">bool</span> <span class="o">-&gt;</span>
  <span class="n">t</span> <span class="o">-&gt;</span>
  <span class="nn">Py</span><span class="p">.</span><span class="nn">Object</span><span class="p">.</span><span class="n">t</span>
</code></pre></div>

<p>Get parameters for this estimator.</p>
<h4>Parameters</h4>
<details class="info" open="open"><summary>deep : bool, default=True</summary><p>If True, will return the parameters for this estimator and
contained subobjects that are estimators.</p>
</details>
<h4>Returns</h4>
<details class="info" open="open"><summary>params : mapping of string to any</summary><p>Parameter names mapped to their values.</p>
</details>
</details>
<h3 id="inverse_transform_2">inverse_transform<a class="headerlink" href="#inverse_transform_2" title="Permanent link">&para;</a></h3>
<details class="note" open="open"><summary>method</summary><div class="highlight"><pre><span></span><code><span class="k">val</span> <span class="n">inverse_transform</span> <span class="o">:</span>
  <span class="n">x</span><span class="o">:</span><span class="nn">Ndarray</span><span class="p">.</span><span class="n">t</span> <span class="o">-&gt;</span>
  <span class="n">t</span> <span class="o">-&gt;</span>
  <span class="nn">Ndarray</span><span class="p">.</span><span class="n">t</span>
</code></pre></div>

<p>Transform X back to original space.</p>
<h4>Parameters</h4>
<details class="info" open="open"><summary>X : array-like, shape (n_samples, n_components)</summary></details>
<h4>Returns</h4>
<details class="info" open="open"><summary>X_new : array-like, shape (n_samples, n_features)</summary></details>
<h4>References</h4>
<p>"Learning to Find Pre-Images", G BakIr et al, 2004.</p>
</details>
<h3 id="set_params_4">set_params<a class="headerlink" href="#set_params_4" title="Permanent link">&para;</a></h3>
<details class="note" open="open"><summary>method</summary><div class="highlight"><pre><span></span><code><span class="k">val</span> <span class="n">set_params</span> <span class="o">:</span>
  <span class="o">?</span><span class="n">params</span><span class="o">:(</span><span class="kt">string</span> <span class="o">*</span> <span class="nn">Py</span><span class="p">.</span><span class="nn">Object</span><span class="p">.</span><span class="n">t</span><span class="o">)</span> <span class="kt">list</span> <span class="o">-&gt;</span>
  <span class="n">t</span> <span class="o">-&gt;</span>
  <span class="n">t</span>
</code></pre></div>

<p>Set the parameters of this estimator.</p>
<p>The method works on simple estimators as well as on nested objects
(such as pipelines). The latter have parameters of the form
<code>&lt;component&gt;__&lt;parameter&gt;</code> so that it's possible to update each
component of a nested object.</p>
<h4>Parameters</h4>
<details class="info" open="open"><summary>**params : dict</summary><p>Estimator parameters.</p>
</details>
<h4>Returns</h4>
<details class="info" open="open"><summary>self : object</summary><p>Estimator instance.</p>
</details>
</details>
<h3 id="transform_4">transform<a class="headerlink" href="#transform_4" title="Permanent link">&para;</a></h3>
<details class="note" open="open"><summary>method</summary><div class="highlight"><pre><span></span><code><span class="k">val</span> <span class="n">transform</span> <span class="o">:</span>
  <span class="n">x</span><span class="o">:</span><span class="nn">Ndarray</span><span class="p">.</span><span class="n">t</span> <span class="o">-&gt;</span>
  <span class="n">t</span> <span class="o">-&gt;</span>
  <span class="nn">Ndarray</span><span class="p">.</span><span class="n">t</span>
</code></pre></div>

<p>Transform X.</p>
<h4>Parameters</h4>
<details class="info" open="open"><summary>X : array-like, shape (n_samples, n_features)</summary></details>
<h4>Returns</h4>
<details class="info" open="open"><summary>X_new : array-like, shape (n_samples, n_components)</summary></details>
</details>
<h3 id="lambdas_">lambdas_<a class="headerlink" href="#lambdas_" title="Permanent link">&para;</a></h3>
<details class="note" open="open"><summary>attribute</summary><div class="highlight"><pre><span></span><code><span class="k">val</span> <span class="n">lambdas_</span> <span class="o">:</span> <span class="n">t</span> <span class="o">-&gt;</span> <span class="nn">Py</span><span class="p">.</span><span class="nn">Object</span><span class="p">.</span><span class="n">t</span>
</code></pre></div>

<p>This attribute is documented in <code>create</code> above.</p>
</details>
<h3 id="alphas_">alphas_<a class="headerlink" href="#alphas_" title="Permanent link">&para;</a></h3>
<details class="note" open="open"><summary>attribute</summary><div class="highlight"><pre><span></span><code><span class="k">val</span> <span class="n">alphas_</span> <span class="o">:</span> <span class="n">t</span> <span class="o">-&gt;</span> <span class="nn">Py</span><span class="p">.</span><span class="nn">Object</span><span class="p">.</span><span class="n">t</span>
</code></pre></div>

<p>This attribute is documented in <code>create</code> above.</p>
</details>
<h3 id="dual_coef_">dual_coef_<a class="headerlink" href="#dual_coef_" title="Permanent link">&para;</a></h3>
<details class="note" open="open"><summary>attribute</summary><div class="highlight"><pre><span></span><code><span class="k">val</span> <span class="n">dual_coef_</span> <span class="o">:</span> <span class="n">t</span> <span class="o">-&gt;</span> <span class="nn">Py</span><span class="p">.</span><span class="nn">Object</span><span class="p">.</span><span class="n">t</span>
</code></pre></div>

<p>This attribute is documented in <code>create</code> above.</p>
</details>
<h3 id="x_transformed_fit_">x_transformed_fit_<a class="headerlink" href="#x_transformed_fit_" title="Permanent link">&para;</a></h3>
<details class="note" open="open"><summary>attribute</summary><div class="highlight"><pre><span></span><code><span class="k">val</span> <span class="n">x_transformed_fit_</span> <span class="o">:</span> <span class="n">t</span> <span class="o">-&gt;</span> <span class="nn">Py</span><span class="p">.</span><span class="nn">Object</span><span class="p">.</span><span class="n">t</span>
</code></pre></div>

<p>This attribute is documented in <code>create</code> above.</p>
</details>
<h3 id="x_fit_">x_fit_<a class="headerlink" href="#x_fit_" title="Permanent link">&para;</a></h3>
<details class="note" open="open"><summary>attribute</summary><div class="highlight"><pre><span></span><code><span class="k">val</span> <span class="n">x_fit_</span> <span class="o">:</span> <span class="n">t</span> <span class="o">-&gt;</span> <span class="nn">Py</span><span class="p">.</span><span class="nn">Object</span><span class="p">.</span><span class="n">t</span>
</code></pre></div>

<p>This attribute is documented in <code>create</code> above.</p>
</details>
<h3 id="to_string_4">to_string<a class="headerlink" href="#to_string_4" title="Permanent link">&para;</a></h3>
<details class="note" open="open"><summary>method</summary><div class="highlight"><pre><span></span><code><span class="k">val</span> <span class="n">to_string</span><span class="o">:</span> <span class="n">t</span> <span class="o">-&gt;</span> <span class="kt">string</span>
</code></pre></div>

<p>Print the object to a human-readable representation.</p>
</details>
<h3 id="show_4">show<a class="headerlink" href="#show_4" title="Permanent link">&para;</a></h3>
<details class="note" open="open"><summary>method</summary><div class="highlight"><pre><span></span><code><span class="k">val</span> <span class="n">show</span><span class="o">:</span> <span class="n">t</span> <span class="o">-&gt;</span> <span class="kt">string</span>
</code></pre></div>

<p>Print the object to a human-readable representation.</p>
</details>
<h3 id="pp_4">pp<a class="headerlink" href="#pp_4" title="Permanent link">&para;</a></h3>
<details class="note" open="open"><summary>method</summary><div class="highlight"><pre><span></span><code><span class="k">val</span> <span class="n">pp</span><span class="o">:</span> <span class="nn">Format</span><span class="p">.</span><span class="n">formatter</span> <span class="o">-&gt;</span> <span class="n">t</span> <span class="o">-&gt;</span> <span class="kt">unit</span>
</code></pre></div>

<p>Pretty-print the object to a formatter.</p>
</details>
<h2 id="module-sklearndecompositionlatentdirichletallocation">module Sklearn.​Decomposition.​LatentDirichletAllocation<a class="headerlink" href="#module-sklearndecompositionlatentdirichletallocation" title="Permanent link">&para;</a></h2>
<div class="highlight"><pre><span></span><code><span class="k">type</span> <span class="n">t</span>
</code></pre></div>

<h3 id="create_5">create<a class="headerlink" href="#create_5" title="Permanent link">&para;</a></h3>
<details class="note" open="open"><summary>constructor and attributes</summary><div class="highlight"><pre><span></span><code><span class="k">val</span> <span class="n">create</span> <span class="o">:</span>
  <span class="o">?</span><span class="n">n_components</span><span class="o">:</span><span class="kt">int</span> <span class="o">-&gt;</span>
  <span class="o">?</span><span class="n">doc_topic_prior</span><span class="o">:</span><span class="kt">float</span> <span class="o">-&gt;</span>
  <span class="o">?</span><span class="n">topic_word_prior</span><span class="o">:</span><span class="kt">float</span> <span class="o">-&gt;</span>
  <span class="o">?</span><span class="n">learning_method</span><span class="o">:[`</span><span class="nc">Batch</span> <span class="o">|</span> <span class="o">`</span><span class="nc">Online</span><span class="o">]</span> <span class="o">-&gt;</span>
  <span class="o">?</span><span class="n">learning_decay</span><span class="o">:</span><span class="kt">float</span> <span class="o">-&gt;</span>
  <span class="o">?</span><span class="n">learning_offset</span><span class="o">:</span><span class="kt">float</span> <span class="o">-&gt;</span>
  <span class="o">?</span><span class="n">max_iter</span><span class="o">:</span><span class="kt">int</span> <span class="o">-&gt;</span>
  <span class="o">?</span><span class="n">batch_size</span><span class="o">:</span><span class="kt">int</span> <span class="o">-&gt;</span>
  <span class="o">?</span><span class="n">evaluate_every</span><span class="o">:</span><span class="kt">int</span> <span class="o">-&gt;</span>
  <span class="o">?</span><span class="n">total_samples</span><span class="o">:</span><span class="kt">int</span> <span class="o">-&gt;</span>
  <span class="o">?</span><span class="n">perp_tol</span><span class="o">:</span><span class="kt">float</span> <span class="o">-&gt;</span>
  <span class="o">?</span><span class="n">mean_change_tol</span><span class="o">:</span><span class="kt">float</span> <span class="o">-&gt;</span>
  <span class="o">?</span><span class="n">max_doc_update_iter</span><span class="o">:</span><span class="kt">int</span> <span class="o">-&gt;</span>
  <span class="o">?</span><span class="n">n_jobs</span><span class="o">:[`</span><span class="nc">Int</span> <span class="k">of</span> <span class="kt">int</span> <span class="o">|</span> <span class="o">`</span><span class="nc">None</span><span class="o">]</span> <span class="o">-&gt;</span>
  <span class="o">?</span><span class="n">verbose</span><span class="o">:</span><span class="kt">int</span> <span class="o">-&gt;</span>
  <span class="o">?</span><span class="n">random_state</span><span class="o">:[`</span><span class="nc">Int</span> <span class="k">of</span> <span class="kt">int</span> <span class="o">|</span> <span class="o">`</span><span class="nc">RandomState</span> <span class="k">of</span> <span class="nn">Py</span><span class="p">.</span><span class="nn">Object</span><span class="p">.</span><span class="n">t</span> <span class="o">|</span> <span class="o">`</span><span class="nc">None</span><span class="o">]</span> <span class="o">-&gt;</span>
  <span class="kt">unit</span> <span class="o">-&gt;</span>
  <span class="n">t</span>
</code></pre></div>

<p>Latent Dirichlet Allocation with online variational Bayes algorithm</p>
<p>.. versionadded:: 0.17</p>
<p>Read more in the :ref:<code>User Guide &lt;LatentDirichletAllocation&gt;</code>.</p>
<h4>Parameters</h4>
<details class="info" open="open"><summary>n_components : int, optional (default=10)</summary><p>Number of topics.</p>
</details>
<details class="info" open="open"><summary>doc_topic_prior : float, optional (default=None)</summary><p>Prior of document topic distribution <code>theta</code>. If the value is None,
defaults to <code>1 / n_components</code>.
In [1]_, this is called <code>alpha</code>.</p>
</details>
<details class="info" open="open"><summary>topic_word_prior : float, optional (default=None)</summary><p>Prior of topic word distribution <code>beta</code>. If the value is None, defaults
to <code>1 / n_components</code>.
In [1]_, this is called <code>eta</code>.</p>
</details>
<details class="info" open="open"><summary>learning_method : 'batch' | 'online', default='batch'</summary><p>Method used to update <code>_component</code>. Only used in :meth:<code>fit</code> method.
In general, if the data size is large, the online update will be much
faster than the batch update.</p>
<p>Valid options::</p>
<div class="codehilite"><pre><span></span><code>&#39;batch&#39;: Batch variational Bayes method. Use all training data in
    each EM update.
    Old `components_` will be overwritten in each iteration.
&#39;online&#39;: Online variational Bayes method. In each EM update, use
    mini-batch of training data to update the ``components_``
    variable incrementally. The learning rate is controlled by the
    ``learning_decay`` and the ``learning_offset`` parameters.
</code></pre></div>


<p>.. versionchanged:: 0.20
    The default learning method is now <code>"batch"</code>.</p>
</details>
<details class="info" open="open"><summary>learning_decay : float, optional (default=0.7)</summary><p>It is a parameter that control learning rate in the online learning
method. The value should be set between (0.5, 1.0] to guarantee
asymptotic convergence. When the value is 0.0 and batch_size is
<code>n_samples</code>, the update method is same as batch learning. In the
literature, this is called kappa.</p>
</details>
<details class="info" open="open"><summary>learning_offset : float, optional (default=10.)</summary><p>A (positive) parameter that downweights early iterations in online
learning.  It should be greater than 1.0. In the literature, this is
called tau_0.</p>
</details>
<details class="info" open="open"><summary>max_iter : integer, optional (default=10)</summary><p>The maximum number of iterations.</p>
</details>
<details class="info" open="open"><summary>batch_size : int, optional (default=128)</summary><p>Number of documents to use in each EM iteration. Only used in online
learning.</p>
</details>
<details class="info" open="open"><summary>evaluate_every : int, optional (default=0)</summary><p>How often to evaluate perplexity. Only used in <code>fit</code> method.
set it to 0 or negative number to not evaluate perplexity in
training at all. Evaluating perplexity can help you check convergence
in training process, but it will also increase total training time.
Evaluating perplexity in every iteration might increase training time
up to two-fold.</p>
</details>
<details class="info" open="open"><summary>total_samples : int, optional (default=1e6)</summary><p>Total number of documents. Only used in the :meth:<code>partial_fit</code> method.</p>
</details>
<details class="info" open="open"><summary>perp_tol : float, optional (default=1e-1)</summary><p>Perplexity tolerance in batch learning. Only used when
<code>evaluate_every</code> is greater than 0.</p>
</details>
<details class="info" open="open"><summary>mean_change_tol : float, optional (default=1e-3)</summary><p>Stopping tolerance for updating document topic distribution in E-step.</p>
</details>
<details class="info" open="open"><summary>max_doc_update_iter : int (default=100)</summary><p>Max number of iterations for updating document topic distribution in
the E-step.</p>
</details>
<details class="info" open="open"><summary>n_jobs : int or None, optional (default=None)</summary><p>The number of jobs to use in the E-step.
<code>None</code> means 1 unless in a :obj:<code>joblib.parallel_backend</code> context.
<code>-1</code> means using all processors. See :term:<code>Glossary &lt;n_jobs&gt;</code>
for more details.</p>
</details>
<details class="info" open="open"><summary>verbose : int, optional (default=0)</summary><p>Verbosity level.</p>
</details>
<details class="info" open="open"><summary>random_state : int, RandomState instance or None, optional (default=None)</summary><p>If int, random_state is the seed used by the random number generator;
If RandomState instance, random_state is the random number generator;
If None, the random number generator is the RandomState instance used
by <code>np.random</code>.</p>
</details>
<h4>Attributes</h4>
<details class="info" open="open"><summary>components_ : array, [n_components, n_features]</summary><p>Variational parameters for topic word distribution. Since the complete
conditional for topic word distribution is a Dirichlet,
<code>components_[i, j]</code> can be viewed as pseudocount that represents the
number of times word <code>j</code> was assigned to topic <code>i</code>.
It can also be viewed as distribution over the words for each topic
after normalization:
<code>model.components_ / model.components_.sum(axis=1)[:, np.newaxis]</code>.</p>
</details>
<details class="info" open="open"><summary>n_batch_iter_ : int</summary><p>Number of iterations of the EM step.</p>
</details>
<details class="info" open="open"><summary>n_iter_ : int</summary><p>Number of passes over the dataset.</p>
</details>
<details class="info" open="open"><summary>bound_ : float</summary><p>Final perplexity score on training set.</p>
</details>
<details class="info" open="open"><summary>doc_topic_prior_ : float</summary><p>Prior of document topic distribution <code>theta</code>. If the value is None,
it is <code>1 / n_components</code>.</p>
</details>
<details class="info" open="open"><summary>topic_word_prior_ : float</summary><p>Prior of topic word distribution <code>beta</code>. If the value is None, it is
<code>1 / n_components</code>.</p>
</details>
<h4>Examples</h4>
<div class="highlight"><pre><span></span><code><span class="o">&gt;&gt;&gt;</span> <span class="kn">from</span> <span class="nn">sklearn.decomposition</span> <span class="kn">import</span> <span class="n">LatentDirichletAllocation</span>
<span class="o">&gt;&gt;&gt;</span> <span class="kn">from</span> <span class="nn">sklearn.datasets</span> <span class="kn">import</span> <span class="n">make_multilabel_classification</span>
<span class="o">&gt;&gt;&gt;</span> <span class="c1"># This produces a feature matrix of token counts, similar to what</span>
<span class="o">&gt;&gt;&gt;</span> <span class="c1"># CountVectorizer would produce on text.</span>
<span class="o">&gt;&gt;&gt;</span> <span class="n">X</span><span class="p">,</span> <span class="n">_</span> <span class="o">=</span> <span class="n">make_multilabel_classification</span><span class="p">(</span><span class="n">random_state</span><span class="o">=</span><span class="mi">0</span><span class="p">)</span>
<span class="o">&gt;&gt;&gt;</span> <span class="n">lda</span> <span class="o">=</span> <span class="n">LatentDirichletAllocation</span><span class="p">(</span><span class="n">n_components</span><span class="o">=</span><span class="mi">5</span><span class="p">,</span>
<span class="o">...</span>     <span class="n">random_state</span><span class="o">=</span><span class="mi">0</span><span class="p">)</span>
<span class="o">&gt;&gt;&gt;</span> <span class="n">lda</span><span class="o">.</span><span class="n">fit</span><span class="p">(</span><span class="n">X</span><span class="p">)</span>
<span class="n">LatentDirichletAllocation</span><span class="p">(</span><span class="o">...</span><span class="p">)</span>
<span class="o">&gt;&gt;&gt;</span> <span class="c1"># get topics for some given samples:</span>
<span class="o">&gt;&gt;&gt;</span> <span class="n">lda</span><span class="o">.</span><span class="n">transform</span><span class="p">(</span><span class="n">X</span><span class="p">[</span><span class="o">-</span><span class="mi">2</span><span class="p">:])</span>
<span class="n">array</span><span class="p">([[</span><span class="mf">0.00360392</span><span class="p">,</span> <span class="mf">0.25499205</span><span class="p">,</span> <span class="mf">0.0036211</span> <span class="p">,</span> <span class="mf">0.64236448</span><span class="p">,</span> <span class="mf">0.09541846</span><span class="p">],</span>
       <span class="p">[</span><span class="mf">0.15297572</span><span class="p">,</span> <span class="mf">0.00362644</span><span class="p">,</span> <span class="mf">0.44412786</span><span class="p">,</span> <span class="mf">0.39568399</span><span class="p">,</span> <span class="mf">0.003586</span>  <span class="p">]])</span>
</code></pre></div>

<h4>References</h4>
<p>.. [1] "Online Learning for Latent Dirichlet Allocation", Matthew D.
    Hoffman, David M. Blei, Francis Bach, 2010</p>
<p>[2] "Stochastic Variational Inference", Matthew D. Hoffman, David M. Blei,
    Chong Wang, John Paisley, 2013</p>
<p>[3] Matthew D. Hoffman's onlineldavb code. Link:</p>
<details class="info" open="open"><summary>https://github.com/blei-lab/onlineldavb</summary></details>
</details>
<h3 id="fit_5">fit<a class="headerlink" href="#fit_5" title="Permanent link">&para;</a></h3>
<details class="note" open="open"><summary>method</summary><div class="highlight"><pre><span></span><code><span class="k">val</span> <span class="n">fit</span> <span class="o">:</span>
  <span class="o">?</span><span class="n">y</span><span class="o">:</span><span class="nn">Py</span><span class="p">.</span><span class="nn">Object</span><span class="p">.</span><span class="n">t</span> <span class="o">-&gt;</span>
  <span class="n">x</span><span class="o">:[`</span><span class="nc">Ndarray</span> <span class="k">of</span> <span class="nn">Ndarray</span><span class="p">.</span><span class="n">t</span> <span class="o">|</span> <span class="o">`</span><span class="nc">SparseMatrix</span> <span class="k">of</span> <span class="nn">Csr_matrix</span><span class="p">.</span><span class="n">t</span><span class="o">]</span> <span class="o">-&gt;</span>
  <span class="n">t</span> <span class="o">-&gt;</span>
  <span class="n">t</span>
</code></pre></div>

<p>Learn model for the data X with variational Bayes method.</p>
<p>When <code>learning_method</code> is 'online', use mini-batch update.
Otherwise, use batch update.</p>
<h4>Parameters</h4>
<details class="info" open="open"><summary>X : array-like or sparse matrix, shape=(n_samples, n_features)</summary><p>Document word matrix.</p>
</details>
<details class="info" open="open"><summary>y : Ignored</summary></details>
<h4>Returns</h4>
<p>self</p>
</details>
<h3 id="fit_transform_5">fit_transform<a class="headerlink" href="#fit_transform_5" title="Permanent link">&para;</a></h3>
<details class="note" open="open"><summary>method</summary><div class="highlight"><pre><span></span><code><span class="k">val</span> <span class="n">fit_transform</span> <span class="o">:</span>
  <span class="o">?</span><span class="n">y</span><span class="o">:</span><span class="nn">Ndarray</span><span class="p">.</span><span class="n">t</span> <span class="o">-&gt;</span>
  <span class="o">?</span><span class="n">fit_params</span><span class="o">:(</span><span class="kt">string</span> <span class="o">*</span> <span class="nn">Py</span><span class="p">.</span><span class="nn">Object</span><span class="p">.</span><span class="n">t</span><span class="o">)</span> <span class="kt">list</span> <span class="o">-&gt;</span>
  <span class="n">x</span><span class="o">:</span><span class="nn">Ndarray</span><span class="p">.</span><span class="n">t</span> <span class="o">-&gt;</span>
  <span class="n">t</span> <span class="o">-&gt;</span>
  <span class="nn">Ndarray</span><span class="p">.</span><span class="n">t</span>
</code></pre></div>

<p>Fit to data, then transform it.</p>
<p>Fits transformer to X and y with optional parameters fit_params
and returns a transformed version of X.</p>
<h4>Parameters</h4>
<details class="info" open="open"><summary>X : numpy array of shape [n_samples, n_features]</summary><p>Training set.</p>
</details>
<details class="info" open="open"><summary>y : numpy array of shape [n_samples]</summary><p>Target values.</p>
</details>
<details class="info" open="open"><summary>**fit_params : dict</summary><p>Additional fit parameters.</p>
</details>
<h4>Returns</h4>
<details class="info" open="open"><summary>X_new : numpy array of shape [n_samples, n_features_new]</summary><p>Transformed array.</p>
</details>
</details>
<h3 id="get_params_5">get_params<a class="headerlink" href="#get_params_5" title="Permanent link">&para;</a></h3>
<details class="note" open="open"><summary>method</summary><div class="highlight"><pre><span></span><code><span class="k">val</span> <span class="n">get_params</span> <span class="o">:</span>
  <span class="o">?</span><span class="n">deep</span><span class="o">:</span><span class="kt">bool</span> <span class="o">-&gt;</span>
  <span class="n">t</span> <span class="o">-&gt;</span>
  <span class="nn">Py</span><span class="p">.</span><span class="nn">Object</span><span class="p">.</span><span class="n">t</span>
</code></pre></div>

<p>Get parameters for this estimator.</p>
<h4>Parameters</h4>
<details class="info" open="open"><summary>deep : bool, default=True</summary><p>If True, will return the parameters for this estimator and
contained subobjects that are estimators.</p>
</details>
<h4>Returns</h4>
<details class="info" open="open"><summary>params : mapping of string to any</summary><p>Parameter names mapped to their values.</p>
</details>
</details>
<h3 id="partial_fit_1">partial_fit<a class="headerlink" href="#partial_fit_1" title="Permanent link">&para;</a></h3>
<details class="note" open="open"><summary>method</summary><div class="highlight"><pre><span></span><code><span class="k">val</span> <span class="n">partial_fit</span> <span class="o">:</span>
  <span class="o">?</span><span class="n">y</span><span class="o">:</span><span class="nn">Py</span><span class="p">.</span><span class="nn">Object</span><span class="p">.</span><span class="n">t</span> <span class="o">-&gt;</span>
  <span class="n">x</span><span class="o">:[`</span><span class="nc">Ndarray</span> <span class="k">of</span> <span class="nn">Ndarray</span><span class="p">.</span><span class="n">t</span> <span class="o">|</span> <span class="o">`</span><span class="nc">SparseMatrix</span> <span class="k">of</span> <span class="nn">Csr_matrix</span><span class="p">.</span><span class="n">t</span><span class="o">]</span> <span class="o">-&gt;</span>
  <span class="n">t</span> <span class="o">-&gt;</span>
  <span class="nn">Py</span><span class="p">.</span><span class="nn">Object</span><span class="p">.</span><span class="n">t</span>
</code></pre></div>

<p>Online VB with Mini-Batch update.</p>
<h4>Parameters</h4>
<details class="info" open="open"><summary>X : array-like or sparse matrix, shape=(n_samples, n_features)</summary><p>Document word matrix.</p>
</details>
<details class="info" open="open"><summary>y : Ignored</summary></details>
<h4>Returns</h4>
<p>self</p>
</details>
<h3 id="perplexity">perplexity<a class="headerlink" href="#perplexity" title="Permanent link">&para;</a></h3>
<details class="note" open="open"><summary>method</summary><div class="highlight"><pre><span></span><code><span class="k">val</span> <span class="n">perplexity</span> <span class="o">:</span>
  <span class="o">?</span><span class="n">sub_sampling</span><span class="o">:</span><span class="kt">bool</span> <span class="o">-&gt;</span>
  <span class="n">x</span><span class="o">:[`</span><span class="nc">Ndarray</span> <span class="k">of</span> <span class="nn">Ndarray</span><span class="p">.</span><span class="n">t</span> <span class="o">|</span> <span class="o">`</span><span class="nc">SparseMatrix</span> <span class="k">of</span> <span class="nn">Csr_matrix</span><span class="p">.</span><span class="n">t</span><span class="o">]</span> <span class="o">-&gt;</span>
  <span class="n">t</span> <span class="o">-&gt;</span>
  <span class="kt">float</span>
</code></pre></div>

<p>Calculate approximate perplexity for data X.</p>
<p>Perplexity is defined as exp(-1. * log-likelihood per word)</p>
<p>.. versionchanged:: 0.19
   <em>doc_topic_distr</em> argument has been deprecated and is ignored
   because user no longer has access to unnormalized distribution</p>
<h4>Parameters</h4>
<details class="info" open="open"><summary>X : array-like or sparse matrix, [n_samples, n_features]</summary><p>Document word matrix.</p>
</details>
<details class="info" open="open"><summary>sub_sampling : bool</summary><p>Do sub-sampling or not.</p>
</details>
<h4>Returns</h4>
<details class="info" open="open"><summary>score : float</summary><p>Perplexity score.</p>
</details>
</details>
<h3 id="score_1">score<a class="headerlink" href="#score_1" title="Permanent link">&para;</a></h3>
<details class="note" open="open"><summary>method</summary><div class="highlight"><pre><span></span><code><span class="k">val</span> <span class="n">score</span> <span class="o">:</span>
  <span class="o">?</span><span class="n">y</span><span class="o">:</span><span class="nn">Py</span><span class="p">.</span><span class="nn">Object</span><span class="p">.</span><span class="n">t</span> <span class="o">-&gt;</span>
  <span class="n">x</span><span class="o">:[`</span><span class="nc">Ndarray</span> <span class="k">of</span> <span class="nn">Ndarray</span><span class="p">.</span><span class="n">t</span> <span class="o">|</span> <span class="o">`</span><span class="nc">SparseMatrix</span> <span class="k">of</span> <span class="nn">Csr_matrix</span><span class="p">.</span><span class="n">t</span><span class="o">]</span> <span class="o">-&gt;</span>
  <span class="n">t</span> <span class="o">-&gt;</span>
  <span class="kt">float</span>
</code></pre></div>

<p>Calculate approximate log-likelihood as score.</p>
<h4>Parameters</h4>
<details class="info" open="open"><summary>X : array-like or sparse matrix, shape=(n_samples, n_features)</summary><p>Document word matrix.</p>
</details>
<details class="info" open="open"><summary>y : Ignored</summary></details>
<h4>Returns</h4>
<details class="info" open="open"><summary>score : float</summary><p>Use approximate bound as score.</p>
</details>
</details>
<h3 id="set_params_5">set_params<a class="headerlink" href="#set_params_5" title="Permanent link">&para;</a></h3>
<details class="note" open="open"><summary>method</summary><div class="highlight"><pre><span></span><code><span class="k">val</span> <span class="n">set_params</span> <span class="o">:</span>
  <span class="o">?</span><span class="n">params</span><span class="o">:(</span><span class="kt">string</span> <span class="o">*</span> <span class="nn">Py</span><span class="p">.</span><span class="nn">Object</span><span class="p">.</span><span class="n">t</span><span class="o">)</span> <span class="kt">list</span> <span class="o">-&gt;</span>
  <span class="n">t</span> <span class="o">-&gt;</span>
  <span class="n">t</span>
</code></pre></div>

<p>Set the parameters of this estimator.</p>
<p>The method works on simple estimators as well as on nested objects
(such as pipelines). The latter have parameters of the form
<code>&lt;component&gt;__&lt;parameter&gt;</code> so that it's possible to update each
component of a nested object.</p>
<h4>Parameters</h4>
<details class="info" open="open"><summary>**params : dict</summary><p>Estimator parameters.</p>
</details>
<h4>Returns</h4>
<details class="info" open="open"><summary>self : object</summary><p>Estimator instance.</p>
</details>
</details>
<h3 id="transform_5">transform<a class="headerlink" href="#transform_5" title="Permanent link">&para;</a></h3>
<details class="note" open="open"><summary>method</summary><div class="highlight"><pre><span></span><code><span class="k">val</span> <span class="n">transform</span> <span class="o">:</span>
  <span class="n">x</span><span class="o">:[`</span><span class="nc">Ndarray</span> <span class="k">of</span> <span class="nn">Ndarray</span><span class="p">.</span><span class="n">t</span> <span class="o">|</span> <span class="o">`</span><span class="nc">SparseMatrix</span> <span class="k">of</span> <span class="nn">Csr_matrix</span><span class="p">.</span><span class="n">t</span><span class="o">]</span> <span class="o">-&gt;</span>
  <span class="n">t</span> <span class="o">-&gt;</span>
  <span class="nn">Ndarray</span><span class="p">.</span><span class="n">t</span>
</code></pre></div>

<p>Transform data X according to the fitted model.</p>
<p>.. versionchanged:: 0.18
      <em>doc_topic_distr</em> is now normalized</p>
<h4>Parameters</h4>
<details class="info" open="open"><summary>X : array-like or sparse matrix, shape=(n_samples, n_features)</summary><p>Document word matrix.</p>
</details>
<h4>Returns</h4>
<details class="info" open="open"><summary>doc_topic_distr : shape=(n_samples, n_components)</summary><p>Document topic distribution for X.</p>
</details>
</details>
<h3 id="components__4">components_<a class="headerlink" href="#components__4" title="Permanent link">&para;</a></h3>
<details class="note" open="open"><summary>attribute</summary><div class="highlight"><pre><span></span><code><span class="k">val</span> <span class="n">components_</span> <span class="o">:</span> <span class="n">t</span> <span class="o">-&gt;</span> <span class="nn">Ndarray</span><span class="p">.</span><span class="n">t</span>
</code></pre></div>

<p>This attribute is documented in <code>create</code> above.</p>
</details>
<h3 id="n_batch_iter_">n_batch_iter_<a class="headerlink" href="#n_batch_iter_" title="Permanent link">&para;</a></h3>
<details class="note" open="open"><summary>attribute</summary><div class="highlight"><pre><span></span><code><span class="k">val</span> <span class="n">n_batch_iter_</span> <span class="o">:</span> <span class="n">t</span> <span class="o">-&gt;</span> <span class="kt">int</span>
</code></pre></div>

<p>This attribute is documented in <code>create</code> above.</p>
</details>
<h3 id="n_iter__3">n_iter_<a class="headerlink" href="#n_iter__3" title="Permanent link">&para;</a></h3>
<details class="note" open="open"><summary>attribute</summary><div class="highlight"><pre><span></span><code><span class="k">val</span> <span class="n">n_iter_</span> <span class="o">:</span> <span class="n">t</span> <span class="o">-&gt;</span> <span class="kt">int</span>
</code></pre></div>

<p>This attribute is documented in <code>create</code> above.</p>
</details>
<h3 id="bound_">bound_<a class="headerlink" href="#bound_" title="Permanent link">&para;</a></h3>
<details class="note" open="open"><summary>attribute</summary><div class="highlight"><pre><span></span><code><span class="k">val</span> <span class="n">bound_</span> <span class="o">:</span> <span class="n">t</span> <span class="o">-&gt;</span> <span class="kt">float</span>
</code></pre></div>

<p>This attribute is documented in <code>create</code> above.</p>
</details>
<h3 id="doc_topic_prior_">doc_topic_prior_<a class="headerlink" href="#doc_topic_prior_" title="Permanent link">&para;</a></h3>
<details class="note" open="open"><summary>attribute</summary><div class="highlight"><pre><span></span><code><span class="k">val</span> <span class="n">doc_topic_prior_</span> <span class="o">:</span> <span class="n">t</span> <span class="o">-&gt;</span> <span class="kt">float</span>
</code></pre></div>

<p>This attribute is documented in <code>create</code> above.</p>
</details>
<h3 id="topic_word_prior_">topic_word_prior_<a class="headerlink" href="#topic_word_prior_" title="Permanent link">&para;</a></h3>
<details class="note" open="open"><summary>attribute</summary><div class="highlight"><pre><span></span><code><span class="k">val</span> <span class="n">topic_word_prior_</span> <span class="o">:</span> <span class="n">t</span> <span class="o">-&gt;</span> <span class="kt">float</span>
</code></pre></div>

<p>This attribute is documented in <code>create</code> above.</p>
</details>
<h3 id="to_string_5">to_string<a class="headerlink" href="#to_string_5" title="Permanent link">&para;</a></h3>
<details class="note" open="open"><summary>method</summary><div class="highlight"><pre><span></span><code><span class="k">val</span> <span class="n">to_string</span><span class="o">:</span> <span class="n">t</span> <span class="o">-&gt;</span> <span class="kt">string</span>
</code></pre></div>

<p>Print the object to a human-readable representation.</p>
</details>
<h3 id="show_5">show<a class="headerlink" href="#show_5" title="Permanent link">&para;</a></h3>
<details class="note" open="open"><summary>method</summary><div class="highlight"><pre><span></span><code><span class="k">val</span> <span class="n">show</span><span class="o">:</span> <span class="n">t</span> <span class="o">-&gt;</span> <span class="kt">string</span>
</code></pre></div>

<p>Print the object to a human-readable representation.</p>
</details>
<h3 id="pp_5">pp<a class="headerlink" href="#pp_5" title="Permanent link">&para;</a></h3>
<details class="note" open="open"><summary>method</summary><div class="highlight"><pre><span></span><code><span class="k">val</span> <span class="n">pp</span><span class="o">:</span> <span class="nn">Format</span><span class="p">.</span><span class="n">formatter</span> <span class="o">-&gt;</span> <span class="n">t</span> <span class="o">-&gt;</span> <span class="kt">unit</span>
</code></pre></div>

<p>Pretty-print the object to a formatter.</p>
</details>
<h2 id="module-sklearndecompositionminibatchdictionarylearning">module Sklearn.​Decomposition.​MiniBatchDictionaryLearning<a class="headerlink" href="#module-sklearndecompositionminibatchdictionarylearning" title="Permanent link">&para;</a></h2>
<div class="highlight"><pre><span></span><code><span class="k">type</span> <span class="n">t</span>
</code></pre></div>

<h3 id="create_6">create<a class="headerlink" href="#create_6" title="Permanent link">&para;</a></h3>
<details class="note" open="open"><summary>constructor and attributes</summary><div class="highlight"><pre><span></span><code><span class="k">val</span> <span class="n">create</span> <span class="o">:</span>
  <span class="o">?</span><span class="n">n_components</span><span class="o">:</span><span class="kt">int</span> <span class="o">-&gt;</span>
  <span class="o">?</span><span class="n">alpha</span><span class="o">:</span><span class="kt">float</span> <span class="o">-&gt;</span>
  <span class="o">?</span><span class="n">n_iter</span><span class="o">:</span><span class="kt">int</span> <span class="o">-&gt;</span>
  <span class="o">?</span><span class="n">fit_algorithm</span><span class="o">:[`</span><span class="nc">Lars</span> <span class="o">|</span> <span class="o">`</span><span class="nc">Cd</span><span class="o">]</span> <span class="o">-&gt;</span>
  <span class="o">?</span><span class="n">n_jobs</span><span class="o">:[`</span><span class="nc">Int</span> <span class="k">of</span> <span class="kt">int</span> <span class="o">|</span> <span class="o">`</span><span class="nc">None</span><span class="o">]</span> <span class="o">-&gt;</span>
  <span class="o">?</span><span class="n">batch_size</span><span class="o">:</span><span class="kt">int</span> <span class="o">-&gt;</span>
  <span class="o">?</span><span class="n">shuffle</span><span class="o">:</span><span class="kt">bool</span> <span class="o">-&gt;</span>
  <span class="o">?</span><span class="n">dict_init</span><span class="o">:</span><span class="nn">Ndarray</span><span class="p">.</span><span class="n">t</span> <span class="o">-&gt;</span>
  <span class="o">?</span><span class="n">transform_algorithm</span><span class="o">:[`</span><span class="nc">Lasso_lars</span> <span class="o">|</span> <span class="o">`</span><span class="nc">Lasso_cd</span> <span class="o">|</span> <span class="o">`</span><span class="nc">Lars</span> <span class="o">|</span> <span class="o">`</span><span class="nc">Omp</span> <span class="o">|</span> <span class="o">`</span><span class="nc">Threshold</span><span class="o">]</span> <span class="o">-&gt;</span>
  <span class="o">?</span><span class="n">transform_n_nonzero_coefs</span><span class="o">:[`</span><span class="nc">Int</span> <span class="k">of</span> <span class="kt">int</span> <span class="o">|</span> <span class="o">`</span><span class="nc">PyObject</span> <span class="k">of</span> <span class="nn">Py</span><span class="p">.</span><span class="nn">Object</span><span class="p">.</span><span class="n">t</span><span class="o">]</span> <span class="o">-&gt;</span>
  <span class="o">?</span><span class="n">transform_alpha</span><span class="o">:</span><span class="kt">float</span> <span class="o">-&gt;</span>
  <span class="o">?</span><span class="n">verbose</span><span class="o">:</span><span class="kt">bool</span> <span class="o">-&gt;</span>
  <span class="o">?</span><span class="n">split_sign</span><span class="o">:</span><span class="kt">bool</span> <span class="o">-&gt;</span>
  <span class="o">?</span><span class="n">random_state</span><span class="o">:[`</span><span class="nc">Int</span> <span class="k">of</span> <span class="kt">int</span> <span class="o">|</span> <span class="o">`</span><span class="nc">RandomState</span> <span class="k">of</span> <span class="nn">Py</span><span class="p">.</span><span class="nn">Object</span><span class="p">.</span><span class="n">t</span> <span class="o">|</span> <span class="o">`</span><span class="nc">None</span><span class="o">]</span> <span class="o">-&gt;</span>
  <span class="o">?</span><span class="n">positive_code</span><span class="o">:</span><span class="kt">bool</span> <span class="o">-&gt;</span>
  <span class="o">?</span><span class="n">positive_dict</span><span class="o">:</span><span class="kt">bool</span> <span class="o">-&gt;</span>
  <span class="o">?</span><span class="n">transform_max_iter</span><span class="o">:</span><span class="kt">int</span> <span class="o">-&gt;</span>
  <span class="kt">unit</span> <span class="o">-&gt;</span>
  <span class="n">t</span>
</code></pre></div>

<p>Mini-batch dictionary learning</p>
<p>Finds a dictionary (a set of atoms) that can best be used to represent data
using a sparse code.</p>
<p>Solves the optimization problem::</p>
<p>(U^<em>,V^</em> ) = argmin 0.5 || Y - U V ||_2^2 + alpha * || U ||_1
                (U,V)
                with || V_k ||_2 = 1 for all  0 &lt;= k &lt; n_components</p>
<p>Read more in the :ref:<code>User Guide &lt;DictionaryLearning&gt;</code>.</p>
<h4>Parameters</h4>
<details class="info" open="open"><summary>n_components : int,</summary><p>number of dictionary elements to extract</p>
</details>
<details class="info" open="open"><summary>alpha : float,</summary><p>sparsity controlling parameter</p>
</details>
<details class="info" open="open"><summary>n_iter : int,</summary><p>total number of iterations to perform</p>
</details>
<details class="info" open="open"><summary>fit_algorithm : {'lars', 'cd'}</summary></details>
<details class="info" open="open"><summary>lars: uses the least angle regression method to solve the lasso problem</summary><p>(linear_model.lars_path)</p>
</details>
<details class="info" open="open"><summary>cd: uses the coordinate descent method to compute the</summary><p>Lasso solution (linear_model.Lasso). Lars will be faster if
the estimated components are sparse.</p>
</details>
<details class="info" open="open"><summary>n_jobs : int or None, optional (default=None)</summary><p>Number of parallel jobs to run.
<code>None</code> means 1 unless in a :obj:<code>joblib.parallel_backend</code> context.
<code>-1</code> means using all processors. See :term:<code>Glossary &lt;n_jobs&gt;</code>
for more details.</p>
</details>
<details class="info" open="open"><summary>batch_size : int,</summary><p>number of samples in each mini-batch</p>
</details>
<details class="info" open="open"><summary>shuffle : bool,</summary><p>whether to shuffle the samples before forming batches</p>
</details>
<details class="info" open="open"><summary>dict_init : array of shape (n_components, n_features),</summary><p>initial value of the dictionary for warm restart scenarios</p>
</details>
<details class="info" open="open"><summary>transform_algorithm : {'lasso_lars', 'lasso_cd', 'lars', 'omp',     'threshold'}</summary><p>Algorithm used to transform the data.</p>
</details>
<details class="info" open="open"><summary>lars: uses the least angle regression method (linear_model.lars_path)</summary></details>
<details class="info" open="open"><summary>lasso_lars: uses Lars to compute the Lasso solution</summary></details>
<details class="info" open="open"><summary>lasso_cd: uses the coordinate descent method to compute the</summary><p>Lasso solution (linear_model.Lasso). lasso_lars will be faster if
the estimated components are sparse.</p>
</details>
<details class="info" open="open"><summary>omp: uses orthogonal matching pursuit to estimate the sparse solution</summary></details>
<details class="info" open="open"><summary>threshold: squashes to zero all coefficients less than alpha from</summary><p>the projection dictionary * X'</p>
</details>
<details class="info" open="open"><summary>transform_n_nonzero_coefs : int, <code>0.1 * n_features</code> by default</summary><p>Number of nonzero coefficients to target in each column of the
solution. This is only used by <code>algorithm='lars'</code> and <code>algorithm='omp'</code>
and is overridden by <code>alpha</code> in the <code>omp</code> case.</p>
</details>
<details class="info" open="open"><summary>transform_alpha : float, 1. by default</summary><p>If <code>algorithm='lasso_lars'</code> or <code>algorithm='lasso_cd'</code>, <code>alpha</code> is the
penalty applied to the L1 norm.
If <code>algorithm='threshold'</code>, <code>alpha</code> is the absolute value of the
threshold below which coefficients will be squashed to zero.
If <code>algorithm='omp'</code>, <code>alpha</code> is the tolerance parameter: the value of
the reconstruction error targeted. In this case, it overrides
<code>n_nonzero_coefs</code>.</p>
</details>
<details class="info" open="open"><summary>verbose : bool, optional (default: False)</summary><p>To control the verbosity of the procedure.</p>
</details>
<details class="info" open="open"><summary>split_sign : bool, False by default</summary><p>Whether to split the sparse feature vector into the concatenation of
its negative part and its positive part. This can improve the
performance of downstream classifiers.</p>
</details>
<details class="info" open="open"><summary>random_state : int, RandomState instance or None, optional (default=None)</summary><p>If int, random_state is the seed used by the random number generator;
If RandomState instance, random_state is the random number generator;
If None, the random number generator is the RandomState instance used
by <code>np.random</code>.</p>
</details>
<details class="info" open="open"><summary>positive_code : bool</summary><p>Whether to enforce positivity when finding the code.</p>
<p>.. versionadded:: 0.20</p>
</details>
<details class="info" open="open"><summary>positive_dict : bool</summary><p>Whether to enforce positivity when finding the dictionary.</p>
<p>.. versionadded:: 0.20</p>
</details>
<details class="info" open="open"><summary>transform_max_iter : int, optional (default=1000)</summary><p>Maximum number of iterations to perform if <code>algorithm='lasso_cd'</code> or
<code>lasso_lars</code>.</p>
<p>.. versionadded:: 0.22</p>
</details>
<h4>Attributes</h4>
<details class="info" open="open"><summary>components_ : array, [n_components, n_features]</summary><p>components extracted from the data</p>
</details>
<details class="info" open="open"><summary>inner_stats_ : tuple of (A, B) ndarrays</summary><p>Internal sufficient statistics that are kept by the algorithm.
Keeping them is useful in online settings, to avoid losing the
history of the evolution, but they shouldn't have any use for the
end user.
A (n_components, n_components) is the dictionary covariance matrix.
B (n_features, n_components) is the data approximation matrix</p>
</details>
<details class="info" open="open"><summary>n_iter_ : int</summary><p>Number of iterations run.</p>
</details>
<details class="info" open="open"><summary>iter_offset_ : int</summary><p>The number of iteration on data batches that has been
performed before.</p>
</details>
<details class="info" open="open"><summary>random_state_ : RandomState</summary><p>RandomState instance that is generated either from a seed, the random
number generattor or by <code>np.random</code>.</p>
</details>
<h4>Notes</h4>
<details class="info" open="open"><summary><strong>References:</strong></summary></details>
<p>J. Mairal, F. Bach, J. Ponce, G. Sapiro, 2009: Online dictionary learning
for sparse coding (https://www.di.ens.fr/sierra/pdfs/icml09.pdf)</p>
<h4>See also</h4>
<p>SparseCoder
DictionaryLearning
SparsePCA
MiniBatchSparsePCA</p>
</details>
<h3 id="fit_6">fit<a class="headerlink" href="#fit_6" title="Permanent link">&para;</a></h3>
<details class="note" open="open"><summary>method</summary><div class="highlight"><pre><span></span><code><span class="k">val</span> <span class="n">fit</span> <span class="o">:</span>
  <span class="o">?</span><span class="n">y</span><span class="o">:</span><span class="nn">Py</span><span class="p">.</span><span class="nn">Object</span><span class="p">.</span><span class="n">t</span> <span class="o">-&gt;</span>
  <span class="n">x</span><span class="o">:</span><span class="nn">Ndarray</span><span class="p">.</span><span class="n">t</span> <span class="o">-&gt;</span>
  <span class="n">t</span> <span class="o">-&gt;</span>
  <span class="n">t</span>
</code></pre></div>

<p>Fit the model from data in X.</p>
<h4>Parameters</h4>
<details class="info" open="open"><summary>X : array-like, shape (n_samples, n_features)</summary><p>Training vector, where n_samples in the number of samples
and n_features is the number of features.</p>
</details>
<details class="info" open="open"><summary>y : Ignored</summary></details>
<h4>Returns</h4>
<details class="info" open="open"><summary>self : object</summary><p>Returns the instance itself.</p>
</details>
</details>
<h3 id="fit_transform_6">fit_transform<a class="headerlink" href="#fit_transform_6" title="Permanent link">&para;</a></h3>
<details class="note" open="open"><summary>method</summary><div class="highlight"><pre><span></span><code><span class="k">val</span> <span class="n">fit_transform</span> <span class="o">:</span>
  <span class="o">?</span><span class="n">y</span><span class="o">:</span><span class="nn">Ndarray</span><span class="p">.</span><span class="n">t</span> <span class="o">-&gt;</span>
  <span class="o">?</span><span class="n">fit_params</span><span class="o">:(</span><span class="kt">string</span> <span class="o">*</span> <span class="nn">Py</span><span class="p">.</span><span class="nn">Object</span><span class="p">.</span><span class="n">t</span><span class="o">)</span> <span class="kt">list</span> <span class="o">-&gt;</span>
  <span class="n">x</span><span class="o">:</span><span class="nn">Ndarray</span><span class="p">.</span><span class="n">t</span> <span class="o">-&gt;</span>
  <span class="n">t</span> <span class="o">-&gt;</span>
  <span class="nn">Ndarray</span><span class="p">.</span><span class="n">t</span>
</code></pre></div>

<p>Fit to data, then transform it.</p>
<p>Fits transformer to X and y with optional parameters fit_params
and returns a transformed version of X.</p>
<h4>Parameters</h4>
<details class="info" open="open"><summary>X : numpy array of shape [n_samples, n_features]</summary><p>Training set.</p>
</details>
<details class="info" open="open"><summary>y : numpy array of shape [n_samples]</summary><p>Target values.</p>
</details>
<details class="info" open="open"><summary>**fit_params : dict</summary><p>Additional fit parameters.</p>
</details>
<h4>Returns</h4>
<details class="info" open="open"><summary>X_new : numpy array of shape [n_samples, n_features_new]</summary><p>Transformed array.</p>
</details>
</details>
<h3 id="get_params_6">get_params<a class="headerlink" href="#get_params_6" title="Permanent link">&para;</a></h3>
<details class="note" open="open"><summary>method</summary><div class="highlight"><pre><span></span><code><span class="k">val</span> <span class="n">get_params</span> <span class="o">:</span>
  <span class="o">?</span><span class="n">deep</span><span class="o">:</span><span class="kt">bool</span> <span class="o">-&gt;</span>
  <span class="n">t</span> <span class="o">-&gt;</span>
  <span class="nn">Py</span><span class="p">.</span><span class="nn">Object</span><span class="p">.</span><span class="n">t</span>
</code></pre></div>

<p>Get parameters for this estimator.</p>
<h4>Parameters</h4>
<details class="info" open="open"><summary>deep : bool, default=True</summary><p>If True, will return the parameters for this estimator and
contained subobjects that are estimators.</p>
</details>
<h4>Returns</h4>
<details class="info" open="open"><summary>params : mapping of string to any</summary><p>Parameter names mapped to their values.</p>
</details>
</details>
<h3 id="partial_fit_2">partial_fit<a class="headerlink" href="#partial_fit_2" title="Permanent link">&para;</a></h3>
<details class="note" open="open"><summary>method</summary><div class="highlight"><pre><span></span><code><span class="k">val</span> <span class="n">partial_fit</span> <span class="o">:</span>
  <span class="o">?</span><span class="n">y</span><span class="o">:</span><span class="nn">Py</span><span class="p">.</span><span class="nn">Object</span><span class="p">.</span><span class="n">t</span> <span class="o">-&gt;</span>
  <span class="o">?</span><span class="n">iter_offset</span><span class="o">:</span><span class="kt">int</span> <span class="o">-&gt;</span>
  <span class="n">x</span><span class="o">:</span><span class="nn">Ndarray</span><span class="p">.</span><span class="n">t</span> <span class="o">-&gt;</span>
  <span class="n">t</span> <span class="o">-&gt;</span>
  <span class="n">t</span>
</code></pre></div>

<p>Updates the model using the data in X as a mini-batch.</p>
<h4>Parameters</h4>
<details class="info" open="open"><summary>X : array-like, shape (n_samples, n_features)</summary><p>Training vector, where n_samples in the number of samples
and n_features is the number of features.</p>
</details>
<details class="info" open="open"><summary>y : Ignored</summary></details>
<details class="info" open="open"><summary>iter_offset : integer, optional</summary><p>The number of iteration on data batches that has been
performed before this call to partial_fit. This is optional:
if no number is passed, the memory of the object is
used.</p>
</details>
<h4>Returns</h4>
<details class="info" open="open"><summary>self : object</summary><p>Returns the instance itself.</p>
</details>
</details>
<h3 id="set_params_6">set_params<a class="headerlink" href="#set_params_6" title="Permanent link">&para;</a></h3>
<details class="note" open="open"><summary>method</summary><div class="highlight"><pre><span></span><code><span class="k">val</span> <span class="n">set_params</span> <span class="o">:</span>
  <span class="o">?</span><span class="n">params</span><span class="o">:(</span><span class="kt">string</span> <span class="o">*</span> <span class="nn">Py</span><span class="p">.</span><span class="nn">Object</span><span class="p">.</span><span class="n">t</span><span class="o">)</span> <span class="kt">list</span> <span class="o">-&gt;</span>
  <span class="n">t</span> <span class="o">-&gt;</span>
  <span class="n">t</span>
</code></pre></div>

<p>Set the parameters of this estimator.</p>
<p>The method works on simple estimators as well as on nested objects
(such as pipelines). The latter have parameters of the form
<code>&lt;component&gt;__&lt;parameter&gt;</code> so that it's possible to update each
component of a nested object.</p>
<h4>Parameters</h4>
<details class="info" open="open"><summary>**params : dict</summary><p>Estimator parameters.</p>
</details>
<h4>Returns</h4>
<details class="info" open="open"><summary>self : object</summary><p>Estimator instance.</p>
</details>
</details>
<h3 id="transform_6">transform<a class="headerlink" href="#transform_6" title="Permanent link">&para;</a></h3>
<details class="note" open="open"><summary>method</summary><div class="highlight"><pre><span></span><code><span class="k">val</span> <span class="n">transform</span> <span class="o">:</span>
  <span class="n">x</span><span class="o">:</span><span class="nn">Ndarray</span><span class="p">.</span><span class="n">t</span> <span class="o">-&gt;</span>
  <span class="n">t</span> <span class="o">-&gt;</span>
  <span class="nn">Ndarray</span><span class="p">.</span><span class="n">t</span>
</code></pre></div>

<p>Encode the data as a sparse combination of the dictionary atoms.</p>
<p>Coding method is determined by the object parameter
<code>transform_algorithm</code>.</p>
<h4>Parameters</h4>
<details class="info" open="open"><summary>X : array of shape (n_samples, n_features)</summary><p>Test data to be transformed, must have the same number of
features as the data used to train the model.</p>
</details>
<h4>Returns</h4>
<details class="info" open="open"><summary>X_new : array, shape (n_samples, n_components)</summary><p>Transformed data</p>
</details>
</details>
<h3 id="components__5">components_<a class="headerlink" href="#components__5" title="Permanent link">&para;</a></h3>
<details class="note" open="open"><summary>attribute</summary><div class="highlight"><pre><span></span><code><span class="k">val</span> <span class="n">components_</span> <span class="o">:</span> <span class="n">t</span> <span class="o">-&gt;</span> <span class="nn">Ndarray</span><span class="p">.</span><span class="n">t</span>
</code></pre></div>

<p>This attribute is documented in <code>create</code> above.</p>
</details>
<h3 id="inner_stats_">inner_stats_<a class="headerlink" href="#inner_stats_" title="Permanent link">&para;</a></h3>
<details class="note" open="open"><summary>attribute</summary><div class="highlight"><pre><span></span><code><span class="k">val</span> <span class="n">inner_stats_</span> <span class="o">:</span> <span class="n">t</span> <span class="o">-&gt;</span> <span class="nn">Py</span><span class="p">.</span><span class="nn">Object</span><span class="p">.</span><span class="n">t</span>
</code></pre></div>

<p>This attribute is documented in <code>create</code> above.</p>
</details>
<h3 id="n_iter__4">n_iter_<a class="headerlink" href="#n_iter__4" title="Permanent link">&para;</a></h3>
<details class="note" open="open"><summary>attribute</summary><div class="highlight"><pre><span></span><code><span class="k">val</span> <span class="n">n_iter_</span> <span class="o">:</span> <span class="n">t</span> <span class="o">-&gt;</span> <span class="kt">int</span>
</code></pre></div>

<p>This attribute is documented in <code>create</code> above.</p>
</details>
<h3 id="iter_offset_">iter_offset_<a class="headerlink" href="#iter_offset_" title="Permanent link">&para;</a></h3>
<details class="note" open="open"><summary>attribute</summary><div class="highlight"><pre><span></span><code><span class="k">val</span> <span class="n">iter_offset_</span> <span class="o">:</span> <span class="n">t</span> <span class="o">-&gt;</span> <span class="kt">int</span>
</code></pre></div>

<p>This attribute is documented in <code>create</code> above.</p>
</details>
<h3 id="random_state_">random_state_<a class="headerlink" href="#random_state_" title="Permanent link">&para;</a></h3>
<details class="note" open="open"><summary>attribute</summary><div class="highlight"><pre><span></span><code><span class="k">val</span> <span class="n">random_state_</span> <span class="o">:</span> <span class="n">t</span> <span class="o">-&gt;</span> <span class="nn">Py</span><span class="p">.</span><span class="nn">Object</span><span class="p">.</span><span class="n">t</span>
</code></pre></div>

<p>This attribute is documented in <code>create</code> above.</p>
</details>
<h3 id="to_string_6">to_string<a class="headerlink" href="#to_string_6" title="Permanent link">&para;</a></h3>
<details class="note" open="open"><summary>method</summary><div class="highlight"><pre><span></span><code><span class="k">val</span> <span class="n">to_string</span><span class="o">:</span> <span class="n">t</span> <span class="o">-&gt;</span> <span class="kt">string</span>
</code></pre></div>

<p>Print the object to a human-readable representation.</p>
</details>
<h3 id="show_6">show<a class="headerlink" href="#show_6" title="Permanent link">&para;</a></h3>
<details class="note" open="open"><summary>method</summary><div class="highlight"><pre><span></span><code><span class="k">val</span> <span class="n">show</span><span class="o">:</span> <span class="n">t</span> <span class="o">-&gt;</span> <span class="kt">string</span>
</code></pre></div>

<p>Print the object to a human-readable representation.</p>
</details>
<h3 id="pp_6">pp<a class="headerlink" href="#pp_6" title="Permanent link">&para;</a></h3>
<details class="note" open="open"><summary>method</summary><div class="highlight"><pre><span></span><code><span class="k">val</span> <span class="n">pp</span><span class="o">:</span> <span class="nn">Format</span><span class="p">.</span><span class="n">formatter</span> <span class="o">-&gt;</span> <span class="n">t</span> <span class="o">-&gt;</span> <span class="kt">unit</span>
</code></pre></div>

<p>Pretty-print the object to a formatter.</p>
</details>
<h2 id="module-sklearndecompositionminibatchsparsepca">module Sklearn.​Decomposition.​MiniBatchSparsePCA<a class="headerlink" href="#module-sklearndecompositionminibatchsparsepca" title="Permanent link">&para;</a></h2>
<div class="highlight"><pre><span></span><code><span class="k">type</span> <span class="n">t</span>
</code></pre></div>

<h3 id="create_7">create<a class="headerlink" href="#create_7" title="Permanent link">&para;</a></h3>
<details class="note" open="open"><summary>constructor and attributes</summary><div class="highlight"><pre><span></span><code><span class="k">val</span> <span class="n">create</span> <span class="o">:</span>
  <span class="o">?</span><span class="n">n_components</span><span class="o">:</span><span class="kt">int</span> <span class="o">-&gt;</span>
  <span class="o">?</span><span class="n">alpha</span><span class="o">:</span><span class="kt">int</span> <span class="o">-&gt;</span>
  <span class="o">?</span><span class="n">ridge_alpha</span><span class="o">:</span><span class="kt">float</span> <span class="o">-&gt;</span>
  <span class="o">?</span><span class="n">n_iter</span><span class="o">:</span><span class="kt">int</span> <span class="o">-&gt;</span>
  <span class="o">?</span><span class="n">callback</span><span class="o">:[`</span><span class="nc">Callable</span> <span class="k">of</span> <span class="nn">Py</span><span class="p">.</span><span class="nn">Object</span><span class="p">.</span><span class="n">t</span> <span class="o">|</span> <span class="o">`</span><span class="nc">None</span><span class="o">]</span> <span class="o">-&gt;</span>
  <span class="o">?</span><span class="n">batch_size</span><span class="o">:</span><span class="kt">int</span> <span class="o">-&gt;</span>
  <span class="o">?</span><span class="n">verbose</span><span class="o">:</span><span class="kt">int</span> <span class="o">-&gt;</span>
  <span class="o">?</span><span class="n">shuffle</span><span class="o">:</span><span class="kt">bool</span> <span class="o">-&gt;</span>
  <span class="o">?</span><span class="n">n_jobs</span><span class="o">:[`</span><span class="nc">Int</span> <span class="k">of</span> <span class="kt">int</span> <span class="o">|</span> <span class="o">`</span><span class="nc">None</span><span class="o">]</span> <span class="o">-&gt;</span>
  <span class="o">?</span><span class="n">method_</span><span class="o">:[`</span><span class="nc">Lars</span> <span class="o">|</span> <span class="o">`</span><span class="nc">Cd</span><span class="o">]</span> <span class="o">-&gt;</span>
  <span class="o">?</span><span class="n">random_state</span><span class="o">:[`</span><span class="nc">Int</span> <span class="k">of</span> <span class="kt">int</span> <span class="o">|</span> <span class="o">`</span><span class="nc">RandomState</span> <span class="k">of</span> <span class="nn">Py</span><span class="p">.</span><span class="nn">Object</span><span class="p">.</span><span class="n">t</span> <span class="o">|</span> <span class="o">`</span><span class="nc">None</span><span class="o">]</span> <span class="o">-&gt;</span>
  <span class="o">?</span><span class="n">normalize_components</span><span class="o">:</span><span class="kt">string</span> <span class="o">-&gt;</span>
  <span class="kt">unit</span> <span class="o">-&gt;</span>
  <span class="n">t</span>
</code></pre></div>

<p>Mini-batch Sparse Principal Components Analysis</p>
<p>Finds the set of sparse components that can optimally reconstruct
the data.  The amount of sparseness is controllable by the coefficient
of the L1 penalty, given by the parameter alpha.</p>
<p>Read more in the :ref:<code>User Guide &lt;SparsePCA&gt;</code>.</p>
<h4>Parameters</h4>
<details class="info" open="open"><summary>n_components : int,</summary><p>number of sparse atoms to extract</p>
</details>
<details class="info" open="open"><summary>alpha : int,</summary><p>Sparsity controlling parameter. Higher values lead to sparser
components.</p>
</details>
<details class="info" open="open"><summary>ridge_alpha : float,</summary><p>Amount of ridge shrinkage to apply in order to improve
conditioning when calling the transform method.</p>
</details>
<details class="info" open="open"><summary>n_iter : int,</summary><p>number of iterations to perform for each mini batch</p>
</details>
<details class="info" open="open"><summary>callback : callable or None, optional (default: None)</summary><p>callable that gets invoked every five iterations</p>
</details>
<details class="info" open="open"><summary>batch_size : int,</summary><p>the number of features to take in each mini batch</p>
</details>
<details class="info" open="open"><summary>verbose : int</summary><p>Controls the verbosity; the higher, the more messages. Defaults to 0.</p>
</details>
<details class="info" open="open"><summary>shuffle : boolean,</summary><p>whether to shuffle the data before splitting it in batches</p>
</details>
<details class="info" open="open"><summary>n_jobs : int or None, optional (default=None)</summary><p>Number of parallel jobs to run.
<code>None</code> means 1 unless in a :obj:<code>joblib.parallel_backend</code> context.
<code>-1</code> means using all processors. See :term:<code>Glossary &lt;n_jobs&gt;</code>
for more details.</p>
</details>
<details class="info" open="open"><summary>method : {'lars', 'cd'}</summary></details>
<details class="info" open="open"><summary>lars: uses the least angle regression method to solve the lasso problem</summary><p>(linear_model.lars_path)</p>
</details>
<details class="info" open="open"><summary>cd: uses the coordinate descent method to compute the</summary><p>Lasso solution (linear_model.Lasso). Lars will be faster if
the estimated components are sparse.</p>
</details>
<details class="info" open="open"><summary>random_state : int, RandomState instance or None, optional (default=None)</summary><p>If int, random_state is the seed used by the random number generator;
If RandomState instance, random_state is the random number generator;
If None, the random number generator is the RandomState instance used
by <code>np.random</code>.</p>
</details>
<details class="info" open="open"><summary>normalize_components : 'deprecated'</summary><p>This parameter does not have any effect. The components are always
normalized.</p>
<p>.. versionadded:: 0.20</p>
<p>.. deprecated:: 0.22
   <code>normalize_components</code> is deprecated in 0.22 and will be removed
   in 0.24.</p>
</details>
<h4>Attributes</h4>
<details class="info" open="open"><summary>components_ : array, [n_components, n_features]</summary><p>Sparse components extracted from the data.</p>
</details>
<details class="info" open="open"><summary>n_iter_ : int</summary><p>Number of iterations run.</p>
</details>
<details class="info" open="open"><summary>mean_ : array, shape (n_features,)</summary><p>Per-feature empirical mean, estimated from the training set.
Equal to <code>X.mean(axis=0)</code>.</p>
</details>
<h4>Examples</h4>
<div class="highlight"><pre><span></span><code><span class="o">&gt;&gt;&gt;</span> <span class="kn">import</span> <span class="nn">numpy</span> <span class="k">as</span> <span class="nn">np</span>
<span class="o">&gt;&gt;&gt;</span> <span class="kn">from</span> <span class="nn">sklearn.datasets</span> <span class="kn">import</span> <span class="n">make_friedman1</span>
<span class="o">&gt;&gt;&gt;</span> <span class="kn">from</span> <span class="nn">sklearn.decomposition</span> <span class="kn">import</span> <span class="n">MiniBatchSparsePCA</span>
<span class="o">&gt;&gt;&gt;</span> <span class="n">X</span><span class="p">,</span> <span class="n">_</span> <span class="o">=</span> <span class="n">make_friedman1</span><span class="p">(</span><span class="n">n_samples</span><span class="o">=</span><span class="mi">200</span><span class="p">,</span> <span class="n">n_features</span><span class="o">=</span><span class="mi">30</span><span class="p">,</span> <span class="n">random_state</span><span class="o">=</span><span class="mi">0</span><span class="p">)</span>
<span class="o">&gt;&gt;&gt;</span> <span class="n">transformer</span> <span class="o">=</span> <span class="n">MiniBatchSparsePCA</span><span class="p">(</span><span class="n">n_components</span><span class="o">=</span><span class="mi">5</span><span class="p">,</span> <span class="n">batch_size</span><span class="o">=</span><span class="mi">50</span><span class="p">,</span>
<span class="o">...</span>                                  <span class="n">random_state</span><span class="o">=</span><span class="mi">0</span><span class="p">)</span>
<span class="o">&gt;&gt;&gt;</span> <span class="n">transformer</span><span class="o">.</span><span class="n">fit</span><span class="p">(</span><span class="n">X</span><span class="p">)</span>
<span class="n">MiniBatchSparsePCA</span><span class="p">(</span><span class="o">...</span><span class="p">)</span>
<span class="o">&gt;&gt;&gt;</span> <span class="n">X_transformed</span> <span class="o">=</span> <span class="n">transformer</span><span class="o">.</span><span class="n">transform</span><span class="p">(</span><span class="n">X</span><span class="p">)</span>
<span class="o">&gt;&gt;&gt;</span> <span class="n">X_transformed</span><span class="o">.</span><span class="n">shape</span>
<span class="p">(</span><span class="mi">200</span><span class="p">,</span> <span class="mi">5</span><span class="p">)</span>
<span class="o">&gt;&gt;&gt;</span> <span class="c1"># most values in the components_ are zero (sparsity)</span>
<span class="o">&gt;&gt;&gt;</span> <span class="n">np</span><span class="o">.</span><span class="n">mean</span><span class="p">(</span><span class="n">transformer</span><span class="o">.</span><span class="n">components_</span> <span class="o">==</span> <span class="mi">0</span><span class="p">)</span>
<span class="mf">0.94</span>
</code></pre></div>

<h4>See also</h4>
<p>PCA
SparsePCA
DictionaryLearning</p>
</details>
<h3 id="fit_7">fit<a class="headerlink" href="#fit_7" title="Permanent link">&para;</a></h3>
<details class="note" open="open"><summary>method</summary><div class="highlight"><pre><span></span><code><span class="k">val</span> <span class="n">fit</span> <span class="o">:</span>
  <span class="o">?</span><span class="n">y</span><span class="o">:</span><span class="nn">Py</span><span class="p">.</span><span class="nn">Object</span><span class="p">.</span><span class="n">t</span> <span class="o">-&gt;</span>
  <span class="n">x</span><span class="o">:</span><span class="nn">Ndarray</span><span class="p">.</span><span class="n">t</span> <span class="o">-&gt;</span>
  <span class="n">t</span> <span class="o">-&gt;</span>
  <span class="n">t</span>
</code></pre></div>

<p>Fit the model from data in X.</p>
<h4>Parameters</h4>
<details class="info" open="open"><summary>X : array-like, shape (n_samples, n_features)</summary><p>Training vector, where n_samples in the number of samples
and n_features is the number of features.</p>
</details>
<details class="info" open="open"><summary>y : Ignored</summary></details>
<h4>Returns</h4>
<details class="info" open="open"><summary>self : object</summary><p>Returns the instance itself.</p>
</details>
</details>
<h3 id="fit_transform_7">fit_transform<a class="headerlink" href="#fit_transform_7" title="Permanent link">&para;</a></h3>
<details class="note" open="open"><summary>method</summary><div class="highlight"><pre><span></span><code><span class="k">val</span> <span class="n">fit_transform</span> <span class="o">:</span>
  <span class="o">?</span><span class="n">y</span><span class="o">:</span><span class="nn">Ndarray</span><span class="p">.</span><span class="n">t</span> <span class="o">-&gt;</span>
  <span class="o">?</span><span class="n">fit_params</span><span class="o">:(</span><span class="kt">string</span> <span class="o">*</span> <span class="nn">Py</span><span class="p">.</span><span class="nn">Object</span><span class="p">.</span><span class="n">t</span><span class="o">)</span> <span class="kt">list</span> <span class="o">-&gt;</span>
  <span class="n">x</span><span class="o">:</span><span class="nn">Ndarray</span><span class="p">.</span><span class="n">t</span> <span class="o">-&gt;</span>
  <span class="n">t</span> <span class="o">-&gt;</span>
  <span class="nn">Ndarray</span><span class="p">.</span><span class="n">t</span>
</code></pre></div>

<p>Fit to data, then transform it.</p>
<p>Fits transformer to X and y with optional parameters fit_params
and returns a transformed version of X.</p>
<h4>Parameters</h4>
<details class="info" open="open"><summary>X : numpy array of shape [n_samples, n_features]</summary><p>Training set.</p>
</details>
<details class="info" open="open"><summary>y : numpy array of shape [n_samples]</summary><p>Target values.</p>
</details>
<details class="info" open="open"><summary>**fit_params : dict</summary><p>Additional fit parameters.</p>
</details>
<h4>Returns</h4>
<details class="info" open="open"><summary>X_new : numpy array of shape [n_samples, n_features_new]</summary><p>Transformed array.</p>
</details>
</details>
<h3 id="get_params_7">get_params<a class="headerlink" href="#get_params_7" title="Permanent link">&para;</a></h3>
<details class="note" open="open"><summary>method</summary><div class="highlight"><pre><span></span><code><span class="k">val</span> <span class="n">get_params</span> <span class="o">:</span>
  <span class="o">?</span><span class="n">deep</span><span class="o">:</span><span class="kt">bool</span> <span class="o">-&gt;</span>
  <span class="n">t</span> <span class="o">-&gt;</span>
  <span class="nn">Py</span><span class="p">.</span><span class="nn">Object</span><span class="p">.</span><span class="n">t</span>
</code></pre></div>

<p>Get parameters for this estimator.</p>
<h4>Parameters</h4>
<details class="info" open="open"><summary>deep : bool, default=True</summary><p>If True, will return the parameters for this estimator and
contained subobjects that are estimators.</p>
</details>
<h4>Returns</h4>
<details class="info" open="open"><summary>params : mapping of string to any</summary><p>Parameter names mapped to their values.</p>
</details>
</details>
<h3 id="set_params_7">set_params<a class="headerlink" href="#set_params_7" title="Permanent link">&para;</a></h3>
<details class="note" open="open"><summary>method</summary><div class="highlight"><pre><span></span><code><span class="k">val</span> <span class="n">set_params</span> <span class="o">:</span>
  <span class="o">?</span><span class="n">params</span><span class="o">:(</span><span class="kt">string</span> <span class="o">*</span> <span class="nn">Py</span><span class="p">.</span><span class="nn">Object</span><span class="p">.</span><span class="n">t</span><span class="o">)</span> <span class="kt">list</span> <span class="o">-&gt;</span>
  <span class="n">t</span> <span class="o">-&gt;</span>
  <span class="n">t</span>
</code></pre></div>

<p>Set the parameters of this estimator.</p>
<p>The method works on simple estimators as well as on nested objects
(such as pipelines). The latter have parameters of the form
<code>&lt;component&gt;__&lt;parameter&gt;</code> so that it's possible to update each
component of a nested object.</p>
<h4>Parameters</h4>
<details class="info" open="open"><summary>**params : dict</summary><p>Estimator parameters.</p>
</details>
<h4>Returns</h4>
<details class="info" open="open"><summary>self : object</summary><p>Estimator instance.</p>
</details>
</details>
<h3 id="transform_7">transform<a class="headerlink" href="#transform_7" title="Permanent link">&para;</a></h3>
<details class="note" open="open"><summary>method</summary><div class="highlight"><pre><span></span><code><span class="k">val</span> <span class="n">transform</span> <span class="o">:</span>
  <span class="n">x</span><span class="o">:</span><span class="nn">Ndarray</span><span class="p">.</span><span class="n">t</span> <span class="o">-&gt;</span>
  <span class="n">t</span> <span class="o">-&gt;</span>
  <span class="nn">Ndarray</span><span class="p">.</span><span class="n">t</span>
</code></pre></div>

<p>Least Squares projection of the data onto the sparse components.</p>
<p>To avoid instability issues in case the system is under-determined,
regularization can be applied (Ridge regression) via the
<code>ridge_alpha</code> parameter.</p>
<p>Note that Sparse PCA components orthogonality is not enforced as in PCA
hence one cannot use a simple linear projection.</p>
<h4>Parameters</h4>
<details class="info" open="open"><summary>X : array of shape (n_samples, n_features)</summary><p>Test data to be transformed, must have the same number of
features as the data used to train the model.</p>
</details>
<h4>Returns</h4>
<p>X_new array, shape (n_samples, n_components)
    Transformed data.</p>
</details>
<h3 id="components__6">components_<a class="headerlink" href="#components__6" title="Permanent link">&para;</a></h3>
<details class="note" open="open"><summary>attribute</summary><div class="highlight"><pre><span></span><code><span class="k">val</span> <span class="n">components_</span> <span class="o">:</span> <span class="n">t</span> <span class="o">-&gt;</span> <span class="nn">Ndarray</span><span class="p">.</span><span class="n">t</span>
</code></pre></div>

<p>This attribute is documented in <code>create</code> above.</p>
</details>
<h3 id="n_iter__5">n_iter_<a class="headerlink" href="#n_iter__5" title="Permanent link">&para;</a></h3>
<details class="note" open="open"><summary>attribute</summary><div class="highlight"><pre><span></span><code><span class="k">val</span> <span class="n">n_iter_</span> <span class="o">:</span> <span class="n">t</span> <span class="o">-&gt;</span> <span class="kt">int</span>
</code></pre></div>

<p>This attribute is documented in <code>create</code> above.</p>
</details>
<h3 id="mean__3">mean_<a class="headerlink" href="#mean__3" title="Permanent link">&para;</a></h3>
<details class="note" open="open"><summary>attribute</summary><div class="highlight"><pre><span></span><code><span class="k">val</span> <span class="n">mean_</span> <span class="o">:</span> <span class="n">t</span> <span class="o">-&gt;</span> <span class="nn">Ndarray</span><span class="p">.</span><span class="n">t</span>
</code></pre></div>

<p>This attribute is documented in <code>create</code> above.</p>
</details>
<h3 id="to_string_7">to_string<a class="headerlink" href="#to_string_7" title="Permanent link">&para;</a></h3>
<details class="note" open="open"><summary>method</summary><div class="highlight"><pre><span></span><code><span class="k">val</span> <span class="n">to_string</span><span class="o">:</span> <span class="n">t</span> <span class="o">-&gt;</span> <span class="kt">string</span>
</code></pre></div>

<p>Print the object to a human-readable representation.</p>
</details>
<h3 id="show_7">show<a class="headerlink" href="#show_7" title="Permanent link">&para;</a></h3>
<details class="note" open="open"><summary>method</summary><div class="highlight"><pre><span></span><code><span class="k">val</span> <span class="n">show</span><span class="o">:</span> <span class="n">t</span> <span class="o">-&gt;</span> <span class="kt">string</span>
</code></pre></div>

<p>Print the object to a human-readable representation.</p>
</details>
<h3 id="pp_7">pp<a class="headerlink" href="#pp_7" title="Permanent link">&para;</a></h3>
<details class="note" open="open"><summary>method</summary><div class="highlight"><pre><span></span><code><span class="k">val</span> <span class="n">pp</span><span class="o">:</span> <span class="nn">Format</span><span class="p">.</span><span class="n">formatter</span> <span class="o">-&gt;</span> <span class="n">t</span> <span class="o">-&gt;</span> <span class="kt">unit</span>
</code></pre></div>

<p>Pretty-print the object to a formatter.</p>
</details>
<h2 id="module-sklearndecompositionnmf">module Sklearn.​Decomposition.​NMF<a class="headerlink" href="#module-sklearndecompositionnmf" title="Permanent link">&para;</a></h2>
<div class="highlight"><pre><span></span><code><span class="k">type</span> <span class="n">t</span>
</code></pre></div>

<h3 id="create_8">create<a class="headerlink" href="#create_8" title="Permanent link">&para;</a></h3>
<details class="note" open="open"><summary>constructor and attributes</summary><div class="highlight"><pre><span></span><code><span class="k">val</span> <span class="n">create</span> <span class="o">:</span>
  <span class="o">?</span><span class="n">n_components</span><span class="o">:[`</span><span class="nc">Int</span> <span class="k">of</span> <span class="kt">int</span> <span class="o">|</span> <span class="o">`</span><span class="nc">None</span><span class="o">]</span> <span class="o">-&gt;</span>
  <span class="o">?</span><span class="n">init</span><span class="o">:[`</span><span class="nc">Random</span> <span class="o">|</span> <span class="o">`</span><span class="nc">Nndsvd</span> <span class="o">|</span> <span class="o">`</span><span class="nc">Nndsvda</span> <span class="o">|</span> <span class="o">`</span><span class="nc">Nndsvdar</span> <span class="o">|</span> <span class="o">`</span><span class="nc">Custom</span> <span class="o">|</span> <span class="o">`</span><span class="nc">None</span><span class="o">]</span> <span class="o">-&gt;</span>
  <span class="o">?</span><span class="n">solver</span><span class="o">:[`</span><span class="nc">Cd</span> <span class="o">|</span> <span class="o">`</span><span class="nc">Mu</span><span class="o">]</span> <span class="o">-&gt;</span>
  <span class="o">?</span><span class="n">beta_loss</span><span class="o">:[`</span><span class="nc">Float</span> <span class="k">of</span> <span class="kt">float</span> <span class="o">|</span> <span class="o">`</span><span class="nc">String</span> <span class="k">of</span> <span class="kt">string</span><span class="o">]</span> <span class="o">-&gt;</span>
  <span class="o">?</span><span class="n">tol</span><span class="o">:</span><span class="kt">float</span> <span class="o">-&gt;</span>
  <span class="o">?</span><span class="n">max_iter</span><span class="o">:</span><span class="kt">int</span> <span class="o">-&gt;</span>
  <span class="o">?</span><span class="n">random_state</span><span class="o">:[`</span><span class="nc">Int</span> <span class="k">of</span> <span class="kt">int</span> <span class="o">|</span> <span class="o">`</span><span class="nc">RandomState</span> <span class="k">of</span> <span class="nn">Py</span><span class="p">.</span><span class="nn">Object</span><span class="p">.</span><span class="n">t</span> <span class="o">|</span> <span class="o">`</span><span class="nc">None</span><span class="o">]</span> <span class="o">-&gt;</span>
  <span class="o">?</span><span class="n">alpha</span><span class="o">:</span><span class="kt">float</span> <span class="o">-&gt;</span>
  <span class="o">?</span><span class="n">l1_ratio</span><span class="o">:</span><span class="kt">float</span> <span class="o">-&gt;</span>
  <span class="o">?</span><span class="n">verbose</span><span class="o">:</span><span class="kt">bool</span> <span class="o">-&gt;</span>
  <span class="o">?</span><span class="n">shuffle</span><span class="o">:</span><span class="kt">bool</span> <span class="o">-&gt;</span>
  <span class="kt">unit</span> <span class="o">-&gt;</span>
  <span class="n">t</span>
</code></pre></div>

<p>Non-Negative Matrix Factorization (NMF)</p>
<p>Find two non-negative matrices (W, H) whose product approximates the non-
negative matrix X. This factorization can be used for example for
dimensionality reduction, source separation or topic extraction.</p>
<p>The objective function is::</p>
<div class="codehilite"><pre><span></span><code>0.5 * ||X - WH||_Fro^2
+ alpha * l1_ratio * ||vec(W)||_1
+ alpha * l1_ratio * ||vec(H)||_1
+ 0.5 * alpha * (1 - l1_ratio) * ||W||_Fro^2
+ 0.5 * alpha * (1 - l1_ratio) * ||H||_Fro^2
</code></pre></div>


<details class="info" open="open"><summary>Where::</summary><p>||A||<em>Fro^2 = \sum</em>{i,j} A_{ij}^2 (Frobenius norm)
||vec(A)||<em>1 = \sum</em>{i,j} abs(A_{ij}) (Elementwise L1 norm)</p>
</details>
<p>For multiplicative-update ('mu') solver, the Frobenius norm
(0.5 * ||X - WH||_Fro^2) can be changed into another beta-divergence loss,
by changing the beta_loss parameter.</p>
<p>The objective function is minimized with an alternating minimization of W
and H.</p>
<p>Read more in the :ref:<code>User Guide &lt;NMF&gt;</code>.</p>
<h4>Parameters</h4>
<details class="info" open="open"><summary>n_components : int or None</summary><p>Number of components, if n_components is not set all features
are kept.</p>
</details>
<details class="info" open="open"><summary>init : None | 'random' | 'nndsvd' |  'nndsvda' | 'nndsvdar' | 'custom'</summary><p>Method used to initialize the procedure.</p>
</details>
<details class="info" open="open"><summary>Default: None.</summary><p>Valid options:</p>
<ul>
<li>
<p>None: 'nndsvd' if n_components &lt;= min(n_samples, n_features),
    otherwise random.</p>
</li>
<li>
<p>'random': non-negative random matrices, scaled with:
    sqrt(X.mean() / n_components)</p>
</li>
<li>
<p>'nndsvd': Nonnegative Double Singular Value Decomposition (NNDSVD)
    initialization (better for sparseness)</p>
</li>
<li>
<p>'nndsvda': NNDSVD with zeros filled with the average of X
    (better when sparsity is not desired)</p>
</li>
<li>
<p>'nndsvdar': NNDSVD with zeros filled with small random values
    (generally faster, less accurate alternative to NNDSVDa
    for when sparsity is not desired)</p>
</li>
<li>
<p>'custom': use custom matrices W and H</p>
</li>
</ul>
</details>
<details class="info" open="open"><summary>solver : 'cd' | 'mu'</summary><p>Numerical solver to use:
'cd' is a Coordinate Descent solver.
'mu' is a Multiplicative Update solver.</p>
<p>.. versionadded:: 0.17
   Coordinate Descent solver.</p>
<p>.. versionadded:: 0.19
   Multiplicative Update solver.</p>
</details>
<details class="info" open="open"><summary>beta_loss : float or string, default 'frobenius'</summary><p>String must be in {'frobenius', 'kullback-leibler', 'itakura-saito'}.
Beta divergence to be minimized, measuring the distance between X
and the dot product WH. Note that values different from 'frobenius'
(or 2) and 'kullback-leibler' (or 1) lead to significantly slower
fits. Note that for beta_loss &lt;= 0 (or 'itakura-saito'), the input
matrix X cannot contain zeros. Used only in 'mu' solver.</p>
<p>.. versionadded:: 0.19</p>
</details>
<details class="info" open="open"><summary>tol : float, default: 1e-4</summary><p>Tolerance of the stopping condition.</p>
</details>
<details class="info" open="open"><summary>max_iter : integer, default: 200</summary><p>Maximum number of iterations before timing out.</p>
</details>
<details class="info" open="open"><summary>random_state : int, RandomState instance or None, optional, default: None</summary><p>If int, random_state is the seed used by the random number generator;
If RandomState instance, random_state is the random number generator;
If None, the random number generator is the RandomState instance used
by <code>np.random</code>.</p>
</details>
<details class="info" open="open"><summary>alpha : double, default: 0.</summary><p>Constant that multiplies the regularization terms. Set it to zero to
have no regularization.</p>
<p>.. versionadded:: 0.17
   <em>alpha</em> used in the Coordinate Descent solver.</p>
</details>
<details class="info" open="open"><summary>l1_ratio : double, default: 0.</summary><p>The regularization mixing parameter, with 0 &lt;= l1_ratio &lt;= 1.
For l1_ratio = 0 the penalty is an elementwise L2 penalty
(aka Frobenius Norm).
For l1_ratio = 1 it is an elementwise L1 penalty.
For 0 &lt; l1_ratio &lt; 1, the penalty is a combination of L1 and L2.</p>
<p>.. versionadded:: 0.17
   Regularization parameter <em>l1_ratio</em> used in the Coordinate Descent
   solver.</p>
</details>
<details class="info" open="open"><summary>verbose : bool, default=False</summary><p>Whether to be verbose.</p>
</details>
<details class="info" open="open"><summary>shuffle : boolean, default: False</summary><p>If true, randomize the order of coordinates in the CD solver.</p>
<p>.. versionadded:: 0.17
   <em>shuffle</em> parameter used in the Coordinate Descent solver.</p>
</details>
<h4>Attributes</h4>
<details class="info" open="open"><summary>components_ : array, [n_components, n_features]</summary><p>Factorization matrix, sometimes called 'dictionary'.</p>
</details>
<details class="info" open="open"><summary>n_components_ : integer</summary><p>The number of components. It is same as the <code>n_components</code> parameter
if it was given. Otherwise, it will be same as the number of
features.</p>
</details>
<details class="info" open="open"><summary>reconstruction_err_ : number</summary><p>Frobenius norm of the matrix difference, or beta-divergence, between
the training data <code>X</code> and the reconstructed data <code>WH</code> from
the fitted model.</p>
</details>
<details class="info" open="open"><summary>n_iter_ : int</summary><p>Actual number of iterations.</p>
</details>
<h4>Examples</h4>
<div class="highlight"><pre><span></span><code><span class="o">&gt;&gt;&gt;</span> <span class="kn">import</span> <span class="nn">numpy</span> <span class="k">as</span> <span class="nn">np</span>
<span class="o">&gt;&gt;&gt;</span> <span class="n">X</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">array</span><span class="p">([[</span><span class="mi">1</span><span class="p">,</span> <span class="mi">1</span><span class="p">],</span> <span class="p">[</span><span class="mi">2</span><span class="p">,</span> <span class="mi">1</span><span class="p">],</span> <span class="p">[</span><span class="mi">3</span><span class="p">,</span> <span class="mf">1.2</span><span class="p">],</span> <span class="p">[</span><span class="mi">4</span><span class="p">,</span> <span class="mi">1</span><span class="p">],</span> <span class="p">[</span><span class="mi">5</span><span class="p">,</span> <span class="mf">0.8</span><span class="p">],</span> <span class="p">[</span><span class="mi">6</span><span class="p">,</span> <span class="mi">1</span><span class="p">]])</span>
<span class="o">&gt;&gt;&gt;</span> <span class="kn">from</span> <span class="nn">sklearn.decomposition</span> <span class="kn">import</span> <span class="n">NMF</span>
<span class="o">&gt;&gt;&gt;</span> <span class="n">model</span> <span class="o">=</span> <span class="n">NMF</span><span class="p">(</span><span class="n">n_components</span><span class="o">=</span><span class="mi">2</span><span class="p">,</span> <span class="n">init</span><span class="o">=</span><span class="s1">&#39;random&#39;</span><span class="p">,</span> <span class="n">random_state</span><span class="o">=</span><span class="mi">0</span><span class="p">)</span>
<span class="o">&gt;&gt;&gt;</span> <span class="n">W</span> <span class="o">=</span> <span class="n">model</span><span class="o">.</span><span class="n">fit_transform</span><span class="p">(</span><span class="n">X</span><span class="p">)</span>
<span class="o">&gt;&gt;&gt;</span> <span class="n">H</span> <span class="o">=</span> <span class="n">model</span><span class="o">.</span><span class="n">components_</span>
</code></pre></div>

<h4>References</h4>
<p>Cichocki, Andrzej, and P. H. A. N. Anh-Huy. "Fast local algorithms for
large scale nonnegative matrix and tensor factorizations."
IEICE transactions on fundamentals of electronics, communications and
computer sciences 92.3: 708-721, 2009.</p>
<p>Fevotte, C., &amp; Idier, J. (2011). Algorithms for nonnegative matrix
factorization with the beta-divergence. Neural Computation, 23(9).</p>
</details>
<h3 id="fit_8">fit<a class="headerlink" href="#fit_8" title="Permanent link">&para;</a></h3>
<details class="note" open="open"><summary>method</summary><div class="highlight"><pre><span></span><code><span class="k">val</span> <span class="n">fit</span> <span class="o">:</span>
  <span class="o">?</span><span class="n">y</span><span class="o">:</span><span class="nn">Py</span><span class="p">.</span><span class="nn">Object</span><span class="p">.</span><span class="n">t</span> <span class="o">-&gt;</span>
  <span class="o">?</span><span class="n">params</span><span class="o">:(</span><span class="kt">string</span> <span class="o">*</span> <span class="nn">Py</span><span class="p">.</span><span class="nn">Object</span><span class="p">.</span><span class="n">t</span><span class="o">)</span> <span class="kt">list</span> <span class="o">-&gt;</span>
  <span class="n">x</span><span class="o">:[`</span><span class="nc">Ndarray</span> <span class="k">of</span> <span class="nn">Ndarray</span><span class="p">.</span><span class="n">t</span> <span class="o">|</span> <span class="o">`</span><span class="nc">SparseMatrix</span> <span class="k">of</span> <span class="nn">Csr_matrix</span><span class="p">.</span><span class="n">t</span><span class="o">]</span> <span class="o">-&gt;</span>
  <span class="n">t</span> <span class="o">-&gt;</span>
  <span class="n">t</span>
</code></pre></div>

<p>Learn a NMF model for the data X.</p>
<h4>Parameters</h4>
<details class="info" open="open"><summary>X : {array-like, sparse matrix}, shape (n_samples, n_features)</summary><p>Data matrix to be decomposed</p>
</details>
<details class="info" open="open"><summary>y : Ignored</summary></details>
<h4>Returns</h4>
<p>self</p>
</details>
<h3 id="fit_transform_8">fit_transform<a class="headerlink" href="#fit_transform_8" title="Permanent link">&para;</a></h3>
<details class="note" open="open"><summary>method</summary><div class="highlight"><pre><span></span><code><span class="k">val</span> <span class="n">fit_transform</span> <span class="o">:</span>
  <span class="o">?</span><span class="n">y</span><span class="o">:</span><span class="nn">Py</span><span class="p">.</span><span class="nn">Object</span><span class="p">.</span><span class="n">t</span> <span class="o">-&gt;</span>
  <span class="o">?</span><span class="n">w</span><span class="o">:</span><span class="nn">Ndarray</span><span class="p">.</span><span class="n">t</span> <span class="o">-&gt;</span>
  <span class="o">?</span><span class="n">h</span><span class="o">:</span><span class="nn">Ndarray</span><span class="p">.</span><span class="n">t</span> <span class="o">-&gt;</span>
  <span class="n">x</span><span class="o">:[`</span><span class="nc">Ndarray</span> <span class="k">of</span> <span class="nn">Ndarray</span><span class="p">.</span><span class="n">t</span> <span class="o">|</span> <span class="o">`</span><span class="nc">SparseMatrix</span> <span class="k">of</span> <span class="nn">Csr_matrix</span><span class="p">.</span><span class="n">t</span><span class="o">]</span> <span class="o">-&gt;</span>
  <span class="n">t</span> <span class="o">-&gt;</span>
  <span class="nn">Ndarray</span><span class="p">.</span><span class="n">t</span>
</code></pre></div>

<p>Learn a NMF model for the data X and returns the transformed data.</p>
<p>This is more efficient than calling fit followed by transform.</p>
<h4>Parameters</h4>
<details class="info" open="open"><summary>X : {array-like, sparse matrix}, shape (n_samples, n_features)</summary><p>Data matrix to be decomposed</p>
</details>
<details class="info" open="open"><summary>y : Ignored</summary></details>
<details class="info" open="open"><summary>W : array-like, shape (n_samples, n_components)</summary><p>If init='custom', it is used as initial guess for the solution.</p>
</details>
<details class="info" open="open"><summary>H : array-like, shape (n_components, n_features)</summary><p>If init='custom', it is used as initial guess for the solution.</p>
</details>
<h4>Returns</h4>
<details class="info" open="open"><summary>W : array, shape (n_samples, n_components)</summary><p>Transformed data.</p>
</details>
</details>
<h3 id="get_params_8">get_params<a class="headerlink" href="#get_params_8" title="Permanent link">&para;</a></h3>
<details class="note" open="open"><summary>method</summary><div class="highlight"><pre><span></span><code><span class="k">val</span> <span class="n">get_params</span> <span class="o">:</span>
  <span class="o">?</span><span class="n">deep</span><span class="o">:</span><span class="kt">bool</span> <span class="o">-&gt;</span>
  <span class="n">t</span> <span class="o">-&gt;</span>
  <span class="nn">Py</span><span class="p">.</span><span class="nn">Object</span><span class="p">.</span><span class="n">t</span>
</code></pre></div>

<p>Get parameters for this estimator.</p>
<h4>Parameters</h4>
<details class="info" open="open"><summary>deep : bool, default=True</summary><p>If True, will return the parameters for this estimator and
contained subobjects that are estimators.</p>
</details>
<h4>Returns</h4>
<details class="info" open="open"><summary>params : mapping of string to any</summary><p>Parameter names mapped to their values.</p>
</details>
</details>
<h3 id="inverse_transform_3">inverse_transform<a class="headerlink" href="#inverse_transform_3" title="Permanent link">&para;</a></h3>
<details class="note" open="open"><summary>method</summary><div class="highlight"><pre><span></span><code><span class="k">val</span> <span class="n">inverse_transform</span> <span class="o">:</span>
  <span class="n">w</span><span class="o">:[`</span><span class="nc">Ndarray</span> <span class="k">of</span> <span class="nn">Ndarray</span><span class="p">.</span><span class="n">t</span> <span class="o">|</span> <span class="o">`</span><span class="nc">SparseMatrix</span> <span class="k">of</span> <span class="nn">Csr_matrix</span><span class="p">.</span><span class="n">t</span><span class="o">]</span> <span class="o">-&gt;</span>
  <span class="n">t</span> <span class="o">-&gt;</span>
  <span class="nn">Py</span><span class="p">.</span><span class="nn">Object</span><span class="p">.</span><span class="n">t</span>
</code></pre></div>

<p>Transform data back to its original space.</p>
<h4>Parameters</h4>
<details class="info" open="open"><summary>W : {array-like, sparse matrix}, shape (n_samples, n_components)</summary><p>Transformed data matrix</p>
</details>
<h4>Returns</h4>
<details class="info" open="open"><summary>X : {array-like, sparse matrix}, shape (n_samples, n_features)</summary><p>Data matrix of original shape</p>
</details>
<p>.. versionadded:: 0.18</p>
</details>
<h3 id="set_params_8">set_params<a class="headerlink" href="#set_params_8" title="Permanent link">&para;</a></h3>
<details class="note" open="open"><summary>method</summary><div class="highlight"><pre><span></span><code><span class="k">val</span> <span class="n">set_params</span> <span class="o">:</span>
  <span class="o">?</span><span class="n">params</span><span class="o">:(</span><span class="kt">string</span> <span class="o">*</span> <span class="nn">Py</span><span class="p">.</span><span class="nn">Object</span><span class="p">.</span><span class="n">t</span><span class="o">)</span> <span class="kt">list</span> <span class="o">-&gt;</span>
  <span class="n">t</span> <span class="o">-&gt;</span>
  <span class="n">t</span>
</code></pre></div>

<p>Set the parameters of this estimator.</p>
<p>The method works on simple estimators as well as on nested objects
(such as pipelines). The latter have parameters of the form
<code>&lt;component&gt;__&lt;parameter&gt;</code> so that it's possible to update each
component of a nested object.</p>
<h4>Parameters</h4>
<details class="info" open="open"><summary>**params : dict</summary><p>Estimator parameters.</p>
</details>
<h4>Returns</h4>
<details class="info" open="open"><summary>self : object</summary><p>Estimator instance.</p>
</details>
</details>
<h3 id="transform_8">transform<a class="headerlink" href="#transform_8" title="Permanent link">&para;</a></h3>
<details class="note" open="open"><summary>method</summary><div class="highlight"><pre><span></span><code><span class="k">val</span> <span class="n">transform</span> <span class="o">:</span>
  <span class="n">x</span><span class="o">:[`</span><span class="nc">Ndarray</span> <span class="k">of</span> <span class="nn">Ndarray</span><span class="p">.</span><span class="n">t</span> <span class="o">|</span> <span class="o">`</span><span class="nc">SparseMatrix</span> <span class="k">of</span> <span class="nn">Csr_matrix</span><span class="p">.</span><span class="n">t</span><span class="o">]</span> <span class="o">-&gt;</span>
  <span class="n">t</span> <span class="o">-&gt;</span>
  <span class="nn">Ndarray</span><span class="p">.</span><span class="n">t</span>
</code></pre></div>

<p>Transform the data X according to the fitted NMF model</p>
<h4>Parameters</h4>
<details class="info" open="open"><summary>X : {array-like, sparse matrix}, shape (n_samples, n_features)</summary><p>Data matrix to be transformed by the model</p>
</details>
<h4>Returns</h4>
<details class="info" open="open"><summary>W : array, shape (n_samples, n_components)</summary><p>Transformed data</p>
</details>
</details>
<h3 id="components__7">components_<a class="headerlink" href="#components__7" title="Permanent link">&para;</a></h3>
<details class="note" open="open"><summary>attribute</summary><div class="highlight"><pre><span></span><code><span class="k">val</span> <span class="n">components_</span> <span class="o">:</span> <span class="n">t</span> <span class="o">-&gt;</span> <span class="nn">Ndarray</span><span class="p">.</span><span class="n">t</span>
</code></pre></div>

<p>This attribute is documented in <code>create</code> above.</p>
</details>
<h3 id="n_components__1">n_components_<a class="headerlink" href="#n_components__1" title="Permanent link">&para;</a></h3>
<details class="note" open="open"><summary>attribute</summary><div class="highlight"><pre><span></span><code><span class="k">val</span> <span class="n">n_components_</span> <span class="o">:</span> <span class="n">t</span> <span class="o">-&gt;</span> <span class="kt">int</span>
</code></pre></div>

<p>This attribute is documented in <code>create</code> above.</p>
</details>
<h3 id="reconstruction_err_">reconstruction_err_<a class="headerlink" href="#reconstruction_err_" title="Permanent link">&para;</a></h3>
<details class="note" open="open"><summary>attribute</summary><div class="highlight"><pre><span></span><code><span class="k">val</span> <span class="n">reconstruction_err_</span> <span class="o">:</span> <span class="n">t</span> <span class="o">-&gt;</span> <span class="nn">Py</span><span class="p">.</span><span class="nn">Object</span><span class="p">.</span><span class="n">t</span>
</code></pre></div>

<p>This attribute is documented in <code>create</code> above.</p>
</details>
<h3 id="n_iter__6">n_iter_<a class="headerlink" href="#n_iter__6" title="Permanent link">&para;</a></h3>
<details class="note" open="open"><summary>attribute</summary><div class="highlight"><pre><span></span><code><span class="k">val</span> <span class="n">n_iter_</span> <span class="o">:</span> <span class="n">t</span> <span class="o">-&gt;</span> <span class="kt">int</span>
</code></pre></div>

<p>This attribute is documented in <code>create</code> above.</p>
</details>
<h3 id="to_string_8">to_string<a class="headerlink" href="#to_string_8" title="Permanent link">&para;</a></h3>
<details class="note" open="open"><summary>method</summary><div class="highlight"><pre><span></span><code><span class="k">val</span> <span class="n">to_string</span><span class="o">:</span> <span class="n">t</span> <span class="o">-&gt;</span> <span class="kt">string</span>
</code></pre></div>

<p>Print the object to a human-readable representation.</p>
</details>
<h3 id="show_8">show<a class="headerlink" href="#show_8" title="Permanent link">&para;</a></h3>
<details class="note" open="open"><summary>method</summary><div class="highlight"><pre><span></span><code><span class="k">val</span> <span class="n">show</span><span class="o">:</span> <span class="n">t</span> <span class="o">-&gt;</span> <span class="kt">string</span>
</code></pre></div>

<p>Print the object to a human-readable representation.</p>
</details>
<h3 id="pp_8">pp<a class="headerlink" href="#pp_8" title="Permanent link">&para;</a></h3>
<details class="note" open="open"><summary>method</summary><div class="highlight"><pre><span></span><code><span class="k">val</span> <span class="n">pp</span><span class="o">:</span> <span class="nn">Format</span><span class="p">.</span><span class="n">formatter</span> <span class="o">-&gt;</span> <span class="n">t</span> <span class="o">-&gt;</span> <span class="kt">unit</span>
</code></pre></div>

<p>Pretty-print the object to a formatter.</p>
</details>
<h2 id="module-sklearndecompositionpca">module Sklearn.​Decomposition.​PCA<a class="headerlink" href="#module-sklearndecompositionpca" title="Permanent link">&para;</a></h2>
<div class="highlight"><pre><span></span><code><span class="k">type</span> <span class="n">t</span>
</code></pre></div>

<h3 id="create_9">create<a class="headerlink" href="#create_9" title="Permanent link">&para;</a></h3>
<details class="note" open="open"><summary>constructor and attributes</summary><div class="highlight"><pre><span></span><code><span class="k">val</span> <span class="n">create</span> <span class="o">:</span>
  <span class="o">?</span><span class="n">n_components</span><span class="o">:[`</span><span class="nc">Int</span> <span class="k">of</span> <span class="kt">int</span> <span class="o">|</span> <span class="o">`</span><span class="nc">Float</span> <span class="k">of</span> <span class="kt">float</span> <span class="o">|</span> <span class="o">`</span><span class="nc">String</span> <span class="k">of</span> <span class="kt">string</span> <span class="o">|</span> <span class="o">`</span><span class="nc">None</span><span class="o">]</span> <span class="o">-&gt;</span>
  <span class="o">?</span><span class="n">copy</span><span class="o">:</span><span class="kt">bool</span> <span class="o">-&gt;</span>
  <span class="o">?</span><span class="n">whiten</span><span class="o">:</span><span class="kt">bool</span> <span class="o">-&gt;</span>
  <span class="o">?</span><span class="n">svd_solver</span><span class="o">:[`</span><span class="nc">Auto</span> <span class="o">|</span> <span class="o">`</span><span class="nc">Full</span> <span class="o">|</span> <span class="o">`</span><span class="nc">Arpack</span> <span class="o">|</span> <span class="o">`</span><span class="nc">Randomized</span><span class="o">]</span> <span class="o">-&gt;</span>
  <span class="o">?</span><span class="n">tol</span><span class="o">:</span><span class="kt">float</span> <span class="o">-&gt;</span>
  <span class="o">?</span><span class="n">iterated_power</span><span class="o">:[`</span><span class="nc">Int</span> <span class="k">of</span> <span class="kt">int</span> <span class="o">|</span> <span class="o">`</span><span class="nc">Auto</span><span class="o">]</span> <span class="o">-&gt;</span>
  <span class="o">?</span><span class="n">random_state</span><span class="o">:[`</span><span class="nc">Int</span> <span class="k">of</span> <span class="kt">int</span> <span class="o">|</span> <span class="o">`</span><span class="nc">RandomState</span> <span class="k">of</span> <span class="nn">Py</span><span class="p">.</span><span class="nn">Object</span><span class="p">.</span><span class="n">t</span> <span class="o">|</span> <span class="o">`</span><span class="nc">None</span><span class="o">]</span> <span class="o">-&gt;</span>
  <span class="kt">unit</span> <span class="o">-&gt;</span>
  <span class="n">t</span>
</code></pre></div>

<p>Principal component analysis (PCA).</p>
<p>Linear dimensionality reduction using Singular Value Decomposition of the
data to project it to a lower dimensional space. The input data is centered
but not scaled for each feature before applying the SVD.</p>
<p>It uses the LAPACK implementation of the full SVD or a randomized truncated
SVD by the method of Halko et al. 2009, depending on the shape of the input
data and the number of components to extract.</p>
<p>It can also use the scipy.sparse.linalg ARPACK implementation of the
truncated SVD.</p>
<p>Notice that this class does not support sparse input. See
:class:<code>TruncatedSVD</code> for an alternative with sparse data.</p>
<p>Read more in the :ref:<code>User Guide &lt;PCA&gt;</code>.</p>
<h4>Parameters</h4>
<details class="info" open="open"><summary>n_components : int, float, None or str</summary><p>Number of components to keep.
if n_components is not set all components are kept::</p>
<div class="codehilite"><pre><span></span><code>n_components == min(n_samples, n_features)
</code></pre></div>


<p>If <code>n_components == 'mle'</code> and <code>svd_solver == 'full'</code>, Minka's
MLE is used to guess the dimension. Use of <code>n_components == 'mle'</code>
will interpret <code>svd_solver == 'auto'</code> as <code>svd_solver == 'full'</code>.</p>
<p>If <code>0 &lt; n_components &lt; 1</code> and <code>svd_solver == 'full'</code>, select the
number of components such that the amount of variance that needs to be
explained is greater than the percentage specified by n_components.</p>
<p>If <code>svd_solver == 'arpack'</code>, the number of components must be
strictly less than the minimum of n_features and n_samples.</p>
<p>Hence, the None case results in::</p>
<div class="codehilite"><pre><span></span><code>n_components == min(n_samples, n_features) - 1
</code></pre></div>


</details>
<details class="info" open="open"><summary>copy : bool, default=True</summary><p>If False, data passed to fit are overwritten and running
fit(X).transform(X) will not yield the expected results,
use fit_transform(X) instead.</p>
</details>
<details class="info" open="open"><summary>whiten : bool, optional (default False)</summary><p>When True (False by default) the <code>components_</code> vectors are multiplied
by the square root of n_samples and then divided by the singular values
to ensure uncorrelated outputs with unit component-wise variances.</p>
<p>Whitening will remove some information from the transformed signal
(the relative variance scales of the components) but can sometime
improve the predictive accuracy of the downstream estimators by
making their data respect some hard-wired assumptions.</p>
</details>
<details class="info" open="open"><summary>svd_solver : str {'auto', 'full', 'arpack', 'randomized'}</summary><p>If auto :
    The solver is selected by a default policy based on <code>X.shape</code> and
    <code>n_components</code>: if the input data is larger than 500x500 and the
    number of components to extract is lower than 80% of the smallest
    dimension of the data, then the more efficient 'randomized'
    method is enabled. Otherwise the exact full SVD is computed and
    optionally truncated afterwards.
If full :
    run exact full SVD calling the standard LAPACK solver via
    <code>scipy.linalg.svd</code> and select the components by postprocessing
If arpack :
    run SVD truncated to n_components calling ARPACK solver via
    <code>scipy.sparse.linalg.svds</code>. It requires strictly
    0 &lt; n_components &lt; min(X.shape)
If randomized :
    run randomized SVD by the method of Halko et al.</p>
<p>.. versionadded:: 0.18.0</p>
</details>
<details class="info" open="open"><summary>tol : float &gt;= 0, optional (default .0)</summary><p>Tolerance for singular values computed by svd_solver == 'arpack'.</p>
<p>.. versionadded:: 0.18.0</p>
</details>
<details class="info" open="open"><summary>iterated_power : int &gt;= 0, or 'auto', (default 'auto')</summary><p>Number of iterations for the power method computed by
svd_solver == 'randomized'.</p>
<p>.. versionadded:: 0.18.0</p>
</details>
<details class="info" open="open"><summary>random_state : int, RandomState instance or None, optional (default None)</summary><p>If int, random_state is the seed used by the random number generator;
If RandomState instance, random_state is the random number generator;
If None, the random number generator is the RandomState instance used
by <code>np.random</code>. Used when <code>svd_solver</code> == 'arpack' or 'randomized'.</p>
<p>.. versionadded:: 0.18.0</p>
</details>
<h4>Attributes</h4>
<details class="info" open="open"><summary>components_ : array, shape (n_components, n_features)</summary><p>Principal axes in feature space, representing the directions of
maximum variance in the data. The components are sorted by
<code>explained_variance_</code>.</p>
</details>
<details class="info" open="open"><summary>explained_variance_ : array, shape (n_components,)</summary><p>The amount of variance explained by each of the selected components.</p>
<p>Equal to n_components largest eigenvalues
of the covariance matrix of X.</p>
<p>.. versionadded:: 0.18</p>
</details>
<details class="info" open="open"><summary>explained_variance_ratio_ : array, shape (n_components,)</summary><p>Percentage of variance explained by each of the selected components.</p>
<p>If <code>n_components</code> is not set then all components are stored and the
sum of the ratios is equal to 1.0.</p>
</details>
<details class="info" open="open"><summary>singular_values_ : array, shape (n_components,)</summary><p>The singular values corresponding to each of the selected components.
The singular values are equal to the 2-norms of the <code>n_components</code>
variables in the lower-dimensional space.</p>
<p>.. versionadded:: 0.19</p>
</details>
<details class="info" open="open"><summary>mean_ : array, shape (n_features,)</summary><p>Per-feature empirical mean, estimated from the training set.</p>
<p>Equal to <code>X.mean(axis=0)</code>.</p>
</details>
<details class="info" open="open"><summary>n_components_ : int</summary><p>The estimated number of components. When n_components is set
to 'mle' or a number between 0 and 1 (with svd_solver == 'full') this
number is estimated from input data. Otherwise it equals the parameter
n_components, or the lesser value of n_features and n_samples
if n_components is None.</p>
</details>
<details class="info" open="open"><summary>n_features_ : int</summary><p>Number of features in the training data.</p>
</details>
<details class="info" open="open"><summary>n_samples_ : int</summary><p>Number of samples in the training data.</p>
</details>
<details class="info" open="open"><summary>noise_variance_ : float</summary><p>The estimated noise covariance following the Probabilistic PCA model
from Tipping and Bishop 1999. See "Pattern Recognition and
Machine Learning" by C. Bishop, 12.2.1 p. 574 or</p>
</details>
<details class="info" open="open"><summary>http://www.miketipping.com/papers/met-mppca.pdf. It is required to</summary><p>compute the estimated data covariance and score samples.</p>
<p>Equal to the average of (min(n_features, n_samples) - n_components)
smallest eigenvalues of the covariance matrix of X.</p>
</details>
<h4>See Also</h4>
<details class="info" open="open"><summary>KernelPCA : Kernel Principal Component Analysis.</summary></details>
<details class="info" open="open"><summary>SparsePCA : Sparse Principal Component Analysis.</summary></details>
<details class="info" open="open"><summary>TruncatedSVD : Dimensionality reduction using truncated SVD.</summary></details>
<details class="info" open="open"><summary>IncrementalPCA : Incremental Principal Component Analysis.</summary></details>
<h4>References</h4>
<p>For n_components == 'mle', this class uses the method of <em>Minka, T. P.
"Automatic choice of dimensionality for PCA". In NIPS, pp. 598-604</em></p>
<p>Implements the probabilistic PCA model from:
Tipping, M. E., and Bishop, C. M. (1999). "Probabilistic principal
component analysis". Journal of the Royal Statistical Society:
Series B (Statistical Methodology), 61(3), 611-622.
via the score and score_samples methods.
See http://www.miketipping.com/papers/met-mppca.pdf</p>
<p>For svd_solver == 'arpack', refer to <code>scipy.sparse.linalg.svds</code>.</p>
<p>For svd_solver == 'randomized', see:
<em>Halko, N., Martinsson, P. G., and Tropp, J. A. (2011).
"Finding structure with randomness: Probabilistic algorithms for
constructing approximate matrix decompositions".
SIAM review, 53(2), 217-288.</em> and also
<em>Martinsson, P. G., Rokhlin, V., and Tygert, M. (2011).
"A randomized algorithm for the decomposition of matrices".
Applied and Computational Harmonic Analysis, 30(1), 47-68.</em></p>
<h4>Examples</h4>
<div class="highlight"><pre><span></span><code><span class="o">&gt;&gt;&gt;</span> <span class="kn">import</span> <span class="nn">numpy</span> <span class="k">as</span> <span class="nn">np</span>
<span class="o">&gt;&gt;&gt;</span> <span class="kn">from</span> <span class="nn">sklearn.decomposition</span> <span class="kn">import</span> <span class="n">PCA</span>
<span class="o">&gt;&gt;&gt;</span> <span class="n">X</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">array</span><span class="p">([[</span><span class="o">-</span><span class="mi">1</span><span class="p">,</span> <span class="o">-</span><span class="mi">1</span><span class="p">],</span> <span class="p">[</span><span class="o">-</span><span class="mi">2</span><span class="p">,</span> <span class="o">-</span><span class="mi">1</span><span class="p">],</span> <span class="p">[</span><span class="o">-</span><span class="mi">3</span><span class="p">,</span> <span class="o">-</span><span class="mi">2</span><span class="p">],</span> <span class="p">[</span><span class="mi">1</span><span class="p">,</span> <span class="mi">1</span><span class="p">],</span> <span class="p">[</span><span class="mi">2</span><span class="p">,</span> <span class="mi">1</span><span class="p">],</span> <span class="p">[</span><span class="mi">3</span><span class="p">,</span> <span class="mi">2</span><span class="p">]])</span>
<span class="o">&gt;&gt;&gt;</span> <span class="n">pca</span> <span class="o">=</span> <span class="n">PCA</span><span class="p">(</span><span class="n">n_components</span><span class="o">=</span><span class="mi">2</span><span class="p">)</span>
<span class="o">&gt;&gt;&gt;</span> <span class="n">pca</span><span class="o">.</span><span class="n">fit</span><span class="p">(</span><span class="n">X</span><span class="p">)</span>
<span class="n">PCA</span><span class="p">(</span><span class="n">n_components</span><span class="o">=</span><span class="mi">2</span><span class="p">)</span>
<span class="o">&gt;&gt;&gt;</span> <span class="nb">print</span><span class="p">(</span><span class="n">pca</span><span class="o">.</span><span class="n">explained_variance_ratio_</span><span class="p">)</span>
<span class="p">[</span><span class="mf">0.9924</span><span class="o">...</span> <span class="mf">0.0075</span><span class="o">...</span><span class="p">]</span>
<span class="o">&gt;&gt;&gt;</span> <span class="nb">print</span><span class="p">(</span><span class="n">pca</span><span class="o">.</span><span class="n">singular_values_</span><span class="p">)</span>
<span class="p">[</span><span class="mf">6.30061</span><span class="o">...</span> <span class="mf">0.54980</span><span class="o">...</span><span class="p">]</span>
</code></pre></div>

<div class="highlight"><pre><span></span><code><span class="o">&gt;&gt;&gt;</span> <span class="n">pca</span> <span class="o">=</span> <span class="n">PCA</span><span class="p">(</span><span class="n">n_components</span><span class="o">=</span><span class="mi">2</span><span class="p">,</span> <span class="n">svd_solver</span><span class="o">=</span><span class="s1">&#39;full&#39;</span><span class="p">)</span>
<span class="o">&gt;&gt;&gt;</span> <span class="n">pca</span><span class="o">.</span><span class="n">fit</span><span class="p">(</span><span class="n">X</span><span class="p">)</span>
<span class="n">PCA</span><span class="p">(</span><span class="n">n_components</span><span class="o">=</span><span class="mi">2</span><span class="p">,</span> <span class="n">svd_solver</span><span class="o">=</span><span class="s1">&#39;full&#39;</span><span class="p">)</span>
<span class="o">&gt;&gt;&gt;</span> <span class="nb">print</span><span class="p">(</span><span class="n">pca</span><span class="o">.</span><span class="n">explained_variance_ratio_</span><span class="p">)</span>
<span class="p">[</span><span class="mf">0.9924</span><span class="o">...</span> <span class="mf">0.00755</span><span class="o">...</span><span class="p">]</span>
<span class="o">&gt;&gt;&gt;</span> <span class="nb">print</span><span class="p">(</span><span class="n">pca</span><span class="o">.</span><span class="n">singular_values_</span><span class="p">)</span>
<span class="p">[</span><span class="mf">6.30061</span><span class="o">...</span> <span class="mf">0.54980</span><span class="o">...</span><span class="p">]</span>
</code></pre></div>

<div class="highlight"><pre><span></span><code><span class="o">&gt;&gt;&gt;</span> <span class="n">pca</span> <span class="o">=</span> <span class="n">PCA</span><span class="p">(</span><span class="n">n_components</span><span class="o">=</span><span class="mi">1</span><span class="p">,</span> <span class="n">svd_solver</span><span class="o">=</span><span class="s1">&#39;arpack&#39;</span><span class="p">)</span>
<span class="o">&gt;&gt;&gt;</span> <span class="n">pca</span><span class="o">.</span><span class="n">fit</span><span class="p">(</span><span class="n">X</span><span class="p">)</span>
<span class="n">PCA</span><span class="p">(</span><span class="n">n_components</span><span class="o">=</span><span class="mi">1</span><span class="p">,</span> <span class="n">svd_solver</span><span class="o">=</span><span class="s1">&#39;arpack&#39;</span><span class="p">)</span>
<span class="o">&gt;&gt;&gt;</span> <span class="nb">print</span><span class="p">(</span><span class="n">pca</span><span class="o">.</span><span class="n">explained_variance_ratio_</span><span class="p">)</span>
<span class="p">[</span><span class="mf">0.99244</span><span class="o">...</span><span class="p">]</span>
<span class="o">&gt;&gt;&gt;</span> <span class="nb">print</span><span class="p">(</span><span class="n">pca</span><span class="o">.</span><span class="n">singular_values_</span><span class="p">)</span>
<span class="p">[</span><span class="mf">6.30061</span><span class="o">...</span><span class="p">]</span>
</code></pre></div>

</details>
<h3 id="fit_9">fit<a class="headerlink" href="#fit_9" title="Permanent link">&para;</a></h3>
<details class="note" open="open"><summary>method</summary><div class="highlight"><pre><span></span><code><span class="k">val</span> <span class="n">fit</span> <span class="o">:</span>
  <span class="o">?</span><span class="n">y</span><span class="o">:</span><span class="nn">Py</span><span class="p">.</span><span class="nn">Object</span><span class="p">.</span><span class="n">t</span> <span class="o">-&gt;</span>
  <span class="n">x</span><span class="o">:</span><span class="nn">Ndarray</span><span class="p">.</span><span class="n">t</span> <span class="o">-&gt;</span>
  <span class="n">t</span> <span class="o">-&gt;</span>
  <span class="n">t</span>
</code></pre></div>

<p>Fit the model with X.</p>
<h4>Parameters</h4>
<details class="info" open="open"><summary>X : array-like, shape (n_samples, n_features)</summary><p>Training data, where n_samples is the number of samples
and n_features is the number of features.</p>
</details>
<details class="info" open="open"><summary>y : None</summary><p>Ignored variable.</p>
</details>
<h4>Returns</h4>
<details class="info" open="open"><summary>self : object</summary><p>Returns the instance itself.</p>
</details>
</details>
<h3 id="fit_transform_9">fit_transform<a class="headerlink" href="#fit_transform_9" title="Permanent link">&para;</a></h3>
<details class="note" open="open"><summary>method</summary><div class="highlight"><pre><span></span><code><span class="k">val</span> <span class="n">fit_transform</span> <span class="o">:</span>
  <span class="o">?</span><span class="n">y</span><span class="o">:</span><span class="nn">Py</span><span class="p">.</span><span class="nn">Object</span><span class="p">.</span><span class="n">t</span> <span class="o">-&gt;</span>
  <span class="n">x</span><span class="o">:</span><span class="nn">Ndarray</span><span class="p">.</span><span class="n">t</span> <span class="o">-&gt;</span>
  <span class="n">t</span> <span class="o">-&gt;</span>
  <span class="nn">Ndarray</span><span class="p">.</span><span class="n">t</span>
</code></pre></div>

<p>Fit the model with X and apply the dimensionality reduction on X.</p>
<h4>Parameters</h4>
<details class="info" open="open"><summary>X : array-like, shape (n_samples, n_features)</summary><p>Training data, where n_samples is the number of samples
and n_features is the number of features.</p>
</details>
<details class="info" open="open"><summary>y : None</summary><p>Ignored variable.</p>
</details>
<h4>Returns</h4>
<details class="info" open="open"><summary>X_new : array-like, shape (n_samples, n_components)</summary><p>Transformed values.</p>
</details>
<h4>Notes</h4>
<p>This method returns a Fortran-ordered array. To convert it to a
C-ordered array, use 'np.ascontiguousarray'.</p>
</details>
<h3 id="get_covariance_2">get_covariance<a class="headerlink" href="#get_covariance_2" title="Permanent link">&para;</a></h3>
<details class="note" open="open"><summary>method</summary><div class="highlight"><pre><span></span><code><span class="k">val</span> <span class="n">get_covariance</span> <span class="o">:</span>
  <span class="n">t</span> <span class="o">-&gt;</span>
  <span class="nn">Ndarray</span><span class="p">.</span><span class="n">t</span>
</code></pre></div>

<p>Compute data covariance with the generative model.</p>
<p><code>cov = components_.T * S**2 * components_ + sigma2 * eye(n_features)</code>
where S**2 contains the explained variances, and sigma2 contains the
noise variances.</p>
<h4>Returns</h4>
<details class="info" open="open"><summary>cov : array, shape=(n_features, n_features)</summary><p>Estimated covariance of data.</p>
</details>
</details>
<h3 id="get_params_9">get_params<a class="headerlink" href="#get_params_9" title="Permanent link">&para;</a></h3>
<details class="note" open="open"><summary>method</summary><div class="highlight"><pre><span></span><code><span class="k">val</span> <span class="n">get_params</span> <span class="o">:</span>
  <span class="o">?</span><span class="n">deep</span><span class="o">:</span><span class="kt">bool</span> <span class="o">-&gt;</span>
  <span class="n">t</span> <span class="o">-&gt;</span>
  <span class="nn">Py</span><span class="p">.</span><span class="nn">Object</span><span class="p">.</span><span class="n">t</span>
</code></pre></div>

<p>Get parameters for this estimator.</p>
<h4>Parameters</h4>
<details class="info" open="open"><summary>deep : bool, default=True</summary><p>If True, will return the parameters for this estimator and
contained subobjects that are estimators.</p>
</details>
<h4>Returns</h4>
<details class="info" open="open"><summary>params : mapping of string to any</summary><p>Parameter names mapped to their values.</p>
</details>
</details>
<h3 id="get_precision_2">get_precision<a class="headerlink" href="#get_precision_2" title="Permanent link">&para;</a></h3>
<details class="note" open="open"><summary>method</summary><div class="highlight"><pre><span></span><code><span class="k">val</span> <span class="n">get_precision</span> <span class="o">:</span>
  <span class="n">t</span> <span class="o">-&gt;</span>
  <span class="nn">Ndarray</span><span class="p">.</span><span class="n">t</span>
</code></pre></div>

<p>Compute data precision matrix with the generative model.</p>
<p>Equals the inverse of the covariance but computed with
the matrix inversion lemma for efficiency.</p>
<h4>Returns</h4>
<details class="info" open="open"><summary>precision : array, shape=(n_features, n_features)</summary><p>Estimated precision of data.</p>
</details>
</details>
<h3 id="inverse_transform_4">inverse_transform<a class="headerlink" href="#inverse_transform_4" title="Permanent link">&para;</a></h3>
<details class="note" open="open"><summary>method</summary><div class="highlight"><pre><span></span><code><span class="k">val</span> <span class="n">inverse_transform</span> <span class="o">:</span>
  <span class="n">x</span><span class="o">:</span><span class="nn">Ndarray</span><span class="p">.</span><span class="n">t</span> <span class="o">-&gt;</span>
  <span class="n">t</span> <span class="o">-&gt;</span>
  <span class="nn">Py</span><span class="p">.</span><span class="nn">Object</span><span class="p">.</span><span class="n">t</span>
</code></pre></div>

<p>Transform data back to its original space.</p>
<p>In other words, return an input X_original whose transform would be X.</p>
<h4>Parameters</h4>
<details class="info" open="open"><summary>X : array-like, shape (n_samples, n_components)</summary><p>New data, where n_samples is the number of samples
and n_components is the number of components.</p>
</details>
<h4>Returns</h4>
<p>X_original array-like, shape (n_samples, n_features)</p>
<h4>Notes</h4>
<p>If whitening is enabled, inverse_transform will compute the
exact inverse operation, which includes reversing whitening.</p>
</details>
<h3 id="score_2">score<a class="headerlink" href="#score_2" title="Permanent link">&para;</a></h3>
<details class="note" open="open"><summary>method</summary><div class="highlight"><pre><span></span><code><span class="k">val</span> <span class="n">score</span> <span class="o">:</span>
  <span class="o">?</span><span class="n">y</span><span class="o">:</span><span class="nn">Py</span><span class="p">.</span><span class="nn">Object</span><span class="p">.</span><span class="n">t</span> <span class="o">-&gt;</span>
  <span class="n">x</span><span class="o">:</span><span class="nn">Ndarray</span><span class="p">.</span><span class="n">t</span> <span class="o">-&gt;</span>
  <span class="n">t</span> <span class="o">-&gt;</span>
  <span class="kt">float</span>
</code></pre></div>

<p>Return the average log-likelihood of all samples.</p>
<p>See. "Pattern Recognition and Machine Learning"
by C. Bishop, 12.2.1 p. 574
or http://www.miketipping.com/papers/met-mppca.pdf</p>
<h4>Parameters</h4>
<details class="info" open="open"><summary>X : array, shape(n_samples, n_features)</summary><p>The data.</p>
</details>
<details class="info" open="open"><summary>y : None</summary><p>Ignored variable.</p>
</details>
<h4>Returns</h4>
<details class="info" open="open"><summary>ll : float</summary><p>Average log-likelihood of the samples under the current model.</p>
</details>
</details>
<h3 id="score_samples_1">score_samples<a class="headerlink" href="#score_samples_1" title="Permanent link">&para;</a></h3>
<details class="note" open="open"><summary>method</summary><div class="highlight"><pre><span></span><code><span class="k">val</span> <span class="n">score_samples</span> <span class="o">:</span>
  <span class="n">x</span><span class="o">:</span><span class="nn">Ndarray</span><span class="p">.</span><span class="n">t</span> <span class="o">-&gt;</span>
  <span class="n">t</span> <span class="o">-&gt;</span>
  <span class="nn">Ndarray</span><span class="p">.</span><span class="n">t</span>
</code></pre></div>

<p>Return the log-likelihood of each sample.</p>
<p>See. "Pattern Recognition and Machine Learning"
by C. Bishop, 12.2.1 p. 574
or http://www.miketipping.com/papers/met-mppca.pdf</p>
<h4>Parameters</h4>
<details class="info" open="open"><summary>X : array, shape(n_samples, n_features)</summary><p>The data.</p>
</details>
<h4>Returns</h4>
<details class="info" open="open"><summary>ll : array, shape (n_samples,)</summary><p>Log-likelihood of each sample under the current model.</p>
</details>
</details>
<h3 id="set_params_9">set_params<a class="headerlink" href="#set_params_9" title="Permanent link">&para;</a></h3>
<details class="note" open="open"><summary>method</summary><div class="highlight"><pre><span></span><code><span class="k">val</span> <span class="n">set_params</span> <span class="o">:</span>
  <span class="o">?</span><span class="n">params</span><span class="o">:(</span><span class="kt">string</span> <span class="o">*</span> <span class="nn">Py</span><span class="p">.</span><span class="nn">Object</span><span class="p">.</span><span class="n">t</span><span class="o">)</span> <span class="kt">list</span> <span class="o">-&gt;</span>
  <span class="n">t</span> <span class="o">-&gt;</span>
  <span class="n">t</span>
</code></pre></div>

<p>Set the parameters of this estimator.</p>
<p>The method works on simple estimators as well as on nested objects
(such as pipelines). The latter have parameters of the form
<code>&lt;component&gt;__&lt;parameter&gt;</code> so that it's possible to update each
component of a nested object.</p>
<h4>Parameters</h4>
<details class="info" open="open"><summary>**params : dict</summary><p>Estimator parameters.</p>
</details>
<h4>Returns</h4>
<details class="info" open="open"><summary>self : object</summary><p>Estimator instance.</p>
</details>
</details>
<h3 id="transform_9">transform<a class="headerlink" href="#transform_9" title="Permanent link">&para;</a></h3>
<details class="note" open="open"><summary>method</summary><div class="highlight"><pre><span></span><code><span class="k">val</span> <span class="n">transform</span> <span class="o">:</span>
  <span class="n">x</span><span class="o">:</span><span class="nn">Ndarray</span><span class="p">.</span><span class="n">t</span> <span class="o">-&gt;</span>
  <span class="n">t</span> <span class="o">-&gt;</span>
  <span class="nn">Ndarray</span><span class="p">.</span><span class="n">t</span>
</code></pre></div>

<p>Apply dimensionality reduction to X.</p>
<p>X is projected on the first principal components previously extracted
from a training set.</p>
<h4>Parameters</h4>
<details class="info" open="open"><summary>X : array-like, shape (n_samples, n_features)</summary><p>New data, where n_samples is the number of samples
and n_features is the number of features.</p>
</details>
<h4>Returns</h4>
<details class="info" open="open"><summary>X_new : array-like, shape (n_samples, n_components)</summary></details>
<h4>Examples</h4>
<div class="highlight"><pre><span></span><code><span class="o">&gt;&gt;&gt;</span> <span class="kn">import</span> <span class="nn">numpy</span> <span class="k">as</span> <span class="nn">np</span>
<span class="o">&gt;&gt;&gt;</span> <span class="kn">from</span> <span class="nn">sklearn.decomposition</span> <span class="kn">import</span> <span class="n">IncrementalPCA</span>
<span class="o">&gt;&gt;&gt;</span> <span class="n">X</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">array</span><span class="p">([[</span><span class="o">-</span><span class="mi">1</span><span class="p">,</span> <span class="o">-</span><span class="mi">1</span><span class="p">],</span> <span class="p">[</span><span class="o">-</span><span class="mi">2</span><span class="p">,</span> <span class="o">-</span><span class="mi">1</span><span class="p">],</span> <span class="p">[</span><span class="o">-</span><span class="mi">3</span><span class="p">,</span> <span class="o">-</span><span class="mi">2</span><span class="p">],</span> <span class="p">[</span><span class="mi">1</span><span class="p">,</span> <span class="mi">1</span><span class="p">],</span> <span class="p">[</span><span class="mi">2</span><span class="p">,</span> <span class="mi">1</span><span class="p">],</span> <span class="p">[</span><span class="mi">3</span><span class="p">,</span> <span class="mi">2</span><span class="p">]])</span>
<span class="o">&gt;&gt;&gt;</span> <span class="n">ipca</span> <span class="o">=</span> <span class="n">IncrementalPCA</span><span class="p">(</span><span class="n">n_components</span><span class="o">=</span><span class="mi">2</span><span class="p">,</span> <span class="n">batch_size</span><span class="o">=</span><span class="mi">3</span><span class="p">)</span>
<span class="o">&gt;&gt;&gt;</span> <span class="n">ipca</span><span class="o">.</span><span class="n">fit</span><span class="p">(</span><span class="n">X</span><span class="p">)</span>
<span class="n">IncrementalPCA</span><span class="p">(</span><span class="n">batch_size</span><span class="o">=</span><span class="mi">3</span><span class="p">,</span> <span class="n">n_components</span><span class="o">=</span><span class="mi">2</span><span class="p">)</span>
<span class="o">&gt;&gt;&gt;</span> <span class="n">ipca</span><span class="o">.</span><span class="n">transform</span><span class="p">(</span><span class="n">X</span><span class="p">)</span> <span class="c1"># doctest: +SKIP</span>
</code></pre></div>

</details>
<h3 id="components__8">components_<a class="headerlink" href="#components__8" title="Permanent link">&para;</a></h3>
<details class="note" open="open"><summary>attribute</summary><div class="highlight"><pre><span></span><code><span class="k">val</span> <span class="n">components_</span> <span class="o">:</span> <span class="n">t</span> <span class="o">-&gt;</span> <span class="nn">Ndarray</span><span class="p">.</span><span class="n">t</span>
</code></pre></div>

<p>This attribute is documented in <code>create</code> above.</p>
</details>
<h3 id="explained_variance__1">explained_variance_<a class="headerlink" href="#explained_variance__1" title="Permanent link">&para;</a></h3>
<details class="note" open="open"><summary>attribute</summary><div class="highlight"><pre><span></span><code><span class="k">val</span> <span class="n">explained_variance_</span> <span class="o">:</span> <span class="n">t</span> <span class="o">-&gt;</span> <span class="nn">Ndarray</span><span class="p">.</span><span class="n">t</span>
</code></pre></div>

<p>This attribute is documented in <code>create</code> above.</p>
</details>
<h3 id="explained_variance_ratio__1">explained_variance_ratio_<a class="headerlink" href="#explained_variance_ratio__1" title="Permanent link">&para;</a></h3>
<details class="note" open="open"><summary>attribute</summary><div class="highlight"><pre><span></span><code><span class="k">val</span> <span class="n">explained_variance_ratio_</span> <span class="o">:</span> <span class="n">t</span> <span class="o">-&gt;</span> <span class="nn">Ndarray</span><span class="p">.</span><span class="n">t</span>
</code></pre></div>

<p>This attribute is documented in <code>create</code> above.</p>
</details>
<h3 id="singular_values__1">singular_values_<a class="headerlink" href="#singular_values__1" title="Permanent link">&para;</a></h3>
<details class="note" open="open"><summary>attribute</summary><div class="highlight"><pre><span></span><code><span class="k">val</span> <span class="n">singular_values_</span> <span class="o">:</span> <span class="n">t</span> <span class="o">-&gt;</span> <span class="nn">Ndarray</span><span class="p">.</span><span class="n">t</span>
</code></pre></div>

<p>This attribute is documented in <code>create</code> above.</p>
</details>
<h3 id="mean__4">mean_<a class="headerlink" href="#mean__4" title="Permanent link">&para;</a></h3>
<details class="note" open="open"><summary>attribute</summary><div class="highlight"><pre><span></span><code><span class="k">val</span> <span class="n">mean_</span> <span class="o">:</span> <span class="n">t</span> <span class="o">-&gt;</span> <span class="nn">Ndarray</span><span class="p">.</span><span class="n">t</span>
</code></pre></div>

<p>This attribute is documented in <code>create</code> above.</p>
</details>
<h3 id="n_components__2">n_components_<a class="headerlink" href="#n_components__2" title="Permanent link">&para;</a></h3>
<details class="note" open="open"><summary>attribute</summary><div class="highlight"><pre><span></span><code><span class="k">val</span> <span class="n">n_components_</span> <span class="o">:</span> <span class="n">t</span> <span class="o">-&gt;</span> <span class="kt">int</span>
</code></pre></div>

<p>This attribute is documented in <code>create</code> above.</p>
</details>
<h3 id="n_features_">n_features_<a class="headerlink" href="#n_features_" title="Permanent link">&para;</a></h3>
<details class="note" open="open"><summary>attribute</summary><div class="highlight"><pre><span></span><code><span class="k">val</span> <span class="n">n_features_</span> <span class="o">:</span> <span class="n">t</span> <span class="o">-&gt;</span> <span class="kt">int</span>
</code></pre></div>

<p>This attribute is documented in <code>create</code> above.</p>
</details>
<h3 id="n_samples_">n_samples_<a class="headerlink" href="#n_samples_" title="Permanent link">&para;</a></h3>
<details class="note" open="open"><summary>attribute</summary><div class="highlight"><pre><span></span><code><span class="k">val</span> <span class="n">n_samples_</span> <span class="o">:</span> <span class="n">t</span> <span class="o">-&gt;</span> <span class="kt">int</span>
</code></pre></div>

<p>This attribute is documented in <code>create</code> above.</p>
</details>
<h3 id="noise_variance__2">noise_variance_<a class="headerlink" href="#noise_variance__2" title="Permanent link">&para;</a></h3>
<details class="note" open="open"><summary>attribute</summary><div class="highlight"><pre><span></span><code><span class="k">val</span> <span class="n">noise_variance_</span> <span class="o">:</span> <span class="n">t</span> <span class="o">-&gt;</span> <span class="kt">float</span>
</code></pre></div>

<p>This attribute is documented in <code>create</code> above.</p>
</details>
<h3 id="to_string_9">to_string<a class="headerlink" href="#to_string_9" title="Permanent link">&para;</a></h3>
<details class="note" open="open"><summary>method</summary><div class="highlight"><pre><span></span><code><span class="k">val</span> <span class="n">to_string</span><span class="o">:</span> <span class="n">t</span> <span class="o">-&gt;</span> <span class="kt">string</span>
</code></pre></div>

<p>Print the object to a human-readable representation.</p>
</details>
<h3 id="show_9">show<a class="headerlink" href="#show_9" title="Permanent link">&para;</a></h3>
<details class="note" open="open"><summary>method</summary><div class="highlight"><pre><span></span><code><span class="k">val</span> <span class="n">show</span><span class="o">:</span> <span class="n">t</span> <span class="o">-&gt;</span> <span class="kt">string</span>
</code></pre></div>

<p>Print the object to a human-readable representation.</p>
</details>
<h3 id="pp_9">pp<a class="headerlink" href="#pp_9" title="Permanent link">&para;</a></h3>
<details class="note" open="open"><summary>method</summary><div class="highlight"><pre><span></span><code><span class="k">val</span> <span class="n">pp</span><span class="o">:</span> <span class="nn">Format</span><span class="p">.</span><span class="n">formatter</span> <span class="o">-&gt;</span> <span class="n">t</span> <span class="o">-&gt;</span> <span class="kt">unit</span>
</code></pre></div>

<p>Pretty-print the object to a formatter.</p>
</details>
<h2 id="module-sklearndecompositionsparsecoder">module Sklearn.​Decomposition.​SparseCoder<a class="headerlink" href="#module-sklearndecompositionsparsecoder" title="Permanent link">&para;</a></h2>
<div class="highlight"><pre><span></span><code><span class="k">type</span> <span class="n">t</span>
</code></pre></div>

<h3 id="create_10">create<a class="headerlink" href="#create_10" title="Permanent link">&para;</a></h3>
<details class="note" open="open"><summary>constructor and attributes</summary><div class="highlight"><pre><span></span><code><span class="k">val</span> <span class="n">create</span> <span class="o">:</span>
  <span class="o">?</span><span class="n">transform_algorithm</span><span class="o">:[`</span><span class="nc">Lasso_lars</span> <span class="o">|</span> <span class="o">`</span><span class="nc">Lasso_cd</span> <span class="o">|</span> <span class="o">`</span><span class="nc">Lars</span> <span class="o">|</span> <span class="o">`</span><span class="nc">Omp</span> <span class="o">|</span> <span class="o">`</span><span class="nc">Threshold</span><span class="o">]</span> <span class="o">-&gt;</span>
  <span class="o">?</span><span class="n">transform_n_nonzero_coefs</span><span class="o">:</span><span class="kt">int</span> <span class="o">-&gt;</span>
  <span class="o">?</span><span class="n">transform_alpha</span><span class="o">:</span><span class="kt">float</span> <span class="o">-&gt;</span>
  <span class="o">?</span><span class="n">split_sign</span><span class="o">:</span><span class="kt">bool</span> <span class="o">-&gt;</span>
  <span class="o">?</span><span class="n">n_jobs</span><span class="o">:[`</span><span class="nc">Int</span> <span class="k">of</span> <span class="kt">int</span> <span class="o">|</span> <span class="o">`</span><span class="nc">None</span><span class="o">]</span> <span class="o">-&gt;</span>
  <span class="o">?</span><span class="n">positive_code</span><span class="o">:</span><span class="kt">bool</span> <span class="o">-&gt;</span>
  <span class="o">?</span><span class="n">transform_max_iter</span><span class="o">:</span><span class="kt">int</span> <span class="o">-&gt;</span>
  <span class="n">dictionary</span><span class="o">:</span><span class="nn">Ndarray</span><span class="p">.</span><span class="n">t</span> <span class="o">-&gt;</span>
  <span class="kt">unit</span> <span class="o">-&gt;</span>
  <span class="n">t</span>
</code></pre></div>

<p>Sparse coding</p>
<p>Finds a sparse representation of data against a fixed, precomputed
dictionary.</p>
<p>Each row of the result is the solution to a sparse coding problem.
The goal is to find a sparse array <code>code</code> such that::</p>
<div class="codehilite"><pre><span></span><code>X ~= code * dictionary
</code></pre></div>


<p>Read more in the :ref:<code>User Guide &lt;SparseCoder&gt;</code>.</p>
<h4>Parameters</h4>
<details class="info" open="open"><summary>dictionary : array, [n_components, n_features]</summary><p>The dictionary atoms used for sparse coding. Lines are assumed to be
normalized to unit norm.</p>
</details>
<details class="info" open="open"><summary>transform_algorithm : {'lasso_lars', 'lasso_cd', 'lars', 'omp',     'threshold'}, default='omp'</summary><p>Algorithm used to transform the data:</p>
</details>
<details class="info" open="open"><summary>lars: uses the least angle regression method (linear_model.lars_path)</summary></details>
<details class="info" open="open"><summary>lasso_lars: uses Lars to compute the Lasso solution</summary></details>
<details class="info" open="open"><summary>lasso_cd: uses the coordinate descent method to compute the</summary><p>Lasso solution (linear_model.Lasso). lasso_lars will be faster if
the estimated components are sparse.</p>
</details>
<details class="info" open="open"><summary>omp: uses orthogonal matching pursuit to estimate the sparse solution</summary></details>
<details class="info" open="open"><summary>threshold: squashes to zero all coefficients less than alpha from</summary><p>the projection <code>dictionary * X'</code></p>
</details>
<details class="info" open="open"><summary>transform_n_nonzero_coefs : int, default=0.1*n_features</summary><p>Number of nonzero coefficients to target in each column of the
solution. This is only used by <code>algorithm='lars'</code> and <code>algorithm='omp'</code>
and is overridden by <code>alpha</code> in the <code>omp</code> case.</p>
</details>
<details class="info" open="open"><summary>transform_alpha : float, default=1.</summary><p>If <code>algorithm='lasso_lars'</code> or <code>algorithm='lasso_cd'</code>, <code>alpha</code> is the
penalty applied to the L1 norm.
If <code>algorithm='threshold'</code>, <code>alpha</code> is the absolute value of the
threshold below which coefficients will be squashed to zero.
If <code>algorithm='omp'</code>, <code>alpha</code> is the tolerance parameter: the value of
the reconstruction error targeted. In this case, it overrides
<code>n_nonzero_coefs</code>.</p>
</details>
<details class="info" open="open"><summary>split_sign : bool, default=False</summary><p>Whether to split the sparse feature vector into the concatenation of
its negative part and its positive part. This can improve the
performance of downstream classifiers.</p>
</details>
<details class="info" open="open"><summary>n_jobs : int or None, default=None</summary><p>Number of parallel jobs to run.
<code>None</code> means 1 unless in a :obj:<code>joblib.parallel_backend</code> context.
<code>-1</code> means using all processors. See :term:<code>Glossary &lt;n_jobs&gt;</code>
for more details.</p>
</details>
<details class="info" open="open"><summary>positive_code : bool, default=False</summary><p>Whether to enforce positivity when finding the code.</p>
<p>.. versionadded:: 0.20</p>
</details>
<details class="info" open="open"><summary>transform_max_iter : int, default=1000</summary><p>Maximum number of iterations to perform if <code>algorithm='lasso_cd'</code> or
<code>lasso_lars</code>.</p>
<p>.. versionadded:: 0.22</p>
</details>
<h4>Attributes</h4>
<details class="info" open="open"><summary>components_ : array, [n_components, n_features]</summary><p>The unchanged dictionary atoms</p>
</details>
<h4>See also</h4>
<p>DictionaryLearning
MiniBatchDictionaryLearning
SparsePCA
MiniBatchSparsePCA
sparse_encode</p>
</details>
<h3 id="fit_10">fit<a class="headerlink" href="#fit_10" title="Permanent link">&para;</a></h3>
<details class="note" open="open"><summary>method</summary><div class="highlight"><pre><span></span><code><span class="k">val</span> <span class="n">fit</span> <span class="o">:</span>
  <span class="o">?</span><span class="n">y</span><span class="o">:</span><span class="nn">Py</span><span class="p">.</span><span class="nn">Object</span><span class="p">.</span><span class="n">t</span> <span class="o">-&gt;</span>
  <span class="n">x</span><span class="o">:</span><span class="nn">Py</span><span class="p">.</span><span class="nn">Object</span><span class="p">.</span><span class="n">t</span> <span class="o">-&gt;</span>
  <span class="n">t</span> <span class="o">-&gt;</span>
  <span class="n">t</span>
</code></pre></div>

<p>Do nothing and return the estimator unchanged</p>
<p>This method is just there to implement the usual API and hence
work in pipelines.</p>
<h4>Parameters</h4>
<details class="info" open="open"><summary>X : Ignored</summary></details>
<details class="info" open="open"><summary>y : Ignored</summary></details>
<h4>Returns</h4>
<details class="info" open="open"><summary>self : object</summary><p>Returns the object itself</p>
</details>
</details>
<h3 id="fit_transform_10">fit_transform<a class="headerlink" href="#fit_transform_10" title="Permanent link">&para;</a></h3>
<details class="note" open="open"><summary>method</summary><div class="highlight"><pre><span></span><code><span class="k">val</span> <span class="n">fit_transform</span> <span class="o">:</span>
  <span class="o">?</span><span class="n">y</span><span class="o">:</span><span class="nn">Ndarray</span><span class="p">.</span><span class="n">t</span> <span class="o">-&gt;</span>
  <span class="o">?</span><span class="n">fit_params</span><span class="o">:(</span><span class="kt">string</span> <span class="o">*</span> <span class="nn">Py</span><span class="p">.</span><span class="nn">Object</span><span class="p">.</span><span class="n">t</span><span class="o">)</span> <span class="kt">list</span> <span class="o">-&gt;</span>
  <span class="n">x</span><span class="o">:</span><span class="nn">Ndarray</span><span class="p">.</span><span class="n">t</span> <span class="o">-&gt;</span>
  <span class="n">t</span> <span class="o">-&gt;</span>
  <span class="nn">Ndarray</span><span class="p">.</span><span class="n">t</span>
</code></pre></div>

<p>Fit to data, then transform it.</p>
<p>Fits transformer to X and y with optional parameters fit_params
and returns a transformed version of X.</p>
<h4>Parameters</h4>
<details class="info" open="open"><summary>X : numpy array of shape [n_samples, n_features]</summary><p>Training set.</p>
</details>
<details class="info" open="open"><summary>y : numpy array of shape [n_samples]</summary><p>Target values.</p>
</details>
<details class="info" open="open"><summary>**fit_params : dict</summary><p>Additional fit parameters.</p>
</details>
<h4>Returns</h4>
<details class="info" open="open"><summary>X_new : numpy array of shape [n_samples, n_features_new]</summary><p>Transformed array.</p>
</details>
</details>
<h3 id="get_params_10">get_params<a class="headerlink" href="#get_params_10" title="Permanent link">&para;</a></h3>
<details class="note" open="open"><summary>method</summary><div class="highlight"><pre><span></span><code><span class="k">val</span> <span class="n">get_params</span> <span class="o">:</span>
  <span class="o">?</span><span class="n">deep</span><span class="o">:</span><span class="kt">bool</span> <span class="o">-&gt;</span>
  <span class="n">t</span> <span class="o">-&gt;</span>
  <span class="nn">Py</span><span class="p">.</span><span class="nn">Object</span><span class="p">.</span><span class="n">t</span>
</code></pre></div>

<p>Get parameters for this estimator.</p>
<h4>Parameters</h4>
<details class="info" open="open"><summary>deep : bool, default=True</summary><p>If True, will return the parameters for this estimator and
contained subobjects that are estimators.</p>
</details>
<h4>Returns</h4>
<details class="info" open="open"><summary>params : mapping of string to any</summary><p>Parameter names mapped to their values.</p>
</details>
</details>
<h3 id="set_params_10">set_params<a class="headerlink" href="#set_params_10" title="Permanent link">&para;</a></h3>
<details class="note" open="open"><summary>method</summary><div class="highlight"><pre><span></span><code><span class="k">val</span> <span class="n">set_params</span> <span class="o">:</span>
  <span class="o">?</span><span class="n">params</span><span class="o">:(</span><span class="kt">string</span> <span class="o">*</span> <span class="nn">Py</span><span class="p">.</span><span class="nn">Object</span><span class="p">.</span><span class="n">t</span><span class="o">)</span> <span class="kt">list</span> <span class="o">-&gt;</span>
  <span class="n">t</span> <span class="o">-&gt;</span>
  <span class="n">t</span>
</code></pre></div>

<p>Set the parameters of this estimator.</p>
<p>The method works on simple estimators as well as on nested objects
(such as pipelines). The latter have parameters of the form
<code>&lt;component&gt;__&lt;parameter&gt;</code> so that it's possible to update each
component of a nested object.</p>
<h4>Parameters</h4>
<details class="info" open="open"><summary>**params : dict</summary><p>Estimator parameters.</p>
</details>
<h4>Returns</h4>
<details class="info" open="open"><summary>self : object</summary><p>Estimator instance.</p>
</details>
</details>
<h3 id="transform_10">transform<a class="headerlink" href="#transform_10" title="Permanent link">&para;</a></h3>
<details class="note" open="open"><summary>method</summary><div class="highlight"><pre><span></span><code><span class="k">val</span> <span class="n">transform</span> <span class="o">:</span>
  <span class="n">x</span><span class="o">:</span><span class="nn">Ndarray</span><span class="p">.</span><span class="n">t</span> <span class="o">-&gt;</span>
  <span class="n">t</span> <span class="o">-&gt;</span>
  <span class="nn">Ndarray</span><span class="p">.</span><span class="n">t</span>
</code></pre></div>

<p>Encode the data as a sparse combination of the dictionary atoms.</p>
<p>Coding method is determined by the object parameter
<code>transform_algorithm</code>.</p>
<h4>Parameters</h4>
<details class="info" open="open"><summary>X : array of shape (n_samples, n_features)</summary><p>Test data to be transformed, must have the same number of
features as the data used to train the model.</p>
</details>
<h4>Returns</h4>
<details class="info" open="open"><summary>X_new : array, shape (n_samples, n_components)</summary><p>Transformed data</p>
</details>
</details>
<h3 id="components__9">components_<a class="headerlink" href="#components__9" title="Permanent link">&para;</a></h3>
<details class="note" open="open"><summary>attribute</summary><div class="highlight"><pre><span></span><code><span class="k">val</span> <span class="n">components_</span> <span class="o">:</span> <span class="n">t</span> <span class="o">-&gt;</span> <span class="nn">Ndarray</span><span class="p">.</span><span class="n">t</span>
</code></pre></div>

<p>This attribute is documented in <code>create</code> above.</p>
</details>
<h3 id="to_string_10">to_string<a class="headerlink" href="#to_string_10" title="Permanent link">&para;</a></h3>
<details class="note" open="open"><summary>method</summary><div class="highlight"><pre><span></span><code><span class="k">val</span> <span class="n">to_string</span><span class="o">:</span> <span class="n">t</span> <span class="o">-&gt;</span> <span class="kt">string</span>
</code></pre></div>

<p>Print the object to a human-readable representation.</p>
</details>
<h3 id="show_10">show<a class="headerlink" href="#show_10" title="Permanent link">&para;</a></h3>
<details class="note" open="open"><summary>method</summary><div class="highlight"><pre><span></span><code><span class="k">val</span> <span class="n">show</span><span class="o">:</span> <span class="n">t</span> <span class="o">-&gt;</span> <span class="kt">string</span>
</code></pre></div>

<p>Print the object to a human-readable representation.</p>
</details>
<h3 id="pp_10">pp<a class="headerlink" href="#pp_10" title="Permanent link">&para;</a></h3>
<details class="note" open="open"><summary>method</summary><div class="highlight"><pre><span></span><code><span class="k">val</span> <span class="n">pp</span><span class="o">:</span> <span class="nn">Format</span><span class="p">.</span><span class="n">formatter</span> <span class="o">-&gt;</span> <span class="n">t</span> <span class="o">-&gt;</span> <span class="kt">unit</span>
</code></pre></div>

<p>Pretty-print the object to a formatter.</p>
</details>
<h2 id="module-sklearndecompositionsparsepca">module Sklearn.​Decomposition.​SparsePCA<a class="headerlink" href="#module-sklearndecompositionsparsepca" title="Permanent link">&para;</a></h2>
<div class="highlight"><pre><span></span><code><span class="k">type</span> <span class="n">t</span>
</code></pre></div>

<h3 id="create_11">create<a class="headerlink" href="#create_11" title="Permanent link">&para;</a></h3>
<details class="note" open="open"><summary>constructor and attributes</summary><div class="highlight"><pre><span></span><code><span class="k">val</span> <span class="n">create</span> <span class="o">:</span>
  <span class="o">?</span><span class="n">n_components</span><span class="o">:</span><span class="kt">int</span> <span class="o">-&gt;</span>
  <span class="o">?</span><span class="n">alpha</span><span class="o">:</span><span class="kt">float</span> <span class="o">-&gt;</span>
  <span class="o">?</span><span class="n">ridge_alpha</span><span class="o">:</span><span class="kt">float</span> <span class="o">-&gt;</span>
  <span class="o">?</span><span class="n">max_iter</span><span class="o">:</span><span class="kt">int</span> <span class="o">-&gt;</span>
  <span class="o">?</span><span class="n">tol</span><span class="o">:</span><span class="kt">float</span> <span class="o">-&gt;</span>
  <span class="o">?</span><span class="n">method_</span><span class="o">:[`</span><span class="nc">Lars</span> <span class="o">|</span> <span class="o">`</span><span class="nc">Cd</span><span class="o">]</span> <span class="o">-&gt;</span>
  <span class="o">?</span><span class="n">n_jobs</span><span class="o">:[`</span><span class="nc">Int</span> <span class="k">of</span> <span class="kt">int</span> <span class="o">|</span> <span class="o">`</span><span class="nc">None</span><span class="o">]</span> <span class="o">-&gt;</span>
  <span class="o">?</span><span class="n">u_init</span><span class="o">:</span><span class="nn">Ndarray</span><span class="p">.</span><span class="n">t</span> <span class="o">-&gt;</span>
  <span class="o">?</span><span class="n">v_init</span><span class="o">:</span><span class="nn">Ndarray</span><span class="p">.</span><span class="n">t</span> <span class="o">-&gt;</span>
  <span class="o">?</span><span class="n">verbose</span><span class="o">:</span><span class="kt">int</span> <span class="o">-&gt;</span>
  <span class="o">?</span><span class="n">random_state</span><span class="o">:[`</span><span class="nc">Int</span> <span class="k">of</span> <span class="kt">int</span> <span class="o">|</span> <span class="o">`</span><span class="nc">RandomState</span> <span class="k">of</span> <span class="nn">Py</span><span class="p">.</span><span class="nn">Object</span><span class="p">.</span><span class="n">t</span> <span class="o">|</span> <span class="o">`</span><span class="nc">None</span><span class="o">]</span> <span class="o">-&gt;</span>
  <span class="o">?</span><span class="n">normalize_components</span><span class="o">:</span><span class="kt">string</span> <span class="o">-&gt;</span>
  <span class="kt">unit</span> <span class="o">-&gt;</span>
  <span class="n">t</span>
</code></pre></div>

<p>Sparse Principal Components Analysis (SparsePCA)</p>
<p>Finds the set of sparse components that can optimally reconstruct
the data.  The amount of sparseness is controllable by the coefficient
of the L1 penalty, given by the parameter alpha.</p>
<p>Read more in the :ref:<code>User Guide &lt;SparsePCA&gt;</code>.</p>
<h4>Parameters</h4>
<details class="info" open="open"><summary>n_components : int,</summary><p>Number of sparse atoms to extract.</p>
</details>
<details class="info" open="open"><summary>alpha : float,</summary><p>Sparsity controlling parameter. Higher values lead to sparser
components.</p>
</details>
<details class="info" open="open"><summary>ridge_alpha : float,</summary><p>Amount of ridge shrinkage to apply in order to improve
conditioning when calling the transform method.</p>
</details>
<details class="info" open="open"><summary>max_iter : int,</summary><p>Maximum number of iterations to perform.</p>
</details>
<details class="info" open="open"><summary>tol : float,</summary><p>Tolerance for the stopping condition.</p>
</details>
<details class="info" open="open"><summary>method : {'lars', 'cd'}</summary></details>
<details class="info" open="open"><summary>lars: uses the least angle regression method to solve the lasso problem</summary><p>(linear_model.lars_path)</p>
</details>
<details class="info" open="open"><summary>cd: uses the coordinate descent method to compute the</summary><p>Lasso solution (linear_model.Lasso). Lars will be faster if
the estimated components are sparse.</p>
</details>
<details class="info" open="open"><summary>n_jobs : int or None, optional (default=None)</summary><p>Number of parallel jobs to run.
<code>None</code> means 1 unless in a :obj:<code>joblib.parallel_backend</code> context.
<code>-1</code> means using all processors. See :term:<code>Glossary &lt;n_jobs&gt;</code>
for more details.</p>
</details>
<details class="info" open="open"><summary>U_init : array of shape (n_samples, n_components),</summary><p>Initial values for the loadings for warm restart scenarios.</p>
</details>
<details class="info" open="open"><summary>V_init : array of shape (n_components, n_features),</summary><p>Initial values for the components for warm restart scenarios.</p>
</details>
<details class="info" open="open"><summary>verbose : int</summary><p>Controls the verbosity; the higher, the more messages. Defaults to 0.</p>
</details>
<details class="info" open="open"><summary>random_state : int, RandomState instance or None, optional (default=None)</summary><p>If int, random_state is the seed used by the random number generator;
If RandomState instance, random_state is the random number generator;
If None, the random number generator is the RandomState instance used
by <code>np.random</code>.</p>
</details>
<details class="info" open="open"><summary>normalize_components : 'deprecated'</summary><p>This parameter does not have any effect. The components are always
normalized.</p>
<p>.. versionadded:: 0.20</p>
<p>.. deprecated:: 0.22
   <code>normalize_components</code> is deprecated in 0.22 and will be removed
   in 0.24.</p>
</details>
<h4>Attributes</h4>
<details class="info" open="open"><summary>components_ : array, [n_components, n_features]</summary><p>Sparse components extracted from the data.</p>
</details>
<details class="info" open="open"><summary>error_ : array</summary><p>Vector of errors at each iteration.</p>
</details>
<details class="info" open="open"><summary>n_iter_ : int</summary><p>Number of iterations run.</p>
</details>
<details class="info" open="open"><summary>mean_ : array, shape (n_features,)</summary><p>Per-feature empirical mean, estimated from the training set.
Equal to <code>X.mean(axis=0)</code>.</p>
</details>
<h4>Examples</h4>
<div class="highlight"><pre><span></span><code><span class="o">&gt;&gt;&gt;</span> <span class="kn">import</span> <span class="nn">numpy</span> <span class="k">as</span> <span class="nn">np</span>
<span class="o">&gt;&gt;&gt;</span> <span class="kn">from</span> <span class="nn">sklearn.datasets</span> <span class="kn">import</span> <span class="n">make_friedman1</span>
<span class="o">&gt;&gt;&gt;</span> <span class="kn">from</span> <span class="nn">sklearn.decomposition</span> <span class="kn">import</span> <span class="n">SparsePCA</span>
<span class="o">&gt;&gt;&gt;</span> <span class="n">X</span><span class="p">,</span> <span class="n">_</span> <span class="o">=</span> <span class="n">make_friedman1</span><span class="p">(</span><span class="n">n_samples</span><span class="o">=</span><span class="mi">200</span><span class="p">,</span> <span class="n">n_features</span><span class="o">=</span><span class="mi">30</span><span class="p">,</span> <span class="n">random_state</span><span class="o">=</span><span class="mi">0</span><span class="p">)</span>
<span class="o">&gt;&gt;&gt;</span> <span class="n">transformer</span> <span class="o">=</span> <span class="n">SparsePCA</span><span class="p">(</span><span class="n">n_components</span><span class="o">=</span><span class="mi">5</span><span class="p">,</span> <span class="n">random_state</span><span class="o">=</span><span class="mi">0</span><span class="p">)</span>
<span class="o">&gt;&gt;&gt;</span> <span class="n">transformer</span><span class="o">.</span><span class="n">fit</span><span class="p">(</span><span class="n">X</span><span class="p">)</span>
<span class="n">SparsePCA</span><span class="p">(</span><span class="o">...</span><span class="p">)</span>
<span class="o">&gt;&gt;&gt;</span> <span class="n">X_transformed</span> <span class="o">=</span> <span class="n">transformer</span><span class="o">.</span><span class="n">transform</span><span class="p">(</span><span class="n">X</span><span class="p">)</span>
<span class="o">&gt;&gt;&gt;</span> <span class="n">X_transformed</span><span class="o">.</span><span class="n">shape</span>
<span class="p">(</span><span class="mi">200</span><span class="p">,</span> <span class="mi">5</span><span class="p">)</span>
<span class="o">&gt;&gt;&gt;</span> <span class="c1"># most values in the components_ are zero (sparsity)</span>
<span class="o">&gt;&gt;&gt;</span> <span class="n">np</span><span class="o">.</span><span class="n">mean</span><span class="p">(</span><span class="n">transformer</span><span class="o">.</span><span class="n">components_</span> <span class="o">==</span> <span class="mi">0</span><span class="p">)</span>
<span class="mf">0.9666</span><span class="o">...</span>
</code></pre></div>

<h4>See also</h4>
<p>PCA
MiniBatchSparsePCA
DictionaryLearning</p>
</details>
<h3 id="fit_11">fit<a class="headerlink" href="#fit_11" title="Permanent link">&para;</a></h3>
<details class="note" open="open"><summary>method</summary><div class="highlight"><pre><span></span><code><span class="k">val</span> <span class="n">fit</span> <span class="o">:</span>
  <span class="o">?</span><span class="n">y</span><span class="o">:</span><span class="nn">Py</span><span class="p">.</span><span class="nn">Object</span><span class="p">.</span><span class="n">t</span> <span class="o">-&gt;</span>
  <span class="n">x</span><span class="o">:</span><span class="nn">Ndarray</span><span class="p">.</span><span class="n">t</span> <span class="o">-&gt;</span>
  <span class="n">t</span> <span class="o">-&gt;</span>
  <span class="n">t</span>
</code></pre></div>

<p>Fit the model from data in X.</p>
<h4>Parameters</h4>
<details class="info" open="open"><summary>X : array-like, shape (n_samples, n_features)</summary><p>Training vector, where n_samples in the number of samples
and n_features is the number of features.</p>
</details>
<details class="info" open="open"><summary>y : Ignored</summary></details>
<h4>Returns</h4>
<details class="info" open="open"><summary>self : object</summary><p>Returns the instance itself.</p>
</details>
</details>
<h3 id="fit_transform_11">fit_transform<a class="headerlink" href="#fit_transform_11" title="Permanent link">&para;</a></h3>
<details class="note" open="open"><summary>method</summary><div class="highlight"><pre><span></span><code><span class="k">val</span> <span class="n">fit_transform</span> <span class="o">:</span>
  <span class="o">?</span><span class="n">y</span><span class="o">:</span><span class="nn">Ndarray</span><span class="p">.</span><span class="n">t</span> <span class="o">-&gt;</span>
  <span class="o">?</span><span class="n">fit_params</span><span class="o">:(</span><span class="kt">string</span> <span class="o">*</span> <span class="nn">Py</span><span class="p">.</span><span class="nn">Object</span><span class="p">.</span><span class="n">t</span><span class="o">)</span> <span class="kt">list</span> <span class="o">-&gt;</span>
  <span class="n">x</span><span class="o">:</span><span class="nn">Ndarray</span><span class="p">.</span><span class="n">t</span> <span class="o">-&gt;</span>
  <span class="n">t</span> <span class="o">-&gt;</span>
  <span class="nn">Ndarray</span><span class="p">.</span><span class="n">t</span>
</code></pre></div>

<p>Fit to data, then transform it.</p>
<p>Fits transformer to X and y with optional parameters fit_params
and returns a transformed version of X.</p>
<h4>Parameters</h4>
<details class="info" open="open"><summary>X : numpy array of shape [n_samples, n_features]</summary><p>Training set.</p>
</details>
<details class="info" open="open"><summary>y : numpy array of shape [n_samples]</summary><p>Target values.</p>
</details>
<details class="info" open="open"><summary>**fit_params : dict</summary><p>Additional fit parameters.</p>
</details>
<h4>Returns</h4>
<details class="info" open="open"><summary>X_new : numpy array of shape [n_samples, n_features_new]</summary><p>Transformed array.</p>
</details>
</details>
<h3 id="get_params_11">get_params<a class="headerlink" href="#get_params_11" title="Permanent link">&para;</a></h3>
<details class="note" open="open"><summary>method</summary><div class="highlight"><pre><span></span><code><span class="k">val</span> <span class="n">get_params</span> <span class="o">:</span>
  <span class="o">?</span><span class="n">deep</span><span class="o">:</span><span class="kt">bool</span> <span class="o">-&gt;</span>
  <span class="n">t</span> <span class="o">-&gt;</span>
  <span class="nn">Py</span><span class="p">.</span><span class="nn">Object</span><span class="p">.</span><span class="n">t</span>
</code></pre></div>

<p>Get parameters for this estimator.</p>
<h4>Parameters</h4>
<details class="info" open="open"><summary>deep : bool, default=True</summary><p>If True, will return the parameters for this estimator and
contained subobjects that are estimators.</p>
</details>
<h4>Returns</h4>
<details class="info" open="open"><summary>params : mapping of string to any</summary><p>Parameter names mapped to their values.</p>
</details>
</details>
<h3 id="set_params_11">set_params<a class="headerlink" href="#set_params_11" title="Permanent link">&para;</a></h3>
<details class="note" open="open"><summary>method</summary><div class="highlight"><pre><span></span><code><span class="k">val</span> <span class="n">set_params</span> <span class="o">:</span>
  <span class="o">?</span><span class="n">params</span><span class="o">:(</span><span class="kt">string</span> <span class="o">*</span> <span class="nn">Py</span><span class="p">.</span><span class="nn">Object</span><span class="p">.</span><span class="n">t</span><span class="o">)</span> <span class="kt">list</span> <span class="o">-&gt;</span>
  <span class="n">t</span> <span class="o">-&gt;</span>
  <span class="n">t</span>
</code></pre></div>

<p>Set the parameters of this estimator.</p>
<p>The method works on simple estimators as well as on nested objects
(such as pipelines). The latter have parameters of the form
<code>&lt;component&gt;__&lt;parameter&gt;</code> so that it's possible to update each
component of a nested object.</p>
<h4>Parameters</h4>
<details class="info" open="open"><summary>**params : dict</summary><p>Estimator parameters.</p>
</details>
<h4>Returns</h4>
<details class="info" open="open"><summary>self : object</summary><p>Estimator instance.</p>
</details>
</details>
<h3 id="transform_11">transform<a class="headerlink" href="#transform_11" title="Permanent link">&para;</a></h3>
<details class="note" open="open"><summary>method</summary><div class="highlight"><pre><span></span><code><span class="k">val</span> <span class="n">transform</span> <span class="o">:</span>
  <span class="n">x</span><span class="o">:</span><span class="nn">Ndarray</span><span class="p">.</span><span class="n">t</span> <span class="o">-&gt;</span>
  <span class="n">t</span> <span class="o">-&gt;</span>
  <span class="nn">Ndarray</span><span class="p">.</span><span class="n">t</span>
</code></pre></div>

<p>Least Squares projection of the data onto the sparse components.</p>
<p>To avoid instability issues in case the system is under-determined,
regularization can be applied (Ridge regression) via the
<code>ridge_alpha</code> parameter.</p>
<p>Note that Sparse PCA components orthogonality is not enforced as in PCA
hence one cannot use a simple linear projection.</p>
<h4>Parameters</h4>
<details class="info" open="open"><summary>X : array of shape (n_samples, n_features)</summary><p>Test data to be transformed, must have the same number of
features as the data used to train the model.</p>
</details>
<h4>Returns</h4>
<p>X_new array, shape (n_samples, n_components)
    Transformed data.</p>
</details>
<h3 id="components__10">components_<a class="headerlink" href="#components__10" title="Permanent link">&para;</a></h3>
<details class="note" open="open"><summary>attribute</summary><div class="highlight"><pre><span></span><code><span class="k">val</span> <span class="n">components_</span> <span class="o">:</span> <span class="n">t</span> <span class="o">-&gt;</span> <span class="nn">Ndarray</span><span class="p">.</span><span class="n">t</span>
</code></pre></div>

<p>This attribute is documented in <code>create</code> above.</p>
</details>
<h3 id="error__1">error_<a class="headerlink" href="#error__1" title="Permanent link">&para;</a></h3>
<details class="note" open="open"><summary>attribute</summary><div class="highlight"><pre><span></span><code><span class="k">val</span> <span class="n">error_</span> <span class="o">:</span> <span class="n">t</span> <span class="o">-&gt;</span> <span class="nn">Ndarray</span><span class="p">.</span><span class="n">t</span>
</code></pre></div>

<p>This attribute is documented in <code>create</code> above.</p>
</details>
<h3 id="n_iter__7">n_iter_<a class="headerlink" href="#n_iter__7" title="Permanent link">&para;</a></h3>
<details class="note" open="open"><summary>attribute</summary><div class="highlight"><pre><span></span><code><span class="k">val</span> <span class="n">n_iter_</span> <span class="o">:</span> <span class="n">t</span> <span class="o">-&gt;</span> <span class="kt">int</span>
</code></pre></div>

<p>This attribute is documented in <code>create</code> above.</p>
</details>
<h3 id="mean__5">mean_<a class="headerlink" href="#mean__5" title="Permanent link">&para;</a></h3>
<details class="note" open="open"><summary>attribute</summary><div class="highlight"><pre><span></span><code><span class="k">val</span> <span class="n">mean_</span> <span class="o">:</span> <span class="n">t</span> <span class="o">-&gt;</span> <span class="nn">Ndarray</span><span class="p">.</span><span class="n">t</span>
</code></pre></div>

<p>This attribute is documented in <code>create</code> above.</p>
</details>
<h3 id="to_string_11">to_string<a class="headerlink" href="#to_string_11" title="Permanent link">&para;</a></h3>
<details class="note" open="open"><summary>method</summary><div class="highlight"><pre><span></span><code><span class="k">val</span> <span class="n">to_string</span><span class="o">:</span> <span class="n">t</span> <span class="o">-&gt;</span> <span class="kt">string</span>
</code></pre></div>

<p>Print the object to a human-readable representation.</p>
</details>
<h3 id="show_11">show<a class="headerlink" href="#show_11" title="Permanent link">&para;</a></h3>
<details class="note" open="open"><summary>method</summary><div class="highlight"><pre><span></span><code><span class="k">val</span> <span class="n">show</span><span class="o">:</span> <span class="n">t</span> <span class="o">-&gt;</span> <span class="kt">string</span>
</code></pre></div>

<p>Print the object to a human-readable representation.</p>
</details>
<h3 id="pp_11">pp<a class="headerlink" href="#pp_11" title="Permanent link">&para;</a></h3>
<details class="note" open="open"><summary>method</summary><div class="highlight"><pre><span></span><code><span class="k">val</span> <span class="n">pp</span><span class="o">:</span> <span class="nn">Format</span><span class="p">.</span><span class="n">formatter</span> <span class="o">-&gt;</span> <span class="n">t</span> <span class="o">-&gt;</span> <span class="kt">unit</span>
</code></pre></div>

<p>Pretty-print the object to a formatter.</p>
</details>
<h2 id="module-sklearndecompositiontruncatedsvd">module Sklearn.​Decomposition.​TruncatedSVD<a class="headerlink" href="#module-sklearndecompositiontruncatedsvd" title="Permanent link">&para;</a></h2>
<div class="highlight"><pre><span></span><code><span class="k">type</span> <span class="n">t</span>
</code></pre></div>

<h3 id="create_12">create<a class="headerlink" href="#create_12" title="Permanent link">&para;</a></h3>
<details class="note" open="open"><summary>constructor and attributes</summary><div class="highlight"><pre><span></span><code><span class="k">val</span> <span class="n">create</span> <span class="o">:</span>
  <span class="o">?</span><span class="n">n_components</span><span class="o">:</span><span class="kt">int</span> <span class="o">-&gt;</span>
  <span class="o">?</span><span class="n">algorithm</span><span class="o">:</span><span class="kt">string</span> <span class="o">-&gt;</span>
  <span class="o">?</span><span class="n">n_iter</span><span class="o">:</span><span class="kt">int</span> <span class="o">-&gt;</span>
  <span class="o">?</span><span class="n">random_state</span><span class="o">:[`</span><span class="nc">Int</span> <span class="k">of</span> <span class="kt">int</span> <span class="o">|</span> <span class="o">`</span><span class="nc">RandomState</span> <span class="k">of</span> <span class="nn">Py</span><span class="p">.</span><span class="nn">Object</span><span class="p">.</span><span class="n">t</span> <span class="o">|</span> <span class="o">`</span><span class="nc">None</span><span class="o">]</span> <span class="o">-&gt;</span>
  <span class="o">?</span><span class="n">tol</span><span class="o">:</span><span class="kt">float</span> <span class="o">-&gt;</span>
  <span class="kt">unit</span> <span class="o">-&gt;</span>
  <span class="n">t</span>
</code></pre></div>

<p>Dimensionality reduction using truncated SVD (aka LSA).</p>
<p>This transformer performs linear dimensionality reduction by means of
truncated singular value decomposition (SVD). Contrary to PCA, this
estimator does not center the data before computing the singular value
decomposition. This means it can work with scipy.sparse matrices
efficiently.</p>
<p>In particular, truncated SVD works on term count/tf-idf matrices as
returned by the vectorizers in sklearn.feature_extraction.text. In that
context, it is known as latent semantic analysis (LSA).</p>
<p>This estimator supports two algorithms: a fast randomized SVD solver, and
a "naive" algorithm that uses ARPACK as an eigensolver on (X * X.T) or
(X.T * X), whichever is more efficient.</p>
<p>Read more in the :ref:<code>User Guide &lt;LSA&gt;</code>.</p>
<h4>Parameters</h4>
<details class="info" open="open"><summary>n_components : int, default = 2</summary><p>Desired dimensionality of output data.
Must be strictly less than the number of features.
The default value is useful for visualisation. For LSA, a value of
100 is recommended.</p>
</details>
<details class="info" open="open"><summary>algorithm : string, default = "randomized"</summary><p>SVD solver to use. Either "arpack" for the ARPACK wrapper in SciPy
(scipy.sparse.linalg.svds), or "randomized" for the randomized
algorithm due to Halko (2009).</p>
</details>
<details class="info" open="open"><summary>n_iter : int, optional (default 5)</summary><p>Number of iterations for randomized SVD solver. Not used by ARPACK. The
default is larger than the default in
<code>~sklearn.utils.extmath.randomized_svd</code> to handle sparse matrices that
may have large slowly decaying spectrum.</p>
</details>
<details class="info" open="open"><summary>random_state : int, RandomState instance or None, optional, default = None</summary><p>If int, random_state is the seed used by the random number generator;
If RandomState instance, random_state is the random number generator;
If None, the random number generator is the RandomState instance used
by <code>np.random</code>.</p>
</details>
<details class="info" open="open"><summary>tol : float, optional</summary><p>Tolerance for ARPACK. 0 means machine precision. Ignored by randomized
SVD solver.</p>
</details>
<h4>Attributes</h4>
<details class="info" open="open"><summary>components_ : array, shape (n_components, n_features)</summary></details>
<details class="info" open="open"><summary>explained_variance_ : array, shape (n_components,)</summary><p>The variance of the training samples transformed by a projection to
each component.</p>
</details>
<details class="info" open="open"><summary>explained_variance_ratio_ : array, shape (n_components,)</summary><p>Percentage of variance explained by each of the selected components.</p>
</details>
<details class="info" open="open"><summary>singular_values_ : array, shape (n_components,)</summary><p>The singular values corresponding to each of the selected components.
The singular values are equal to the 2-norms of the <code>n_components</code>
variables in the lower-dimensional space.</p>
</details>
<h4>Examples</h4>
<div class="highlight"><pre><span></span><code><span class="o">&gt;&gt;&gt;</span> <span class="kn">from</span> <span class="nn">sklearn.decomposition</span> <span class="kn">import</span> <span class="n">TruncatedSVD</span>
<span class="o">&gt;&gt;&gt;</span> <span class="kn">from</span> <span class="nn">scipy.sparse</span> <span class="kn">import</span> <span class="n">random</span> <span class="k">as</span> <span class="n">sparse_random</span>
<span class="o">&gt;&gt;&gt;</span> <span class="kn">from</span> <span class="nn">sklearn.random_projection</span> <span class="kn">import</span> <span class="n">sparse_random_matrix</span>
<span class="o">&gt;&gt;&gt;</span> <span class="n">X</span> <span class="o">=</span> <span class="n">sparse_random</span><span class="p">(</span><span class="mi">100</span><span class="p">,</span> <span class="mi">100</span><span class="p">,</span> <span class="n">density</span><span class="o">=</span><span class="mf">0.01</span><span class="p">,</span> <span class="nb">format</span><span class="o">=</span><span class="s1">&#39;csr&#39;</span><span class="p">,</span>
<span class="o">...</span>                   <span class="n">random_state</span><span class="o">=</span><span class="mi">42</span><span class="p">)</span>
<span class="o">&gt;&gt;&gt;</span> <span class="n">svd</span> <span class="o">=</span> <span class="n">TruncatedSVD</span><span class="p">(</span><span class="n">n_components</span><span class="o">=</span><span class="mi">5</span><span class="p">,</span> <span class="n">n_iter</span><span class="o">=</span><span class="mi">7</span><span class="p">,</span> <span class="n">random_state</span><span class="o">=</span><span class="mi">42</span><span class="p">)</span>
<span class="o">&gt;&gt;&gt;</span> <span class="n">svd</span><span class="o">.</span><span class="n">fit</span><span class="p">(</span><span class="n">X</span><span class="p">)</span>
<span class="n">TruncatedSVD</span><span class="p">(</span><span class="n">n_components</span><span class="o">=</span><span class="mi">5</span><span class="p">,</span> <span class="n">n_iter</span><span class="o">=</span><span class="mi">7</span><span class="p">,</span> <span class="n">random_state</span><span class="o">=</span><span class="mi">42</span><span class="p">)</span>
<span class="o">&gt;&gt;&gt;</span> <span class="nb">print</span><span class="p">(</span><span class="n">svd</span><span class="o">.</span><span class="n">explained_variance_ratio_</span><span class="p">)</span>
<span class="p">[</span><span class="mf">0.0646</span><span class="o">...</span> <span class="mf">0.0633</span><span class="o">...</span> <span class="mf">0.0639</span><span class="o">...</span> <span class="mf">0.0535</span><span class="o">...</span> <span class="mf">0.0406</span><span class="o">...</span><span class="p">]</span>
<span class="o">&gt;&gt;&gt;</span> <span class="nb">print</span><span class="p">(</span><span class="n">svd</span><span class="o">.</span><span class="n">explained_variance_ratio_</span><span class="o">.</span><span class="n">sum</span><span class="p">())</span>
<span class="mf">0.286</span><span class="o">...</span>
<span class="o">&gt;&gt;&gt;</span> <span class="nb">print</span><span class="p">(</span><span class="n">svd</span><span class="o">.</span><span class="n">singular_values_</span><span class="p">)</span>
<span class="p">[</span><span class="mf">1.553</span><span class="o">...</span> <span class="mf">1.512</span><span class="o">...</span>  <span class="mf">1.510</span><span class="o">...</span> <span class="mf">1.370</span><span class="o">...</span> <span class="mf">1.199</span><span class="o">...</span><span class="p">]</span>
</code></pre></div>

<h4>See also</h4>
<p>PCA</p>
<h4>References</h4>
<p>Finding structure with randomness: Stochastic algorithms for constructing
approximate matrix decompositions
Halko, et al., 2009 (arXiv:909) https://arxiv.org/pdf/0909.4061.pdf</p>
<h4>Notes</h4>
<p>SVD suffers from a problem called "sign indeterminacy", which means the
sign of the <code>components_</code> and the output from transform depend on the
algorithm and random state. To work around this, fit instances of this
class to data once, then keep the instance around to do transformations.</p>
</details>
<h3 id="fit_12">fit<a class="headerlink" href="#fit_12" title="Permanent link">&para;</a></h3>
<details class="note" open="open"><summary>method</summary><div class="highlight"><pre><span></span><code><span class="k">val</span> <span class="n">fit</span> <span class="o">:</span>
  <span class="o">?</span><span class="n">y</span><span class="o">:</span><span class="nn">Py</span><span class="p">.</span><span class="nn">Object</span><span class="p">.</span><span class="n">t</span> <span class="o">-&gt;</span>
  <span class="n">x</span><span class="o">:[`</span><span class="nc">Ndarray</span> <span class="k">of</span> <span class="nn">Ndarray</span><span class="p">.</span><span class="n">t</span> <span class="o">|</span> <span class="o">`</span><span class="nc">SparseMatrix</span> <span class="k">of</span> <span class="nn">Csr_matrix</span><span class="p">.</span><span class="n">t</span><span class="o">]</span> <span class="o">-&gt;</span>
  <span class="n">t</span> <span class="o">-&gt;</span>
  <span class="n">t</span>
</code></pre></div>

<p>Fit LSI model on training data X.</p>
<h4>Parameters</h4>
<details class="info" open="open"><summary>X : {array-like, sparse matrix}, shape (n_samples, n_features)</summary><p>Training data.</p>
</details>
<details class="info" open="open"><summary>y : Ignored</summary></details>
<h4>Returns</h4>
<details class="info" open="open"><summary>self : object</summary><p>Returns the transformer object.</p>
</details>
</details>
<h3 id="fit_transform_12">fit_transform<a class="headerlink" href="#fit_transform_12" title="Permanent link">&para;</a></h3>
<details class="note" open="open"><summary>method</summary><div class="highlight"><pre><span></span><code><span class="k">val</span> <span class="n">fit_transform</span> <span class="o">:</span>
  <span class="o">?</span><span class="n">y</span><span class="o">:</span><span class="nn">Py</span><span class="p">.</span><span class="nn">Object</span><span class="p">.</span><span class="n">t</span> <span class="o">-&gt;</span>
  <span class="n">x</span><span class="o">:[`</span><span class="nc">Ndarray</span> <span class="k">of</span> <span class="nn">Ndarray</span><span class="p">.</span><span class="n">t</span> <span class="o">|</span> <span class="o">`</span><span class="nc">SparseMatrix</span> <span class="k">of</span> <span class="nn">Csr_matrix</span><span class="p">.</span><span class="n">t</span><span class="o">]</span> <span class="o">-&gt;</span>
  <span class="n">t</span> <span class="o">-&gt;</span>
  <span class="nn">Ndarray</span><span class="p">.</span><span class="n">t</span>
</code></pre></div>

<p>Fit LSI model to X and perform dimensionality reduction on X.</p>
<h4>Parameters</h4>
<details class="info" open="open"><summary>X : {array-like, sparse matrix}, shape (n_samples, n_features)</summary><p>Training data.</p>
</details>
<details class="info" open="open"><summary>y : Ignored</summary></details>
<h4>Returns</h4>
<details class="info" open="open"><summary>X_new : array, shape (n_samples, n_components)</summary><p>Reduced version of X. This will always be a dense array.</p>
</details>
</details>
<h3 id="get_params_12">get_params<a class="headerlink" href="#get_params_12" title="Permanent link">&para;</a></h3>
<details class="note" open="open"><summary>method</summary><div class="highlight"><pre><span></span><code><span class="k">val</span> <span class="n">get_params</span> <span class="o">:</span>
  <span class="o">?</span><span class="n">deep</span><span class="o">:</span><span class="kt">bool</span> <span class="o">-&gt;</span>
  <span class="n">t</span> <span class="o">-&gt;</span>
  <span class="nn">Py</span><span class="p">.</span><span class="nn">Object</span><span class="p">.</span><span class="n">t</span>
</code></pre></div>

<p>Get parameters for this estimator.</p>
<h4>Parameters</h4>
<details class="info" open="open"><summary>deep : bool, default=True</summary><p>If True, will return the parameters for this estimator and
contained subobjects that are estimators.</p>
</details>
<h4>Returns</h4>
<details class="info" open="open"><summary>params : mapping of string to any</summary><p>Parameter names mapped to their values.</p>
</details>
</details>
<h3 id="inverse_transform_5">inverse_transform<a class="headerlink" href="#inverse_transform_5" title="Permanent link">&para;</a></h3>
<details class="note" open="open"><summary>method</summary><div class="highlight"><pre><span></span><code><span class="k">val</span> <span class="n">inverse_transform</span> <span class="o">:</span>
  <span class="n">x</span><span class="o">:</span><span class="nn">Ndarray</span><span class="p">.</span><span class="n">t</span> <span class="o">-&gt;</span>
  <span class="n">t</span> <span class="o">-&gt;</span>
  <span class="nn">Ndarray</span><span class="p">.</span><span class="n">t</span>
</code></pre></div>

<p>Transform X back to its original space.</p>
<p>Returns an array X_original whose transform would be X.</p>
<h4>Parameters</h4>
<details class="info" open="open"><summary>X : array-like, shape (n_samples, n_components)</summary><p>New data.</p>
</details>
<h4>Returns</h4>
<details class="info" open="open"><summary>X_original : array, shape (n_samples, n_features)</summary><p>Note that this is always a dense array.</p>
</details>
</details>
<h3 id="set_params_12">set_params<a class="headerlink" href="#set_params_12" title="Permanent link">&para;</a></h3>
<details class="note" open="open"><summary>method</summary><div class="highlight"><pre><span></span><code><span class="k">val</span> <span class="n">set_params</span> <span class="o">:</span>
  <span class="o">?</span><span class="n">params</span><span class="o">:(</span><span class="kt">string</span> <span class="o">*</span> <span class="nn">Py</span><span class="p">.</span><span class="nn">Object</span><span class="p">.</span><span class="n">t</span><span class="o">)</span> <span class="kt">list</span> <span class="o">-&gt;</span>
  <span class="n">t</span> <span class="o">-&gt;</span>
  <span class="n">t</span>
</code></pre></div>

<p>Set the parameters of this estimator.</p>
<p>The method works on simple estimators as well as on nested objects
(such as pipelines). The latter have parameters of the form
<code>&lt;component&gt;__&lt;parameter&gt;</code> so that it's possible to update each
component of a nested object.</p>
<h4>Parameters</h4>
<details class="info" open="open"><summary>**params : dict</summary><p>Estimator parameters.</p>
</details>
<h4>Returns</h4>
<details class="info" open="open"><summary>self : object</summary><p>Estimator instance.</p>
</details>
</details>
<h3 id="transform_12">transform<a class="headerlink" href="#transform_12" title="Permanent link">&para;</a></h3>
<details class="note" open="open"><summary>method</summary><div class="highlight"><pre><span></span><code><span class="k">val</span> <span class="n">transform</span> <span class="o">:</span>
  <span class="n">x</span><span class="o">:[`</span><span class="nc">Ndarray</span> <span class="k">of</span> <span class="nn">Ndarray</span><span class="p">.</span><span class="n">t</span> <span class="o">|</span> <span class="o">`</span><span class="nc">SparseMatrix</span> <span class="k">of</span> <span class="nn">Csr_matrix</span><span class="p">.</span><span class="n">t</span><span class="o">]</span> <span class="o">-&gt;</span>
  <span class="n">t</span> <span class="o">-&gt;</span>
  <span class="nn">Ndarray</span><span class="p">.</span><span class="n">t</span>
</code></pre></div>

<p>Perform dimensionality reduction on X.</p>
<h4>Parameters</h4>
<details class="info" open="open"><summary>X : {array-like, sparse matrix}, shape (n_samples, n_features)</summary><p>New data.</p>
</details>
<h4>Returns</h4>
<details class="info" open="open"><summary>X_new : array, shape (n_samples, n_components)</summary><p>Reduced version of X. This will always be a dense array.</p>
</details>
</details>
<h3 id="components__11">components_<a class="headerlink" href="#components__11" title="Permanent link">&para;</a></h3>
<details class="note" open="open"><summary>attribute</summary><div class="highlight"><pre><span></span><code><span class="k">val</span> <span class="n">components_</span> <span class="o">:</span> <span class="n">t</span> <span class="o">-&gt;</span> <span class="nn">Ndarray</span><span class="p">.</span><span class="n">t</span>
</code></pre></div>

<p>This attribute is documented in <code>create</code> above.</p>
</details>
<h3 id="explained_variance__2">explained_variance_<a class="headerlink" href="#explained_variance__2" title="Permanent link">&para;</a></h3>
<details class="note" open="open"><summary>attribute</summary><div class="highlight"><pre><span></span><code><span class="k">val</span> <span class="n">explained_variance_</span> <span class="o">:</span> <span class="n">t</span> <span class="o">-&gt;</span> <span class="nn">Ndarray</span><span class="p">.</span><span class="n">t</span>
</code></pre></div>

<p>This attribute is documented in <code>create</code> above.</p>
</details>
<h3 id="explained_variance_ratio__2">explained_variance_ratio_<a class="headerlink" href="#explained_variance_ratio__2" title="Permanent link">&para;</a></h3>
<details class="note" open="open"><summary>attribute</summary><div class="highlight"><pre><span></span><code><span class="k">val</span> <span class="n">explained_variance_ratio_</span> <span class="o">:</span> <span class="n">t</span> <span class="o">-&gt;</span> <span class="nn">Ndarray</span><span class="p">.</span><span class="n">t</span>
</code></pre></div>

<p>This attribute is documented in <code>create</code> above.</p>
</details>
<h3 id="singular_values__2">singular_values_<a class="headerlink" href="#singular_values__2" title="Permanent link">&para;</a></h3>
<details class="note" open="open"><summary>attribute</summary><div class="highlight"><pre><span></span><code><span class="k">val</span> <span class="n">singular_values_</span> <span class="o">:</span> <span class="n">t</span> <span class="o">-&gt;</span> <span class="nn">Ndarray</span><span class="p">.</span><span class="n">t</span>
</code></pre></div>

<p>This attribute is documented in <code>create</code> above.</p>
</details>
<h3 id="to_string_12">to_string<a class="headerlink" href="#to_string_12" title="Permanent link">&para;</a></h3>
<details class="note" open="open"><summary>method</summary><div class="highlight"><pre><span></span><code><span class="k">val</span> <span class="n">to_string</span><span class="o">:</span> <span class="n">t</span> <span class="o">-&gt;</span> <span class="kt">string</span>
</code></pre></div>

<p>Print the object to a human-readable representation.</p>
</details>
<h3 id="show_12">show<a class="headerlink" href="#show_12" title="Permanent link">&para;</a></h3>
<details class="note" open="open"><summary>method</summary><div class="highlight"><pre><span></span><code><span class="k">val</span> <span class="n">show</span><span class="o">:</span> <span class="n">t</span> <span class="o">-&gt;</span> <span class="kt">string</span>
</code></pre></div>

<p>Print the object to a human-readable representation.</p>
</details>
<h3 id="pp_12">pp<a class="headerlink" href="#pp_12" title="Permanent link">&para;</a></h3>
<details class="note" open="open"><summary>method</summary><div class="highlight"><pre><span></span><code><span class="k">val</span> <span class="n">pp</span><span class="o">:</span> <span class="nn">Format</span><span class="p">.</span><span class="n">formatter</span> <span class="o">-&gt;</span> <span class="n">t</span> <span class="o">-&gt;</span> <span class="kt">unit</span>
</code></pre></div>

<p>Pretty-print the object to a formatter.</p>
</details>
<h3 id="dict_learning">dict_learning<a class="headerlink" href="#dict_learning" title="Permanent link">&para;</a></h3>
<details class="note" open="open"><summary>function</summary><div class="highlight"><pre><span></span><code><span class="k">val</span> <span class="n">dict_learning</span> <span class="o">:</span>
  <span class="o">?</span><span class="n">max_iter</span><span class="o">:</span><span class="kt">int</span> <span class="o">-&gt;</span>
  <span class="o">?</span><span class="n">tol</span><span class="o">:</span><span class="kt">float</span> <span class="o">-&gt;</span>
  <span class="o">?</span><span class="n">method_</span><span class="o">:[`</span><span class="nc">Lars</span> <span class="o">|</span> <span class="o">`</span><span class="nc">Cd</span><span class="o">]</span> <span class="o">-&gt;</span>
  <span class="o">?</span><span class="n">n_jobs</span><span class="o">:[`</span><span class="nc">Int</span> <span class="k">of</span> <span class="kt">int</span> <span class="o">|</span> <span class="o">`</span><span class="nc">None</span><span class="o">]</span> <span class="o">-&gt;</span>
  <span class="o">?</span><span class="n">dict_init</span><span class="o">:</span><span class="nn">Ndarray</span><span class="p">.</span><span class="n">t</span> <span class="o">-&gt;</span>
  <span class="o">?</span><span class="n">code_init</span><span class="o">:</span><span class="nn">Ndarray</span><span class="p">.</span><span class="n">t</span> <span class="o">-&gt;</span>
  <span class="o">?</span><span class="n">callback</span><span class="o">:[`</span><span class="nc">Callable</span> <span class="k">of</span> <span class="nn">Py</span><span class="p">.</span><span class="nn">Object</span><span class="p">.</span><span class="n">t</span> <span class="o">|</span> <span class="o">`</span><span class="nc">None</span><span class="o">]</span> <span class="o">-&gt;</span>
  <span class="o">?</span><span class="n">verbose</span><span class="o">:</span><span class="kt">bool</span> <span class="o">-&gt;</span>
  <span class="o">?</span><span class="n">random_state</span><span class="o">:[`</span><span class="nc">Int</span> <span class="k">of</span> <span class="kt">int</span> <span class="o">|</span> <span class="o">`</span><span class="nc">RandomState</span> <span class="k">of</span> <span class="nn">Py</span><span class="p">.</span><span class="nn">Object</span><span class="p">.</span><span class="n">t</span> <span class="o">|</span> <span class="o">`</span><span class="nc">None</span><span class="o">]</span> <span class="o">-&gt;</span>
  <span class="o">?</span><span class="n">return_n_iter</span><span class="o">:</span><span class="kt">bool</span> <span class="o">-&gt;</span>
  <span class="o">?</span><span class="n">positive_dict</span><span class="o">:</span><span class="kt">bool</span> <span class="o">-&gt;</span>
  <span class="o">?</span><span class="n">positive_code</span><span class="o">:</span><span class="kt">bool</span> <span class="o">-&gt;</span>
  <span class="o">?</span><span class="n">method_max_iter</span><span class="o">:</span><span class="kt">int</span> <span class="o">-&gt;</span>
  <span class="n">x</span><span class="o">:</span><span class="nn">Ndarray</span><span class="p">.</span><span class="n">t</span> <span class="o">-&gt;</span>
  <span class="n">n_components</span><span class="o">:</span><span class="kt">int</span> <span class="o">-&gt;</span>
  <span class="n">alpha</span><span class="o">:</span><span class="kt">int</span> <span class="o">-&gt;</span>
  <span class="kt">unit</span> <span class="o">-&gt;</span>
  <span class="o">(</span><span class="nn">Ndarray</span><span class="p">.</span><span class="n">t</span> <span class="o">*</span> <span class="nn">Ndarray</span><span class="p">.</span><span class="n">t</span> <span class="o">*</span> <span class="nn">Ndarray</span><span class="p">.</span><span class="n">t</span> <span class="o">*</span> <span class="kt">int</span><span class="o">)</span>
</code></pre></div>

<p>Solves a dictionary learning matrix factorization problem.</p>
<p>Finds the best dictionary and the corresponding sparse code for
approximating the data matrix X by solving::</p>
<div class="codehilite"><pre><span></span><code>(U^*, V^* ) = argmin 0.5 || X - U V ||_2^2 + alpha * || U ||_1
             (U,V)
            with || V_k ||_2 = 1 for all  0 &lt;= k &lt; n_components
</code></pre></div>


<p>where V is the dictionary and U is the sparse code.</p>
<p>Read more in the :ref:<code>User Guide &lt;DictionaryLearning&gt;</code>.</p>
<h4>Parameters</h4>
<details class="info" open="open"><summary>X : array of shape (n_samples, n_features)</summary><p>Data matrix.</p>
</details>
<details class="info" open="open"><summary>n_components : int,</summary><p>Number of dictionary atoms to extract.</p>
</details>
<details class="info" open="open"><summary>alpha : int,</summary><p>Sparsity controlling parameter.</p>
</details>
<details class="info" open="open"><summary>max_iter : int,</summary><p>Maximum number of iterations to perform.</p>
</details>
<details class="info" open="open"><summary>tol : float,</summary><p>Tolerance for the stopping condition.</p>
</details>
<details class="info" open="open"><summary>method : {'lars', 'cd'}</summary></details>
<details class="info" open="open"><summary>lars: uses the least angle regression method to solve the lasso problem</summary><p>(linear_model.lars_path)</p>
</details>
<details class="info" open="open"><summary>cd: uses the coordinate descent method to compute the</summary><p>Lasso solution (linear_model.Lasso). Lars will be faster if
the estimated components are sparse.</p>
</details>
<details class="info" open="open"><summary>n_jobs : int or None, optional (default=None)</summary><p>Number of parallel jobs to run.
<code>None</code> means 1 unless in a :obj:<code>joblib.parallel_backend</code> context.
<code>-1</code> means using all processors. See :term:<code>Glossary &lt;n_jobs&gt;</code>
for more details.</p>
</details>
<details class="info" open="open"><summary>dict_init : array of shape (n_components, n_features),</summary><p>Initial value for the dictionary for warm restart scenarios.</p>
</details>
<details class="info" open="open"><summary>code_init : array of shape (n_samples, n_components),</summary><p>Initial value for the sparse code for warm restart scenarios.</p>
</details>
<details class="info" open="open"><summary>callback : callable or None, optional (default: None)</summary><p>Callable that gets invoked every five iterations</p>
</details>
<details class="info" open="open"><summary>verbose : bool, optional (default: False)</summary><p>To control the verbosity of the procedure.</p>
</details>
<details class="info" open="open"><summary>random_state : int, RandomState instance or None, optional (default=None)</summary><p>If int, random_state is the seed used by the random number generator;
If RandomState instance, random_state is the random number generator;
If None, the random number generator is the RandomState instance used
by <code>np.random</code>.</p>
</details>
<details class="info" open="open"><summary>return_n_iter : bool</summary><p>Whether or not to return the number of iterations.</p>
</details>
<details class="info" open="open"><summary>positive_dict : bool</summary><p>Whether to enforce positivity when finding the dictionary.</p>
<p>.. versionadded:: 0.20</p>
</details>
<details class="info" open="open"><summary>positive_code : bool</summary><p>Whether to enforce positivity when finding the code.</p>
<p>.. versionadded:: 0.20</p>
</details>
<details class="info" open="open"><summary>method_max_iter : int, optional (default=1000)</summary><p>Maximum number of iterations to perform.</p>
<p>.. versionadded:: 0.22</p>
</details>
<h4>Returns</h4>
<details class="info" open="open"><summary>code : array of shape (n_samples, n_components)</summary><p>The sparse code factor in the matrix factorization.</p>
</details>
<details class="info" open="open"><summary>dictionary : array of shape (n_components, n_features),</summary><p>The dictionary factor in the matrix factorization.</p>
</details>
<details class="info" open="open"><summary>errors : array</summary><p>Vector of errors at each iteration.</p>
</details>
<details class="info" open="open"><summary>n_iter : int</summary><p>Number of iterations run. Returned only if <code>return_n_iter</code> is
set to True.</p>
</details>
<h4>See also</h4>
<p>dict_learning_online
DictionaryLearning
MiniBatchDictionaryLearning
SparsePCA
MiniBatchSparsePCA</p>
</details>
<h3 id="dict_learning_online">dict_learning_online<a class="headerlink" href="#dict_learning_online" title="Permanent link">&para;</a></h3>
<details class="note" open="open"><summary>function</summary><div class="highlight"><pre><span></span><code><span class="k">val</span> <span class="n">dict_learning_online</span> <span class="o">:</span>
  <span class="o">?</span><span class="n">n_components</span><span class="o">:</span><span class="kt">int</span> <span class="o">-&gt;</span>
  <span class="o">?</span><span class="n">alpha</span><span class="o">:</span><span class="kt">float</span> <span class="o">-&gt;</span>
  <span class="o">?</span><span class="n">n_iter</span><span class="o">:</span><span class="kt">int</span> <span class="o">-&gt;</span>
  <span class="o">?</span><span class="n">return_code</span><span class="o">:</span><span class="kt">bool</span> <span class="o">-&gt;</span>
  <span class="o">?</span><span class="n">dict_init</span><span class="o">:</span><span class="nn">Ndarray</span><span class="p">.</span><span class="n">t</span> <span class="o">-&gt;</span>
  <span class="o">?</span><span class="n">callback</span><span class="o">:[`</span><span class="nc">Callable</span> <span class="k">of</span> <span class="nn">Py</span><span class="p">.</span><span class="nn">Object</span><span class="p">.</span><span class="n">t</span> <span class="o">|</span> <span class="o">`</span><span class="nc">None</span><span class="o">]</span> <span class="o">-&gt;</span>
  <span class="o">?</span><span class="n">batch_size</span><span class="o">:</span><span class="kt">int</span> <span class="o">-&gt;</span>
  <span class="o">?</span><span class="n">verbose</span><span class="o">:</span><span class="kt">bool</span> <span class="o">-&gt;</span>
  <span class="o">?</span><span class="n">shuffle</span><span class="o">:</span><span class="kt">bool</span> <span class="o">-&gt;</span>
  <span class="o">?</span><span class="n">n_jobs</span><span class="o">:[`</span><span class="nc">Int</span> <span class="k">of</span> <span class="kt">int</span> <span class="o">|</span> <span class="o">`</span><span class="nc">None</span><span class="o">]</span> <span class="o">-&gt;</span>
  <span class="o">?</span><span class="n">method_</span><span class="o">:[`</span><span class="nc">Lars</span> <span class="o">|</span> <span class="o">`</span><span class="nc">Cd</span><span class="o">]</span> <span class="o">-&gt;</span>
  <span class="o">?</span><span class="n">iter_offset</span><span class="o">:</span><span class="kt">int</span> <span class="o">-&gt;</span>
  <span class="o">?</span><span class="n">random_state</span><span class="o">:[`</span><span class="nc">Int</span> <span class="k">of</span> <span class="kt">int</span> <span class="o">|</span> <span class="o">`</span><span class="nc">RandomState</span> <span class="k">of</span> <span class="nn">Py</span><span class="p">.</span><span class="nn">Object</span><span class="p">.</span><span class="n">t</span> <span class="o">|</span> <span class="o">`</span><span class="nc">None</span><span class="o">]</span> <span class="o">-&gt;</span>
  <span class="o">?</span><span class="n">return_inner_stats</span><span class="o">:</span><span class="kt">bool</span> <span class="o">-&gt;</span>
  <span class="o">?</span><span class="n">inner_stats</span><span class="o">:</span><span class="nn">Py</span><span class="p">.</span><span class="nn">Object</span><span class="p">.</span><span class="n">t</span> <span class="o">-&gt;</span>
  <span class="o">?</span><span class="n">return_n_iter</span><span class="o">:</span><span class="kt">bool</span> <span class="o">-&gt;</span>
  <span class="o">?</span><span class="n">positive_dict</span><span class="o">:</span><span class="kt">bool</span> <span class="o">-&gt;</span>
  <span class="o">?</span><span class="n">positive_code</span><span class="o">:</span><span class="kt">bool</span> <span class="o">-&gt;</span>
  <span class="o">?</span><span class="n">method_max_iter</span><span class="o">:</span><span class="kt">int</span> <span class="o">-&gt;</span>
  <span class="n">x</span><span class="o">:</span><span class="nn">Ndarray</span><span class="p">.</span><span class="n">t</span> <span class="o">-&gt;</span>
  <span class="kt">unit</span> <span class="o">-&gt;</span>
  <span class="o">(</span><span class="nn">Ndarray</span><span class="p">.</span><span class="n">t</span> <span class="o">*</span> <span class="nn">Ndarray</span><span class="p">.</span><span class="n">t</span> <span class="o">*</span> <span class="kt">int</span><span class="o">)</span>
</code></pre></div>

<p>Solves a dictionary learning matrix factorization problem online.</p>
<p>Finds the best dictionary and the corresponding sparse code for
approximating the data matrix X by solving::</p>
<div class="codehilite"><pre><span></span><code>(U^*, V^* ) = argmin 0.5 || X - U V ||_2^2 + alpha * || U ||_1
             (U,V)
             with || V_k ||_2 = 1 for all  0 &lt;= k &lt; n_components
</code></pre></div>


<p>where V is the dictionary and U is the sparse code. This is
accomplished by repeatedly iterating over mini-batches by slicing
the input data.</p>
<p>Read more in the :ref:<code>User Guide &lt;DictionaryLearning&gt;</code>.</p>
<h4>Parameters</h4>
<details class="info" open="open"><summary>X : array of shape (n_samples, n_features)</summary><p>Data matrix.</p>
</details>
<details class="info" open="open"><summary>n_components : int,</summary><p>Number of dictionary atoms to extract.</p>
</details>
<details class="info" open="open"><summary>alpha : float,</summary><p>Sparsity controlling parameter.</p>
</details>
<details class="info" open="open"><summary>n_iter : int,</summary><p>Number of mini-batch iterations to perform.</p>
</details>
<details class="info" open="open"><summary>return_code : boolean,</summary><p>Whether to also return the code U or just the dictionary V.</p>
</details>
<details class="info" open="open"><summary>dict_init : array of shape (n_components, n_features),</summary><p>Initial value for the dictionary for warm restart scenarios.</p>
</details>
<details class="info" open="open"><summary>callback : callable or None, optional (default: None)</summary><p>callable that gets invoked every five iterations</p>
</details>
<details class="info" open="open"><summary>batch_size : int,</summary><p>The number of samples to take in each batch.</p>
</details>
<details class="info" open="open"><summary>verbose : bool, optional (default: False)</summary><p>To control the verbosity of the procedure.</p>
</details>
<details class="info" open="open"><summary>shuffle : boolean,</summary><p>Whether to shuffle the data before splitting it in batches.</p>
</details>
<details class="info" open="open"><summary>n_jobs : int or None, optional (default=None)</summary><p>Number of parallel jobs to run.
<code>None</code> means 1 unless in a :obj:<code>joblib.parallel_backend</code> context.
<code>-1</code> means using all processors. See :term:<code>Glossary &lt;n_jobs&gt;</code>
for more details.</p>
</details>
<details class="info" open="open"><summary>method : {'lars', 'cd'}</summary></details>
<details class="info" open="open"><summary>lars: uses the least angle regression method to solve the lasso problem</summary><p>(linear_model.lars_path)</p>
</details>
<details class="info" open="open"><summary>cd: uses the coordinate descent method to compute the</summary><p>Lasso solution (linear_model.Lasso). Lars will be faster if
the estimated components are sparse.</p>
</details>
<details class="info" open="open"><summary>iter_offset : int, default 0</summary><p>Number of previous iterations completed on the dictionary used for
initialization.</p>
</details>
<details class="info" open="open"><summary>random_state : int, RandomState instance or None, optional (default=None)</summary><p>If int, random_state is the seed used by the random number generator;
If RandomState instance, random_state is the random number generator;
If None, the random number generator is the RandomState instance used
by <code>np.random</code>.</p>
</details>
<details class="info" open="open"><summary>return_inner_stats : boolean, optional</summary><p>Return the inner statistics A (dictionary covariance) and B
(data approximation). Useful to restart the algorithm in an
online setting. If return_inner_stats is True, return_code is
ignored</p>
</details>
<details class="info" open="open"><summary>inner_stats : tuple of (A, B) ndarrays</summary><p>Inner sufficient statistics that are kept by the algorithm.
Passing them at initialization is useful in online settings, to
avoid losing the history of the evolution.
A (n_components, n_components) is the dictionary covariance matrix.
B (n_features, n_components) is the data approximation matrix</p>
</details>
<details class="info" open="open"><summary>return_n_iter : bool</summary><p>Whether or not to return the number of iterations.</p>
</details>
<details class="info" open="open"><summary>positive_dict : bool</summary><p>Whether to enforce positivity when finding the dictionary.</p>
<p>.. versionadded:: 0.20</p>
</details>
<details class="info" open="open"><summary>positive_code : bool</summary><p>Whether to enforce positivity when finding the code.</p>
<p>.. versionadded:: 0.20</p>
</details>
<details class="info" open="open"><summary>method_max_iter : int, optional (default=1000)</summary><p>Maximum number of iterations to perform when solving the lasso problem.</p>
<p>.. versionadded:: 0.22</p>
</details>
<h4>Returns</h4>
<details class="info" open="open"><summary>code : array of shape (n_samples, n_components),</summary><p>the sparse code (only returned if <code>return_code=True</code>)</p>
</details>
<details class="info" open="open"><summary>dictionary : array of shape (n_components, n_features),</summary><p>the solutions to the dictionary learning problem</p>
</details>
<details class="info" open="open"><summary>n_iter : int</summary><p>Number of iterations run. Returned only if <code>return_n_iter</code> is
set to <code>True</code>.</p>
</details>
<h4>See also</h4>
<p>dict_learning
DictionaryLearning
MiniBatchDictionaryLearning
SparsePCA
MiniBatchSparsePCA</p>
</details>
<h3 id="fastica">fastica<a class="headerlink" href="#fastica" title="Permanent link">&para;</a></h3>
<details class="note" open="open"><summary>function</summary><div class="highlight"><pre><span></span><code><span class="k">val</span> <span class="n">fastica</span> <span class="o">:</span>
  <span class="o">?</span><span class="n">n_components</span><span class="o">:</span><span class="kt">int</span> <span class="o">-&gt;</span>
  <span class="o">?</span><span class="n">algorithm</span><span class="o">:[`</span><span class="nc">Parallel</span> <span class="o">|</span> <span class="o">`</span><span class="nc">Deflation</span><span class="o">]</span> <span class="o">-&gt;</span>
  <span class="o">?</span><span class="n">whiten</span><span class="o">:</span><span class="kt">bool</span> <span class="o">-&gt;</span>
  <span class="o">?</span><span class="n">fun_</span><span class="o">:[`</span><span class="nc">String</span> <span class="k">of</span> <span class="kt">string</span> <span class="o">|</span> <span class="o">`</span><span class="nc">Callable</span> <span class="k">of</span> <span class="nn">Py</span><span class="p">.</span><span class="nn">Object</span><span class="p">.</span><span class="n">t</span><span class="o">]</span> <span class="o">-&gt;</span>
  <span class="o">?</span><span class="n">fun_args</span><span class="o">:</span><span class="nn">Py</span><span class="p">.</span><span class="nn">Object</span><span class="p">.</span><span class="n">t</span> <span class="o">-&gt;</span>
  <span class="o">?</span><span class="n">max_iter</span><span class="o">:</span><span class="kt">int</span> <span class="o">-&gt;</span>
  <span class="o">?</span><span class="n">tol</span><span class="o">:</span><span class="kt">float</span> <span class="o">-&gt;</span>
  <span class="o">?</span><span class="n">w_init</span><span class="o">:</span><span class="nn">Py</span><span class="p">.</span><span class="nn">Object</span><span class="p">.</span><span class="n">t</span> <span class="o">-&gt;</span>
  <span class="o">?</span><span class="n">random_state</span><span class="o">:[`</span><span class="nc">Int</span> <span class="k">of</span> <span class="kt">int</span> <span class="o">|</span> <span class="o">`</span><span class="nc">RandomState</span> <span class="k">of</span> <span class="nn">Py</span><span class="p">.</span><span class="nn">Object</span><span class="p">.</span><span class="n">t</span> <span class="o">|</span> <span class="o">`</span><span class="nc">None</span><span class="o">]</span> <span class="o">-&gt;</span>
  <span class="o">?</span><span class="n">return_X_mean</span><span class="o">:</span><span class="kt">bool</span> <span class="o">-&gt;</span>
  <span class="o">?</span><span class="n">compute_sources</span><span class="o">:</span><span class="kt">bool</span> <span class="o">-&gt;</span>
  <span class="o">?</span><span class="n">return_n_iter</span><span class="o">:</span><span class="kt">bool</span> <span class="o">-&gt;</span>
  <span class="n">x</span><span class="o">:</span><span class="nn">Ndarray</span><span class="p">.</span><span class="n">t</span> <span class="o">-&gt;</span>
  <span class="kt">unit</span> <span class="o">-&gt;</span>
  <span class="o">(</span><span class="nn">Py</span><span class="p">.</span><span class="nn">Object</span><span class="p">.</span><span class="n">t</span> <span class="o">*</span> <span class="nn">Ndarray</span><span class="p">.</span><span class="n">t</span> <span class="o">*</span> <span class="nn">Py</span><span class="p">.</span><span class="nn">Object</span><span class="p">.</span><span class="n">t</span> <span class="o">*</span> <span class="nn">Ndarray</span><span class="p">.</span><span class="n">t</span> <span class="o">*</span> <span class="kt">int</span><span class="o">)</span>
</code></pre></div>

<p>Perform Fast Independent Component Analysis.</p>
<p>Read more in the :ref:<code>User Guide &lt;ICA&gt;</code>.</p>
<h4>Parameters</h4>
<details class="info" open="open"><summary>X : array-like, shape (n_samples, n_features)</summary><p>Training vector, where n_samples is the number of samples and
n_features is the number of features.</p>
</details>
<details class="info" open="open"><summary>n_components : int, optional</summary><p>Number of components to extract. If None no dimension reduction
is performed.</p>
</details>
<details class="info" open="open"><summary>algorithm : {'parallel', 'deflation'}, optional</summary><p>Apply a parallel or deflational FASTICA algorithm.</p>
</details>
<details class="info" open="open"><summary>whiten : boolean, optional</summary><p>If True perform an initial whitening of the data.
If False, the data is assumed to have already been</p>
</details>
<details class="info" open="open"><summary>preprocessed: it should be centered, normed and white.</summary><p>Otherwise you will get incorrect results.
In this case the parameter n_components will be ignored.</p>
</details>
<details class="info" open="open"><summary>fun : string or function, optional. Default: 'logcosh'</summary><p>The functional form of the G function used in the
approximation to neg-entropy. Could be either 'logcosh', 'exp',
or 'cube'.
You can also provide your own function. It should return a tuple
containing the value of the function, and of its derivative, in the
point. The derivative should be averaged along its last dimension.
Example:</p>
<p>def my_g(x):
    return x <strong> 3, np.mean(3 * x </strong> 2, axis=-1)</p>
</details>
<details class="info" open="open"><summary>fun_args : dictionary, optional</summary><p>Arguments to send to the functional form.
If empty or None and if fun='logcosh', fun_args will take value
{'alpha' : 1.0}</p>
</details>
<details class="info" open="open"><summary>max_iter : int, optional</summary><p>Maximum number of iterations to perform.</p>
</details>
<details class="info" open="open"><summary>tol : float, optional</summary><p>A positive scalar giving the tolerance at which the
un-mixing matrix is considered to have converged.</p>
</details>
<details class="info" open="open"><summary>w_init : (n_components, n_components) array, optional</summary><p>Initial un-mixing array of dimension (n.comp,n.comp).
If None (default) then an array of normal r.v.'s is used.</p>
</details>
<details class="info" open="open"><summary>random_state : int, RandomState instance or None, optional (default=None)</summary><p>If int, random_state is the seed used by the random number generator;
If RandomState instance, random_state is the random number generator;
If None, the random number generator is the RandomState instance used
by <code>np.random</code>.</p>
</details>
<details class="info" open="open"><summary>return_X_mean : bool, optional</summary><p>If True, X_mean is returned too.</p>
</details>
<details class="info" open="open"><summary>compute_sources : bool, optional</summary><p>If False, sources are not computed, but only the rotation matrix.
This can save memory when working with big data. Defaults to True.</p>
</details>
<details class="info" open="open"><summary>return_n_iter : bool, optional</summary><p>Whether or not to return the number of iterations.</p>
</details>
<h4>Returns</h4>
<details class="info" open="open"><summary>K : array, shape (n_components, n_features) | None.</summary><p>If whiten is 'True', K is the pre-whitening matrix that projects data
onto the first n_components principal components. If whiten is 'False',
K is 'None'.</p>
</details>
<details class="info" open="open"><summary>W : array, shape (n_components, n_components)</summary><p>The square matrix that unmixes the data after whitening.
The mixing matrix is the pseudo-inverse of matrix <code>W K</code>
if K is not None, else it is the inverse of W.</p>
</details>
<details class="info" open="open"><summary>S : array, shape (n_samples, n_components) | None</summary><p>Estimated source matrix</p>
</details>
<details class="info" open="open"><summary>X_mean : array, shape (n_features, )</summary><p>The mean over features. Returned only if return_X_mean is True.</p>
</details>
<details class="info" open="open"><summary>n_iter : int</summary><p>If the algorithm is "deflation", n_iter is the
maximum number of iterations run across all components. Else
they are just the number of iterations taken to converge. This is
returned only when return_n_iter is set to <code>True</code>.</p>
</details>
<h4>Notes</h4>
<p>The data matrix X is considered to be a linear combination of
non-Gaussian (independent) components i.e. X = AS where columns of S
contain the independent components and A is a linear mixing
matrix. In short ICA attempts to `un-mix' the data by estimating an
un-mixing matrix W where <code>S = W K X.</code>
While FastICA was proposed to estimate as many sources
as features, it is possible to estimate less by setting
n_components &lt; n_features. It this case K is not a square matrix
and the estimated A is the pseudo-inverse of <code>W K</code>.</p>
<p>This implementation was originally made for data of shape
[n_features, n_samples]. Now the input is transposed
before the algorithm is applied. This makes it slightly
faster for Fortran-ordered input.</p>
<p>Implemented using FastICA:
<em>A. Hyvarinen and E. Oja, Independent Component Analysis:
Algorithms and Applications, Neural Networks, 13(4-5), 2000,
pp. 411-430</em></p>
</details>
<h3 id="non_negative_factorization">non_negative_factorization<a class="headerlink" href="#non_negative_factorization" title="Permanent link">&para;</a></h3>
<details class="note" open="open"><summary>function</summary><div class="highlight"><pre><span></span><code><span class="k">val</span> <span class="n">non_negative_factorization</span> <span class="o">:</span>
  <span class="o">?</span><span class="n">w</span><span class="o">:</span><span class="nn">Ndarray</span><span class="p">.</span><span class="n">t</span> <span class="o">-&gt;</span>
  <span class="o">?</span><span class="n">h</span><span class="o">:</span><span class="nn">Ndarray</span><span class="p">.</span><span class="n">t</span> <span class="o">-&gt;</span>
  <span class="o">?</span><span class="n">n_components</span><span class="o">:</span><span class="kt">int</span> <span class="o">-&gt;</span>
  <span class="o">?</span><span class="n">init</span><span class="o">:[`</span><span class="nc">Random</span> <span class="o">|</span> <span class="o">`</span><span class="nc">Nndsvd</span> <span class="o">|</span> <span class="o">`</span><span class="nc">Nndsvda</span> <span class="o">|</span> <span class="o">`</span><span class="nc">Nndsvdar</span> <span class="o">|</span> <span class="o">`</span><span class="nc">Custom</span> <span class="o">|</span> <span class="o">`</span><span class="nc">None</span><span class="o">]</span> <span class="o">-&gt;</span>
  <span class="o">?</span><span class="n">update_H</span><span class="o">:</span><span class="kt">bool</span> <span class="o">-&gt;</span>
  <span class="o">?</span><span class="n">solver</span><span class="o">:[`</span><span class="nc">Cd</span> <span class="o">|</span> <span class="o">`</span><span class="nc">Mu</span><span class="o">]</span> <span class="o">-&gt;</span>
  <span class="o">?</span><span class="n">beta_loss</span><span class="o">:[`</span><span class="nc">Float</span> <span class="k">of</span> <span class="kt">float</span> <span class="o">|</span> <span class="o">`</span><span class="nc">String</span> <span class="k">of</span> <span class="kt">string</span><span class="o">]</span> <span class="o">-&gt;</span>
  <span class="o">?</span><span class="n">tol</span><span class="o">:</span><span class="kt">float</span> <span class="o">-&gt;</span>
  <span class="o">?</span><span class="n">max_iter</span><span class="o">:</span><span class="kt">int</span> <span class="o">-&gt;</span>
  <span class="o">?</span><span class="n">alpha</span><span class="o">:</span><span class="kt">float</span> <span class="o">-&gt;</span>
  <span class="o">?</span><span class="n">l1_ratio</span><span class="o">:</span><span class="kt">float</span> <span class="o">-&gt;</span>
  <span class="o">?</span><span class="n">regularization</span><span class="o">:[`</span><span class="nc">Both</span> <span class="o">|</span> <span class="o">`</span><span class="nc">Components</span> <span class="o">|</span> <span class="o">`</span><span class="nc">Transformation</span> <span class="o">|</span> <span class="o">`</span><span class="nc">None</span><span class="o">]</span> <span class="o">-&gt;</span>
  <span class="o">?</span><span class="n">random_state</span><span class="o">:[`</span><span class="nc">Int</span> <span class="k">of</span> <span class="kt">int</span> <span class="o">|</span> <span class="o">`</span><span class="nc">RandomState</span> <span class="k">of</span> <span class="nn">Py</span><span class="p">.</span><span class="nn">Object</span><span class="p">.</span><span class="n">t</span> <span class="o">|</span> <span class="o">`</span><span class="nc">None</span><span class="o">]</span> <span class="o">-&gt;</span>
  <span class="o">?</span><span class="n">verbose</span><span class="o">:</span><span class="kt">int</span> <span class="o">-&gt;</span>
  <span class="o">?</span><span class="n">shuffle</span><span class="o">:</span><span class="kt">bool</span> <span class="o">-&gt;</span>
  <span class="n">x</span><span class="o">:</span><span class="nn">Ndarray</span><span class="p">.</span><span class="n">t</span> <span class="o">-&gt;</span>
  <span class="kt">unit</span> <span class="o">-&gt;</span>
  <span class="o">(</span><span class="nn">Ndarray</span><span class="p">.</span><span class="n">t</span> <span class="o">*</span> <span class="nn">Ndarray</span><span class="p">.</span><span class="n">t</span> <span class="o">*</span> <span class="kt">int</span><span class="o">)</span>
</code></pre></div>

<p>Compute Non-negative Matrix Factorization (NMF)</p>
<p>Find two non-negative matrices (W, H) whose product approximates the non-
negative matrix X. This factorization can be used for example for
dimensionality reduction, source separation or topic extraction.</p>
<p>The objective function is::</p>
<div class="codehilite"><pre><span></span><code>0.5 * ||X - WH||_Fro^2
+ alpha * l1_ratio * ||vec(W)||_1
+ alpha * l1_ratio * ||vec(H)||_1
+ 0.5 * alpha * (1 - l1_ratio) * ||W||_Fro^2
+ 0.5 * alpha * (1 - l1_ratio) * ||H||_Fro^2
</code></pre></div>


<details class="info" open="open"><summary>Where::</summary><p>||A||<em>Fro^2 = \sum</em>{i,j} A_{ij}^2 (Frobenius norm)
||vec(A)||<em>1 = \sum</em>{i,j} abs(A_{ij}) (Elementwise L1 norm)</p>
</details>
<p>For multiplicative-update ('mu') solver, the Frobenius norm
(0.5 * ||X - WH||_Fro^2) can be changed into another beta-divergence loss,
by changing the beta_loss parameter.</p>
<p>The objective function is minimized with an alternating minimization of W
and H. If H is given and update_H=False, it solves for W only.</p>
<h4>Parameters</h4>
<details class="info" open="open"><summary>X : array-like, shape (n_samples, n_features)</summary><p>Constant matrix.</p>
</details>
<details class="info" open="open"><summary>W : array-like, shape (n_samples, n_components)</summary><p>If init='custom', it is used as initial guess for the solution.</p>
</details>
<details class="info" open="open"><summary>H : array-like, shape (n_components, n_features)</summary><p>If init='custom', it is used as initial guess for the solution.
If update_H=False, it is used as a constant, to solve for W only.</p>
</details>
<details class="info" open="open"><summary>n_components : integer</summary><p>Number of components, if n_components is not set all features
are kept.</p>
</details>
<details class="info" open="open"><summary>init : None | 'random' | 'nndsvd' | 'nndsvda' | 'nndsvdar' | 'custom'</summary><p>Method used to initialize the procedure.</p>
</details>
<details class="info" open="open"><summary>Default: 'random'.</summary><p>The default value will change from 'random' to None in version 0.23
to make it consistent with decomposition.NMF.</p>
<p>Valid options:</p>
<ul>
<li>
<p>None: 'nndsvd' if n_components &lt; n_features, otherwise 'random'.</p>
</li>
<li>
<p>'random': non-negative random matrices, scaled with:
    sqrt(X.mean() / n_components)</p>
</li>
<li>
<p>'nndsvd': Nonnegative Double Singular Value Decomposition (NNDSVD)
    initialization (better for sparseness)</p>
</li>
<li>
<p>'nndsvda': NNDSVD with zeros filled with the average of X
    (better when sparsity is not desired)</p>
</li>
<li>
<p>'nndsvdar': NNDSVD with zeros filled with small random values
    (generally faster, less accurate alternative to NNDSVDa
    for when sparsity is not desired)</p>
</li>
<li>
<p>'custom': use custom matrices W and H</p>
</li>
</ul>
</details>
<details class="info" open="open"><summary>update_H : boolean, default: True</summary><p>Set to True, both W and H will be estimated from initial guesses.
Set to False, only W will be estimated.</p>
</details>
<details class="info" open="open"><summary>solver : 'cd' | 'mu'</summary><p>Numerical solver to use:</p>
<ul>
<li>
<p>'cd' is a Coordinate Descent solver that uses Fast Hierarchical
    Alternating Least Squares (Fast HALS).</p>
</li>
<li>
<p>'mu' is a Multiplicative Update solver.</p>
</li>
</ul>
<p>.. versionadded:: 0.17
   Coordinate Descent solver.</p>
<p>.. versionadded:: 0.19
   Multiplicative Update solver.</p>
</details>
<details class="info" open="open"><summary>beta_loss : float or string, default 'frobenius'</summary><p>String must be in {'frobenius', 'kullback-leibler', 'itakura-saito'}.
Beta divergence to be minimized, measuring the distance between X
and the dot product WH. Note that values different from 'frobenius'
(or 2) and 'kullback-leibler' (or 1) lead to significantly slower
fits. Note that for beta_loss &lt;= 0 (or 'itakura-saito'), the input
matrix X cannot contain zeros. Used only in 'mu' solver.</p>
<p>.. versionadded:: 0.19</p>
</details>
<details class="info" open="open"><summary>tol : float, default: 1e-4</summary><p>Tolerance of the stopping condition.</p>
</details>
<details class="info" open="open"><summary>max_iter : integer, default: 200</summary><p>Maximum number of iterations before timing out.</p>
</details>
<details class="info" open="open"><summary>alpha : double, default: 0.</summary><p>Constant that multiplies the regularization terms.</p>
</details>
<details class="info" open="open"><summary>l1_ratio : double, default: 0.</summary><p>The regularization mixing parameter, with 0 &lt;= l1_ratio &lt;= 1.
For l1_ratio = 0 the penalty is an elementwise L2 penalty
(aka Frobenius Norm).
For l1_ratio = 1 it is an elementwise L1 penalty.
For 0 &lt; l1_ratio &lt; 1, the penalty is a combination of L1 and L2.</p>
</details>
<details class="info" open="open"><summary>regularization : 'both' | 'components' | 'transformation' | None</summary><p>Select whether the regularization affects the components (H), the
transformation (W), both or none of them.</p>
</details>
<details class="info" open="open"><summary>random_state : int, RandomState instance or None, optional, default: None</summary><p>If int, random_state is the seed used by the random number generator;
If RandomState instance, random_state is the random number generator;
If None, the random number generator is the RandomState instance used
by <code>np.random</code>.</p>
</details>
<details class="info" open="open"><summary>verbose : integer, default: 0</summary><p>The verbosity level.</p>
</details>
<details class="info" open="open"><summary>shuffle : boolean, default: False</summary><p>If true, randomize the order of coordinates in the CD solver.</p>
</details>
<h4>Returns</h4>
<details class="info" open="open"><summary>W : array-like, shape (n_samples, n_components)</summary><p>Solution to the non-negative least squares problem.</p>
</details>
<details class="info" open="open"><summary>H : array-like, shape (n_components, n_features)</summary><p>Solution to the non-negative least squares problem.</p>
</details>
<details class="info" open="open"><summary>n_iter : int</summary><p>Actual number of iterations.</p>
</details>
<h4>Examples</h4>
<div class="highlight"><pre><span></span><code><span class="o">&gt;&gt;&gt;</span> <span class="kn">import</span> <span class="nn">numpy</span> <span class="k">as</span> <span class="nn">np</span>
<span class="o">&gt;&gt;&gt;</span> <span class="n">X</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">array</span><span class="p">([[</span><span class="mi">1</span><span class="p">,</span><span class="mi">1</span><span class="p">],</span> <span class="p">[</span><span class="mi">2</span><span class="p">,</span> <span class="mi">1</span><span class="p">],</span> <span class="p">[</span><span class="mi">3</span><span class="p">,</span> <span class="mf">1.2</span><span class="p">],</span> <span class="p">[</span><span class="mi">4</span><span class="p">,</span> <span class="mi">1</span><span class="p">],</span> <span class="p">[</span><span class="mi">5</span><span class="p">,</span> <span class="mf">0.8</span><span class="p">],</span> <span class="p">[</span><span class="mi">6</span><span class="p">,</span> <span class="mi">1</span><span class="p">]])</span>
<span class="o">&gt;&gt;&gt;</span> <span class="kn">from</span> <span class="nn">sklearn.decomposition</span> <span class="kn">import</span> <span class="n">non_negative_factorization</span>
<span class="o">&gt;&gt;&gt;</span> <span class="n">W</span><span class="p">,</span> <span class="n">H</span><span class="p">,</span> <span class="n">n_iter</span> <span class="o">=</span> <span class="n">non_negative_factorization</span><span class="p">(</span><span class="n">X</span><span class="p">,</span> <span class="n">n_components</span><span class="o">=</span><span class="mi">2</span><span class="p">,</span>
<span class="o">...</span> <span class="n">init</span><span class="o">=</span><span class="s1">&#39;random&#39;</span><span class="p">,</span> <span class="n">random_state</span><span class="o">=</span><span class="mi">0</span><span class="p">)</span>
</code></pre></div>

<h4>References</h4>
<p>Cichocki, Andrzej, and P. H. A. N. Anh-Huy. "Fast local algorithms for
large scale nonnegative matrix and tensor factorizations."
IEICE transactions on fundamentals of electronics, communications and
computer sciences 92.3: 708-721, 2009.</p>
<p>Fevotte, C., &amp; Idier, J. (2011). Algorithms for nonnegative matrix
factorization with the beta-divergence. Neural Computation, 23(9).</p>
</details>
<h3 id="randomized_svd">randomized_svd<a class="headerlink" href="#randomized_svd" title="Permanent link">&para;</a></h3>
<details class="note" open="open"><summary>function</summary><div class="highlight"><pre><span></span><code><span class="k">val</span> <span class="n">randomized_svd</span> <span class="o">:</span>
  <span class="o">?</span><span class="n">n_oversamples</span><span class="o">:</span><span class="nn">Py</span><span class="p">.</span><span class="nn">Object</span><span class="p">.</span><span class="n">t</span> <span class="o">-&gt;</span>
  <span class="o">?</span><span class="n">n_iter</span><span class="o">:[`</span><span class="nc">Int</span> <span class="k">of</span> <span class="kt">int</span> <span class="o">|</span> <span class="o">`</span><span class="nc">PyObject</span> <span class="k">of</span> <span class="nn">Py</span><span class="p">.</span><span class="nn">Object</span><span class="p">.</span><span class="n">t</span><span class="o">]</span> <span class="o">-&gt;</span>
  <span class="o">?</span><span class="n">power_iteration_normalizer</span><span class="o">:</span><span class="kt">string</span> <span class="o">-&gt;</span>
  <span class="o">?</span><span class="n">transpose</span><span class="o">:[`</span><span class="nc">Bool</span> <span class="k">of</span> <span class="kt">bool</span> <span class="o">|</span> <span class="o">`</span><span class="nc">Auto</span><span class="o">]</span> <span class="o">-&gt;</span>
  <span class="o">?</span><span class="n">flip_sign</span><span class="o">:[`</span><span class="nc">Bool</span> <span class="k">of</span> <span class="kt">bool</span> <span class="o">|</span> <span class="o">`</span><span class="nc">PyObject</span> <span class="k">of</span> <span class="nn">Py</span><span class="p">.</span><span class="nn">Object</span><span class="p">.</span><span class="n">t</span><span class="o">]</span> <span class="o">-&gt;</span>
  <span class="o">?</span><span class="n">random_state</span><span class="o">:[`</span><span class="nc">Int</span> <span class="k">of</span> <span class="kt">int</span> <span class="o">|</span> <span class="o">`</span><span class="nc">RandomState</span> <span class="k">of</span> <span class="nn">Py</span><span class="p">.</span><span class="nn">Object</span><span class="p">.</span><span class="n">t</span> <span class="o">|</span> <span class="o">`</span><span class="nc">None</span><span class="o">]</span> <span class="o">-&gt;</span>
  <span class="n">m</span><span class="o">:[`</span><span class="nc">Ndarray</span> <span class="k">of</span> <span class="nn">Ndarray</span><span class="p">.</span><span class="n">t</span> <span class="o">|</span> <span class="o">`</span><span class="nc">SparseMatrix</span> <span class="k">of</span> <span class="nn">Csr_matrix</span><span class="p">.</span><span class="n">t</span><span class="o">]</span> <span class="o">-&gt;</span>
  <span class="n">n_components</span><span class="o">:</span><span class="kt">int</span> <span class="o">-&gt;</span>
  <span class="kt">unit</span> <span class="o">-&gt;</span>
  <span class="nn">Py</span><span class="p">.</span><span class="nn">Object</span><span class="p">.</span><span class="n">t</span>
</code></pre></div>

<p>Computes a truncated randomized SVD</p>
<h4>Parameters</h4>
<details class="info" open="open"><summary>M : ndarray or sparse matrix</summary><p>Matrix to decompose</p>
</details>
<details class="info" open="open"><summary>n_components : int</summary><p>Number of singular values and vectors to extract.</p>
</details>
<details class="info" open="open"><summary>n_oversamples : int (default is 10)</summary><p>Additional number of random vectors to sample the range of M so as
to ensure proper conditioning. The total number of random vectors
used to find the range of M is n_components + n_oversamples. Smaller
number can improve speed but can negatively impact the quality of
approximation of singular vectors and singular values.</p>
</details>
<details class="info" open="open"><summary>n_iter : int or 'auto' (default is 'auto')</summary><p>Number of power iterations. It can be used to deal with very noisy
problems. When 'auto', it is set to 4, unless <code>n_components</code> is small
(&lt; .1 * min(X.shape)) <code>n_iter</code> in which case is set to 7.
This improves precision with few components.</p>
<p>.. versionchanged:: 0.18</p>
</details>
<details class="info" open="open"><summary>power_iteration_normalizer : 'auto' (default), 'QR', 'LU', 'none'</summary><p>Whether the power iterations are normalized with step-by-step
QR factorization (the slowest but most accurate), 'none'
(the fastest but numerically unstable when <code>n_iter</code> is large, e.g.
typically 5 or larger), or 'LU' factorization (numerically stable
but can lose slightly in accuracy). The 'auto' mode applies no
normalization if <code>n_iter</code> &lt;= 2 and switches to LU otherwise.</p>
<p>.. versionadded:: 0.18</p>
</details>
<details class="info" open="open"><summary>transpose : True, False or 'auto' (default)</summary><p>Whether the algorithm should be applied to M.T instead of M. The
result should approximately be the same. The 'auto' mode will
trigger the transposition if M.shape[1] &gt; M.shape[0] since this
implementation of randomized SVD tend to be a little faster in that
case.</p>
<p>.. versionchanged:: 0.18</p>
</details>
<details class="info" open="open"><summary>flip_sign : boolean, (True by default)</summary><p>The output of a singular value decomposition is only unique up to a
permutation of the signs of the singular vectors. If <code>flip_sign</code> is
set to <code>True</code>, the sign ambiguity is resolved by making the largest
loadings for each component in the left singular vectors positive.</p>
</details>
<details class="info" open="open"><summary>random_state : int, RandomState instance or None, optional (default=None)</summary><p>The seed of the pseudo random number generator to use when shuffling
the data.  If int, random_state is the seed used by the random number
generator; If RandomState instance, random_state is the random number
generator; If None, the random number generator is the RandomState
instance used by <code>np.random</code>.</p>
</details>
<h4>Notes</h4>
<p>This algorithm finds a (usually very good) approximate truncated
singular value decomposition using randomization to speed up the
computations. It is particularly fast on large matrices on which
you wish to extract only a small number of components. In order to
obtain further speed up, <code>n_iter</code> can be set &lt;=2 (at the cost of
loss of precision).</p>
<h4>References</h4>
<ul>
<li>
<p>Finding structure with randomness: Stochastic algorithms for constructing
  approximate matrix decompositions
  Halko, et al., 2009 https://arxiv.org/abs/0909.4061</p>
</li>
<li>
<p>A randomized algorithm for the decomposition of matrices
  Per-Gunnar Martinsson, Vladimir Rokhlin and Mark Tygert</p>
</li>
<li>
<p>An implementation of a randomized algorithm for principal component
  analysis
  A. Szlam et al. 2014</p>
</li>
</ul>
</details>
<h3 id="sparse_encode">sparse_encode<a class="headerlink" href="#sparse_encode" title="Permanent link">&para;</a></h3>
<details class="note" open="open"><summary>function</summary><div class="highlight"><pre><span></span><code><span class="k">val</span> <span class="n">sparse_encode</span> <span class="o">:</span>
  <span class="o">?</span><span class="n">gram</span><span class="o">:</span><span class="nn">Ndarray</span><span class="p">.</span><span class="n">t</span> <span class="o">-&gt;</span>
  <span class="o">?</span><span class="n">cov</span><span class="o">:</span><span class="nn">Ndarray</span><span class="p">.</span><span class="n">t</span> <span class="o">-&gt;</span>
  <span class="o">?</span><span class="n">algorithm</span><span class="o">:[`</span><span class="nc">Lasso_lars</span> <span class="o">|</span> <span class="o">`</span><span class="nc">Lasso_cd</span> <span class="o">|</span> <span class="o">`</span><span class="nc">Lars</span> <span class="o">|</span> <span class="o">`</span><span class="nc">Omp</span> <span class="o">|</span> <span class="o">`</span><span class="nc">Threshold</span><span class="o">]</span> <span class="o">-&gt;</span>
  <span class="o">?</span><span class="n">n_nonzero_coefs</span><span class="o">:[`</span><span class="nc">Int</span> <span class="k">of</span> <span class="kt">int</span> <span class="o">|</span> <span class="o">`</span><span class="nc">PyObject</span> <span class="k">of</span> <span class="nn">Py</span><span class="p">.</span><span class="nn">Object</span><span class="p">.</span><span class="n">t</span><span class="o">]</span> <span class="o">-&gt;</span>
  <span class="o">?</span><span class="n">alpha</span><span class="o">:</span><span class="kt">float</span> <span class="o">-&gt;</span>
  <span class="o">?</span><span class="n">copy_cov</span><span class="o">:</span><span class="kt">bool</span> <span class="o">-&gt;</span>
  <span class="o">?</span><span class="n">init</span><span class="o">:</span><span class="nn">Ndarray</span><span class="p">.</span><span class="n">t</span> <span class="o">-&gt;</span>
  <span class="o">?</span><span class="n">max_iter</span><span class="o">:</span><span class="kt">int</span> <span class="o">-&gt;</span>
  <span class="o">?</span><span class="n">n_jobs</span><span class="o">:[`</span><span class="nc">Int</span> <span class="k">of</span> <span class="kt">int</span> <span class="o">|</span> <span class="o">`</span><span class="nc">None</span><span class="o">]</span> <span class="o">-&gt;</span>
  <span class="o">?</span><span class="n">check_input</span><span class="o">:</span><span class="kt">bool</span> <span class="o">-&gt;</span>
  <span class="o">?</span><span class="n">verbose</span><span class="o">:</span><span class="kt">int</span> <span class="o">-&gt;</span>
  <span class="o">?</span><span class="n">positive</span><span class="o">:</span><span class="kt">bool</span> <span class="o">-&gt;</span>
  <span class="n">x</span><span class="o">:</span><span class="nn">Ndarray</span><span class="p">.</span><span class="n">t</span> <span class="o">-&gt;</span>
  <span class="n">dictionary</span><span class="o">:</span><span class="nn">Ndarray</span><span class="p">.</span><span class="n">t</span> <span class="o">-&gt;</span>
  <span class="kt">unit</span> <span class="o">-&gt;</span>
  <span class="nn">Ndarray</span><span class="p">.</span><span class="n">t</span>
</code></pre></div>

<p>Sparse coding</p>
<p>Each row of the result is the solution to a sparse coding problem.
The goal is to find a sparse array <code>code</code> such that::</p>
<div class="codehilite"><pre><span></span><code>X ~= code * dictionary
</code></pre></div>


<p>Read more in the :ref:<code>User Guide &lt;SparseCoder&gt;</code>.</p>
<h4>Parameters</h4>
<details class="info" open="open"><summary>X : array of shape (n_samples, n_features)</summary><p>Data matrix</p>
</details>
<details class="info" open="open"><summary>dictionary : array of shape (n_components, n_features)</summary><p>The dictionary matrix against which to solve the sparse coding of
the data. Some of the algorithms assume normalized rows for meaningful
output.</p>
</details>
<details class="info" open="open"><summary>gram : array, shape=(n_components, n_components)</summary><p>Precomputed Gram matrix, dictionary * dictionary'</p>
</details>
<details class="info" open="open"><summary>cov : array, shape=(n_components, n_samples)</summary><p>Precomputed covariance, dictionary' * X</p>
</details>
<details class="info" open="open"><summary>algorithm : {'lasso_lars', 'lasso_cd', 'lars', 'omp', 'threshold'}</summary></details>
<details class="info" open="open"><summary>lars: uses the least angle regression method (linear_model.lars_path)</summary></details>
<details class="info" open="open"><summary>lasso_lars: uses Lars to compute the Lasso solution</summary></details>
<details class="info" open="open"><summary>lasso_cd: uses the coordinate descent method to compute the</summary><p>Lasso solution (linear_model.Lasso). lasso_lars will be faster if
the estimated components are sparse.</p>
</details>
<details class="info" open="open"><summary>omp: uses orthogonal matching pursuit to estimate the sparse solution</summary></details>
<details class="info" open="open"><summary>threshold: squashes to zero all coefficients less than alpha from</summary><p>the projection dictionary * X'</p>
</details>
<details class="info" open="open"><summary>n_nonzero_coefs : int, 0.1 * n_features by default</summary><p>Number of nonzero coefficients to target in each column of the
solution. This is only used by <code>algorithm='lars'</code> and <code>algorithm='omp'</code>
and is overridden by <code>alpha</code> in the <code>omp</code> case.</p>
</details>
<details class="info" open="open"><summary>alpha : float, 1. by default</summary><p>If <code>algorithm='lasso_lars'</code> or <code>algorithm='lasso_cd'</code>, <code>alpha</code> is the
penalty applied to the L1 norm.
If <code>algorithm='threshold'</code>, <code>alpha</code> is the absolute value of the
threshold below which coefficients will be squashed to zero.
If <code>algorithm='omp'</code>, <code>alpha</code> is the tolerance parameter: the value of
the reconstruction error targeted. In this case, it overrides
<code>n_nonzero_coefs</code>.</p>
</details>
<details class="info" open="open"><summary>copy_cov : boolean, optional</summary><p>Whether to copy the precomputed covariance matrix; if False, it may be
overwritten.</p>
</details>
<details class="info" open="open"><summary>init : array of shape (n_samples, n_components)</summary><p>Initialization value of the sparse codes. Only used if
<code>algorithm='lasso_cd'</code>.</p>
</details>
<details class="info" open="open"><summary>max_iter : int, 1000 by default</summary><p>Maximum number of iterations to perform if <code>algorithm='lasso_cd'</code> or
<code>lasso_lars</code>.</p>
</details>
<details class="info" open="open"><summary>n_jobs : int or None, optional (default=None)</summary><p>Number of parallel jobs to run.
<code>None</code> means 1 unless in a :obj:<code>joblib.parallel_backend</code> context.
<code>-1</code> means using all processors. See :term:<code>Glossary &lt;n_jobs&gt;</code>
for more details.</p>
</details>
<details class="info" open="open"><summary>check_input : boolean, optional</summary><p>If False, the input arrays X and dictionary will not be checked.</p>
</details>
<details class="info" open="open"><summary>verbose : int, optional</summary><p>Controls the verbosity; the higher, the more messages. Defaults to 0.</p>
</details>
<details class="info" open="open"><summary>positive : boolean, optional</summary><p>Whether to enforce positivity when finding the encoding.</p>
<p>.. versionadded:: 0.20</p>
</details>
<h4>Returns</h4>
<details class="info" open="open"><summary>code : array of shape (n_samples, n_components)</summary><p>The sparse codes</p>
</details>
<h4>See also</h4>
<p>sklearn.linear_model.lars_path
sklearn.linear_model.orthogonal_mp
sklearn.linear_model.Lasso
SparseCoder</p>
</details>
                
              
              
                


              
            </article>
          </div>
        </div>
      </main>
      
        
<footer class="md-footer">
  
    <div class="md-footer-nav">
      <nav class="md-footer-nav__inner md-grid" aria-label="Footer">
        
          <a href="../datasets/" title="Datasets" class="md-footer-nav__link md-footer-nav__link--prev" rel="prev">
            <div class="md-footer-nav__button md-icon">
              <svg xmlns="http://www.w3.org/2000/svg" viewBox="0 0 24 24"><path d="M20,11V13H8L13.5,18.5L12.08,19.92L4.16,12L12.08,4.08L13.5,5.5L8,11H20Z" /></svg>
            </div>
            <div class="md-footer-nav__title">
              <div class="md-ellipsis">
                <span class="md-footer-nav__direction">
                  Previous
                </span>
                Datasets
              </div>
            </div>
          </a>
        
        
          <a href="../discriminant_analysis/" title="Discriminant analysis" class="md-footer-nav__link md-footer-nav__link--next" rel="next">
            <div class="md-footer-nav__title">
              <div class="md-ellipsis">
                <span class="md-footer-nav__direction">
                  Next
                </span>
                Discriminant analysis
              </div>
            </div>
            <div class="md-footer-nav__button md-icon">
              <svg xmlns="http://www.w3.org/2000/svg" viewBox="0 0 24 24"><path d="M4,11V13H16L10.5,18.5L11.92,19.92L19.84,12L11.92,4.08L10.5,5.5L16,11H4Z" /></svg>
            </div>
          </a>
        
      </nav>
    </div>
  
  <div class="md-footer-meta md-typeset">
    <div class="md-footer-meta__inner md-grid">
      <div class="md-footer-copyright">
        
        Made with
        <a href="https://squidfunk.github.io/mkdocs-material/" target="_blank" rel="noopener">
          Material for MkDocs
        </a>
      </div>
      
    </div>
  </div>
</footer>
      
    </div>
    
      <script src="../assets/javascripts/vendor.36cbf620.min.js"></script>
      <script src="../assets/javascripts/bundle.00c583dd.min.js"></script><script id="__lang" type="application/json">{"clipboard.copy": "Copy to clipboard", "clipboard.copied": "Copied to clipboard", "search.config.lang": "en", "search.config.pipeline": "trimmer, stopWordFilter", "search.config.separator": "[\\s\\-]+", "search.result.placeholder": "Type to start searching", "search.result.none": "No matching documents", "search.result.one": "1 matching document", "search.result.other": "# matching documents"}</script>
      
      <script>
        app = initialize({
          base: "..",
          features: ["instant"],
          search: Object.assign({
            worker: "../assets/javascripts/worker/search.7f7c8775.min.js"
          }, typeof search !== "undefined" && search)
        })
      </script>
      
        <script src="https://cdnjs.cloudflare.com/ajax/libs/mathjax/2.7.0/MathJax.js?config=TeX-MML-AM_CHTML"></script>
      
    
  </body>
</html>