{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Gradient Boosting Regression\n",
    "\n",
    "Demonstrate Gradient Boosting on the Boston housing dataset.\n",
    "\n",
    "This example fits a Gradient Boosting model with least squares loss and 500 regression trees of depth 4.\n",
    "\n",
    "This is a port to OCaml of the [scikit-learn gradient boosting regression example](https://scikit-learn.org/stable/auto_examples/ensemble/plot_gradient_boosting_regression.html#sphx-glr-auto-examples-ensemble-plot-gradient-boosting-regression-py)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "#require \"pyml\"\n",
    "#require \"matplotlib\"\n",
    "#require \"jupyter.notebook\"\n",
    "#require \"shell\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "open Matplotlib;;\n",
    "let plot () =\n",
    "  let data = Mpl.plot_data `png in\n",
    "  ignore (Jupyter_notebook.display ~base64:true \"image/png\" data);;\n",
    "\n",
    "let () =\n",
    "    Mpl.set_backend Agg\n",
    ";;"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "(* load sklearn from the current git repo (build first with dune build @install) *)\n",
    "let root = String.trim @@ Shell.run_full \"git\" [\"rev-parse\"; \"--show-toplevel\"];;\n",
    "let libdir = root ^ \"/_build/install/default/lib/sklearn/\";;\n",
    "Topdirs.dir_directory libdir;;\n",
    "#load \"sklearn.cma\";;"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "(* it would be nice if the OCaml kernel installed printers automatically like utop *)\n",
    "#install_printer Sklearn.Arr.pp;;\n",
    "#install_printer Sklearn.Ndarray.pp;;\n",
    "#install_printer Sklearn.Ensemble.GradientBoostingRegressor.pp;;"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Load data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "(* The Python source does a custom split using shuffle(). The equivalent with train_test_split is simpler (see below) ,\n",
    "   but it is nice to reproduce the numerical results and graphics. *)\n",
    "   \n",
    "(* (* the recommended simpler version *)\n",
    "  let [@ocaml.warning \"-8\"] [x_train; x_test; y_train; y_test] =\n",
    "  Sklearn.Model_selection.train_test_split [boston#data; boston#target] ~random_state:42 ~train_size:(`F 0.9);; *)\n",
    "\n",
    "let boston = Sklearn.Datasets.load_boston();;\n",
    "\n",
    "let [@ocaml.warning \"-8\"] [x; y] = Sklearn.Utils.shuffle [boston#data; boston#target] ~random_state:13;;\n",
    "let offset = int_of_float @@ (float_of_int (Sklearn.Arr.shape x).(0)) *. 0.9;;\n",
    "let x_train = Sklearn.Arr.(get_sub [slice ~j:offset ()] x);;\n",
    "let y_train = Sklearn.Arr.(get_sub [slice ~j:offset ()] y);;\n",
    "let x_test = Sklearn.Arr.(get_sub [slice ~i:offset ()] x);;\n",
    "let y_test = Sklearn.Arr.(get_sub [slice ~i:offset ()] y);;"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Fit regression model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "let get_f = function `F x -> x | _ -> assert false;;\n",
    "\n",
    "let n_estimators = 500;;\n",
    "\n",
    "module Gbr = Sklearn.Ensemble.GradientBoostingRegressor;;\n",
    "let clf =\n",
    "  Gbr.(create ~n_estimators ~max_depth:4 ~min_samples_split:(`I 2) ~learning_rate:0.01 ~loss:`Ls()\n",
    "       |> fit ~x:x_train ~y:y_train);;\n",
    "\n",
    "let mse = Sklearn.Metrics.mean_squared_error ~y_true:y_test ~y_pred:(Gbr.predict clf ~x:x_test) () |> get_f in\n",
    "Printf.printf \"MSE: %.4f\\n%!\" mse;;"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Plot training deviance"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "let protect f =\n",
    "  try f()\n",
    "  with (Py.E (a, b)) as exc -> Printf.printf \"error: %s\\n%s\\n%!\" (Py.Object.to_string a) (Py.Object.to_string b); raise exc\n",
    "\n",
    "let call_loss ~y ~raw_predictions loss =\n",
    "  Py.Callable.to_function loss [|Sklearn.Arr.to_pyobject y; Sklearn.Arr.to_pyobject raw_predictions|] |> Py.Float.to_float;;\n",
    "\n",
    "(* TODO: contribute this to ocaml-matplotlib *)\n",
    "let set_yticks ax ticks =\n",
    "  let _ = Py.Module.get_function (Ax.Expert.to_pyobject ax) \"set_yticks\" [|Sklearn.Arr.to_pyobject ticks|] in ();;\n",
    "\n",
    "let set_yticklabels ax labels =\n",
    "  let _ = Py.Module.get_function (Ax.Expert.to_pyobject ax) \"set_yticklabels\" [|Sklearn.Arr.to_pyobject labels|] in ();;\n",
    "\n",
    "(* Axes.barh(self, y, width, height=0.8, left=None, *, align='center', **kwargs)[source]) *)\n",
    "let barh ax y width =\n",
    "  let _ = Py.Module.get_function (Ax.Expert.to_pyobject ax) \"barh\" [|Sklearn.Arr.to_pyobject y; Sklearn.Arr.to_pyobject width|] in ();;\n",
    "\n",
    "(* plot deviance *)\n",
    "(* TODO: better wrapper for staged_predict (return iterator of Arr.t) *)\n",
    "(* TODO: better wrapper for Gbr.loss_: return callable function *)\n",
    "let test_score =\n",
    "  let score = Sklearn.Ndarray.zeros ~dtype:(`S \"float64\") [n_estimators] in\n",
    "  let _ = Py.Iter.fold_left\n",
    "    (fun i e -> Sklearn.Ndarray.set [|`I i|] (`F (call_loss y_test (Sklearn.Arr.of_pyobject e) (Gbr.loss_ clf))) score; i+1)\n",
    "    0 (Gbr.staged_predict clf ~x:x_test)\n",
    "  in score\n",
    "in\n",
    "\n",
    "let fig, ax1, ax2 = Fig.create_with_two_axes ~figsize:(12., 6.) `horizontal in\n",
    "\n",
    "let xs = Array.init n_estimators (fun i -> float_of_int (i+1)) in\n",
    "let train_score = Gbr.train_score_ clf |> Sklearn.Arr.get_ndarray |> Sklearn.Ndarray.to_float_array in\n",
    "Ax.set_title ax1 \"Deviance\";\n",
    "Ax.plot ax1 ~label:\"Training Set Deviance\" ~linestyle:Solid ~xs train_score;\n",
    "Ax.plot ax1 ~label:\"Test Set Deviance\" ~linestyle:Solid ~xs (Sklearn.Ndarray.to_float_array test_score);\n",
    "Ax.legend ax1;\n",
    "Ax.set_xlabel ax1 \"Boosting iterations\";\n",
    "Ax.set_ylabel ax1 \"Deviance\";\n",
    "\n",
    "(* TODO: rethink Ops (this should include min/max/argsort...?) *)\n",
    "let feature_importance = Gbr.feature_importances_ clf in\n",
    "let feature_importance = Sklearn.Arr.Ops.((int 100) * feature_importance / (float (Sklearn.Arr.max feature_importance))) in\n",
    "let sorted_idx = Sklearn.Arr.argsort feature_importance in\n",
    "let pos = Sklearn.Arr.arange (Sklearn.Arr.shape sorted_idx).(0) in\n",
    "let pos = Sklearn.Arr.Ops.(pos + (float 0.5)) in\n",
    "Ax.set_title ax2 \"Variable Importance\";\n",
    "barh ax2 pos Sklearn.Arr.(get_sub [`Arr sorted_idx] feature_importance);\n",
    "set_yticks ax2 pos;\n",
    "set_yticklabels ax2 (Sklearn.Arr.get_sub [`Arr sorted_idx] boston#feature_names);\n",
    "Ax.set_xlabel ax2 \"Relative Importance\";\n",
    "Ax.set_title ax2 \"Variable Importance\";\n",
    "plot ();;"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "OCaml 4.07.1+flambda",
   "language": "OCaml",
   "name": "ocaml-jupyter"
  },
  "language_info": {
   "codemirror_mode": "text/x-ocaml",
   "file_extension": ".ml",
   "mimetype": "text/x-ocaml",
   "name": "OCaml",
   "nbconverter_exporter": null,
   "pygments_lexer": "OCaml",
   "version": "4.07.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
