{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Gradient Boosting Regression\n",
    "\n",
    "Demonstrate Gradient Boosting on the Boston housing dataset.\n",
    "\n",
    "This example fits a Gradient Boosting model with least squares loss and 500 regression trees of depth 4.\n",
    "\n",
    "This is a port to OCaml of the [scikit-learn gradient boosting regression example](https://scikit-learn.org/stable/auto_examples/ensemble/plot_gradient_boosting_regression.html#sphx-glr-auto-examples-ensemble-plot-gradient-boosting-regression-py)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "#require \"pyml\"\n",
    "#require \"matplotlib\"\n",
    "#require \"jupyter.notebook\"\n",
    "#require \"shell\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "open Matplotlib;;\n",
    "let plot () =\n",
    "  let data = Mpl.plot_data `png in\n",
    "  ignore (Jupyter_notebook.display ~base64:true \"image/png\" data);;\n",
    "\n",
    "let () =\n",
    "    Mpl.set_backend Agg\n",
    ";;"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "(* load sklearn from the current git repo (build first with dune build @install) *)\n",
    "let root = String.trim @@ Shell.run_full \"git\" [\"rev-parse\"; \"--show-toplevel\"];;\n",
    "List.iter (fun component ->\n",
    "    let libdir = root ^ \"/_build/install/default/lib/\" ^ component in\n",
    "    Topdirs.dir_directory libdir) [\"np\"; \"scipy\"; \"sklearn\"];;\n",
    "#load \"np.cma\";;\n",
    "#load \"scipy.cma\";;\n",
    "#load \"sklearn.cma\";;\n",
    "module Np = Np.Numpy;;"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "(* it would be nice if the OCaml kernel installed printers automatically like utop *)\n",
    "#install_printer Np.Obj.pp;;\n",
    "(* #install_printer Sklearn.Ensemble.GradientBoostingRegressor.pp;;*)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Load data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "(* The Python source does a custom split using shuffle(). The equivalent with train_test_split is simpler (see below) ,\n",
    "   but it is nice to reproduce the numerical results and graphics. *)\n",
    "   \n",
    "(* (* the recommended simpler version *)\n",
    "  let [@ocaml.warning \"-8\"] [x_train; x_test; y_train; y_test] =\n",
    "  Sklearn.Model_selection.train_test_split [boston#data; boston#target] ~random_state:42 ~train_size:(`F 0.9);; *)\n",
    "\n",
    "let boston = Sklearn.Datasets.load_boston();;\n",
    "\n",
    "let [@ocaml.warning \"-8\"] [x; y] = Sklearn.Utils.shuffle [boston#data; boston#target] ~random_state:13;;\n",
    "let offset = int_of_float @@ (float_of_int (Np.shape x).(0)) *. 0.9;;\n",
    "let x_train = Np.Ndarray.(get ~key:[slice ~j:offset ()] x);;\n",
    "let y_train = Np.Ndarray.(get ~key:[slice ~j:offset ()] y);;\n",
    "let x_test = Np.Ndarray.(get ~key:[slice ~i:offset ()] x);;\n",
    "let y_test = Np.Ndarray.(get ~key:[slice ~i:offset ()] y);"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Fit regression model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "let get_f = function `F x -> x | _ -> assert false;;\n",
    "\n",
    "let n_estimators = 500;;\n",
    "\n",
    "module Gbr = Sklearn.Ensemble.GradientBoostingRegressor;;\n",
    "let clf =\n",
    "  Gbr.(create ~n_estimators ~max_depth:4 ~min_samples_split:(`I 2) ~learning_rate:0.01 ~loss:`Ls()\n",
    "       |> fit ~x:x_train ~y:y_train);;\n",
    "\n",
    "let mse = Sklearn.Metrics.mean_squared_error ~y_true:y_test ~y_pred:(Gbr.predict clf ~x:x_test) () |> fun x -> (Np.Ndarray.to_float_array x).(0) in\n",
    "Printf.printf \"MSE: %.4f\\n%!\" mse;;"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Plot training deviance"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "let protect f =\n",
    "  try f()\n",
    "  with (Py.E (a, b)) as exc -> Printf.printf \"error: %s\\n%s\\n%!\" (Py.Object.to_string a) (Py.Object.to_string b); raise exc\n",
    "\n",
    "(* let call_loss ~y ~raw_predictions loss =\n",
    "  Py.Callable.to_function loss [|Sklearn.Arr.to_pyobject y; Sklearn.Arr.to_pyobject raw_predictions|] |> Py.Float.to_float;; *)\n",
    "\n",
    "(* TODO: contribute this to ocaml-matplotlib *)\n",
    "let set_yticks ax ticks =\n",
    "  let _ = Py.Module.get_function (Ax.Expert.to_pyobject ax) \"set_yticks\" [|Np.Obj.to_pyobject ticks|] in ();;\n",
    " \n",
    "let set_yticklabels ax labels =\n",
    "  let _ = Py.Module.get_function (Ax.Expert.to_pyobject ax) \"set_yticklabels\" [|Np.Obj.to_pyobject labels|] in ();;\n",
    "\n",
    "(* Axes.barh(self, y, width, height=0.8, left=None, *, align='center', **kwargs)[source]) *)\n",
    "let barh ax y width =\n",
    "  let _ = Py.Module.get_function (Ax.Expert.to_pyobject ax) \"barh\" [|Np.Obj.to_pyobject y; Np.Obj.to_pyobject width|] in ();;\n",
    "\n",
    "(* plot deviance *)\n",
    "let test_score =\n",
    "  let score = Np.zeros ~dtype:(`S \"float64\") [n_estimators] in\n",
    "  let _ = Seq.fold_left\n",
    "    (fun i e -> Np.(Ndarray.set ~key:[`I i] ~value:(float (Gbr.loss_ clf y_test e)) score); succ i)\n",
    "    0\n",
    "    (Gbr.staged_predict clf ~x:x_test)\n",
    "  in score\n",
    "in\n",
    "\n",
    "let fig, ax1, ax2 = Fig.create_with_two_axes ~figsize:(12., 6.) `horizontal in\n",
    "\n",
    "let xs = Array.init n_estimators (fun i -> float_of_int (succ i)) in\n",
    "let train_score = Gbr.train_score_ clf |> Np.Ndarray.to_float_array in\n",
    "Ax.set_title ax1 \"Deviance\";\n",
    "Ax.plot ax1 ~label:\"Training Set Deviance\" ~linestyle:Solid ~xs train_score;\n",
    "Ax.plot ax1 ~label:\"Test Set Deviance\" ~linestyle:Solid ~xs (Np.Ndarray.to_float_array test_score);\n",
    "Ax.legend ax1;\n",
    "Ax.set_xlabel ax1 \"Boosting iterations\";\n",
    "Ax.set_ylabel ax1 \"Deviance\";\n",
    "\n",
    "let feature_importance = Gbr.feature_importances_ clf in\n",
    "let feature_importance = Np.((int 100) * feature_importance / (max feature_importance)) in\n",
    "let sorted_idx = Np.argsort feature_importance in\n",
    "let pos = Np.(arange (`I (shape sorted_idx).(0))) in\n",
    "let pos = Np.(pos + (float 0.5)) in\n",
    "Ax.set_title ax2 \"Variable Importance\";\n",
    "barh ax2 pos Np.(Ndarray.get ~key:[mask sorted_idx] feature_importance);\n",
    "set_yticks ax2 pos;\n",
    "set_yticklabels ax2 Np.(Ndarray.get ~key:[mask sorted_idx] (Np.Ndarray.of_string_list boston#feature_names));\n",
    "Ax.set_xlabel ax2 \"Relative Importance\";\n",
    "Ax.set_title ax2 \"Variable Importance\";\n",
    "plot ();;"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "OCaml 4.07.1+flambda",
   "language": "OCaml",
   "name": "ocaml-jupyter"
  },
  "language_info": {
   "codemirror_mode": "text/x-ocaml",
   "file_extension": ".ml",
   "mimetype": "text/x-ocaml",
   "name": "OCaml",
   "nbconverter_exporter": null,
   "pygments_lexer": "OCaml",
   "version": "4.07.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
