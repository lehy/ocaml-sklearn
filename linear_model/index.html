


<!doctype html>
<html lang="en" class="no-js">
  <head>
    
      <meta charset="utf-8">
      <meta name="viewport" content="width=device-width,initial-scale=1">
      
      
      
      <link rel="shortcut icon" href="../assets/images/favicon.png">
      <meta name="generator" content="mkdocs-1.1, mkdocs-material-5.1.0">
    
    
      
        <title>Linear model - OCaml scikit-learn interface</title>
      
    
    
      <link rel="stylesheet" href="../assets/stylesheets/main.89dc9fe3.min.css">
      
        <link rel="stylesheet" href="../assets/stylesheets/palette.ecd4686e.min.css">
      
      
        
        
        <meta name="theme-color" content="#3f51b5">
      
    
    
    
      
        <link href="https://fonts.gstatic.com" rel="preconnect" crossorigin>
        <link rel="stylesheet" href="https://fonts.googleapis.com/css?family=Roboto:300,400,400i,700%7CRoboto+Mono&display=fallback">
        <style>body,input{font-family:"Roboto",-apple-system,BlinkMacSystemFont,Helvetica,Arial,sans-serif}code,kbd,pre{font-family:"Roboto Mono",SFMono-Regular,Consolas,Menlo,monospace}</style>
      
    
    
    
    
      
    
    
  </head>
  
  
    
    
    <body dir="ltr" data-md-color-primary="indigo" data-md-color-accent="indigo">
  
    <input class="md-toggle" data-md-toggle="drawer" type="checkbox" id="__drawer" autocomplete="off">
    <input class="md-toggle" data-md-toggle="search" type="checkbox" id="__search" autocomplete="off">
    <label class="md-overlay" for="__drawer"></label>
    <div data-md-component="skip">
      
        
        <a href="#module-sklearnlinear_modelardregression" class="md-skip">
          Skip to content
        </a>
      
    </div>
    <div data-md-component="announce">
      
    </div>
    
      <header class="md-header" data-md-component="header">
  <nav class="md-header-nav md-grid" aria-label="Header">
    <a href=".." title="OCaml scikit-learn interface" class="md-header-nav__button md-logo" aria-label="OCaml scikit-learn interface">
      
  
  <svg xmlns="http://www.w3.org/2000/svg" viewBox="0 0 24 24"><path d="M12,8A3,3 0 0,0 15,5A3,3 0 0,0 12,2A3,3 0 0,0 9,5A3,3 0 0,0 12,8M12,11.54C9.64,9.35 6.5,8 3,8V19C6.5,19 9.64,20.35 12,22.54C14.36,20.35 17.5,19 21,19V8C17.5,8 14.36,9.35 12,11.54Z" /></svg>

    </a>
    <label class="md-header-nav__button md-icon" for="__drawer">
      <svg xmlns="http://www.w3.org/2000/svg" viewBox="0 0 24 24"><path d="M3,6H21V8H3V6M3,11H21V13H3V11M3,16H21V18H3V16Z" /></svg>
    </label>
    <div class="md-header-nav__title" data-md-component="header-title">
      
        <div class="md-header-nav__ellipsis">
          <span class="md-header-nav__topic md-ellipsis">
            OCaml scikit-learn interface
          </span>
          <span class="md-header-nav__topic md-ellipsis">
            
              Linear model
            
          </span>
        </div>
      
    </div>
    
      <label class="md-header-nav__button md-icon" for="__search">
        <svg xmlns="http://www.w3.org/2000/svg" viewBox="0 0 24 24"><path d="M9.5,3A6.5,6.5 0 0,1 16,9.5C16,11.11 15.41,12.59 14.44,13.73L14.71,14H15.5L20.5,19L19,20.5L14,15.5V14.71L13.73,14.44C12.59,15.41 11.11,16 9.5,16A6.5,6.5 0 0,1 3,9.5A6.5,6.5 0 0,1 9.5,3M9.5,5C7,5 5,7 5,9.5C5,12 7,14 9.5,14C12,14 14,12 14,9.5C14,7 12,5 9.5,5Z" /></svg>
      </label>
      
<div class="md-search" data-md-component="search" role="dialog">
  <label class="md-search__overlay" for="__search"></label>
  <div class="md-search__inner" role="search">
    <form class="md-search__form" name="search">
      <input type="text" class="md-search__input" name="query" aria-label="Search" placeholder="Search" autocapitalize="off" autocorrect="off" autocomplete="off" spellcheck="false" data-md-component="search-query" data-md-state="active">
      <label class="md-search__icon md-icon" for="__search">
        <svg xmlns="http://www.w3.org/2000/svg" viewBox="0 0 24 24"><path d="M9.5,3A6.5,6.5 0 0,1 16,9.5C16,11.11 15.41,12.59 14.44,13.73L14.71,14H15.5L20.5,19L19,20.5L14,15.5V14.71L13.73,14.44C12.59,15.41 11.11,16 9.5,16A6.5,6.5 0 0,1 3,9.5A6.5,6.5 0 0,1 9.5,3M9.5,5C7,5 5,7 5,9.5C5,12 7,14 9.5,14C12,14 14,12 14,9.5C14,7 12,5 9.5,5Z" /></svg>
        <svg xmlns="http://www.w3.org/2000/svg" viewBox="0 0 24 24"><path d="M20,11V13H8L13.5,18.5L12.08,19.92L4.16,12L12.08,4.08L13.5,5.5L8,11H20Z" /></svg>
      </label>
      <button type="reset" class="md-search__icon md-icon" aria-label="Clear" data-md-component="search-reset" tabindex="-1">
        <svg xmlns="http://www.w3.org/2000/svg" viewBox="0 0 24 24"><path d="M19,6.41L17.59,5L12,10.59L6.41,5L5,6.41L10.59,12L5,17.59L6.41,19L12,13.41L17.59,19L19,17.59L13.41,12L19,6.41Z" /></svg>
      </button>
    </form>
    <div class="md-search__output">
      <div class="md-search__scrollwrap" data-md-scrollfix>
        <div class="md-search-result" data-md-component="search-result">
          <div class="md-search-result__meta">
            Type to start searching
          </div>
          <ol class="md-search-result__list"></ol>
        </div>
      </div>
    </div>
  </div>
</div>
    
    
      <div class="md-header-nav__source">
        
<a href="https://github.com/lehy/ocaml-sklearn/" title="Go to repository" class="md-source">
  <div class="md-source__icon md-icon">
    
    <svg xmlns="http://www.w3.org/2000/svg" viewBox="0 0 448 512"><path d="M439.55 236.05L244 40.45a28.87 28.87 0 0 0-40.81 0l-40.66 40.63 51.52 51.52c27.06-9.14 52.68 16.77 43.39 43.68l49.66 49.66c34.23-11.8 61.18 31 35.47 56.69-26.49 26.49-70.21-2.87-56-37.34L240.22 199v121.85c25.3 12.54 22.26 41.85 9.08 55a34.34 34.34 0 0 1-48.55 0c-17.57-17.6-11.07-46.91 11.25-56v-123c-20.8-8.51-24.6-30.74-18.64-45L142.57 101 8.45 235.14a28.86 28.86 0 0 0 0 40.81l195.61 195.6a28.86 28.86 0 0 0 40.8 0l194.69-194.69a28.86 28.86 0 0 0 0-40.81z"/></svg>
  </div>
  <div class="md-source__repository">
    lehy/ocaml-sklearn
  </div>
</a>
      </div>
    
  </nav>
</header>
    
    <div class="md-container" data-md-component="container">
      
        
      
      
        
      
      <main class="md-main" data-md-component="main">
        <div class="md-main__inner md-grid">
          
            
              <div class="md-sidebar md-sidebar--primary" data-md-component="navigation">
                <div class="md-sidebar__scrollwrap">
                  <div class="md-sidebar__inner">
                    <nav class="md-nav md-nav--primary" aria-label="Navigation" data-md-level="0">
  <label class="md-nav__title" for="__drawer">
    <a href=".." title="OCaml scikit-learn interface" class="md-nav__button md-logo" aria-label="OCaml scikit-learn interface">
      
  
  <svg xmlns="http://www.w3.org/2000/svg" viewBox="0 0 24 24"><path d="M12,8A3,3 0 0,0 15,5A3,3 0 0,0 12,2A3,3 0 0,0 9,5A3,3 0 0,0 12,8M12,11.54C9.64,9.35 6.5,8 3,8V19C6.5,19 9.64,20.35 12,22.54C14.36,20.35 17.5,19 21,19V8C17.5,8 14.36,9.35 12,11.54Z" /></svg>

    </a>
    OCaml scikit-learn interface
  </label>
  
    <div class="md-nav__source">
      
<a href="https://github.com/lehy/ocaml-sklearn/" title="Go to repository" class="md-source">
  <div class="md-source__icon md-icon">
    
    <svg xmlns="http://www.w3.org/2000/svg" viewBox="0 0 448 512"><path d="M439.55 236.05L244 40.45a28.87 28.87 0 0 0-40.81 0l-40.66 40.63 51.52 51.52c27.06-9.14 52.68 16.77 43.39 43.68l49.66 49.66c34.23-11.8 61.18 31 35.47 56.69-26.49 26.49-70.21-2.87-56-37.34L240.22 199v121.85c25.3 12.54 22.26 41.85 9.08 55a34.34 34.34 0 0 1-48.55 0c-17.57-17.6-11.07-46.91 11.25-56v-123c-20.8-8.51-24.6-30.74-18.64-45L142.57 101 8.45 235.14a28.86 28.86 0 0 0 0 40.81l195.61 195.6a28.86 28.86 0 0 0 40.8 0l194.69-194.69a28.86 28.86 0 0 0 0-40.81z"/></svg>
  </div>
  <div class="md-source__repository">
    lehy/ocaml-sklearn
  </div>
</a>
    </div>
  
  <ul class="md-nav__list" data-md-scrollfix>
    
      
      
      


  <li class="md-nav__item">
    <a href=".." title="Home" class="md-nav__link">
      Home
    </a>
  </li>

    
      
      
      


  <li class="md-nav__item">
    <a href="../base/" title="Base" class="md-nav__link">
      Base
    </a>
  </li>

    
      
      
      


  <li class="md-nav__item">
    <a href="../calibration/" title="Calibration" class="md-nav__link">
      Calibration
    </a>
  </li>

    
      
      
      


  <li class="md-nav__item">
    <a href="../cluster/" title="Cluster" class="md-nav__link">
      Cluster
    </a>
  </li>

    
      
      
      


  <li class="md-nav__item">
    <a href="../compose/" title="Compose" class="md-nav__link">
      Compose
    </a>
  </li>

    
      
      
      


  <li class="md-nav__item">
    <a href="../conftest/" title="Conftest" class="md-nav__link">
      Conftest
    </a>
  </li>

    
      
      
      


  <li class="md-nav__item">
    <a href="../covariance/" title="Covariance" class="md-nav__link">
      Covariance
    </a>
  </li>

    
      
      
      


  <li class="md-nav__item">
    <a href="../cross_decomposition/" title="Cross decomposition" class="md-nav__link">
      Cross decomposition
    </a>
  </li>

    
      
      
      


  <li class="md-nav__item">
    <a href="../datasets/" title="Datasets" class="md-nav__link">
      Datasets
    </a>
  </li>

    
      
      
      


  <li class="md-nav__item">
    <a href="../decomposition/" title="Decomposition" class="md-nav__link">
      Decomposition
    </a>
  </li>

    
      
      
      


  <li class="md-nav__item">
    <a href="../discriminant_analysis/" title="Discriminant analysis" class="md-nav__link">
      Discriminant analysis
    </a>
  </li>

    
      
      
      


  <li class="md-nav__item">
    <a href="../dummy/" title="Dummy" class="md-nav__link">
      Dummy
    </a>
  </li>

    
      
      
      


  <li class="md-nav__item">
    <a href="../ensemble/" title="Ensemble" class="md-nav__link">
      Ensemble
    </a>
  </li>

    
      
      
      


  <li class="md-nav__item">
    <a href="../exceptions/" title="Exceptions" class="md-nav__link">
      Exceptions
    </a>
  </li>

    
      
      
      


  <li class="md-nav__item">
    <a href="../experimental/" title="Experimental" class="md-nav__link">
      Experimental
    </a>
  </li>

    
      
      
      


  <li class="md-nav__item">
    <a href="../externals/" title="Externals" class="md-nav__link">
      Externals
    </a>
  </li>

    
      
      
      


  <li class="md-nav__item">
    <a href="../feature_extraction/" title="Feature extraction" class="md-nav__link">
      Feature extraction
    </a>
  </li>

    
      
      
      


  <li class="md-nav__item">
    <a href="../feature_selection/" title="Feature selection" class="md-nav__link">
      Feature selection
    </a>
  </li>

    
      
      
      


  <li class="md-nav__item">
    <a href="../gaussian_process/" title="Gaussian process" class="md-nav__link">
      Gaussian process
    </a>
  </li>

    
      
      
      


  <li class="md-nav__item">
    <a href="../impute/" title="Impute" class="md-nav__link">
      Impute
    </a>
  </li>

    
      
      
      


  <li class="md-nav__item">
    <a href="../inspection/" title="Inspection" class="md-nav__link">
      Inspection
    </a>
  </li>

    
      
      
      


  <li class="md-nav__item">
    <a href="../isotonic/" title="Isotonic" class="md-nav__link">
      Isotonic
    </a>
  </li>

    
      
      
      


  <li class="md-nav__item">
    <a href="../kernel_approximation/" title="Kernel approximation" class="md-nav__link">
      Kernel approximation
    </a>
  </li>

    
      
      
      


  <li class="md-nav__item">
    <a href="../kernel_ridge/" title="Kernel ridge" class="md-nav__link">
      Kernel ridge
    </a>
  </li>

    
      
      
      

  


  <li class="md-nav__item md-nav__item--active">
    
    <input class="md-nav__toggle md-toggle" data-md-toggle="toc" type="checkbox" id="__toc">
    
    
      <label class="md-nav__link md-nav__link--active" for="__toc">
        Linear model
        <span class="md-nav__icon md-icon">
          <svg xmlns="http://www.w3.org/2000/svg" viewBox="0 0 24 24"><path d="M3,9H17V7H3V9M3,13H17V11H3V13M3,17H17V15H3V17M19,17H21V15H19V17M19,7V9H21V7H19M19,13H21V11H19V13Z" /></svg>
        </span>
      </label>
    
    <a href="./" title="Linear model" class="md-nav__link md-nav__link--active">
      Linear model
    </a>
    
      
<nav class="md-nav md-nav--secondary" aria-label="Table of contents">
  
  
  
    <label class="md-nav__title" for="__toc">
      <span class="md-nav__icon md-icon">
        <svg xmlns="http://www.w3.org/2000/svg" viewBox="0 0 24 24"><path d="M20,11V13H8L13.5,18.5L12.08,19.92L4.16,12L12.08,4.08L13.5,5.5L8,11H20Z" /></svg>
      </span>
      Table of contents
    </label>
    <ul class="md-nav__list" data-md-scrollfix>
      
        <li class="md-nav__item">
  <a href="#module-sklearnlinear_modelardregression" class="md-nav__link">
    module Sklearn.​Linear_model.​ARDRegression
  </a>
  
    <nav class="md-nav" aria-label="module Sklearn.​Linear_model.​ARDRegression">
      <ul class="md-nav__list">
        
          <li class="md-nav__item">
  <a href="#create" class="md-nav__link">
    create
  </a>
  
</li>
        
          <li class="md-nav__item">
  <a href="#fit" class="md-nav__link">
    fit
  </a>
  
</li>
        
          <li class="md-nav__item">
  <a href="#get_params" class="md-nav__link">
    get_params
  </a>
  
</li>
        
          <li class="md-nav__item">
  <a href="#predict" class="md-nav__link">
    predict
  </a>
  
</li>
        
          <li class="md-nav__item">
  <a href="#score" class="md-nav__link">
    score
  </a>
  
</li>
        
          <li class="md-nav__item">
  <a href="#set_params" class="md-nav__link">
    set_params
  </a>
  
</li>
        
          <li class="md-nav__item">
  <a href="#coef_" class="md-nav__link">
    coef_
  </a>
  
</li>
        
          <li class="md-nav__item">
  <a href="#alpha_" class="md-nav__link">
    alpha_
  </a>
  
</li>
        
          <li class="md-nav__item">
  <a href="#lambda_" class="md-nav__link">
    lambda_
  </a>
  
</li>
        
          <li class="md-nav__item">
  <a href="#sigma_" class="md-nav__link">
    sigma_
  </a>
  
</li>
        
          <li class="md-nav__item">
  <a href="#scores_" class="md-nav__link">
    scores_
  </a>
  
</li>
        
          <li class="md-nav__item">
  <a href="#intercept_" class="md-nav__link">
    intercept_
  </a>
  
</li>
        
          <li class="md-nav__item">
  <a href="#to_string" class="md-nav__link">
    to_string
  </a>
  
</li>
        
          <li class="md-nav__item">
  <a href="#show" class="md-nav__link">
    show
  </a>
  
</li>
        
          <li class="md-nav__item">
  <a href="#pp" class="md-nav__link">
    pp
  </a>
  
</li>
        
      </ul>
    </nav>
  
</li>
      
        <li class="md-nav__item">
  <a href="#module-sklearnlinear_modelbayesianridge" class="md-nav__link">
    module Sklearn.​Linear_model.​BayesianRidge
  </a>
  
    <nav class="md-nav" aria-label="module Sklearn.​Linear_model.​BayesianRidge">
      <ul class="md-nav__list">
        
          <li class="md-nav__item">
  <a href="#create_1" class="md-nav__link">
    create
  </a>
  
</li>
        
          <li class="md-nav__item">
  <a href="#fit_1" class="md-nav__link">
    fit
  </a>
  
</li>
        
          <li class="md-nav__item">
  <a href="#get_params_1" class="md-nav__link">
    get_params
  </a>
  
</li>
        
          <li class="md-nav__item">
  <a href="#predict_1" class="md-nav__link">
    predict
  </a>
  
</li>
        
          <li class="md-nav__item">
  <a href="#score_1" class="md-nav__link">
    score
  </a>
  
</li>
        
          <li class="md-nav__item">
  <a href="#set_params_1" class="md-nav__link">
    set_params
  </a>
  
</li>
        
          <li class="md-nav__item">
  <a href="#coef__1" class="md-nav__link">
    coef_
  </a>
  
</li>
        
          <li class="md-nav__item">
  <a href="#intercept__1" class="md-nav__link">
    intercept_
  </a>
  
</li>
        
          <li class="md-nav__item">
  <a href="#alpha__1" class="md-nav__link">
    alpha_
  </a>
  
</li>
        
          <li class="md-nav__item">
  <a href="#lambda__1" class="md-nav__link">
    lambda_
  </a>
  
</li>
        
          <li class="md-nav__item">
  <a href="#sigma__1" class="md-nav__link">
    sigma_
  </a>
  
</li>
        
          <li class="md-nav__item">
  <a href="#scores__1" class="md-nav__link">
    scores_
  </a>
  
</li>
        
          <li class="md-nav__item">
  <a href="#n_iter_" class="md-nav__link">
    n_iter_
  </a>
  
</li>
        
          <li class="md-nav__item">
  <a href="#to_string_1" class="md-nav__link">
    to_string
  </a>
  
</li>
        
          <li class="md-nav__item">
  <a href="#show_1" class="md-nav__link">
    show
  </a>
  
</li>
        
          <li class="md-nav__item">
  <a href="#pp_1" class="md-nav__link">
    pp
  </a>
  
</li>
        
      </ul>
    </nav>
  
</li>
      
        <li class="md-nav__item">
  <a href="#module-sklearnlinear_modelelasticnet" class="md-nav__link">
    module Sklearn.​Linear_model.​ElasticNet
  </a>
  
    <nav class="md-nav" aria-label="module Sklearn.​Linear_model.​ElasticNet">
      <ul class="md-nav__list">
        
          <li class="md-nav__item">
  <a href="#create_2" class="md-nav__link">
    create
  </a>
  
</li>
        
          <li class="md-nav__item">
  <a href="#fit_2" class="md-nav__link">
    fit
  </a>
  
</li>
        
          <li class="md-nav__item">
  <a href="#get_params_2" class="md-nav__link">
    get_params
  </a>
  
</li>
        
          <li class="md-nav__item">
  <a href="#predict_2" class="md-nav__link">
    predict
  </a>
  
</li>
        
          <li class="md-nav__item">
  <a href="#score_2" class="md-nav__link">
    score
  </a>
  
</li>
        
          <li class="md-nav__item">
  <a href="#set_params_2" class="md-nav__link">
    set_params
  </a>
  
</li>
        
          <li class="md-nav__item">
  <a href="#coef__2" class="md-nav__link">
    coef_
  </a>
  
</li>
        
          <li class="md-nav__item">
  <a href="#sparse_coef_" class="md-nav__link">
    sparse_coef_
  </a>
  
</li>
        
          <li class="md-nav__item">
  <a href="#intercept__2" class="md-nav__link">
    intercept_
  </a>
  
</li>
        
          <li class="md-nav__item">
  <a href="#n_iter__1" class="md-nav__link">
    n_iter_
  </a>
  
</li>
        
          <li class="md-nav__item">
  <a href="#to_string_2" class="md-nav__link">
    to_string
  </a>
  
</li>
        
          <li class="md-nav__item">
  <a href="#show_2" class="md-nav__link">
    show
  </a>
  
</li>
        
          <li class="md-nav__item">
  <a href="#pp_2" class="md-nav__link">
    pp
  </a>
  
</li>
        
      </ul>
    </nav>
  
</li>
      
        <li class="md-nav__item">
  <a href="#module-sklearnlinear_modelelasticnetcv" class="md-nav__link">
    module Sklearn.​Linear_model.​ElasticNetCV
  </a>
  
    <nav class="md-nav" aria-label="module Sklearn.​Linear_model.​ElasticNetCV">
      <ul class="md-nav__list">
        
          <li class="md-nav__item">
  <a href="#create_3" class="md-nav__link">
    create
  </a>
  
</li>
        
          <li class="md-nav__item">
  <a href="#fit_3" class="md-nav__link">
    fit
  </a>
  
</li>
        
          <li class="md-nav__item">
  <a href="#get_params_3" class="md-nav__link">
    get_params
  </a>
  
</li>
        
          <li class="md-nav__item">
  <a href="#predict_3" class="md-nav__link">
    predict
  </a>
  
</li>
        
          <li class="md-nav__item">
  <a href="#score_3" class="md-nav__link">
    score
  </a>
  
</li>
        
          <li class="md-nav__item">
  <a href="#set_params_3" class="md-nav__link">
    set_params
  </a>
  
</li>
        
          <li class="md-nav__item">
  <a href="#alpha__2" class="md-nav__link">
    alpha_
  </a>
  
</li>
        
          <li class="md-nav__item">
  <a href="#l1_ratio_" class="md-nav__link">
    l1_ratio_
  </a>
  
</li>
        
          <li class="md-nav__item">
  <a href="#coef__3" class="md-nav__link">
    coef_
  </a>
  
</li>
        
          <li class="md-nav__item">
  <a href="#intercept__3" class="md-nav__link">
    intercept_
  </a>
  
</li>
        
          <li class="md-nav__item">
  <a href="#mse_path_" class="md-nav__link">
    mse_path_
  </a>
  
</li>
        
          <li class="md-nav__item">
  <a href="#alphas_" class="md-nav__link">
    alphas_
  </a>
  
</li>
        
          <li class="md-nav__item">
  <a href="#n_iter__2" class="md-nav__link">
    n_iter_
  </a>
  
</li>
        
          <li class="md-nav__item">
  <a href="#to_string_3" class="md-nav__link">
    to_string
  </a>
  
</li>
        
          <li class="md-nav__item">
  <a href="#show_3" class="md-nav__link">
    show
  </a>
  
</li>
        
          <li class="md-nav__item">
  <a href="#pp_3" class="md-nav__link">
    pp
  </a>
  
</li>
        
      </ul>
    </nav>
  
</li>
      
        <li class="md-nav__item">
  <a href="#module-sklearnlinear_modelhuberregressor" class="md-nav__link">
    module Sklearn.​Linear_model.​HuberRegressor
  </a>
  
    <nav class="md-nav" aria-label="module Sklearn.​Linear_model.​HuberRegressor">
      <ul class="md-nav__list">
        
          <li class="md-nav__item">
  <a href="#create_4" class="md-nav__link">
    create
  </a>
  
</li>
        
          <li class="md-nav__item">
  <a href="#fit_4" class="md-nav__link">
    fit
  </a>
  
</li>
        
          <li class="md-nav__item">
  <a href="#get_params_4" class="md-nav__link">
    get_params
  </a>
  
</li>
        
          <li class="md-nav__item">
  <a href="#predict_4" class="md-nav__link">
    predict
  </a>
  
</li>
        
          <li class="md-nav__item">
  <a href="#score_4" class="md-nav__link">
    score
  </a>
  
</li>
        
          <li class="md-nav__item">
  <a href="#set_params_4" class="md-nav__link">
    set_params
  </a>
  
</li>
        
          <li class="md-nav__item">
  <a href="#coef__4" class="md-nav__link">
    coef_
  </a>
  
</li>
        
          <li class="md-nav__item">
  <a href="#intercept__4" class="md-nav__link">
    intercept_
  </a>
  
</li>
        
          <li class="md-nav__item">
  <a href="#scale_" class="md-nav__link">
    scale_
  </a>
  
</li>
        
          <li class="md-nav__item">
  <a href="#n_iter__3" class="md-nav__link">
    n_iter_
  </a>
  
</li>
        
          <li class="md-nav__item">
  <a href="#outliers_" class="md-nav__link">
    outliers_
  </a>
  
</li>
        
          <li class="md-nav__item">
  <a href="#to_string_4" class="md-nav__link">
    to_string
  </a>
  
</li>
        
          <li class="md-nav__item">
  <a href="#show_4" class="md-nav__link">
    show
  </a>
  
</li>
        
          <li class="md-nav__item">
  <a href="#pp_4" class="md-nav__link">
    pp
  </a>
  
</li>
        
      </ul>
    </nav>
  
</li>
      
        <li class="md-nav__item">
  <a href="#module-sklearnlinear_modellars" class="md-nav__link">
    module Sklearn.​Linear_model.​Lars
  </a>
  
    <nav class="md-nav" aria-label="module Sklearn.​Linear_model.​Lars">
      <ul class="md-nav__list">
        
          <li class="md-nav__item">
  <a href="#create_5" class="md-nav__link">
    create
  </a>
  
</li>
        
          <li class="md-nav__item">
  <a href="#fit_5" class="md-nav__link">
    fit
  </a>
  
</li>
        
          <li class="md-nav__item">
  <a href="#get_params_5" class="md-nav__link">
    get_params
  </a>
  
</li>
        
          <li class="md-nav__item">
  <a href="#predict_5" class="md-nav__link">
    predict
  </a>
  
</li>
        
          <li class="md-nav__item">
  <a href="#score_5" class="md-nav__link">
    score
  </a>
  
</li>
        
          <li class="md-nav__item">
  <a href="#set_params_5" class="md-nav__link">
    set_params
  </a>
  
</li>
        
          <li class="md-nav__item">
  <a href="#alphas__1" class="md-nav__link">
    alphas_
  </a>
  
</li>
        
          <li class="md-nav__item">
  <a href="#active_" class="md-nav__link">
    active_
  </a>
  
</li>
        
          <li class="md-nav__item">
  <a href="#coef_path_" class="md-nav__link">
    coef_path_
  </a>
  
</li>
        
          <li class="md-nav__item">
  <a href="#coef__5" class="md-nav__link">
    coef_
  </a>
  
</li>
        
          <li class="md-nav__item">
  <a href="#intercept__5" class="md-nav__link">
    intercept_
  </a>
  
</li>
        
          <li class="md-nav__item">
  <a href="#n_iter__4" class="md-nav__link">
    n_iter_
  </a>
  
</li>
        
          <li class="md-nav__item">
  <a href="#to_string_5" class="md-nav__link">
    to_string
  </a>
  
</li>
        
          <li class="md-nav__item">
  <a href="#show_5" class="md-nav__link">
    show
  </a>
  
</li>
        
          <li class="md-nav__item">
  <a href="#pp_5" class="md-nav__link">
    pp
  </a>
  
</li>
        
      </ul>
    </nav>
  
</li>
      
        <li class="md-nav__item">
  <a href="#module-sklearnlinear_modellarscv" class="md-nav__link">
    module Sklearn.​Linear_model.​LarsCV
  </a>
  
    <nav class="md-nav" aria-label="module Sklearn.​Linear_model.​LarsCV">
      <ul class="md-nav__list">
        
          <li class="md-nav__item">
  <a href="#create_6" class="md-nav__link">
    create
  </a>
  
</li>
        
          <li class="md-nav__item">
  <a href="#fit_6" class="md-nav__link">
    fit
  </a>
  
</li>
        
          <li class="md-nav__item">
  <a href="#get_params_6" class="md-nav__link">
    get_params
  </a>
  
</li>
        
          <li class="md-nav__item">
  <a href="#predict_6" class="md-nav__link">
    predict
  </a>
  
</li>
        
          <li class="md-nav__item">
  <a href="#score_6" class="md-nav__link">
    score
  </a>
  
</li>
        
          <li class="md-nav__item">
  <a href="#set_params_6" class="md-nav__link">
    set_params
  </a>
  
</li>
        
          <li class="md-nav__item">
  <a href="#coef__6" class="md-nav__link">
    coef_
  </a>
  
</li>
        
          <li class="md-nav__item">
  <a href="#intercept__6" class="md-nav__link">
    intercept_
  </a>
  
</li>
        
          <li class="md-nav__item">
  <a href="#coef_path__1" class="md-nav__link">
    coef_path_
  </a>
  
</li>
        
          <li class="md-nav__item">
  <a href="#alpha__3" class="md-nav__link">
    alpha_
  </a>
  
</li>
        
          <li class="md-nav__item">
  <a href="#alphas__2" class="md-nav__link">
    alphas_
  </a>
  
</li>
        
          <li class="md-nav__item">
  <a href="#cv_alphas_" class="md-nav__link">
    cv_alphas_
  </a>
  
</li>
        
          <li class="md-nav__item">
  <a href="#mse_path__1" class="md-nav__link">
    mse_path_
  </a>
  
</li>
        
          <li class="md-nav__item">
  <a href="#n_iter__5" class="md-nav__link">
    n_iter_
  </a>
  
</li>
        
          <li class="md-nav__item">
  <a href="#to_string_6" class="md-nav__link">
    to_string
  </a>
  
</li>
        
          <li class="md-nav__item">
  <a href="#show_6" class="md-nav__link">
    show
  </a>
  
</li>
        
          <li class="md-nav__item">
  <a href="#pp_6" class="md-nav__link">
    pp
  </a>
  
</li>
        
      </ul>
    </nav>
  
</li>
      
        <li class="md-nav__item">
  <a href="#module-sklearnlinear_modellasso" class="md-nav__link">
    module Sklearn.​Linear_model.​Lasso
  </a>
  
    <nav class="md-nav" aria-label="module Sklearn.​Linear_model.​Lasso">
      <ul class="md-nav__list">
        
          <li class="md-nav__item">
  <a href="#create_7" class="md-nav__link">
    create
  </a>
  
</li>
        
          <li class="md-nav__item">
  <a href="#fit_7" class="md-nav__link">
    fit
  </a>
  
</li>
        
          <li class="md-nav__item">
  <a href="#get_params_7" class="md-nav__link">
    get_params
  </a>
  
</li>
        
          <li class="md-nav__item">
  <a href="#predict_7" class="md-nav__link">
    predict
  </a>
  
</li>
        
          <li class="md-nav__item">
  <a href="#score_7" class="md-nav__link">
    score
  </a>
  
</li>
        
          <li class="md-nav__item">
  <a href="#set_params_7" class="md-nav__link">
    set_params
  </a>
  
</li>
        
          <li class="md-nav__item">
  <a href="#coef__7" class="md-nav__link">
    coef_
  </a>
  
</li>
        
          <li class="md-nav__item">
  <a href="#sparse_coef__1" class="md-nav__link">
    sparse_coef_
  </a>
  
</li>
        
          <li class="md-nav__item">
  <a href="#intercept__7" class="md-nav__link">
    intercept_
  </a>
  
</li>
        
          <li class="md-nav__item">
  <a href="#n_iter__6" class="md-nav__link">
    n_iter_
  </a>
  
</li>
        
          <li class="md-nav__item">
  <a href="#to_string_7" class="md-nav__link">
    to_string
  </a>
  
</li>
        
          <li class="md-nav__item">
  <a href="#show_7" class="md-nav__link">
    show
  </a>
  
</li>
        
          <li class="md-nav__item">
  <a href="#pp_7" class="md-nav__link">
    pp
  </a>
  
</li>
        
      </ul>
    </nav>
  
</li>
      
        <li class="md-nav__item">
  <a href="#module-sklearnlinear_modellassocv" class="md-nav__link">
    module Sklearn.​Linear_model.​LassoCV
  </a>
  
    <nav class="md-nav" aria-label="module Sklearn.​Linear_model.​LassoCV">
      <ul class="md-nav__list">
        
          <li class="md-nav__item">
  <a href="#create_8" class="md-nav__link">
    create
  </a>
  
</li>
        
          <li class="md-nav__item">
  <a href="#fit_8" class="md-nav__link">
    fit
  </a>
  
</li>
        
          <li class="md-nav__item">
  <a href="#get_params_8" class="md-nav__link">
    get_params
  </a>
  
</li>
        
          <li class="md-nav__item">
  <a href="#predict_8" class="md-nav__link">
    predict
  </a>
  
</li>
        
          <li class="md-nav__item">
  <a href="#score_8" class="md-nav__link">
    score
  </a>
  
</li>
        
          <li class="md-nav__item">
  <a href="#set_params_8" class="md-nav__link">
    set_params
  </a>
  
</li>
        
          <li class="md-nav__item">
  <a href="#alpha__4" class="md-nav__link">
    alpha_
  </a>
  
</li>
        
          <li class="md-nav__item">
  <a href="#coef__8" class="md-nav__link">
    coef_
  </a>
  
</li>
        
          <li class="md-nav__item">
  <a href="#intercept__8" class="md-nav__link">
    intercept_
  </a>
  
</li>
        
          <li class="md-nav__item">
  <a href="#mse_path__2" class="md-nav__link">
    mse_path_
  </a>
  
</li>
        
          <li class="md-nav__item">
  <a href="#alphas__3" class="md-nav__link">
    alphas_
  </a>
  
</li>
        
          <li class="md-nav__item">
  <a href="#dual_gap_" class="md-nav__link">
    dual_gap_
  </a>
  
</li>
        
          <li class="md-nav__item">
  <a href="#n_iter__7" class="md-nav__link">
    n_iter_
  </a>
  
</li>
        
          <li class="md-nav__item">
  <a href="#to_string_8" class="md-nav__link">
    to_string
  </a>
  
</li>
        
          <li class="md-nav__item">
  <a href="#show_8" class="md-nav__link">
    show
  </a>
  
</li>
        
          <li class="md-nav__item">
  <a href="#pp_8" class="md-nav__link">
    pp
  </a>
  
</li>
        
      </ul>
    </nav>
  
</li>
      
        <li class="md-nav__item">
  <a href="#module-sklearnlinear_modellassolars" class="md-nav__link">
    module Sklearn.​Linear_model.​LassoLars
  </a>
  
    <nav class="md-nav" aria-label="module Sklearn.​Linear_model.​LassoLars">
      <ul class="md-nav__list">
        
          <li class="md-nav__item">
  <a href="#create_9" class="md-nav__link">
    create
  </a>
  
</li>
        
          <li class="md-nav__item">
  <a href="#fit_9" class="md-nav__link">
    fit
  </a>
  
</li>
        
          <li class="md-nav__item">
  <a href="#get_params_9" class="md-nav__link">
    get_params
  </a>
  
</li>
        
          <li class="md-nav__item">
  <a href="#predict_9" class="md-nav__link">
    predict
  </a>
  
</li>
        
          <li class="md-nav__item">
  <a href="#score_9" class="md-nav__link">
    score
  </a>
  
</li>
        
          <li class="md-nav__item">
  <a href="#set_params_9" class="md-nav__link">
    set_params
  </a>
  
</li>
        
          <li class="md-nav__item">
  <a href="#alphas__4" class="md-nav__link">
    alphas_
  </a>
  
</li>
        
          <li class="md-nav__item">
  <a href="#active__1" class="md-nav__link">
    active_
  </a>
  
</li>
        
          <li class="md-nav__item">
  <a href="#coef_path__2" class="md-nav__link">
    coef_path_
  </a>
  
</li>
        
          <li class="md-nav__item">
  <a href="#coef__9" class="md-nav__link">
    coef_
  </a>
  
</li>
        
          <li class="md-nav__item">
  <a href="#intercept__9" class="md-nav__link">
    intercept_
  </a>
  
</li>
        
          <li class="md-nav__item">
  <a href="#n_iter__8" class="md-nav__link">
    n_iter_
  </a>
  
</li>
        
          <li class="md-nav__item">
  <a href="#to_string_9" class="md-nav__link">
    to_string
  </a>
  
</li>
        
          <li class="md-nav__item">
  <a href="#show_9" class="md-nav__link">
    show
  </a>
  
</li>
        
          <li class="md-nav__item">
  <a href="#pp_9" class="md-nav__link">
    pp
  </a>
  
</li>
        
      </ul>
    </nav>
  
</li>
      
        <li class="md-nav__item">
  <a href="#module-sklearnlinear_modellassolarscv" class="md-nav__link">
    module Sklearn.​Linear_model.​LassoLarsCV
  </a>
  
    <nav class="md-nav" aria-label="module Sklearn.​Linear_model.​LassoLarsCV">
      <ul class="md-nav__list">
        
          <li class="md-nav__item">
  <a href="#create_10" class="md-nav__link">
    create
  </a>
  
</li>
        
          <li class="md-nav__item">
  <a href="#fit_10" class="md-nav__link">
    fit
  </a>
  
</li>
        
          <li class="md-nav__item">
  <a href="#get_params_10" class="md-nav__link">
    get_params
  </a>
  
</li>
        
          <li class="md-nav__item">
  <a href="#predict_10" class="md-nav__link">
    predict
  </a>
  
</li>
        
          <li class="md-nav__item">
  <a href="#score_10" class="md-nav__link">
    score
  </a>
  
</li>
        
          <li class="md-nav__item">
  <a href="#set_params_10" class="md-nav__link">
    set_params
  </a>
  
</li>
        
          <li class="md-nav__item">
  <a href="#coef__10" class="md-nav__link">
    coef_
  </a>
  
</li>
        
          <li class="md-nav__item">
  <a href="#intercept__10" class="md-nav__link">
    intercept_
  </a>
  
</li>
        
          <li class="md-nav__item">
  <a href="#coef_path__3" class="md-nav__link">
    coef_path_
  </a>
  
</li>
        
          <li class="md-nav__item">
  <a href="#alpha__5" class="md-nav__link">
    alpha_
  </a>
  
</li>
        
          <li class="md-nav__item">
  <a href="#alphas__5" class="md-nav__link">
    alphas_
  </a>
  
</li>
        
          <li class="md-nav__item">
  <a href="#cv_alphas__1" class="md-nav__link">
    cv_alphas_
  </a>
  
</li>
        
          <li class="md-nav__item">
  <a href="#mse_path__3" class="md-nav__link">
    mse_path_
  </a>
  
</li>
        
          <li class="md-nav__item">
  <a href="#n_iter__9" class="md-nav__link">
    n_iter_
  </a>
  
</li>
        
          <li class="md-nav__item">
  <a href="#to_string_10" class="md-nav__link">
    to_string
  </a>
  
</li>
        
          <li class="md-nav__item">
  <a href="#show_10" class="md-nav__link">
    show
  </a>
  
</li>
        
          <li class="md-nav__item">
  <a href="#pp_10" class="md-nav__link">
    pp
  </a>
  
</li>
        
      </ul>
    </nav>
  
</li>
      
        <li class="md-nav__item">
  <a href="#module-sklearnlinear_modellassolarsic" class="md-nav__link">
    module Sklearn.​Linear_model.​LassoLarsIC
  </a>
  
    <nav class="md-nav" aria-label="module Sklearn.​Linear_model.​LassoLarsIC">
      <ul class="md-nav__list">
        
          <li class="md-nav__item">
  <a href="#create_11" class="md-nav__link">
    create
  </a>
  
</li>
        
          <li class="md-nav__item">
  <a href="#fit_11" class="md-nav__link">
    fit
  </a>
  
</li>
        
          <li class="md-nav__item">
  <a href="#get_params_11" class="md-nav__link">
    get_params
  </a>
  
</li>
        
          <li class="md-nav__item">
  <a href="#predict_11" class="md-nav__link">
    predict
  </a>
  
</li>
        
          <li class="md-nav__item">
  <a href="#score_11" class="md-nav__link">
    score
  </a>
  
</li>
        
          <li class="md-nav__item">
  <a href="#set_params_11" class="md-nav__link">
    set_params
  </a>
  
</li>
        
          <li class="md-nav__item">
  <a href="#coef__11" class="md-nav__link">
    coef_
  </a>
  
</li>
        
          <li class="md-nav__item">
  <a href="#intercept__11" class="md-nav__link">
    intercept_
  </a>
  
</li>
        
          <li class="md-nav__item">
  <a href="#alpha__6" class="md-nav__link">
    alpha_
  </a>
  
</li>
        
          <li class="md-nav__item">
  <a href="#n_iter__10" class="md-nav__link">
    n_iter_
  </a>
  
</li>
        
          <li class="md-nav__item">
  <a href="#criterion_" class="md-nav__link">
    criterion_
  </a>
  
</li>
        
          <li class="md-nav__item">
  <a href="#to_string_11" class="md-nav__link">
    to_string
  </a>
  
</li>
        
          <li class="md-nav__item">
  <a href="#show_11" class="md-nav__link">
    show
  </a>
  
</li>
        
          <li class="md-nav__item">
  <a href="#pp_11" class="md-nav__link">
    pp
  </a>
  
</li>
        
      </ul>
    </nav>
  
</li>
      
        <li class="md-nav__item">
  <a href="#module-sklearnlinear_modellinearregression" class="md-nav__link">
    module Sklearn.​Linear_model.​LinearRegression
  </a>
  
    <nav class="md-nav" aria-label="module Sklearn.​Linear_model.​LinearRegression">
      <ul class="md-nav__list">
        
          <li class="md-nav__item">
  <a href="#create_12" class="md-nav__link">
    create
  </a>
  
</li>
        
          <li class="md-nav__item">
  <a href="#fit_12" class="md-nav__link">
    fit
  </a>
  
</li>
        
          <li class="md-nav__item">
  <a href="#get_params_12" class="md-nav__link">
    get_params
  </a>
  
</li>
        
          <li class="md-nav__item">
  <a href="#predict_12" class="md-nav__link">
    predict
  </a>
  
</li>
        
          <li class="md-nav__item">
  <a href="#score_12" class="md-nav__link">
    score
  </a>
  
</li>
        
          <li class="md-nav__item">
  <a href="#set_params_12" class="md-nav__link">
    set_params
  </a>
  
</li>
        
          <li class="md-nav__item">
  <a href="#coef__12" class="md-nav__link">
    coef_
  </a>
  
</li>
        
          <li class="md-nav__item">
  <a href="#rank_" class="md-nav__link">
    rank_
  </a>
  
</li>
        
          <li class="md-nav__item">
  <a href="#singular_" class="md-nav__link">
    singular_
  </a>
  
</li>
        
          <li class="md-nav__item">
  <a href="#intercept__12" class="md-nav__link">
    intercept_
  </a>
  
</li>
        
          <li class="md-nav__item">
  <a href="#to_string_12" class="md-nav__link">
    to_string
  </a>
  
</li>
        
          <li class="md-nav__item">
  <a href="#show_12" class="md-nav__link">
    show
  </a>
  
</li>
        
          <li class="md-nav__item">
  <a href="#pp_12" class="md-nav__link">
    pp
  </a>
  
</li>
        
      </ul>
    </nav>
  
</li>
      
        <li class="md-nav__item">
  <a href="#module-sklearnlinear_modellogisticregression" class="md-nav__link">
    module Sklearn.​Linear_model.​LogisticRegression
  </a>
  
    <nav class="md-nav" aria-label="module Sklearn.​Linear_model.​LogisticRegression">
      <ul class="md-nav__list">
        
          <li class="md-nav__item">
  <a href="#create_13" class="md-nav__link">
    create
  </a>
  
</li>
        
          <li class="md-nav__item">
  <a href="#decision_function" class="md-nav__link">
    decision_function
  </a>
  
</li>
        
          <li class="md-nav__item">
  <a href="#densify" class="md-nav__link">
    densify
  </a>
  
</li>
        
          <li class="md-nav__item">
  <a href="#fit_13" class="md-nav__link">
    fit
  </a>
  
</li>
        
          <li class="md-nav__item">
  <a href="#get_params_13" class="md-nav__link">
    get_params
  </a>
  
</li>
        
          <li class="md-nav__item">
  <a href="#predict_13" class="md-nav__link">
    predict
  </a>
  
</li>
        
          <li class="md-nav__item">
  <a href="#predict_log_proba" class="md-nav__link">
    predict_log_proba
  </a>
  
</li>
        
          <li class="md-nav__item">
  <a href="#predict_proba" class="md-nav__link">
    predict_proba
  </a>
  
</li>
        
          <li class="md-nav__item">
  <a href="#score_13" class="md-nav__link">
    score
  </a>
  
</li>
        
          <li class="md-nav__item">
  <a href="#set_params_13" class="md-nav__link">
    set_params
  </a>
  
</li>
        
          <li class="md-nav__item">
  <a href="#sparsify" class="md-nav__link">
    sparsify
  </a>
  
</li>
        
          <li class="md-nav__item">
  <a href="#classes_" class="md-nav__link">
    classes_
  </a>
  
</li>
        
          <li class="md-nav__item">
  <a href="#coef__13" class="md-nav__link">
    coef_
  </a>
  
</li>
        
          <li class="md-nav__item">
  <a href="#intercept__13" class="md-nav__link">
    intercept_
  </a>
  
</li>
        
          <li class="md-nav__item">
  <a href="#n_iter__11" class="md-nav__link">
    n_iter_
  </a>
  
</li>
        
          <li class="md-nav__item">
  <a href="#to_string_13" class="md-nav__link">
    to_string
  </a>
  
</li>
        
          <li class="md-nav__item">
  <a href="#show_13" class="md-nav__link">
    show
  </a>
  
</li>
        
          <li class="md-nav__item">
  <a href="#pp_13" class="md-nav__link">
    pp
  </a>
  
</li>
        
      </ul>
    </nav>
  
</li>
      
        <li class="md-nav__item">
  <a href="#module-sklearnlinear_modellogisticregressioncv" class="md-nav__link">
    module Sklearn.​Linear_model.​LogisticRegressionCV
  </a>
  
    <nav class="md-nav" aria-label="module Sklearn.​Linear_model.​LogisticRegressionCV">
      <ul class="md-nav__list">
        
          <li class="md-nav__item">
  <a href="#create_14" class="md-nav__link">
    create
  </a>
  
</li>
        
          <li class="md-nav__item">
  <a href="#decision_function_1" class="md-nav__link">
    decision_function
  </a>
  
</li>
        
          <li class="md-nav__item">
  <a href="#densify_1" class="md-nav__link">
    densify
  </a>
  
</li>
        
          <li class="md-nav__item">
  <a href="#fit_14" class="md-nav__link">
    fit
  </a>
  
</li>
        
          <li class="md-nav__item">
  <a href="#get_params_14" class="md-nav__link">
    get_params
  </a>
  
</li>
        
          <li class="md-nav__item">
  <a href="#predict_14" class="md-nav__link">
    predict
  </a>
  
</li>
        
          <li class="md-nav__item">
  <a href="#predict_log_proba_1" class="md-nav__link">
    predict_log_proba
  </a>
  
</li>
        
          <li class="md-nav__item">
  <a href="#predict_proba_1" class="md-nav__link">
    predict_proba
  </a>
  
</li>
        
          <li class="md-nav__item">
  <a href="#score_14" class="md-nav__link">
    score
  </a>
  
</li>
        
          <li class="md-nav__item">
  <a href="#set_params_14" class="md-nav__link">
    set_params
  </a>
  
</li>
        
          <li class="md-nav__item">
  <a href="#sparsify_1" class="md-nav__link">
    sparsify
  </a>
  
</li>
        
          <li class="md-nav__item">
  <a href="#classes__1" class="md-nav__link">
    classes_
  </a>
  
</li>
        
          <li class="md-nav__item">
  <a href="#coef__14" class="md-nav__link">
    coef_
  </a>
  
</li>
        
          <li class="md-nav__item">
  <a href="#intercept__14" class="md-nav__link">
    intercept_
  </a>
  
</li>
        
          <li class="md-nav__item">
  <a href="#cs_" class="md-nav__link">
    cs_
  </a>
  
</li>
        
          <li class="md-nav__item">
  <a href="#l1_ratios_" class="md-nav__link">
    l1_ratios_
  </a>
  
</li>
        
          <li class="md-nav__item">
  <a href="#coefs_paths_" class="md-nav__link">
    coefs_paths_
  </a>
  
</li>
        
          <li class="md-nav__item">
  <a href="#scores__2" class="md-nav__link">
    scores_
  </a>
  
</li>
        
          <li class="md-nav__item">
  <a href="#c_" class="md-nav__link">
    c_
  </a>
  
</li>
        
          <li class="md-nav__item">
  <a href="#l1_ratio__1" class="md-nav__link">
    l1_ratio_
  </a>
  
</li>
        
          <li class="md-nav__item">
  <a href="#n_iter__12" class="md-nav__link">
    n_iter_
  </a>
  
</li>
        
          <li class="md-nav__item">
  <a href="#to_string_14" class="md-nav__link">
    to_string
  </a>
  
</li>
        
          <li class="md-nav__item">
  <a href="#show_14" class="md-nav__link">
    show
  </a>
  
</li>
        
          <li class="md-nav__item">
  <a href="#pp_14" class="md-nav__link">
    pp
  </a>
  
</li>
        
      </ul>
    </nav>
  
</li>
      
        <li class="md-nav__item">
  <a href="#module-sklearnlinear_modelmultitaskelasticnet" class="md-nav__link">
    module Sklearn.​Linear_model.​MultiTaskElasticNet
  </a>
  
    <nav class="md-nav" aria-label="module Sklearn.​Linear_model.​MultiTaskElasticNet">
      <ul class="md-nav__list">
        
          <li class="md-nav__item">
  <a href="#create_15" class="md-nav__link">
    create
  </a>
  
</li>
        
          <li class="md-nav__item">
  <a href="#fit_15" class="md-nav__link">
    fit
  </a>
  
</li>
        
          <li class="md-nav__item">
  <a href="#get_params_15" class="md-nav__link">
    get_params
  </a>
  
</li>
        
          <li class="md-nav__item">
  <a href="#predict_15" class="md-nav__link">
    predict
  </a>
  
</li>
        
          <li class="md-nav__item">
  <a href="#score_15" class="md-nav__link">
    score
  </a>
  
</li>
        
          <li class="md-nav__item">
  <a href="#set_params_15" class="md-nav__link">
    set_params
  </a>
  
</li>
        
          <li class="md-nav__item">
  <a href="#intercept__15" class="md-nav__link">
    intercept_
  </a>
  
</li>
        
          <li class="md-nav__item">
  <a href="#coef__15" class="md-nav__link">
    coef_
  </a>
  
</li>
        
          <li class="md-nav__item">
  <a href="#n_iter__13" class="md-nav__link">
    n_iter_
  </a>
  
</li>
        
          <li class="md-nav__item">
  <a href="#to_string_15" class="md-nav__link">
    to_string
  </a>
  
</li>
        
          <li class="md-nav__item">
  <a href="#show_15" class="md-nav__link">
    show
  </a>
  
</li>
        
          <li class="md-nav__item">
  <a href="#pp_15" class="md-nav__link">
    pp
  </a>
  
</li>
        
      </ul>
    </nav>
  
</li>
      
        <li class="md-nav__item">
  <a href="#module-sklearnlinear_modelmultitaskelasticnetcv" class="md-nav__link">
    module Sklearn.​Linear_model.​MultiTaskElasticNetCV
  </a>
  
    <nav class="md-nav" aria-label="module Sklearn.​Linear_model.​MultiTaskElasticNetCV">
      <ul class="md-nav__list">
        
          <li class="md-nav__item">
  <a href="#create_16" class="md-nav__link">
    create
  </a>
  
</li>
        
          <li class="md-nav__item">
  <a href="#fit_16" class="md-nav__link">
    fit
  </a>
  
</li>
        
          <li class="md-nav__item">
  <a href="#get_params_16" class="md-nav__link">
    get_params
  </a>
  
</li>
        
          <li class="md-nav__item">
  <a href="#predict_16" class="md-nav__link">
    predict
  </a>
  
</li>
        
          <li class="md-nav__item">
  <a href="#score_16" class="md-nav__link">
    score
  </a>
  
</li>
        
          <li class="md-nav__item">
  <a href="#set_params_16" class="md-nav__link">
    set_params
  </a>
  
</li>
        
          <li class="md-nav__item">
  <a href="#intercept__16" class="md-nav__link">
    intercept_
  </a>
  
</li>
        
          <li class="md-nav__item">
  <a href="#coef__16" class="md-nav__link">
    coef_
  </a>
  
</li>
        
          <li class="md-nav__item">
  <a href="#alpha__7" class="md-nav__link">
    alpha_
  </a>
  
</li>
        
          <li class="md-nav__item">
  <a href="#mse_path__4" class="md-nav__link">
    mse_path_
  </a>
  
</li>
        
          <li class="md-nav__item">
  <a href="#alphas__6" class="md-nav__link">
    alphas_
  </a>
  
</li>
        
          <li class="md-nav__item">
  <a href="#l1_ratio__2" class="md-nav__link">
    l1_ratio_
  </a>
  
</li>
        
          <li class="md-nav__item">
  <a href="#n_iter__14" class="md-nav__link">
    n_iter_
  </a>
  
</li>
        
          <li class="md-nav__item">
  <a href="#to_string_16" class="md-nav__link">
    to_string
  </a>
  
</li>
        
          <li class="md-nav__item">
  <a href="#show_16" class="md-nav__link">
    show
  </a>
  
</li>
        
          <li class="md-nav__item">
  <a href="#pp_16" class="md-nav__link">
    pp
  </a>
  
</li>
        
      </ul>
    </nav>
  
</li>
      
        <li class="md-nav__item">
  <a href="#module-sklearnlinear_modelmultitasklasso" class="md-nav__link">
    module Sklearn.​Linear_model.​MultiTaskLasso
  </a>
  
    <nav class="md-nav" aria-label="module Sklearn.​Linear_model.​MultiTaskLasso">
      <ul class="md-nav__list">
        
          <li class="md-nav__item">
  <a href="#create_17" class="md-nav__link">
    create
  </a>
  
</li>
        
          <li class="md-nav__item">
  <a href="#fit_17" class="md-nav__link">
    fit
  </a>
  
</li>
        
          <li class="md-nav__item">
  <a href="#get_params_17" class="md-nav__link">
    get_params
  </a>
  
</li>
        
          <li class="md-nav__item">
  <a href="#predict_17" class="md-nav__link">
    predict
  </a>
  
</li>
        
          <li class="md-nav__item">
  <a href="#score_17" class="md-nav__link">
    score
  </a>
  
</li>
        
          <li class="md-nav__item">
  <a href="#set_params_17" class="md-nav__link">
    set_params
  </a>
  
</li>
        
          <li class="md-nav__item">
  <a href="#coef__17" class="md-nav__link">
    coef_
  </a>
  
</li>
        
          <li class="md-nav__item">
  <a href="#intercept__17" class="md-nav__link">
    intercept_
  </a>
  
</li>
        
          <li class="md-nav__item">
  <a href="#n_iter__15" class="md-nav__link">
    n_iter_
  </a>
  
</li>
        
          <li class="md-nav__item">
  <a href="#to_string_17" class="md-nav__link">
    to_string
  </a>
  
</li>
        
          <li class="md-nav__item">
  <a href="#show_17" class="md-nav__link">
    show
  </a>
  
</li>
        
          <li class="md-nav__item">
  <a href="#pp_17" class="md-nav__link">
    pp
  </a>
  
</li>
        
      </ul>
    </nav>
  
</li>
      
        <li class="md-nav__item">
  <a href="#module-sklearnlinear_modelmultitasklassocv" class="md-nav__link">
    module Sklearn.​Linear_model.​MultiTaskLassoCV
  </a>
  
    <nav class="md-nav" aria-label="module Sklearn.​Linear_model.​MultiTaskLassoCV">
      <ul class="md-nav__list">
        
          <li class="md-nav__item">
  <a href="#create_18" class="md-nav__link">
    create
  </a>
  
</li>
        
          <li class="md-nav__item">
  <a href="#fit_18" class="md-nav__link">
    fit
  </a>
  
</li>
        
          <li class="md-nav__item">
  <a href="#get_params_18" class="md-nav__link">
    get_params
  </a>
  
</li>
        
          <li class="md-nav__item">
  <a href="#predict_18" class="md-nav__link">
    predict
  </a>
  
</li>
        
          <li class="md-nav__item">
  <a href="#score_18" class="md-nav__link">
    score
  </a>
  
</li>
        
          <li class="md-nav__item">
  <a href="#set_params_18" class="md-nav__link">
    set_params
  </a>
  
</li>
        
          <li class="md-nav__item">
  <a href="#intercept__18" class="md-nav__link">
    intercept_
  </a>
  
</li>
        
          <li class="md-nav__item">
  <a href="#coef__18" class="md-nav__link">
    coef_
  </a>
  
</li>
        
          <li class="md-nav__item">
  <a href="#alpha__8" class="md-nav__link">
    alpha_
  </a>
  
</li>
        
          <li class="md-nav__item">
  <a href="#mse_path__5" class="md-nav__link">
    mse_path_
  </a>
  
</li>
        
          <li class="md-nav__item">
  <a href="#alphas__7" class="md-nav__link">
    alphas_
  </a>
  
</li>
        
          <li class="md-nav__item">
  <a href="#n_iter__16" class="md-nav__link">
    n_iter_
  </a>
  
</li>
        
          <li class="md-nav__item">
  <a href="#to_string_18" class="md-nav__link">
    to_string
  </a>
  
</li>
        
          <li class="md-nav__item">
  <a href="#show_18" class="md-nav__link">
    show
  </a>
  
</li>
        
          <li class="md-nav__item">
  <a href="#pp_18" class="md-nav__link">
    pp
  </a>
  
</li>
        
      </ul>
    </nav>
  
</li>
      
        <li class="md-nav__item">
  <a href="#module-sklearnlinear_modelorthogonalmatchingpursuit" class="md-nav__link">
    module Sklearn.​Linear_model.​OrthogonalMatchingPursuit
  </a>
  
    <nav class="md-nav" aria-label="module Sklearn.​Linear_model.​OrthogonalMatchingPursuit">
      <ul class="md-nav__list">
        
          <li class="md-nav__item">
  <a href="#create_19" class="md-nav__link">
    create
  </a>
  
</li>
        
          <li class="md-nav__item">
  <a href="#fit_19" class="md-nav__link">
    fit
  </a>
  
</li>
        
          <li class="md-nav__item">
  <a href="#get_params_19" class="md-nav__link">
    get_params
  </a>
  
</li>
        
          <li class="md-nav__item">
  <a href="#predict_19" class="md-nav__link">
    predict
  </a>
  
</li>
        
          <li class="md-nav__item">
  <a href="#score_19" class="md-nav__link">
    score
  </a>
  
</li>
        
          <li class="md-nav__item">
  <a href="#set_params_19" class="md-nav__link">
    set_params
  </a>
  
</li>
        
          <li class="md-nav__item">
  <a href="#coef__19" class="md-nav__link">
    coef_
  </a>
  
</li>
        
          <li class="md-nav__item">
  <a href="#intercept__19" class="md-nav__link">
    intercept_
  </a>
  
</li>
        
          <li class="md-nav__item">
  <a href="#n_iter__17" class="md-nav__link">
    n_iter_
  </a>
  
</li>
        
          <li class="md-nav__item">
  <a href="#to_string_19" class="md-nav__link">
    to_string
  </a>
  
</li>
        
          <li class="md-nav__item">
  <a href="#show_19" class="md-nav__link">
    show
  </a>
  
</li>
        
          <li class="md-nav__item">
  <a href="#pp_19" class="md-nav__link">
    pp
  </a>
  
</li>
        
      </ul>
    </nav>
  
</li>
      
        <li class="md-nav__item">
  <a href="#module-sklearnlinear_modelorthogonalmatchingpursuitcv" class="md-nav__link">
    module Sklearn.​Linear_model.​OrthogonalMatchingPursuitCV
  </a>
  
    <nav class="md-nav" aria-label="module Sklearn.​Linear_model.​OrthogonalMatchingPursuitCV">
      <ul class="md-nav__list">
        
          <li class="md-nav__item">
  <a href="#create_20" class="md-nav__link">
    create
  </a>
  
</li>
        
          <li class="md-nav__item">
  <a href="#fit_20" class="md-nav__link">
    fit
  </a>
  
</li>
        
          <li class="md-nav__item">
  <a href="#get_params_20" class="md-nav__link">
    get_params
  </a>
  
</li>
        
          <li class="md-nav__item">
  <a href="#predict_20" class="md-nav__link">
    predict
  </a>
  
</li>
        
          <li class="md-nav__item">
  <a href="#score_20" class="md-nav__link">
    score
  </a>
  
</li>
        
          <li class="md-nav__item">
  <a href="#set_params_20" class="md-nav__link">
    set_params
  </a>
  
</li>
        
          <li class="md-nav__item">
  <a href="#intercept__20" class="md-nav__link">
    intercept_
  </a>
  
</li>
        
          <li class="md-nav__item">
  <a href="#coef__20" class="md-nav__link">
    coef_
  </a>
  
</li>
        
          <li class="md-nav__item">
  <a href="#n_nonzero_coefs_" class="md-nav__link">
    n_nonzero_coefs_
  </a>
  
</li>
        
          <li class="md-nav__item">
  <a href="#n_iter__18" class="md-nav__link">
    n_iter_
  </a>
  
</li>
        
          <li class="md-nav__item">
  <a href="#to_string_20" class="md-nav__link">
    to_string
  </a>
  
</li>
        
          <li class="md-nav__item">
  <a href="#show_20" class="md-nav__link">
    show
  </a>
  
</li>
        
          <li class="md-nav__item">
  <a href="#pp_20" class="md-nav__link">
    pp
  </a>
  
</li>
        
      </ul>
    </nav>
  
</li>
      
        <li class="md-nav__item">
  <a href="#module-sklearnlinear_modelransacregressor" class="md-nav__link">
    module Sklearn.​Linear_model.​RANSACRegressor
  </a>
  
    <nav class="md-nav" aria-label="module Sklearn.​Linear_model.​RANSACRegressor">
      <ul class="md-nav__list">
        
          <li class="md-nav__item">
  <a href="#create_21" class="md-nav__link">
    create
  </a>
  
</li>
        
          <li class="md-nav__item">
  <a href="#fit_21" class="md-nav__link">
    fit
  </a>
  
</li>
        
          <li class="md-nav__item">
  <a href="#get_params_21" class="md-nav__link">
    get_params
  </a>
  
</li>
        
          <li class="md-nav__item">
  <a href="#predict_21" class="md-nav__link">
    predict
  </a>
  
</li>
        
          <li class="md-nav__item">
  <a href="#score_21" class="md-nav__link">
    score
  </a>
  
</li>
        
          <li class="md-nav__item">
  <a href="#set_params_21" class="md-nav__link">
    set_params
  </a>
  
</li>
        
          <li class="md-nav__item">
  <a href="#estimator_" class="md-nav__link">
    estimator_
  </a>
  
</li>
        
          <li class="md-nav__item">
  <a href="#n_trials_" class="md-nav__link">
    n_trials_
  </a>
  
</li>
        
          <li class="md-nav__item">
  <a href="#inlier_mask_" class="md-nav__link">
    inlier_mask_
  </a>
  
</li>
        
          <li class="md-nav__item">
  <a href="#n_skips_no_inliers_" class="md-nav__link">
    n_skips_no_inliers_
  </a>
  
</li>
        
          <li class="md-nav__item">
  <a href="#n_skips_invalid_data_" class="md-nav__link">
    n_skips_invalid_data_
  </a>
  
</li>
        
          <li class="md-nav__item">
  <a href="#n_skips_invalid_model_" class="md-nav__link">
    n_skips_invalid_model_
  </a>
  
</li>
        
          <li class="md-nav__item">
  <a href="#to_string_21" class="md-nav__link">
    to_string
  </a>
  
</li>
        
          <li class="md-nav__item">
  <a href="#show_21" class="md-nav__link">
    show
  </a>
  
</li>
        
          <li class="md-nav__item">
  <a href="#pp_21" class="md-nav__link">
    pp
  </a>
  
</li>
        
      </ul>
    </nav>
  
</li>
      
        <li class="md-nav__item">
  <a href="#module-sklearnlinear_modelridge" class="md-nav__link">
    module Sklearn.​Linear_model.​Ridge
  </a>
  
    <nav class="md-nav" aria-label="module Sklearn.​Linear_model.​Ridge">
      <ul class="md-nav__list">
        
          <li class="md-nav__item">
  <a href="#create_22" class="md-nav__link">
    create
  </a>
  
</li>
        
          <li class="md-nav__item">
  <a href="#fit_22" class="md-nav__link">
    fit
  </a>
  
</li>
        
          <li class="md-nav__item">
  <a href="#get_params_22" class="md-nav__link">
    get_params
  </a>
  
</li>
        
          <li class="md-nav__item">
  <a href="#predict_22" class="md-nav__link">
    predict
  </a>
  
</li>
        
          <li class="md-nav__item">
  <a href="#score_22" class="md-nav__link">
    score
  </a>
  
</li>
        
          <li class="md-nav__item">
  <a href="#set_params_22" class="md-nav__link">
    set_params
  </a>
  
</li>
        
          <li class="md-nav__item">
  <a href="#coef__21" class="md-nav__link">
    coef_
  </a>
  
</li>
        
          <li class="md-nav__item">
  <a href="#intercept__21" class="md-nav__link">
    intercept_
  </a>
  
</li>
        
          <li class="md-nav__item">
  <a href="#n_iter__19" class="md-nav__link">
    n_iter_
  </a>
  
</li>
        
          <li class="md-nav__item">
  <a href="#to_string_22" class="md-nav__link">
    to_string
  </a>
  
</li>
        
          <li class="md-nav__item">
  <a href="#show_22" class="md-nav__link">
    show
  </a>
  
</li>
        
          <li class="md-nav__item">
  <a href="#pp_22" class="md-nav__link">
    pp
  </a>
  
</li>
        
      </ul>
    </nav>
  
</li>
      
        <li class="md-nav__item">
  <a href="#module-sklearnlinear_modelridgecv" class="md-nav__link">
    module Sklearn.​Linear_model.​RidgeCV
  </a>
  
    <nav class="md-nav" aria-label="module Sklearn.​Linear_model.​RidgeCV">
      <ul class="md-nav__list">
        
          <li class="md-nav__item">
  <a href="#create_23" class="md-nav__link">
    create
  </a>
  
</li>
        
          <li class="md-nav__item">
  <a href="#fit_23" class="md-nav__link">
    fit
  </a>
  
</li>
        
          <li class="md-nav__item">
  <a href="#get_params_23" class="md-nav__link">
    get_params
  </a>
  
</li>
        
          <li class="md-nav__item">
  <a href="#predict_23" class="md-nav__link">
    predict
  </a>
  
</li>
        
          <li class="md-nav__item">
  <a href="#score_23" class="md-nav__link">
    score
  </a>
  
</li>
        
          <li class="md-nav__item">
  <a href="#set_params_23" class="md-nav__link">
    set_params
  </a>
  
</li>
        
          <li class="md-nav__item">
  <a href="#cv_values_" class="md-nav__link">
    cv_values_
  </a>
  
</li>
        
          <li class="md-nav__item">
  <a href="#coef__22" class="md-nav__link">
    coef_
  </a>
  
</li>
        
          <li class="md-nav__item">
  <a href="#intercept__22" class="md-nav__link">
    intercept_
  </a>
  
</li>
        
          <li class="md-nav__item">
  <a href="#alpha__9" class="md-nav__link">
    alpha_
  </a>
  
</li>
        
          <li class="md-nav__item">
  <a href="#to_string_23" class="md-nav__link">
    to_string
  </a>
  
</li>
        
          <li class="md-nav__item">
  <a href="#show_23" class="md-nav__link">
    show
  </a>
  
</li>
        
          <li class="md-nav__item">
  <a href="#pp_23" class="md-nav__link">
    pp
  </a>
  
</li>
        
      </ul>
    </nav>
  
</li>
      
        <li class="md-nav__item">
  <a href="#module-sklearnlinear_modelridgeclassifier" class="md-nav__link">
    module Sklearn.​Linear_model.​RidgeClassifier
  </a>
  
    <nav class="md-nav" aria-label="module Sklearn.​Linear_model.​RidgeClassifier">
      <ul class="md-nav__list">
        
          <li class="md-nav__item">
  <a href="#create_24" class="md-nav__link">
    create
  </a>
  
</li>
        
          <li class="md-nav__item">
  <a href="#decision_function_2" class="md-nav__link">
    decision_function
  </a>
  
</li>
        
          <li class="md-nav__item">
  <a href="#fit_24" class="md-nav__link">
    fit
  </a>
  
</li>
        
          <li class="md-nav__item">
  <a href="#get_params_24" class="md-nav__link">
    get_params
  </a>
  
</li>
        
          <li class="md-nav__item">
  <a href="#predict_24" class="md-nav__link">
    predict
  </a>
  
</li>
        
          <li class="md-nav__item">
  <a href="#score_24" class="md-nav__link">
    score
  </a>
  
</li>
        
          <li class="md-nav__item">
  <a href="#set_params_24" class="md-nav__link">
    set_params
  </a>
  
</li>
        
          <li class="md-nav__item">
  <a href="#coef__23" class="md-nav__link">
    coef_
  </a>
  
</li>
        
          <li class="md-nav__item">
  <a href="#intercept__23" class="md-nav__link">
    intercept_
  </a>
  
</li>
        
          <li class="md-nav__item">
  <a href="#n_iter__20" class="md-nav__link">
    n_iter_
  </a>
  
</li>
        
          <li class="md-nav__item">
  <a href="#classes__2" class="md-nav__link">
    classes_
  </a>
  
</li>
        
          <li class="md-nav__item">
  <a href="#to_string_24" class="md-nav__link">
    to_string
  </a>
  
</li>
        
          <li class="md-nav__item">
  <a href="#show_24" class="md-nav__link">
    show
  </a>
  
</li>
        
          <li class="md-nav__item">
  <a href="#pp_24" class="md-nav__link">
    pp
  </a>
  
</li>
        
      </ul>
    </nav>
  
</li>
      
        <li class="md-nav__item">
  <a href="#module-sklearnlinear_modelridgeclassifiercv" class="md-nav__link">
    module Sklearn.​Linear_model.​RidgeClassifierCV
  </a>
  
    <nav class="md-nav" aria-label="module Sklearn.​Linear_model.​RidgeClassifierCV">
      <ul class="md-nav__list">
        
          <li class="md-nav__item">
  <a href="#create_25" class="md-nav__link">
    create
  </a>
  
</li>
        
          <li class="md-nav__item">
  <a href="#decision_function_3" class="md-nav__link">
    decision_function
  </a>
  
</li>
        
          <li class="md-nav__item">
  <a href="#fit_25" class="md-nav__link">
    fit
  </a>
  
</li>
        
          <li class="md-nav__item">
  <a href="#get_params_25" class="md-nav__link">
    get_params
  </a>
  
</li>
        
          <li class="md-nav__item">
  <a href="#predict_25" class="md-nav__link">
    predict
  </a>
  
</li>
        
          <li class="md-nav__item">
  <a href="#score_25" class="md-nav__link">
    score
  </a>
  
</li>
        
          <li class="md-nav__item">
  <a href="#set_params_25" class="md-nav__link">
    set_params
  </a>
  
</li>
        
          <li class="md-nav__item">
  <a href="#cv_values__1" class="md-nav__link">
    cv_values_
  </a>
  
</li>
        
          <li class="md-nav__item">
  <a href="#coef__24" class="md-nav__link">
    coef_
  </a>
  
</li>
        
          <li class="md-nav__item">
  <a href="#intercept__24" class="md-nav__link">
    intercept_
  </a>
  
</li>
        
          <li class="md-nav__item">
  <a href="#alpha__10" class="md-nav__link">
    alpha_
  </a>
  
</li>
        
          <li class="md-nav__item">
  <a href="#classes__3" class="md-nav__link">
    classes_
  </a>
  
</li>
        
          <li class="md-nav__item">
  <a href="#to_string_25" class="md-nav__link">
    to_string
  </a>
  
</li>
        
          <li class="md-nav__item">
  <a href="#show_25" class="md-nav__link">
    show
  </a>
  
</li>
        
          <li class="md-nav__item">
  <a href="#pp_25" class="md-nav__link">
    pp
  </a>
  
</li>
        
      </ul>
    </nav>
  
</li>
      
        <li class="md-nav__item">
  <a href="#module-sklearnlinear_modeltheilsenregressor" class="md-nav__link">
    module Sklearn.​Linear_model.​TheilSenRegressor
  </a>
  
    <nav class="md-nav" aria-label="module Sklearn.​Linear_model.​TheilSenRegressor">
      <ul class="md-nav__list">
        
          <li class="md-nav__item">
  <a href="#create_26" class="md-nav__link">
    create
  </a>
  
</li>
        
          <li class="md-nav__item">
  <a href="#fit_26" class="md-nav__link">
    fit
  </a>
  
</li>
        
          <li class="md-nav__item">
  <a href="#get_params_26" class="md-nav__link">
    get_params
  </a>
  
</li>
        
          <li class="md-nav__item">
  <a href="#predict_26" class="md-nav__link">
    predict
  </a>
  
</li>
        
          <li class="md-nav__item">
  <a href="#score_26" class="md-nav__link">
    score
  </a>
  
</li>
        
          <li class="md-nav__item">
  <a href="#set_params_26" class="md-nav__link">
    set_params
  </a>
  
</li>
        
          <li class="md-nav__item">
  <a href="#coef__25" class="md-nav__link">
    coef_
  </a>
  
</li>
        
          <li class="md-nav__item">
  <a href="#intercept__25" class="md-nav__link">
    intercept_
  </a>
  
</li>
        
          <li class="md-nav__item">
  <a href="#breakdown_" class="md-nav__link">
    breakdown_
  </a>
  
</li>
        
          <li class="md-nav__item">
  <a href="#n_iter__21" class="md-nav__link">
    n_iter_
  </a>
  
</li>
        
          <li class="md-nav__item">
  <a href="#n_subpopulation_" class="md-nav__link">
    n_subpopulation_
  </a>
  
</li>
        
          <li class="md-nav__item">
  <a href="#to_string_26" class="md-nav__link">
    to_string
  </a>
  
</li>
        
          <li class="md-nav__item">
  <a href="#show_26" class="md-nav__link">
    show
  </a>
  
</li>
        
          <li class="md-nav__item">
  <a href="#pp_26" class="md-nav__link">
    pp
  </a>
  
</li>
        
          <li class="md-nav__item">
  <a href="#enet_path" class="md-nav__link">
    enet_path
  </a>
  
</li>
        
          <li class="md-nav__item">
  <a href="#lars_path" class="md-nav__link">
    lars_path
  </a>
  
</li>
        
          <li class="md-nav__item">
  <a href="#lars_path_gram" class="md-nav__link">
    lars_path_gram
  </a>
  
</li>
        
          <li class="md-nav__item">
  <a href="#lasso_path" class="md-nav__link">
    lasso_path
  </a>
  
</li>
        
          <li class="md-nav__item">
  <a href="#logistic_regression_path" class="md-nav__link">
    logistic_regression_path
  </a>
  
</li>
        
      </ul>
    </nav>
  
</li>
      
        <li class="md-nav__item">
  <a href="#returns" class="md-nav__link">
    Returns
  </a>
  
</li>
      
        <li class="md-nav__item">
  <a href="#notes" class="md-nav__link">
    Notes
  </a>
  
    <nav class="md-nav" aria-label="Notes">
      <ul class="md-nav__list">
        
          <li class="md-nav__item">
  <a href="#orthogonal_mp" class="md-nav__link">
    orthogonal_mp
  </a>
  
</li>
        
          <li class="md-nav__item">
  <a href="#orthogonal_mp_gram" class="md-nav__link">
    orthogonal_mp_gram
  </a>
  
</li>
        
          <li class="md-nav__item">
  <a href="#ridge_regression" class="md-nav__link">
    ridge_regression
  </a>
  
</li>
        
      </ul>
    </nav>
  
</li>
      
    </ul>
  
</nav>
    
  </li>

    
      
      
      


  <li class="md-nav__item">
    <a href="../manifold/" title="Manifold" class="md-nav__link">
      Manifold
    </a>
  </li>

    
      
      
      


  <li class="md-nav__item">
    <a href="../metrics/" title="Metrics" class="md-nav__link">
      Metrics
    </a>
  </li>

    
      
      
      


  <li class="md-nav__item">
    <a href="../mixture/" title="Mixture" class="md-nav__link">
      Mixture
    </a>
  </li>

    
      
      
      


  <li class="md-nav__item">
    <a href="../model_selection/" title="Model selection" class="md-nav__link">
      Model selection
    </a>
  </li>

    
      
      
      


  <li class="md-nav__item">
    <a href="../multiclass/" title="Multiclass" class="md-nav__link">
      Multiclass
    </a>
  </li>

    
      
      
      


  <li class="md-nav__item">
    <a href="../multioutput/" title="Multioutput" class="md-nav__link">
      Multioutput
    </a>
  </li>

    
      
      
      


  <li class="md-nav__item">
    <a href="../naive_bayes/" title="Naive bayes" class="md-nav__link">
      Naive bayes
    </a>
  </li>

    
      
      
      


  <li class="md-nav__item">
    <a href="../neighbors/" title="Neighbors" class="md-nav__link">
      Neighbors
    </a>
  </li>

    
      
      
      


  <li class="md-nav__item">
    <a href="../neural_network/" title="Neural network" class="md-nav__link">
      Neural network
    </a>
  </li>

    
      
      
      


  <li class="md-nav__item">
    <a href="../pipeline/" title="Pipeline" class="md-nav__link">
      Pipeline
    </a>
  </li>

    
      
      
      


  <li class="md-nav__item">
    <a href="../preprocessing/" title="Preprocessing" class="md-nav__link">
      Preprocessing
    </a>
  </li>

    
      
      
      


  <li class="md-nav__item">
    <a href="../random_projection/" title="Random projection" class="md-nav__link">
      Random projection
    </a>
  </li>

    
      
      
      


  <li class="md-nav__item">
    <a href="../semi_supervised/" title="Semi supervised" class="md-nav__link">
      Semi supervised
    </a>
  </li>

    
      
      
      


  <li class="md-nav__item">
    <a href="../setup/" title="Setup" class="md-nav__link">
      Setup
    </a>
  </li>

    
      
      
      


  <li class="md-nav__item">
    <a href="../svm/" title="Svm" class="md-nav__link">
      Svm
    </a>
  </li>

    
      
      
      


  <li class="md-nav__item">
    <a href="../tests/" title="Tests" class="md-nav__link">
      Tests
    </a>
  </li>

    
      
      
      


  <li class="md-nav__item">
    <a href="../tree/" title="Tree" class="md-nav__link">
      Tree
    </a>
  </li>

    
      
      
      


  <li class="md-nav__item">
    <a href="../utils/" title="Utils" class="md-nav__link">
      Utils
    </a>
  </li>

    
  </ul>
</nav>
                  </div>
                </div>
              </div>
            
            
              <div class="md-sidebar md-sidebar--secondary" data-md-component="toc">
                <div class="md-sidebar__scrollwrap">
                  <div class="md-sidebar__inner">
                    
<nav class="md-nav md-nav--secondary" aria-label="Table of contents">
  
  
  
    <label class="md-nav__title" for="__toc">
      <span class="md-nav__icon md-icon">
        <svg xmlns="http://www.w3.org/2000/svg" viewBox="0 0 24 24"><path d="M20,11V13H8L13.5,18.5L12.08,19.92L4.16,12L12.08,4.08L13.5,5.5L8,11H20Z" /></svg>
      </span>
      Table of contents
    </label>
    <ul class="md-nav__list" data-md-scrollfix>
      
        <li class="md-nav__item">
  <a href="#module-sklearnlinear_modelardregression" class="md-nav__link">
    module Sklearn.​Linear_model.​ARDRegression
  </a>
  
    <nav class="md-nav" aria-label="module Sklearn.​Linear_model.​ARDRegression">
      <ul class="md-nav__list">
        
          <li class="md-nav__item">
  <a href="#create" class="md-nav__link">
    create
  </a>
  
</li>
        
          <li class="md-nav__item">
  <a href="#fit" class="md-nav__link">
    fit
  </a>
  
</li>
        
          <li class="md-nav__item">
  <a href="#get_params" class="md-nav__link">
    get_params
  </a>
  
</li>
        
          <li class="md-nav__item">
  <a href="#predict" class="md-nav__link">
    predict
  </a>
  
</li>
        
          <li class="md-nav__item">
  <a href="#score" class="md-nav__link">
    score
  </a>
  
</li>
        
          <li class="md-nav__item">
  <a href="#set_params" class="md-nav__link">
    set_params
  </a>
  
</li>
        
          <li class="md-nav__item">
  <a href="#coef_" class="md-nav__link">
    coef_
  </a>
  
</li>
        
          <li class="md-nav__item">
  <a href="#alpha_" class="md-nav__link">
    alpha_
  </a>
  
</li>
        
          <li class="md-nav__item">
  <a href="#lambda_" class="md-nav__link">
    lambda_
  </a>
  
</li>
        
          <li class="md-nav__item">
  <a href="#sigma_" class="md-nav__link">
    sigma_
  </a>
  
</li>
        
          <li class="md-nav__item">
  <a href="#scores_" class="md-nav__link">
    scores_
  </a>
  
</li>
        
          <li class="md-nav__item">
  <a href="#intercept_" class="md-nav__link">
    intercept_
  </a>
  
</li>
        
          <li class="md-nav__item">
  <a href="#to_string" class="md-nav__link">
    to_string
  </a>
  
</li>
        
          <li class="md-nav__item">
  <a href="#show" class="md-nav__link">
    show
  </a>
  
</li>
        
          <li class="md-nav__item">
  <a href="#pp" class="md-nav__link">
    pp
  </a>
  
</li>
        
      </ul>
    </nav>
  
</li>
      
        <li class="md-nav__item">
  <a href="#module-sklearnlinear_modelbayesianridge" class="md-nav__link">
    module Sklearn.​Linear_model.​BayesianRidge
  </a>
  
    <nav class="md-nav" aria-label="module Sklearn.​Linear_model.​BayesianRidge">
      <ul class="md-nav__list">
        
          <li class="md-nav__item">
  <a href="#create_1" class="md-nav__link">
    create
  </a>
  
</li>
        
          <li class="md-nav__item">
  <a href="#fit_1" class="md-nav__link">
    fit
  </a>
  
</li>
        
          <li class="md-nav__item">
  <a href="#get_params_1" class="md-nav__link">
    get_params
  </a>
  
</li>
        
          <li class="md-nav__item">
  <a href="#predict_1" class="md-nav__link">
    predict
  </a>
  
</li>
        
          <li class="md-nav__item">
  <a href="#score_1" class="md-nav__link">
    score
  </a>
  
</li>
        
          <li class="md-nav__item">
  <a href="#set_params_1" class="md-nav__link">
    set_params
  </a>
  
</li>
        
          <li class="md-nav__item">
  <a href="#coef__1" class="md-nav__link">
    coef_
  </a>
  
</li>
        
          <li class="md-nav__item">
  <a href="#intercept__1" class="md-nav__link">
    intercept_
  </a>
  
</li>
        
          <li class="md-nav__item">
  <a href="#alpha__1" class="md-nav__link">
    alpha_
  </a>
  
</li>
        
          <li class="md-nav__item">
  <a href="#lambda__1" class="md-nav__link">
    lambda_
  </a>
  
</li>
        
          <li class="md-nav__item">
  <a href="#sigma__1" class="md-nav__link">
    sigma_
  </a>
  
</li>
        
          <li class="md-nav__item">
  <a href="#scores__1" class="md-nav__link">
    scores_
  </a>
  
</li>
        
          <li class="md-nav__item">
  <a href="#n_iter_" class="md-nav__link">
    n_iter_
  </a>
  
</li>
        
          <li class="md-nav__item">
  <a href="#to_string_1" class="md-nav__link">
    to_string
  </a>
  
</li>
        
          <li class="md-nav__item">
  <a href="#show_1" class="md-nav__link">
    show
  </a>
  
</li>
        
          <li class="md-nav__item">
  <a href="#pp_1" class="md-nav__link">
    pp
  </a>
  
</li>
        
      </ul>
    </nav>
  
</li>
      
        <li class="md-nav__item">
  <a href="#module-sklearnlinear_modelelasticnet" class="md-nav__link">
    module Sklearn.​Linear_model.​ElasticNet
  </a>
  
    <nav class="md-nav" aria-label="module Sklearn.​Linear_model.​ElasticNet">
      <ul class="md-nav__list">
        
          <li class="md-nav__item">
  <a href="#create_2" class="md-nav__link">
    create
  </a>
  
</li>
        
          <li class="md-nav__item">
  <a href="#fit_2" class="md-nav__link">
    fit
  </a>
  
</li>
        
          <li class="md-nav__item">
  <a href="#get_params_2" class="md-nav__link">
    get_params
  </a>
  
</li>
        
          <li class="md-nav__item">
  <a href="#predict_2" class="md-nav__link">
    predict
  </a>
  
</li>
        
          <li class="md-nav__item">
  <a href="#score_2" class="md-nav__link">
    score
  </a>
  
</li>
        
          <li class="md-nav__item">
  <a href="#set_params_2" class="md-nav__link">
    set_params
  </a>
  
</li>
        
          <li class="md-nav__item">
  <a href="#coef__2" class="md-nav__link">
    coef_
  </a>
  
</li>
        
          <li class="md-nav__item">
  <a href="#sparse_coef_" class="md-nav__link">
    sparse_coef_
  </a>
  
</li>
        
          <li class="md-nav__item">
  <a href="#intercept__2" class="md-nav__link">
    intercept_
  </a>
  
</li>
        
          <li class="md-nav__item">
  <a href="#n_iter__1" class="md-nav__link">
    n_iter_
  </a>
  
</li>
        
          <li class="md-nav__item">
  <a href="#to_string_2" class="md-nav__link">
    to_string
  </a>
  
</li>
        
          <li class="md-nav__item">
  <a href="#show_2" class="md-nav__link">
    show
  </a>
  
</li>
        
          <li class="md-nav__item">
  <a href="#pp_2" class="md-nav__link">
    pp
  </a>
  
</li>
        
      </ul>
    </nav>
  
</li>
      
        <li class="md-nav__item">
  <a href="#module-sklearnlinear_modelelasticnetcv" class="md-nav__link">
    module Sklearn.​Linear_model.​ElasticNetCV
  </a>
  
    <nav class="md-nav" aria-label="module Sklearn.​Linear_model.​ElasticNetCV">
      <ul class="md-nav__list">
        
          <li class="md-nav__item">
  <a href="#create_3" class="md-nav__link">
    create
  </a>
  
</li>
        
          <li class="md-nav__item">
  <a href="#fit_3" class="md-nav__link">
    fit
  </a>
  
</li>
        
          <li class="md-nav__item">
  <a href="#get_params_3" class="md-nav__link">
    get_params
  </a>
  
</li>
        
          <li class="md-nav__item">
  <a href="#predict_3" class="md-nav__link">
    predict
  </a>
  
</li>
        
          <li class="md-nav__item">
  <a href="#score_3" class="md-nav__link">
    score
  </a>
  
</li>
        
          <li class="md-nav__item">
  <a href="#set_params_3" class="md-nav__link">
    set_params
  </a>
  
</li>
        
          <li class="md-nav__item">
  <a href="#alpha__2" class="md-nav__link">
    alpha_
  </a>
  
</li>
        
          <li class="md-nav__item">
  <a href="#l1_ratio_" class="md-nav__link">
    l1_ratio_
  </a>
  
</li>
        
          <li class="md-nav__item">
  <a href="#coef__3" class="md-nav__link">
    coef_
  </a>
  
</li>
        
          <li class="md-nav__item">
  <a href="#intercept__3" class="md-nav__link">
    intercept_
  </a>
  
</li>
        
          <li class="md-nav__item">
  <a href="#mse_path_" class="md-nav__link">
    mse_path_
  </a>
  
</li>
        
          <li class="md-nav__item">
  <a href="#alphas_" class="md-nav__link">
    alphas_
  </a>
  
</li>
        
          <li class="md-nav__item">
  <a href="#n_iter__2" class="md-nav__link">
    n_iter_
  </a>
  
</li>
        
          <li class="md-nav__item">
  <a href="#to_string_3" class="md-nav__link">
    to_string
  </a>
  
</li>
        
          <li class="md-nav__item">
  <a href="#show_3" class="md-nav__link">
    show
  </a>
  
</li>
        
          <li class="md-nav__item">
  <a href="#pp_3" class="md-nav__link">
    pp
  </a>
  
</li>
        
      </ul>
    </nav>
  
</li>
      
        <li class="md-nav__item">
  <a href="#module-sklearnlinear_modelhuberregressor" class="md-nav__link">
    module Sklearn.​Linear_model.​HuberRegressor
  </a>
  
    <nav class="md-nav" aria-label="module Sklearn.​Linear_model.​HuberRegressor">
      <ul class="md-nav__list">
        
          <li class="md-nav__item">
  <a href="#create_4" class="md-nav__link">
    create
  </a>
  
</li>
        
          <li class="md-nav__item">
  <a href="#fit_4" class="md-nav__link">
    fit
  </a>
  
</li>
        
          <li class="md-nav__item">
  <a href="#get_params_4" class="md-nav__link">
    get_params
  </a>
  
</li>
        
          <li class="md-nav__item">
  <a href="#predict_4" class="md-nav__link">
    predict
  </a>
  
</li>
        
          <li class="md-nav__item">
  <a href="#score_4" class="md-nav__link">
    score
  </a>
  
</li>
        
          <li class="md-nav__item">
  <a href="#set_params_4" class="md-nav__link">
    set_params
  </a>
  
</li>
        
          <li class="md-nav__item">
  <a href="#coef__4" class="md-nav__link">
    coef_
  </a>
  
</li>
        
          <li class="md-nav__item">
  <a href="#intercept__4" class="md-nav__link">
    intercept_
  </a>
  
</li>
        
          <li class="md-nav__item">
  <a href="#scale_" class="md-nav__link">
    scale_
  </a>
  
</li>
        
          <li class="md-nav__item">
  <a href="#n_iter__3" class="md-nav__link">
    n_iter_
  </a>
  
</li>
        
          <li class="md-nav__item">
  <a href="#outliers_" class="md-nav__link">
    outliers_
  </a>
  
</li>
        
          <li class="md-nav__item">
  <a href="#to_string_4" class="md-nav__link">
    to_string
  </a>
  
</li>
        
          <li class="md-nav__item">
  <a href="#show_4" class="md-nav__link">
    show
  </a>
  
</li>
        
          <li class="md-nav__item">
  <a href="#pp_4" class="md-nav__link">
    pp
  </a>
  
</li>
        
      </ul>
    </nav>
  
</li>
      
        <li class="md-nav__item">
  <a href="#module-sklearnlinear_modellars" class="md-nav__link">
    module Sklearn.​Linear_model.​Lars
  </a>
  
    <nav class="md-nav" aria-label="module Sklearn.​Linear_model.​Lars">
      <ul class="md-nav__list">
        
          <li class="md-nav__item">
  <a href="#create_5" class="md-nav__link">
    create
  </a>
  
</li>
        
          <li class="md-nav__item">
  <a href="#fit_5" class="md-nav__link">
    fit
  </a>
  
</li>
        
          <li class="md-nav__item">
  <a href="#get_params_5" class="md-nav__link">
    get_params
  </a>
  
</li>
        
          <li class="md-nav__item">
  <a href="#predict_5" class="md-nav__link">
    predict
  </a>
  
</li>
        
          <li class="md-nav__item">
  <a href="#score_5" class="md-nav__link">
    score
  </a>
  
</li>
        
          <li class="md-nav__item">
  <a href="#set_params_5" class="md-nav__link">
    set_params
  </a>
  
</li>
        
          <li class="md-nav__item">
  <a href="#alphas__1" class="md-nav__link">
    alphas_
  </a>
  
</li>
        
          <li class="md-nav__item">
  <a href="#active_" class="md-nav__link">
    active_
  </a>
  
</li>
        
          <li class="md-nav__item">
  <a href="#coef_path_" class="md-nav__link">
    coef_path_
  </a>
  
</li>
        
          <li class="md-nav__item">
  <a href="#coef__5" class="md-nav__link">
    coef_
  </a>
  
</li>
        
          <li class="md-nav__item">
  <a href="#intercept__5" class="md-nav__link">
    intercept_
  </a>
  
</li>
        
          <li class="md-nav__item">
  <a href="#n_iter__4" class="md-nav__link">
    n_iter_
  </a>
  
</li>
        
          <li class="md-nav__item">
  <a href="#to_string_5" class="md-nav__link">
    to_string
  </a>
  
</li>
        
          <li class="md-nav__item">
  <a href="#show_5" class="md-nav__link">
    show
  </a>
  
</li>
        
          <li class="md-nav__item">
  <a href="#pp_5" class="md-nav__link">
    pp
  </a>
  
</li>
        
      </ul>
    </nav>
  
</li>
      
        <li class="md-nav__item">
  <a href="#module-sklearnlinear_modellarscv" class="md-nav__link">
    module Sklearn.​Linear_model.​LarsCV
  </a>
  
    <nav class="md-nav" aria-label="module Sklearn.​Linear_model.​LarsCV">
      <ul class="md-nav__list">
        
          <li class="md-nav__item">
  <a href="#create_6" class="md-nav__link">
    create
  </a>
  
</li>
        
          <li class="md-nav__item">
  <a href="#fit_6" class="md-nav__link">
    fit
  </a>
  
</li>
        
          <li class="md-nav__item">
  <a href="#get_params_6" class="md-nav__link">
    get_params
  </a>
  
</li>
        
          <li class="md-nav__item">
  <a href="#predict_6" class="md-nav__link">
    predict
  </a>
  
</li>
        
          <li class="md-nav__item">
  <a href="#score_6" class="md-nav__link">
    score
  </a>
  
</li>
        
          <li class="md-nav__item">
  <a href="#set_params_6" class="md-nav__link">
    set_params
  </a>
  
</li>
        
          <li class="md-nav__item">
  <a href="#coef__6" class="md-nav__link">
    coef_
  </a>
  
</li>
        
          <li class="md-nav__item">
  <a href="#intercept__6" class="md-nav__link">
    intercept_
  </a>
  
</li>
        
          <li class="md-nav__item">
  <a href="#coef_path__1" class="md-nav__link">
    coef_path_
  </a>
  
</li>
        
          <li class="md-nav__item">
  <a href="#alpha__3" class="md-nav__link">
    alpha_
  </a>
  
</li>
        
          <li class="md-nav__item">
  <a href="#alphas__2" class="md-nav__link">
    alphas_
  </a>
  
</li>
        
          <li class="md-nav__item">
  <a href="#cv_alphas_" class="md-nav__link">
    cv_alphas_
  </a>
  
</li>
        
          <li class="md-nav__item">
  <a href="#mse_path__1" class="md-nav__link">
    mse_path_
  </a>
  
</li>
        
          <li class="md-nav__item">
  <a href="#n_iter__5" class="md-nav__link">
    n_iter_
  </a>
  
</li>
        
          <li class="md-nav__item">
  <a href="#to_string_6" class="md-nav__link">
    to_string
  </a>
  
</li>
        
          <li class="md-nav__item">
  <a href="#show_6" class="md-nav__link">
    show
  </a>
  
</li>
        
          <li class="md-nav__item">
  <a href="#pp_6" class="md-nav__link">
    pp
  </a>
  
</li>
        
      </ul>
    </nav>
  
</li>
      
        <li class="md-nav__item">
  <a href="#module-sklearnlinear_modellasso" class="md-nav__link">
    module Sklearn.​Linear_model.​Lasso
  </a>
  
    <nav class="md-nav" aria-label="module Sklearn.​Linear_model.​Lasso">
      <ul class="md-nav__list">
        
          <li class="md-nav__item">
  <a href="#create_7" class="md-nav__link">
    create
  </a>
  
</li>
        
          <li class="md-nav__item">
  <a href="#fit_7" class="md-nav__link">
    fit
  </a>
  
</li>
        
          <li class="md-nav__item">
  <a href="#get_params_7" class="md-nav__link">
    get_params
  </a>
  
</li>
        
          <li class="md-nav__item">
  <a href="#predict_7" class="md-nav__link">
    predict
  </a>
  
</li>
        
          <li class="md-nav__item">
  <a href="#score_7" class="md-nav__link">
    score
  </a>
  
</li>
        
          <li class="md-nav__item">
  <a href="#set_params_7" class="md-nav__link">
    set_params
  </a>
  
</li>
        
          <li class="md-nav__item">
  <a href="#coef__7" class="md-nav__link">
    coef_
  </a>
  
</li>
        
          <li class="md-nav__item">
  <a href="#sparse_coef__1" class="md-nav__link">
    sparse_coef_
  </a>
  
</li>
        
          <li class="md-nav__item">
  <a href="#intercept__7" class="md-nav__link">
    intercept_
  </a>
  
</li>
        
          <li class="md-nav__item">
  <a href="#n_iter__6" class="md-nav__link">
    n_iter_
  </a>
  
</li>
        
          <li class="md-nav__item">
  <a href="#to_string_7" class="md-nav__link">
    to_string
  </a>
  
</li>
        
          <li class="md-nav__item">
  <a href="#show_7" class="md-nav__link">
    show
  </a>
  
</li>
        
          <li class="md-nav__item">
  <a href="#pp_7" class="md-nav__link">
    pp
  </a>
  
</li>
        
      </ul>
    </nav>
  
</li>
      
        <li class="md-nav__item">
  <a href="#module-sklearnlinear_modellassocv" class="md-nav__link">
    module Sklearn.​Linear_model.​LassoCV
  </a>
  
    <nav class="md-nav" aria-label="module Sklearn.​Linear_model.​LassoCV">
      <ul class="md-nav__list">
        
          <li class="md-nav__item">
  <a href="#create_8" class="md-nav__link">
    create
  </a>
  
</li>
        
          <li class="md-nav__item">
  <a href="#fit_8" class="md-nav__link">
    fit
  </a>
  
</li>
        
          <li class="md-nav__item">
  <a href="#get_params_8" class="md-nav__link">
    get_params
  </a>
  
</li>
        
          <li class="md-nav__item">
  <a href="#predict_8" class="md-nav__link">
    predict
  </a>
  
</li>
        
          <li class="md-nav__item">
  <a href="#score_8" class="md-nav__link">
    score
  </a>
  
</li>
        
          <li class="md-nav__item">
  <a href="#set_params_8" class="md-nav__link">
    set_params
  </a>
  
</li>
        
          <li class="md-nav__item">
  <a href="#alpha__4" class="md-nav__link">
    alpha_
  </a>
  
</li>
        
          <li class="md-nav__item">
  <a href="#coef__8" class="md-nav__link">
    coef_
  </a>
  
</li>
        
          <li class="md-nav__item">
  <a href="#intercept__8" class="md-nav__link">
    intercept_
  </a>
  
</li>
        
          <li class="md-nav__item">
  <a href="#mse_path__2" class="md-nav__link">
    mse_path_
  </a>
  
</li>
        
          <li class="md-nav__item">
  <a href="#alphas__3" class="md-nav__link">
    alphas_
  </a>
  
</li>
        
          <li class="md-nav__item">
  <a href="#dual_gap_" class="md-nav__link">
    dual_gap_
  </a>
  
</li>
        
          <li class="md-nav__item">
  <a href="#n_iter__7" class="md-nav__link">
    n_iter_
  </a>
  
</li>
        
          <li class="md-nav__item">
  <a href="#to_string_8" class="md-nav__link">
    to_string
  </a>
  
</li>
        
          <li class="md-nav__item">
  <a href="#show_8" class="md-nav__link">
    show
  </a>
  
</li>
        
          <li class="md-nav__item">
  <a href="#pp_8" class="md-nav__link">
    pp
  </a>
  
</li>
        
      </ul>
    </nav>
  
</li>
      
        <li class="md-nav__item">
  <a href="#module-sklearnlinear_modellassolars" class="md-nav__link">
    module Sklearn.​Linear_model.​LassoLars
  </a>
  
    <nav class="md-nav" aria-label="module Sklearn.​Linear_model.​LassoLars">
      <ul class="md-nav__list">
        
          <li class="md-nav__item">
  <a href="#create_9" class="md-nav__link">
    create
  </a>
  
</li>
        
          <li class="md-nav__item">
  <a href="#fit_9" class="md-nav__link">
    fit
  </a>
  
</li>
        
          <li class="md-nav__item">
  <a href="#get_params_9" class="md-nav__link">
    get_params
  </a>
  
</li>
        
          <li class="md-nav__item">
  <a href="#predict_9" class="md-nav__link">
    predict
  </a>
  
</li>
        
          <li class="md-nav__item">
  <a href="#score_9" class="md-nav__link">
    score
  </a>
  
</li>
        
          <li class="md-nav__item">
  <a href="#set_params_9" class="md-nav__link">
    set_params
  </a>
  
</li>
        
          <li class="md-nav__item">
  <a href="#alphas__4" class="md-nav__link">
    alphas_
  </a>
  
</li>
        
          <li class="md-nav__item">
  <a href="#active__1" class="md-nav__link">
    active_
  </a>
  
</li>
        
          <li class="md-nav__item">
  <a href="#coef_path__2" class="md-nav__link">
    coef_path_
  </a>
  
</li>
        
          <li class="md-nav__item">
  <a href="#coef__9" class="md-nav__link">
    coef_
  </a>
  
</li>
        
          <li class="md-nav__item">
  <a href="#intercept__9" class="md-nav__link">
    intercept_
  </a>
  
</li>
        
          <li class="md-nav__item">
  <a href="#n_iter__8" class="md-nav__link">
    n_iter_
  </a>
  
</li>
        
          <li class="md-nav__item">
  <a href="#to_string_9" class="md-nav__link">
    to_string
  </a>
  
</li>
        
          <li class="md-nav__item">
  <a href="#show_9" class="md-nav__link">
    show
  </a>
  
</li>
        
          <li class="md-nav__item">
  <a href="#pp_9" class="md-nav__link">
    pp
  </a>
  
</li>
        
      </ul>
    </nav>
  
</li>
      
        <li class="md-nav__item">
  <a href="#module-sklearnlinear_modellassolarscv" class="md-nav__link">
    module Sklearn.​Linear_model.​LassoLarsCV
  </a>
  
    <nav class="md-nav" aria-label="module Sklearn.​Linear_model.​LassoLarsCV">
      <ul class="md-nav__list">
        
          <li class="md-nav__item">
  <a href="#create_10" class="md-nav__link">
    create
  </a>
  
</li>
        
          <li class="md-nav__item">
  <a href="#fit_10" class="md-nav__link">
    fit
  </a>
  
</li>
        
          <li class="md-nav__item">
  <a href="#get_params_10" class="md-nav__link">
    get_params
  </a>
  
</li>
        
          <li class="md-nav__item">
  <a href="#predict_10" class="md-nav__link">
    predict
  </a>
  
</li>
        
          <li class="md-nav__item">
  <a href="#score_10" class="md-nav__link">
    score
  </a>
  
</li>
        
          <li class="md-nav__item">
  <a href="#set_params_10" class="md-nav__link">
    set_params
  </a>
  
</li>
        
          <li class="md-nav__item">
  <a href="#coef__10" class="md-nav__link">
    coef_
  </a>
  
</li>
        
          <li class="md-nav__item">
  <a href="#intercept__10" class="md-nav__link">
    intercept_
  </a>
  
</li>
        
          <li class="md-nav__item">
  <a href="#coef_path__3" class="md-nav__link">
    coef_path_
  </a>
  
</li>
        
          <li class="md-nav__item">
  <a href="#alpha__5" class="md-nav__link">
    alpha_
  </a>
  
</li>
        
          <li class="md-nav__item">
  <a href="#alphas__5" class="md-nav__link">
    alphas_
  </a>
  
</li>
        
          <li class="md-nav__item">
  <a href="#cv_alphas__1" class="md-nav__link">
    cv_alphas_
  </a>
  
</li>
        
          <li class="md-nav__item">
  <a href="#mse_path__3" class="md-nav__link">
    mse_path_
  </a>
  
</li>
        
          <li class="md-nav__item">
  <a href="#n_iter__9" class="md-nav__link">
    n_iter_
  </a>
  
</li>
        
          <li class="md-nav__item">
  <a href="#to_string_10" class="md-nav__link">
    to_string
  </a>
  
</li>
        
          <li class="md-nav__item">
  <a href="#show_10" class="md-nav__link">
    show
  </a>
  
</li>
        
          <li class="md-nav__item">
  <a href="#pp_10" class="md-nav__link">
    pp
  </a>
  
</li>
        
      </ul>
    </nav>
  
</li>
      
        <li class="md-nav__item">
  <a href="#module-sklearnlinear_modellassolarsic" class="md-nav__link">
    module Sklearn.​Linear_model.​LassoLarsIC
  </a>
  
    <nav class="md-nav" aria-label="module Sklearn.​Linear_model.​LassoLarsIC">
      <ul class="md-nav__list">
        
          <li class="md-nav__item">
  <a href="#create_11" class="md-nav__link">
    create
  </a>
  
</li>
        
          <li class="md-nav__item">
  <a href="#fit_11" class="md-nav__link">
    fit
  </a>
  
</li>
        
          <li class="md-nav__item">
  <a href="#get_params_11" class="md-nav__link">
    get_params
  </a>
  
</li>
        
          <li class="md-nav__item">
  <a href="#predict_11" class="md-nav__link">
    predict
  </a>
  
</li>
        
          <li class="md-nav__item">
  <a href="#score_11" class="md-nav__link">
    score
  </a>
  
</li>
        
          <li class="md-nav__item">
  <a href="#set_params_11" class="md-nav__link">
    set_params
  </a>
  
</li>
        
          <li class="md-nav__item">
  <a href="#coef__11" class="md-nav__link">
    coef_
  </a>
  
</li>
        
          <li class="md-nav__item">
  <a href="#intercept__11" class="md-nav__link">
    intercept_
  </a>
  
</li>
        
          <li class="md-nav__item">
  <a href="#alpha__6" class="md-nav__link">
    alpha_
  </a>
  
</li>
        
          <li class="md-nav__item">
  <a href="#n_iter__10" class="md-nav__link">
    n_iter_
  </a>
  
</li>
        
          <li class="md-nav__item">
  <a href="#criterion_" class="md-nav__link">
    criterion_
  </a>
  
</li>
        
          <li class="md-nav__item">
  <a href="#to_string_11" class="md-nav__link">
    to_string
  </a>
  
</li>
        
          <li class="md-nav__item">
  <a href="#show_11" class="md-nav__link">
    show
  </a>
  
</li>
        
          <li class="md-nav__item">
  <a href="#pp_11" class="md-nav__link">
    pp
  </a>
  
</li>
        
      </ul>
    </nav>
  
</li>
      
        <li class="md-nav__item">
  <a href="#module-sklearnlinear_modellinearregression" class="md-nav__link">
    module Sklearn.​Linear_model.​LinearRegression
  </a>
  
    <nav class="md-nav" aria-label="module Sklearn.​Linear_model.​LinearRegression">
      <ul class="md-nav__list">
        
          <li class="md-nav__item">
  <a href="#create_12" class="md-nav__link">
    create
  </a>
  
</li>
        
          <li class="md-nav__item">
  <a href="#fit_12" class="md-nav__link">
    fit
  </a>
  
</li>
        
          <li class="md-nav__item">
  <a href="#get_params_12" class="md-nav__link">
    get_params
  </a>
  
</li>
        
          <li class="md-nav__item">
  <a href="#predict_12" class="md-nav__link">
    predict
  </a>
  
</li>
        
          <li class="md-nav__item">
  <a href="#score_12" class="md-nav__link">
    score
  </a>
  
</li>
        
          <li class="md-nav__item">
  <a href="#set_params_12" class="md-nav__link">
    set_params
  </a>
  
</li>
        
          <li class="md-nav__item">
  <a href="#coef__12" class="md-nav__link">
    coef_
  </a>
  
</li>
        
          <li class="md-nav__item">
  <a href="#rank_" class="md-nav__link">
    rank_
  </a>
  
</li>
        
          <li class="md-nav__item">
  <a href="#singular_" class="md-nav__link">
    singular_
  </a>
  
</li>
        
          <li class="md-nav__item">
  <a href="#intercept__12" class="md-nav__link">
    intercept_
  </a>
  
</li>
        
          <li class="md-nav__item">
  <a href="#to_string_12" class="md-nav__link">
    to_string
  </a>
  
</li>
        
          <li class="md-nav__item">
  <a href="#show_12" class="md-nav__link">
    show
  </a>
  
</li>
        
          <li class="md-nav__item">
  <a href="#pp_12" class="md-nav__link">
    pp
  </a>
  
</li>
        
      </ul>
    </nav>
  
</li>
      
        <li class="md-nav__item">
  <a href="#module-sklearnlinear_modellogisticregression" class="md-nav__link">
    module Sklearn.​Linear_model.​LogisticRegression
  </a>
  
    <nav class="md-nav" aria-label="module Sklearn.​Linear_model.​LogisticRegression">
      <ul class="md-nav__list">
        
          <li class="md-nav__item">
  <a href="#create_13" class="md-nav__link">
    create
  </a>
  
</li>
        
          <li class="md-nav__item">
  <a href="#decision_function" class="md-nav__link">
    decision_function
  </a>
  
</li>
        
          <li class="md-nav__item">
  <a href="#densify" class="md-nav__link">
    densify
  </a>
  
</li>
        
          <li class="md-nav__item">
  <a href="#fit_13" class="md-nav__link">
    fit
  </a>
  
</li>
        
          <li class="md-nav__item">
  <a href="#get_params_13" class="md-nav__link">
    get_params
  </a>
  
</li>
        
          <li class="md-nav__item">
  <a href="#predict_13" class="md-nav__link">
    predict
  </a>
  
</li>
        
          <li class="md-nav__item">
  <a href="#predict_log_proba" class="md-nav__link">
    predict_log_proba
  </a>
  
</li>
        
          <li class="md-nav__item">
  <a href="#predict_proba" class="md-nav__link">
    predict_proba
  </a>
  
</li>
        
          <li class="md-nav__item">
  <a href="#score_13" class="md-nav__link">
    score
  </a>
  
</li>
        
          <li class="md-nav__item">
  <a href="#set_params_13" class="md-nav__link">
    set_params
  </a>
  
</li>
        
          <li class="md-nav__item">
  <a href="#sparsify" class="md-nav__link">
    sparsify
  </a>
  
</li>
        
          <li class="md-nav__item">
  <a href="#classes_" class="md-nav__link">
    classes_
  </a>
  
</li>
        
          <li class="md-nav__item">
  <a href="#coef__13" class="md-nav__link">
    coef_
  </a>
  
</li>
        
          <li class="md-nav__item">
  <a href="#intercept__13" class="md-nav__link">
    intercept_
  </a>
  
</li>
        
          <li class="md-nav__item">
  <a href="#n_iter__11" class="md-nav__link">
    n_iter_
  </a>
  
</li>
        
          <li class="md-nav__item">
  <a href="#to_string_13" class="md-nav__link">
    to_string
  </a>
  
</li>
        
          <li class="md-nav__item">
  <a href="#show_13" class="md-nav__link">
    show
  </a>
  
</li>
        
          <li class="md-nav__item">
  <a href="#pp_13" class="md-nav__link">
    pp
  </a>
  
</li>
        
      </ul>
    </nav>
  
</li>
      
        <li class="md-nav__item">
  <a href="#module-sklearnlinear_modellogisticregressioncv" class="md-nav__link">
    module Sklearn.​Linear_model.​LogisticRegressionCV
  </a>
  
    <nav class="md-nav" aria-label="module Sklearn.​Linear_model.​LogisticRegressionCV">
      <ul class="md-nav__list">
        
          <li class="md-nav__item">
  <a href="#create_14" class="md-nav__link">
    create
  </a>
  
</li>
        
          <li class="md-nav__item">
  <a href="#decision_function_1" class="md-nav__link">
    decision_function
  </a>
  
</li>
        
          <li class="md-nav__item">
  <a href="#densify_1" class="md-nav__link">
    densify
  </a>
  
</li>
        
          <li class="md-nav__item">
  <a href="#fit_14" class="md-nav__link">
    fit
  </a>
  
</li>
        
          <li class="md-nav__item">
  <a href="#get_params_14" class="md-nav__link">
    get_params
  </a>
  
</li>
        
          <li class="md-nav__item">
  <a href="#predict_14" class="md-nav__link">
    predict
  </a>
  
</li>
        
          <li class="md-nav__item">
  <a href="#predict_log_proba_1" class="md-nav__link">
    predict_log_proba
  </a>
  
</li>
        
          <li class="md-nav__item">
  <a href="#predict_proba_1" class="md-nav__link">
    predict_proba
  </a>
  
</li>
        
          <li class="md-nav__item">
  <a href="#score_14" class="md-nav__link">
    score
  </a>
  
</li>
        
          <li class="md-nav__item">
  <a href="#set_params_14" class="md-nav__link">
    set_params
  </a>
  
</li>
        
          <li class="md-nav__item">
  <a href="#sparsify_1" class="md-nav__link">
    sparsify
  </a>
  
</li>
        
          <li class="md-nav__item">
  <a href="#classes__1" class="md-nav__link">
    classes_
  </a>
  
</li>
        
          <li class="md-nav__item">
  <a href="#coef__14" class="md-nav__link">
    coef_
  </a>
  
</li>
        
          <li class="md-nav__item">
  <a href="#intercept__14" class="md-nav__link">
    intercept_
  </a>
  
</li>
        
          <li class="md-nav__item">
  <a href="#cs_" class="md-nav__link">
    cs_
  </a>
  
</li>
        
          <li class="md-nav__item">
  <a href="#l1_ratios_" class="md-nav__link">
    l1_ratios_
  </a>
  
</li>
        
          <li class="md-nav__item">
  <a href="#coefs_paths_" class="md-nav__link">
    coefs_paths_
  </a>
  
</li>
        
          <li class="md-nav__item">
  <a href="#scores__2" class="md-nav__link">
    scores_
  </a>
  
</li>
        
          <li class="md-nav__item">
  <a href="#c_" class="md-nav__link">
    c_
  </a>
  
</li>
        
          <li class="md-nav__item">
  <a href="#l1_ratio__1" class="md-nav__link">
    l1_ratio_
  </a>
  
</li>
        
          <li class="md-nav__item">
  <a href="#n_iter__12" class="md-nav__link">
    n_iter_
  </a>
  
</li>
        
          <li class="md-nav__item">
  <a href="#to_string_14" class="md-nav__link">
    to_string
  </a>
  
</li>
        
          <li class="md-nav__item">
  <a href="#show_14" class="md-nav__link">
    show
  </a>
  
</li>
        
          <li class="md-nav__item">
  <a href="#pp_14" class="md-nav__link">
    pp
  </a>
  
</li>
        
      </ul>
    </nav>
  
</li>
      
        <li class="md-nav__item">
  <a href="#module-sklearnlinear_modelmultitaskelasticnet" class="md-nav__link">
    module Sklearn.​Linear_model.​MultiTaskElasticNet
  </a>
  
    <nav class="md-nav" aria-label="module Sklearn.​Linear_model.​MultiTaskElasticNet">
      <ul class="md-nav__list">
        
          <li class="md-nav__item">
  <a href="#create_15" class="md-nav__link">
    create
  </a>
  
</li>
        
          <li class="md-nav__item">
  <a href="#fit_15" class="md-nav__link">
    fit
  </a>
  
</li>
        
          <li class="md-nav__item">
  <a href="#get_params_15" class="md-nav__link">
    get_params
  </a>
  
</li>
        
          <li class="md-nav__item">
  <a href="#predict_15" class="md-nav__link">
    predict
  </a>
  
</li>
        
          <li class="md-nav__item">
  <a href="#score_15" class="md-nav__link">
    score
  </a>
  
</li>
        
          <li class="md-nav__item">
  <a href="#set_params_15" class="md-nav__link">
    set_params
  </a>
  
</li>
        
          <li class="md-nav__item">
  <a href="#intercept__15" class="md-nav__link">
    intercept_
  </a>
  
</li>
        
          <li class="md-nav__item">
  <a href="#coef__15" class="md-nav__link">
    coef_
  </a>
  
</li>
        
          <li class="md-nav__item">
  <a href="#n_iter__13" class="md-nav__link">
    n_iter_
  </a>
  
</li>
        
          <li class="md-nav__item">
  <a href="#to_string_15" class="md-nav__link">
    to_string
  </a>
  
</li>
        
          <li class="md-nav__item">
  <a href="#show_15" class="md-nav__link">
    show
  </a>
  
</li>
        
          <li class="md-nav__item">
  <a href="#pp_15" class="md-nav__link">
    pp
  </a>
  
</li>
        
      </ul>
    </nav>
  
</li>
      
        <li class="md-nav__item">
  <a href="#module-sklearnlinear_modelmultitaskelasticnetcv" class="md-nav__link">
    module Sklearn.​Linear_model.​MultiTaskElasticNetCV
  </a>
  
    <nav class="md-nav" aria-label="module Sklearn.​Linear_model.​MultiTaskElasticNetCV">
      <ul class="md-nav__list">
        
          <li class="md-nav__item">
  <a href="#create_16" class="md-nav__link">
    create
  </a>
  
</li>
        
          <li class="md-nav__item">
  <a href="#fit_16" class="md-nav__link">
    fit
  </a>
  
</li>
        
          <li class="md-nav__item">
  <a href="#get_params_16" class="md-nav__link">
    get_params
  </a>
  
</li>
        
          <li class="md-nav__item">
  <a href="#predict_16" class="md-nav__link">
    predict
  </a>
  
</li>
        
          <li class="md-nav__item">
  <a href="#score_16" class="md-nav__link">
    score
  </a>
  
</li>
        
          <li class="md-nav__item">
  <a href="#set_params_16" class="md-nav__link">
    set_params
  </a>
  
</li>
        
          <li class="md-nav__item">
  <a href="#intercept__16" class="md-nav__link">
    intercept_
  </a>
  
</li>
        
          <li class="md-nav__item">
  <a href="#coef__16" class="md-nav__link">
    coef_
  </a>
  
</li>
        
          <li class="md-nav__item">
  <a href="#alpha__7" class="md-nav__link">
    alpha_
  </a>
  
</li>
        
          <li class="md-nav__item">
  <a href="#mse_path__4" class="md-nav__link">
    mse_path_
  </a>
  
</li>
        
          <li class="md-nav__item">
  <a href="#alphas__6" class="md-nav__link">
    alphas_
  </a>
  
</li>
        
          <li class="md-nav__item">
  <a href="#l1_ratio__2" class="md-nav__link">
    l1_ratio_
  </a>
  
</li>
        
          <li class="md-nav__item">
  <a href="#n_iter__14" class="md-nav__link">
    n_iter_
  </a>
  
</li>
        
          <li class="md-nav__item">
  <a href="#to_string_16" class="md-nav__link">
    to_string
  </a>
  
</li>
        
          <li class="md-nav__item">
  <a href="#show_16" class="md-nav__link">
    show
  </a>
  
</li>
        
          <li class="md-nav__item">
  <a href="#pp_16" class="md-nav__link">
    pp
  </a>
  
</li>
        
      </ul>
    </nav>
  
</li>
      
        <li class="md-nav__item">
  <a href="#module-sklearnlinear_modelmultitasklasso" class="md-nav__link">
    module Sklearn.​Linear_model.​MultiTaskLasso
  </a>
  
    <nav class="md-nav" aria-label="module Sklearn.​Linear_model.​MultiTaskLasso">
      <ul class="md-nav__list">
        
          <li class="md-nav__item">
  <a href="#create_17" class="md-nav__link">
    create
  </a>
  
</li>
        
          <li class="md-nav__item">
  <a href="#fit_17" class="md-nav__link">
    fit
  </a>
  
</li>
        
          <li class="md-nav__item">
  <a href="#get_params_17" class="md-nav__link">
    get_params
  </a>
  
</li>
        
          <li class="md-nav__item">
  <a href="#predict_17" class="md-nav__link">
    predict
  </a>
  
</li>
        
          <li class="md-nav__item">
  <a href="#score_17" class="md-nav__link">
    score
  </a>
  
</li>
        
          <li class="md-nav__item">
  <a href="#set_params_17" class="md-nav__link">
    set_params
  </a>
  
</li>
        
          <li class="md-nav__item">
  <a href="#coef__17" class="md-nav__link">
    coef_
  </a>
  
</li>
        
          <li class="md-nav__item">
  <a href="#intercept__17" class="md-nav__link">
    intercept_
  </a>
  
</li>
        
          <li class="md-nav__item">
  <a href="#n_iter__15" class="md-nav__link">
    n_iter_
  </a>
  
</li>
        
          <li class="md-nav__item">
  <a href="#to_string_17" class="md-nav__link">
    to_string
  </a>
  
</li>
        
          <li class="md-nav__item">
  <a href="#show_17" class="md-nav__link">
    show
  </a>
  
</li>
        
          <li class="md-nav__item">
  <a href="#pp_17" class="md-nav__link">
    pp
  </a>
  
</li>
        
      </ul>
    </nav>
  
</li>
      
        <li class="md-nav__item">
  <a href="#module-sklearnlinear_modelmultitasklassocv" class="md-nav__link">
    module Sklearn.​Linear_model.​MultiTaskLassoCV
  </a>
  
    <nav class="md-nav" aria-label="module Sklearn.​Linear_model.​MultiTaskLassoCV">
      <ul class="md-nav__list">
        
          <li class="md-nav__item">
  <a href="#create_18" class="md-nav__link">
    create
  </a>
  
</li>
        
          <li class="md-nav__item">
  <a href="#fit_18" class="md-nav__link">
    fit
  </a>
  
</li>
        
          <li class="md-nav__item">
  <a href="#get_params_18" class="md-nav__link">
    get_params
  </a>
  
</li>
        
          <li class="md-nav__item">
  <a href="#predict_18" class="md-nav__link">
    predict
  </a>
  
</li>
        
          <li class="md-nav__item">
  <a href="#score_18" class="md-nav__link">
    score
  </a>
  
</li>
        
          <li class="md-nav__item">
  <a href="#set_params_18" class="md-nav__link">
    set_params
  </a>
  
</li>
        
          <li class="md-nav__item">
  <a href="#intercept__18" class="md-nav__link">
    intercept_
  </a>
  
</li>
        
          <li class="md-nav__item">
  <a href="#coef__18" class="md-nav__link">
    coef_
  </a>
  
</li>
        
          <li class="md-nav__item">
  <a href="#alpha__8" class="md-nav__link">
    alpha_
  </a>
  
</li>
        
          <li class="md-nav__item">
  <a href="#mse_path__5" class="md-nav__link">
    mse_path_
  </a>
  
</li>
        
          <li class="md-nav__item">
  <a href="#alphas__7" class="md-nav__link">
    alphas_
  </a>
  
</li>
        
          <li class="md-nav__item">
  <a href="#n_iter__16" class="md-nav__link">
    n_iter_
  </a>
  
</li>
        
          <li class="md-nav__item">
  <a href="#to_string_18" class="md-nav__link">
    to_string
  </a>
  
</li>
        
          <li class="md-nav__item">
  <a href="#show_18" class="md-nav__link">
    show
  </a>
  
</li>
        
          <li class="md-nav__item">
  <a href="#pp_18" class="md-nav__link">
    pp
  </a>
  
</li>
        
      </ul>
    </nav>
  
</li>
      
        <li class="md-nav__item">
  <a href="#module-sklearnlinear_modelorthogonalmatchingpursuit" class="md-nav__link">
    module Sklearn.​Linear_model.​OrthogonalMatchingPursuit
  </a>
  
    <nav class="md-nav" aria-label="module Sklearn.​Linear_model.​OrthogonalMatchingPursuit">
      <ul class="md-nav__list">
        
          <li class="md-nav__item">
  <a href="#create_19" class="md-nav__link">
    create
  </a>
  
</li>
        
          <li class="md-nav__item">
  <a href="#fit_19" class="md-nav__link">
    fit
  </a>
  
</li>
        
          <li class="md-nav__item">
  <a href="#get_params_19" class="md-nav__link">
    get_params
  </a>
  
</li>
        
          <li class="md-nav__item">
  <a href="#predict_19" class="md-nav__link">
    predict
  </a>
  
</li>
        
          <li class="md-nav__item">
  <a href="#score_19" class="md-nav__link">
    score
  </a>
  
</li>
        
          <li class="md-nav__item">
  <a href="#set_params_19" class="md-nav__link">
    set_params
  </a>
  
</li>
        
          <li class="md-nav__item">
  <a href="#coef__19" class="md-nav__link">
    coef_
  </a>
  
</li>
        
          <li class="md-nav__item">
  <a href="#intercept__19" class="md-nav__link">
    intercept_
  </a>
  
</li>
        
          <li class="md-nav__item">
  <a href="#n_iter__17" class="md-nav__link">
    n_iter_
  </a>
  
</li>
        
          <li class="md-nav__item">
  <a href="#to_string_19" class="md-nav__link">
    to_string
  </a>
  
</li>
        
          <li class="md-nav__item">
  <a href="#show_19" class="md-nav__link">
    show
  </a>
  
</li>
        
          <li class="md-nav__item">
  <a href="#pp_19" class="md-nav__link">
    pp
  </a>
  
</li>
        
      </ul>
    </nav>
  
</li>
      
        <li class="md-nav__item">
  <a href="#module-sklearnlinear_modelorthogonalmatchingpursuitcv" class="md-nav__link">
    module Sklearn.​Linear_model.​OrthogonalMatchingPursuitCV
  </a>
  
    <nav class="md-nav" aria-label="module Sklearn.​Linear_model.​OrthogonalMatchingPursuitCV">
      <ul class="md-nav__list">
        
          <li class="md-nav__item">
  <a href="#create_20" class="md-nav__link">
    create
  </a>
  
</li>
        
          <li class="md-nav__item">
  <a href="#fit_20" class="md-nav__link">
    fit
  </a>
  
</li>
        
          <li class="md-nav__item">
  <a href="#get_params_20" class="md-nav__link">
    get_params
  </a>
  
</li>
        
          <li class="md-nav__item">
  <a href="#predict_20" class="md-nav__link">
    predict
  </a>
  
</li>
        
          <li class="md-nav__item">
  <a href="#score_20" class="md-nav__link">
    score
  </a>
  
</li>
        
          <li class="md-nav__item">
  <a href="#set_params_20" class="md-nav__link">
    set_params
  </a>
  
</li>
        
          <li class="md-nav__item">
  <a href="#intercept__20" class="md-nav__link">
    intercept_
  </a>
  
</li>
        
          <li class="md-nav__item">
  <a href="#coef__20" class="md-nav__link">
    coef_
  </a>
  
</li>
        
          <li class="md-nav__item">
  <a href="#n_nonzero_coefs_" class="md-nav__link">
    n_nonzero_coefs_
  </a>
  
</li>
        
          <li class="md-nav__item">
  <a href="#n_iter__18" class="md-nav__link">
    n_iter_
  </a>
  
</li>
        
          <li class="md-nav__item">
  <a href="#to_string_20" class="md-nav__link">
    to_string
  </a>
  
</li>
        
          <li class="md-nav__item">
  <a href="#show_20" class="md-nav__link">
    show
  </a>
  
</li>
        
          <li class="md-nav__item">
  <a href="#pp_20" class="md-nav__link">
    pp
  </a>
  
</li>
        
      </ul>
    </nav>
  
</li>
      
        <li class="md-nav__item">
  <a href="#module-sklearnlinear_modelransacregressor" class="md-nav__link">
    module Sklearn.​Linear_model.​RANSACRegressor
  </a>
  
    <nav class="md-nav" aria-label="module Sklearn.​Linear_model.​RANSACRegressor">
      <ul class="md-nav__list">
        
          <li class="md-nav__item">
  <a href="#create_21" class="md-nav__link">
    create
  </a>
  
</li>
        
          <li class="md-nav__item">
  <a href="#fit_21" class="md-nav__link">
    fit
  </a>
  
</li>
        
          <li class="md-nav__item">
  <a href="#get_params_21" class="md-nav__link">
    get_params
  </a>
  
</li>
        
          <li class="md-nav__item">
  <a href="#predict_21" class="md-nav__link">
    predict
  </a>
  
</li>
        
          <li class="md-nav__item">
  <a href="#score_21" class="md-nav__link">
    score
  </a>
  
</li>
        
          <li class="md-nav__item">
  <a href="#set_params_21" class="md-nav__link">
    set_params
  </a>
  
</li>
        
          <li class="md-nav__item">
  <a href="#estimator_" class="md-nav__link">
    estimator_
  </a>
  
</li>
        
          <li class="md-nav__item">
  <a href="#n_trials_" class="md-nav__link">
    n_trials_
  </a>
  
</li>
        
          <li class="md-nav__item">
  <a href="#inlier_mask_" class="md-nav__link">
    inlier_mask_
  </a>
  
</li>
        
          <li class="md-nav__item">
  <a href="#n_skips_no_inliers_" class="md-nav__link">
    n_skips_no_inliers_
  </a>
  
</li>
        
          <li class="md-nav__item">
  <a href="#n_skips_invalid_data_" class="md-nav__link">
    n_skips_invalid_data_
  </a>
  
</li>
        
          <li class="md-nav__item">
  <a href="#n_skips_invalid_model_" class="md-nav__link">
    n_skips_invalid_model_
  </a>
  
</li>
        
          <li class="md-nav__item">
  <a href="#to_string_21" class="md-nav__link">
    to_string
  </a>
  
</li>
        
          <li class="md-nav__item">
  <a href="#show_21" class="md-nav__link">
    show
  </a>
  
</li>
        
          <li class="md-nav__item">
  <a href="#pp_21" class="md-nav__link">
    pp
  </a>
  
</li>
        
      </ul>
    </nav>
  
</li>
      
        <li class="md-nav__item">
  <a href="#module-sklearnlinear_modelridge" class="md-nav__link">
    module Sklearn.​Linear_model.​Ridge
  </a>
  
    <nav class="md-nav" aria-label="module Sklearn.​Linear_model.​Ridge">
      <ul class="md-nav__list">
        
          <li class="md-nav__item">
  <a href="#create_22" class="md-nav__link">
    create
  </a>
  
</li>
        
          <li class="md-nav__item">
  <a href="#fit_22" class="md-nav__link">
    fit
  </a>
  
</li>
        
          <li class="md-nav__item">
  <a href="#get_params_22" class="md-nav__link">
    get_params
  </a>
  
</li>
        
          <li class="md-nav__item">
  <a href="#predict_22" class="md-nav__link">
    predict
  </a>
  
</li>
        
          <li class="md-nav__item">
  <a href="#score_22" class="md-nav__link">
    score
  </a>
  
</li>
        
          <li class="md-nav__item">
  <a href="#set_params_22" class="md-nav__link">
    set_params
  </a>
  
</li>
        
          <li class="md-nav__item">
  <a href="#coef__21" class="md-nav__link">
    coef_
  </a>
  
</li>
        
          <li class="md-nav__item">
  <a href="#intercept__21" class="md-nav__link">
    intercept_
  </a>
  
</li>
        
          <li class="md-nav__item">
  <a href="#n_iter__19" class="md-nav__link">
    n_iter_
  </a>
  
</li>
        
          <li class="md-nav__item">
  <a href="#to_string_22" class="md-nav__link">
    to_string
  </a>
  
</li>
        
          <li class="md-nav__item">
  <a href="#show_22" class="md-nav__link">
    show
  </a>
  
</li>
        
          <li class="md-nav__item">
  <a href="#pp_22" class="md-nav__link">
    pp
  </a>
  
</li>
        
      </ul>
    </nav>
  
</li>
      
        <li class="md-nav__item">
  <a href="#module-sklearnlinear_modelridgecv" class="md-nav__link">
    module Sklearn.​Linear_model.​RidgeCV
  </a>
  
    <nav class="md-nav" aria-label="module Sklearn.​Linear_model.​RidgeCV">
      <ul class="md-nav__list">
        
          <li class="md-nav__item">
  <a href="#create_23" class="md-nav__link">
    create
  </a>
  
</li>
        
          <li class="md-nav__item">
  <a href="#fit_23" class="md-nav__link">
    fit
  </a>
  
</li>
        
          <li class="md-nav__item">
  <a href="#get_params_23" class="md-nav__link">
    get_params
  </a>
  
</li>
        
          <li class="md-nav__item">
  <a href="#predict_23" class="md-nav__link">
    predict
  </a>
  
</li>
        
          <li class="md-nav__item">
  <a href="#score_23" class="md-nav__link">
    score
  </a>
  
</li>
        
          <li class="md-nav__item">
  <a href="#set_params_23" class="md-nav__link">
    set_params
  </a>
  
</li>
        
          <li class="md-nav__item">
  <a href="#cv_values_" class="md-nav__link">
    cv_values_
  </a>
  
</li>
        
          <li class="md-nav__item">
  <a href="#coef__22" class="md-nav__link">
    coef_
  </a>
  
</li>
        
          <li class="md-nav__item">
  <a href="#intercept__22" class="md-nav__link">
    intercept_
  </a>
  
</li>
        
          <li class="md-nav__item">
  <a href="#alpha__9" class="md-nav__link">
    alpha_
  </a>
  
</li>
        
          <li class="md-nav__item">
  <a href="#to_string_23" class="md-nav__link">
    to_string
  </a>
  
</li>
        
          <li class="md-nav__item">
  <a href="#show_23" class="md-nav__link">
    show
  </a>
  
</li>
        
          <li class="md-nav__item">
  <a href="#pp_23" class="md-nav__link">
    pp
  </a>
  
</li>
        
      </ul>
    </nav>
  
</li>
      
        <li class="md-nav__item">
  <a href="#module-sklearnlinear_modelridgeclassifier" class="md-nav__link">
    module Sklearn.​Linear_model.​RidgeClassifier
  </a>
  
    <nav class="md-nav" aria-label="module Sklearn.​Linear_model.​RidgeClassifier">
      <ul class="md-nav__list">
        
          <li class="md-nav__item">
  <a href="#create_24" class="md-nav__link">
    create
  </a>
  
</li>
        
          <li class="md-nav__item">
  <a href="#decision_function_2" class="md-nav__link">
    decision_function
  </a>
  
</li>
        
          <li class="md-nav__item">
  <a href="#fit_24" class="md-nav__link">
    fit
  </a>
  
</li>
        
          <li class="md-nav__item">
  <a href="#get_params_24" class="md-nav__link">
    get_params
  </a>
  
</li>
        
          <li class="md-nav__item">
  <a href="#predict_24" class="md-nav__link">
    predict
  </a>
  
</li>
        
          <li class="md-nav__item">
  <a href="#score_24" class="md-nav__link">
    score
  </a>
  
</li>
        
          <li class="md-nav__item">
  <a href="#set_params_24" class="md-nav__link">
    set_params
  </a>
  
</li>
        
          <li class="md-nav__item">
  <a href="#coef__23" class="md-nav__link">
    coef_
  </a>
  
</li>
        
          <li class="md-nav__item">
  <a href="#intercept__23" class="md-nav__link">
    intercept_
  </a>
  
</li>
        
          <li class="md-nav__item">
  <a href="#n_iter__20" class="md-nav__link">
    n_iter_
  </a>
  
</li>
        
          <li class="md-nav__item">
  <a href="#classes__2" class="md-nav__link">
    classes_
  </a>
  
</li>
        
          <li class="md-nav__item">
  <a href="#to_string_24" class="md-nav__link">
    to_string
  </a>
  
</li>
        
          <li class="md-nav__item">
  <a href="#show_24" class="md-nav__link">
    show
  </a>
  
</li>
        
          <li class="md-nav__item">
  <a href="#pp_24" class="md-nav__link">
    pp
  </a>
  
</li>
        
      </ul>
    </nav>
  
</li>
      
        <li class="md-nav__item">
  <a href="#module-sklearnlinear_modelridgeclassifiercv" class="md-nav__link">
    module Sklearn.​Linear_model.​RidgeClassifierCV
  </a>
  
    <nav class="md-nav" aria-label="module Sklearn.​Linear_model.​RidgeClassifierCV">
      <ul class="md-nav__list">
        
          <li class="md-nav__item">
  <a href="#create_25" class="md-nav__link">
    create
  </a>
  
</li>
        
          <li class="md-nav__item">
  <a href="#decision_function_3" class="md-nav__link">
    decision_function
  </a>
  
</li>
        
          <li class="md-nav__item">
  <a href="#fit_25" class="md-nav__link">
    fit
  </a>
  
</li>
        
          <li class="md-nav__item">
  <a href="#get_params_25" class="md-nav__link">
    get_params
  </a>
  
</li>
        
          <li class="md-nav__item">
  <a href="#predict_25" class="md-nav__link">
    predict
  </a>
  
</li>
        
          <li class="md-nav__item">
  <a href="#score_25" class="md-nav__link">
    score
  </a>
  
</li>
        
          <li class="md-nav__item">
  <a href="#set_params_25" class="md-nav__link">
    set_params
  </a>
  
</li>
        
          <li class="md-nav__item">
  <a href="#cv_values__1" class="md-nav__link">
    cv_values_
  </a>
  
</li>
        
          <li class="md-nav__item">
  <a href="#coef__24" class="md-nav__link">
    coef_
  </a>
  
</li>
        
          <li class="md-nav__item">
  <a href="#intercept__24" class="md-nav__link">
    intercept_
  </a>
  
</li>
        
          <li class="md-nav__item">
  <a href="#alpha__10" class="md-nav__link">
    alpha_
  </a>
  
</li>
        
          <li class="md-nav__item">
  <a href="#classes__3" class="md-nav__link">
    classes_
  </a>
  
</li>
        
          <li class="md-nav__item">
  <a href="#to_string_25" class="md-nav__link">
    to_string
  </a>
  
</li>
        
          <li class="md-nav__item">
  <a href="#show_25" class="md-nav__link">
    show
  </a>
  
</li>
        
          <li class="md-nav__item">
  <a href="#pp_25" class="md-nav__link">
    pp
  </a>
  
</li>
        
      </ul>
    </nav>
  
</li>
      
        <li class="md-nav__item">
  <a href="#module-sklearnlinear_modeltheilsenregressor" class="md-nav__link">
    module Sklearn.​Linear_model.​TheilSenRegressor
  </a>
  
    <nav class="md-nav" aria-label="module Sklearn.​Linear_model.​TheilSenRegressor">
      <ul class="md-nav__list">
        
          <li class="md-nav__item">
  <a href="#create_26" class="md-nav__link">
    create
  </a>
  
</li>
        
          <li class="md-nav__item">
  <a href="#fit_26" class="md-nav__link">
    fit
  </a>
  
</li>
        
          <li class="md-nav__item">
  <a href="#get_params_26" class="md-nav__link">
    get_params
  </a>
  
</li>
        
          <li class="md-nav__item">
  <a href="#predict_26" class="md-nav__link">
    predict
  </a>
  
</li>
        
          <li class="md-nav__item">
  <a href="#score_26" class="md-nav__link">
    score
  </a>
  
</li>
        
          <li class="md-nav__item">
  <a href="#set_params_26" class="md-nav__link">
    set_params
  </a>
  
</li>
        
          <li class="md-nav__item">
  <a href="#coef__25" class="md-nav__link">
    coef_
  </a>
  
</li>
        
          <li class="md-nav__item">
  <a href="#intercept__25" class="md-nav__link">
    intercept_
  </a>
  
</li>
        
          <li class="md-nav__item">
  <a href="#breakdown_" class="md-nav__link">
    breakdown_
  </a>
  
</li>
        
          <li class="md-nav__item">
  <a href="#n_iter__21" class="md-nav__link">
    n_iter_
  </a>
  
</li>
        
          <li class="md-nav__item">
  <a href="#n_subpopulation_" class="md-nav__link">
    n_subpopulation_
  </a>
  
</li>
        
          <li class="md-nav__item">
  <a href="#to_string_26" class="md-nav__link">
    to_string
  </a>
  
</li>
        
          <li class="md-nav__item">
  <a href="#show_26" class="md-nav__link">
    show
  </a>
  
</li>
        
          <li class="md-nav__item">
  <a href="#pp_26" class="md-nav__link">
    pp
  </a>
  
</li>
        
          <li class="md-nav__item">
  <a href="#enet_path" class="md-nav__link">
    enet_path
  </a>
  
</li>
        
          <li class="md-nav__item">
  <a href="#lars_path" class="md-nav__link">
    lars_path
  </a>
  
</li>
        
          <li class="md-nav__item">
  <a href="#lars_path_gram" class="md-nav__link">
    lars_path_gram
  </a>
  
</li>
        
          <li class="md-nav__item">
  <a href="#lasso_path" class="md-nav__link">
    lasso_path
  </a>
  
</li>
        
          <li class="md-nav__item">
  <a href="#logistic_regression_path" class="md-nav__link">
    logistic_regression_path
  </a>
  
</li>
        
      </ul>
    </nav>
  
</li>
      
        <li class="md-nav__item">
  <a href="#returns" class="md-nav__link">
    Returns
  </a>
  
</li>
      
        <li class="md-nav__item">
  <a href="#notes" class="md-nav__link">
    Notes
  </a>
  
    <nav class="md-nav" aria-label="Notes">
      <ul class="md-nav__list">
        
          <li class="md-nav__item">
  <a href="#orthogonal_mp" class="md-nav__link">
    orthogonal_mp
  </a>
  
</li>
        
          <li class="md-nav__item">
  <a href="#orthogonal_mp_gram" class="md-nav__link">
    orthogonal_mp_gram
  </a>
  
</li>
        
          <li class="md-nav__item">
  <a href="#ridge_regression" class="md-nav__link">
    ridge_regression
  </a>
  
</li>
        
      </ul>
    </nav>
  
</li>
      
    </ul>
  
</nav>
                  </div>
                </div>
              </div>
            
          
          <div class="md-content">
            <article class="md-content__inner md-typeset">
              
                
                  <a href="https://github.com/lehy/ocaml-sklearn/edit/master/docs/linear_model.md" title="Edit this page" class="md-content__button md-icon">
                    <svg xmlns="http://www.w3.org/2000/svg" viewBox="0 0 24 24"><path d="M20.71,7.04C21.1,6.65 21.1,6 20.71,5.63L18.37,3.29C18,2.9 17.35,2.9 16.96,3.29L15.12,5.12L18.87,8.87M3,17.25V21H6.75L17.81,9.93L14.06,6.18L3,17.25Z" /></svg>
                  </a>
                
                
                  
                
                
                  <h1>Linear model</h1>
                
                <h2 id="module-sklearnlinear_modelardregression">module Sklearn.​Linear_model.​ARDRegression<a class="headerlink" href="#module-sklearnlinear_modelardregression" title="Permanent link">&para;</a></h2>
<div class="highlight"><pre><span></span><code><span class="k">type</span> <span class="n">t</span>
</code></pre></div>

<h3 id="create">create<a class="headerlink" href="#create" title="Permanent link">&para;</a></h3>
<details class="note" open="open"><summary>constructor and attributes</summary><div class="highlight"><pre><span></span><code><span class="k">val</span> <span class="n">create</span> <span class="o">:</span>
  <span class="o">?</span><span class="n">n_iter</span><span class="o">:</span><span class="kt">int</span> <span class="o">-&gt;</span>
  <span class="o">?</span><span class="n">tol</span><span class="o">:</span><span class="kt">float</span> <span class="o">-&gt;</span>
  <span class="o">?</span><span class="n">alpha_1</span><span class="o">:</span><span class="kt">float</span> <span class="o">-&gt;</span>
  <span class="o">?</span><span class="n">alpha_2</span><span class="o">:</span><span class="kt">float</span> <span class="o">-&gt;</span>
  <span class="o">?</span><span class="n">lambda_1</span><span class="o">:</span><span class="kt">float</span> <span class="o">-&gt;</span>
  <span class="o">?</span><span class="n">lambda_2</span><span class="o">:</span><span class="kt">float</span> <span class="o">-&gt;</span>
  <span class="o">?</span><span class="n">compute_score</span><span class="o">:</span><span class="kt">bool</span> <span class="o">-&gt;</span>
  <span class="o">?</span><span class="n">threshold_lambda</span><span class="o">:</span><span class="kt">float</span> <span class="o">-&gt;</span>
  <span class="o">?</span><span class="n">fit_intercept</span><span class="o">:</span><span class="kt">bool</span> <span class="o">-&gt;</span>
  <span class="o">?</span><span class="n">normalize</span><span class="o">:</span><span class="kt">bool</span> <span class="o">-&gt;</span>
  <span class="o">?</span><span class="n">copy_X</span><span class="o">:</span><span class="kt">bool</span> <span class="o">-&gt;</span>
  <span class="o">?</span><span class="n">verbose</span><span class="o">:</span><span class="kt">int</span> <span class="o">-&gt;</span>
  <span class="kt">unit</span> <span class="o">-&gt;</span>
  <span class="n">t</span>
</code></pre></div>

<p>Bayesian ARD regression.</p>
<p>Fit the weights of a regression model, using an ARD prior. The weights of
the regression model are assumed to be in Gaussian distributions.
Also estimate the parameters lambda (precisions of the distributions of the
weights) and alpha (precision of the distribution of the noise).
The estimation is done by an iterative procedures (Evidence Maximization)</p>
<p>Read more in the :ref:<code>User Guide &lt;bayesian_regression&gt;</code>.</p>
<h4>Parameters</h4>
<details class="info" open="open"><summary>n_iter : int, default=300</summary><p>Maximum number of iterations.</p>
</details>
<details class="info" open="open"><summary>tol : float, default=1e-3</summary><p>Stop the algorithm if w has converged.</p>
</details>
<details class="info" open="open"><summary>alpha_1 : float, default=1e-6</summary></details>
<details class="info" open="open"><summary>Hyper-parameter : shape parameter for the Gamma distribution prior</summary><p>over the alpha parameter.</p>
</details>
<details class="info" open="open"><summary>alpha_2 : float, default=1e-6</summary></details>
<details class="info" open="open"><summary>Hyper-parameter : inverse scale parameter (rate parameter) for the</summary><p>Gamma distribution prior over the alpha parameter.</p>
</details>
<details class="info" open="open"><summary>lambda_1 : float, default=1e-6</summary></details>
<details class="info" open="open"><summary>Hyper-parameter : shape parameter for the Gamma distribution prior</summary><p>over the lambda parameter.</p>
</details>
<details class="info" open="open"><summary>lambda_2 : float, default=1e-6</summary></details>
<details class="info" open="open"><summary>Hyper-parameter : inverse scale parameter (rate parameter) for the</summary><p>Gamma distribution prior over the lambda parameter.</p>
</details>
<details class="info" open="open"><summary>compute_score : bool, default=False</summary><p>If True, compute the objective function at each step of the model.</p>
</details>
<details class="info" open="open"><summary>threshold_lambda : float, default=10 000</summary><p>threshold for removing (pruning) weights with high precision from
the computation.</p>
</details>
<details class="info" open="open"><summary>fit_intercept : bool, default=True</summary><p>whether to calculate the intercept for this model. If set
to false, no intercept will be used in calculations
(i.e. data is expected to be centered).</p>
</details>
<details class="info" open="open"><summary>normalize : bool, default=False</summary><p>This parameter is ignored when <code>fit_intercept</code> is set to False.
If True, the regressors X will be normalized before regression by
subtracting the mean and dividing by the l2-norm.
If you wish to standardize, please use
:class:<code>sklearn.preprocessing.StandardScaler</code> before calling <code>fit</code>
on an estimator with <code>normalize=False</code>.</p>
</details>
<details class="info" open="open"><summary>copy_X : bool, default=True</summary><p>If True, X will be copied; else, it may be overwritten.</p>
</details>
<details class="info" open="open"><summary>verbose : bool, default=False</summary><p>Verbose mode when fitting the model.</p>
</details>
<h4>Attributes</h4>
<details class="info" open="open"><summary>coef_ : array-like of shape (n_features,)</summary><p>Coefficients of the regression model (mean of distribution)</p>
</details>
<details class="info" open="open"><summary>alpha_ : float</summary></details>
<p>estimated precision of the noise.</p>
<details class="info" open="open"><summary>lambda_ : array-like of shape (n_features,)</summary></details>
<p>estimated precisions of the weights.</p>
<details class="info" open="open"><summary>sigma_ : array-like of shape (n_features, n_features)</summary><p>estimated variance-covariance matrix of the weights</p>
</details>
<details class="info" open="open"><summary>scores_ : float</summary><p>if computed, value of the objective function (to be maximized)</p>
</details>
<details class="info" open="open"><summary>intercept_ : float</summary><p>Independent term in decision function. Set to 0.0 if
<code>fit_intercept = False</code>.</p>
</details>
<h4>Examples</h4>
<div class="highlight"><pre><span></span><code><span class="o">&gt;&gt;&gt;</span> <span class="kn">from</span> <span class="nn">sklearn</span> <span class="kn">import</span> <span class="n">linear_model</span>
<span class="o">&gt;&gt;&gt;</span> <span class="n">clf</span> <span class="o">=</span> <span class="n">linear_model</span><span class="o">.</span><span class="n">ARDRegression</span><span class="p">()</span>
<span class="o">&gt;&gt;&gt;</span> <span class="n">clf</span><span class="o">.</span><span class="n">fit</span><span class="p">([[</span><span class="mi">0</span><span class="p">,</span><span class="mi">0</span><span class="p">],</span> <span class="p">[</span><span class="mi">1</span><span class="p">,</span> <span class="mi">1</span><span class="p">],</span> <span class="p">[</span><span class="mi">2</span><span class="p">,</span> <span class="mi">2</span><span class="p">]],</span> <span class="p">[</span><span class="mi">0</span><span class="p">,</span> <span class="mi">1</span><span class="p">,</span> <span class="mi">2</span><span class="p">])</span>
<span class="n">ARDRegression</span><span class="p">()</span>
<span class="o">&gt;&gt;&gt;</span> <span class="n">clf</span><span class="o">.</span><span class="n">predict</span><span class="p">([[</span><span class="mi">1</span><span class="p">,</span> <span class="mi">1</span><span class="p">]])</span>
<span class="n">array</span><span class="p">([</span><span class="mf">1.</span><span class="p">])</span>
</code></pre></div>

<h4>Notes</h4>
<p>For an example, see :ref:<code>examples/linear_model/plot_ard.py
&lt;sphx_glr_auto_examples_linear_model_plot_ard.py&gt;</code>.</p>
<h4>References</h4>
<p>D. J. C. MacKay, Bayesian nonlinear modeling for the prediction
competition, ASHRAE Transactions, 1994.</p>
<p>R. Salakhutdinov, Lecture notes on Statistical Machine Learning,</p>
<details class="info" open="open"><summary>http://www.utstat.toronto.edu/~rsalakhu/sta4273/notes/Lecture2.pdf#page=15</summary></details>
<p>Their beta is our <code>self.alpha_</code>
Their alpha is our <code>self.lambda_</code>
ARD is a little different than the slide: only dimensions/features for
which <code>self.lambda_ &lt; self.threshold_lambda</code> are kept and the rest are
discarded.</p>
</details>
<h3 id="fit">fit<a class="headerlink" href="#fit" title="Permanent link">&para;</a></h3>
<details class="note" open="open"><summary>method</summary><div class="highlight"><pre><span></span><code><span class="k">val</span> <span class="n">fit</span> <span class="o">:</span>
  <span class="n">x</span><span class="o">:</span><span class="nn">Arr</span><span class="p">.</span><span class="n">t</span> <span class="o">-&gt;</span>
  <span class="n">y</span><span class="o">:</span><span class="nn">Py</span><span class="p">.</span><span class="nn">Object</span><span class="p">.</span><span class="n">t</span> <span class="o">-&gt;</span>
  <span class="n">t</span> <span class="o">-&gt;</span>
  <span class="n">t</span>
</code></pre></div>

<p>Fit the ARDRegression model according to the given training data
and parameters.</p>
<p>Iterative procedure to maximize the evidence</p>
<h4>Parameters</h4>
<details class="info" open="open"><summary>X : array-like of shape (n_samples, n_features)</summary><p>Training vector, where n_samples in the number of samples and
n_features is the number of features.</p>
</details>
<details class="info" open="open"><summary>y : array-like of shape (n_samples,)</summary><p>Target values (integers). Will be cast to X's dtype if necessary</p>
</details>
<h4>Returns</h4>
<details class="info" open="open"><summary>self : returns an instance of self.</summary></details>
</details>
<h3 id="get_params">get_params<a class="headerlink" href="#get_params" title="Permanent link">&para;</a></h3>
<details class="note" open="open"><summary>method</summary><div class="highlight"><pre><span></span><code><span class="k">val</span> <span class="n">get_params</span> <span class="o">:</span>
  <span class="o">?</span><span class="n">deep</span><span class="o">:</span><span class="kt">bool</span> <span class="o">-&gt;</span>
  <span class="n">t</span> <span class="o">-&gt;</span>
  <span class="nn">Dict</span><span class="p">.</span><span class="n">t</span>
</code></pre></div>

<p>Get parameters for this estimator.</p>
<h4>Parameters</h4>
<details class="info" open="open"><summary>deep : bool, default=True</summary><p>If True, will return the parameters for this estimator and
contained subobjects that are estimators.</p>
</details>
<h4>Returns</h4>
<details class="info" open="open"><summary>params : mapping of string to any</summary><p>Parameter names mapped to their values.</p>
</details>
</details>
<h3 id="predict">predict<a class="headerlink" href="#predict" title="Permanent link">&para;</a></h3>
<details class="note" open="open"><summary>method</summary><div class="highlight"><pre><span></span><code><span class="k">val</span> <span class="n">predict</span> <span class="o">:</span>
  <span class="o">?</span><span class="n">return_std</span><span class="o">:</span><span class="kt">bool</span> <span class="o">-&gt;</span>
  <span class="n">x</span><span class="o">:</span><span class="nn">Arr</span><span class="p">.</span><span class="n">t</span> <span class="o">-&gt;</span>
  <span class="n">t</span> <span class="o">-&gt;</span>
  <span class="nn">Arr</span><span class="p">.</span><span class="n">t</span>
</code></pre></div>

<p>Predict using the linear model.</p>
<p>In addition to the mean of the predictive distribution, also its
standard deviation can be returned.</p>
<h4>Parameters</h4>
<details class="info" open="open"><summary>X : {array-like, sparse matrix} of shape (n_samples, n_features)</summary><p>Samples.</p>
</details>
<details class="info" open="open"><summary>return_std : bool, default=False</summary><p>Whether to return the standard deviation of posterior prediction.</p>
</details>
<h4>Returns</h4>
<details class="info" open="open"><summary>y_mean : array-like of shape (n_samples,)</summary><p>Mean of predictive distribution of query points.</p>
</details>
<details class="info" open="open"><summary>y_std : array-like of shape (n_samples,)</summary><p>Standard deviation of predictive distribution of query points.</p>
</details>
</details>
<h3 id="score">score<a class="headerlink" href="#score" title="Permanent link">&para;</a></h3>
<details class="note" open="open"><summary>method</summary><div class="highlight"><pre><span></span><code><span class="k">val</span> <span class="n">score</span> <span class="o">:</span>
  <span class="o">?</span><span class="n">sample_weight</span><span class="o">:</span><span class="nn">Arr</span><span class="p">.</span><span class="n">t</span> <span class="o">-&gt;</span>
  <span class="n">x</span><span class="o">:</span><span class="nn">Arr</span><span class="p">.</span><span class="n">t</span> <span class="o">-&gt;</span>
  <span class="n">y</span><span class="o">:</span><span class="nn">Arr</span><span class="p">.</span><span class="n">t</span> <span class="o">-&gt;</span>
  <span class="n">t</span> <span class="o">-&gt;</span>
  <span class="kt">float</span>
</code></pre></div>

<p>Return the coefficient of determination R^2 of the prediction.</p>
<p>The coefficient R^2 is defined as (1 - u/v), where u is the residual
sum of squares ((y_true - y_pred) <strong> 2).sum() and v is the total
sum of squares ((y_true - y_true.mean()) </strong> 2).sum().
The best possible score is 1.0 and it can be negative (because the
model can be arbitrarily worse). A constant model that always
predicts the expected value of y, disregarding the input features,
would get a R^2 score of 0.0.</p>
<h4>Parameters</h4>
<details class="info" open="open"><summary>X : array-like of shape (n_samples, n_features)</summary><p>Test samples. For some estimators this may be a
precomputed kernel matrix or a list of generic objects instead,
shape = (n_samples, n_samples_fitted),
where n_samples_fitted is the number of
samples used in the fitting for the estimator.</p>
</details>
<details class="info" open="open"><summary>y : array-like of shape (n_samples,) or (n_samples, n_outputs)</summary><p>True values for X.</p>
</details>
<details class="info" open="open"><summary>sample_weight : array-like of shape (n_samples,), default=None</summary><p>Sample weights.</p>
</details>
<h4>Returns</h4>
<details class="info" open="open"><summary>score : float</summary><p>R^2 of self.predict(X) wrt. y.</p>
</details>
<h4>Notes</h4>
<p>The R2 score used when calling <code>score</code> on a regressor will use
<code>multioutput='uniform_average'</code> from version 0.23 to keep consistent</p>
<details class="info" open="open"><summary>with :func:<code>~sklearn.metrics.r2_score</code>. This will influence the</summary></details>
<p><code>score</code> method of all the multioutput regressors (except for
:class:<code>~sklearn.multioutput.MultiOutputRegressor</code>). To specify the
default value manually and avoid the warning, please either call
:func:<code>~sklearn.metrics.r2_score</code> directly or make a custom scorer with
:func:<code>~sklearn.metrics.make_scorer</code> (the built-in scorer <code>'r2'</code> uses
<code>multioutput='uniform_average'</code>).</p>
</details>
<h3 id="set_params">set_params<a class="headerlink" href="#set_params" title="Permanent link">&para;</a></h3>
<details class="note" open="open"><summary>method</summary><div class="highlight"><pre><span></span><code><span class="k">val</span> <span class="n">set_params</span> <span class="o">:</span>
  <span class="o">?</span><span class="n">params</span><span class="o">:(</span><span class="kt">string</span> <span class="o">*</span> <span class="nn">Py</span><span class="p">.</span><span class="nn">Object</span><span class="p">.</span><span class="n">t</span><span class="o">)</span> <span class="kt">list</span> <span class="o">-&gt;</span>
  <span class="n">t</span> <span class="o">-&gt;</span>
  <span class="n">t</span>
</code></pre></div>

<p>Set the parameters of this estimator.</p>
<p>The method works on simple estimators as well as on nested objects
(such as pipelines). The latter have parameters of the form
<code>&lt;component&gt;__&lt;parameter&gt;</code> so that it's possible to update each
component of a nested object.</p>
<h4>Parameters</h4>
<details class="info" open="open"><summary>**params : dict</summary><p>Estimator parameters.</p>
</details>
<h4>Returns</h4>
<details class="info" open="open"><summary>self : object</summary><p>Estimator instance.</p>
</details>
</details>
<h3 id="coef_">coef_<a class="headerlink" href="#coef_" title="Permanent link">&para;</a></h3>
<details class="note" open="open"><summary>attribute</summary><div class="highlight"><pre><span></span><code><span class="k">val</span> <span class="n">coef_</span> <span class="o">:</span> <span class="n">t</span> <span class="o">-&gt;</span> <span class="nn">Arr</span><span class="p">.</span><span class="n">t</span>
<span class="k">val</span> <span class="n">coef_opt</span> <span class="o">:</span> <span class="n">t</span> <span class="o">-&gt;</span> <span class="o">(</span><span class="nn">Arr</span><span class="p">.</span><span class="n">t</span><span class="o">)</span> <span class="n">option</span>
</code></pre></div>

<p>This attribute is documented in <code>create</code> above. The first version raises Not_found
if the attribute is None. The _opt version returns an option.</p>
</details>
<h3 id="alpha_">alpha_<a class="headerlink" href="#alpha_" title="Permanent link">&para;</a></h3>
<details class="note" open="open"><summary>attribute</summary><div class="highlight"><pre><span></span><code><span class="k">val</span> <span class="n">alpha_</span> <span class="o">:</span> <span class="n">t</span> <span class="o">-&gt;</span> <span class="kt">float</span>
<span class="k">val</span> <span class="n">alpha_opt</span> <span class="o">:</span> <span class="n">t</span> <span class="o">-&gt;</span> <span class="o">(</span><span class="kt">float</span><span class="o">)</span> <span class="n">option</span>
</code></pre></div>

<p>This attribute is documented in <code>create</code> above. The first version raises Not_found
if the attribute is None. The _opt version returns an option.</p>
</details>
<h3 id="lambda_">lambda_<a class="headerlink" href="#lambda_" title="Permanent link">&para;</a></h3>
<details class="note" open="open"><summary>attribute</summary><div class="highlight"><pre><span></span><code><span class="k">val</span> <span class="n">lambda_</span> <span class="o">:</span> <span class="n">t</span> <span class="o">-&gt;</span> <span class="nn">Arr</span><span class="p">.</span><span class="n">t</span>
<span class="k">val</span> <span class="n">lambda_opt</span> <span class="o">:</span> <span class="n">t</span> <span class="o">-&gt;</span> <span class="o">(</span><span class="nn">Arr</span><span class="p">.</span><span class="n">t</span><span class="o">)</span> <span class="n">option</span>
</code></pre></div>

<p>This attribute is documented in <code>create</code> above. The first version raises Not_found
if the attribute is None. The _opt version returns an option.</p>
</details>
<h3 id="sigma_">sigma_<a class="headerlink" href="#sigma_" title="Permanent link">&para;</a></h3>
<details class="note" open="open"><summary>attribute</summary><div class="highlight"><pre><span></span><code><span class="k">val</span> <span class="n">sigma_</span> <span class="o">:</span> <span class="n">t</span> <span class="o">-&gt;</span> <span class="nn">Arr</span><span class="p">.</span><span class="n">t</span>
<span class="k">val</span> <span class="n">sigma_opt</span> <span class="o">:</span> <span class="n">t</span> <span class="o">-&gt;</span> <span class="o">(</span><span class="nn">Arr</span><span class="p">.</span><span class="n">t</span><span class="o">)</span> <span class="n">option</span>
</code></pre></div>

<p>This attribute is documented in <code>create</code> above. The first version raises Not_found
if the attribute is None. The _opt version returns an option.</p>
</details>
<h3 id="scores_">scores_<a class="headerlink" href="#scores_" title="Permanent link">&para;</a></h3>
<details class="note" open="open"><summary>attribute</summary><div class="highlight"><pre><span></span><code><span class="k">val</span> <span class="n">scores_</span> <span class="o">:</span> <span class="n">t</span> <span class="o">-&gt;</span> <span class="kt">float</span>
<span class="k">val</span> <span class="n">scores_opt</span> <span class="o">:</span> <span class="n">t</span> <span class="o">-&gt;</span> <span class="o">(</span><span class="kt">float</span><span class="o">)</span> <span class="n">option</span>
</code></pre></div>

<p>This attribute is documented in <code>create</code> above. The first version raises Not_found
if the attribute is None. The _opt version returns an option.</p>
</details>
<h3 id="intercept_">intercept_<a class="headerlink" href="#intercept_" title="Permanent link">&para;</a></h3>
<details class="note" open="open"><summary>attribute</summary><div class="highlight"><pre><span></span><code><span class="k">val</span> <span class="n">intercept_</span> <span class="o">:</span> <span class="n">t</span> <span class="o">-&gt;</span> <span class="nn">Arr</span><span class="p">.</span><span class="n">t</span>
<span class="k">val</span> <span class="n">intercept_opt</span> <span class="o">:</span> <span class="n">t</span> <span class="o">-&gt;</span> <span class="o">(</span><span class="nn">Arr</span><span class="p">.</span><span class="n">t</span><span class="o">)</span> <span class="n">option</span>
</code></pre></div>

<p>This attribute is documented in <code>create</code> above. The first version raises Not_found
if the attribute is None. The _opt version returns an option.</p>
</details>
<h3 id="to_string">to_string<a class="headerlink" href="#to_string" title="Permanent link">&para;</a></h3>
<details class="note" open="open"><summary>method</summary><div class="highlight"><pre><span></span><code><span class="k">val</span> <span class="n">to_string</span><span class="o">:</span> <span class="n">t</span> <span class="o">-&gt;</span> <span class="kt">string</span>
</code></pre></div>

<p>Print the object to a human-readable representation.</p>
</details>
<h3 id="show">show<a class="headerlink" href="#show" title="Permanent link">&para;</a></h3>
<details class="note" open="open"><summary>method</summary><div class="highlight"><pre><span></span><code><span class="k">val</span> <span class="n">show</span><span class="o">:</span> <span class="n">t</span> <span class="o">-&gt;</span> <span class="kt">string</span>
</code></pre></div>

<p>Print the object to a human-readable representation.</p>
</details>
<h3 id="pp">pp<a class="headerlink" href="#pp" title="Permanent link">&para;</a></h3>
<details class="note" open="open"><summary>method</summary><div class="highlight"><pre><span></span><code><span class="k">val</span> <span class="n">pp</span><span class="o">:</span> <span class="nn">Format</span><span class="p">.</span><span class="n">formatter</span> <span class="o">-&gt;</span> <span class="n">t</span> <span class="o">-&gt;</span> <span class="kt">unit</span>
</code></pre></div>

<p>Pretty-print the object to a formatter.</p>
</details>
<h2 id="module-sklearnlinear_modelbayesianridge">module Sklearn.​Linear_model.​BayesianRidge<a class="headerlink" href="#module-sklearnlinear_modelbayesianridge" title="Permanent link">&para;</a></h2>
<div class="highlight"><pre><span></span><code><span class="k">type</span> <span class="n">t</span>
</code></pre></div>

<h3 id="create_1">create<a class="headerlink" href="#create_1" title="Permanent link">&para;</a></h3>
<details class="note" open="open"><summary>constructor and attributes</summary><div class="highlight"><pre><span></span><code><span class="k">val</span> <span class="n">create</span> <span class="o">:</span>
  <span class="o">?</span><span class="n">n_iter</span><span class="o">:</span><span class="kt">int</span> <span class="o">-&gt;</span>
  <span class="o">?</span><span class="n">tol</span><span class="o">:</span><span class="kt">float</span> <span class="o">-&gt;</span>
  <span class="o">?</span><span class="n">alpha_1</span><span class="o">:</span><span class="kt">float</span> <span class="o">-&gt;</span>
  <span class="o">?</span><span class="n">alpha_2</span><span class="o">:</span><span class="kt">float</span> <span class="o">-&gt;</span>
  <span class="o">?</span><span class="n">lambda_1</span><span class="o">:</span><span class="kt">float</span> <span class="o">-&gt;</span>
  <span class="o">?</span><span class="n">lambda_2</span><span class="o">:</span><span class="kt">float</span> <span class="o">-&gt;</span>
  <span class="o">?</span><span class="n">alpha_init</span><span class="o">:</span><span class="kt">float</span> <span class="o">-&gt;</span>
  <span class="o">?</span><span class="n">lambda_init</span><span class="o">:</span><span class="kt">float</span> <span class="o">-&gt;</span>
  <span class="o">?</span><span class="n">compute_score</span><span class="o">:</span><span class="kt">bool</span> <span class="o">-&gt;</span>
  <span class="o">?</span><span class="n">fit_intercept</span><span class="o">:</span><span class="kt">bool</span> <span class="o">-&gt;</span>
  <span class="o">?</span><span class="n">normalize</span><span class="o">:</span><span class="kt">bool</span> <span class="o">-&gt;</span>
  <span class="o">?</span><span class="n">copy_X</span><span class="o">:</span><span class="kt">bool</span> <span class="o">-&gt;</span>
  <span class="o">?</span><span class="n">verbose</span><span class="o">:</span><span class="kt">int</span> <span class="o">-&gt;</span>
  <span class="kt">unit</span> <span class="o">-&gt;</span>
  <span class="n">t</span>
</code></pre></div>

<p>Bayesian ridge regression.</p>
<p>Fit a Bayesian ridge model. See the Notes section for details on this
implementation and the optimization of the regularization parameters
lambda (precision of the weights) and alpha (precision of the noise).</p>
<p>Read more in the :ref:<code>User Guide &lt;bayesian_regression&gt;</code>.</p>
<h4>Parameters</h4>
<details class="info" open="open"><summary>n_iter : int, default=300</summary><p>Maximum number of iterations. Should be greater than or equal to 1.</p>
</details>
<details class="info" open="open"><summary>tol : float, default=1e-3</summary><p>Stop the algorithm if w has converged.</p>
</details>
<details class="info" open="open"><summary>alpha_1 : float, default=1e-6</summary></details>
<details class="info" open="open"><summary>Hyper-parameter : shape parameter for the Gamma distribution prior</summary><p>over the alpha parameter.</p>
</details>
<details class="info" open="open"><summary>alpha_2 : float, default=1e-6</summary></details>
<details class="info" open="open"><summary>Hyper-parameter : inverse scale parameter (rate parameter) for the</summary><p>Gamma distribution prior over the alpha parameter.</p>
</details>
<details class="info" open="open"><summary>lambda_1 : float, default=1e-6</summary></details>
<details class="info" open="open"><summary>Hyper-parameter : shape parameter for the Gamma distribution prior</summary><p>over the lambda parameter.</p>
</details>
<details class="info" open="open"><summary>lambda_2 : float, default=1e-6</summary></details>
<details class="info" open="open"><summary>Hyper-parameter : inverse scale parameter (rate parameter) for the</summary><p>Gamma distribution prior over the lambda parameter.</p>
</details>
<details class="info" open="open"><summary>alpha_init : float, default=None</summary><p>Initial value for alpha (precision of the noise).
If not set, alpha_init is 1/Var(y).</p>
<div class="codehilite"><pre><span></span><code>.. versionadded:: 0.22
</code></pre></div>


</details>
<details class="info" open="open"><summary>lambda_init : float, default=None</summary><p>Initial value for lambda (precision of the weights).
If not set, lambda_init is 1.</p>
<div class="codehilite"><pre><span></span><code>.. versionadded:: 0.22
</code></pre></div>


</details>
<details class="info" open="open"><summary>compute_score : bool, default=False</summary><p>If True, compute the log marginal likelihood at each iteration of the
optimization.</p>
</details>
<details class="info" open="open"><summary>fit_intercept : bool, default=True</summary><p>Whether to calculate the intercept for this model.
The intercept is not treated as a probabilistic parameter
and thus has no associated variance. If set
to False, no intercept will be used in calculations
(i.e. data is expected to be centered).</p>
</details>
<details class="info" open="open"><summary>normalize : bool, default=False</summary><p>This parameter is ignored when <code>fit_intercept</code> is set to False.
If True, the regressors X will be normalized before regression by
subtracting the mean and dividing by the l2-norm.
If you wish to standardize, please use
:class:<code>sklearn.preprocessing.StandardScaler</code> before calling <code>fit</code>
on an estimator with <code>normalize=False</code>.</p>
</details>
<details class="info" open="open"><summary>copy_X : bool, default=True</summary><p>If True, X will be copied; else, it may be overwritten.</p>
</details>
<details class="info" open="open"><summary>verbose : bool, default=False</summary><p>Verbose mode when fitting the model.</p>
</details>
<h4>Attributes</h4>
<details class="info" open="open"><summary>coef_ : array-like of shape (n_features,)</summary><p>Coefficients of the regression model (mean of distribution)</p>
</details>
<details class="info" open="open"><summary>intercept_ : float</summary><p>Independent term in decision function. Set to 0.0 if
<code>fit_intercept = False</code>.</p>
</details>
<details class="info" open="open"><summary>alpha_ : float</summary></details>
<p>Estimated precision of the noise.</p>
<details class="info" open="open"><summary>lambda_ : float</summary></details>
<p>Estimated precision of the weights.</p>
<details class="info" open="open"><summary>sigma_ : array-like of shape (n_features, n_features)</summary><p>Estimated variance-covariance matrix of the weights</p>
</details>
<details class="info" open="open"><summary>scores_ : array-like of shape (n_iter_+1,)</summary><p>If computed_score is True, value of the log marginal likelihood (to be
maximized) at each iteration of the optimization. The array starts
with the value of the log marginal likelihood obtained for the initial
values of alpha and lambda and ends with the value obtained for the
estimated alpha and lambda.</p>
</details>
<details class="info" open="open"><summary>n_iter_ : int</summary><p>The actual number of iterations to reach the stopping criterion.</p>
</details>
<h4>Examples</h4>
<div class="highlight"><pre><span></span><code><span class="o">&gt;&gt;&gt;</span> <span class="kn">from</span> <span class="nn">sklearn</span> <span class="kn">import</span> <span class="n">linear_model</span>
<span class="o">&gt;&gt;&gt;</span> <span class="n">clf</span> <span class="o">=</span> <span class="n">linear_model</span><span class="o">.</span><span class="n">BayesianRidge</span><span class="p">()</span>
<span class="o">&gt;&gt;&gt;</span> <span class="n">clf</span><span class="o">.</span><span class="n">fit</span><span class="p">([[</span><span class="mi">0</span><span class="p">,</span><span class="mi">0</span><span class="p">],</span> <span class="p">[</span><span class="mi">1</span><span class="p">,</span> <span class="mi">1</span><span class="p">],</span> <span class="p">[</span><span class="mi">2</span><span class="p">,</span> <span class="mi">2</span><span class="p">]],</span> <span class="p">[</span><span class="mi">0</span><span class="p">,</span> <span class="mi">1</span><span class="p">,</span> <span class="mi">2</span><span class="p">])</span>
<span class="n">BayesianRidge</span><span class="p">()</span>
<span class="o">&gt;&gt;&gt;</span> <span class="n">clf</span><span class="o">.</span><span class="n">predict</span><span class="p">([[</span><span class="mi">1</span><span class="p">,</span> <span class="mi">1</span><span class="p">]])</span>
<span class="n">array</span><span class="p">([</span><span class="mf">1.</span><span class="p">])</span>
</code></pre></div>

<h4>Notes</h4>
<p>There exist several strategies to perform Bayesian ridge regression. This
implementation is based on the algorithm described in Appendix A of
(Tipping, 2001) where updates of the regularization parameters are done as
suggested in (MacKay, 1992). Note that according to A New
View of Automatic Relevance Determination (Wipf and Nagarajan, 2008) these
update rules do not guarantee that the marginal likelihood is increasing
between two consecutive iterations of the optimization.</p>
<h4>References</h4>
<p>D. J. C. MacKay, Bayesian Interpolation, Computation and Neural Systems,
Vol. 4, No. 3, 1992.</p>
<p>M. E. Tipping, Sparse Bayesian Learning and the Relevance Vector Machine,
Journal of Machine Learning Research, Vol. 1, 2001.</p>
</details>
<h3 id="fit_1">fit<a class="headerlink" href="#fit_1" title="Permanent link">&para;</a></h3>
<details class="note" open="open"><summary>method</summary><div class="highlight"><pre><span></span><code><span class="k">val</span> <span class="n">fit</span> <span class="o">:</span>
  <span class="o">?</span><span class="n">sample_weight</span><span class="o">:</span><span class="nn">Arr</span><span class="p">.</span><span class="n">t</span> <span class="o">-&gt;</span>
  <span class="n">x</span><span class="o">:</span><span class="nn">Arr</span><span class="p">.</span><span class="n">t</span> <span class="o">-&gt;</span>
  <span class="n">y</span><span class="o">:</span><span class="nn">Py</span><span class="p">.</span><span class="nn">Object</span><span class="p">.</span><span class="n">t</span> <span class="o">-&gt;</span>
  <span class="n">t</span> <span class="o">-&gt;</span>
  <span class="n">t</span>
</code></pre></div>

<p>Fit the model</p>
<h4>Parameters</h4>
<details class="info" open="open"><summary>X : ndarray of shape (n_samples, n_features)</summary><p>Training data</p>
</details>
<details class="info" open="open"><summary>y : ndarray of shape (n_samples,)</summary><p>Target values. Will be cast to X's dtype if necessary</p>
</details>
<details class="info" open="open"><summary>sample_weight : ndarray of shape (n_samples,), default=None</summary><p>Individual weights for each sample</p>
<p>.. versionadded:: 0.20
   parameter <em>sample_weight</em> support to BayesianRidge.</p>
</details>
<h4>Returns</h4>
<details class="info" open="open"><summary>self : returns an instance of self.</summary></details>
</details>
<h3 id="get_params_1">get_params<a class="headerlink" href="#get_params_1" title="Permanent link">&para;</a></h3>
<details class="note" open="open"><summary>method</summary><div class="highlight"><pre><span></span><code><span class="k">val</span> <span class="n">get_params</span> <span class="o">:</span>
  <span class="o">?</span><span class="n">deep</span><span class="o">:</span><span class="kt">bool</span> <span class="o">-&gt;</span>
  <span class="n">t</span> <span class="o">-&gt;</span>
  <span class="nn">Dict</span><span class="p">.</span><span class="n">t</span>
</code></pre></div>

<p>Get parameters for this estimator.</p>
<h4>Parameters</h4>
<details class="info" open="open"><summary>deep : bool, default=True</summary><p>If True, will return the parameters for this estimator and
contained subobjects that are estimators.</p>
</details>
<h4>Returns</h4>
<details class="info" open="open"><summary>params : mapping of string to any</summary><p>Parameter names mapped to their values.</p>
</details>
</details>
<h3 id="predict_1">predict<a class="headerlink" href="#predict_1" title="Permanent link">&para;</a></h3>
<details class="note" open="open"><summary>method</summary><div class="highlight"><pre><span></span><code><span class="k">val</span> <span class="n">predict</span> <span class="o">:</span>
  <span class="o">?</span><span class="n">return_std</span><span class="o">:</span><span class="kt">bool</span> <span class="o">-&gt;</span>
  <span class="n">x</span><span class="o">:</span><span class="nn">Arr</span><span class="p">.</span><span class="n">t</span> <span class="o">-&gt;</span>
  <span class="n">t</span> <span class="o">-&gt;</span>
  <span class="nn">Arr</span><span class="p">.</span><span class="n">t</span>
</code></pre></div>

<p>Predict using the linear model.</p>
<p>In addition to the mean of the predictive distribution, also its
standard deviation can be returned.</p>
<h4>Parameters</h4>
<details class="info" open="open"><summary>X : {array-like, sparse matrix} of shape (n_samples, n_features)</summary><p>Samples.</p>
</details>
<details class="info" open="open"><summary>return_std : bool, default=False</summary><p>Whether to return the standard deviation of posterior prediction.</p>
</details>
<h4>Returns</h4>
<details class="info" open="open"><summary>y_mean : array-like of shape (n_samples,)</summary><p>Mean of predictive distribution of query points.</p>
</details>
<details class="info" open="open"><summary>y_std : array-like of shape (n_samples,)</summary><p>Standard deviation of predictive distribution of query points.</p>
</details>
</details>
<h3 id="score_1">score<a class="headerlink" href="#score_1" title="Permanent link">&para;</a></h3>
<details class="note" open="open"><summary>method</summary><div class="highlight"><pre><span></span><code><span class="k">val</span> <span class="n">score</span> <span class="o">:</span>
  <span class="o">?</span><span class="n">sample_weight</span><span class="o">:</span><span class="nn">Arr</span><span class="p">.</span><span class="n">t</span> <span class="o">-&gt;</span>
  <span class="n">x</span><span class="o">:</span><span class="nn">Arr</span><span class="p">.</span><span class="n">t</span> <span class="o">-&gt;</span>
  <span class="n">y</span><span class="o">:</span><span class="nn">Arr</span><span class="p">.</span><span class="n">t</span> <span class="o">-&gt;</span>
  <span class="n">t</span> <span class="o">-&gt;</span>
  <span class="kt">float</span>
</code></pre></div>

<p>Return the coefficient of determination R^2 of the prediction.</p>
<p>The coefficient R^2 is defined as (1 - u/v), where u is the residual
sum of squares ((y_true - y_pred) <strong> 2).sum() and v is the total
sum of squares ((y_true - y_true.mean()) </strong> 2).sum().
The best possible score is 1.0 and it can be negative (because the
model can be arbitrarily worse). A constant model that always
predicts the expected value of y, disregarding the input features,
would get a R^2 score of 0.0.</p>
<h4>Parameters</h4>
<details class="info" open="open"><summary>X : array-like of shape (n_samples, n_features)</summary><p>Test samples. For some estimators this may be a
precomputed kernel matrix or a list of generic objects instead,
shape = (n_samples, n_samples_fitted),
where n_samples_fitted is the number of
samples used in the fitting for the estimator.</p>
</details>
<details class="info" open="open"><summary>y : array-like of shape (n_samples,) or (n_samples, n_outputs)</summary><p>True values for X.</p>
</details>
<details class="info" open="open"><summary>sample_weight : array-like of shape (n_samples,), default=None</summary><p>Sample weights.</p>
</details>
<h4>Returns</h4>
<details class="info" open="open"><summary>score : float</summary><p>R^2 of self.predict(X) wrt. y.</p>
</details>
<h4>Notes</h4>
<p>The R2 score used when calling <code>score</code> on a regressor will use
<code>multioutput='uniform_average'</code> from version 0.23 to keep consistent</p>
<details class="info" open="open"><summary>with :func:<code>~sklearn.metrics.r2_score</code>. This will influence the</summary></details>
<p><code>score</code> method of all the multioutput regressors (except for
:class:<code>~sklearn.multioutput.MultiOutputRegressor</code>). To specify the
default value manually and avoid the warning, please either call
:func:<code>~sklearn.metrics.r2_score</code> directly or make a custom scorer with
:func:<code>~sklearn.metrics.make_scorer</code> (the built-in scorer <code>'r2'</code> uses
<code>multioutput='uniform_average'</code>).</p>
</details>
<h3 id="set_params_1">set_params<a class="headerlink" href="#set_params_1" title="Permanent link">&para;</a></h3>
<details class="note" open="open"><summary>method</summary><div class="highlight"><pre><span></span><code><span class="k">val</span> <span class="n">set_params</span> <span class="o">:</span>
  <span class="o">?</span><span class="n">params</span><span class="o">:(</span><span class="kt">string</span> <span class="o">*</span> <span class="nn">Py</span><span class="p">.</span><span class="nn">Object</span><span class="p">.</span><span class="n">t</span><span class="o">)</span> <span class="kt">list</span> <span class="o">-&gt;</span>
  <span class="n">t</span> <span class="o">-&gt;</span>
  <span class="n">t</span>
</code></pre></div>

<p>Set the parameters of this estimator.</p>
<p>The method works on simple estimators as well as on nested objects
(such as pipelines). The latter have parameters of the form
<code>&lt;component&gt;__&lt;parameter&gt;</code> so that it's possible to update each
component of a nested object.</p>
<h4>Parameters</h4>
<details class="info" open="open"><summary>**params : dict</summary><p>Estimator parameters.</p>
</details>
<h4>Returns</h4>
<details class="info" open="open"><summary>self : object</summary><p>Estimator instance.</p>
</details>
</details>
<h3 id="coef__1">coef_<a class="headerlink" href="#coef__1" title="Permanent link">&para;</a></h3>
<details class="note" open="open"><summary>attribute</summary><div class="highlight"><pre><span></span><code><span class="k">val</span> <span class="n">coef_</span> <span class="o">:</span> <span class="n">t</span> <span class="o">-&gt;</span> <span class="nn">Arr</span><span class="p">.</span><span class="n">t</span>
<span class="k">val</span> <span class="n">coef_opt</span> <span class="o">:</span> <span class="n">t</span> <span class="o">-&gt;</span> <span class="o">(</span><span class="nn">Arr</span><span class="p">.</span><span class="n">t</span><span class="o">)</span> <span class="n">option</span>
</code></pre></div>

<p>This attribute is documented in <code>create</code> above. The first version raises Not_found
if the attribute is None. The _opt version returns an option.</p>
</details>
<h3 id="intercept__1">intercept_<a class="headerlink" href="#intercept__1" title="Permanent link">&para;</a></h3>
<details class="note" open="open"><summary>attribute</summary><div class="highlight"><pre><span></span><code><span class="k">val</span> <span class="n">intercept_</span> <span class="o">:</span> <span class="n">t</span> <span class="o">-&gt;</span> <span class="nn">Arr</span><span class="p">.</span><span class="n">t</span>
<span class="k">val</span> <span class="n">intercept_opt</span> <span class="o">:</span> <span class="n">t</span> <span class="o">-&gt;</span> <span class="o">(</span><span class="nn">Arr</span><span class="p">.</span><span class="n">t</span><span class="o">)</span> <span class="n">option</span>
</code></pre></div>

<p>This attribute is documented in <code>create</code> above. The first version raises Not_found
if the attribute is None. The _opt version returns an option.</p>
</details>
<h3 id="alpha__1">alpha_<a class="headerlink" href="#alpha__1" title="Permanent link">&para;</a></h3>
<details class="note" open="open"><summary>attribute</summary><div class="highlight"><pre><span></span><code><span class="k">val</span> <span class="n">alpha_</span> <span class="o">:</span> <span class="n">t</span> <span class="o">-&gt;</span> <span class="kt">float</span>
<span class="k">val</span> <span class="n">alpha_opt</span> <span class="o">:</span> <span class="n">t</span> <span class="o">-&gt;</span> <span class="o">(</span><span class="kt">float</span><span class="o">)</span> <span class="n">option</span>
</code></pre></div>

<p>This attribute is documented in <code>create</code> above. The first version raises Not_found
if the attribute is None. The _opt version returns an option.</p>
</details>
<h3 id="lambda__1">lambda_<a class="headerlink" href="#lambda__1" title="Permanent link">&para;</a></h3>
<details class="note" open="open"><summary>attribute</summary><div class="highlight"><pre><span></span><code><span class="k">val</span> <span class="n">lambda_</span> <span class="o">:</span> <span class="n">t</span> <span class="o">-&gt;</span> <span class="kt">float</span>
<span class="k">val</span> <span class="n">lambda_opt</span> <span class="o">:</span> <span class="n">t</span> <span class="o">-&gt;</span> <span class="o">(</span><span class="kt">float</span><span class="o">)</span> <span class="n">option</span>
</code></pre></div>

<p>This attribute is documented in <code>create</code> above. The first version raises Not_found
if the attribute is None. The _opt version returns an option.</p>
</details>
<h3 id="sigma__1">sigma_<a class="headerlink" href="#sigma__1" title="Permanent link">&para;</a></h3>
<details class="note" open="open"><summary>attribute</summary><div class="highlight"><pre><span></span><code><span class="k">val</span> <span class="n">sigma_</span> <span class="o">:</span> <span class="n">t</span> <span class="o">-&gt;</span> <span class="nn">Arr</span><span class="p">.</span><span class="n">t</span>
<span class="k">val</span> <span class="n">sigma_opt</span> <span class="o">:</span> <span class="n">t</span> <span class="o">-&gt;</span> <span class="o">(</span><span class="nn">Arr</span><span class="p">.</span><span class="n">t</span><span class="o">)</span> <span class="n">option</span>
</code></pre></div>

<p>This attribute is documented in <code>create</code> above. The first version raises Not_found
if the attribute is None. The _opt version returns an option.</p>
</details>
<h3 id="scores__1">scores_<a class="headerlink" href="#scores__1" title="Permanent link">&para;</a></h3>
<details class="note" open="open"><summary>attribute</summary><div class="highlight"><pre><span></span><code><span class="k">val</span> <span class="n">scores_</span> <span class="o">:</span> <span class="n">t</span> <span class="o">-&gt;</span> <span class="nn">Arr</span><span class="p">.</span><span class="n">t</span>
<span class="k">val</span> <span class="n">scores_opt</span> <span class="o">:</span> <span class="n">t</span> <span class="o">-&gt;</span> <span class="o">(</span><span class="nn">Arr</span><span class="p">.</span><span class="n">t</span><span class="o">)</span> <span class="n">option</span>
</code></pre></div>

<p>This attribute is documented in <code>create</code> above. The first version raises Not_found
if the attribute is None. The _opt version returns an option.</p>
</details>
<h3 id="n_iter_">n_iter_<a class="headerlink" href="#n_iter_" title="Permanent link">&para;</a></h3>
<details class="note" open="open"><summary>attribute</summary><div class="highlight"><pre><span></span><code><span class="k">val</span> <span class="n">n_iter_</span> <span class="o">:</span> <span class="n">t</span> <span class="o">-&gt;</span> <span class="kt">int</span>
<span class="k">val</span> <span class="n">n_iter_opt</span> <span class="o">:</span> <span class="n">t</span> <span class="o">-&gt;</span> <span class="o">(</span><span class="kt">int</span><span class="o">)</span> <span class="n">option</span>
</code></pre></div>

<p>This attribute is documented in <code>create</code> above. The first version raises Not_found
if the attribute is None. The _opt version returns an option.</p>
</details>
<h3 id="to_string_1">to_string<a class="headerlink" href="#to_string_1" title="Permanent link">&para;</a></h3>
<details class="note" open="open"><summary>method</summary><div class="highlight"><pre><span></span><code><span class="k">val</span> <span class="n">to_string</span><span class="o">:</span> <span class="n">t</span> <span class="o">-&gt;</span> <span class="kt">string</span>
</code></pre></div>

<p>Print the object to a human-readable representation.</p>
</details>
<h3 id="show_1">show<a class="headerlink" href="#show_1" title="Permanent link">&para;</a></h3>
<details class="note" open="open"><summary>method</summary><div class="highlight"><pre><span></span><code><span class="k">val</span> <span class="n">show</span><span class="o">:</span> <span class="n">t</span> <span class="o">-&gt;</span> <span class="kt">string</span>
</code></pre></div>

<p>Print the object to a human-readable representation.</p>
</details>
<h3 id="pp_1">pp<a class="headerlink" href="#pp_1" title="Permanent link">&para;</a></h3>
<details class="note" open="open"><summary>method</summary><div class="highlight"><pre><span></span><code><span class="k">val</span> <span class="n">pp</span><span class="o">:</span> <span class="nn">Format</span><span class="p">.</span><span class="n">formatter</span> <span class="o">-&gt;</span> <span class="n">t</span> <span class="o">-&gt;</span> <span class="kt">unit</span>
</code></pre></div>

<p>Pretty-print the object to a formatter.</p>
</details>
<h2 id="module-sklearnlinear_modelelasticnet">module Sklearn.​Linear_model.​ElasticNet<a class="headerlink" href="#module-sklearnlinear_modelelasticnet" title="Permanent link">&para;</a></h2>
<div class="highlight"><pre><span></span><code><span class="k">type</span> <span class="n">t</span>
</code></pre></div>

<h3 id="create_2">create<a class="headerlink" href="#create_2" title="Permanent link">&para;</a></h3>
<details class="note" open="open"><summary>constructor and attributes</summary><div class="highlight"><pre><span></span><code><span class="k">val</span> <span class="n">create</span> <span class="o">:</span>
  <span class="o">?</span><span class="n">alpha</span><span class="o">:</span><span class="kt">float</span> <span class="o">-&gt;</span>
  <span class="o">?</span><span class="n">l1_ratio</span><span class="o">:</span><span class="kt">float</span> <span class="o">-&gt;</span>
  <span class="o">?</span><span class="n">fit_intercept</span><span class="o">:</span><span class="kt">bool</span> <span class="o">-&gt;</span>
  <span class="o">?</span><span class="n">normalize</span><span class="o">:</span><span class="kt">bool</span> <span class="o">-&gt;</span>
  <span class="o">?</span><span class="n">precompute</span><span class="o">:[`</span><span class="nc">Bool</span> <span class="k">of</span> <span class="kt">bool</span> <span class="o">|</span> <span class="o">`</span><span class="nc">Arr</span> <span class="k">of</span> <span class="nn">Arr</span><span class="p">.</span><span class="n">t</span><span class="o">]</span> <span class="o">-&gt;</span>
  <span class="o">?</span><span class="n">max_iter</span><span class="o">:</span><span class="kt">int</span> <span class="o">-&gt;</span>
  <span class="o">?</span><span class="n">copy_X</span><span class="o">:</span><span class="kt">bool</span> <span class="o">-&gt;</span>
  <span class="o">?</span><span class="n">tol</span><span class="o">:</span><span class="kt">float</span> <span class="o">-&gt;</span>
  <span class="o">?</span><span class="n">warm_start</span><span class="o">:</span><span class="kt">bool</span> <span class="o">-&gt;</span>
  <span class="o">?</span><span class="n">positive</span><span class="o">:</span><span class="kt">bool</span> <span class="o">-&gt;</span>
  <span class="o">?</span><span class="n">random_state</span><span class="o">:</span><span class="kt">int</span> <span class="o">-&gt;</span>
  <span class="o">?</span><span class="n">selection</span><span class="o">:</span><span class="kt">string</span> <span class="o">-&gt;</span>
  <span class="kt">unit</span> <span class="o">-&gt;</span>
  <span class="n">t</span>
</code></pre></div>

<p>Linear regression with combined L1 and L2 priors as regularizer.</p>
<p>Minimizes the objective function::</p>
<div class="codehilite"><pre><span></span><code>    1 / (2 * n_samples) * ||y - Xw||^2_2
    + alpha * l1_ratio * ||w||_1
    + 0.5 * alpha * (1 - l1_ratio) * ||w||^2_2
</code></pre></div>


<p>If you are interested in controlling the L1 and L2 penalty
separately, keep in mind that this is equivalent to::</p>
<div class="codehilite"><pre><span></span><code>    a * L1 + b * L2
</code></pre></div>


<details class="info" open="open"><summary>where::</summary><div class="codehilite"><pre><span></span><code>alpha = a + b and l1_ratio = a / (a + b)
</code></pre></div>


</details>
<p>The parameter l1_ratio corresponds to alpha in the glmnet R package while
alpha corresponds to the lambda parameter in glmnet. Specifically, l1_ratio
= 1 is the lasso penalty. Currently, l1_ratio &lt;= 0.01 is not reliable,
unless you supply your own sequence of alpha.</p>
<p>Read more in the :ref:<code>User Guide &lt;elastic_net&gt;</code>.</p>
<h4>Parameters</h4>
<details class="info" open="open"><summary>alpha : float, optional</summary><p>Constant that multiplies the penalty terms. Defaults to 1.0.
See the notes for the exact mathematical meaning of this
parameter. <code>alpha = 0</code> is equivalent to an ordinary least square,
solved by the :class:<code>LinearRegression</code> object. For numerical
reasons, using <code>alpha = 0</code> with the <code>Lasso</code> object is not advised.
Given this, you should use the :class:<code>LinearRegression</code> object.</p>
</details>
<details class="info" open="open"><summary>l1_ratio : float</summary><p>The ElasticNet mixing parameter, with <code>0 &lt;= l1_ratio &lt;= 1</code>. For
<code>l1_ratio = 0</code> the penalty is an L2 penalty. <code>For l1_ratio = 1</code> it
is an L1 penalty.  For <code>0 &lt; l1_ratio &lt; 1</code>, the penalty is a
combination of L1 and L2.</p>
</details>
<details class="info" open="open"><summary>fit_intercept : bool</summary><p>Whether the intercept should be estimated or not. If <code>False</code>, the
data is assumed to be already centered.</p>
</details>
<details class="info" open="open"><summary>normalize : boolean, optional, default False</summary><p>This parameter is ignored when <code>fit_intercept</code> is set to False.
If True, the regressors X will be normalized before regression by
subtracting the mean and dividing by the l2-norm.
If you wish to standardize, please use
:class:<code>sklearn.preprocessing.StandardScaler</code> before calling <code>fit</code>
on an estimator with <code>normalize=False</code>.</p>
</details>
<details class="info" open="open"><summary>precompute : True | False | array-like</summary><p>Whether to use a precomputed Gram matrix to speed up
calculations. The Gram matrix can also be passed as argument.
For sparse input this option is always <code>True</code> to preserve sparsity.</p>
</details>
<details class="info" open="open"><summary>max_iter : int, optional</summary><p>The maximum number of iterations</p>
</details>
<details class="info" open="open"><summary>copy_X : boolean, optional, default True</summary><p>If <code>True</code>, X will be copied; else, it may be overwritten.</p>
</details>
<details class="info" open="open"><summary>tol : float, optional</summary><p>The tolerance for the optimization: if the updates are
smaller than <code>tol</code>, the optimization code checks the
dual gap for optimality and continues until it is smaller
than <code>tol</code>.</p>
</details>
<details class="info" open="open"><summary>warm_start : bool, optional</summary><p>When set to <code>True</code>, reuse the solution of the previous call to fit as
initialization, otherwise, just erase the previous solution.</p>
</details>
<details class="info" open="open"><summary>See :term:<code>the Glossary &lt;warm_start&gt;</code>.</summary></details>
<details class="info" open="open"><summary>positive : bool, optional</summary><p>When set to <code>True</code>, forces the coefficients to be positive.</p>
</details>
<details class="info" open="open"><summary>random_state : int, RandomState instance or None, optional, default None</summary><p>The seed of the pseudo random number generator that selects a random
feature to update.  If int, random_state is the seed used by the random
number generator; If RandomState instance, random_state is the random
number generator; If None, the random number generator is the
RandomState instance used by <code>np.random</code>. Used when <code>selection</code> ==
'random'.</p>
</details>
<details class="info" open="open"><summary>selection : str, default 'cyclic'</summary><p>If set to 'random', a random coefficient is updated every iteration
rather than looping over features sequentially by default. This
(setting to 'random') often leads to significantly faster convergence
especially when tol is higher than 1e-4.</p>
</details>
<h4>Attributes</h4>
<details class="info" open="open"><summary>coef_ : array, shape (n_features,) | (n_targets, n_features)</summary><p>parameter vector (w in the cost function formula)</p>
</details>
<details class="info" open="open"><summary>sparse_coef_ : scipy.sparse matrix, shape (n_features, 1) |             (n_targets, n_features)</summary><p><code>sparse_coef_</code> is a readonly property derived from <code>coef_</code></p>
</details>
<details class="info" open="open"><summary>intercept_ : float | array, shape (n_targets,)</summary><p>independent term in decision function.</p>
</details>
<details class="info" open="open"><summary>n_iter_ : array-like, shape (n_targets,)</summary><p>number of iterations run by the coordinate descent solver to reach
the specified tolerance.</p>
</details>
<h4>Examples</h4>
<div class="highlight"><pre><span></span><code><span class="o">&gt;&gt;&gt;</span> <span class="kn">from</span> <span class="nn">sklearn.linear_model</span> <span class="kn">import</span> <span class="n">ElasticNet</span>
<span class="o">&gt;&gt;&gt;</span> <span class="kn">from</span> <span class="nn">sklearn.datasets</span> <span class="kn">import</span> <span class="n">make_regression</span>
</code></pre></div>

<div class="highlight"><pre><span></span><code><span class="o">&gt;&gt;&gt;</span> <span class="n">X</span><span class="p">,</span> <span class="n">y</span> <span class="o">=</span> <span class="n">make_regression</span><span class="p">(</span><span class="n">n_features</span><span class="o">=</span><span class="mi">2</span><span class="p">,</span> <span class="n">random_state</span><span class="o">=</span><span class="mi">0</span><span class="p">)</span>
<span class="o">&gt;&gt;&gt;</span> <span class="n">regr</span> <span class="o">=</span> <span class="n">ElasticNet</span><span class="p">(</span><span class="n">random_state</span><span class="o">=</span><span class="mi">0</span><span class="p">)</span>
<span class="o">&gt;&gt;&gt;</span> <span class="n">regr</span><span class="o">.</span><span class="n">fit</span><span class="p">(</span><span class="n">X</span><span class="p">,</span> <span class="n">y</span><span class="p">)</span>
<span class="n">ElasticNet</span><span class="p">(</span><span class="n">random_state</span><span class="o">=</span><span class="mi">0</span><span class="p">)</span>
<span class="o">&gt;&gt;&gt;</span> <span class="nb">print</span><span class="p">(</span><span class="n">regr</span><span class="o">.</span><span class="n">coef_</span><span class="p">)</span>
<span class="p">[</span><span class="mf">18.83816048</span> <span class="mf">64.55968825</span><span class="p">]</span>
<span class="o">&gt;&gt;&gt;</span> <span class="nb">print</span><span class="p">(</span><span class="n">regr</span><span class="o">.</span><span class="n">intercept_</span><span class="p">)</span>
<span class="mf">1.451</span><span class="o">...</span>
<span class="o">&gt;&gt;&gt;</span> <span class="nb">print</span><span class="p">(</span><span class="n">regr</span><span class="o">.</span><span class="n">predict</span><span class="p">([[</span><span class="mi">0</span><span class="p">,</span> <span class="mi">0</span><span class="p">]]))</span>
<span class="p">[</span><span class="mf">1.451</span><span class="o">...</span><span class="p">]</span>
</code></pre></div>

<h4>Notes</h4>
<p>To avoid unnecessary memory duplication the X argument of the fit method
should be directly passed as a Fortran-contiguous numpy array.</p>
<h4>See also</h4>
<details class="info" open="open"><summary>ElasticNetCV : Elastic net model with best model selection by</summary><p>cross-validation.</p>
</details>
<details class="info" open="open"><summary>SGDRegressor: implements elastic net regression with incremental training.</summary></details>
<details class="info" open="open"><summary>SGDClassifier: implements logistic regression with elastic net penalty</summary><p>(<code>SGDClassifier(loss="log", penalty="elasticnet")</code>).</p>
</details>
</details>
<h3 id="fit_2">fit<a class="headerlink" href="#fit_2" title="Permanent link">&para;</a></h3>
<details class="note" open="open"><summary>method</summary><div class="highlight"><pre><span></span><code><span class="k">val</span> <span class="n">fit</span> <span class="o">:</span>
  <span class="o">?</span><span class="n">check_input</span><span class="o">:</span><span class="kt">bool</span> <span class="o">-&gt;</span>
  <span class="n">x</span><span class="o">:[`</span><span class="nc">Arr</span> <span class="k">of</span> <span class="nn">Arr</span><span class="p">.</span><span class="n">t</span> <span class="o">|</span> <span class="o">`</span><span class="nc">PyObject</span> <span class="k">of</span> <span class="nn">Py</span><span class="p">.</span><span class="nn">Object</span><span class="p">.</span><span class="n">t</span><span class="o">]</span> <span class="o">-&gt;</span>
  <span class="n">y</span><span class="o">:</span><span class="nn">Arr</span><span class="p">.</span><span class="n">t</span> <span class="o">-&gt;</span>
  <span class="n">t</span> <span class="o">-&gt;</span>
  <span class="n">t</span>
</code></pre></div>

<p>Fit model with coordinate descent.</p>
<h4>Parameters</h4>
<details class="info" open="open"><summary>X : ndarray or scipy.sparse matrix, (n_samples, n_features)</summary><p>Data</p>
</details>
<details class="info" open="open"><summary>y : ndarray, shape (n_samples,) or (n_samples, n_targets)</summary><p>Target. Will be cast to X's dtype if necessary</p>
</details>
<details class="info" open="open"><summary>check_input : boolean, (default=True)</summary><p>Allow to bypass several input checking.
Don't use this parameter unless you know what you do.</p>
</details>
<h4>Notes</h4>
<p>Coordinate descent is an algorithm that considers each column of
data at a time hence it will automatically convert the X input
as a Fortran-contiguous numpy array if necessary.</p>
<p>To avoid memory re-allocation it is advised to allocate the
initial data in memory directly using that format.</p>
</details>
<h3 id="get_params_2">get_params<a class="headerlink" href="#get_params_2" title="Permanent link">&para;</a></h3>
<details class="note" open="open"><summary>method</summary><div class="highlight"><pre><span></span><code><span class="k">val</span> <span class="n">get_params</span> <span class="o">:</span>
  <span class="o">?</span><span class="n">deep</span><span class="o">:</span><span class="kt">bool</span> <span class="o">-&gt;</span>
  <span class="n">t</span> <span class="o">-&gt;</span>
  <span class="nn">Dict</span><span class="p">.</span><span class="n">t</span>
</code></pre></div>

<p>Get parameters for this estimator.</p>
<h4>Parameters</h4>
<details class="info" open="open"><summary>deep : bool, default=True</summary><p>If True, will return the parameters for this estimator and
contained subobjects that are estimators.</p>
</details>
<h4>Returns</h4>
<details class="info" open="open"><summary>params : mapping of string to any</summary><p>Parameter names mapped to their values.</p>
</details>
</details>
<h3 id="predict_2">predict<a class="headerlink" href="#predict_2" title="Permanent link">&para;</a></h3>
<details class="note" open="open"><summary>method</summary><div class="highlight"><pre><span></span><code><span class="k">val</span> <span class="n">predict</span> <span class="o">:</span>
  <span class="n">x</span><span class="o">:</span><span class="nn">Arr</span><span class="p">.</span><span class="n">t</span> <span class="o">-&gt;</span>
  <span class="n">t</span> <span class="o">-&gt;</span>
  <span class="nn">Arr</span><span class="p">.</span><span class="n">t</span>
</code></pre></div>

<p>Predict using the linear model.</p>
<h4>Parameters</h4>
<details class="info" open="open"><summary>X : array_like or sparse matrix, shape (n_samples, n_features)</summary><p>Samples.</p>
</details>
<h4>Returns</h4>
<details class="info" open="open"><summary>C : array, shape (n_samples,)</summary><p>Returns predicted values.</p>
</details>
</details>
<h3 id="score_2">score<a class="headerlink" href="#score_2" title="Permanent link">&para;</a></h3>
<details class="note" open="open"><summary>method</summary><div class="highlight"><pre><span></span><code><span class="k">val</span> <span class="n">score</span> <span class="o">:</span>
  <span class="o">?</span><span class="n">sample_weight</span><span class="o">:</span><span class="nn">Arr</span><span class="p">.</span><span class="n">t</span> <span class="o">-&gt;</span>
  <span class="n">x</span><span class="o">:</span><span class="nn">Arr</span><span class="p">.</span><span class="n">t</span> <span class="o">-&gt;</span>
  <span class="n">y</span><span class="o">:</span><span class="nn">Arr</span><span class="p">.</span><span class="n">t</span> <span class="o">-&gt;</span>
  <span class="n">t</span> <span class="o">-&gt;</span>
  <span class="kt">float</span>
</code></pre></div>

<p>Return the coefficient of determination R^2 of the prediction.</p>
<p>The coefficient R^2 is defined as (1 - u/v), where u is the residual
sum of squares ((y_true - y_pred) <strong> 2).sum() and v is the total
sum of squares ((y_true - y_true.mean()) </strong> 2).sum().
The best possible score is 1.0 and it can be negative (because the
model can be arbitrarily worse). A constant model that always
predicts the expected value of y, disregarding the input features,
would get a R^2 score of 0.0.</p>
<h4>Parameters</h4>
<details class="info" open="open"><summary>X : array-like of shape (n_samples, n_features)</summary><p>Test samples. For some estimators this may be a
precomputed kernel matrix or a list of generic objects instead,
shape = (n_samples, n_samples_fitted),
where n_samples_fitted is the number of
samples used in the fitting for the estimator.</p>
</details>
<details class="info" open="open"><summary>y : array-like of shape (n_samples,) or (n_samples, n_outputs)</summary><p>True values for X.</p>
</details>
<details class="info" open="open"><summary>sample_weight : array-like of shape (n_samples,), default=None</summary><p>Sample weights.</p>
</details>
<h4>Returns</h4>
<details class="info" open="open"><summary>score : float</summary><p>R^2 of self.predict(X) wrt. y.</p>
</details>
<h4>Notes</h4>
<p>The R2 score used when calling <code>score</code> on a regressor will use
<code>multioutput='uniform_average'</code> from version 0.23 to keep consistent</p>
<details class="info" open="open"><summary>with :func:<code>~sklearn.metrics.r2_score</code>. This will influence the</summary></details>
<p><code>score</code> method of all the multioutput regressors (except for
:class:<code>~sklearn.multioutput.MultiOutputRegressor</code>). To specify the
default value manually and avoid the warning, please either call
:func:<code>~sklearn.metrics.r2_score</code> directly or make a custom scorer with
:func:<code>~sklearn.metrics.make_scorer</code> (the built-in scorer <code>'r2'</code> uses
<code>multioutput='uniform_average'</code>).</p>
</details>
<h3 id="set_params_2">set_params<a class="headerlink" href="#set_params_2" title="Permanent link">&para;</a></h3>
<details class="note" open="open"><summary>method</summary><div class="highlight"><pre><span></span><code><span class="k">val</span> <span class="n">set_params</span> <span class="o">:</span>
  <span class="o">?</span><span class="n">params</span><span class="o">:(</span><span class="kt">string</span> <span class="o">*</span> <span class="nn">Py</span><span class="p">.</span><span class="nn">Object</span><span class="p">.</span><span class="n">t</span><span class="o">)</span> <span class="kt">list</span> <span class="o">-&gt;</span>
  <span class="n">t</span> <span class="o">-&gt;</span>
  <span class="n">t</span>
</code></pre></div>

<p>Set the parameters of this estimator.</p>
<p>The method works on simple estimators as well as on nested objects
(such as pipelines). The latter have parameters of the form
<code>&lt;component&gt;__&lt;parameter&gt;</code> so that it's possible to update each
component of a nested object.</p>
<h4>Parameters</h4>
<details class="info" open="open"><summary>**params : dict</summary><p>Estimator parameters.</p>
</details>
<h4>Returns</h4>
<details class="info" open="open"><summary>self : object</summary><p>Estimator instance.</p>
</details>
</details>
<h3 id="coef__2">coef_<a class="headerlink" href="#coef__2" title="Permanent link">&para;</a></h3>
<details class="note" open="open"><summary>attribute</summary><div class="highlight"><pre><span></span><code><span class="k">val</span> <span class="n">coef_</span> <span class="o">:</span> <span class="n">t</span> <span class="o">-&gt;</span> <span class="nn">Arr</span><span class="p">.</span><span class="n">t</span>
<span class="k">val</span> <span class="n">coef_opt</span> <span class="o">:</span> <span class="n">t</span> <span class="o">-&gt;</span> <span class="o">(</span><span class="nn">Arr</span><span class="p">.</span><span class="n">t</span><span class="o">)</span> <span class="n">option</span>
</code></pre></div>

<p>This attribute is documented in <code>create</code> above. The first version raises Not_found
if the attribute is None. The _opt version returns an option.</p>
</details>
<h3 id="sparse_coef_">sparse_coef_<a class="headerlink" href="#sparse_coef_" title="Permanent link">&para;</a></h3>
<details class="note" open="open"><summary>attribute</summary><div class="highlight"><pre><span></span><code><span class="k">val</span> <span class="n">sparse_coef_</span> <span class="o">:</span> <span class="n">t</span> <span class="o">-&gt;</span> <span class="nn">Py</span><span class="p">.</span><span class="nn">Object</span><span class="p">.</span><span class="n">t</span>
<span class="k">val</span> <span class="n">sparse_coef_opt</span> <span class="o">:</span> <span class="n">t</span> <span class="o">-&gt;</span> <span class="o">(</span><span class="nn">Py</span><span class="p">.</span><span class="nn">Object</span><span class="p">.</span><span class="n">t</span><span class="o">)</span> <span class="n">option</span>
</code></pre></div>

<p>This attribute is documented in <code>create</code> above. The first version raises Not_found
if the attribute is None. The _opt version returns an option.</p>
</details>
<h3 id="intercept__2">intercept_<a class="headerlink" href="#intercept__2" title="Permanent link">&para;</a></h3>
<details class="note" open="open"><summary>attribute</summary><div class="highlight"><pre><span></span><code><span class="k">val</span> <span class="n">intercept_</span> <span class="o">:</span> <span class="n">t</span> <span class="o">-&gt;</span> <span class="nn">Arr</span><span class="p">.</span><span class="n">t</span>
<span class="k">val</span> <span class="n">intercept_opt</span> <span class="o">:</span> <span class="n">t</span> <span class="o">-&gt;</span> <span class="o">(</span><span class="nn">Arr</span><span class="p">.</span><span class="n">t</span><span class="o">)</span> <span class="n">option</span>
</code></pre></div>

<p>This attribute is documented in <code>create</code> above. The first version raises Not_found
if the attribute is None. The _opt version returns an option.</p>
</details>
<h3 id="n_iter__1">n_iter_<a class="headerlink" href="#n_iter__1" title="Permanent link">&para;</a></h3>
<details class="note" open="open"><summary>attribute</summary><div class="highlight"><pre><span></span><code><span class="k">val</span> <span class="n">n_iter_</span> <span class="o">:</span> <span class="n">t</span> <span class="o">-&gt;</span> <span class="nn">Arr</span><span class="p">.</span><span class="n">t</span>
<span class="k">val</span> <span class="n">n_iter_opt</span> <span class="o">:</span> <span class="n">t</span> <span class="o">-&gt;</span> <span class="o">(</span><span class="nn">Arr</span><span class="p">.</span><span class="n">t</span><span class="o">)</span> <span class="n">option</span>
</code></pre></div>

<p>This attribute is documented in <code>create</code> above. The first version raises Not_found
if the attribute is None. The _opt version returns an option.</p>
</details>
<h3 id="to_string_2">to_string<a class="headerlink" href="#to_string_2" title="Permanent link">&para;</a></h3>
<details class="note" open="open"><summary>method</summary><div class="highlight"><pre><span></span><code><span class="k">val</span> <span class="n">to_string</span><span class="o">:</span> <span class="n">t</span> <span class="o">-&gt;</span> <span class="kt">string</span>
</code></pre></div>

<p>Print the object to a human-readable representation.</p>
</details>
<h3 id="show_2">show<a class="headerlink" href="#show_2" title="Permanent link">&para;</a></h3>
<details class="note" open="open"><summary>method</summary><div class="highlight"><pre><span></span><code><span class="k">val</span> <span class="n">show</span><span class="o">:</span> <span class="n">t</span> <span class="o">-&gt;</span> <span class="kt">string</span>
</code></pre></div>

<p>Print the object to a human-readable representation.</p>
</details>
<h3 id="pp_2">pp<a class="headerlink" href="#pp_2" title="Permanent link">&para;</a></h3>
<details class="note" open="open"><summary>method</summary><div class="highlight"><pre><span></span><code><span class="k">val</span> <span class="n">pp</span><span class="o">:</span> <span class="nn">Format</span><span class="p">.</span><span class="n">formatter</span> <span class="o">-&gt;</span> <span class="n">t</span> <span class="o">-&gt;</span> <span class="kt">unit</span>
</code></pre></div>

<p>Pretty-print the object to a formatter.</p>
</details>
<h2 id="module-sklearnlinear_modelelasticnetcv">module Sklearn.​Linear_model.​ElasticNetCV<a class="headerlink" href="#module-sklearnlinear_modelelasticnetcv" title="Permanent link">&para;</a></h2>
<div class="highlight"><pre><span></span><code><span class="k">type</span> <span class="n">t</span>
</code></pre></div>

<h3 id="create_3">create<a class="headerlink" href="#create_3" title="Permanent link">&para;</a></h3>
<details class="note" open="open"><summary>constructor and attributes</summary><div class="highlight"><pre><span></span><code><span class="k">val</span> <span class="n">create</span> <span class="o">:</span>
  <span class="o">?</span><span class="n">l1_ratio</span><span class="o">:[`</span><span class="nc">F</span> <span class="k">of</span> <span class="kt">float</span> <span class="o">|</span> <span class="o">`</span><span class="nc">Arr</span> <span class="k">of</span> <span class="nn">Arr</span><span class="p">.</span><span class="n">t</span><span class="o">]</span> <span class="o">-&gt;</span>
  <span class="o">?</span><span class="n">eps</span><span class="o">:</span><span class="kt">float</span> <span class="o">-&gt;</span>
  <span class="o">?</span><span class="n">n_alphas</span><span class="o">:</span><span class="kt">int</span> <span class="o">-&gt;</span>
  <span class="o">?</span><span class="n">alphas</span><span class="o">:</span><span class="nn">Arr</span><span class="p">.</span><span class="n">t</span> <span class="o">-&gt;</span>
  <span class="o">?</span><span class="n">fit_intercept</span><span class="o">:</span><span class="kt">bool</span> <span class="o">-&gt;</span>
  <span class="o">?</span><span class="n">normalize</span><span class="o">:</span><span class="kt">bool</span> <span class="o">-&gt;</span>
  <span class="o">?</span><span class="n">precompute</span><span class="o">:[`</span><span class="nc">Bool</span> <span class="k">of</span> <span class="kt">bool</span> <span class="o">|</span> <span class="o">`</span><span class="nc">Auto</span> <span class="o">|</span> <span class="o">`</span><span class="nc">Arr</span> <span class="k">of</span> <span class="nn">Arr</span><span class="p">.</span><span class="n">t</span><span class="o">]</span> <span class="o">-&gt;</span>
  <span class="o">?</span><span class="n">max_iter</span><span class="o">:</span><span class="kt">int</span> <span class="o">-&gt;</span>
  <span class="o">?</span><span class="n">tol</span><span class="o">:</span><span class="kt">float</span> <span class="o">-&gt;</span>
  <span class="o">?</span><span class="n">cv</span><span class="o">:[`</span><span class="nc">I</span> <span class="k">of</span> <span class="kt">int</span> <span class="o">|</span> <span class="o">`</span><span class="nc">CrossValGenerator</span> <span class="k">of</span> <span class="nn">Py</span><span class="p">.</span><span class="nn">Object</span><span class="p">.</span><span class="n">t</span> <span class="o">|</span> <span class="o">`</span><span class="nc">Arr</span> <span class="k">of</span> <span class="nn">Arr</span><span class="p">.</span><span class="n">t</span><span class="o">]</span> <span class="o">-&gt;</span>
  <span class="o">?</span><span class="n">copy_X</span><span class="o">:</span><span class="kt">bool</span> <span class="o">-&gt;</span>
  <span class="o">?</span><span class="n">verbose</span><span class="o">:</span><span class="kt">int</span> <span class="o">-&gt;</span>
  <span class="o">?</span><span class="n">n_jobs</span><span class="o">:</span><span class="kt">int</span> <span class="o">-&gt;</span>
  <span class="o">?</span><span class="n">positive</span><span class="o">:</span><span class="kt">bool</span> <span class="o">-&gt;</span>
  <span class="o">?</span><span class="n">random_state</span><span class="o">:</span><span class="kt">int</span> <span class="o">-&gt;</span>
  <span class="o">?</span><span class="n">selection</span><span class="o">:</span><span class="kt">string</span> <span class="o">-&gt;</span>
  <span class="kt">unit</span> <span class="o">-&gt;</span>
  <span class="n">t</span>
</code></pre></div>

<p>Elastic Net model with iterative fitting along a regularization path.</p>
<p>See glossary entry for :term:<code>cross-validation estimator</code>.</p>
<p>Read more in the :ref:<code>User Guide &lt;elastic_net&gt;</code>.</p>
<h4>Parameters</h4>
<details class="info" open="open"><summary>l1_ratio : float or array of floats, optional</summary><p>float between 0 and 1 passed to ElasticNet (scaling between
l1 and l2 penalties). For <code>l1_ratio = 0</code>
the penalty is an L2 penalty. For <code>l1_ratio = 1</code> it is an L1 penalty.
For <code>0 &lt; l1_ratio &lt; 1</code>, the penalty is a combination of L1 and L2
This parameter can be a list, in which case the different
values are tested by cross-validation and the one giving the best
prediction score is used. Note that a good choice of list of
values for l1_ratio is often to put more values close to 1
(i.e. Lasso) and less close to 0 (i.e. Ridge), as in <code>[.1, .5, .7,
.9, .95, .99, 1]</code></p>
</details>
<details class="info" open="open"><summary>eps : float, optional</summary><p>Length of the path. <code>eps=1e-3</code> means that
<code>alpha_min / alpha_max = 1e-3</code>.</p>
</details>
<details class="info" open="open"><summary>n_alphas : int, optional</summary><p>Number of alphas along the regularization path, used for each l1_ratio.</p>
</details>
<details class="info" open="open"><summary>alphas : numpy array, optional</summary><p>List of alphas where to compute the models.
If None alphas are set automatically</p>
</details>
<details class="info" open="open"><summary>fit_intercept : boolean</summary><p>whether to calculate the intercept for this model. If set
to false, no intercept will be used in calculations
(i.e. data is expected to be centered).</p>
</details>
<details class="info" open="open"><summary>normalize : boolean, optional, default False</summary><p>This parameter is ignored when <code>fit_intercept</code> is set to False.
If True, the regressors X will be normalized before regression by
subtracting the mean and dividing by the l2-norm.
If you wish to standardize, please use
:class:<code>sklearn.preprocessing.StandardScaler</code> before calling <code>fit</code>
on an estimator with <code>normalize=False</code>.</p>
</details>
<details class="info" open="open"><summary>precompute : True | False | 'auto' | array-like</summary><p>Whether to use a precomputed Gram matrix to speed up
calculations. If set to <code>'auto'</code> let us decide. The Gram
matrix can also be passed as argument.</p>
</details>
<details class="info" open="open"><summary>max_iter : int, optional</summary><p>The maximum number of iterations</p>
</details>
<details class="info" open="open"><summary>tol : float, optional</summary><p>The tolerance for the optimization: if the updates are
smaller than <code>tol</code>, the optimization code checks the
dual gap for optimality and continues until it is smaller
than <code>tol</code>.</p>
</details>
<details class="info" open="open"><summary>cv : int, cross-validation generator or an iterable, optional</summary><p>Determines the cross-validation splitting strategy.
Possible inputs for cv are:</p>
<ul>
<li>None, to use the default 5-fold cross-validation,</li>
<li>integer, to specify the number of folds.</li>
<li>:term:<code>CV splitter</code>,</li>
<li>An iterable yielding (train, test) splits as arrays of indices.</li>
</ul>
<p>For integer/None inputs, :class:<code>KFold</code> is used.</p>
</details>
<details class="info" open="open"><summary>Refer :ref:<code>User Guide &lt;cross_validation&gt;</code> for the various</summary><p>cross-validation strategies that can be used here.</p>
<p>.. versionchanged:: 0.22
    <code>cv</code> default value if None changed from 3-fold to 5-fold.</p>
</details>
<details class="info" open="open"><summary>copy_X : boolean, optional, default True</summary><p>If <code>True</code>, X will be copied; else, it may be overwritten.</p>
</details>
<details class="info" open="open"><summary>verbose : bool or integer</summary><p>Amount of verbosity.</p>
</details>
<details class="info" open="open"><summary>n_jobs : int or None, optional (default=None)</summary><p>Number of CPUs to use during the cross validation.
<code>None</code> means 1 unless in a :obj:<code>joblib.parallel_backend</code> context.
<code>-1</code> means using all processors. See :term:<code>Glossary &lt;n_jobs&gt;</code>
for more details.</p>
</details>
<details class="info" open="open"><summary>positive : bool, optional</summary><p>When set to <code>True</code>, forces the coefficients to be positive.</p>
</details>
<details class="info" open="open"><summary>random_state : int, RandomState instance or None, optional, default None</summary><p>The seed of the pseudo random number generator that selects a random
feature to update.  If int, random_state is the seed used by the random
number generator; If RandomState instance, random_state is the random
number generator; If None, the random number generator is the
RandomState instance used by <code>np.random</code>. Used when <code>selection</code> ==
'random'.</p>
</details>
<details class="info" open="open"><summary>selection : str, default 'cyclic'</summary><p>If set to 'random', a random coefficient is updated every iteration
rather than looping over features sequentially by default. This
(setting to 'random') often leads to significantly faster convergence
especially when tol is higher than 1e-4.</p>
</details>
<h4>Attributes</h4>
<details class="info" open="open"><summary>alpha_ : float</summary><p>The amount of penalization chosen by cross validation</p>
</details>
<details class="info" open="open"><summary>l1_ratio_ : float</summary><p>The compromise between l1 and l2 penalization chosen by
cross validation</p>
</details>
<details class="info" open="open"><summary>coef_ : array, shape (n_features,) | (n_targets, n_features)</summary><p>Parameter vector (w in the cost function formula),</p>
</details>
<details class="info" open="open"><summary>intercept_ : float | array, shape (n_targets, n_features)</summary><p>Independent term in the decision function.</p>
</details>
<details class="info" open="open"><summary>mse_path_ : array, shape (n_l1_ratio, n_alpha, n_folds)</summary><p>Mean square error for the test set on each fold, varying l1_ratio and
alpha.</p>
</details>
<details class="info" open="open"><summary>alphas_ : numpy array, shape (n_alphas,) or (n_l1_ratio, n_alphas)</summary><p>The grid of alphas used for fitting, for each l1_ratio.</p>
</details>
<details class="info" open="open"><summary>n_iter_ : int</summary><p>number of iterations run by the coordinate descent solver to reach
the specified tolerance for the optimal alpha.</p>
</details>
<h4>Examples</h4>
<div class="highlight"><pre><span></span><code><span class="o">&gt;&gt;&gt;</span> <span class="kn">from</span> <span class="nn">sklearn.linear_model</span> <span class="kn">import</span> <span class="n">ElasticNetCV</span>
<span class="o">&gt;&gt;&gt;</span> <span class="kn">from</span> <span class="nn">sklearn.datasets</span> <span class="kn">import</span> <span class="n">make_regression</span>
</code></pre></div>

<div class="highlight"><pre><span></span><code><span class="o">&gt;&gt;&gt;</span> <span class="n">X</span><span class="p">,</span> <span class="n">y</span> <span class="o">=</span> <span class="n">make_regression</span><span class="p">(</span><span class="n">n_features</span><span class="o">=</span><span class="mi">2</span><span class="p">,</span> <span class="n">random_state</span><span class="o">=</span><span class="mi">0</span><span class="p">)</span>
<span class="o">&gt;&gt;&gt;</span> <span class="n">regr</span> <span class="o">=</span> <span class="n">ElasticNetCV</span><span class="p">(</span><span class="n">cv</span><span class="o">=</span><span class="mi">5</span><span class="p">,</span> <span class="n">random_state</span><span class="o">=</span><span class="mi">0</span><span class="p">)</span>
<span class="o">&gt;&gt;&gt;</span> <span class="n">regr</span><span class="o">.</span><span class="n">fit</span><span class="p">(</span><span class="n">X</span><span class="p">,</span> <span class="n">y</span><span class="p">)</span>
<span class="n">ElasticNetCV</span><span class="p">(</span><span class="n">cv</span><span class="o">=</span><span class="mi">5</span><span class="p">,</span> <span class="n">random_state</span><span class="o">=</span><span class="mi">0</span><span class="p">)</span>
<span class="o">&gt;&gt;&gt;</span> <span class="nb">print</span><span class="p">(</span><span class="n">regr</span><span class="o">.</span><span class="n">alpha_</span><span class="p">)</span>
<span class="mf">0.199</span><span class="o">...</span>
<span class="o">&gt;&gt;&gt;</span> <span class="nb">print</span><span class="p">(</span><span class="n">regr</span><span class="o">.</span><span class="n">intercept_</span><span class="p">)</span>
<span class="mf">0.398</span><span class="o">...</span>
<span class="o">&gt;&gt;&gt;</span> <span class="nb">print</span><span class="p">(</span><span class="n">regr</span><span class="o">.</span><span class="n">predict</span><span class="p">([[</span><span class="mi">0</span><span class="p">,</span> <span class="mi">0</span><span class="p">]]))</span>
<span class="p">[</span><span class="mf">0.398</span><span class="o">...</span><span class="p">]</span>
</code></pre></div>

<h4>Notes</h4>
<p>For an example, see
:ref:<code>examples/linear_model/plot_lasso_model_selection.py
&lt;sphx_glr_auto_examples_linear_model_plot_lasso_model_selection.py&gt;</code>.</p>
<p>To avoid unnecessary memory duplication the X argument of the fit method
should be directly passed as a Fortran-contiguous numpy array.</p>
<p>The parameter l1_ratio corresponds to alpha in the glmnet R package
while alpha corresponds to the lambda parameter in glmnet.
More specifically, the optimization objective is::</p>
<div class="codehilite"><pre><span></span><code>1 / (2 * n_samples) * ||y - Xw||^2_2
+ alpha * l1_ratio * ||w||_1
+ 0.5 * alpha * (1 - l1_ratio) * ||w||^2_2
</code></pre></div>


<p>If you are interested in controlling the L1 and L2 penalty
separately, keep in mind that this is equivalent to::</p>
<div class="codehilite"><pre><span></span><code>a * L1 + b * L2
</code></pre></div>


<details class="info" open="open"><summary>for::</summary><p>alpha = a + b and l1_ratio = a / (a + b).</p>
</details>
<h4>See also</h4>
<p>enet_path
ElasticNet</p>
</details>
<h3 id="fit_3">fit<a class="headerlink" href="#fit_3" title="Permanent link">&para;</a></h3>
<details class="note" open="open"><summary>method</summary><div class="highlight"><pre><span></span><code><span class="k">val</span> <span class="n">fit</span> <span class="o">:</span>
  <span class="n">x</span><span class="o">:</span><span class="nn">Arr</span><span class="p">.</span><span class="n">t</span> <span class="o">-&gt;</span>
  <span class="n">y</span><span class="o">:</span><span class="nn">Arr</span><span class="p">.</span><span class="n">t</span> <span class="o">-&gt;</span>
  <span class="n">t</span> <span class="o">-&gt;</span>
  <span class="n">t</span>
</code></pre></div>

<p>Fit linear model with coordinate descent</p>
<p>Fit is on grid of alphas and best alpha estimated by cross-validation.</p>
<h4>Parameters</h4>
<details class="info" open="open"><summary>X : {array-like}, shape (n_samples, n_features)</summary><p>Training data. Pass directly as Fortran-contiguous data
to avoid unnecessary memory duplication. If y is mono-output,
X can be sparse.</p>
</details>
<details class="info" open="open"><summary>y : array-like, shape (n_samples,) or (n_samples, n_targets)</summary><p>Target values</p>
</details>
</details>
<h3 id="get_params_3">get_params<a class="headerlink" href="#get_params_3" title="Permanent link">&para;</a></h3>
<details class="note" open="open"><summary>method</summary><div class="highlight"><pre><span></span><code><span class="k">val</span> <span class="n">get_params</span> <span class="o">:</span>
  <span class="o">?</span><span class="n">deep</span><span class="o">:</span><span class="kt">bool</span> <span class="o">-&gt;</span>
  <span class="n">t</span> <span class="o">-&gt;</span>
  <span class="nn">Dict</span><span class="p">.</span><span class="n">t</span>
</code></pre></div>

<p>Get parameters for this estimator.</p>
<h4>Parameters</h4>
<details class="info" open="open"><summary>deep : bool, default=True</summary><p>If True, will return the parameters for this estimator and
contained subobjects that are estimators.</p>
</details>
<h4>Returns</h4>
<details class="info" open="open"><summary>params : mapping of string to any</summary><p>Parameter names mapped to their values.</p>
</details>
</details>
<h3 id="predict_3">predict<a class="headerlink" href="#predict_3" title="Permanent link">&para;</a></h3>
<details class="note" open="open"><summary>method</summary><div class="highlight"><pre><span></span><code><span class="k">val</span> <span class="n">predict</span> <span class="o">:</span>
  <span class="n">x</span><span class="o">:</span><span class="nn">Arr</span><span class="p">.</span><span class="n">t</span> <span class="o">-&gt;</span>
  <span class="n">t</span> <span class="o">-&gt;</span>
  <span class="nn">Arr</span><span class="p">.</span><span class="n">t</span>
</code></pre></div>

<p>Predict using the linear model.</p>
<h4>Parameters</h4>
<details class="info" open="open"><summary>X : array_like or sparse matrix, shape (n_samples, n_features)</summary><p>Samples.</p>
</details>
<h4>Returns</h4>
<details class="info" open="open"><summary>C : array, shape (n_samples,)</summary><p>Returns predicted values.</p>
</details>
</details>
<h3 id="score_3">score<a class="headerlink" href="#score_3" title="Permanent link">&para;</a></h3>
<details class="note" open="open"><summary>method</summary><div class="highlight"><pre><span></span><code><span class="k">val</span> <span class="n">score</span> <span class="o">:</span>
  <span class="o">?</span><span class="n">sample_weight</span><span class="o">:</span><span class="nn">Arr</span><span class="p">.</span><span class="n">t</span> <span class="o">-&gt;</span>
  <span class="n">x</span><span class="o">:</span><span class="nn">Arr</span><span class="p">.</span><span class="n">t</span> <span class="o">-&gt;</span>
  <span class="n">y</span><span class="o">:</span><span class="nn">Arr</span><span class="p">.</span><span class="n">t</span> <span class="o">-&gt;</span>
  <span class="n">t</span> <span class="o">-&gt;</span>
  <span class="kt">float</span>
</code></pre></div>

<p>Return the coefficient of determination R^2 of the prediction.</p>
<p>The coefficient R^2 is defined as (1 - u/v), where u is the residual
sum of squares ((y_true - y_pred) <strong> 2).sum() and v is the total
sum of squares ((y_true - y_true.mean()) </strong> 2).sum().
The best possible score is 1.0 and it can be negative (because the
model can be arbitrarily worse). A constant model that always
predicts the expected value of y, disregarding the input features,
would get a R^2 score of 0.0.</p>
<h4>Parameters</h4>
<details class="info" open="open"><summary>X : array-like of shape (n_samples, n_features)</summary><p>Test samples. For some estimators this may be a
precomputed kernel matrix or a list of generic objects instead,
shape = (n_samples, n_samples_fitted),
where n_samples_fitted is the number of
samples used in the fitting for the estimator.</p>
</details>
<details class="info" open="open"><summary>y : array-like of shape (n_samples,) or (n_samples, n_outputs)</summary><p>True values for X.</p>
</details>
<details class="info" open="open"><summary>sample_weight : array-like of shape (n_samples,), default=None</summary><p>Sample weights.</p>
</details>
<h4>Returns</h4>
<details class="info" open="open"><summary>score : float</summary><p>R^2 of self.predict(X) wrt. y.</p>
</details>
<h4>Notes</h4>
<p>The R2 score used when calling <code>score</code> on a regressor will use
<code>multioutput='uniform_average'</code> from version 0.23 to keep consistent</p>
<details class="info" open="open"><summary>with :func:<code>~sklearn.metrics.r2_score</code>. This will influence the</summary></details>
<p><code>score</code> method of all the multioutput regressors (except for
:class:<code>~sklearn.multioutput.MultiOutputRegressor</code>). To specify the
default value manually and avoid the warning, please either call
:func:<code>~sklearn.metrics.r2_score</code> directly or make a custom scorer with
:func:<code>~sklearn.metrics.make_scorer</code> (the built-in scorer <code>'r2'</code> uses
<code>multioutput='uniform_average'</code>).</p>
</details>
<h3 id="set_params_3">set_params<a class="headerlink" href="#set_params_3" title="Permanent link">&para;</a></h3>
<details class="note" open="open"><summary>method</summary><div class="highlight"><pre><span></span><code><span class="k">val</span> <span class="n">set_params</span> <span class="o">:</span>
  <span class="o">?</span><span class="n">params</span><span class="o">:(</span><span class="kt">string</span> <span class="o">*</span> <span class="nn">Py</span><span class="p">.</span><span class="nn">Object</span><span class="p">.</span><span class="n">t</span><span class="o">)</span> <span class="kt">list</span> <span class="o">-&gt;</span>
  <span class="n">t</span> <span class="o">-&gt;</span>
  <span class="n">t</span>
</code></pre></div>

<p>Set the parameters of this estimator.</p>
<p>The method works on simple estimators as well as on nested objects
(such as pipelines). The latter have parameters of the form
<code>&lt;component&gt;__&lt;parameter&gt;</code> so that it's possible to update each
component of a nested object.</p>
<h4>Parameters</h4>
<details class="info" open="open"><summary>**params : dict</summary><p>Estimator parameters.</p>
</details>
<h4>Returns</h4>
<details class="info" open="open"><summary>self : object</summary><p>Estimator instance.</p>
</details>
</details>
<h3 id="alpha__2">alpha_<a class="headerlink" href="#alpha__2" title="Permanent link">&para;</a></h3>
<details class="note" open="open"><summary>attribute</summary><div class="highlight"><pre><span></span><code><span class="k">val</span> <span class="n">alpha_</span> <span class="o">:</span> <span class="n">t</span> <span class="o">-&gt;</span> <span class="kt">float</span>
<span class="k">val</span> <span class="n">alpha_opt</span> <span class="o">:</span> <span class="n">t</span> <span class="o">-&gt;</span> <span class="o">(</span><span class="kt">float</span><span class="o">)</span> <span class="n">option</span>
</code></pre></div>

<p>This attribute is documented in <code>create</code> above. The first version raises Not_found
if the attribute is None. The _opt version returns an option.</p>
</details>
<h3 id="l1_ratio_">l1_ratio_<a class="headerlink" href="#l1_ratio_" title="Permanent link">&para;</a></h3>
<details class="note" open="open"><summary>attribute</summary><div class="highlight"><pre><span></span><code><span class="k">val</span> <span class="n">l1_ratio_</span> <span class="o">:</span> <span class="n">t</span> <span class="o">-&gt;</span> <span class="kt">float</span>
<span class="k">val</span> <span class="n">l1_ratio_opt</span> <span class="o">:</span> <span class="n">t</span> <span class="o">-&gt;</span> <span class="o">(</span><span class="kt">float</span><span class="o">)</span> <span class="n">option</span>
</code></pre></div>

<p>This attribute is documented in <code>create</code> above. The first version raises Not_found
if the attribute is None. The _opt version returns an option.</p>
</details>
<h3 id="coef__3">coef_<a class="headerlink" href="#coef__3" title="Permanent link">&para;</a></h3>
<details class="note" open="open"><summary>attribute</summary><div class="highlight"><pre><span></span><code><span class="k">val</span> <span class="n">coef_</span> <span class="o">:</span> <span class="n">t</span> <span class="o">-&gt;</span> <span class="nn">Arr</span><span class="p">.</span><span class="n">t</span>
<span class="k">val</span> <span class="n">coef_opt</span> <span class="o">:</span> <span class="n">t</span> <span class="o">-&gt;</span> <span class="o">(</span><span class="nn">Arr</span><span class="p">.</span><span class="n">t</span><span class="o">)</span> <span class="n">option</span>
</code></pre></div>

<p>This attribute is documented in <code>create</code> above. The first version raises Not_found
if the attribute is None. The _opt version returns an option.</p>
</details>
<h3 id="intercept__3">intercept_<a class="headerlink" href="#intercept__3" title="Permanent link">&para;</a></h3>
<details class="note" open="open"><summary>attribute</summary><div class="highlight"><pre><span></span><code><span class="k">val</span> <span class="n">intercept_</span> <span class="o">:</span> <span class="n">t</span> <span class="o">-&gt;</span> <span class="nn">Arr</span><span class="p">.</span><span class="n">t</span>
<span class="k">val</span> <span class="n">intercept_opt</span> <span class="o">:</span> <span class="n">t</span> <span class="o">-&gt;</span> <span class="o">(</span><span class="nn">Arr</span><span class="p">.</span><span class="n">t</span><span class="o">)</span> <span class="n">option</span>
</code></pre></div>

<p>This attribute is documented in <code>create</code> above. The first version raises Not_found
if the attribute is None. The _opt version returns an option.</p>
</details>
<h3 id="mse_path_">mse_path_<a class="headerlink" href="#mse_path_" title="Permanent link">&para;</a></h3>
<details class="note" open="open"><summary>attribute</summary><div class="highlight"><pre><span></span><code><span class="k">val</span> <span class="n">mse_path_</span> <span class="o">:</span> <span class="n">t</span> <span class="o">-&gt;</span> <span class="nn">Arr</span><span class="p">.</span><span class="n">t</span>
<span class="k">val</span> <span class="n">mse_path_opt</span> <span class="o">:</span> <span class="n">t</span> <span class="o">-&gt;</span> <span class="o">(</span><span class="nn">Arr</span><span class="p">.</span><span class="n">t</span><span class="o">)</span> <span class="n">option</span>
</code></pre></div>

<p>This attribute is documented in <code>create</code> above. The first version raises Not_found
if the attribute is None. The _opt version returns an option.</p>
</details>
<h3 id="alphas_">alphas_<a class="headerlink" href="#alphas_" title="Permanent link">&para;</a></h3>
<details class="note" open="open"><summary>attribute</summary><div class="highlight"><pre><span></span><code><span class="k">val</span> <span class="n">alphas_</span> <span class="o">:</span> <span class="n">t</span> <span class="o">-&gt;</span> <span class="nn">Arr</span><span class="p">.</span><span class="n">t</span>
<span class="k">val</span> <span class="n">alphas_opt</span> <span class="o">:</span> <span class="n">t</span> <span class="o">-&gt;</span> <span class="o">(</span><span class="nn">Arr</span><span class="p">.</span><span class="n">t</span><span class="o">)</span> <span class="n">option</span>
</code></pre></div>

<p>This attribute is documented in <code>create</code> above. The first version raises Not_found
if the attribute is None. The _opt version returns an option.</p>
</details>
<h3 id="n_iter__2">n_iter_<a class="headerlink" href="#n_iter__2" title="Permanent link">&para;</a></h3>
<details class="note" open="open"><summary>attribute</summary><div class="highlight"><pre><span></span><code><span class="k">val</span> <span class="n">n_iter_</span> <span class="o">:</span> <span class="n">t</span> <span class="o">-&gt;</span> <span class="kt">int</span>
<span class="k">val</span> <span class="n">n_iter_opt</span> <span class="o">:</span> <span class="n">t</span> <span class="o">-&gt;</span> <span class="o">(</span><span class="kt">int</span><span class="o">)</span> <span class="n">option</span>
</code></pre></div>

<p>This attribute is documented in <code>create</code> above. The first version raises Not_found
if the attribute is None. The _opt version returns an option.</p>
</details>
<h3 id="to_string_3">to_string<a class="headerlink" href="#to_string_3" title="Permanent link">&para;</a></h3>
<details class="note" open="open"><summary>method</summary><div class="highlight"><pre><span></span><code><span class="k">val</span> <span class="n">to_string</span><span class="o">:</span> <span class="n">t</span> <span class="o">-&gt;</span> <span class="kt">string</span>
</code></pre></div>

<p>Print the object to a human-readable representation.</p>
</details>
<h3 id="show_3">show<a class="headerlink" href="#show_3" title="Permanent link">&para;</a></h3>
<details class="note" open="open"><summary>method</summary><div class="highlight"><pre><span></span><code><span class="k">val</span> <span class="n">show</span><span class="o">:</span> <span class="n">t</span> <span class="o">-&gt;</span> <span class="kt">string</span>
</code></pre></div>

<p>Print the object to a human-readable representation.</p>
</details>
<h3 id="pp_3">pp<a class="headerlink" href="#pp_3" title="Permanent link">&para;</a></h3>
<details class="note" open="open"><summary>method</summary><div class="highlight"><pre><span></span><code><span class="k">val</span> <span class="n">pp</span><span class="o">:</span> <span class="nn">Format</span><span class="p">.</span><span class="n">formatter</span> <span class="o">-&gt;</span> <span class="n">t</span> <span class="o">-&gt;</span> <span class="kt">unit</span>
</code></pre></div>

<p>Pretty-print the object to a formatter.</p>
</details>
<h2 id="module-sklearnlinear_modelhuberregressor">module Sklearn.​Linear_model.​HuberRegressor<a class="headerlink" href="#module-sklearnlinear_modelhuberregressor" title="Permanent link">&para;</a></h2>
<div class="highlight"><pre><span></span><code><span class="k">type</span> <span class="n">t</span>
</code></pre></div>

<h3 id="create_4">create<a class="headerlink" href="#create_4" title="Permanent link">&para;</a></h3>
<details class="note" open="open"><summary>constructor and attributes</summary><div class="highlight"><pre><span></span><code><span class="k">val</span> <span class="n">create</span> <span class="o">:</span>
  <span class="o">?</span><span class="n">epsilon</span><span class="o">:</span><span class="kt">float</span> <span class="o">-&gt;</span>
  <span class="o">?</span><span class="n">max_iter</span><span class="o">:</span><span class="kt">int</span> <span class="o">-&gt;</span>
  <span class="o">?</span><span class="n">alpha</span><span class="o">:</span><span class="kt">float</span> <span class="o">-&gt;</span>
  <span class="o">?</span><span class="n">warm_start</span><span class="o">:</span><span class="kt">bool</span> <span class="o">-&gt;</span>
  <span class="o">?</span><span class="n">fit_intercept</span><span class="o">:</span><span class="kt">bool</span> <span class="o">-&gt;</span>
  <span class="o">?</span><span class="n">tol</span><span class="o">:</span><span class="kt">float</span> <span class="o">-&gt;</span>
  <span class="kt">unit</span> <span class="o">-&gt;</span>
  <span class="n">t</span>
</code></pre></div>

<p>Linear regression model that is robust to outliers.</p>
<p>The Huber Regressor optimizes the squared loss for the samples where
<code>|(y - X'w) / sigma| &lt; epsilon</code> and the absolute loss for the samples
where <code>|(y - X'w) / sigma| &gt; epsilon</code>, where w and sigma are parameters
to be optimized. The parameter sigma makes sure that if y is scaled up
or down by a certain factor, one does not need to rescale epsilon to
achieve the same robustness. Note that this does not take into account
the fact that the different features of X may be of different scales.</p>
<p>This makes sure that the loss function is not heavily influenced by the
outliers while not completely ignoring their effect.</p>
<p>Read more in the :ref:<code>User Guide &lt;huber_regression&gt;</code></p>
<p>.. versionadded:: 0.18</p>
<h4>Parameters</h4>
<details class="info" open="open"><summary>epsilon : float, greater than 1.0, default 1.35</summary><p>The parameter epsilon controls the number of samples that should be
classified as outliers. The smaller the epsilon, the more robust it is
to outliers.</p>
</details>
<details class="info" open="open"><summary>max_iter : int, default 100</summary><p>Maximum number of iterations that
<code>scipy.optimize.minimize(method="L-BFGS-B")</code> should run for.</p>
</details>
<details class="info" open="open"><summary>alpha : float, default 0.0001</summary><p>Regularization parameter.</p>
</details>
<details class="info" open="open"><summary>warm_start : bool, default False</summary><p>This is useful if the stored attributes of a previously used model
has to be reused. If set to False, then the coefficients will
be rewritten for every call to fit.</p>
</details>
<details class="info" open="open"><summary>See :term:<code>the Glossary &lt;warm_start&gt;</code>.</summary></details>
<details class="info" open="open"><summary>fit_intercept : bool, default True</summary><p>Whether or not to fit the intercept. This can be set to False
if the data is already centered around the origin.</p>
</details>
<details class="info" open="open"><summary>tol : float, default 1e-5</summary><p>The iteration will stop when
<code>max{ |proj g_i | i = 1, ..., n}</code> &lt;= <code>tol</code>
where pg_i is the i-th component of the projected gradient.</p>
</details>
<h4>Attributes</h4>
<details class="info" open="open"><summary>coef_ : array, shape (n_features,)</summary><p>Features got by optimizing the Huber loss.</p>
</details>
<details class="info" open="open"><summary>intercept_ : float</summary><p>Bias.</p>
</details>
<details class="info" open="open"><summary>scale_ : float</summary><p>The value by which <code>|y - X'w - c|</code> is scaled down.</p>
</details>
<details class="info" open="open"><summary>n_iter_ : int</summary><p>Number of iterations that
<code>scipy.optimize.minimize(method="L-BFGS-B")</code> has run for.</p>
<p>.. versionchanged:: 0.20</p>
<div class="codehilite"><pre><span></span><code>In SciPy &lt;= 1.0.0 the number of lbfgs iterations may exceed
``max_iter``. ``n_iter_`` will now report at most ``max_iter``.
</code></pre></div>


</details>
<details class="info" open="open"><summary>outliers_ : array, shape (n_samples,)</summary><p>A boolean mask which is set to True where the samples are identified
as outliers.</p>
</details>
<h4>Examples</h4>
<div class="highlight"><pre><span></span><code><span class="o">&gt;&gt;&gt;</span> <span class="kn">import</span> <span class="nn">numpy</span> <span class="k">as</span> <span class="nn">np</span>
<span class="o">&gt;&gt;&gt;</span> <span class="kn">from</span> <span class="nn">sklearn.linear_model</span> <span class="kn">import</span> <span class="n">HuberRegressor</span><span class="p">,</span> <span class="n">LinearRegression</span>
<span class="o">&gt;&gt;&gt;</span> <span class="kn">from</span> <span class="nn">sklearn.datasets</span> <span class="kn">import</span> <span class="n">make_regression</span>
<span class="o">&gt;&gt;&gt;</span> <span class="n">rng</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">random</span><span class="o">.</span><span class="n">RandomState</span><span class="p">(</span><span class="mi">0</span><span class="p">)</span>
<span class="o">&gt;&gt;&gt;</span> <span class="n">X</span><span class="p">,</span> <span class="n">y</span><span class="p">,</span> <span class="n">coef</span> <span class="o">=</span> <span class="n">make_regression</span><span class="p">(</span>
<span class="o">...</span>     <span class="n">n_samples</span><span class="o">=</span><span class="mi">200</span><span class="p">,</span> <span class="n">n_features</span><span class="o">=</span><span class="mi">2</span><span class="p">,</span> <span class="n">noise</span><span class="o">=</span><span class="mf">4.0</span><span class="p">,</span> <span class="n">coef</span><span class="o">=</span><span class="kc">True</span><span class="p">,</span> <span class="n">random_state</span><span class="o">=</span><span class="mi">0</span><span class="p">)</span>
<span class="o">&gt;&gt;&gt;</span> <span class="n">X</span><span class="p">[:</span><span class="mi">4</span><span class="p">]</span> <span class="o">=</span> <span class="n">rng</span><span class="o">.</span><span class="n">uniform</span><span class="p">(</span><span class="mi">10</span><span class="p">,</span> <span class="mi">20</span><span class="p">,</span> <span class="p">(</span><span class="mi">4</span><span class="p">,</span> <span class="mi">2</span><span class="p">))</span>
<span class="o">&gt;&gt;&gt;</span> <span class="n">y</span><span class="p">[:</span><span class="mi">4</span><span class="p">]</span> <span class="o">=</span> <span class="n">rng</span><span class="o">.</span><span class="n">uniform</span><span class="p">(</span><span class="mi">10</span><span class="p">,</span> <span class="mi">20</span><span class="p">,</span> <span class="mi">4</span><span class="p">)</span>
<span class="o">&gt;&gt;&gt;</span> <span class="n">huber</span> <span class="o">=</span> <span class="n">HuberRegressor</span><span class="p">()</span><span class="o">.</span><span class="n">fit</span><span class="p">(</span><span class="n">X</span><span class="p">,</span> <span class="n">y</span><span class="p">)</span>
<span class="o">&gt;&gt;&gt;</span> <span class="n">huber</span><span class="o">.</span><span class="n">score</span><span class="p">(</span><span class="n">X</span><span class="p">,</span> <span class="n">y</span><span class="p">)</span>
<span class="o">-</span><span class="mf">7.284608623514573</span>
<span class="o">&gt;&gt;&gt;</span> <span class="n">huber</span><span class="o">.</span><span class="n">predict</span><span class="p">(</span><span class="n">X</span><span class="p">[:</span><span class="mi">1</span><span class="p">,])</span>
<span class="n">array</span><span class="p">([</span><span class="mf">806.7200</span><span class="o">...</span><span class="p">])</span>
<span class="o">&gt;&gt;&gt;</span> <span class="n">linear</span> <span class="o">=</span> <span class="n">LinearRegression</span><span class="p">()</span><span class="o">.</span><span class="n">fit</span><span class="p">(</span><span class="n">X</span><span class="p">,</span> <span class="n">y</span><span class="p">)</span>
<span class="o">&gt;&gt;&gt;</span> <span class="nb">print</span><span class="p">(</span><span class="s2">&quot;True coefficients:&quot;</span><span class="p">,</span> <span class="n">coef</span><span class="p">)</span>
<span class="kc">True</span> <span class="n">coefficients</span><span class="p">:</span> <span class="p">[</span><span class="mf">20.4923</span><span class="o">...</span>  <span class="mf">34.1698</span><span class="o">...</span><span class="p">]</span>
<span class="o">&gt;&gt;&gt;</span> <span class="nb">print</span><span class="p">(</span><span class="s2">&quot;Huber coefficients:&quot;</span><span class="p">,</span> <span class="n">huber</span><span class="o">.</span><span class="n">coef_</span><span class="p">)</span>
<span class="n">Huber</span> <span class="n">coefficients</span><span class="p">:</span> <span class="p">[</span><span class="mf">17.7906</span><span class="o">...</span> <span class="mf">31.0106</span><span class="o">...</span><span class="p">]</span>
<span class="o">&gt;&gt;&gt;</span> <span class="nb">print</span><span class="p">(</span><span class="s2">&quot;Linear Regression coefficients:&quot;</span><span class="p">,</span> <span class="n">linear</span><span class="o">.</span><span class="n">coef_</span><span class="p">)</span>
<span class="n">Linear</span> <span class="n">Regression</span> <span class="n">coefficients</span><span class="p">:</span> <span class="p">[</span><span class="o">-</span><span class="mf">1.9221</span><span class="o">...</span>  <span class="mf">7.0226</span><span class="o">...</span><span class="p">]</span>
</code></pre></div>

<h4>References</h4>
<p>.. [1] Peter J. Huber, Elvezio M. Ronchetti, Robust Statistics
       Concomitant scale estimates, pg 172
.. [2] Art B. Owen (2006), A robust hybrid of lasso and ridge regression.</p>
<details class="info" open="open"><summary>https://statweb.stanford.edu/~owen/reports/hhu.pdf</summary></details>
</details>
<h3 id="fit_4">fit<a class="headerlink" href="#fit_4" title="Permanent link">&para;</a></h3>
<details class="note" open="open"><summary>method</summary><div class="highlight"><pre><span></span><code><span class="k">val</span> <span class="n">fit</span> <span class="o">:</span>
  <span class="o">?</span><span class="n">sample_weight</span><span class="o">:</span><span class="nn">Arr</span><span class="p">.</span><span class="n">t</span> <span class="o">-&gt;</span>
  <span class="n">x</span><span class="o">:</span><span class="nn">Arr</span><span class="p">.</span><span class="n">t</span> <span class="o">-&gt;</span>
  <span class="n">y</span><span class="o">:</span><span class="nn">Arr</span><span class="p">.</span><span class="n">t</span> <span class="o">-&gt;</span>
  <span class="n">t</span> <span class="o">-&gt;</span>
  <span class="n">t</span>
</code></pre></div>

<p>Fit the model according to the given training data.</p>
<h4>Parameters</h4>
<details class="info" open="open"><summary>X : array-like, shape (n_samples, n_features)</summary><p>Training vector, where n_samples in the number of samples and
n_features is the number of features.</p>
</details>
<details class="info" open="open"><summary>y : array-like, shape (n_samples,)</summary><p>Target vector relative to X.</p>
</details>
<details class="info" open="open"><summary>sample_weight : array-like, shape (n_samples,)</summary><p>Weight given to each sample.</p>
</details>
<h4>Returns</h4>
<details class="info" open="open"><summary>self : object</summary></details>
</details>
<h3 id="get_params_4">get_params<a class="headerlink" href="#get_params_4" title="Permanent link">&para;</a></h3>
<details class="note" open="open"><summary>method</summary><div class="highlight"><pre><span></span><code><span class="k">val</span> <span class="n">get_params</span> <span class="o">:</span>
  <span class="o">?</span><span class="n">deep</span><span class="o">:</span><span class="kt">bool</span> <span class="o">-&gt;</span>
  <span class="n">t</span> <span class="o">-&gt;</span>
  <span class="nn">Dict</span><span class="p">.</span><span class="n">t</span>
</code></pre></div>

<p>Get parameters for this estimator.</p>
<h4>Parameters</h4>
<details class="info" open="open"><summary>deep : bool, default=True</summary><p>If True, will return the parameters for this estimator and
contained subobjects that are estimators.</p>
</details>
<h4>Returns</h4>
<details class="info" open="open"><summary>params : mapping of string to any</summary><p>Parameter names mapped to their values.</p>
</details>
</details>
<h3 id="predict_4">predict<a class="headerlink" href="#predict_4" title="Permanent link">&para;</a></h3>
<details class="note" open="open"><summary>method</summary><div class="highlight"><pre><span></span><code><span class="k">val</span> <span class="n">predict</span> <span class="o">:</span>
  <span class="n">x</span><span class="o">:</span><span class="nn">Arr</span><span class="p">.</span><span class="n">t</span> <span class="o">-&gt;</span>
  <span class="n">t</span> <span class="o">-&gt;</span>
  <span class="nn">Arr</span><span class="p">.</span><span class="n">t</span>
</code></pre></div>

<p>Predict using the linear model.</p>
<h4>Parameters</h4>
<details class="info" open="open"><summary>X : array_like or sparse matrix, shape (n_samples, n_features)</summary><p>Samples.</p>
</details>
<h4>Returns</h4>
<details class="info" open="open"><summary>C : array, shape (n_samples,)</summary><p>Returns predicted values.</p>
</details>
</details>
<h3 id="score_4">score<a class="headerlink" href="#score_4" title="Permanent link">&para;</a></h3>
<details class="note" open="open"><summary>method</summary><div class="highlight"><pre><span></span><code><span class="k">val</span> <span class="n">score</span> <span class="o">:</span>
  <span class="o">?</span><span class="n">sample_weight</span><span class="o">:</span><span class="nn">Arr</span><span class="p">.</span><span class="n">t</span> <span class="o">-&gt;</span>
  <span class="n">x</span><span class="o">:</span><span class="nn">Arr</span><span class="p">.</span><span class="n">t</span> <span class="o">-&gt;</span>
  <span class="n">y</span><span class="o">:</span><span class="nn">Arr</span><span class="p">.</span><span class="n">t</span> <span class="o">-&gt;</span>
  <span class="n">t</span> <span class="o">-&gt;</span>
  <span class="kt">float</span>
</code></pre></div>

<p>Return the coefficient of determination R^2 of the prediction.</p>
<p>The coefficient R^2 is defined as (1 - u/v), where u is the residual
sum of squares ((y_true - y_pred) <strong> 2).sum() and v is the total
sum of squares ((y_true - y_true.mean()) </strong> 2).sum().
The best possible score is 1.0 and it can be negative (because the
model can be arbitrarily worse). A constant model that always
predicts the expected value of y, disregarding the input features,
would get a R^2 score of 0.0.</p>
<h4>Parameters</h4>
<details class="info" open="open"><summary>X : array-like of shape (n_samples, n_features)</summary><p>Test samples. For some estimators this may be a
precomputed kernel matrix or a list of generic objects instead,
shape = (n_samples, n_samples_fitted),
where n_samples_fitted is the number of
samples used in the fitting for the estimator.</p>
</details>
<details class="info" open="open"><summary>y : array-like of shape (n_samples,) or (n_samples, n_outputs)</summary><p>True values for X.</p>
</details>
<details class="info" open="open"><summary>sample_weight : array-like of shape (n_samples,), default=None</summary><p>Sample weights.</p>
</details>
<h4>Returns</h4>
<details class="info" open="open"><summary>score : float</summary><p>R^2 of self.predict(X) wrt. y.</p>
</details>
<h4>Notes</h4>
<p>The R2 score used when calling <code>score</code> on a regressor will use
<code>multioutput='uniform_average'</code> from version 0.23 to keep consistent</p>
<details class="info" open="open"><summary>with :func:<code>~sklearn.metrics.r2_score</code>. This will influence the</summary></details>
<p><code>score</code> method of all the multioutput regressors (except for
:class:<code>~sklearn.multioutput.MultiOutputRegressor</code>). To specify the
default value manually and avoid the warning, please either call
:func:<code>~sklearn.metrics.r2_score</code> directly or make a custom scorer with
:func:<code>~sklearn.metrics.make_scorer</code> (the built-in scorer <code>'r2'</code> uses
<code>multioutput='uniform_average'</code>).</p>
</details>
<h3 id="set_params_4">set_params<a class="headerlink" href="#set_params_4" title="Permanent link">&para;</a></h3>
<details class="note" open="open"><summary>method</summary><div class="highlight"><pre><span></span><code><span class="k">val</span> <span class="n">set_params</span> <span class="o">:</span>
  <span class="o">?</span><span class="n">params</span><span class="o">:(</span><span class="kt">string</span> <span class="o">*</span> <span class="nn">Py</span><span class="p">.</span><span class="nn">Object</span><span class="p">.</span><span class="n">t</span><span class="o">)</span> <span class="kt">list</span> <span class="o">-&gt;</span>
  <span class="n">t</span> <span class="o">-&gt;</span>
  <span class="n">t</span>
</code></pre></div>

<p>Set the parameters of this estimator.</p>
<p>The method works on simple estimators as well as on nested objects
(such as pipelines). The latter have parameters of the form
<code>&lt;component&gt;__&lt;parameter&gt;</code> so that it's possible to update each
component of a nested object.</p>
<h4>Parameters</h4>
<details class="info" open="open"><summary>**params : dict</summary><p>Estimator parameters.</p>
</details>
<h4>Returns</h4>
<details class="info" open="open"><summary>self : object</summary><p>Estimator instance.</p>
</details>
</details>
<h3 id="coef__4">coef_<a class="headerlink" href="#coef__4" title="Permanent link">&para;</a></h3>
<details class="note" open="open"><summary>attribute</summary><div class="highlight"><pre><span></span><code><span class="k">val</span> <span class="n">coef_</span> <span class="o">:</span> <span class="n">t</span> <span class="o">-&gt;</span> <span class="nn">Arr</span><span class="p">.</span><span class="n">t</span>
<span class="k">val</span> <span class="n">coef_opt</span> <span class="o">:</span> <span class="n">t</span> <span class="o">-&gt;</span> <span class="o">(</span><span class="nn">Arr</span><span class="p">.</span><span class="n">t</span><span class="o">)</span> <span class="n">option</span>
</code></pre></div>

<p>This attribute is documented in <code>create</code> above. The first version raises Not_found
if the attribute is None. The _opt version returns an option.</p>
</details>
<h3 id="intercept__4">intercept_<a class="headerlink" href="#intercept__4" title="Permanent link">&para;</a></h3>
<details class="note" open="open"><summary>attribute</summary><div class="highlight"><pre><span></span><code><span class="k">val</span> <span class="n">intercept_</span> <span class="o">:</span> <span class="n">t</span> <span class="o">-&gt;</span> <span class="nn">Arr</span><span class="p">.</span><span class="n">t</span>
<span class="k">val</span> <span class="n">intercept_opt</span> <span class="o">:</span> <span class="n">t</span> <span class="o">-&gt;</span> <span class="o">(</span><span class="nn">Arr</span><span class="p">.</span><span class="n">t</span><span class="o">)</span> <span class="n">option</span>
</code></pre></div>

<p>This attribute is documented in <code>create</code> above. The first version raises Not_found
if the attribute is None. The _opt version returns an option.</p>
</details>
<h3 id="scale_">scale_<a class="headerlink" href="#scale_" title="Permanent link">&para;</a></h3>
<details class="note" open="open"><summary>attribute</summary><div class="highlight"><pre><span></span><code><span class="k">val</span> <span class="n">scale_</span> <span class="o">:</span> <span class="n">t</span> <span class="o">-&gt;</span> <span class="kt">float</span>
<span class="k">val</span> <span class="n">scale_opt</span> <span class="o">:</span> <span class="n">t</span> <span class="o">-&gt;</span> <span class="o">(</span><span class="kt">float</span><span class="o">)</span> <span class="n">option</span>
</code></pre></div>

<p>This attribute is documented in <code>create</code> above. The first version raises Not_found
if the attribute is None. The _opt version returns an option.</p>
</details>
<h3 id="n_iter__3">n_iter_<a class="headerlink" href="#n_iter__3" title="Permanent link">&para;</a></h3>
<details class="note" open="open"><summary>attribute</summary><div class="highlight"><pre><span></span><code><span class="k">val</span> <span class="n">n_iter_</span> <span class="o">:</span> <span class="n">t</span> <span class="o">-&gt;</span> <span class="kt">int</span>
<span class="k">val</span> <span class="n">n_iter_opt</span> <span class="o">:</span> <span class="n">t</span> <span class="o">-&gt;</span> <span class="o">(</span><span class="kt">int</span><span class="o">)</span> <span class="n">option</span>
</code></pre></div>

<p>This attribute is documented in <code>create</code> above. The first version raises Not_found
if the attribute is None. The _opt version returns an option.</p>
</details>
<h3 id="outliers_">outliers_<a class="headerlink" href="#outliers_" title="Permanent link">&para;</a></h3>
<details class="note" open="open"><summary>attribute</summary><div class="highlight"><pre><span></span><code><span class="k">val</span> <span class="n">outliers_</span> <span class="o">:</span> <span class="n">t</span> <span class="o">-&gt;</span> <span class="nn">Arr</span><span class="p">.</span><span class="n">t</span>
<span class="k">val</span> <span class="n">outliers_opt</span> <span class="o">:</span> <span class="n">t</span> <span class="o">-&gt;</span> <span class="o">(</span><span class="nn">Arr</span><span class="p">.</span><span class="n">t</span><span class="o">)</span> <span class="n">option</span>
</code></pre></div>

<p>This attribute is documented in <code>create</code> above. The first version raises Not_found
if the attribute is None. The _opt version returns an option.</p>
</details>
<h3 id="to_string_4">to_string<a class="headerlink" href="#to_string_4" title="Permanent link">&para;</a></h3>
<details class="note" open="open"><summary>method</summary><div class="highlight"><pre><span></span><code><span class="k">val</span> <span class="n">to_string</span><span class="o">:</span> <span class="n">t</span> <span class="o">-&gt;</span> <span class="kt">string</span>
</code></pre></div>

<p>Print the object to a human-readable representation.</p>
</details>
<h3 id="show_4">show<a class="headerlink" href="#show_4" title="Permanent link">&para;</a></h3>
<details class="note" open="open"><summary>method</summary><div class="highlight"><pre><span></span><code><span class="k">val</span> <span class="n">show</span><span class="o">:</span> <span class="n">t</span> <span class="o">-&gt;</span> <span class="kt">string</span>
</code></pre></div>

<p>Print the object to a human-readable representation.</p>
</details>
<h3 id="pp_4">pp<a class="headerlink" href="#pp_4" title="Permanent link">&para;</a></h3>
<details class="note" open="open"><summary>method</summary><div class="highlight"><pre><span></span><code><span class="k">val</span> <span class="n">pp</span><span class="o">:</span> <span class="nn">Format</span><span class="p">.</span><span class="n">formatter</span> <span class="o">-&gt;</span> <span class="n">t</span> <span class="o">-&gt;</span> <span class="kt">unit</span>
</code></pre></div>

<p>Pretty-print the object to a formatter.</p>
</details>
<h2 id="module-sklearnlinear_modellars">module Sklearn.​Linear_model.​Lars<a class="headerlink" href="#module-sklearnlinear_modellars" title="Permanent link">&para;</a></h2>
<div class="highlight"><pre><span></span><code><span class="k">type</span> <span class="n">t</span>
</code></pre></div>

<h3 id="create_5">create<a class="headerlink" href="#create_5" title="Permanent link">&para;</a></h3>
<details class="note" open="open"><summary>constructor and attributes</summary><div class="highlight"><pre><span></span><code><span class="k">val</span> <span class="n">create</span> <span class="o">:</span>
  <span class="o">?</span><span class="n">fit_intercept</span><span class="o">:</span><span class="kt">bool</span> <span class="o">-&gt;</span>
  <span class="o">?</span><span class="n">verbose</span><span class="o">:</span><span class="kt">int</span> <span class="o">-&gt;</span>
  <span class="o">?</span><span class="n">normalize</span><span class="o">:</span><span class="kt">bool</span> <span class="o">-&gt;</span>
  <span class="o">?</span><span class="n">precompute</span><span class="o">:[`</span><span class="nc">Bool</span> <span class="k">of</span> <span class="kt">bool</span> <span class="o">|</span> <span class="o">`</span><span class="nc">Auto</span> <span class="o">|</span> <span class="o">`</span><span class="nc">Arr</span> <span class="k">of</span> <span class="nn">Arr</span><span class="p">.</span><span class="n">t</span><span class="o">]</span> <span class="o">-&gt;</span>
  <span class="o">?</span><span class="n">n_nonzero_coefs</span><span class="o">:</span><span class="kt">int</span> <span class="o">-&gt;</span>
  <span class="o">?</span><span class="n">eps</span><span class="o">:</span><span class="kt">float</span> <span class="o">-&gt;</span>
  <span class="o">?</span><span class="n">copy_X</span><span class="o">:</span><span class="kt">bool</span> <span class="o">-&gt;</span>
  <span class="o">?</span><span class="n">fit_path</span><span class="o">:</span><span class="kt">bool</span> <span class="o">-&gt;</span>
  <span class="kt">unit</span> <span class="o">-&gt;</span>
  <span class="n">t</span>
</code></pre></div>

<p>Least Angle Regression model a.k.a. LAR</p>
<p>Read more in the :ref:<code>User Guide &lt;least_angle_regression&gt;</code>.</p>
<h4>Parameters</h4>
<details class="info" open="open"><summary>fit_intercept : bool, default=True</summary><p>Whether to calculate the intercept for this model. If set
to false, no intercept will be used in calculations
(i.e. data is expected to be centered).</p>
</details>
<details class="info" open="open"><summary>verbose : bool or int, default=False</summary><p>Sets the verbosity amount</p>
</details>
<details class="info" open="open"><summary>normalize : bool, default=True</summary><p>This parameter is ignored when <code>fit_intercept</code> is set to False.
If True, the regressors X will be normalized before regression by
subtracting the mean and dividing by the l2-norm.
If you wish to standardize, please use
:class:<code>sklearn.preprocessing.StandardScaler</code> before calling <code>fit</code>
on an estimator with <code>normalize=False</code>.</p>
</details>
<details class="info" open="open"><summary>precompute : bool, 'auto' or array-like , default='auto'</summary><p>Whether to use a precomputed Gram matrix to speed up
calculations. If set to <code>'auto'</code> let us decide. The Gram
matrix can also be passed as argument.</p>
</details>
<details class="info" open="open"><summary>n_nonzero_coefs : int, default=500</summary><p>Target number of non-zero coefficients. Use <code>np.inf</code> for no limit.</p>
</details>
<details class="info" open="open"><summary>eps : float, optional</summary><p>The machine-precision regularization in the computation of the
Cholesky diagonal factors. Increase this for very ill-conditioned
systems. Unlike the <code>tol</code> parameter in some iterative
optimization-based algorithms, this parameter does not control
the tolerance of the optimization.
By default, <code>np.finfo(np.float).eps</code> is used.</p>
</details>
<details class="info" open="open"><summary>copy_X : bool, default=True</summary><p>If <code>True</code>, X will be copied; else, it may be overwritten.</p>
</details>
<details class="info" open="open"><summary>fit_path : bool, default=True</summary><p>If True the full path is stored in the <code>coef_path_</code> attribute.
If you compute the solution for a large problem or many targets,
setting <code>fit_path</code> to <code>False</code> will lead to a speedup, especially
with a small alpha.</p>
</details>
<h4>Attributes</h4>
<details class="info" open="open"><summary>alphas_ : array-like of shape (n_alphas + 1,) | list of n_targets such             arrays</summary><p>Maximum of covariances (in absolute value) at each iteration.         <code>n_alphas</code> is either <code>n_nonzero_coefs</code> or <code>n_features</code>,         whichever is smaller.</p>
</details>
<details class="info" open="open"><summary>active_ : list, length = n_alphas | list of n_targets such lists</summary><p>Indices of active variables at the end of the path.</p>
</details>
<details class="info" open="open"><summary>coef_path_ : array-like of shape (n_features, n_alphas + 1)         | list of n_targets such arrays</summary><p>The varying values of the coefficients along the path. It is not
present if the <code>fit_path</code> parameter is <code>False</code>.</p>
</details>
<details class="info" open="open"><summary>coef_ : array-like of shape (n_features,) or (n_targets, n_features)</summary><p>Parameter vector (w in the formulation formula).</p>
</details>
<details class="info" open="open"><summary>intercept_ : float or array-like of shape (n_targets,)</summary><p>Independent term in decision function.</p>
</details>
<details class="info" open="open"><summary>n_iter_ : array-like or int</summary><p>The number of iterations taken by lars_path to find the
grid of alphas for each target.</p>
</details>
<h4>Examples</h4>
<div class="highlight"><pre><span></span><code><span class="o">&gt;&gt;&gt;</span> <span class="kn">from</span> <span class="nn">sklearn</span> <span class="kn">import</span> <span class="n">linear_model</span>
<span class="o">&gt;&gt;&gt;</span> <span class="n">reg</span> <span class="o">=</span> <span class="n">linear_model</span><span class="o">.</span><span class="n">Lars</span><span class="p">(</span><span class="n">n_nonzero_coefs</span><span class="o">=</span><span class="mi">1</span><span class="p">)</span>
<span class="o">&gt;&gt;&gt;</span> <span class="n">reg</span><span class="o">.</span><span class="n">fit</span><span class="p">([[</span><span class="o">-</span><span class="mi">1</span><span class="p">,</span> <span class="mi">1</span><span class="p">],</span> <span class="p">[</span><span class="mi">0</span><span class="p">,</span> <span class="mi">0</span><span class="p">],</span> <span class="p">[</span><span class="mi">1</span><span class="p">,</span> <span class="mi">1</span><span class="p">]],</span> <span class="p">[</span><span class="o">-</span><span class="mf">1.1111</span><span class="p">,</span> <span class="mi">0</span><span class="p">,</span> <span class="o">-</span><span class="mf">1.1111</span><span class="p">])</span>
<span class="n">Lars</span><span class="p">(</span><span class="n">n_nonzero_coefs</span><span class="o">=</span><span class="mi">1</span><span class="p">)</span>
<span class="o">&gt;&gt;&gt;</span> <span class="nb">print</span><span class="p">(</span><span class="n">reg</span><span class="o">.</span><span class="n">coef_</span><span class="p">)</span>
<span class="p">[</span> <span class="mf">0.</span> <span class="o">-</span><span class="mf">1.11</span><span class="o">...</span><span class="p">]</span>
</code></pre></div>

<h4>See also</h4>
<p>lars_path, LarsCV
sklearn.decomposition.sparse_encode</p>
</details>
<h3 id="fit_5">fit<a class="headerlink" href="#fit_5" title="Permanent link">&para;</a></h3>
<details class="note" open="open"><summary>method</summary><div class="highlight"><pre><span></span><code><span class="k">val</span> <span class="n">fit</span> <span class="o">:</span>
  <span class="o">?</span><span class="n">xy</span><span class="o">:</span><span class="nn">Arr</span><span class="p">.</span><span class="n">t</span> <span class="o">-&gt;</span>
  <span class="n">x</span><span class="o">:</span><span class="nn">Arr</span><span class="p">.</span><span class="n">t</span> <span class="o">-&gt;</span>
  <span class="n">y</span><span class="o">:</span><span class="nn">Arr</span><span class="p">.</span><span class="n">t</span> <span class="o">-&gt;</span>
  <span class="n">t</span> <span class="o">-&gt;</span>
  <span class="n">t</span>
</code></pre></div>

<p>Fit the model using X, y as training data.</p>
<h4>Parameters</h4>
<details class="info" open="open"><summary>X : array-like of shape (n_samples, n_features)</summary><p>Training data.</p>
</details>
<details class="info" open="open"><summary>y : array-like of shape (n_samples,) or (n_samples, n_targets)</summary><p>Target values.</p>
</details>
<details class="info" open="open"><summary>Xy : array-like of shape (n_samples,) or (n_samples, n_targets),                 default=None</summary><p>Xy = np.dot(X.T, y) that can be precomputed. It is useful
only when the Gram matrix is precomputed.</p>
</details>
<h4>Returns</h4>
<details class="info" open="open"><summary>self : object</summary><p>returns an instance of self.</p>
</details>
</details>
<h3 id="get_params_5">get_params<a class="headerlink" href="#get_params_5" title="Permanent link">&para;</a></h3>
<details class="note" open="open"><summary>method</summary><div class="highlight"><pre><span></span><code><span class="k">val</span> <span class="n">get_params</span> <span class="o">:</span>
  <span class="o">?</span><span class="n">deep</span><span class="o">:</span><span class="kt">bool</span> <span class="o">-&gt;</span>
  <span class="n">t</span> <span class="o">-&gt;</span>
  <span class="nn">Dict</span><span class="p">.</span><span class="n">t</span>
</code></pre></div>

<p>Get parameters for this estimator.</p>
<h4>Parameters</h4>
<details class="info" open="open"><summary>deep : bool, default=True</summary><p>If True, will return the parameters for this estimator and
contained subobjects that are estimators.</p>
</details>
<h4>Returns</h4>
<details class="info" open="open"><summary>params : mapping of string to any</summary><p>Parameter names mapped to their values.</p>
</details>
</details>
<h3 id="predict_5">predict<a class="headerlink" href="#predict_5" title="Permanent link">&para;</a></h3>
<details class="note" open="open"><summary>method</summary><div class="highlight"><pre><span></span><code><span class="k">val</span> <span class="n">predict</span> <span class="o">:</span>
  <span class="n">x</span><span class="o">:</span><span class="nn">Arr</span><span class="p">.</span><span class="n">t</span> <span class="o">-&gt;</span>
  <span class="n">t</span> <span class="o">-&gt;</span>
  <span class="nn">Arr</span><span class="p">.</span><span class="n">t</span>
</code></pre></div>

<p>Predict using the linear model.</p>
<h4>Parameters</h4>
<details class="info" open="open"><summary>X : array_like or sparse matrix, shape (n_samples, n_features)</summary><p>Samples.</p>
</details>
<h4>Returns</h4>
<details class="info" open="open"><summary>C : array, shape (n_samples,)</summary><p>Returns predicted values.</p>
</details>
</details>
<h3 id="score_5">score<a class="headerlink" href="#score_5" title="Permanent link">&para;</a></h3>
<details class="note" open="open"><summary>method</summary><div class="highlight"><pre><span></span><code><span class="k">val</span> <span class="n">score</span> <span class="o">:</span>
  <span class="o">?</span><span class="n">sample_weight</span><span class="o">:</span><span class="nn">Arr</span><span class="p">.</span><span class="n">t</span> <span class="o">-&gt;</span>
  <span class="n">x</span><span class="o">:</span><span class="nn">Arr</span><span class="p">.</span><span class="n">t</span> <span class="o">-&gt;</span>
  <span class="n">y</span><span class="o">:</span><span class="nn">Arr</span><span class="p">.</span><span class="n">t</span> <span class="o">-&gt;</span>
  <span class="n">t</span> <span class="o">-&gt;</span>
  <span class="kt">float</span>
</code></pre></div>

<p>Return the coefficient of determination R^2 of the prediction.</p>
<p>The coefficient R^2 is defined as (1 - u/v), where u is the residual
sum of squares ((y_true - y_pred) <strong> 2).sum() and v is the total
sum of squares ((y_true - y_true.mean()) </strong> 2).sum().
The best possible score is 1.0 and it can be negative (because the
model can be arbitrarily worse). A constant model that always
predicts the expected value of y, disregarding the input features,
would get a R^2 score of 0.0.</p>
<h4>Parameters</h4>
<details class="info" open="open"><summary>X : array-like of shape (n_samples, n_features)</summary><p>Test samples. For some estimators this may be a
precomputed kernel matrix or a list of generic objects instead,
shape = (n_samples, n_samples_fitted),
where n_samples_fitted is the number of
samples used in the fitting for the estimator.</p>
</details>
<details class="info" open="open"><summary>y : array-like of shape (n_samples,) or (n_samples, n_outputs)</summary><p>True values for X.</p>
</details>
<details class="info" open="open"><summary>sample_weight : array-like of shape (n_samples,), default=None</summary><p>Sample weights.</p>
</details>
<h4>Returns</h4>
<details class="info" open="open"><summary>score : float</summary><p>R^2 of self.predict(X) wrt. y.</p>
</details>
<h4>Notes</h4>
<p>The R2 score used when calling <code>score</code> on a regressor will use
<code>multioutput='uniform_average'</code> from version 0.23 to keep consistent</p>
<details class="info" open="open"><summary>with :func:<code>~sklearn.metrics.r2_score</code>. This will influence the</summary></details>
<p><code>score</code> method of all the multioutput regressors (except for
:class:<code>~sklearn.multioutput.MultiOutputRegressor</code>). To specify the
default value manually and avoid the warning, please either call
:func:<code>~sklearn.metrics.r2_score</code> directly or make a custom scorer with
:func:<code>~sklearn.metrics.make_scorer</code> (the built-in scorer <code>'r2'</code> uses
<code>multioutput='uniform_average'</code>).</p>
</details>
<h3 id="set_params_5">set_params<a class="headerlink" href="#set_params_5" title="Permanent link">&para;</a></h3>
<details class="note" open="open"><summary>method</summary><div class="highlight"><pre><span></span><code><span class="k">val</span> <span class="n">set_params</span> <span class="o">:</span>
  <span class="o">?</span><span class="n">params</span><span class="o">:(</span><span class="kt">string</span> <span class="o">*</span> <span class="nn">Py</span><span class="p">.</span><span class="nn">Object</span><span class="p">.</span><span class="n">t</span><span class="o">)</span> <span class="kt">list</span> <span class="o">-&gt;</span>
  <span class="n">t</span> <span class="o">-&gt;</span>
  <span class="n">t</span>
</code></pre></div>

<p>Set the parameters of this estimator.</p>
<p>The method works on simple estimators as well as on nested objects
(such as pipelines). The latter have parameters of the form
<code>&lt;component&gt;__&lt;parameter&gt;</code> so that it's possible to update each
component of a nested object.</p>
<h4>Parameters</h4>
<details class="info" open="open"><summary>**params : dict</summary><p>Estimator parameters.</p>
</details>
<h4>Returns</h4>
<details class="info" open="open"><summary>self : object</summary><p>Estimator instance.</p>
</details>
</details>
<h3 id="alphas__1">alphas_<a class="headerlink" href="#alphas__1" title="Permanent link">&para;</a></h3>
<details class="note" open="open"><summary>attribute</summary><div class="highlight"><pre><span></span><code><span class="k">val</span> <span class="n">alphas_</span> <span class="o">:</span> <span class="n">t</span> <span class="o">-&gt;</span> <span class="nn">Py</span><span class="p">.</span><span class="nn">Object</span><span class="p">.</span><span class="n">t</span>
<span class="k">val</span> <span class="n">alphas_opt</span> <span class="o">:</span> <span class="n">t</span> <span class="o">-&gt;</span> <span class="o">(</span><span class="nn">Py</span><span class="p">.</span><span class="nn">Object</span><span class="p">.</span><span class="n">t</span><span class="o">)</span> <span class="n">option</span>
</code></pre></div>

<p>This attribute is documented in <code>create</code> above. The first version raises Not_found
if the attribute is None. The _opt version returns an option.</p>
</details>
<h3 id="active_">active_<a class="headerlink" href="#active_" title="Permanent link">&para;</a></h3>
<details class="note" open="open"><summary>attribute</summary><div class="highlight"><pre><span></span><code><span class="k">val</span> <span class="n">active_</span> <span class="o">:</span> <span class="n">t</span> <span class="o">-&gt;</span> <span class="nn">Py</span><span class="p">.</span><span class="nn">Object</span><span class="p">.</span><span class="n">t</span>
<span class="k">val</span> <span class="n">active_opt</span> <span class="o">:</span> <span class="n">t</span> <span class="o">-&gt;</span> <span class="o">(</span><span class="nn">Py</span><span class="p">.</span><span class="nn">Object</span><span class="p">.</span><span class="n">t</span><span class="o">)</span> <span class="n">option</span>
</code></pre></div>

<p>This attribute is documented in <code>create</code> above. The first version raises Not_found
if the attribute is None. The _opt version returns an option.</p>
</details>
<h3 id="coef_path_">coef_path_<a class="headerlink" href="#coef_path_" title="Permanent link">&para;</a></h3>
<details class="note" open="open"><summary>attribute</summary><div class="highlight"><pre><span></span><code><span class="k">val</span> <span class="n">coef_path_</span> <span class="o">:</span> <span class="n">t</span> <span class="o">-&gt;</span> <span class="nn">Py</span><span class="p">.</span><span class="nn">Object</span><span class="p">.</span><span class="n">t</span>
<span class="k">val</span> <span class="n">coef_path_opt</span> <span class="o">:</span> <span class="n">t</span> <span class="o">-&gt;</span> <span class="o">(</span><span class="nn">Py</span><span class="p">.</span><span class="nn">Object</span><span class="p">.</span><span class="n">t</span><span class="o">)</span> <span class="n">option</span>
</code></pre></div>

<p>This attribute is documented in <code>create</code> above. The first version raises Not_found
if the attribute is None. The _opt version returns an option.</p>
</details>
<h3 id="coef__5">coef_<a class="headerlink" href="#coef__5" title="Permanent link">&para;</a></h3>
<details class="note" open="open"><summary>attribute</summary><div class="highlight"><pre><span></span><code><span class="k">val</span> <span class="n">coef_</span> <span class="o">:</span> <span class="n">t</span> <span class="o">-&gt;</span> <span class="nn">Arr</span><span class="p">.</span><span class="n">t</span>
<span class="k">val</span> <span class="n">coef_opt</span> <span class="o">:</span> <span class="n">t</span> <span class="o">-&gt;</span> <span class="o">(</span><span class="nn">Arr</span><span class="p">.</span><span class="n">t</span><span class="o">)</span> <span class="n">option</span>
</code></pre></div>

<p>This attribute is documented in <code>create</code> above. The first version raises Not_found
if the attribute is None. The _opt version returns an option.</p>
</details>
<h3 id="intercept__5">intercept_<a class="headerlink" href="#intercept__5" title="Permanent link">&para;</a></h3>
<details class="note" open="open"><summary>attribute</summary><div class="highlight"><pre><span></span><code><span class="k">val</span> <span class="n">intercept_</span> <span class="o">:</span> <span class="n">t</span> <span class="o">-&gt;</span> <span class="nn">Arr</span><span class="p">.</span><span class="n">t</span>
<span class="k">val</span> <span class="n">intercept_opt</span> <span class="o">:</span> <span class="n">t</span> <span class="o">-&gt;</span> <span class="o">(</span><span class="nn">Arr</span><span class="p">.</span><span class="n">t</span><span class="o">)</span> <span class="n">option</span>
</code></pre></div>

<p>This attribute is documented in <code>create</code> above. The first version raises Not_found
if the attribute is None. The _opt version returns an option.</p>
</details>
<h3 id="n_iter__4">n_iter_<a class="headerlink" href="#n_iter__4" title="Permanent link">&para;</a></h3>
<details class="note" open="open"><summary>attribute</summary><div class="highlight"><pre><span></span><code><span class="k">val</span> <span class="n">n_iter_</span> <span class="o">:</span> <span class="n">t</span> <span class="o">-&gt;</span> <span class="o">[`</span><span class="nc">Arr</span> <span class="k">of</span> <span class="nn">Arr</span><span class="p">.</span><span class="n">t</span> <span class="o">|</span> <span class="o">`</span><span class="nc">I</span> <span class="k">of</span> <span class="kt">int</span><span class="o">]</span>
<span class="k">val</span> <span class="n">n_iter_opt</span> <span class="o">:</span> <span class="n">t</span> <span class="o">-&gt;</span> <span class="o">([`</span><span class="nc">Arr</span> <span class="k">of</span> <span class="nn">Arr</span><span class="p">.</span><span class="n">t</span> <span class="o">|</span> <span class="o">`</span><span class="nc">I</span> <span class="k">of</span> <span class="kt">int</span><span class="o">])</span> <span class="n">option</span>
</code></pre></div>

<p>This attribute is documented in <code>create</code> above. The first version raises Not_found
if the attribute is None. The _opt version returns an option.</p>
</details>
<h3 id="to_string_5">to_string<a class="headerlink" href="#to_string_5" title="Permanent link">&para;</a></h3>
<details class="note" open="open"><summary>method</summary><div class="highlight"><pre><span></span><code><span class="k">val</span> <span class="n">to_string</span><span class="o">:</span> <span class="n">t</span> <span class="o">-&gt;</span> <span class="kt">string</span>
</code></pre></div>

<p>Print the object to a human-readable representation.</p>
</details>
<h3 id="show_5">show<a class="headerlink" href="#show_5" title="Permanent link">&para;</a></h3>
<details class="note" open="open"><summary>method</summary><div class="highlight"><pre><span></span><code><span class="k">val</span> <span class="n">show</span><span class="o">:</span> <span class="n">t</span> <span class="o">-&gt;</span> <span class="kt">string</span>
</code></pre></div>

<p>Print the object to a human-readable representation.</p>
</details>
<h3 id="pp_5">pp<a class="headerlink" href="#pp_5" title="Permanent link">&para;</a></h3>
<details class="note" open="open"><summary>method</summary><div class="highlight"><pre><span></span><code><span class="k">val</span> <span class="n">pp</span><span class="o">:</span> <span class="nn">Format</span><span class="p">.</span><span class="n">formatter</span> <span class="o">-&gt;</span> <span class="n">t</span> <span class="o">-&gt;</span> <span class="kt">unit</span>
</code></pre></div>

<p>Pretty-print the object to a formatter.</p>
</details>
<h2 id="module-sklearnlinear_modellarscv">module Sklearn.​Linear_model.​LarsCV<a class="headerlink" href="#module-sklearnlinear_modellarscv" title="Permanent link">&para;</a></h2>
<div class="highlight"><pre><span></span><code><span class="k">type</span> <span class="n">t</span>
</code></pre></div>

<h3 id="create_6">create<a class="headerlink" href="#create_6" title="Permanent link">&para;</a></h3>
<details class="note" open="open"><summary>constructor and attributes</summary><div class="highlight"><pre><span></span><code><span class="k">val</span> <span class="n">create</span> <span class="o">:</span>
  <span class="o">?</span><span class="n">fit_intercept</span><span class="o">:</span><span class="kt">bool</span> <span class="o">-&gt;</span>
  <span class="o">?</span><span class="n">verbose</span><span class="o">:</span><span class="kt">int</span> <span class="o">-&gt;</span>
  <span class="o">?</span><span class="n">max_iter</span><span class="o">:</span><span class="kt">int</span> <span class="o">-&gt;</span>
  <span class="o">?</span><span class="n">normalize</span><span class="o">:</span><span class="kt">bool</span> <span class="o">-&gt;</span>
  <span class="o">?</span><span class="n">precompute</span><span class="o">:[`</span><span class="nc">Bool</span> <span class="k">of</span> <span class="kt">bool</span> <span class="o">|</span> <span class="o">`</span><span class="nc">Auto</span> <span class="o">|</span> <span class="o">`</span><span class="nc">Arr</span> <span class="k">of</span> <span class="nn">Arr</span><span class="p">.</span><span class="n">t</span><span class="o">]</span> <span class="o">-&gt;</span>
  <span class="o">?</span><span class="n">cv</span><span class="o">:[`</span><span class="nc">I</span> <span class="k">of</span> <span class="kt">int</span> <span class="o">|</span> <span class="o">`</span><span class="nc">CrossValGenerator</span> <span class="k">of</span> <span class="nn">Py</span><span class="p">.</span><span class="nn">Object</span><span class="p">.</span><span class="n">t</span> <span class="o">|</span> <span class="o">`</span><span class="nc">Arr</span> <span class="k">of</span> <span class="nn">Arr</span><span class="p">.</span><span class="n">t</span><span class="o">]</span> <span class="o">-&gt;</span>
  <span class="o">?</span><span class="n">max_n_alphas</span><span class="o">:</span><span class="kt">int</span> <span class="o">-&gt;</span>
  <span class="o">?</span><span class="n">n_jobs</span><span class="o">:</span><span class="kt">int</span> <span class="o">-&gt;</span>
  <span class="o">?</span><span class="n">eps</span><span class="o">:</span><span class="kt">float</span> <span class="o">-&gt;</span>
  <span class="o">?</span><span class="n">copy_X</span><span class="o">:</span><span class="kt">bool</span> <span class="o">-&gt;</span>
  <span class="kt">unit</span> <span class="o">-&gt;</span>
  <span class="n">t</span>
</code></pre></div>

<p>Cross-validated Least Angle Regression model.</p>
<p>See glossary entry for :term:<code>cross-validation estimator</code>.</p>
<p>Read more in the :ref:<code>User Guide &lt;least_angle_regression&gt;</code>.</p>
<h4>Parameters</h4>
<details class="info" open="open"><summary>fit_intercept : bool, default=True</summary><p>whether to calculate the intercept for this model. If set
to false, no intercept will be used in calculations
(i.e. data is expected to be centered).</p>
</details>
<details class="info" open="open"><summary>verbose : bool or int, default=False</summary><p>Sets the verbosity amount</p>
</details>
<details class="info" open="open"><summary>max_iter : int, default=500</summary><p>Maximum number of iterations to perform.</p>
</details>
<details class="info" open="open"><summary>normalize : bool, default=True</summary><p>This parameter is ignored when <code>fit_intercept</code> is set to False.
If True, the regressors X will be normalized before regression by
subtracting the mean and dividing by the l2-norm.
If you wish to standardize, please use
:class:<code>sklearn.preprocessing.StandardScaler</code> before calling <code>fit</code>
on an estimator with <code>normalize=False</code>.</p>
</details>
<details class="info" open="open"><summary>precompute : bool, 'auto' or array-like , default='auto'</summary><p>Whether to use a precomputed Gram matrix to speed up
calculations. If set to <code>'auto'</code> let us decide. The Gram matrix
cannot be passed as argument since we will use only subsets of X.</p>
</details>
<details class="info" open="open"><summary>cv : int, cross-validation generator or an iterable, default=None</summary><p>Determines the cross-validation splitting strategy.
Possible inputs for cv are:</p>
<ul>
<li>None, to use the default 5-fold cross-validation,</li>
<li>integer, to specify the number of folds.</li>
<li>:term:<code>CV splitter</code>,</li>
<li>An iterable yielding (train, test) splits as arrays of indices.</li>
</ul>
<p>For integer/None inputs, :class:<code>KFold</code> is used.</p>
</details>
<details class="info" open="open"><summary>Refer :ref:<code>User Guide &lt;cross_validation&gt;</code> for the various</summary><p>cross-validation strategies that can be used here.</p>
<p>.. versionchanged:: 0.22
    <code>cv</code> default value if None changed from 3-fold to 5-fold.</p>
</details>
<details class="info" open="open"><summary>max_n_alphas : int, default=1000</summary><p>The maximum number of points on the path used to compute the
residuals in the cross-validation</p>
</details>
<details class="info" open="open"><summary>n_jobs : int or None, default=None</summary><p>Number of CPUs to use during the cross validation.
<code>None</code> means 1 unless in a :obj:<code>joblib.parallel_backend</code> context.
<code>-1</code> means using all processors. See :term:<code>Glossary &lt;n_jobs&gt;</code>
for more details.</p>
</details>
<details class="info" open="open"><summary>eps : float, optional</summary><p>The machine-precision regularization in the computation of the
Cholesky diagonal factors. Increase this for very ill-conditioned
systems. By default, <code>np.finfo(np.float).eps</code> is used.</p>
</details>
<details class="info" open="open"><summary>copy_X : bool, default=True</summary><p>If <code>True</code>, X will be copied; else, it may be overwritten.</p>
</details>
<h4>Attributes</h4>
<details class="info" open="open"><summary>coef_ : array-like of shape (n_features,)</summary><p>parameter vector (w in the formulation formula)</p>
</details>
<details class="info" open="open"><summary>intercept_ : float</summary><p>independent term in decision function</p>
</details>
<details class="info" open="open"><summary>coef_path_ : array-like of shape (n_features, n_alphas)</summary><p>the varying values of the coefficients along the path</p>
</details>
<details class="info" open="open"><summary>alpha_ : float</summary><p>the estimated regularization parameter alpha</p>
</details>
<details class="info" open="open"><summary>alphas_ : array-like of shape (n_alphas,)</summary><p>the different values of alpha along the path</p>
</details>
<details class="info" open="open"><summary>cv_alphas_ : array-like of shape (n_cv_alphas,)</summary><p>all the values of alpha along the path for the different folds</p>
</details>
<details class="info" open="open"><summary>mse_path_ : array-like of shape (n_folds, n_cv_alphas)</summary><p>the mean square error on left-out for each fold along the path
(alpha values given by <code>cv_alphas</code>)</p>
</details>
<details class="info" open="open"><summary>n_iter_ : array-like or int</summary><p>the number of iterations run by Lars with the optimal alpha.</p>
</details>
<h4>Examples</h4>
<div class="highlight"><pre><span></span><code><span class="o">&gt;&gt;&gt;</span> <span class="kn">from</span> <span class="nn">sklearn.linear_model</span> <span class="kn">import</span> <span class="n">LarsCV</span>
<span class="o">&gt;&gt;&gt;</span> <span class="kn">from</span> <span class="nn">sklearn.datasets</span> <span class="kn">import</span> <span class="n">make_regression</span>
<span class="o">&gt;&gt;&gt;</span> <span class="n">X</span><span class="p">,</span> <span class="n">y</span> <span class="o">=</span> <span class="n">make_regression</span><span class="p">(</span><span class="n">n_samples</span><span class="o">=</span><span class="mi">200</span><span class="p">,</span> <span class="n">noise</span><span class="o">=</span><span class="mf">4.0</span><span class="p">,</span> <span class="n">random_state</span><span class="o">=</span><span class="mi">0</span><span class="p">)</span>
<span class="o">&gt;&gt;&gt;</span> <span class="n">reg</span> <span class="o">=</span> <span class="n">LarsCV</span><span class="p">(</span><span class="n">cv</span><span class="o">=</span><span class="mi">5</span><span class="p">)</span><span class="o">.</span><span class="n">fit</span><span class="p">(</span><span class="n">X</span><span class="p">,</span> <span class="n">y</span><span class="p">)</span>
<span class="o">&gt;&gt;&gt;</span> <span class="n">reg</span><span class="o">.</span><span class="n">score</span><span class="p">(</span><span class="n">X</span><span class="p">,</span> <span class="n">y</span><span class="p">)</span>
<span class="mf">0.9996</span><span class="o">...</span>
<span class="o">&gt;&gt;&gt;</span> <span class="n">reg</span><span class="o">.</span><span class="n">alpha_</span>
<span class="mf">0.0254</span><span class="o">...</span>
<span class="o">&gt;&gt;&gt;</span> <span class="n">reg</span><span class="o">.</span><span class="n">predict</span><span class="p">(</span><span class="n">X</span><span class="p">[:</span><span class="mi">1</span><span class="p">,])</span>
<span class="n">array</span><span class="p">([</span><span class="mf">154.0842</span><span class="o">...</span><span class="p">])</span>
</code></pre></div>

<h4>See also</h4>
<p>lars_path, LassoLars, LassoLarsCV</p>
</details>
<h3 id="fit_6">fit<a class="headerlink" href="#fit_6" title="Permanent link">&para;</a></h3>
<details class="note" open="open"><summary>method</summary><div class="highlight"><pre><span></span><code><span class="k">val</span> <span class="n">fit</span> <span class="o">:</span>
  <span class="n">x</span><span class="o">:</span><span class="nn">Arr</span><span class="p">.</span><span class="n">t</span> <span class="o">-&gt;</span>
  <span class="n">y</span><span class="o">:</span><span class="nn">Arr</span><span class="p">.</span><span class="n">t</span> <span class="o">-&gt;</span>
  <span class="n">t</span> <span class="o">-&gt;</span>
  <span class="n">t</span>
</code></pre></div>

<p>Fit the model using X, y as training data.</p>
<h4>Parameters</h4>
<details class="info" open="open"><summary>X : array-like of shape (n_samples, n_features)</summary><p>Training data.</p>
</details>
<details class="info" open="open"><summary>y : array-like of shape (n_samples,)</summary><p>Target values.</p>
</details>
<h4>Returns</h4>
<details class="info" open="open"><summary>self : object</summary><p>returns an instance of self.</p>
</details>
</details>
<h3 id="get_params_6">get_params<a class="headerlink" href="#get_params_6" title="Permanent link">&para;</a></h3>
<details class="note" open="open"><summary>method</summary><div class="highlight"><pre><span></span><code><span class="k">val</span> <span class="n">get_params</span> <span class="o">:</span>
  <span class="o">?</span><span class="n">deep</span><span class="o">:</span><span class="kt">bool</span> <span class="o">-&gt;</span>
  <span class="n">t</span> <span class="o">-&gt;</span>
  <span class="nn">Dict</span><span class="p">.</span><span class="n">t</span>
</code></pre></div>

<p>Get parameters for this estimator.</p>
<h4>Parameters</h4>
<details class="info" open="open"><summary>deep : bool, default=True</summary><p>If True, will return the parameters for this estimator and
contained subobjects that are estimators.</p>
</details>
<h4>Returns</h4>
<details class="info" open="open"><summary>params : mapping of string to any</summary><p>Parameter names mapped to their values.</p>
</details>
</details>
<h3 id="predict_6">predict<a class="headerlink" href="#predict_6" title="Permanent link">&para;</a></h3>
<details class="note" open="open"><summary>method</summary><div class="highlight"><pre><span></span><code><span class="k">val</span> <span class="n">predict</span> <span class="o">:</span>
  <span class="n">x</span><span class="o">:</span><span class="nn">Arr</span><span class="p">.</span><span class="n">t</span> <span class="o">-&gt;</span>
  <span class="n">t</span> <span class="o">-&gt;</span>
  <span class="nn">Arr</span><span class="p">.</span><span class="n">t</span>
</code></pre></div>

<p>Predict using the linear model.</p>
<h4>Parameters</h4>
<details class="info" open="open"><summary>X : array_like or sparse matrix, shape (n_samples, n_features)</summary><p>Samples.</p>
</details>
<h4>Returns</h4>
<details class="info" open="open"><summary>C : array, shape (n_samples,)</summary><p>Returns predicted values.</p>
</details>
</details>
<h3 id="score_6">score<a class="headerlink" href="#score_6" title="Permanent link">&para;</a></h3>
<details class="note" open="open"><summary>method</summary><div class="highlight"><pre><span></span><code><span class="k">val</span> <span class="n">score</span> <span class="o">:</span>
  <span class="o">?</span><span class="n">sample_weight</span><span class="o">:</span><span class="nn">Arr</span><span class="p">.</span><span class="n">t</span> <span class="o">-&gt;</span>
  <span class="n">x</span><span class="o">:</span><span class="nn">Arr</span><span class="p">.</span><span class="n">t</span> <span class="o">-&gt;</span>
  <span class="n">y</span><span class="o">:</span><span class="nn">Arr</span><span class="p">.</span><span class="n">t</span> <span class="o">-&gt;</span>
  <span class="n">t</span> <span class="o">-&gt;</span>
  <span class="kt">float</span>
</code></pre></div>

<p>Return the coefficient of determination R^2 of the prediction.</p>
<p>The coefficient R^2 is defined as (1 - u/v), where u is the residual
sum of squares ((y_true - y_pred) <strong> 2).sum() and v is the total
sum of squares ((y_true - y_true.mean()) </strong> 2).sum().
The best possible score is 1.0 and it can be negative (because the
model can be arbitrarily worse). A constant model that always
predicts the expected value of y, disregarding the input features,
would get a R^2 score of 0.0.</p>
<h4>Parameters</h4>
<details class="info" open="open"><summary>X : array-like of shape (n_samples, n_features)</summary><p>Test samples. For some estimators this may be a
precomputed kernel matrix or a list of generic objects instead,
shape = (n_samples, n_samples_fitted),
where n_samples_fitted is the number of
samples used in the fitting for the estimator.</p>
</details>
<details class="info" open="open"><summary>y : array-like of shape (n_samples,) or (n_samples, n_outputs)</summary><p>True values for X.</p>
</details>
<details class="info" open="open"><summary>sample_weight : array-like of shape (n_samples,), default=None</summary><p>Sample weights.</p>
</details>
<h4>Returns</h4>
<details class="info" open="open"><summary>score : float</summary><p>R^2 of self.predict(X) wrt. y.</p>
</details>
<h4>Notes</h4>
<p>The R2 score used when calling <code>score</code> on a regressor will use
<code>multioutput='uniform_average'</code> from version 0.23 to keep consistent</p>
<details class="info" open="open"><summary>with :func:<code>~sklearn.metrics.r2_score</code>. This will influence the</summary></details>
<p><code>score</code> method of all the multioutput regressors (except for
:class:<code>~sklearn.multioutput.MultiOutputRegressor</code>). To specify the
default value manually and avoid the warning, please either call
:func:<code>~sklearn.metrics.r2_score</code> directly or make a custom scorer with
:func:<code>~sklearn.metrics.make_scorer</code> (the built-in scorer <code>'r2'</code> uses
<code>multioutput='uniform_average'</code>).</p>
</details>
<h3 id="set_params_6">set_params<a class="headerlink" href="#set_params_6" title="Permanent link">&para;</a></h3>
<details class="note" open="open"><summary>method</summary><div class="highlight"><pre><span></span><code><span class="k">val</span> <span class="n">set_params</span> <span class="o">:</span>
  <span class="o">?</span><span class="n">params</span><span class="o">:(</span><span class="kt">string</span> <span class="o">*</span> <span class="nn">Py</span><span class="p">.</span><span class="nn">Object</span><span class="p">.</span><span class="n">t</span><span class="o">)</span> <span class="kt">list</span> <span class="o">-&gt;</span>
  <span class="n">t</span> <span class="o">-&gt;</span>
  <span class="n">t</span>
</code></pre></div>

<p>Set the parameters of this estimator.</p>
<p>The method works on simple estimators as well as on nested objects
(such as pipelines). The latter have parameters of the form
<code>&lt;component&gt;__&lt;parameter&gt;</code> so that it's possible to update each
component of a nested object.</p>
<h4>Parameters</h4>
<details class="info" open="open"><summary>**params : dict</summary><p>Estimator parameters.</p>
</details>
<h4>Returns</h4>
<details class="info" open="open"><summary>self : object</summary><p>Estimator instance.</p>
</details>
</details>
<h3 id="coef__6">coef_<a class="headerlink" href="#coef__6" title="Permanent link">&para;</a></h3>
<details class="note" open="open"><summary>attribute</summary><div class="highlight"><pre><span></span><code><span class="k">val</span> <span class="n">coef_</span> <span class="o">:</span> <span class="n">t</span> <span class="o">-&gt;</span> <span class="nn">Arr</span><span class="p">.</span><span class="n">t</span>
<span class="k">val</span> <span class="n">coef_opt</span> <span class="o">:</span> <span class="n">t</span> <span class="o">-&gt;</span> <span class="o">(</span><span class="nn">Arr</span><span class="p">.</span><span class="n">t</span><span class="o">)</span> <span class="n">option</span>
</code></pre></div>

<p>This attribute is documented in <code>create</code> above. The first version raises Not_found
if the attribute is None. The _opt version returns an option.</p>
</details>
<h3 id="intercept__6">intercept_<a class="headerlink" href="#intercept__6" title="Permanent link">&para;</a></h3>
<details class="note" open="open"><summary>attribute</summary><div class="highlight"><pre><span></span><code><span class="k">val</span> <span class="n">intercept_</span> <span class="o">:</span> <span class="n">t</span> <span class="o">-&gt;</span> <span class="nn">Arr</span><span class="p">.</span><span class="n">t</span>
<span class="k">val</span> <span class="n">intercept_opt</span> <span class="o">:</span> <span class="n">t</span> <span class="o">-&gt;</span> <span class="o">(</span><span class="nn">Arr</span><span class="p">.</span><span class="n">t</span><span class="o">)</span> <span class="n">option</span>
</code></pre></div>

<p>This attribute is documented in <code>create</code> above. The first version raises Not_found
if the attribute is None. The _opt version returns an option.</p>
</details>
<h3 id="coef_path__1">coef_path_<a class="headerlink" href="#coef_path__1" title="Permanent link">&para;</a></h3>
<details class="note" open="open"><summary>attribute</summary><div class="highlight"><pre><span></span><code><span class="k">val</span> <span class="n">coef_path_</span> <span class="o">:</span> <span class="n">t</span> <span class="o">-&gt;</span> <span class="nn">Arr</span><span class="p">.</span><span class="n">t</span>
<span class="k">val</span> <span class="n">coef_path_opt</span> <span class="o">:</span> <span class="n">t</span> <span class="o">-&gt;</span> <span class="o">(</span><span class="nn">Arr</span><span class="p">.</span><span class="n">t</span><span class="o">)</span> <span class="n">option</span>
</code></pre></div>

<p>This attribute is documented in <code>create</code> above. The first version raises Not_found
if the attribute is None. The _opt version returns an option.</p>
</details>
<h3 id="alpha__3">alpha_<a class="headerlink" href="#alpha__3" title="Permanent link">&para;</a></h3>
<details class="note" open="open"><summary>attribute</summary><div class="highlight"><pre><span></span><code><span class="k">val</span> <span class="n">alpha_</span> <span class="o">:</span> <span class="n">t</span> <span class="o">-&gt;</span> <span class="kt">float</span>
<span class="k">val</span> <span class="n">alpha_opt</span> <span class="o">:</span> <span class="n">t</span> <span class="o">-&gt;</span> <span class="o">(</span><span class="kt">float</span><span class="o">)</span> <span class="n">option</span>
</code></pre></div>

<p>This attribute is documented in <code>create</code> above. The first version raises Not_found
if the attribute is None. The _opt version returns an option.</p>
</details>
<h3 id="alphas__2">alphas_<a class="headerlink" href="#alphas__2" title="Permanent link">&para;</a></h3>
<details class="note" open="open"><summary>attribute</summary><div class="highlight"><pre><span></span><code><span class="k">val</span> <span class="n">alphas_</span> <span class="o">:</span> <span class="n">t</span> <span class="o">-&gt;</span> <span class="nn">Arr</span><span class="p">.</span><span class="n">t</span>
<span class="k">val</span> <span class="n">alphas_opt</span> <span class="o">:</span> <span class="n">t</span> <span class="o">-&gt;</span> <span class="o">(</span><span class="nn">Arr</span><span class="p">.</span><span class="n">t</span><span class="o">)</span> <span class="n">option</span>
</code></pre></div>

<p>This attribute is documented in <code>create</code> above. The first version raises Not_found
if the attribute is None. The _opt version returns an option.</p>
</details>
<h3 id="cv_alphas_">cv_alphas_<a class="headerlink" href="#cv_alphas_" title="Permanent link">&para;</a></h3>
<details class="note" open="open"><summary>attribute</summary><div class="highlight"><pre><span></span><code><span class="k">val</span> <span class="n">cv_alphas_</span> <span class="o">:</span> <span class="n">t</span> <span class="o">-&gt;</span> <span class="nn">Arr</span><span class="p">.</span><span class="n">t</span>
<span class="k">val</span> <span class="n">cv_alphas_opt</span> <span class="o">:</span> <span class="n">t</span> <span class="o">-&gt;</span> <span class="o">(</span><span class="nn">Arr</span><span class="p">.</span><span class="n">t</span><span class="o">)</span> <span class="n">option</span>
</code></pre></div>

<p>This attribute is documented in <code>create</code> above. The first version raises Not_found
if the attribute is None. The _opt version returns an option.</p>
</details>
<h3 id="mse_path__1">mse_path_<a class="headerlink" href="#mse_path__1" title="Permanent link">&para;</a></h3>
<details class="note" open="open"><summary>attribute</summary><div class="highlight"><pre><span></span><code><span class="k">val</span> <span class="n">mse_path_</span> <span class="o">:</span> <span class="n">t</span> <span class="o">-&gt;</span> <span class="nn">Arr</span><span class="p">.</span><span class="n">t</span>
<span class="k">val</span> <span class="n">mse_path_opt</span> <span class="o">:</span> <span class="n">t</span> <span class="o">-&gt;</span> <span class="o">(</span><span class="nn">Arr</span><span class="p">.</span><span class="n">t</span><span class="o">)</span> <span class="n">option</span>
</code></pre></div>

<p>This attribute is documented in <code>create</code> above. The first version raises Not_found
if the attribute is None. The _opt version returns an option.</p>
</details>
<h3 id="n_iter__5">n_iter_<a class="headerlink" href="#n_iter__5" title="Permanent link">&para;</a></h3>
<details class="note" open="open"><summary>attribute</summary><div class="highlight"><pre><span></span><code><span class="k">val</span> <span class="n">n_iter_</span> <span class="o">:</span> <span class="n">t</span> <span class="o">-&gt;</span> <span class="o">[`</span><span class="nc">Arr</span> <span class="k">of</span> <span class="nn">Arr</span><span class="p">.</span><span class="n">t</span> <span class="o">|</span> <span class="o">`</span><span class="nc">I</span> <span class="k">of</span> <span class="kt">int</span><span class="o">]</span>
<span class="k">val</span> <span class="n">n_iter_opt</span> <span class="o">:</span> <span class="n">t</span> <span class="o">-&gt;</span> <span class="o">([`</span><span class="nc">Arr</span> <span class="k">of</span> <span class="nn">Arr</span><span class="p">.</span><span class="n">t</span> <span class="o">|</span> <span class="o">`</span><span class="nc">I</span> <span class="k">of</span> <span class="kt">int</span><span class="o">])</span> <span class="n">option</span>
</code></pre></div>

<p>This attribute is documented in <code>create</code> above. The first version raises Not_found
if the attribute is None. The _opt version returns an option.</p>
</details>
<h3 id="to_string_6">to_string<a class="headerlink" href="#to_string_6" title="Permanent link">&para;</a></h3>
<details class="note" open="open"><summary>method</summary><div class="highlight"><pre><span></span><code><span class="k">val</span> <span class="n">to_string</span><span class="o">:</span> <span class="n">t</span> <span class="o">-&gt;</span> <span class="kt">string</span>
</code></pre></div>

<p>Print the object to a human-readable representation.</p>
</details>
<h3 id="show_6">show<a class="headerlink" href="#show_6" title="Permanent link">&para;</a></h3>
<details class="note" open="open"><summary>method</summary><div class="highlight"><pre><span></span><code><span class="k">val</span> <span class="n">show</span><span class="o">:</span> <span class="n">t</span> <span class="o">-&gt;</span> <span class="kt">string</span>
</code></pre></div>

<p>Print the object to a human-readable representation.</p>
</details>
<h3 id="pp_6">pp<a class="headerlink" href="#pp_6" title="Permanent link">&para;</a></h3>
<details class="note" open="open"><summary>method</summary><div class="highlight"><pre><span></span><code><span class="k">val</span> <span class="n">pp</span><span class="o">:</span> <span class="nn">Format</span><span class="p">.</span><span class="n">formatter</span> <span class="o">-&gt;</span> <span class="n">t</span> <span class="o">-&gt;</span> <span class="kt">unit</span>
</code></pre></div>

<p>Pretty-print the object to a formatter.</p>
</details>
<h2 id="module-sklearnlinear_modellasso">module Sklearn.​Linear_model.​Lasso<a class="headerlink" href="#module-sklearnlinear_modellasso" title="Permanent link">&para;</a></h2>
<div class="highlight"><pre><span></span><code><span class="k">type</span> <span class="n">t</span>
</code></pre></div>

<h3 id="create_7">create<a class="headerlink" href="#create_7" title="Permanent link">&para;</a></h3>
<details class="note" open="open"><summary>constructor and attributes</summary><div class="highlight"><pre><span></span><code><span class="k">val</span> <span class="n">create</span> <span class="o">:</span>
  <span class="o">?</span><span class="n">alpha</span><span class="o">:</span><span class="kt">float</span> <span class="o">-&gt;</span>
  <span class="o">?</span><span class="n">fit_intercept</span><span class="o">:</span><span class="kt">bool</span> <span class="o">-&gt;</span>
  <span class="o">?</span><span class="n">normalize</span><span class="o">:</span><span class="kt">bool</span> <span class="o">-&gt;</span>
  <span class="o">?</span><span class="n">precompute</span><span class="o">:[`</span><span class="nc">Bool</span> <span class="k">of</span> <span class="kt">bool</span> <span class="o">|</span> <span class="o">`</span><span class="nc">Arr</span> <span class="k">of</span> <span class="nn">Arr</span><span class="p">.</span><span class="n">t</span><span class="o">]</span> <span class="o">-&gt;</span>
  <span class="o">?</span><span class="n">copy_X</span><span class="o">:</span><span class="kt">bool</span> <span class="o">-&gt;</span>
  <span class="o">?</span><span class="n">max_iter</span><span class="o">:</span><span class="kt">int</span> <span class="o">-&gt;</span>
  <span class="o">?</span><span class="n">tol</span><span class="o">:</span><span class="kt">float</span> <span class="o">-&gt;</span>
  <span class="o">?</span><span class="n">warm_start</span><span class="o">:</span><span class="kt">bool</span> <span class="o">-&gt;</span>
  <span class="o">?</span><span class="n">positive</span><span class="o">:</span><span class="kt">bool</span> <span class="o">-&gt;</span>
  <span class="o">?</span><span class="n">random_state</span><span class="o">:</span><span class="kt">int</span> <span class="o">-&gt;</span>
  <span class="o">?</span><span class="n">selection</span><span class="o">:</span><span class="kt">string</span> <span class="o">-&gt;</span>
  <span class="kt">unit</span> <span class="o">-&gt;</span>
  <span class="n">t</span>
</code></pre></div>

<p>Linear Model trained with L1 prior as regularizer (aka the Lasso)</p>
<p>The optimization objective for Lasso is::</p>
<div class="codehilite"><pre><span></span><code>(1 / (2 * n_samples)) * ||y - Xw||^2_2 + alpha * ||w||_1
</code></pre></div>


<p>Technically the Lasso model is optimizing the same objective function as
the Elastic Net with <code>l1_ratio=1.0</code> (no L2 penalty).</p>
<p>Read more in the :ref:<code>User Guide &lt;lasso&gt;</code>.</p>
<h4>Parameters</h4>
<details class="info" open="open"><summary>alpha : float, optional</summary><p>Constant that multiplies the L1 term. Defaults to 1.0.
<code>alpha = 0</code> is equivalent to an ordinary least square, solved
by the :class:<code>LinearRegression</code> object. For numerical
reasons, using <code>alpha = 0</code> with the <code>Lasso</code> object is not advised.
Given this, you should use the :class:<code>LinearRegression</code> object.</p>
</details>
<details class="info" open="open"><summary>fit_intercept : boolean, optional, default True</summary><p>Whether to calculate the intercept for this model. If set
to False, no intercept will be used in calculations
(i.e. data is expected to be centered).</p>
</details>
<details class="info" open="open"><summary>normalize : boolean, optional, default False</summary><p>This parameter is ignored when <code>fit_intercept</code> is set to False.
If True, the regressors X will be normalized before regression by
subtracting the mean and dividing by the l2-norm.
If you wish to standardize, please use
:class:<code>sklearn.preprocessing.StandardScaler</code> before calling <code>fit</code>
on an estimator with <code>normalize=False</code>.</p>
</details>
<details class="info" open="open"><summary>precompute : True | False | array-like, default=False</summary><p>Whether to use a precomputed Gram matrix to speed up
calculations. If set to <code>'auto'</code> let us decide. The Gram
matrix can also be passed as argument. For sparse input
this option is always <code>True</code> to preserve sparsity.</p>
</details>
<details class="info" open="open"><summary>copy_X : boolean, optional, default True</summary><p>If <code>True</code>, X will be copied; else, it may be overwritten.</p>
</details>
<details class="info" open="open"><summary>max_iter : int, optional</summary><p>The maximum number of iterations</p>
</details>
<details class="info" open="open"><summary>tol : float, optional</summary><p>The tolerance for the optimization: if the updates are
smaller than <code>tol</code>, the optimization code checks the
dual gap for optimality and continues until it is smaller
than <code>tol</code>.</p>
</details>
<details class="info" open="open"><summary>warm_start : bool, optional</summary><p>When set to True, reuse the solution of the previous call to fit as
initialization, otherwise, just erase the previous solution.</p>
</details>
<details class="info" open="open"><summary>See :term:<code>the Glossary &lt;warm_start&gt;</code>.</summary></details>
<details class="info" open="open"><summary>positive : bool, optional</summary><p>When set to <code>True</code>, forces the coefficients to be positive.</p>
</details>
<details class="info" open="open"><summary>random_state : int, RandomState instance or None, optional, default None</summary><p>The seed of the pseudo random number generator that selects a random
feature to update.  If int, random_state is the seed used by the random
number generator; If RandomState instance, random_state is the random
number generator; If None, the random number generator is the
RandomState instance used by <code>np.random</code>. Used when <code>selection</code> ==
'random'.</p>
</details>
<details class="info" open="open"><summary>selection : str, default 'cyclic'</summary><p>If set to 'random', a random coefficient is updated every iteration
rather than looping over features sequentially by default. This
(setting to 'random') often leads to significantly faster convergence
especially when tol is higher than 1e-4.</p>
</details>
<h4>Attributes</h4>
<details class="info" open="open"><summary>coef_ : array, shape (n_features,) | (n_targets, n_features)</summary><p>parameter vector (w in the cost function formula)</p>
</details>
<details class="info" open="open"><summary>sparse_coef_ : scipy.sparse matrix, shape (n_features, 1) |             (n_targets, n_features)</summary><p><code>sparse_coef_</code> is a readonly property derived from <code>coef_</code></p>
</details>
<details class="info" open="open"><summary>intercept_ : float | array, shape (n_targets,)</summary><p>independent term in decision function.</p>
</details>
<details class="info" open="open"><summary>n_iter_ : int | array-like, shape (n_targets,)</summary><p>number of iterations run by the coordinate descent solver to reach
the specified tolerance.</p>
</details>
<h4>Examples</h4>
<div class="highlight"><pre><span></span><code><span class="o">&gt;&gt;&gt;</span> <span class="kn">from</span> <span class="nn">sklearn</span> <span class="kn">import</span> <span class="n">linear_model</span>
<span class="o">&gt;&gt;&gt;</span> <span class="n">clf</span> <span class="o">=</span> <span class="n">linear_model</span><span class="o">.</span><span class="n">Lasso</span><span class="p">(</span><span class="n">alpha</span><span class="o">=</span><span class="mf">0.1</span><span class="p">)</span>
<span class="o">&gt;&gt;&gt;</span> <span class="n">clf</span><span class="o">.</span><span class="n">fit</span><span class="p">([[</span><span class="mi">0</span><span class="p">,</span><span class="mi">0</span><span class="p">],</span> <span class="p">[</span><span class="mi">1</span><span class="p">,</span> <span class="mi">1</span><span class="p">],</span> <span class="p">[</span><span class="mi">2</span><span class="p">,</span> <span class="mi">2</span><span class="p">]],</span> <span class="p">[</span><span class="mi">0</span><span class="p">,</span> <span class="mi">1</span><span class="p">,</span> <span class="mi">2</span><span class="p">])</span>
<span class="n">Lasso</span><span class="p">(</span><span class="n">alpha</span><span class="o">=</span><span class="mf">0.1</span><span class="p">)</span>
<span class="o">&gt;&gt;&gt;</span> <span class="nb">print</span><span class="p">(</span><span class="n">clf</span><span class="o">.</span><span class="n">coef_</span><span class="p">)</span>
<span class="p">[</span><span class="mf">0.85</span> <span class="mf">0.</span>  <span class="p">]</span>
<span class="o">&gt;&gt;&gt;</span> <span class="nb">print</span><span class="p">(</span><span class="n">clf</span><span class="o">.</span><span class="n">intercept_</span><span class="p">)</span>
<span class="mf">0.15</span><span class="o">...</span>
</code></pre></div>

<h4>See also</h4>
<p>lars_path
lasso_path
LassoLars
LassoCV
LassoLarsCV
sklearn.decomposition.sparse_encode</p>
<h4>Notes</h4>
<p>The algorithm used to fit the model is coordinate descent.</p>
<p>To avoid unnecessary memory duplication the X argument of the fit method
should be directly passed as a Fortran-contiguous numpy array.</p>
</details>
<h3 id="fit_7">fit<a class="headerlink" href="#fit_7" title="Permanent link">&para;</a></h3>
<details class="note" open="open"><summary>method</summary><div class="highlight"><pre><span></span><code><span class="k">val</span> <span class="n">fit</span> <span class="o">:</span>
  <span class="o">?</span><span class="n">check_input</span><span class="o">:</span><span class="kt">bool</span> <span class="o">-&gt;</span>
  <span class="n">x</span><span class="o">:[`</span><span class="nc">Arr</span> <span class="k">of</span> <span class="nn">Arr</span><span class="p">.</span><span class="n">t</span> <span class="o">|</span> <span class="o">`</span><span class="nc">PyObject</span> <span class="k">of</span> <span class="nn">Py</span><span class="p">.</span><span class="nn">Object</span><span class="p">.</span><span class="n">t</span><span class="o">]</span> <span class="o">-&gt;</span>
  <span class="n">y</span><span class="o">:</span><span class="nn">Arr</span><span class="p">.</span><span class="n">t</span> <span class="o">-&gt;</span>
  <span class="n">t</span> <span class="o">-&gt;</span>
  <span class="n">t</span>
</code></pre></div>

<p>Fit model with coordinate descent.</p>
<h4>Parameters</h4>
<details class="info" open="open"><summary>X : ndarray or scipy.sparse matrix, (n_samples, n_features)</summary><p>Data</p>
</details>
<details class="info" open="open"><summary>y : ndarray, shape (n_samples,) or (n_samples, n_targets)</summary><p>Target. Will be cast to X's dtype if necessary</p>
</details>
<details class="info" open="open"><summary>check_input : boolean, (default=True)</summary><p>Allow to bypass several input checking.
Don't use this parameter unless you know what you do.</p>
</details>
<h4>Notes</h4>
<p>Coordinate descent is an algorithm that considers each column of
data at a time hence it will automatically convert the X input
as a Fortran-contiguous numpy array if necessary.</p>
<p>To avoid memory re-allocation it is advised to allocate the
initial data in memory directly using that format.</p>
</details>
<h3 id="get_params_7">get_params<a class="headerlink" href="#get_params_7" title="Permanent link">&para;</a></h3>
<details class="note" open="open"><summary>method</summary><div class="highlight"><pre><span></span><code><span class="k">val</span> <span class="n">get_params</span> <span class="o">:</span>
  <span class="o">?</span><span class="n">deep</span><span class="o">:</span><span class="kt">bool</span> <span class="o">-&gt;</span>
  <span class="n">t</span> <span class="o">-&gt;</span>
  <span class="nn">Dict</span><span class="p">.</span><span class="n">t</span>
</code></pre></div>

<p>Get parameters for this estimator.</p>
<h4>Parameters</h4>
<details class="info" open="open"><summary>deep : bool, default=True</summary><p>If True, will return the parameters for this estimator and
contained subobjects that are estimators.</p>
</details>
<h4>Returns</h4>
<details class="info" open="open"><summary>params : mapping of string to any</summary><p>Parameter names mapped to their values.</p>
</details>
</details>
<h3 id="predict_7">predict<a class="headerlink" href="#predict_7" title="Permanent link">&para;</a></h3>
<details class="note" open="open"><summary>method</summary><div class="highlight"><pre><span></span><code><span class="k">val</span> <span class="n">predict</span> <span class="o">:</span>
  <span class="n">x</span><span class="o">:</span><span class="nn">Arr</span><span class="p">.</span><span class="n">t</span> <span class="o">-&gt;</span>
  <span class="n">t</span> <span class="o">-&gt;</span>
  <span class="nn">Arr</span><span class="p">.</span><span class="n">t</span>
</code></pre></div>

<p>Predict using the linear model.</p>
<h4>Parameters</h4>
<details class="info" open="open"><summary>X : array_like or sparse matrix, shape (n_samples, n_features)</summary><p>Samples.</p>
</details>
<h4>Returns</h4>
<details class="info" open="open"><summary>C : array, shape (n_samples,)</summary><p>Returns predicted values.</p>
</details>
</details>
<h3 id="score_7">score<a class="headerlink" href="#score_7" title="Permanent link">&para;</a></h3>
<details class="note" open="open"><summary>method</summary><div class="highlight"><pre><span></span><code><span class="k">val</span> <span class="n">score</span> <span class="o">:</span>
  <span class="o">?</span><span class="n">sample_weight</span><span class="o">:</span><span class="nn">Arr</span><span class="p">.</span><span class="n">t</span> <span class="o">-&gt;</span>
  <span class="n">x</span><span class="o">:</span><span class="nn">Arr</span><span class="p">.</span><span class="n">t</span> <span class="o">-&gt;</span>
  <span class="n">y</span><span class="o">:</span><span class="nn">Arr</span><span class="p">.</span><span class="n">t</span> <span class="o">-&gt;</span>
  <span class="n">t</span> <span class="o">-&gt;</span>
  <span class="kt">float</span>
</code></pre></div>

<p>Return the coefficient of determination R^2 of the prediction.</p>
<p>The coefficient R^2 is defined as (1 - u/v), where u is the residual
sum of squares ((y_true - y_pred) <strong> 2).sum() and v is the total
sum of squares ((y_true - y_true.mean()) </strong> 2).sum().
The best possible score is 1.0 and it can be negative (because the
model can be arbitrarily worse). A constant model that always
predicts the expected value of y, disregarding the input features,
would get a R^2 score of 0.0.</p>
<h4>Parameters</h4>
<details class="info" open="open"><summary>X : array-like of shape (n_samples, n_features)</summary><p>Test samples. For some estimators this may be a
precomputed kernel matrix or a list of generic objects instead,
shape = (n_samples, n_samples_fitted),
where n_samples_fitted is the number of
samples used in the fitting for the estimator.</p>
</details>
<details class="info" open="open"><summary>y : array-like of shape (n_samples,) or (n_samples, n_outputs)</summary><p>True values for X.</p>
</details>
<details class="info" open="open"><summary>sample_weight : array-like of shape (n_samples,), default=None</summary><p>Sample weights.</p>
</details>
<h4>Returns</h4>
<details class="info" open="open"><summary>score : float</summary><p>R^2 of self.predict(X) wrt. y.</p>
</details>
<h4>Notes</h4>
<p>The R2 score used when calling <code>score</code> on a regressor will use
<code>multioutput='uniform_average'</code> from version 0.23 to keep consistent</p>
<details class="info" open="open"><summary>with :func:<code>~sklearn.metrics.r2_score</code>. This will influence the</summary></details>
<p><code>score</code> method of all the multioutput regressors (except for
:class:<code>~sklearn.multioutput.MultiOutputRegressor</code>). To specify the
default value manually and avoid the warning, please either call
:func:<code>~sklearn.metrics.r2_score</code> directly or make a custom scorer with
:func:<code>~sklearn.metrics.make_scorer</code> (the built-in scorer <code>'r2'</code> uses
<code>multioutput='uniform_average'</code>).</p>
</details>
<h3 id="set_params_7">set_params<a class="headerlink" href="#set_params_7" title="Permanent link">&para;</a></h3>
<details class="note" open="open"><summary>method</summary><div class="highlight"><pre><span></span><code><span class="k">val</span> <span class="n">set_params</span> <span class="o">:</span>
  <span class="o">?</span><span class="n">params</span><span class="o">:(</span><span class="kt">string</span> <span class="o">*</span> <span class="nn">Py</span><span class="p">.</span><span class="nn">Object</span><span class="p">.</span><span class="n">t</span><span class="o">)</span> <span class="kt">list</span> <span class="o">-&gt;</span>
  <span class="n">t</span> <span class="o">-&gt;</span>
  <span class="n">t</span>
</code></pre></div>

<p>Set the parameters of this estimator.</p>
<p>The method works on simple estimators as well as on nested objects
(such as pipelines). The latter have parameters of the form
<code>&lt;component&gt;__&lt;parameter&gt;</code> so that it's possible to update each
component of a nested object.</p>
<h4>Parameters</h4>
<details class="info" open="open"><summary>**params : dict</summary><p>Estimator parameters.</p>
</details>
<h4>Returns</h4>
<details class="info" open="open"><summary>self : object</summary><p>Estimator instance.</p>
</details>
</details>
<h3 id="coef__7">coef_<a class="headerlink" href="#coef__7" title="Permanent link">&para;</a></h3>
<details class="note" open="open"><summary>attribute</summary><div class="highlight"><pre><span></span><code><span class="k">val</span> <span class="n">coef_</span> <span class="o">:</span> <span class="n">t</span> <span class="o">-&gt;</span> <span class="nn">Arr</span><span class="p">.</span><span class="n">t</span>
<span class="k">val</span> <span class="n">coef_opt</span> <span class="o">:</span> <span class="n">t</span> <span class="o">-&gt;</span> <span class="o">(</span><span class="nn">Arr</span><span class="p">.</span><span class="n">t</span><span class="o">)</span> <span class="n">option</span>
</code></pre></div>

<p>This attribute is documented in <code>create</code> above. The first version raises Not_found
if the attribute is None. The _opt version returns an option.</p>
</details>
<h3 id="sparse_coef__1">sparse_coef_<a class="headerlink" href="#sparse_coef__1" title="Permanent link">&para;</a></h3>
<details class="note" open="open"><summary>attribute</summary><div class="highlight"><pre><span></span><code><span class="k">val</span> <span class="n">sparse_coef_</span> <span class="o">:</span> <span class="n">t</span> <span class="o">-&gt;</span> <span class="nn">Py</span><span class="p">.</span><span class="nn">Object</span><span class="p">.</span><span class="n">t</span>
<span class="k">val</span> <span class="n">sparse_coef_opt</span> <span class="o">:</span> <span class="n">t</span> <span class="o">-&gt;</span> <span class="o">(</span><span class="nn">Py</span><span class="p">.</span><span class="nn">Object</span><span class="p">.</span><span class="n">t</span><span class="o">)</span> <span class="n">option</span>
</code></pre></div>

<p>This attribute is documented in <code>create</code> above. The first version raises Not_found
if the attribute is None. The _opt version returns an option.</p>
</details>
<h3 id="intercept__7">intercept_<a class="headerlink" href="#intercept__7" title="Permanent link">&para;</a></h3>
<details class="note" open="open"><summary>attribute</summary><div class="highlight"><pre><span></span><code><span class="k">val</span> <span class="n">intercept_</span> <span class="o">:</span> <span class="n">t</span> <span class="o">-&gt;</span> <span class="nn">Arr</span><span class="p">.</span><span class="n">t</span>
<span class="k">val</span> <span class="n">intercept_opt</span> <span class="o">:</span> <span class="n">t</span> <span class="o">-&gt;</span> <span class="o">(</span><span class="nn">Arr</span><span class="p">.</span><span class="n">t</span><span class="o">)</span> <span class="n">option</span>
</code></pre></div>

<p>This attribute is documented in <code>create</code> above. The first version raises Not_found
if the attribute is None. The _opt version returns an option.</p>
</details>
<h3 id="n_iter__6">n_iter_<a class="headerlink" href="#n_iter__6" title="Permanent link">&para;</a></h3>
<details class="note" open="open"><summary>attribute</summary><div class="highlight"><pre><span></span><code><span class="k">val</span> <span class="n">n_iter_</span> <span class="o">:</span> <span class="n">t</span> <span class="o">-&gt;</span> <span class="o">[`</span><span class="nc">I</span> <span class="k">of</span> <span class="kt">int</span> <span class="o">|</span> <span class="o">`</span><span class="nc">Arr</span> <span class="k">of</span> <span class="nn">Arr</span><span class="p">.</span><span class="n">t</span><span class="o">]</span>
<span class="k">val</span> <span class="n">n_iter_opt</span> <span class="o">:</span> <span class="n">t</span> <span class="o">-&gt;</span> <span class="o">([`</span><span class="nc">I</span> <span class="k">of</span> <span class="kt">int</span> <span class="o">|</span> <span class="o">`</span><span class="nc">Arr</span> <span class="k">of</span> <span class="nn">Arr</span><span class="p">.</span><span class="n">t</span><span class="o">])</span> <span class="n">option</span>
</code></pre></div>

<p>This attribute is documented in <code>create</code> above. The first version raises Not_found
if the attribute is None. The _opt version returns an option.</p>
</details>
<h3 id="to_string_7">to_string<a class="headerlink" href="#to_string_7" title="Permanent link">&para;</a></h3>
<details class="note" open="open"><summary>method</summary><div class="highlight"><pre><span></span><code><span class="k">val</span> <span class="n">to_string</span><span class="o">:</span> <span class="n">t</span> <span class="o">-&gt;</span> <span class="kt">string</span>
</code></pre></div>

<p>Print the object to a human-readable representation.</p>
</details>
<h3 id="show_7">show<a class="headerlink" href="#show_7" title="Permanent link">&para;</a></h3>
<details class="note" open="open"><summary>method</summary><div class="highlight"><pre><span></span><code><span class="k">val</span> <span class="n">show</span><span class="o">:</span> <span class="n">t</span> <span class="o">-&gt;</span> <span class="kt">string</span>
</code></pre></div>

<p>Print the object to a human-readable representation.</p>
</details>
<h3 id="pp_7">pp<a class="headerlink" href="#pp_7" title="Permanent link">&para;</a></h3>
<details class="note" open="open"><summary>method</summary><div class="highlight"><pre><span></span><code><span class="k">val</span> <span class="n">pp</span><span class="o">:</span> <span class="nn">Format</span><span class="p">.</span><span class="n">formatter</span> <span class="o">-&gt;</span> <span class="n">t</span> <span class="o">-&gt;</span> <span class="kt">unit</span>
</code></pre></div>

<p>Pretty-print the object to a formatter.</p>
</details>
<h2 id="module-sklearnlinear_modellassocv">module Sklearn.​Linear_model.​LassoCV<a class="headerlink" href="#module-sklearnlinear_modellassocv" title="Permanent link">&para;</a></h2>
<div class="highlight"><pre><span></span><code><span class="k">type</span> <span class="n">t</span>
</code></pre></div>

<h3 id="create_8">create<a class="headerlink" href="#create_8" title="Permanent link">&para;</a></h3>
<details class="note" open="open"><summary>constructor and attributes</summary><div class="highlight"><pre><span></span><code><span class="k">val</span> <span class="n">create</span> <span class="o">:</span>
  <span class="o">?</span><span class="n">eps</span><span class="o">:</span><span class="kt">float</span> <span class="o">-&gt;</span>
  <span class="o">?</span><span class="n">n_alphas</span><span class="o">:</span><span class="kt">int</span> <span class="o">-&gt;</span>
  <span class="o">?</span><span class="n">alphas</span><span class="o">:</span><span class="nn">Arr</span><span class="p">.</span><span class="n">t</span> <span class="o">-&gt;</span>
  <span class="o">?</span><span class="n">fit_intercept</span><span class="o">:</span><span class="kt">bool</span> <span class="o">-&gt;</span>
  <span class="o">?</span><span class="n">normalize</span><span class="o">:</span><span class="kt">bool</span> <span class="o">-&gt;</span>
  <span class="o">?</span><span class="n">precompute</span><span class="o">:[`</span><span class="nc">Bool</span> <span class="k">of</span> <span class="kt">bool</span> <span class="o">|</span> <span class="o">`</span><span class="nc">Auto</span> <span class="o">|</span> <span class="o">`</span><span class="nc">Arr</span> <span class="k">of</span> <span class="nn">Arr</span><span class="p">.</span><span class="n">t</span><span class="o">]</span> <span class="o">-&gt;</span>
  <span class="o">?</span><span class="n">max_iter</span><span class="o">:</span><span class="kt">int</span> <span class="o">-&gt;</span>
  <span class="o">?</span><span class="n">tol</span><span class="o">:</span><span class="kt">float</span> <span class="o">-&gt;</span>
  <span class="o">?</span><span class="n">copy_X</span><span class="o">:</span><span class="kt">bool</span> <span class="o">-&gt;</span>
  <span class="o">?</span><span class="n">cv</span><span class="o">:[`</span><span class="nc">I</span> <span class="k">of</span> <span class="kt">int</span> <span class="o">|</span> <span class="o">`</span><span class="nc">CrossValGenerator</span> <span class="k">of</span> <span class="nn">Py</span><span class="p">.</span><span class="nn">Object</span><span class="p">.</span><span class="n">t</span> <span class="o">|</span> <span class="o">`</span><span class="nc">Arr</span> <span class="k">of</span> <span class="nn">Arr</span><span class="p">.</span><span class="n">t</span><span class="o">]</span> <span class="o">-&gt;</span>
  <span class="o">?</span><span class="n">verbose</span><span class="o">:</span><span class="kt">int</span> <span class="o">-&gt;</span>
  <span class="o">?</span><span class="n">n_jobs</span><span class="o">:</span><span class="kt">int</span> <span class="o">-&gt;</span>
  <span class="o">?</span><span class="n">positive</span><span class="o">:</span><span class="kt">bool</span> <span class="o">-&gt;</span>
  <span class="o">?</span><span class="n">random_state</span><span class="o">:</span><span class="kt">int</span> <span class="o">-&gt;</span>
  <span class="o">?</span><span class="n">selection</span><span class="o">:</span><span class="kt">string</span> <span class="o">-&gt;</span>
  <span class="kt">unit</span> <span class="o">-&gt;</span>
  <span class="n">t</span>
</code></pre></div>

<p>Lasso linear model with iterative fitting along a regularization path.</p>
<p>See glossary entry for :term:<code>cross-validation estimator</code>.</p>
<p>The best model is selected by cross-validation.</p>
<p>The optimization objective for Lasso is::</p>
<div class="codehilite"><pre><span></span><code>(1 / (2 * n_samples)) * ||y - Xw||^2_2 + alpha * ||w||_1
</code></pre></div>


<p>Read more in the :ref:<code>User Guide &lt;lasso&gt;</code>.</p>
<h4>Parameters</h4>
<details class="info" open="open"><summary>eps : float, optional</summary><p>Length of the path. <code>eps=1e-3</code> means that
<code>alpha_min / alpha_max = 1e-3</code>.</p>
</details>
<details class="info" open="open"><summary>n_alphas : int, optional</summary><p>Number of alphas along the regularization path</p>
</details>
<details class="info" open="open"><summary>alphas : numpy array, optional</summary><p>List of alphas where to compute the models.
If <code>None</code> alphas are set automatically</p>
</details>
<details class="info" open="open"><summary>fit_intercept : boolean, default True</summary><p>whether to calculate the intercept for this model. If set
to false, no intercept will be used in calculations
(i.e. data is expected to be centered).</p>
</details>
<details class="info" open="open"><summary>normalize : boolean, optional, default False</summary><p>This parameter is ignored when <code>fit_intercept</code> is set to False.
If True, the regressors X will be normalized before regression by
subtracting the mean and dividing by the l2-norm.
If you wish to standardize, please use
:class:<code>sklearn.preprocessing.StandardScaler</code> before calling <code>fit</code>
on an estimator with <code>normalize=False</code>.</p>
</details>
<details class="info" open="open"><summary>precompute : True | False | 'auto' | array-like</summary><p>Whether to use a precomputed Gram matrix to speed up
calculations. If set to <code>'auto'</code> let us decide. The Gram
matrix can also be passed as argument.</p>
</details>
<details class="info" open="open"><summary>max_iter : int, optional</summary><p>The maximum number of iterations</p>
</details>
<details class="info" open="open"><summary>tol : float, optional</summary><p>The tolerance for the optimization: if the updates are
smaller than <code>tol</code>, the optimization code checks the
dual gap for optimality and continues until it is smaller
than <code>tol</code>.</p>
</details>
<details class="info" open="open"><summary>copy_X : boolean, optional, default True</summary><p>If <code>True</code>, X will be copied; else, it may be overwritten.</p>
</details>
<details class="info" open="open"><summary>cv : int, cross-validation generator or an iterable, optional</summary><p>Determines the cross-validation splitting strategy.
Possible inputs for cv are:</p>
<ul>
<li>None, to use the default 5-fold cross-validation,</li>
<li>integer, to specify the number of folds.</li>
<li>:term:<code>CV splitter</code>,</li>
<li>An iterable yielding (train, test) splits as arrays of indices.</li>
</ul>
<p>For integer/None inputs, :class:<code>KFold</code> is used.</p>
</details>
<details class="info" open="open"><summary>Refer :ref:<code>User Guide &lt;cross_validation&gt;</code> for the various</summary><p>cross-validation strategies that can be used here.</p>
<p>.. versionchanged:: 0.22
    <code>cv</code> default value if None changed from 3-fold to 5-fold.</p>
</details>
<details class="info" open="open"><summary>verbose : bool or integer</summary><p>Amount of verbosity.</p>
</details>
<details class="info" open="open"><summary>n_jobs : int or None, optional (default=None)</summary><p>Number of CPUs to use during the cross validation.
<code>None</code> means 1 unless in a :obj:<code>joblib.parallel_backend</code> context.
<code>-1</code> means using all processors. See :term:<code>Glossary &lt;n_jobs&gt;</code>
for more details.</p>
</details>
<details class="info" open="open"><summary>positive : bool, optional</summary><p>If positive, restrict regression coefficients to be positive</p>
</details>
<details class="info" open="open"><summary>random_state : int, RandomState instance or None, optional, default None</summary><p>The seed of the pseudo random number generator that selects a random
feature to update.  If int, random_state is the seed used by the random
number generator; If RandomState instance, random_state is the random
number generator; If None, the random number generator is the
RandomState instance used by <code>np.random</code>. Used when <code>selection</code> ==
'random'.</p>
</details>
<details class="info" open="open"><summary>selection : str, default 'cyclic'</summary><p>If set to 'random', a random coefficient is updated every iteration
rather than looping over features sequentially by default. This
(setting to 'random') often leads to significantly faster convergence
especially when tol is higher than 1e-4.</p>
</details>
<h4>Attributes</h4>
<details class="info" open="open"><summary>alpha_ : float</summary><p>The amount of penalization chosen by cross validation</p>
</details>
<details class="info" open="open"><summary>coef_ : array, shape (n_features,) | (n_targets, n_features)</summary><p>parameter vector (w in the cost function formula)</p>
</details>
<details class="info" open="open"><summary>intercept_ : float | array, shape (n_targets,)</summary><p>independent term in decision function.</p>
</details>
<details class="info" open="open"><summary>mse_path_ : array, shape (n_alphas, n_folds)</summary><p>mean square error for the test set on each fold, varying alpha</p>
</details>
<details class="info" open="open"><summary>alphas_ : numpy array, shape (n_alphas,)</summary><p>The grid of alphas used for fitting</p>
</details>
<details class="info" open="open"><summary>dual_gap_ : ndarray, shape ()</summary><p>The dual gap at the end of the optimization for the optimal alpha
(<code>alpha_</code>).</p>
</details>
<details class="info" open="open"><summary>n_iter_ : int</summary><p>number of iterations run by the coordinate descent solver to reach
the specified tolerance for the optimal alpha.</p>
</details>
<h4>Examples</h4>
<div class="highlight"><pre><span></span><code><span class="o">&gt;&gt;&gt;</span> <span class="kn">from</span> <span class="nn">sklearn.linear_model</span> <span class="kn">import</span> <span class="n">LassoCV</span>
<span class="o">&gt;&gt;&gt;</span> <span class="kn">from</span> <span class="nn">sklearn.datasets</span> <span class="kn">import</span> <span class="n">make_regression</span>
<span class="o">&gt;&gt;&gt;</span> <span class="n">X</span><span class="p">,</span> <span class="n">y</span> <span class="o">=</span> <span class="n">make_regression</span><span class="p">(</span><span class="n">noise</span><span class="o">=</span><span class="mi">4</span><span class="p">,</span> <span class="n">random_state</span><span class="o">=</span><span class="mi">0</span><span class="p">)</span>
<span class="o">&gt;&gt;&gt;</span> <span class="n">reg</span> <span class="o">=</span> <span class="n">LassoCV</span><span class="p">(</span><span class="n">cv</span><span class="o">=</span><span class="mi">5</span><span class="p">,</span> <span class="n">random_state</span><span class="o">=</span><span class="mi">0</span><span class="p">)</span><span class="o">.</span><span class="n">fit</span><span class="p">(</span><span class="n">X</span><span class="p">,</span> <span class="n">y</span><span class="p">)</span>
<span class="o">&gt;&gt;&gt;</span> <span class="n">reg</span><span class="o">.</span><span class="n">score</span><span class="p">(</span><span class="n">X</span><span class="p">,</span> <span class="n">y</span><span class="p">)</span>
<span class="mf">0.9993</span><span class="o">...</span>
<span class="o">&gt;&gt;&gt;</span> <span class="n">reg</span><span class="o">.</span><span class="n">predict</span><span class="p">(</span><span class="n">X</span><span class="p">[:</span><span class="mi">1</span><span class="p">,])</span>
<span class="n">array</span><span class="p">([</span><span class="o">-</span><span class="mf">78.4951</span><span class="o">...</span><span class="p">])</span>
</code></pre></div>

<h4>Notes</h4>
<p>For an example, see
:ref:<code>examples/linear_model/plot_lasso_model_selection.py
&lt;sphx_glr_auto_examples_linear_model_plot_lasso_model_selection.py&gt;</code>.</p>
<p>To avoid unnecessary memory duplication the X argument of the fit method
should be directly passed as a Fortran-contiguous numpy array.</p>
<h4>See also</h4>
<p>lars_path
lasso_path
LassoLars
Lasso
LassoLarsCV</p>
</details>
<h3 id="fit_8">fit<a class="headerlink" href="#fit_8" title="Permanent link">&para;</a></h3>
<details class="note" open="open"><summary>method</summary><div class="highlight"><pre><span></span><code><span class="k">val</span> <span class="n">fit</span> <span class="o">:</span>
  <span class="n">x</span><span class="o">:</span><span class="nn">Arr</span><span class="p">.</span><span class="n">t</span> <span class="o">-&gt;</span>
  <span class="n">y</span><span class="o">:</span><span class="nn">Arr</span><span class="p">.</span><span class="n">t</span> <span class="o">-&gt;</span>
  <span class="n">t</span> <span class="o">-&gt;</span>
  <span class="n">t</span>
</code></pre></div>

<p>Fit linear model with coordinate descent</p>
<p>Fit is on grid of alphas and best alpha estimated by cross-validation.</p>
<h4>Parameters</h4>
<details class="info" open="open"><summary>X : {array-like}, shape (n_samples, n_features)</summary><p>Training data. Pass directly as Fortran-contiguous data
to avoid unnecessary memory duplication. If y is mono-output,
X can be sparse.</p>
</details>
<details class="info" open="open"><summary>y : array-like, shape (n_samples,) or (n_samples, n_targets)</summary><p>Target values</p>
</details>
</details>
<h3 id="get_params_8">get_params<a class="headerlink" href="#get_params_8" title="Permanent link">&para;</a></h3>
<details class="note" open="open"><summary>method</summary><div class="highlight"><pre><span></span><code><span class="k">val</span> <span class="n">get_params</span> <span class="o">:</span>
  <span class="o">?</span><span class="n">deep</span><span class="o">:</span><span class="kt">bool</span> <span class="o">-&gt;</span>
  <span class="n">t</span> <span class="o">-&gt;</span>
  <span class="nn">Dict</span><span class="p">.</span><span class="n">t</span>
</code></pre></div>

<p>Get parameters for this estimator.</p>
<h4>Parameters</h4>
<details class="info" open="open"><summary>deep : bool, default=True</summary><p>If True, will return the parameters for this estimator and
contained subobjects that are estimators.</p>
</details>
<h4>Returns</h4>
<details class="info" open="open"><summary>params : mapping of string to any</summary><p>Parameter names mapped to their values.</p>
</details>
</details>
<h3 id="predict_8">predict<a class="headerlink" href="#predict_8" title="Permanent link">&para;</a></h3>
<details class="note" open="open"><summary>method</summary><div class="highlight"><pre><span></span><code><span class="k">val</span> <span class="n">predict</span> <span class="o">:</span>
  <span class="n">x</span><span class="o">:</span><span class="nn">Arr</span><span class="p">.</span><span class="n">t</span> <span class="o">-&gt;</span>
  <span class="n">t</span> <span class="o">-&gt;</span>
  <span class="nn">Arr</span><span class="p">.</span><span class="n">t</span>
</code></pre></div>

<p>Predict using the linear model.</p>
<h4>Parameters</h4>
<details class="info" open="open"><summary>X : array_like or sparse matrix, shape (n_samples, n_features)</summary><p>Samples.</p>
</details>
<h4>Returns</h4>
<details class="info" open="open"><summary>C : array, shape (n_samples,)</summary><p>Returns predicted values.</p>
</details>
</details>
<h3 id="score_8">score<a class="headerlink" href="#score_8" title="Permanent link">&para;</a></h3>
<details class="note" open="open"><summary>method</summary><div class="highlight"><pre><span></span><code><span class="k">val</span> <span class="n">score</span> <span class="o">:</span>
  <span class="o">?</span><span class="n">sample_weight</span><span class="o">:</span><span class="nn">Arr</span><span class="p">.</span><span class="n">t</span> <span class="o">-&gt;</span>
  <span class="n">x</span><span class="o">:</span><span class="nn">Arr</span><span class="p">.</span><span class="n">t</span> <span class="o">-&gt;</span>
  <span class="n">y</span><span class="o">:</span><span class="nn">Arr</span><span class="p">.</span><span class="n">t</span> <span class="o">-&gt;</span>
  <span class="n">t</span> <span class="o">-&gt;</span>
  <span class="kt">float</span>
</code></pre></div>

<p>Return the coefficient of determination R^2 of the prediction.</p>
<p>The coefficient R^2 is defined as (1 - u/v), where u is the residual
sum of squares ((y_true - y_pred) <strong> 2).sum() and v is the total
sum of squares ((y_true - y_true.mean()) </strong> 2).sum().
The best possible score is 1.0 and it can be negative (because the
model can be arbitrarily worse). A constant model that always
predicts the expected value of y, disregarding the input features,
would get a R^2 score of 0.0.</p>
<h4>Parameters</h4>
<details class="info" open="open"><summary>X : array-like of shape (n_samples, n_features)</summary><p>Test samples. For some estimators this may be a
precomputed kernel matrix or a list of generic objects instead,
shape = (n_samples, n_samples_fitted),
where n_samples_fitted is the number of
samples used in the fitting for the estimator.</p>
</details>
<details class="info" open="open"><summary>y : array-like of shape (n_samples,) or (n_samples, n_outputs)</summary><p>True values for X.</p>
</details>
<details class="info" open="open"><summary>sample_weight : array-like of shape (n_samples,), default=None</summary><p>Sample weights.</p>
</details>
<h4>Returns</h4>
<details class="info" open="open"><summary>score : float</summary><p>R^2 of self.predict(X) wrt. y.</p>
</details>
<h4>Notes</h4>
<p>The R2 score used when calling <code>score</code> on a regressor will use
<code>multioutput='uniform_average'</code> from version 0.23 to keep consistent</p>
<details class="info" open="open"><summary>with :func:<code>~sklearn.metrics.r2_score</code>. This will influence the</summary></details>
<p><code>score</code> method of all the multioutput regressors (except for
:class:<code>~sklearn.multioutput.MultiOutputRegressor</code>). To specify the
default value manually and avoid the warning, please either call
:func:<code>~sklearn.metrics.r2_score</code> directly or make a custom scorer with
:func:<code>~sklearn.metrics.make_scorer</code> (the built-in scorer <code>'r2'</code> uses
<code>multioutput='uniform_average'</code>).</p>
</details>
<h3 id="set_params_8">set_params<a class="headerlink" href="#set_params_8" title="Permanent link">&para;</a></h3>
<details class="note" open="open"><summary>method</summary><div class="highlight"><pre><span></span><code><span class="k">val</span> <span class="n">set_params</span> <span class="o">:</span>
  <span class="o">?</span><span class="n">params</span><span class="o">:(</span><span class="kt">string</span> <span class="o">*</span> <span class="nn">Py</span><span class="p">.</span><span class="nn">Object</span><span class="p">.</span><span class="n">t</span><span class="o">)</span> <span class="kt">list</span> <span class="o">-&gt;</span>
  <span class="n">t</span> <span class="o">-&gt;</span>
  <span class="n">t</span>
</code></pre></div>

<p>Set the parameters of this estimator.</p>
<p>The method works on simple estimators as well as on nested objects
(such as pipelines). The latter have parameters of the form
<code>&lt;component&gt;__&lt;parameter&gt;</code> so that it's possible to update each
component of a nested object.</p>
<h4>Parameters</h4>
<details class="info" open="open"><summary>**params : dict</summary><p>Estimator parameters.</p>
</details>
<h4>Returns</h4>
<details class="info" open="open"><summary>self : object</summary><p>Estimator instance.</p>
</details>
</details>
<h3 id="alpha__4">alpha_<a class="headerlink" href="#alpha__4" title="Permanent link">&para;</a></h3>
<details class="note" open="open"><summary>attribute</summary><div class="highlight"><pre><span></span><code><span class="k">val</span> <span class="n">alpha_</span> <span class="o">:</span> <span class="n">t</span> <span class="o">-&gt;</span> <span class="kt">float</span>
<span class="k">val</span> <span class="n">alpha_opt</span> <span class="o">:</span> <span class="n">t</span> <span class="o">-&gt;</span> <span class="o">(</span><span class="kt">float</span><span class="o">)</span> <span class="n">option</span>
</code></pre></div>

<p>This attribute is documented in <code>create</code> above. The first version raises Not_found
if the attribute is None. The _opt version returns an option.</p>
</details>
<h3 id="coef__8">coef_<a class="headerlink" href="#coef__8" title="Permanent link">&para;</a></h3>
<details class="note" open="open"><summary>attribute</summary><div class="highlight"><pre><span></span><code><span class="k">val</span> <span class="n">coef_</span> <span class="o">:</span> <span class="n">t</span> <span class="o">-&gt;</span> <span class="nn">Arr</span><span class="p">.</span><span class="n">t</span>
<span class="k">val</span> <span class="n">coef_opt</span> <span class="o">:</span> <span class="n">t</span> <span class="o">-&gt;</span> <span class="o">(</span><span class="nn">Arr</span><span class="p">.</span><span class="n">t</span><span class="o">)</span> <span class="n">option</span>
</code></pre></div>

<p>This attribute is documented in <code>create</code> above. The first version raises Not_found
if the attribute is None. The _opt version returns an option.</p>
</details>
<h3 id="intercept__8">intercept_<a class="headerlink" href="#intercept__8" title="Permanent link">&para;</a></h3>
<details class="note" open="open"><summary>attribute</summary><div class="highlight"><pre><span></span><code><span class="k">val</span> <span class="n">intercept_</span> <span class="o">:</span> <span class="n">t</span> <span class="o">-&gt;</span> <span class="nn">Arr</span><span class="p">.</span><span class="n">t</span>
<span class="k">val</span> <span class="n">intercept_opt</span> <span class="o">:</span> <span class="n">t</span> <span class="o">-&gt;</span> <span class="o">(</span><span class="nn">Arr</span><span class="p">.</span><span class="n">t</span><span class="o">)</span> <span class="n">option</span>
</code></pre></div>

<p>This attribute is documented in <code>create</code> above. The first version raises Not_found
if the attribute is None. The _opt version returns an option.</p>
</details>
<h3 id="mse_path__2">mse_path_<a class="headerlink" href="#mse_path__2" title="Permanent link">&para;</a></h3>
<details class="note" open="open"><summary>attribute</summary><div class="highlight"><pre><span></span><code><span class="k">val</span> <span class="n">mse_path_</span> <span class="o">:</span> <span class="n">t</span> <span class="o">-&gt;</span> <span class="nn">Arr</span><span class="p">.</span><span class="n">t</span>
<span class="k">val</span> <span class="n">mse_path_opt</span> <span class="o">:</span> <span class="n">t</span> <span class="o">-&gt;</span> <span class="o">(</span><span class="nn">Arr</span><span class="p">.</span><span class="n">t</span><span class="o">)</span> <span class="n">option</span>
</code></pre></div>

<p>This attribute is documented in <code>create</code> above. The first version raises Not_found
if the attribute is None. The _opt version returns an option.</p>
</details>
<h3 id="alphas__3">alphas_<a class="headerlink" href="#alphas__3" title="Permanent link">&para;</a></h3>
<details class="note" open="open"><summary>attribute</summary><div class="highlight"><pre><span></span><code><span class="k">val</span> <span class="n">alphas_</span> <span class="o">:</span> <span class="n">t</span> <span class="o">-&gt;</span> <span class="nn">Arr</span><span class="p">.</span><span class="n">t</span>
<span class="k">val</span> <span class="n">alphas_opt</span> <span class="o">:</span> <span class="n">t</span> <span class="o">-&gt;</span> <span class="o">(</span><span class="nn">Arr</span><span class="p">.</span><span class="n">t</span><span class="o">)</span> <span class="n">option</span>
</code></pre></div>

<p>This attribute is documented in <code>create</code> above. The first version raises Not_found
if the attribute is None. The _opt version returns an option.</p>
</details>
<h3 id="dual_gap_">dual_gap_<a class="headerlink" href="#dual_gap_" title="Permanent link">&para;</a></h3>
<details class="note" open="open"><summary>attribute</summary><div class="highlight"><pre><span></span><code><span class="k">val</span> <span class="n">dual_gap_</span> <span class="o">:</span> <span class="n">t</span> <span class="o">-&gt;</span> <span class="nn">Arr</span><span class="p">.</span><span class="n">t</span>
<span class="k">val</span> <span class="n">dual_gap_opt</span> <span class="o">:</span> <span class="n">t</span> <span class="o">-&gt;</span> <span class="o">(</span><span class="nn">Arr</span><span class="p">.</span><span class="n">t</span><span class="o">)</span> <span class="n">option</span>
</code></pre></div>

<p>This attribute is documented in <code>create</code> above. The first version raises Not_found
if the attribute is None. The _opt version returns an option.</p>
</details>
<h3 id="n_iter__7">n_iter_<a class="headerlink" href="#n_iter__7" title="Permanent link">&para;</a></h3>
<details class="note" open="open"><summary>attribute</summary><div class="highlight"><pre><span></span><code><span class="k">val</span> <span class="n">n_iter_</span> <span class="o">:</span> <span class="n">t</span> <span class="o">-&gt;</span> <span class="kt">int</span>
<span class="k">val</span> <span class="n">n_iter_opt</span> <span class="o">:</span> <span class="n">t</span> <span class="o">-&gt;</span> <span class="o">(</span><span class="kt">int</span><span class="o">)</span> <span class="n">option</span>
</code></pre></div>

<p>This attribute is documented in <code>create</code> above. The first version raises Not_found
if the attribute is None. The _opt version returns an option.</p>
</details>
<h3 id="to_string_8">to_string<a class="headerlink" href="#to_string_8" title="Permanent link">&para;</a></h3>
<details class="note" open="open"><summary>method</summary><div class="highlight"><pre><span></span><code><span class="k">val</span> <span class="n">to_string</span><span class="o">:</span> <span class="n">t</span> <span class="o">-&gt;</span> <span class="kt">string</span>
</code></pre></div>

<p>Print the object to a human-readable representation.</p>
</details>
<h3 id="show_8">show<a class="headerlink" href="#show_8" title="Permanent link">&para;</a></h3>
<details class="note" open="open"><summary>method</summary><div class="highlight"><pre><span></span><code><span class="k">val</span> <span class="n">show</span><span class="o">:</span> <span class="n">t</span> <span class="o">-&gt;</span> <span class="kt">string</span>
</code></pre></div>

<p>Print the object to a human-readable representation.</p>
</details>
<h3 id="pp_8">pp<a class="headerlink" href="#pp_8" title="Permanent link">&para;</a></h3>
<details class="note" open="open"><summary>method</summary><div class="highlight"><pre><span></span><code><span class="k">val</span> <span class="n">pp</span><span class="o">:</span> <span class="nn">Format</span><span class="p">.</span><span class="n">formatter</span> <span class="o">-&gt;</span> <span class="n">t</span> <span class="o">-&gt;</span> <span class="kt">unit</span>
</code></pre></div>

<p>Pretty-print the object to a formatter.</p>
</details>
<h2 id="module-sklearnlinear_modellassolars">module Sklearn.​Linear_model.​LassoLars<a class="headerlink" href="#module-sklearnlinear_modellassolars" title="Permanent link">&para;</a></h2>
<div class="highlight"><pre><span></span><code><span class="k">type</span> <span class="n">t</span>
</code></pre></div>

<h3 id="create_9">create<a class="headerlink" href="#create_9" title="Permanent link">&para;</a></h3>
<details class="note" open="open"><summary>constructor and attributes</summary><div class="highlight"><pre><span></span><code><span class="k">val</span> <span class="n">create</span> <span class="o">:</span>
  <span class="o">?</span><span class="n">alpha</span><span class="o">:</span><span class="kt">float</span> <span class="o">-&gt;</span>
  <span class="o">?</span><span class="n">fit_intercept</span><span class="o">:</span><span class="kt">bool</span> <span class="o">-&gt;</span>
  <span class="o">?</span><span class="n">verbose</span><span class="o">:</span><span class="kt">int</span> <span class="o">-&gt;</span>
  <span class="o">?</span><span class="n">normalize</span><span class="o">:</span><span class="kt">bool</span> <span class="o">-&gt;</span>
  <span class="o">?</span><span class="n">precompute</span><span class="o">:[`</span><span class="nc">Bool</span> <span class="k">of</span> <span class="kt">bool</span> <span class="o">|</span> <span class="o">`</span><span class="nc">Auto</span> <span class="o">|</span> <span class="o">`</span><span class="nc">Arr</span> <span class="k">of</span> <span class="nn">Arr</span><span class="p">.</span><span class="n">t</span><span class="o">]</span> <span class="o">-&gt;</span>
  <span class="o">?</span><span class="n">max_iter</span><span class="o">:</span><span class="kt">int</span> <span class="o">-&gt;</span>
  <span class="o">?</span><span class="n">eps</span><span class="o">:</span><span class="kt">float</span> <span class="o">-&gt;</span>
  <span class="o">?</span><span class="n">copy_X</span><span class="o">:</span><span class="kt">bool</span> <span class="o">-&gt;</span>
  <span class="o">?</span><span class="n">fit_path</span><span class="o">:</span><span class="kt">bool</span> <span class="o">-&gt;</span>
  <span class="o">?</span><span class="n">positive</span><span class="o">:</span><span class="kt">bool</span> <span class="o">-&gt;</span>
  <span class="kt">unit</span> <span class="o">-&gt;</span>
  <span class="n">t</span>
</code></pre></div>

<p>Lasso model fit with Least Angle Regression a.k.a. Lars</p>
<p>It is a Linear Model trained with an L1 prior as regularizer.</p>
<p>The optimization objective for Lasso is::</p>
<p>(1 / (2 * n_samples)) * ||y - Xw||^2_2 + alpha * ||w||_1</p>
<p>Read more in the :ref:<code>User Guide &lt;least_angle_regression&gt;</code>.</p>
<h4>Parameters</h4>
<details class="info" open="open"><summary>alpha : float, default=1.0</summary><p>Constant that multiplies the penalty term. Defaults to 1.0.
<code>alpha = 0</code> is equivalent to an ordinary least square, solved</p>
</details>
<details class="info" open="open"><summary>by :class:<code>LinearRegression</code>. For numerical reasons, using</summary><p><code>alpha = 0</code> with the LassoLars object is not advised and you
should prefer the LinearRegression object.</p>
</details>
<details class="info" open="open"><summary>fit_intercept : bool, default=True</summary><p>whether to calculate the intercept for this model. If set
to false, no intercept will be used in calculations
(i.e. data is expected to be centered).</p>
</details>
<details class="info" open="open"><summary>verbose : bool or int, default=False</summary><p>Sets the verbosity amount</p>
</details>
<details class="info" open="open"><summary>normalize : bool, default=True</summary><p>This parameter is ignored when <code>fit_intercept</code> is set to False.
If True, the regressors X will be normalized before regression by
subtracting the mean and dividing by the l2-norm.
If you wish to standardize, please use
:class:<code>sklearn.preprocessing.StandardScaler</code> before calling <code>fit</code>
on an estimator with <code>normalize=False</code>.</p>
</details>
<details class="info" open="open"><summary>precompute : bool, 'auto' or array-like, default='auto'</summary><p>Whether to use a precomputed Gram matrix to speed up
calculations. If set to <code>'auto'</code> let us decide. The Gram
matrix can also be passed as argument.</p>
</details>
<details class="info" open="open"><summary>max_iter : int, default=500</summary><p>Maximum number of iterations to perform.</p>
</details>
<details class="info" open="open"><summary>eps : float, optional</summary><p>The machine-precision regularization in the computation of the
Cholesky diagonal factors. Increase this for very ill-conditioned
systems. Unlike the <code>tol</code> parameter in some iterative
optimization-based algorithms, this parameter does not control
the tolerance of the optimization.
By default, <code>np.finfo(np.float).eps</code> is used.</p>
</details>
<details class="info" open="open"><summary>copy_X : bool, default=True</summary><p>If True, X will be copied; else, it may be overwritten.</p>
</details>
<details class="info" open="open"><summary>fit_path : bool, default=True</summary><p>If <code>True</code> the full path is stored in the <code>coef_path_</code> attribute.
If you compute the solution for a large problem or many targets,
setting <code>fit_path</code> to <code>False</code> will lead to a speedup, especially
with a small alpha.</p>
</details>
<details class="info" open="open"><summary>positive : bool, default=False</summary><p>Restrict coefficients to be &gt;= 0. Be aware that you might want to
remove fit_intercept which is set True by default.
Under the positive restriction the model coefficients will not converge
to the ordinary-least-squares solution for small values of alpha.
Only coefficients up to the smallest alpha value (<code>alphas_[alphas_ &gt;
0.].min()</code> when fit_path=True) reached by the stepwise Lars-Lasso
algorithm are typically in congruence with the solution of the
coordinate descent Lasso estimator.</p>
</details>
<h4>Attributes</h4>
<details class="info" open="open"><summary>alphas_ : array-like of shape (n_alphas + 1,) | list of n_targets such             arrays</summary><p>Maximum of covariances (in absolute value) at each iteration.         <code>n_alphas</code> is either <code>max_iter</code>, <code>n_features</code>, or the number of         nodes in the path with correlation greater than <code>alpha</code>, whichever         is smaller.</p>
</details>
<details class="info" open="open"><summary>active_ : list, length = n_alphas | list of n_targets such lists</summary><p>Indices of active variables at the end of the path.</p>
</details>
<details class="info" open="open"><summary>coef_path_ : array-like of shape (n_features, n_alphas + 1) or list</summary><p>If a list is passed it's expected to be one of n_targets such arrays.
The varying values of the coefficients along the path. It is not
present if the <code>fit_path</code> parameter is <code>False</code>.</p>
</details>
<details class="info" open="open"><summary>coef_ : array-like of shape (n_features,) or (n_targets, n_features)</summary><p>Parameter vector (w in the formulation formula).</p>
</details>
<details class="info" open="open"><summary>intercept_ : float or array-like of shape (n_targets,)</summary><p>Independent term in decision function.</p>
</details>
<details class="info" open="open"><summary>n_iter_ : array-like or int.</summary><p>The number of iterations taken by lars_path to find the
grid of alphas for each target.</p>
</details>
<h4>Examples</h4>
<div class="highlight"><pre><span></span><code><span class="o">&gt;&gt;&gt;</span> <span class="kn">from</span> <span class="nn">sklearn</span> <span class="kn">import</span> <span class="n">linear_model</span>
<span class="o">&gt;&gt;&gt;</span> <span class="n">reg</span> <span class="o">=</span> <span class="n">linear_model</span><span class="o">.</span><span class="n">LassoLars</span><span class="p">(</span><span class="n">alpha</span><span class="o">=</span><span class="mf">0.01</span><span class="p">)</span>
<span class="o">&gt;&gt;&gt;</span> <span class="n">reg</span><span class="o">.</span><span class="n">fit</span><span class="p">([[</span><span class="o">-</span><span class="mi">1</span><span class="p">,</span> <span class="mi">1</span><span class="p">],</span> <span class="p">[</span><span class="mi">0</span><span class="p">,</span> <span class="mi">0</span><span class="p">],</span> <span class="p">[</span><span class="mi">1</span><span class="p">,</span> <span class="mi">1</span><span class="p">]],</span> <span class="p">[</span><span class="o">-</span><span class="mi">1</span><span class="p">,</span> <span class="mi">0</span><span class="p">,</span> <span class="o">-</span><span class="mi">1</span><span class="p">])</span>
<span class="n">LassoLars</span><span class="p">(</span><span class="n">alpha</span><span class="o">=</span><span class="mf">0.01</span><span class="p">)</span>
<span class="o">&gt;&gt;&gt;</span> <span class="nb">print</span><span class="p">(</span><span class="n">reg</span><span class="o">.</span><span class="n">coef_</span><span class="p">)</span>
<span class="p">[</span> <span class="mf">0.</span>         <span class="o">-</span><span class="mf">0.963257</span><span class="o">...</span><span class="p">]</span>
</code></pre></div>

<h4>See also</h4>
<p>lars_path
lasso_path
Lasso
LassoCV
LassoLarsCV
LassoLarsIC
sklearn.decomposition.sparse_encode</p>
</details>
<h3 id="fit_9">fit<a class="headerlink" href="#fit_9" title="Permanent link">&para;</a></h3>
<details class="note" open="open"><summary>method</summary><div class="highlight"><pre><span></span><code><span class="k">val</span> <span class="n">fit</span> <span class="o">:</span>
  <span class="o">?</span><span class="n">xy</span><span class="o">:</span><span class="nn">Arr</span><span class="p">.</span><span class="n">t</span> <span class="o">-&gt;</span>
  <span class="n">x</span><span class="o">:</span><span class="nn">Arr</span><span class="p">.</span><span class="n">t</span> <span class="o">-&gt;</span>
  <span class="n">y</span><span class="o">:</span><span class="nn">Arr</span><span class="p">.</span><span class="n">t</span> <span class="o">-&gt;</span>
  <span class="n">t</span> <span class="o">-&gt;</span>
  <span class="n">t</span>
</code></pre></div>

<p>Fit the model using X, y as training data.</p>
<h4>Parameters</h4>
<details class="info" open="open"><summary>X : array-like of shape (n_samples, n_features)</summary><p>Training data.</p>
</details>
<details class="info" open="open"><summary>y : array-like of shape (n_samples,) or (n_samples, n_targets)</summary><p>Target values.</p>
</details>
<details class="info" open="open"><summary>Xy : array-like of shape (n_samples,) or (n_samples, n_targets),                 default=None</summary><p>Xy = np.dot(X.T, y) that can be precomputed. It is useful
only when the Gram matrix is precomputed.</p>
</details>
<h4>Returns</h4>
<details class="info" open="open"><summary>self : object</summary><p>returns an instance of self.</p>
</details>
</details>
<h3 id="get_params_9">get_params<a class="headerlink" href="#get_params_9" title="Permanent link">&para;</a></h3>
<details class="note" open="open"><summary>method</summary><div class="highlight"><pre><span></span><code><span class="k">val</span> <span class="n">get_params</span> <span class="o">:</span>
  <span class="o">?</span><span class="n">deep</span><span class="o">:</span><span class="kt">bool</span> <span class="o">-&gt;</span>
  <span class="n">t</span> <span class="o">-&gt;</span>
  <span class="nn">Dict</span><span class="p">.</span><span class="n">t</span>
</code></pre></div>

<p>Get parameters for this estimator.</p>
<h4>Parameters</h4>
<details class="info" open="open"><summary>deep : bool, default=True</summary><p>If True, will return the parameters for this estimator and
contained subobjects that are estimators.</p>
</details>
<h4>Returns</h4>
<details class="info" open="open"><summary>params : mapping of string to any</summary><p>Parameter names mapped to their values.</p>
</details>
</details>
<h3 id="predict_9">predict<a class="headerlink" href="#predict_9" title="Permanent link">&para;</a></h3>
<details class="note" open="open"><summary>method</summary><div class="highlight"><pre><span></span><code><span class="k">val</span> <span class="n">predict</span> <span class="o">:</span>
  <span class="n">x</span><span class="o">:</span><span class="nn">Arr</span><span class="p">.</span><span class="n">t</span> <span class="o">-&gt;</span>
  <span class="n">t</span> <span class="o">-&gt;</span>
  <span class="nn">Arr</span><span class="p">.</span><span class="n">t</span>
</code></pre></div>

<p>Predict using the linear model.</p>
<h4>Parameters</h4>
<details class="info" open="open"><summary>X : array_like or sparse matrix, shape (n_samples, n_features)</summary><p>Samples.</p>
</details>
<h4>Returns</h4>
<details class="info" open="open"><summary>C : array, shape (n_samples,)</summary><p>Returns predicted values.</p>
</details>
</details>
<h3 id="score_9">score<a class="headerlink" href="#score_9" title="Permanent link">&para;</a></h3>
<details class="note" open="open"><summary>method</summary><div class="highlight"><pre><span></span><code><span class="k">val</span> <span class="n">score</span> <span class="o">:</span>
  <span class="o">?</span><span class="n">sample_weight</span><span class="o">:</span><span class="nn">Arr</span><span class="p">.</span><span class="n">t</span> <span class="o">-&gt;</span>
  <span class="n">x</span><span class="o">:</span><span class="nn">Arr</span><span class="p">.</span><span class="n">t</span> <span class="o">-&gt;</span>
  <span class="n">y</span><span class="o">:</span><span class="nn">Arr</span><span class="p">.</span><span class="n">t</span> <span class="o">-&gt;</span>
  <span class="n">t</span> <span class="o">-&gt;</span>
  <span class="kt">float</span>
</code></pre></div>

<p>Return the coefficient of determination R^2 of the prediction.</p>
<p>The coefficient R^2 is defined as (1 - u/v), where u is the residual
sum of squares ((y_true - y_pred) <strong> 2).sum() and v is the total
sum of squares ((y_true - y_true.mean()) </strong> 2).sum().
The best possible score is 1.0 and it can be negative (because the
model can be arbitrarily worse). A constant model that always
predicts the expected value of y, disregarding the input features,
would get a R^2 score of 0.0.</p>
<h4>Parameters</h4>
<details class="info" open="open"><summary>X : array-like of shape (n_samples, n_features)</summary><p>Test samples. For some estimators this may be a
precomputed kernel matrix or a list of generic objects instead,
shape = (n_samples, n_samples_fitted),
where n_samples_fitted is the number of
samples used in the fitting for the estimator.</p>
</details>
<details class="info" open="open"><summary>y : array-like of shape (n_samples,) or (n_samples, n_outputs)</summary><p>True values for X.</p>
</details>
<details class="info" open="open"><summary>sample_weight : array-like of shape (n_samples,), default=None</summary><p>Sample weights.</p>
</details>
<h4>Returns</h4>
<details class="info" open="open"><summary>score : float</summary><p>R^2 of self.predict(X) wrt. y.</p>
</details>
<h4>Notes</h4>
<p>The R2 score used when calling <code>score</code> on a regressor will use
<code>multioutput='uniform_average'</code> from version 0.23 to keep consistent</p>
<details class="info" open="open"><summary>with :func:<code>~sklearn.metrics.r2_score</code>. This will influence the</summary></details>
<p><code>score</code> method of all the multioutput regressors (except for
:class:<code>~sklearn.multioutput.MultiOutputRegressor</code>). To specify the
default value manually and avoid the warning, please either call
:func:<code>~sklearn.metrics.r2_score</code> directly or make a custom scorer with
:func:<code>~sklearn.metrics.make_scorer</code> (the built-in scorer <code>'r2'</code> uses
<code>multioutput='uniform_average'</code>).</p>
</details>
<h3 id="set_params_9">set_params<a class="headerlink" href="#set_params_9" title="Permanent link">&para;</a></h3>
<details class="note" open="open"><summary>method</summary><div class="highlight"><pre><span></span><code><span class="k">val</span> <span class="n">set_params</span> <span class="o">:</span>
  <span class="o">?</span><span class="n">params</span><span class="o">:(</span><span class="kt">string</span> <span class="o">*</span> <span class="nn">Py</span><span class="p">.</span><span class="nn">Object</span><span class="p">.</span><span class="n">t</span><span class="o">)</span> <span class="kt">list</span> <span class="o">-&gt;</span>
  <span class="n">t</span> <span class="o">-&gt;</span>
  <span class="n">t</span>
</code></pre></div>

<p>Set the parameters of this estimator.</p>
<p>The method works on simple estimators as well as on nested objects
(such as pipelines). The latter have parameters of the form
<code>&lt;component&gt;__&lt;parameter&gt;</code> so that it's possible to update each
component of a nested object.</p>
<h4>Parameters</h4>
<details class="info" open="open"><summary>**params : dict</summary><p>Estimator parameters.</p>
</details>
<h4>Returns</h4>
<details class="info" open="open"><summary>self : object</summary><p>Estimator instance.</p>
</details>
</details>
<h3 id="alphas__4">alphas_<a class="headerlink" href="#alphas__4" title="Permanent link">&para;</a></h3>
<details class="note" open="open"><summary>attribute</summary><div class="highlight"><pre><span></span><code><span class="k">val</span> <span class="n">alphas_</span> <span class="o">:</span> <span class="n">t</span> <span class="o">-&gt;</span> <span class="nn">Py</span><span class="p">.</span><span class="nn">Object</span><span class="p">.</span><span class="n">t</span>
<span class="k">val</span> <span class="n">alphas_opt</span> <span class="o">:</span> <span class="n">t</span> <span class="o">-&gt;</span> <span class="o">(</span><span class="nn">Py</span><span class="p">.</span><span class="nn">Object</span><span class="p">.</span><span class="n">t</span><span class="o">)</span> <span class="n">option</span>
</code></pre></div>

<p>This attribute is documented in <code>create</code> above. The first version raises Not_found
if the attribute is None. The _opt version returns an option.</p>
</details>
<h3 id="active__1">active_<a class="headerlink" href="#active__1" title="Permanent link">&para;</a></h3>
<details class="note" open="open"><summary>attribute</summary><div class="highlight"><pre><span></span><code><span class="k">val</span> <span class="n">active_</span> <span class="o">:</span> <span class="n">t</span> <span class="o">-&gt;</span> <span class="nn">Py</span><span class="p">.</span><span class="nn">Object</span><span class="p">.</span><span class="n">t</span>
<span class="k">val</span> <span class="n">active_opt</span> <span class="o">:</span> <span class="n">t</span> <span class="o">-&gt;</span> <span class="o">(</span><span class="nn">Py</span><span class="p">.</span><span class="nn">Object</span><span class="p">.</span><span class="n">t</span><span class="o">)</span> <span class="n">option</span>
</code></pre></div>

<p>This attribute is documented in <code>create</code> above. The first version raises Not_found
if the attribute is None. The _opt version returns an option.</p>
</details>
<h3 id="coef_path__2">coef_path_<a class="headerlink" href="#coef_path__2" title="Permanent link">&para;</a></h3>
<details class="note" open="open"><summary>attribute</summary><div class="highlight"><pre><span></span><code><span class="k">val</span> <span class="n">coef_path_</span> <span class="o">:</span> <span class="n">t</span> <span class="o">-&gt;</span> <span class="nn">Arr</span><span class="p">.</span><span class="n">t</span>
<span class="k">val</span> <span class="n">coef_path_opt</span> <span class="o">:</span> <span class="n">t</span> <span class="o">-&gt;</span> <span class="o">(</span><span class="nn">Arr</span><span class="p">.</span><span class="n">t</span><span class="o">)</span> <span class="n">option</span>
</code></pre></div>

<p>This attribute is documented in <code>create</code> above. The first version raises Not_found
if the attribute is None. The _opt version returns an option.</p>
</details>
<h3 id="coef__9">coef_<a class="headerlink" href="#coef__9" title="Permanent link">&para;</a></h3>
<details class="note" open="open"><summary>attribute</summary><div class="highlight"><pre><span></span><code><span class="k">val</span> <span class="n">coef_</span> <span class="o">:</span> <span class="n">t</span> <span class="o">-&gt;</span> <span class="nn">Arr</span><span class="p">.</span><span class="n">t</span>
<span class="k">val</span> <span class="n">coef_opt</span> <span class="o">:</span> <span class="n">t</span> <span class="o">-&gt;</span> <span class="o">(</span><span class="nn">Arr</span><span class="p">.</span><span class="n">t</span><span class="o">)</span> <span class="n">option</span>
</code></pre></div>

<p>This attribute is documented in <code>create</code> above. The first version raises Not_found
if the attribute is None. The _opt version returns an option.</p>
</details>
<h3 id="intercept__9">intercept_<a class="headerlink" href="#intercept__9" title="Permanent link">&para;</a></h3>
<details class="note" open="open"><summary>attribute</summary><div class="highlight"><pre><span></span><code><span class="k">val</span> <span class="n">intercept_</span> <span class="o">:</span> <span class="n">t</span> <span class="o">-&gt;</span> <span class="nn">Arr</span><span class="p">.</span><span class="n">t</span>
<span class="k">val</span> <span class="n">intercept_opt</span> <span class="o">:</span> <span class="n">t</span> <span class="o">-&gt;</span> <span class="o">(</span><span class="nn">Arr</span><span class="p">.</span><span class="n">t</span><span class="o">)</span> <span class="n">option</span>
</code></pre></div>

<p>This attribute is documented in <code>create</code> above. The first version raises Not_found
if the attribute is None. The _opt version returns an option.</p>
</details>
<h3 id="n_iter__8">n_iter_<a class="headerlink" href="#n_iter__8" title="Permanent link">&para;</a></h3>
<details class="note" open="open"><summary>attribute</summary><div class="highlight"><pre><span></span><code><span class="k">val</span> <span class="n">n_iter_</span> <span class="o">:</span> <span class="n">t</span> <span class="o">-&gt;</span> <span class="o">[`</span><span class="nc">Arr</span> <span class="k">of</span> <span class="nn">Arr</span><span class="p">.</span><span class="n">t</span> <span class="o">|</span> <span class="o">`</span><span class="nc">I</span> <span class="k">of</span> <span class="kt">int</span><span class="o">]</span>
<span class="k">val</span> <span class="n">n_iter_opt</span> <span class="o">:</span> <span class="n">t</span> <span class="o">-&gt;</span> <span class="o">([`</span><span class="nc">Arr</span> <span class="k">of</span> <span class="nn">Arr</span><span class="p">.</span><span class="n">t</span> <span class="o">|</span> <span class="o">`</span><span class="nc">I</span> <span class="k">of</span> <span class="kt">int</span><span class="o">])</span> <span class="n">option</span>
</code></pre></div>

<p>This attribute is documented in <code>create</code> above. The first version raises Not_found
if the attribute is None. The _opt version returns an option.</p>
</details>
<h3 id="to_string_9">to_string<a class="headerlink" href="#to_string_9" title="Permanent link">&para;</a></h3>
<details class="note" open="open"><summary>method</summary><div class="highlight"><pre><span></span><code><span class="k">val</span> <span class="n">to_string</span><span class="o">:</span> <span class="n">t</span> <span class="o">-&gt;</span> <span class="kt">string</span>
</code></pre></div>

<p>Print the object to a human-readable representation.</p>
</details>
<h3 id="show_9">show<a class="headerlink" href="#show_9" title="Permanent link">&para;</a></h3>
<details class="note" open="open"><summary>method</summary><div class="highlight"><pre><span></span><code><span class="k">val</span> <span class="n">show</span><span class="o">:</span> <span class="n">t</span> <span class="o">-&gt;</span> <span class="kt">string</span>
</code></pre></div>

<p>Print the object to a human-readable representation.</p>
</details>
<h3 id="pp_9">pp<a class="headerlink" href="#pp_9" title="Permanent link">&para;</a></h3>
<details class="note" open="open"><summary>method</summary><div class="highlight"><pre><span></span><code><span class="k">val</span> <span class="n">pp</span><span class="o">:</span> <span class="nn">Format</span><span class="p">.</span><span class="n">formatter</span> <span class="o">-&gt;</span> <span class="n">t</span> <span class="o">-&gt;</span> <span class="kt">unit</span>
</code></pre></div>

<p>Pretty-print the object to a formatter.</p>
</details>
<h2 id="module-sklearnlinear_modellassolarscv">module Sklearn.​Linear_model.​LassoLarsCV<a class="headerlink" href="#module-sklearnlinear_modellassolarscv" title="Permanent link">&para;</a></h2>
<div class="highlight"><pre><span></span><code><span class="k">type</span> <span class="n">t</span>
</code></pre></div>

<h3 id="create_10">create<a class="headerlink" href="#create_10" title="Permanent link">&para;</a></h3>
<details class="note" open="open"><summary>constructor and attributes</summary><div class="highlight"><pre><span></span><code><span class="k">val</span> <span class="n">create</span> <span class="o">:</span>
  <span class="o">?</span><span class="n">fit_intercept</span><span class="o">:</span><span class="kt">bool</span> <span class="o">-&gt;</span>
  <span class="o">?</span><span class="n">verbose</span><span class="o">:</span><span class="kt">int</span> <span class="o">-&gt;</span>
  <span class="o">?</span><span class="n">max_iter</span><span class="o">:</span><span class="kt">int</span> <span class="o">-&gt;</span>
  <span class="o">?</span><span class="n">normalize</span><span class="o">:</span><span class="kt">bool</span> <span class="o">-&gt;</span>
  <span class="o">?</span><span class="n">precompute</span><span class="o">:[`</span><span class="nc">Bool</span> <span class="k">of</span> <span class="kt">bool</span> <span class="o">|</span> <span class="o">`</span><span class="nc">Auto</span><span class="o">]</span> <span class="o">-&gt;</span>
  <span class="o">?</span><span class="n">cv</span><span class="o">:[`</span><span class="nc">I</span> <span class="k">of</span> <span class="kt">int</span> <span class="o">|</span> <span class="o">`</span><span class="nc">CrossValGenerator</span> <span class="k">of</span> <span class="nn">Py</span><span class="p">.</span><span class="nn">Object</span><span class="p">.</span><span class="n">t</span> <span class="o">|</span> <span class="o">`</span><span class="nc">Arr</span> <span class="k">of</span> <span class="nn">Arr</span><span class="p">.</span><span class="n">t</span><span class="o">]</span> <span class="o">-&gt;</span>
  <span class="o">?</span><span class="n">max_n_alphas</span><span class="o">:</span><span class="kt">int</span> <span class="o">-&gt;</span>
  <span class="o">?</span><span class="n">n_jobs</span><span class="o">:</span><span class="kt">int</span> <span class="o">-&gt;</span>
  <span class="o">?</span><span class="n">eps</span><span class="o">:</span><span class="kt">float</span> <span class="o">-&gt;</span>
  <span class="o">?</span><span class="n">copy_X</span><span class="o">:</span><span class="kt">bool</span> <span class="o">-&gt;</span>
  <span class="o">?</span><span class="n">positive</span><span class="o">:</span><span class="kt">bool</span> <span class="o">-&gt;</span>
  <span class="kt">unit</span> <span class="o">-&gt;</span>
  <span class="n">t</span>
</code></pre></div>

<p>Cross-validated Lasso, using the LARS algorithm.</p>
<p>See glossary entry for :term:<code>cross-validation estimator</code>.</p>
<p>The optimization objective for Lasso is::</p>
<p>(1 / (2 * n_samples)) * ||y - Xw||^2_2 + alpha * ||w||_1</p>
<p>Read more in the :ref:<code>User Guide &lt;least_angle_regression&gt;</code>.</p>
<h4>Parameters</h4>
<details class="info" open="open"><summary>fit_intercept : bool, default=True</summary><p>whether to calculate the intercept for this model. If set
to false, no intercept will be used in calculations
(i.e. data is expected to be centered).</p>
</details>
<details class="info" open="open"><summary>verbose : bool or int, default=False</summary><p>Sets the verbosity amount</p>
</details>
<details class="info" open="open"><summary>max_iter : int, default=500</summary><p>Maximum number of iterations to perform.</p>
</details>
<details class="info" open="open"><summary>normalize : bool, default=True</summary><p>This parameter is ignored when <code>fit_intercept</code> is set to False.
If True, the regressors X will be normalized before regression by
subtracting the mean and dividing by the l2-norm.
If you wish to standardize, please use
:class:<code>sklearn.preprocessing.StandardScaler</code> before calling <code>fit</code>
on an estimator with <code>normalize=False</code>.</p>
</details>
<details class="info" open="open"><summary>precompute : bool or 'auto' , default='auto'</summary><p>Whether to use a precomputed Gram matrix to speed up
calculations. If set to <code>'auto'</code> let us decide. The Gram matrix
cannot be passed as argument since we will use only subsets of X.</p>
</details>
<details class="info" open="open"><summary>cv : int, cross-validation generator or an iterable, default=None</summary><p>Determines the cross-validation splitting strategy.
Possible inputs for cv are:</p>
<ul>
<li>None, to use the default 5-fold cross-validation,</li>
<li>integer, to specify the number of folds.</li>
<li>:term:<code>CV splitter</code>,</li>
<li>An iterable yielding (train, test) splits as arrays of indices.</li>
</ul>
<p>For integer/None inputs, :class:<code>KFold</code> is used.</p>
</details>
<details class="info" open="open"><summary>Refer :ref:<code>User Guide &lt;cross_validation&gt;</code> for the various</summary><p>cross-validation strategies that can be used here.</p>
<p>.. versionchanged:: 0.22
    <code>cv</code> default value if None changed from 3-fold to 5-fold.</p>
</details>
<details class="info" open="open"><summary>max_n_alphas : int, default=1000</summary><p>The maximum number of points on the path used to compute the
residuals in the cross-validation</p>
</details>
<details class="info" open="open"><summary>n_jobs : int or None, default=None</summary><p>Number of CPUs to use during the cross validation.
<code>None</code> means 1 unless in a :obj:<code>joblib.parallel_backend</code> context.
<code>-1</code> means using all processors. See :term:<code>Glossary &lt;n_jobs&gt;</code>
for more details.</p>
</details>
<details class="info" open="open"><summary>eps : float, optional</summary><p>The machine-precision regularization in the computation of the
Cholesky diagonal factors. Increase this for very ill-conditioned
systems. By default, <code>np.finfo(np.float).eps</code> is used.</p>
</details>
<details class="info" open="open"><summary>copy_X : bool, default=True</summary><p>If True, X will be copied; else, it may be overwritten.</p>
</details>
<details class="info" open="open"><summary>positive : bool, default=False</summary><p>Restrict coefficients to be &gt;= 0. Be aware that you might want to
remove fit_intercept which is set True by default.
Under the positive restriction the model coefficients do not converge
to the ordinary-least-squares solution for small values of alpha.
Only coefficients up to the smallest alpha value (<code>alphas_[alphas_ &gt;
0.].min()</code> when fit_path=True) reached by the stepwise Lars-Lasso
algorithm are typically in congruence with the solution of the
coordinate descent Lasso estimator.
As a consequence using LassoLarsCV only makes sense for problems where
a sparse solution is expected and/or reached.</p>
</details>
<h4>Attributes</h4>
<details class="info" open="open"><summary>coef_ : array-like of shape (n_features,)</summary><p>parameter vector (w in the formulation formula)</p>
</details>
<details class="info" open="open"><summary>intercept_ : float</summary><p>independent term in decision function.</p>
</details>
<details class="info" open="open"><summary>coef_path_ : array-like of shape (n_features, n_alphas)</summary><p>the varying values of the coefficients along the path</p>
</details>
<details class="info" open="open"><summary>alpha_ : float</summary><p>the estimated regularization parameter alpha</p>
</details>
<details class="info" open="open"><summary>alphas_ : array-like of shape (n_alphas,)</summary><p>the different values of alpha along the path</p>
</details>
<details class="info" open="open"><summary>cv_alphas_ : array-like of shape (n_cv_alphas,)</summary><p>all the values of alpha along the path for the different folds</p>
</details>
<details class="info" open="open"><summary>mse_path_ : array-like of shape (n_folds, n_cv_alphas)</summary><p>the mean square error on left-out for each fold along the path
(alpha values given by <code>cv_alphas</code>)</p>
</details>
<details class="info" open="open"><summary>n_iter_ : array-like or int</summary><p>the number of iterations run by Lars with the optimal alpha.</p>
</details>
<h4>Examples</h4>
<div class="highlight"><pre><span></span><code><span class="o">&gt;&gt;&gt;</span> <span class="kn">from</span> <span class="nn">sklearn.linear_model</span> <span class="kn">import</span> <span class="n">LassoLarsCV</span>
<span class="o">&gt;&gt;&gt;</span> <span class="kn">from</span> <span class="nn">sklearn.datasets</span> <span class="kn">import</span> <span class="n">make_regression</span>
<span class="o">&gt;&gt;&gt;</span> <span class="n">X</span><span class="p">,</span> <span class="n">y</span> <span class="o">=</span> <span class="n">make_regression</span><span class="p">(</span><span class="n">noise</span><span class="o">=</span><span class="mf">4.0</span><span class="p">,</span> <span class="n">random_state</span><span class="o">=</span><span class="mi">0</span><span class="p">)</span>
<span class="o">&gt;&gt;&gt;</span> <span class="n">reg</span> <span class="o">=</span> <span class="n">LassoLarsCV</span><span class="p">(</span><span class="n">cv</span><span class="o">=</span><span class="mi">5</span><span class="p">)</span><span class="o">.</span><span class="n">fit</span><span class="p">(</span><span class="n">X</span><span class="p">,</span> <span class="n">y</span><span class="p">)</span>
<span class="o">&gt;&gt;&gt;</span> <span class="n">reg</span><span class="o">.</span><span class="n">score</span><span class="p">(</span><span class="n">X</span><span class="p">,</span> <span class="n">y</span><span class="p">)</span>
<span class="mf">0.9992</span><span class="o">...</span>
<span class="o">&gt;&gt;&gt;</span> <span class="n">reg</span><span class="o">.</span><span class="n">alpha_</span>
<span class="mf">0.0484</span><span class="o">...</span>
<span class="o">&gt;&gt;&gt;</span> <span class="n">reg</span><span class="o">.</span><span class="n">predict</span><span class="p">(</span><span class="n">X</span><span class="p">[:</span><span class="mi">1</span><span class="p">,])</span>
<span class="n">array</span><span class="p">([</span><span class="o">-</span><span class="mf">77.8723</span><span class="o">...</span><span class="p">])</span>
</code></pre></div>

<h4>Notes</h4>
<p>The object solves the same problem as the LassoCV object. However,
unlike the LassoCV, it find the relevant alphas values by itself.
In general, because of this property, it will be more stable.
However, it is more fragile to heavily multicollinear datasets.</p>
<p>It is more efficient than the LassoCV if only a small number of
features are selected compared to the total number, for instance if
there are very few samples compared to the number of features.</p>
<h4>See also</h4>
<p>lars_path, LassoLars, LarsCV, LassoCV</p>
</details>
<h3 id="fit_10">fit<a class="headerlink" href="#fit_10" title="Permanent link">&para;</a></h3>
<details class="note" open="open"><summary>method</summary><div class="highlight"><pre><span></span><code><span class="k">val</span> <span class="n">fit</span> <span class="o">:</span>
  <span class="n">x</span><span class="o">:</span><span class="nn">Arr</span><span class="p">.</span><span class="n">t</span> <span class="o">-&gt;</span>
  <span class="n">y</span><span class="o">:</span><span class="nn">Arr</span><span class="p">.</span><span class="n">t</span> <span class="o">-&gt;</span>
  <span class="n">t</span> <span class="o">-&gt;</span>
  <span class="n">t</span>
</code></pre></div>

<p>Fit the model using X, y as training data.</p>
<h4>Parameters</h4>
<details class="info" open="open"><summary>X : array-like of shape (n_samples, n_features)</summary><p>Training data.</p>
</details>
<details class="info" open="open"><summary>y : array-like of shape (n_samples,)</summary><p>Target values.</p>
</details>
<h4>Returns</h4>
<details class="info" open="open"><summary>self : object</summary><p>returns an instance of self.</p>
</details>
</details>
<h3 id="get_params_10">get_params<a class="headerlink" href="#get_params_10" title="Permanent link">&para;</a></h3>
<details class="note" open="open"><summary>method</summary><div class="highlight"><pre><span></span><code><span class="k">val</span> <span class="n">get_params</span> <span class="o">:</span>
  <span class="o">?</span><span class="n">deep</span><span class="o">:</span><span class="kt">bool</span> <span class="o">-&gt;</span>
  <span class="n">t</span> <span class="o">-&gt;</span>
  <span class="nn">Dict</span><span class="p">.</span><span class="n">t</span>
</code></pre></div>

<p>Get parameters for this estimator.</p>
<h4>Parameters</h4>
<details class="info" open="open"><summary>deep : bool, default=True</summary><p>If True, will return the parameters for this estimator and
contained subobjects that are estimators.</p>
</details>
<h4>Returns</h4>
<details class="info" open="open"><summary>params : mapping of string to any</summary><p>Parameter names mapped to their values.</p>
</details>
</details>
<h3 id="predict_10">predict<a class="headerlink" href="#predict_10" title="Permanent link">&para;</a></h3>
<details class="note" open="open"><summary>method</summary><div class="highlight"><pre><span></span><code><span class="k">val</span> <span class="n">predict</span> <span class="o">:</span>
  <span class="n">x</span><span class="o">:</span><span class="nn">Arr</span><span class="p">.</span><span class="n">t</span> <span class="o">-&gt;</span>
  <span class="n">t</span> <span class="o">-&gt;</span>
  <span class="nn">Arr</span><span class="p">.</span><span class="n">t</span>
</code></pre></div>

<p>Predict using the linear model.</p>
<h4>Parameters</h4>
<details class="info" open="open"><summary>X : array_like or sparse matrix, shape (n_samples, n_features)</summary><p>Samples.</p>
</details>
<h4>Returns</h4>
<details class="info" open="open"><summary>C : array, shape (n_samples,)</summary><p>Returns predicted values.</p>
</details>
</details>
<h3 id="score_10">score<a class="headerlink" href="#score_10" title="Permanent link">&para;</a></h3>
<details class="note" open="open"><summary>method</summary><div class="highlight"><pre><span></span><code><span class="k">val</span> <span class="n">score</span> <span class="o">:</span>
  <span class="o">?</span><span class="n">sample_weight</span><span class="o">:</span><span class="nn">Arr</span><span class="p">.</span><span class="n">t</span> <span class="o">-&gt;</span>
  <span class="n">x</span><span class="o">:</span><span class="nn">Arr</span><span class="p">.</span><span class="n">t</span> <span class="o">-&gt;</span>
  <span class="n">y</span><span class="o">:</span><span class="nn">Arr</span><span class="p">.</span><span class="n">t</span> <span class="o">-&gt;</span>
  <span class="n">t</span> <span class="o">-&gt;</span>
  <span class="kt">float</span>
</code></pre></div>

<p>Return the coefficient of determination R^2 of the prediction.</p>
<p>The coefficient R^2 is defined as (1 - u/v), where u is the residual
sum of squares ((y_true - y_pred) <strong> 2).sum() and v is the total
sum of squares ((y_true - y_true.mean()) </strong> 2).sum().
The best possible score is 1.0 and it can be negative (because the
model can be arbitrarily worse). A constant model that always
predicts the expected value of y, disregarding the input features,
would get a R^2 score of 0.0.</p>
<h4>Parameters</h4>
<details class="info" open="open"><summary>X : array-like of shape (n_samples, n_features)</summary><p>Test samples. For some estimators this may be a
precomputed kernel matrix or a list of generic objects instead,
shape = (n_samples, n_samples_fitted),
where n_samples_fitted is the number of
samples used in the fitting for the estimator.</p>
</details>
<details class="info" open="open"><summary>y : array-like of shape (n_samples,) or (n_samples, n_outputs)</summary><p>True values for X.</p>
</details>
<details class="info" open="open"><summary>sample_weight : array-like of shape (n_samples,), default=None</summary><p>Sample weights.</p>
</details>
<h4>Returns</h4>
<details class="info" open="open"><summary>score : float</summary><p>R^2 of self.predict(X) wrt. y.</p>
</details>
<h4>Notes</h4>
<p>The R2 score used when calling <code>score</code> on a regressor will use
<code>multioutput='uniform_average'</code> from version 0.23 to keep consistent</p>
<details class="info" open="open"><summary>with :func:<code>~sklearn.metrics.r2_score</code>. This will influence the</summary></details>
<p><code>score</code> method of all the multioutput regressors (except for
:class:<code>~sklearn.multioutput.MultiOutputRegressor</code>). To specify the
default value manually and avoid the warning, please either call
:func:<code>~sklearn.metrics.r2_score</code> directly or make a custom scorer with
:func:<code>~sklearn.metrics.make_scorer</code> (the built-in scorer <code>'r2'</code> uses
<code>multioutput='uniform_average'</code>).</p>
</details>
<h3 id="set_params_10">set_params<a class="headerlink" href="#set_params_10" title="Permanent link">&para;</a></h3>
<details class="note" open="open"><summary>method</summary><div class="highlight"><pre><span></span><code><span class="k">val</span> <span class="n">set_params</span> <span class="o">:</span>
  <span class="o">?</span><span class="n">params</span><span class="o">:(</span><span class="kt">string</span> <span class="o">*</span> <span class="nn">Py</span><span class="p">.</span><span class="nn">Object</span><span class="p">.</span><span class="n">t</span><span class="o">)</span> <span class="kt">list</span> <span class="o">-&gt;</span>
  <span class="n">t</span> <span class="o">-&gt;</span>
  <span class="n">t</span>
</code></pre></div>

<p>Set the parameters of this estimator.</p>
<p>The method works on simple estimators as well as on nested objects
(such as pipelines). The latter have parameters of the form
<code>&lt;component&gt;__&lt;parameter&gt;</code> so that it's possible to update each
component of a nested object.</p>
<h4>Parameters</h4>
<details class="info" open="open"><summary>**params : dict</summary><p>Estimator parameters.</p>
</details>
<h4>Returns</h4>
<details class="info" open="open"><summary>self : object</summary><p>Estimator instance.</p>
</details>
</details>
<h3 id="coef__10">coef_<a class="headerlink" href="#coef__10" title="Permanent link">&para;</a></h3>
<details class="note" open="open"><summary>attribute</summary><div class="highlight"><pre><span></span><code><span class="k">val</span> <span class="n">coef_</span> <span class="o">:</span> <span class="n">t</span> <span class="o">-&gt;</span> <span class="nn">Arr</span><span class="p">.</span><span class="n">t</span>
<span class="k">val</span> <span class="n">coef_opt</span> <span class="o">:</span> <span class="n">t</span> <span class="o">-&gt;</span> <span class="o">(</span><span class="nn">Arr</span><span class="p">.</span><span class="n">t</span><span class="o">)</span> <span class="n">option</span>
</code></pre></div>

<p>This attribute is documented in <code>create</code> above. The first version raises Not_found
if the attribute is None. The _opt version returns an option.</p>
</details>
<h3 id="intercept__10">intercept_<a class="headerlink" href="#intercept__10" title="Permanent link">&para;</a></h3>
<details class="note" open="open"><summary>attribute</summary><div class="highlight"><pre><span></span><code><span class="k">val</span> <span class="n">intercept_</span> <span class="o">:</span> <span class="n">t</span> <span class="o">-&gt;</span> <span class="nn">Arr</span><span class="p">.</span><span class="n">t</span>
<span class="k">val</span> <span class="n">intercept_opt</span> <span class="o">:</span> <span class="n">t</span> <span class="o">-&gt;</span> <span class="o">(</span><span class="nn">Arr</span><span class="p">.</span><span class="n">t</span><span class="o">)</span> <span class="n">option</span>
</code></pre></div>

<p>This attribute is documented in <code>create</code> above. The first version raises Not_found
if the attribute is None. The _opt version returns an option.</p>
</details>
<h3 id="coef_path__3">coef_path_<a class="headerlink" href="#coef_path__3" title="Permanent link">&para;</a></h3>
<details class="note" open="open"><summary>attribute</summary><div class="highlight"><pre><span></span><code><span class="k">val</span> <span class="n">coef_path_</span> <span class="o">:</span> <span class="n">t</span> <span class="o">-&gt;</span> <span class="nn">Arr</span><span class="p">.</span><span class="n">t</span>
<span class="k">val</span> <span class="n">coef_path_opt</span> <span class="o">:</span> <span class="n">t</span> <span class="o">-&gt;</span> <span class="o">(</span><span class="nn">Arr</span><span class="p">.</span><span class="n">t</span><span class="o">)</span> <span class="n">option</span>
</code></pre></div>

<p>This attribute is documented in <code>create</code> above. The first version raises Not_found
if the attribute is None. The _opt version returns an option.</p>
</details>
<h3 id="alpha__5">alpha_<a class="headerlink" href="#alpha__5" title="Permanent link">&para;</a></h3>
<details class="note" open="open"><summary>attribute</summary><div class="highlight"><pre><span></span><code><span class="k">val</span> <span class="n">alpha_</span> <span class="o">:</span> <span class="n">t</span> <span class="o">-&gt;</span> <span class="kt">float</span>
<span class="k">val</span> <span class="n">alpha_opt</span> <span class="o">:</span> <span class="n">t</span> <span class="o">-&gt;</span> <span class="o">(</span><span class="kt">float</span><span class="o">)</span> <span class="n">option</span>
</code></pre></div>

<p>This attribute is documented in <code>create</code> above. The first version raises Not_found
if the attribute is None. The _opt version returns an option.</p>
</details>
<h3 id="alphas__5">alphas_<a class="headerlink" href="#alphas__5" title="Permanent link">&para;</a></h3>
<details class="note" open="open"><summary>attribute</summary><div class="highlight"><pre><span></span><code><span class="k">val</span> <span class="n">alphas_</span> <span class="o">:</span> <span class="n">t</span> <span class="o">-&gt;</span> <span class="nn">Arr</span><span class="p">.</span><span class="n">t</span>
<span class="k">val</span> <span class="n">alphas_opt</span> <span class="o">:</span> <span class="n">t</span> <span class="o">-&gt;</span> <span class="o">(</span><span class="nn">Arr</span><span class="p">.</span><span class="n">t</span><span class="o">)</span> <span class="n">option</span>
</code></pre></div>

<p>This attribute is documented in <code>create</code> above. The first version raises Not_found
if the attribute is None. The _opt version returns an option.</p>
</details>
<h3 id="cv_alphas__1">cv_alphas_<a class="headerlink" href="#cv_alphas__1" title="Permanent link">&para;</a></h3>
<details class="note" open="open"><summary>attribute</summary><div class="highlight"><pre><span></span><code><span class="k">val</span> <span class="n">cv_alphas_</span> <span class="o">:</span> <span class="n">t</span> <span class="o">-&gt;</span> <span class="nn">Arr</span><span class="p">.</span><span class="n">t</span>
<span class="k">val</span> <span class="n">cv_alphas_opt</span> <span class="o">:</span> <span class="n">t</span> <span class="o">-&gt;</span> <span class="o">(</span><span class="nn">Arr</span><span class="p">.</span><span class="n">t</span><span class="o">)</span> <span class="n">option</span>
</code></pre></div>

<p>This attribute is documented in <code>create</code> above. The first version raises Not_found
if the attribute is None. The _opt version returns an option.</p>
</details>
<h3 id="mse_path__3">mse_path_<a class="headerlink" href="#mse_path__3" title="Permanent link">&para;</a></h3>
<details class="note" open="open"><summary>attribute</summary><div class="highlight"><pre><span></span><code><span class="k">val</span> <span class="n">mse_path_</span> <span class="o">:</span> <span class="n">t</span> <span class="o">-&gt;</span> <span class="nn">Arr</span><span class="p">.</span><span class="n">t</span>
<span class="k">val</span> <span class="n">mse_path_opt</span> <span class="o">:</span> <span class="n">t</span> <span class="o">-&gt;</span> <span class="o">(</span><span class="nn">Arr</span><span class="p">.</span><span class="n">t</span><span class="o">)</span> <span class="n">option</span>
</code></pre></div>

<p>This attribute is documented in <code>create</code> above. The first version raises Not_found
if the attribute is None. The _opt version returns an option.</p>
</details>
<h3 id="n_iter__9">n_iter_<a class="headerlink" href="#n_iter__9" title="Permanent link">&para;</a></h3>
<details class="note" open="open"><summary>attribute</summary><div class="highlight"><pre><span></span><code><span class="k">val</span> <span class="n">n_iter_</span> <span class="o">:</span> <span class="n">t</span> <span class="o">-&gt;</span> <span class="o">[`</span><span class="nc">Arr</span> <span class="k">of</span> <span class="nn">Arr</span><span class="p">.</span><span class="n">t</span> <span class="o">|</span> <span class="o">`</span><span class="nc">I</span> <span class="k">of</span> <span class="kt">int</span><span class="o">]</span>
<span class="k">val</span> <span class="n">n_iter_opt</span> <span class="o">:</span> <span class="n">t</span> <span class="o">-&gt;</span> <span class="o">([`</span><span class="nc">Arr</span> <span class="k">of</span> <span class="nn">Arr</span><span class="p">.</span><span class="n">t</span> <span class="o">|</span> <span class="o">`</span><span class="nc">I</span> <span class="k">of</span> <span class="kt">int</span><span class="o">])</span> <span class="n">option</span>
</code></pre></div>

<p>This attribute is documented in <code>create</code> above. The first version raises Not_found
if the attribute is None. The _opt version returns an option.</p>
</details>
<h3 id="to_string_10">to_string<a class="headerlink" href="#to_string_10" title="Permanent link">&para;</a></h3>
<details class="note" open="open"><summary>method</summary><div class="highlight"><pre><span></span><code><span class="k">val</span> <span class="n">to_string</span><span class="o">:</span> <span class="n">t</span> <span class="o">-&gt;</span> <span class="kt">string</span>
</code></pre></div>

<p>Print the object to a human-readable representation.</p>
</details>
<h3 id="show_10">show<a class="headerlink" href="#show_10" title="Permanent link">&para;</a></h3>
<details class="note" open="open"><summary>method</summary><div class="highlight"><pre><span></span><code><span class="k">val</span> <span class="n">show</span><span class="o">:</span> <span class="n">t</span> <span class="o">-&gt;</span> <span class="kt">string</span>
</code></pre></div>

<p>Print the object to a human-readable representation.</p>
</details>
<h3 id="pp_10">pp<a class="headerlink" href="#pp_10" title="Permanent link">&para;</a></h3>
<details class="note" open="open"><summary>method</summary><div class="highlight"><pre><span></span><code><span class="k">val</span> <span class="n">pp</span><span class="o">:</span> <span class="nn">Format</span><span class="p">.</span><span class="n">formatter</span> <span class="o">-&gt;</span> <span class="n">t</span> <span class="o">-&gt;</span> <span class="kt">unit</span>
</code></pre></div>

<p>Pretty-print the object to a formatter.</p>
</details>
<h2 id="module-sklearnlinear_modellassolarsic">module Sklearn.​Linear_model.​LassoLarsIC<a class="headerlink" href="#module-sklearnlinear_modellassolarsic" title="Permanent link">&para;</a></h2>
<div class="highlight"><pre><span></span><code><span class="k">type</span> <span class="n">t</span>
</code></pre></div>

<h3 id="create_11">create<a class="headerlink" href="#create_11" title="Permanent link">&para;</a></h3>
<details class="note" open="open"><summary>constructor and attributes</summary><div class="highlight"><pre><span></span><code><span class="k">val</span> <span class="n">create</span> <span class="o">:</span>
  <span class="o">?</span><span class="n">criterion</span><span class="o">:[`</span><span class="nc">Bic</span> <span class="o">|</span> <span class="o">`</span><span class="nc">Aic</span><span class="o">]</span> <span class="o">-&gt;</span>
  <span class="o">?</span><span class="n">fit_intercept</span><span class="o">:</span><span class="kt">bool</span> <span class="o">-&gt;</span>
  <span class="o">?</span><span class="n">verbose</span><span class="o">:</span><span class="kt">int</span> <span class="o">-&gt;</span>
  <span class="o">?</span><span class="n">normalize</span><span class="o">:</span><span class="kt">bool</span> <span class="o">-&gt;</span>
  <span class="o">?</span><span class="n">precompute</span><span class="o">:[`</span><span class="nc">Bool</span> <span class="k">of</span> <span class="kt">bool</span> <span class="o">|</span> <span class="o">`</span><span class="nc">Auto</span> <span class="o">|</span> <span class="o">`</span><span class="nc">Arr</span> <span class="k">of</span> <span class="nn">Arr</span><span class="p">.</span><span class="n">t</span><span class="o">]</span> <span class="o">-&gt;</span>
  <span class="o">?</span><span class="n">max_iter</span><span class="o">:</span><span class="kt">int</span> <span class="o">-&gt;</span>
  <span class="o">?</span><span class="n">eps</span><span class="o">:</span><span class="kt">float</span> <span class="o">-&gt;</span>
  <span class="o">?</span><span class="n">copy_X</span><span class="o">:</span><span class="kt">bool</span> <span class="o">-&gt;</span>
  <span class="o">?</span><span class="n">positive</span><span class="o">:</span><span class="kt">bool</span> <span class="o">-&gt;</span>
  <span class="kt">unit</span> <span class="o">-&gt;</span>
  <span class="n">t</span>
</code></pre></div>

<p>Lasso model fit with Lars using BIC or AIC for model selection</p>
<p>The optimization objective for Lasso is::</p>
<p>(1 / (2 * n_samples)) * ||y - Xw||^2_2 + alpha * ||w||_1</p>
<p>AIC is the Akaike information criterion and BIC is the Bayes
Information criterion. Such criteria are useful to select the value
of the regularization parameter by making a trade-off between the
goodness of fit and the complexity of the model. A good model should
explain well the data while being simple.</p>
<p>Read more in the :ref:<code>User Guide &lt;least_angle_regression&gt;</code>.</p>
<h4>Parameters</h4>
<details class="info" open="open"><summary>criterion : {'bic' , 'aic'}, default='aic'</summary><p>The type of criterion to use.</p>
</details>
<details class="info" open="open"><summary>fit_intercept : bool, default=True</summary><p>whether to calculate the intercept for this model. If set
to false, no intercept will be used in calculations
(i.e. data is expected to be centered).</p>
</details>
<details class="info" open="open"><summary>verbose : bool or int, default=False</summary><p>Sets the verbosity amount</p>
</details>
<details class="info" open="open"><summary>normalize : bool, default=True</summary><p>This parameter is ignored when <code>fit_intercept</code> is set to False.
If True, the regressors X will be normalized before regression by
subtracting the mean and dividing by the l2-norm.
If you wish to standardize, please use
:class:<code>sklearn.preprocessing.StandardScaler</code> before calling <code>fit</code>
on an estimator with <code>normalize=False</code>.</p>
</details>
<details class="info" open="open"><summary>precompute : bool, 'auto' or array-like, default='auto'</summary><p>Whether to use a precomputed Gram matrix to speed up
calculations. If set to <code>'auto'</code> let us decide. The Gram
matrix can also be passed as argument.</p>
</details>
<details class="info" open="open"><summary>max_iter : int, default=500</summary><p>Maximum number of iterations to perform. Can be used for
early stopping.</p>
</details>
<details class="info" open="open"><summary>eps : float, optional</summary><p>The machine-precision regularization in the computation of the
Cholesky diagonal factors. Increase this for very ill-conditioned
systems. Unlike the <code>tol</code> parameter in some iterative
optimization-based algorithms, this parameter does not control
the tolerance of the optimization.
By default, <code>np.finfo(np.float).eps</code> is used</p>
</details>
<details class="info" open="open"><summary>copy_X : bool, default=True</summary><p>If True, X will be copied; else, it may be overwritten.</p>
</details>
<details class="info" open="open"><summary>positive : bool, default=False</summary><p>Restrict coefficients to be &gt;= 0. Be aware that you might want to
remove fit_intercept which is set True by default.
Under the positive restriction the model coefficients do not converge
to the ordinary-least-squares solution for small values of alpha.
Only coefficients up to the smallest alpha value (<code>alphas_[alphas_ &gt;
0.].min()</code> when fit_path=True) reached by the stepwise Lars-Lasso
algorithm are typically in congruence with the solution of the
coordinate descent Lasso estimator.
As a consequence using LassoLarsIC only makes sense for problems where
a sparse solution is expected and/or reached.</p>
</details>
<h4>Attributes</h4>
<details class="info" open="open"><summary>coef_ : array-like of shape (n_features,)</summary><p>parameter vector (w in the formulation formula)</p>
</details>
<details class="info" open="open"><summary>intercept_ : float</summary><p>independent term in decision function.</p>
</details>
<details class="info" open="open"><summary>alpha_ : float</summary><p>the alpha parameter chosen by the information criterion</p>
</details>
<details class="info" open="open"><summary>n_iter_ : int</summary><p>number of iterations run by lars_path to find the grid of
alphas.</p>
</details>
<details class="info" open="open"><summary>criterion_ : array-like of shape (n_alphas,)</summary><p>The value of the information criteria ('aic', 'bic') across all
alphas. The alpha which has the smallest information criterion is
chosen. This value is larger by a factor of <code>n_samples</code> compared to
Eqns. 2.15 and 2.16 in (Zou et al, 2007).</p>
</details>
<h4>Examples</h4>
<div class="highlight"><pre><span></span><code><span class="o">&gt;&gt;&gt;</span> <span class="kn">from</span> <span class="nn">sklearn</span> <span class="kn">import</span> <span class="n">linear_model</span>
<span class="o">&gt;&gt;&gt;</span> <span class="n">reg</span> <span class="o">=</span> <span class="n">linear_model</span><span class="o">.</span><span class="n">LassoLarsIC</span><span class="p">(</span><span class="n">criterion</span><span class="o">=</span><span class="s1">&#39;bic&#39;</span><span class="p">)</span>
<span class="o">&gt;&gt;&gt;</span> <span class="n">reg</span><span class="o">.</span><span class="n">fit</span><span class="p">([[</span><span class="o">-</span><span class="mi">1</span><span class="p">,</span> <span class="mi">1</span><span class="p">],</span> <span class="p">[</span><span class="mi">0</span><span class="p">,</span> <span class="mi">0</span><span class="p">],</span> <span class="p">[</span><span class="mi">1</span><span class="p">,</span> <span class="mi">1</span><span class="p">]],</span> <span class="p">[</span><span class="o">-</span><span class="mf">1.1111</span><span class="p">,</span> <span class="mi">0</span><span class="p">,</span> <span class="o">-</span><span class="mf">1.1111</span><span class="p">])</span>
<span class="n">LassoLarsIC</span><span class="p">(</span><span class="n">criterion</span><span class="o">=</span><span class="s1">&#39;bic&#39;</span><span class="p">)</span>
<span class="o">&gt;&gt;&gt;</span> <span class="nb">print</span><span class="p">(</span><span class="n">reg</span><span class="o">.</span><span class="n">coef_</span><span class="p">)</span>
<span class="p">[</span> <span class="mf">0.</span>  <span class="o">-</span><span class="mf">1.11</span><span class="o">...</span><span class="p">]</span>
</code></pre></div>

<h4>Notes</h4>
<p>The estimation of the number of degrees of freedom is given by:</p>
<p>"On the degrees of freedom of the lasso"
Hui Zou, Trevor Hastie, and Robert Tibshirani
Ann. Statist. Volume 35, Number 5 (2007), 2173-2192.</p>
<details class="info" open="open"><summary>https://en.wikipedia.org/wiki/Akaike_information_criterion</summary></details>
<details class="info" open="open"><summary>https://en.wikipedia.org/wiki/Bayesian_information_criterion</summary></details>
<h4>See also</h4>
<p>lars_path, LassoLars, LassoLarsCV</p>
</details>
<h3 id="fit_11">fit<a class="headerlink" href="#fit_11" title="Permanent link">&para;</a></h3>
<details class="note" open="open"><summary>method</summary><div class="highlight"><pre><span></span><code><span class="k">val</span> <span class="n">fit</span> <span class="o">:</span>
  <span class="o">?</span><span class="n">copy_X</span><span class="o">:</span><span class="kt">bool</span> <span class="o">-&gt;</span>
  <span class="n">x</span><span class="o">:</span><span class="nn">Arr</span><span class="p">.</span><span class="n">t</span> <span class="o">-&gt;</span>
  <span class="n">y</span><span class="o">:</span><span class="nn">Arr</span><span class="p">.</span><span class="n">t</span> <span class="o">-&gt;</span>
  <span class="n">t</span> <span class="o">-&gt;</span>
  <span class="n">t</span>
</code></pre></div>

<p>Fit the model using X, y as training data.</p>
<h4>Parameters</h4>
<details class="info" open="open"><summary>X : array-like of shape (n_samples, n_features)</summary><p>training data.</p>
</details>
<details class="info" open="open"><summary>y : array-like of shape (n_samples,)</summary><p>target values. Will be cast to X's dtype if necessary</p>
</details>
<details class="info" open="open"><summary>copy_X : bool, default=None</summary><p>If provided, this parameter will override the choice
of copy_X made at instance creation.
If <code>True</code>, X will be copied; else, it may be overwritten.</p>
</details>
<h4>Returns</h4>
<details class="info" open="open"><summary>self : object</summary><p>returns an instance of self.</p>
</details>
</details>
<h3 id="get_params_11">get_params<a class="headerlink" href="#get_params_11" title="Permanent link">&para;</a></h3>
<details class="note" open="open"><summary>method</summary><div class="highlight"><pre><span></span><code><span class="k">val</span> <span class="n">get_params</span> <span class="o">:</span>
  <span class="o">?</span><span class="n">deep</span><span class="o">:</span><span class="kt">bool</span> <span class="o">-&gt;</span>
  <span class="n">t</span> <span class="o">-&gt;</span>
  <span class="nn">Dict</span><span class="p">.</span><span class="n">t</span>
</code></pre></div>

<p>Get parameters for this estimator.</p>
<h4>Parameters</h4>
<details class="info" open="open"><summary>deep : bool, default=True</summary><p>If True, will return the parameters for this estimator and
contained subobjects that are estimators.</p>
</details>
<h4>Returns</h4>
<details class="info" open="open"><summary>params : mapping of string to any</summary><p>Parameter names mapped to their values.</p>
</details>
</details>
<h3 id="predict_11">predict<a class="headerlink" href="#predict_11" title="Permanent link">&para;</a></h3>
<details class="note" open="open"><summary>method</summary><div class="highlight"><pre><span></span><code><span class="k">val</span> <span class="n">predict</span> <span class="o">:</span>
  <span class="n">x</span><span class="o">:</span><span class="nn">Arr</span><span class="p">.</span><span class="n">t</span> <span class="o">-&gt;</span>
  <span class="n">t</span> <span class="o">-&gt;</span>
  <span class="nn">Arr</span><span class="p">.</span><span class="n">t</span>
</code></pre></div>

<p>Predict using the linear model.</p>
<h4>Parameters</h4>
<details class="info" open="open"><summary>X : array_like or sparse matrix, shape (n_samples, n_features)</summary><p>Samples.</p>
</details>
<h4>Returns</h4>
<details class="info" open="open"><summary>C : array, shape (n_samples,)</summary><p>Returns predicted values.</p>
</details>
</details>
<h3 id="score_11">score<a class="headerlink" href="#score_11" title="Permanent link">&para;</a></h3>
<details class="note" open="open"><summary>method</summary><div class="highlight"><pre><span></span><code><span class="k">val</span> <span class="n">score</span> <span class="o">:</span>
  <span class="o">?</span><span class="n">sample_weight</span><span class="o">:</span><span class="nn">Arr</span><span class="p">.</span><span class="n">t</span> <span class="o">-&gt;</span>
  <span class="n">x</span><span class="o">:</span><span class="nn">Arr</span><span class="p">.</span><span class="n">t</span> <span class="o">-&gt;</span>
  <span class="n">y</span><span class="o">:</span><span class="nn">Arr</span><span class="p">.</span><span class="n">t</span> <span class="o">-&gt;</span>
  <span class="n">t</span> <span class="o">-&gt;</span>
  <span class="kt">float</span>
</code></pre></div>

<p>Return the coefficient of determination R^2 of the prediction.</p>
<p>The coefficient R^2 is defined as (1 - u/v), where u is the residual
sum of squares ((y_true - y_pred) <strong> 2).sum() and v is the total
sum of squares ((y_true - y_true.mean()) </strong> 2).sum().
The best possible score is 1.0 and it can be negative (because the
model can be arbitrarily worse). A constant model that always
predicts the expected value of y, disregarding the input features,
would get a R^2 score of 0.0.</p>
<h4>Parameters</h4>
<details class="info" open="open"><summary>X : array-like of shape (n_samples, n_features)</summary><p>Test samples. For some estimators this may be a
precomputed kernel matrix or a list of generic objects instead,
shape = (n_samples, n_samples_fitted),
where n_samples_fitted is the number of
samples used in the fitting for the estimator.</p>
</details>
<details class="info" open="open"><summary>y : array-like of shape (n_samples,) or (n_samples, n_outputs)</summary><p>True values for X.</p>
</details>
<details class="info" open="open"><summary>sample_weight : array-like of shape (n_samples,), default=None</summary><p>Sample weights.</p>
</details>
<h4>Returns</h4>
<details class="info" open="open"><summary>score : float</summary><p>R^2 of self.predict(X) wrt. y.</p>
</details>
<h4>Notes</h4>
<p>The R2 score used when calling <code>score</code> on a regressor will use
<code>multioutput='uniform_average'</code> from version 0.23 to keep consistent</p>
<details class="info" open="open"><summary>with :func:<code>~sklearn.metrics.r2_score</code>. This will influence the</summary></details>
<p><code>score</code> method of all the multioutput regressors (except for
:class:<code>~sklearn.multioutput.MultiOutputRegressor</code>). To specify the
default value manually and avoid the warning, please either call
:func:<code>~sklearn.metrics.r2_score</code> directly or make a custom scorer with
:func:<code>~sklearn.metrics.make_scorer</code> (the built-in scorer <code>'r2'</code> uses
<code>multioutput='uniform_average'</code>).</p>
</details>
<h3 id="set_params_11">set_params<a class="headerlink" href="#set_params_11" title="Permanent link">&para;</a></h3>
<details class="note" open="open"><summary>method</summary><div class="highlight"><pre><span></span><code><span class="k">val</span> <span class="n">set_params</span> <span class="o">:</span>
  <span class="o">?</span><span class="n">params</span><span class="o">:(</span><span class="kt">string</span> <span class="o">*</span> <span class="nn">Py</span><span class="p">.</span><span class="nn">Object</span><span class="p">.</span><span class="n">t</span><span class="o">)</span> <span class="kt">list</span> <span class="o">-&gt;</span>
  <span class="n">t</span> <span class="o">-&gt;</span>
  <span class="n">t</span>
</code></pre></div>

<p>Set the parameters of this estimator.</p>
<p>The method works on simple estimators as well as on nested objects
(such as pipelines). The latter have parameters of the form
<code>&lt;component&gt;__&lt;parameter&gt;</code> so that it's possible to update each
component of a nested object.</p>
<h4>Parameters</h4>
<details class="info" open="open"><summary>**params : dict</summary><p>Estimator parameters.</p>
</details>
<h4>Returns</h4>
<details class="info" open="open"><summary>self : object</summary><p>Estimator instance.</p>
</details>
</details>
<h3 id="coef__11">coef_<a class="headerlink" href="#coef__11" title="Permanent link">&para;</a></h3>
<details class="note" open="open"><summary>attribute</summary><div class="highlight"><pre><span></span><code><span class="k">val</span> <span class="n">coef_</span> <span class="o">:</span> <span class="n">t</span> <span class="o">-&gt;</span> <span class="nn">Arr</span><span class="p">.</span><span class="n">t</span>
<span class="k">val</span> <span class="n">coef_opt</span> <span class="o">:</span> <span class="n">t</span> <span class="o">-&gt;</span> <span class="o">(</span><span class="nn">Arr</span><span class="p">.</span><span class="n">t</span><span class="o">)</span> <span class="n">option</span>
</code></pre></div>

<p>This attribute is documented in <code>create</code> above. The first version raises Not_found
if the attribute is None. The _opt version returns an option.</p>
</details>
<h3 id="intercept__11">intercept_<a class="headerlink" href="#intercept__11" title="Permanent link">&para;</a></h3>
<details class="note" open="open"><summary>attribute</summary><div class="highlight"><pre><span></span><code><span class="k">val</span> <span class="n">intercept_</span> <span class="o">:</span> <span class="n">t</span> <span class="o">-&gt;</span> <span class="nn">Arr</span><span class="p">.</span><span class="n">t</span>
<span class="k">val</span> <span class="n">intercept_opt</span> <span class="o">:</span> <span class="n">t</span> <span class="o">-&gt;</span> <span class="o">(</span><span class="nn">Arr</span><span class="p">.</span><span class="n">t</span><span class="o">)</span> <span class="n">option</span>
</code></pre></div>

<p>This attribute is documented in <code>create</code> above. The first version raises Not_found
if the attribute is None. The _opt version returns an option.</p>
</details>
<h3 id="alpha__6">alpha_<a class="headerlink" href="#alpha__6" title="Permanent link">&para;</a></h3>
<details class="note" open="open"><summary>attribute</summary><div class="highlight"><pre><span></span><code><span class="k">val</span> <span class="n">alpha_</span> <span class="o">:</span> <span class="n">t</span> <span class="o">-&gt;</span> <span class="kt">float</span>
<span class="k">val</span> <span class="n">alpha_opt</span> <span class="o">:</span> <span class="n">t</span> <span class="o">-&gt;</span> <span class="o">(</span><span class="kt">float</span><span class="o">)</span> <span class="n">option</span>
</code></pre></div>

<p>This attribute is documented in <code>create</code> above. The first version raises Not_found
if the attribute is None. The _opt version returns an option.</p>
</details>
<h3 id="n_iter__10">n_iter_<a class="headerlink" href="#n_iter__10" title="Permanent link">&para;</a></h3>
<details class="note" open="open"><summary>attribute</summary><div class="highlight"><pre><span></span><code><span class="k">val</span> <span class="n">n_iter_</span> <span class="o">:</span> <span class="n">t</span> <span class="o">-&gt;</span> <span class="kt">int</span>
<span class="k">val</span> <span class="n">n_iter_opt</span> <span class="o">:</span> <span class="n">t</span> <span class="o">-&gt;</span> <span class="o">(</span><span class="kt">int</span><span class="o">)</span> <span class="n">option</span>
</code></pre></div>

<p>This attribute is documented in <code>create</code> above. The first version raises Not_found
if the attribute is None. The _opt version returns an option.</p>
</details>
<h3 id="criterion_">criterion_<a class="headerlink" href="#criterion_" title="Permanent link">&para;</a></h3>
<details class="note" open="open"><summary>attribute</summary><div class="highlight"><pre><span></span><code><span class="k">val</span> <span class="n">criterion_</span> <span class="o">:</span> <span class="n">t</span> <span class="o">-&gt;</span> <span class="nn">Arr</span><span class="p">.</span><span class="n">t</span>
<span class="k">val</span> <span class="n">criterion_opt</span> <span class="o">:</span> <span class="n">t</span> <span class="o">-&gt;</span> <span class="o">(</span><span class="nn">Arr</span><span class="p">.</span><span class="n">t</span><span class="o">)</span> <span class="n">option</span>
</code></pre></div>

<p>This attribute is documented in <code>create</code> above. The first version raises Not_found
if the attribute is None. The _opt version returns an option.</p>
</details>
<h3 id="to_string_11">to_string<a class="headerlink" href="#to_string_11" title="Permanent link">&para;</a></h3>
<details class="note" open="open"><summary>method</summary><div class="highlight"><pre><span></span><code><span class="k">val</span> <span class="n">to_string</span><span class="o">:</span> <span class="n">t</span> <span class="o">-&gt;</span> <span class="kt">string</span>
</code></pre></div>

<p>Print the object to a human-readable representation.</p>
</details>
<h3 id="show_11">show<a class="headerlink" href="#show_11" title="Permanent link">&para;</a></h3>
<details class="note" open="open"><summary>method</summary><div class="highlight"><pre><span></span><code><span class="k">val</span> <span class="n">show</span><span class="o">:</span> <span class="n">t</span> <span class="o">-&gt;</span> <span class="kt">string</span>
</code></pre></div>

<p>Print the object to a human-readable representation.</p>
</details>
<h3 id="pp_11">pp<a class="headerlink" href="#pp_11" title="Permanent link">&para;</a></h3>
<details class="note" open="open"><summary>method</summary><div class="highlight"><pre><span></span><code><span class="k">val</span> <span class="n">pp</span><span class="o">:</span> <span class="nn">Format</span><span class="p">.</span><span class="n">formatter</span> <span class="o">-&gt;</span> <span class="n">t</span> <span class="o">-&gt;</span> <span class="kt">unit</span>
</code></pre></div>

<p>Pretty-print the object to a formatter.</p>
</details>
<h2 id="module-sklearnlinear_modellinearregression">module Sklearn.​Linear_model.​LinearRegression<a class="headerlink" href="#module-sklearnlinear_modellinearregression" title="Permanent link">&para;</a></h2>
<div class="highlight"><pre><span></span><code><span class="k">type</span> <span class="n">t</span>
</code></pre></div>

<h3 id="create_12">create<a class="headerlink" href="#create_12" title="Permanent link">&para;</a></h3>
<details class="note" open="open"><summary>constructor and attributes</summary><div class="highlight"><pre><span></span><code><span class="k">val</span> <span class="n">create</span> <span class="o">:</span>
  <span class="o">?</span><span class="n">fit_intercept</span><span class="o">:</span><span class="kt">bool</span> <span class="o">-&gt;</span>
  <span class="o">?</span><span class="n">normalize</span><span class="o">:</span><span class="kt">bool</span> <span class="o">-&gt;</span>
  <span class="o">?</span><span class="n">copy_X</span><span class="o">:</span><span class="kt">bool</span> <span class="o">-&gt;</span>
  <span class="o">?</span><span class="n">n_jobs</span><span class="o">:</span><span class="kt">int</span> <span class="o">-&gt;</span>
  <span class="kt">unit</span> <span class="o">-&gt;</span>
  <span class="n">t</span>
</code></pre></div>

<p>Ordinary least squares Linear Regression.</p>
<p>LinearRegression fits a linear model with coefficients w = (w1, ..., wp)
to minimize the residual sum of squares between the observed targets in
the dataset, and the targets predicted by the linear approximation.</p>
<h4>Parameters</h4>
<details class="info" open="open"><summary>fit_intercept : bool, optional, default True</summary><p>Whether to calculate the intercept for this model. If set
to False, no intercept will be used in calculations
(i.e. data is expected to be centered).</p>
</details>
<details class="info" open="open"><summary>normalize : bool, optional, default False</summary><p>This parameter is ignored when <code>fit_intercept</code> is set to False.
If True, the regressors X will be normalized before regression by
subtracting the mean and dividing by the l2-norm.
If you wish to standardize, please use
:class:<code>sklearn.preprocessing.StandardScaler</code> before calling <code>fit</code> on
an estimator with <code>normalize=False</code>.</p>
</details>
<details class="info" open="open"><summary>copy_X : bool, optional, default True</summary><p>If True, X will be copied; else, it may be overwritten.</p>
</details>
<details class="info" open="open"><summary>n_jobs : int or None, optional (default=None)</summary><p>The number of jobs to use for the computation. This will only provide
speedup for n_targets &gt; 1 and sufficient large problems.
<code>None</code> means 1 unless in a :obj:<code>joblib.parallel_backend</code> context.
<code>-1</code> means using all processors. See :term:<code>Glossary &lt;n_jobs&gt;</code>
for more details.</p>
</details>
<h4>Attributes</h4>
<details class="info" open="open"><summary>coef_ : array of shape (n_features, ) or (n_targets, n_features)</summary><p>Estimated coefficients for the linear regression problem.
If multiple targets are passed during the fit (y 2D), this
is a 2D array of shape (n_targets, n_features), while if only
one target is passed, this is a 1D array of length n_features.</p>
</details>
<details class="info" open="open"><summary>rank_ : int</summary><p>Rank of matrix <code>X</code>. Only available when <code>X</code> is dense.</p>
</details>
<details class="info" open="open"><summary>singular_ : array of shape (min(X, y),)</summary><p>Singular values of <code>X</code>. Only available when <code>X</code> is dense.</p>
</details>
<details class="info" open="open"><summary>intercept_ : float or array of shape of (n_targets,)</summary><p>Independent term in the linear model. Set to 0.0 if
<code>fit_intercept = False</code>.</p>
</details>
<h4>See Also</h4>
<details class="info" open="open"><summary>sklearn.linear_model.Ridge : Ridge regression addresses some of the</summary><p>problems of Ordinary Least Squares by imposing a penalty on the
size of the coefficients with l2 regularization.</p>
</details>
<details class="info" open="open"><summary>sklearn.linear_model.Lasso : The Lasso is a linear model that estimates</summary><p>sparse coefficients with l1 regularization.</p>
</details>
<details class="info" open="open"><summary>sklearn.linear_model.ElasticNet : Elastic-Net is a linear regression</summary><p>model trained with both l1 and l2 -norm regularization of the
coefficients.</p>
</details>
<h4>Notes</h4>
<p>From the implementation point of view, this is just plain Ordinary
Least Squares (scipy.linalg.lstsq) wrapped as a predictor object.</p>
<h4>Examples</h4>
<div class="highlight"><pre><span></span><code><span class="o">&gt;&gt;&gt;</span> <span class="kn">import</span> <span class="nn">numpy</span> <span class="k">as</span> <span class="nn">np</span>
<span class="o">&gt;&gt;&gt;</span> <span class="kn">from</span> <span class="nn">sklearn.linear_model</span> <span class="kn">import</span> <span class="n">LinearRegression</span>
<span class="o">&gt;&gt;&gt;</span> <span class="n">X</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">array</span><span class="p">([[</span><span class="mi">1</span><span class="p">,</span> <span class="mi">1</span><span class="p">],</span> <span class="p">[</span><span class="mi">1</span><span class="p">,</span> <span class="mi">2</span><span class="p">],</span> <span class="p">[</span><span class="mi">2</span><span class="p">,</span> <span class="mi">2</span><span class="p">],</span> <span class="p">[</span><span class="mi">2</span><span class="p">,</span> <span class="mi">3</span><span class="p">]])</span>
<span class="o">&gt;&gt;&gt;</span> <span class="c1"># y = 1 * x_0 + 2 * x_1 + 3</span>
<span class="o">&gt;&gt;&gt;</span> <span class="n">y</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">dot</span><span class="p">(</span><span class="n">X</span><span class="p">,</span> <span class="n">np</span><span class="o">.</span><span class="n">array</span><span class="p">([</span><span class="mi">1</span><span class="p">,</span> <span class="mi">2</span><span class="p">]))</span> <span class="o">+</span> <span class="mi">3</span>
<span class="o">&gt;&gt;&gt;</span> <span class="n">reg</span> <span class="o">=</span> <span class="n">LinearRegression</span><span class="p">()</span><span class="o">.</span><span class="n">fit</span><span class="p">(</span><span class="n">X</span><span class="p">,</span> <span class="n">y</span><span class="p">)</span>
<span class="o">&gt;&gt;&gt;</span> <span class="n">reg</span><span class="o">.</span><span class="n">score</span><span class="p">(</span><span class="n">X</span><span class="p">,</span> <span class="n">y</span><span class="p">)</span>
<span class="mf">1.0</span>
<span class="o">&gt;&gt;&gt;</span> <span class="n">reg</span><span class="o">.</span><span class="n">coef_</span>
<span class="n">array</span><span class="p">([</span><span class="mf">1.</span><span class="p">,</span> <span class="mf">2.</span><span class="p">])</span>
<span class="o">&gt;&gt;&gt;</span> <span class="n">reg</span><span class="o">.</span><span class="n">intercept_</span>
<span class="mf">3.0000</span><span class="o">...</span>
<span class="o">&gt;&gt;&gt;</span> <span class="n">reg</span><span class="o">.</span><span class="n">predict</span><span class="p">(</span><span class="n">np</span><span class="o">.</span><span class="n">array</span><span class="p">([[</span><span class="mi">3</span><span class="p">,</span> <span class="mi">5</span><span class="p">]]))</span>
<span class="n">array</span><span class="p">([</span><span class="mf">16.</span><span class="p">])</span>
</code></pre></div>

</details>
<h3 id="fit_12">fit<a class="headerlink" href="#fit_12" title="Permanent link">&para;</a></h3>
<details class="note" open="open"><summary>method</summary><div class="highlight"><pre><span></span><code><span class="k">val</span> <span class="n">fit</span> <span class="o">:</span>
  <span class="o">?</span><span class="n">sample_weight</span><span class="o">:</span><span class="nn">Arr</span><span class="p">.</span><span class="n">t</span> <span class="o">-&gt;</span>
  <span class="n">x</span><span class="o">:</span><span class="nn">Arr</span><span class="p">.</span><span class="n">t</span> <span class="o">-&gt;</span>
  <span class="n">y</span><span class="o">:</span><span class="nn">Arr</span><span class="p">.</span><span class="n">t</span> <span class="o">-&gt;</span>
  <span class="n">t</span> <span class="o">-&gt;</span>
  <span class="n">t</span>
</code></pre></div>

<p>Fit linear model.</p>
<h4>Parameters</h4>
<details class="info" open="open"><summary>X : {array-like, sparse matrix} of shape (n_samples, n_features)</summary><p>Training data</p>
</details>
<details class="info" open="open"><summary>y : array-like of shape (n_samples,) or (n_samples, n_targets)</summary><p>Target values. Will be cast to X's dtype if necessary</p>
</details>
<details class="info" open="open"><summary>sample_weight : array-like of shape (n_samples,), default=None</summary><p>Individual weights for each sample</p>
<p>.. versionadded:: 0.17
   parameter <em>sample_weight</em> support to LinearRegression.</p>
</details>
<h4>Returns</h4>
<details class="info" open="open"><summary>self : returns an instance of self.</summary></details>
</details>
<h3 id="get_params_12">get_params<a class="headerlink" href="#get_params_12" title="Permanent link">&para;</a></h3>
<details class="note" open="open"><summary>method</summary><div class="highlight"><pre><span></span><code><span class="k">val</span> <span class="n">get_params</span> <span class="o">:</span>
  <span class="o">?</span><span class="n">deep</span><span class="o">:</span><span class="kt">bool</span> <span class="o">-&gt;</span>
  <span class="n">t</span> <span class="o">-&gt;</span>
  <span class="nn">Dict</span><span class="p">.</span><span class="n">t</span>
</code></pre></div>

<p>Get parameters for this estimator.</p>
<h4>Parameters</h4>
<details class="info" open="open"><summary>deep : bool, default=True</summary><p>If True, will return the parameters for this estimator and
contained subobjects that are estimators.</p>
</details>
<h4>Returns</h4>
<details class="info" open="open"><summary>params : mapping of string to any</summary><p>Parameter names mapped to their values.</p>
</details>
</details>
<h3 id="predict_12">predict<a class="headerlink" href="#predict_12" title="Permanent link">&para;</a></h3>
<details class="note" open="open"><summary>method</summary><div class="highlight"><pre><span></span><code><span class="k">val</span> <span class="n">predict</span> <span class="o">:</span>
  <span class="n">x</span><span class="o">:</span><span class="nn">Arr</span><span class="p">.</span><span class="n">t</span> <span class="o">-&gt;</span>
  <span class="n">t</span> <span class="o">-&gt;</span>
  <span class="nn">Arr</span><span class="p">.</span><span class="n">t</span>
</code></pre></div>

<p>Predict using the linear model.</p>
<h4>Parameters</h4>
<details class="info" open="open"><summary>X : array_like or sparse matrix, shape (n_samples, n_features)</summary><p>Samples.</p>
</details>
<h4>Returns</h4>
<details class="info" open="open"><summary>C : array, shape (n_samples,)</summary><p>Returns predicted values.</p>
</details>
</details>
<h3 id="score_12">score<a class="headerlink" href="#score_12" title="Permanent link">&para;</a></h3>
<details class="note" open="open"><summary>method</summary><div class="highlight"><pre><span></span><code><span class="k">val</span> <span class="n">score</span> <span class="o">:</span>
  <span class="o">?</span><span class="n">sample_weight</span><span class="o">:</span><span class="nn">Arr</span><span class="p">.</span><span class="n">t</span> <span class="o">-&gt;</span>
  <span class="n">x</span><span class="o">:</span><span class="nn">Arr</span><span class="p">.</span><span class="n">t</span> <span class="o">-&gt;</span>
  <span class="n">y</span><span class="o">:</span><span class="nn">Arr</span><span class="p">.</span><span class="n">t</span> <span class="o">-&gt;</span>
  <span class="n">t</span> <span class="o">-&gt;</span>
  <span class="kt">float</span>
</code></pre></div>

<p>Return the coefficient of determination R^2 of the prediction.</p>
<p>The coefficient R^2 is defined as (1 - u/v), where u is the residual
sum of squares ((y_true - y_pred) <strong> 2).sum() and v is the total
sum of squares ((y_true - y_true.mean()) </strong> 2).sum().
The best possible score is 1.0 and it can be negative (because the
model can be arbitrarily worse). A constant model that always
predicts the expected value of y, disregarding the input features,
would get a R^2 score of 0.0.</p>
<h4>Parameters</h4>
<details class="info" open="open"><summary>X : array-like of shape (n_samples, n_features)</summary><p>Test samples. For some estimators this may be a
precomputed kernel matrix or a list of generic objects instead,
shape = (n_samples, n_samples_fitted),
where n_samples_fitted is the number of
samples used in the fitting for the estimator.</p>
</details>
<details class="info" open="open"><summary>y : array-like of shape (n_samples,) or (n_samples, n_outputs)</summary><p>True values for X.</p>
</details>
<details class="info" open="open"><summary>sample_weight : array-like of shape (n_samples,), default=None</summary><p>Sample weights.</p>
</details>
<h4>Returns</h4>
<details class="info" open="open"><summary>score : float</summary><p>R^2 of self.predict(X) wrt. y.</p>
</details>
<h4>Notes</h4>
<p>The R2 score used when calling <code>score</code> on a regressor will use
<code>multioutput='uniform_average'</code> from version 0.23 to keep consistent</p>
<details class="info" open="open"><summary>with :func:<code>~sklearn.metrics.r2_score</code>. This will influence the</summary></details>
<p><code>score</code> method of all the multioutput regressors (except for
:class:<code>~sklearn.multioutput.MultiOutputRegressor</code>). To specify the
default value manually and avoid the warning, please either call
:func:<code>~sklearn.metrics.r2_score</code> directly or make a custom scorer with
:func:<code>~sklearn.metrics.make_scorer</code> (the built-in scorer <code>'r2'</code> uses
<code>multioutput='uniform_average'</code>).</p>
</details>
<h3 id="set_params_12">set_params<a class="headerlink" href="#set_params_12" title="Permanent link">&para;</a></h3>
<details class="note" open="open"><summary>method</summary><div class="highlight"><pre><span></span><code><span class="k">val</span> <span class="n">set_params</span> <span class="o">:</span>
  <span class="o">?</span><span class="n">params</span><span class="o">:(</span><span class="kt">string</span> <span class="o">*</span> <span class="nn">Py</span><span class="p">.</span><span class="nn">Object</span><span class="p">.</span><span class="n">t</span><span class="o">)</span> <span class="kt">list</span> <span class="o">-&gt;</span>
  <span class="n">t</span> <span class="o">-&gt;</span>
  <span class="n">t</span>
</code></pre></div>

<p>Set the parameters of this estimator.</p>
<p>The method works on simple estimators as well as on nested objects
(such as pipelines). The latter have parameters of the form
<code>&lt;component&gt;__&lt;parameter&gt;</code> so that it's possible to update each
component of a nested object.</p>
<h4>Parameters</h4>
<details class="info" open="open"><summary>**params : dict</summary><p>Estimator parameters.</p>
</details>
<h4>Returns</h4>
<details class="info" open="open"><summary>self : object</summary><p>Estimator instance.</p>
</details>
</details>
<h3 id="coef__12">coef_<a class="headerlink" href="#coef__12" title="Permanent link">&para;</a></h3>
<details class="note" open="open"><summary>attribute</summary><div class="highlight"><pre><span></span><code><span class="k">val</span> <span class="n">coef_</span> <span class="o">:</span> <span class="n">t</span> <span class="o">-&gt;</span> <span class="nn">Arr</span><span class="p">.</span><span class="n">t</span>
<span class="k">val</span> <span class="n">coef_opt</span> <span class="o">:</span> <span class="n">t</span> <span class="o">-&gt;</span> <span class="o">(</span><span class="nn">Arr</span><span class="p">.</span><span class="n">t</span><span class="o">)</span> <span class="n">option</span>
</code></pre></div>

<p>This attribute is documented in <code>create</code> above. The first version raises Not_found
if the attribute is None. The _opt version returns an option.</p>
</details>
<h3 id="rank_">rank_<a class="headerlink" href="#rank_" title="Permanent link">&para;</a></h3>
<details class="note" open="open"><summary>attribute</summary><div class="highlight"><pre><span></span><code><span class="k">val</span> <span class="n">rank_</span> <span class="o">:</span> <span class="n">t</span> <span class="o">-&gt;</span> <span class="kt">int</span>
<span class="k">val</span> <span class="n">rank_opt</span> <span class="o">:</span> <span class="n">t</span> <span class="o">-&gt;</span> <span class="o">(</span><span class="kt">int</span><span class="o">)</span> <span class="n">option</span>
</code></pre></div>

<p>This attribute is documented in <code>create</code> above. The first version raises Not_found
if the attribute is None. The _opt version returns an option.</p>
</details>
<h3 id="singular_">singular_<a class="headerlink" href="#singular_" title="Permanent link">&para;</a></h3>
<details class="note" open="open"><summary>attribute</summary><div class="highlight"><pre><span></span><code><span class="k">val</span> <span class="n">singular_</span> <span class="o">:</span> <span class="n">t</span> <span class="o">-&gt;</span> <span class="nn">Py</span><span class="p">.</span><span class="nn">Object</span><span class="p">.</span><span class="n">t</span>
<span class="k">val</span> <span class="n">singular_opt</span> <span class="o">:</span> <span class="n">t</span> <span class="o">-&gt;</span> <span class="o">(</span><span class="nn">Py</span><span class="p">.</span><span class="nn">Object</span><span class="p">.</span><span class="n">t</span><span class="o">)</span> <span class="n">option</span>
</code></pre></div>

<p>This attribute is documented in <code>create</code> above. The first version raises Not_found
if the attribute is None. The _opt version returns an option.</p>
</details>
<h3 id="intercept__12">intercept_<a class="headerlink" href="#intercept__12" title="Permanent link">&para;</a></h3>
<details class="note" open="open"><summary>attribute</summary><div class="highlight"><pre><span></span><code><span class="k">val</span> <span class="n">intercept_</span> <span class="o">:</span> <span class="n">t</span> <span class="o">-&gt;</span> <span class="nn">Arr</span><span class="p">.</span><span class="n">t</span>
<span class="k">val</span> <span class="n">intercept_opt</span> <span class="o">:</span> <span class="n">t</span> <span class="o">-&gt;</span> <span class="o">(</span><span class="nn">Arr</span><span class="p">.</span><span class="n">t</span><span class="o">)</span> <span class="n">option</span>
</code></pre></div>

<p>This attribute is documented in <code>create</code> above. The first version raises Not_found
if the attribute is None. The _opt version returns an option.</p>
</details>
<h3 id="to_string_12">to_string<a class="headerlink" href="#to_string_12" title="Permanent link">&para;</a></h3>
<details class="note" open="open"><summary>method</summary><div class="highlight"><pre><span></span><code><span class="k">val</span> <span class="n">to_string</span><span class="o">:</span> <span class="n">t</span> <span class="o">-&gt;</span> <span class="kt">string</span>
</code></pre></div>

<p>Print the object to a human-readable representation.</p>
</details>
<h3 id="show_12">show<a class="headerlink" href="#show_12" title="Permanent link">&para;</a></h3>
<details class="note" open="open"><summary>method</summary><div class="highlight"><pre><span></span><code><span class="k">val</span> <span class="n">show</span><span class="o">:</span> <span class="n">t</span> <span class="o">-&gt;</span> <span class="kt">string</span>
</code></pre></div>

<p>Print the object to a human-readable representation.</p>
</details>
<h3 id="pp_12">pp<a class="headerlink" href="#pp_12" title="Permanent link">&para;</a></h3>
<details class="note" open="open"><summary>method</summary><div class="highlight"><pre><span></span><code><span class="k">val</span> <span class="n">pp</span><span class="o">:</span> <span class="nn">Format</span><span class="p">.</span><span class="n">formatter</span> <span class="o">-&gt;</span> <span class="n">t</span> <span class="o">-&gt;</span> <span class="kt">unit</span>
</code></pre></div>

<p>Pretty-print the object to a formatter.</p>
</details>
<h2 id="module-sklearnlinear_modellogisticregression">module Sklearn.​Linear_model.​LogisticRegression<a class="headerlink" href="#module-sklearnlinear_modellogisticregression" title="Permanent link">&para;</a></h2>
<div class="highlight"><pre><span></span><code><span class="k">type</span> <span class="n">t</span>
</code></pre></div>

<h3 id="create_13">create<a class="headerlink" href="#create_13" title="Permanent link">&para;</a></h3>
<details class="note" open="open"><summary>constructor and attributes</summary><div class="highlight"><pre><span></span><code><span class="k">val</span> <span class="n">create</span> <span class="o">:</span>
  <span class="o">?</span><span class="n">penalty</span><span class="o">:[`</span><span class="nc">L1</span> <span class="o">|</span> <span class="o">`</span><span class="nc">L2</span> <span class="o">|</span> <span class="o">`</span><span class="nc">Elasticnet</span> <span class="o">|</span> <span class="o">`</span><span class="nc">None</span><span class="o">]</span> <span class="o">-&gt;</span>
  <span class="o">?</span><span class="n">dual</span><span class="o">:</span><span class="kt">bool</span> <span class="o">-&gt;</span>
  <span class="o">?</span><span class="n">tol</span><span class="o">:</span><span class="kt">float</span> <span class="o">-&gt;</span>
  <span class="o">?</span><span class="n">c</span><span class="o">:</span><span class="kt">float</span> <span class="o">-&gt;</span>
  <span class="o">?</span><span class="n">fit_intercept</span><span class="o">:</span><span class="kt">bool</span> <span class="o">-&gt;</span>
  <span class="o">?</span><span class="n">intercept_scaling</span><span class="o">:</span><span class="kt">float</span> <span class="o">-&gt;</span>
  <span class="o">?</span><span class="n">class_weight</span><span class="o">:[`</span><span class="nc">DictIntToFloat</span> <span class="k">of</span> <span class="o">(</span><span class="kt">int</span> <span class="o">*</span> <span class="kt">float</span><span class="o">)</span> <span class="kt">list</span> <span class="o">|</span> <span class="o">`</span><span class="nc">Balanced</span><span class="o">]</span> <span class="o">-&gt;</span>
  <span class="o">?</span><span class="n">random_state</span><span class="o">:</span><span class="kt">int</span> <span class="o">-&gt;</span>
  <span class="o">?</span><span class="n">solver</span><span class="o">:[`</span><span class="nc">Newton_cg</span> <span class="o">|</span> <span class="o">`</span><span class="nc">Lbfgs</span> <span class="o">|</span> <span class="o">`</span><span class="nc">Liblinear</span> <span class="o">|</span> <span class="o">`</span><span class="nc">Sag</span> <span class="o">|</span> <span class="o">`</span><span class="nc">Saga</span><span class="o">]</span> <span class="o">-&gt;</span>
  <span class="o">?</span><span class="n">max_iter</span><span class="o">:</span><span class="kt">int</span> <span class="o">-&gt;</span>
  <span class="o">?</span><span class="n">multi_class</span><span class="o">:[`</span><span class="nc">Auto</span> <span class="o">|</span> <span class="o">`</span><span class="nc">Ovr</span> <span class="o">|</span> <span class="o">`</span><span class="nc">Multinomial</span><span class="o">]</span> <span class="o">-&gt;</span>
  <span class="o">?</span><span class="n">verbose</span><span class="o">:</span><span class="kt">int</span> <span class="o">-&gt;</span>
  <span class="o">?</span><span class="n">warm_start</span><span class="o">:</span><span class="kt">bool</span> <span class="o">-&gt;</span>
  <span class="o">?</span><span class="n">n_jobs</span><span class="o">:</span><span class="kt">int</span> <span class="o">-&gt;</span>
  <span class="o">?</span><span class="n">l1_ratio</span><span class="o">:</span><span class="kt">float</span> <span class="o">-&gt;</span>
  <span class="kt">unit</span> <span class="o">-&gt;</span>
  <span class="n">t</span>
</code></pre></div>

<p>Logistic Regression (aka logit, MaxEnt) classifier.</p>
<p>In the multiclass case, the training algorithm uses the one-vs-rest (OvR)
scheme if the 'multi_class' option is set to 'ovr', and uses the
cross-entropy loss if the 'multi_class' option is set to 'multinomial'.
(Currently the 'multinomial' option is supported only by the 'lbfgs',
'sag', 'saga' and 'newton-cg' solvers.)</p>
<p>This class implements regularized logistic regression using the
'liblinear' library, 'newton-cg', 'sag', 'saga' and 'lbfgs' solvers. <strong>Note
that regularization is applied by default</strong>. It can handle both dense
and sparse input. Use C-ordered arrays or CSR matrices containing 64-bit
floats for optimal performance; any other input format will be converted
(and copied).</p>
<p>The 'newton-cg', 'sag', and 'lbfgs' solvers support only L2 regularization
with primal formulation, or no regularization. The 'liblinear' solver
supports both L1 and L2 regularization, with a dual formulation only for
the L2 penalty. The Elastic-Net regularization is only supported by the
'saga' solver.</p>
<p>Read more in the :ref:<code>User Guide &lt;logistic_regression&gt;</code>.</p>
<h4>Parameters</h4>
<details class="info" open="open"><summary>penalty : {'l1', 'l2', 'elasticnet', 'none'}, default='l2'</summary><p>Used to specify the norm used in the penalization. The 'newton-cg',
'sag' and 'lbfgs' solvers support only l2 penalties. 'elasticnet' is
only supported by the 'saga' solver. If 'none' (not supported by the
liblinear solver), no regularization is applied.</p>
<p>.. versionadded:: 0.19
   l1 penalty with SAGA solver (allowing 'multinomial' + L1)</p>
</details>
<details class="info" open="open"><summary>dual : bool, default=False</summary><p>Dual or primal formulation. Dual formulation is only implemented for
l2 penalty with liblinear solver. Prefer dual=False when
n_samples &gt; n_features.</p>
</details>
<details class="info" open="open"><summary>tol : float, default=1e-4</summary><p>Tolerance for stopping criteria.</p>
</details>
<details class="info" open="open"><summary>C : float, default=1.0</summary><p>Inverse of regularization strength; must be a positive float.
Like in support vector machines, smaller values specify stronger
regularization.</p>
</details>
<details class="info" open="open"><summary>fit_intercept : bool, default=True</summary><p>Specifies if a constant (a.k.a. bias or intercept) should be
added to the decision function.</p>
</details>
<details class="info" open="open"><summary>intercept_scaling : float, default=1</summary><p>Useful only when the solver 'liblinear' is used
and self.fit_intercept is set to True. In this case, x becomes
[x, self.intercept_scaling],
i.e. a "synthetic" feature with constant value equal to
intercept_scaling is appended to the instance vector.
The intercept becomes <code>intercept_scaling * synthetic_feature_weight</code>.</p>
<p>Note! the synthetic feature weight is subject to l1/l2 regularization
as all other features.
To lessen the effect of regularization on synthetic feature weight
(and therefore on the intercept) intercept_scaling has to be increased.</p>
</details>
<details class="info" open="open"><summary>class_weight : dict or 'balanced', default=None</summary><p>Weights associated with classes in the form <code>{class_label: weight}</code>.
If not given, all classes are supposed to have weight one.</p>
<p>The "balanced" mode uses the values of y to automatically adjust
weights inversely proportional to class frequencies in the input data
as <code>n_samples / (n_classes * np.bincount(y))</code>.</p>
<p>Note that these weights will be multiplied with sample_weight (passed
through the fit method) if sample_weight is specified.</p>
<p>.. versionadded:: 0.17
   <em>class_weight='balanced'</em></p>
</details>
<details class="info" open="open"><summary>random_state : int, RandomState instance, default=None</summary><p>The seed of the pseudo random number generator to use when shuffling
the data.  If int, random_state is the seed used by the random number
generator; If RandomState instance, random_state is the random number
generator; If None, the random number generator is the RandomState
instance used by <code>np.random</code>. Used when <code>solver</code> == 'sag' or
'liblinear'.</p>
</details>
<details class="info" open="open"><summary>solver : {'newton-cg', 'lbfgs', 'liblinear', 'sag', 'saga'},             default='lbfgs'</summary><p>Algorithm to use in the optimization problem.</p>
<ul>
<li>For small datasets, 'liblinear' is a good choice, whereas 'sag' and
  'saga' are faster for large ones.</li>
<li>For multiclass problems, only 'newton-cg', 'sag', 'saga' and 'lbfgs'
  handle multinomial loss; 'liblinear' is limited to one-versus-rest
  schemes.</li>
<li>'newton-cg', 'lbfgs', 'sag' and 'saga' handle L2 or no penalty</li>
<li>'liblinear' and 'saga' also handle L1 penalty</li>
<li>'saga' also supports 'elasticnet' penalty</li>
<li>'liblinear' does not support setting <code>penalty='none'</code></li>
</ul>
<p>Note that 'sag' and 'saga' fast convergence is only guaranteed on
features with approximately the same scale. You can
preprocess the data with a scaler from sklearn.preprocessing.</p>
<p>.. versionadded:: 0.17
   Stochastic Average Gradient descent solver.
.. versionadded:: 0.19
   SAGA solver.
.. versionchanged:: 0.22
    The default solver changed from 'liblinear' to 'lbfgs' in 0.22.</p>
</details>
<details class="info" open="open"><summary>max_iter : int, default=100</summary><p>Maximum number of iterations taken for the solvers to converge.</p>
</details>
<details class="info" open="open"><summary>multi_class : {'auto', 'ovr', 'multinomial'}, default='auto'</summary><p>If the option chosen is 'ovr', then a binary problem is fit for each
label. For 'multinomial' the loss minimised is the multinomial loss fit
across the entire probability distribution, <em>even when the data is
binary</em>. 'multinomial' is unavailable when solver='liblinear'.
'auto' selects 'ovr' if the data is binary, or if solver='liblinear',
and otherwise selects 'multinomial'.</p>
<p>.. versionadded:: 0.18
   Stochastic Average Gradient descent solver for 'multinomial' case.
.. versionchanged:: 0.22
    Default changed from 'ovr' to 'auto' in 0.22.</p>
</details>
<details class="info" open="open"><summary>verbose : int, default=0</summary><p>For the liblinear and lbfgs solvers set verbose to any positive
number for verbosity.</p>
</details>
<details class="info" open="open"><summary>warm_start : bool, default=False</summary><p>When set to True, reuse the solution of the previous call to fit as
initialization, otherwise, just erase the previous solution.
Useless for liblinear solver. See :term:<code>the Glossary &lt;warm_start&gt;</code>.</p>
<p>.. versionadded:: 0.17
   <em>warm_start</em> to support <em>lbfgs</em>, <em>newton-cg</em>, <em>sag</em>, <em>saga</em> solvers.</p>
</details>
<details class="info" open="open"><summary>n_jobs : int, default=None</summary><p>Number of CPU cores used when parallelizing over classes if
multi_class='ovr'". This parameter is ignored when the <code>solver</code> is
set to 'liblinear' regardless of whether 'multi_class' is specified or
not. <code>None</code> means 1 unless in a :obj:<code>joblib.parallel_backend</code>
context. <code>-1</code> means using all processors.</p>
</details>
<details class="info" open="open"><summary>See :term:<code>Glossary &lt;n_jobs&gt;</code> for more details.</summary></details>
<details class="info" open="open"><summary>l1_ratio : float, default=None</summary><p>The Elastic-Net mixing parameter, with <code>0 &lt;= l1_ratio &lt;= 1</code>. Only
used if <code>penalty='elasticnet'`. Setting</code>l1_ratio=0<code>is equivalent
to using</code>penalty='l2'<code>, while setting</code>l1_ratio=1<code>is equivalent
to using</code>penalty='l1'<code>. For</code>0 &lt; l1_ratio &lt;1``, the penalty is a
combination of L1 and L2.</p>
</details>
<h4>Attributes</h4>
<details class="info" open="open"><summary>classes_ : ndarray of shape (n_classes, )</summary><p>A list of class labels known to the classifier.</p>
</details>
<details class="info" open="open"><summary>coef_ : ndarray of shape (1, n_features) or (n_classes, n_features)</summary><p>Coefficient of the features in the decision function.</p>
<p><code>coef_</code> is of shape (1, n_features) when the given problem is binary.
In particular, when <code>multi_class='multinomial'</code>, <code>coef_</code> corresponds
to outcome 1 (True) and <code>-coef_</code> corresponds to outcome 0 (False).</p>
</details>
<details class="info" open="open"><summary>intercept_ : ndarray of shape (1,) or (n_classes,)</summary><p>Intercept (a.k.a. bias) added to the decision function.</p>
<p>If <code>fit_intercept</code> is set to False, the intercept is set to zero.
<code>intercept_</code> is of shape (1,) when the given problem is binary.
In particular, when <code>multi_class='multinomial'</code>, <code>intercept_</code>
corresponds to outcome 1 (True) and <code>-intercept_</code> corresponds to
outcome 0 (False).</p>
</details>
<details class="info" open="open"><summary>n_iter_ : ndarray of shape (n_classes,) or (1, )</summary><p>Actual number of iterations for all classes. If binary or multinomial,
it returns only 1 element. For liblinear solver, only the maximum
number of iteration across all classes is given.</p>
<p>.. versionchanged:: 0.20</p>
<div class="codehilite"><pre><span></span><code>In SciPy &lt;= 1.0.0 the number of lbfgs iterations may exceed
``max_iter``. ``n_iter_`` will now report at most ``max_iter``.
</code></pre></div>


</details>
<h4>See Also</h4>
<details class="info" open="open"><summary>SGDClassifier : Incrementally trained logistic regression (when given</summary><p>the parameter <code>loss="log"</code>).</p>
</details>
<details class="info" open="open"><summary>LogisticRegressionCV : Logistic regression with built-in cross validation.</summary></details>
<h4>Notes</h4>
<p>The underlying C implementation uses a random number generator to
select features when fitting the model. It is thus not uncommon,
to have slightly different results for the same input data. If
that happens, try with a smaller tol parameter.</p>
<p>Predict output may not match that of standalone liblinear in certain
cases. See :ref:<code>differences from liblinear &lt;liblinear_differences&gt;</code>
in the narrative documentation.</p>
<h4>References</h4>
<p>L-BFGS-B -- Software for Large-scale Bound-constrained Optimization
    Ciyou Zhu, Richard Byrd, Jorge Nocedal and Jose Luis Morales.</p>
<details class="info" open="open"><summary>http://users.iems.northwestern.edu/~nocedal/lbfgsb.html</summary></details>
<p>LIBLINEAR -- A Library for Large Linear Classification</p>
<details class="info" open="open"><summary>https://www.csie.ntu.edu.tw/~cjlin/liblinear/</summary></details>
<p>SAG -- Mark Schmidt, Nicolas Le Roux, and Francis Bach
    Minimizing Finite Sums with the Stochastic Average Gradient</p>
<details class="info" open="open"><summary>https://hal.inria.fr/hal-00860051/document</summary></details>
<p>SAGA -- Defazio, A., Bach F. &amp; Lacoste-Julien S. (2014).</p>
<details class="info" open="open"><summary>SAGA: A Fast Incremental Gradient Method With Support</summary><p>for Non-Strongly Convex Composite Objectives</p>
</details>
<details class="info" open="open"><summary>https://arxiv.org/abs/1407.0202</summary></details>
<p>Hsiang-Fu Yu, Fang-Lan Huang, Chih-Jen Lin (2011). Dual coordinate descent
    methods for logistic regression and maximum entropy models.
    Machine Learning 85(1-2):41-75.</p>
<details class="info" open="open"><summary>https://www.csie.ntu.edu.tw/~cjlin/papers/maxent_dual.pdf</summary></details>
<h4>Examples</h4>
<div class="highlight"><pre><span></span><code><span class="o">&gt;&gt;&gt;</span> <span class="kn">from</span> <span class="nn">sklearn.datasets</span> <span class="kn">import</span> <span class="n">load_iris</span>
<span class="o">&gt;&gt;&gt;</span> <span class="kn">from</span> <span class="nn">sklearn.linear_model</span> <span class="kn">import</span> <span class="n">LogisticRegression</span>
<span class="o">&gt;&gt;&gt;</span> <span class="n">X</span><span class="p">,</span> <span class="n">y</span> <span class="o">=</span> <span class="n">load_iris</span><span class="p">(</span><span class="n">return_X_y</span><span class="o">=</span><span class="kc">True</span><span class="p">)</span>
<span class="o">&gt;&gt;&gt;</span> <span class="n">clf</span> <span class="o">=</span> <span class="n">LogisticRegression</span><span class="p">(</span><span class="n">random_state</span><span class="o">=</span><span class="mi">0</span><span class="p">)</span><span class="o">.</span><span class="n">fit</span><span class="p">(</span><span class="n">X</span><span class="p">,</span> <span class="n">y</span><span class="p">)</span>
<span class="o">&gt;&gt;&gt;</span> <span class="n">clf</span><span class="o">.</span><span class="n">predict</span><span class="p">(</span><span class="n">X</span><span class="p">[:</span><span class="mi">2</span><span class="p">,</span> <span class="p">:])</span>
<span class="n">array</span><span class="p">([</span><span class="mi">0</span><span class="p">,</span> <span class="mi">0</span><span class="p">])</span>
<span class="o">&gt;&gt;&gt;</span> <span class="n">clf</span><span class="o">.</span><span class="n">predict_proba</span><span class="p">(</span><span class="n">X</span><span class="p">[:</span><span class="mi">2</span><span class="p">,</span> <span class="p">:])</span>
<span class="n">array</span><span class="p">([[</span><span class="mf">9.8</span><span class="o">...</span><span class="n">e</span><span class="o">-</span><span class="mi">01</span><span class="p">,</span> <span class="mf">1.8</span><span class="o">...</span><span class="n">e</span><span class="o">-</span><span class="mi">02</span><span class="p">,</span> <span class="mf">1.4</span><span class="o">...</span><span class="n">e</span><span class="o">-</span><span class="mi">08</span><span class="p">],</span>
       <span class="p">[</span><span class="mf">9.7</span><span class="o">...</span><span class="n">e</span><span class="o">-</span><span class="mi">01</span><span class="p">,</span> <span class="mf">2.8</span><span class="o">...</span><span class="n">e</span><span class="o">-</span><span class="mi">02</span><span class="p">,</span> <span class="o">...</span><span class="n">e</span><span class="o">-</span><span class="mi">08</span><span class="p">]])</span>
<span class="o">&gt;&gt;&gt;</span> <span class="n">clf</span><span class="o">.</span><span class="n">score</span><span class="p">(</span><span class="n">X</span><span class="p">,</span> <span class="n">y</span><span class="p">)</span>
<span class="mf">0.97</span><span class="o">...</span><span class="s2">&quot;</span>
</code></pre></div>

</details>
<h3 id="decision_function">decision_function<a class="headerlink" href="#decision_function" title="Permanent link">&para;</a></h3>
<details class="note" open="open"><summary>method</summary><div class="highlight"><pre><span></span><code><span class="k">val</span> <span class="n">decision_function</span> <span class="o">:</span>
  <span class="n">x</span><span class="o">:</span><span class="nn">Arr</span><span class="p">.</span><span class="n">t</span> <span class="o">-&gt;</span>
  <span class="n">t</span> <span class="o">-&gt;</span>
  <span class="nn">Arr</span><span class="p">.</span><span class="n">t</span>
</code></pre></div>

<p>Predict confidence scores for samples.</p>
<p>The confidence score for a sample is the signed distance of that
sample to the hyperplane.</p>
<h4>Parameters</h4>
<details class="info" open="open"><summary>X : array_like or sparse matrix, shape (n_samples, n_features)</summary><p>Samples.</p>
</details>
<h4>Returns</h4>
<p>array, shape=(n_samples,) if n_classes == 2 else (n_samples, n_classes)
    Confidence scores per (sample, class) combination. In the binary
    case, confidence score for self.classes_[1] where &gt;0 means this
    class would be predicted.</p>
</details>
<h3 id="densify">densify<a class="headerlink" href="#densify" title="Permanent link">&para;</a></h3>
<details class="note" open="open"><summary>method</summary><div class="highlight"><pre><span></span><code><span class="k">val</span> <span class="n">densify</span> <span class="o">:</span>
  <span class="n">t</span> <span class="o">-&gt;</span>
  <span class="n">t</span>
</code></pre></div>

<p>Convert coefficient matrix to dense array format.</p>
<p>Converts the <code>coef_</code> member (back) to a numpy.ndarray. This is the
default format of <code>coef_</code> and is required for fitting, so calling
this method is only required on models that have previously been
sparsified; otherwise, it is a no-op.</p>
<h4>Returns</h4>
<p>self
    Fitted estimator.</p>
</details>
<h3 id="fit_13">fit<a class="headerlink" href="#fit_13" title="Permanent link">&para;</a></h3>
<details class="note" open="open"><summary>method</summary><div class="highlight"><pre><span></span><code><span class="k">val</span> <span class="n">fit</span> <span class="o">:</span>
  <span class="o">?</span><span class="n">sample_weight</span><span class="o">:</span><span class="nn">Arr</span><span class="p">.</span><span class="n">t</span> <span class="o">-&gt;</span>
  <span class="n">x</span><span class="o">:</span><span class="nn">Arr</span><span class="p">.</span><span class="n">t</span> <span class="o">-&gt;</span>
  <span class="n">y</span><span class="o">:</span><span class="nn">Arr</span><span class="p">.</span><span class="n">t</span> <span class="o">-&gt;</span>
  <span class="n">t</span> <span class="o">-&gt;</span>
  <span class="n">t</span>
</code></pre></div>

<p>Fit the model according to the given training data.</p>
<h4>Parameters</h4>
<details class="info" open="open"><summary>X : {array-like, sparse matrix} of shape (n_samples, n_features)</summary><p>Training vector, where n_samples is the number of samples and
n_features is the number of features.</p>
</details>
<details class="info" open="open"><summary>y : array-like of shape (n_samples,)</summary><p>Target vector relative to X.</p>
</details>
<details class="info" open="open"><summary>sample_weight : array-like of shape (n_samples,) default=None</summary><p>Array of weights that are assigned to individual samples.
If not provided, then each sample is given unit weight.</p>
<p>.. versionadded:: 0.17
   <em>sample_weight</em> support to LogisticRegression.</p>
</details>
<h4>Returns</h4>
<p>self
    Fitted estimator.</p>
<h4>Notes</h4>
<p>The SAGA solver supports both float64 and float32 bit arrays.</p>
</details>
<h3 id="get_params_13">get_params<a class="headerlink" href="#get_params_13" title="Permanent link">&para;</a></h3>
<details class="note" open="open"><summary>method</summary><div class="highlight"><pre><span></span><code><span class="k">val</span> <span class="n">get_params</span> <span class="o">:</span>
  <span class="o">?</span><span class="n">deep</span><span class="o">:</span><span class="kt">bool</span> <span class="o">-&gt;</span>
  <span class="n">t</span> <span class="o">-&gt;</span>
  <span class="nn">Dict</span><span class="p">.</span><span class="n">t</span>
</code></pre></div>

<p>Get parameters for this estimator.</p>
<h4>Parameters</h4>
<details class="info" open="open"><summary>deep : bool, default=True</summary><p>If True, will return the parameters for this estimator and
contained subobjects that are estimators.</p>
</details>
<h4>Returns</h4>
<details class="info" open="open"><summary>params : mapping of string to any</summary><p>Parameter names mapped to their values.</p>
</details>
</details>
<h3 id="predict_13">predict<a class="headerlink" href="#predict_13" title="Permanent link">&para;</a></h3>
<details class="note" open="open"><summary>method</summary><div class="highlight"><pre><span></span><code><span class="k">val</span> <span class="n">predict</span> <span class="o">:</span>
  <span class="n">x</span><span class="o">:</span><span class="nn">Arr</span><span class="p">.</span><span class="n">t</span> <span class="o">-&gt;</span>
  <span class="n">t</span> <span class="o">-&gt;</span>
  <span class="nn">Arr</span><span class="p">.</span><span class="n">t</span>
</code></pre></div>

<p>Predict class labels for samples in X.</p>
<h4>Parameters</h4>
<details class="info" open="open"><summary>X : array_like or sparse matrix, shape (n_samples, n_features)</summary><p>Samples.</p>
</details>
<h4>Returns</h4>
<details class="info" open="open"><summary>C : array, shape [n_samples]</summary><p>Predicted class label per sample.</p>
</details>
</details>
<h3 id="predict_log_proba">predict_log_proba<a class="headerlink" href="#predict_log_proba" title="Permanent link">&para;</a></h3>
<details class="note" open="open"><summary>method</summary><div class="highlight"><pre><span></span><code><span class="k">val</span> <span class="n">predict_log_proba</span> <span class="o">:</span>
  <span class="n">x</span><span class="o">:</span><span class="nn">Arr</span><span class="p">.</span><span class="n">t</span> <span class="o">-&gt;</span>
  <span class="n">t</span> <span class="o">-&gt;</span>
  <span class="nn">Arr</span><span class="p">.</span><span class="n">t</span>
</code></pre></div>

<p>Predict logarithm of probability estimates.</p>
<p>The returned estimates for all classes are ordered by the
label of classes.</p>
<h4>Parameters</h4>
<details class="info" open="open"><summary>X : array-like of shape (n_samples, n_features)</summary><p>Vector to be scored, where <code>n_samples</code> is the number of samples and
<code>n_features</code> is the number of features.</p>
</details>
<h4>Returns</h4>
<details class="info" open="open"><summary>T : array-like of shape (n_samples, n_classes)</summary><p>Returns the log-probability of the sample for each class in the
model, where classes are ordered as they are in <code>self.classes_</code>.</p>
</details>
</details>
<h3 id="predict_proba">predict_proba<a class="headerlink" href="#predict_proba" title="Permanent link">&para;</a></h3>
<details class="note" open="open"><summary>method</summary><div class="highlight"><pre><span></span><code><span class="k">val</span> <span class="n">predict_proba</span> <span class="o">:</span>
  <span class="n">x</span><span class="o">:</span><span class="nn">Arr</span><span class="p">.</span><span class="n">t</span> <span class="o">-&gt;</span>
  <span class="n">t</span> <span class="o">-&gt;</span>
  <span class="nn">Arr</span><span class="p">.</span><span class="n">t</span>
</code></pre></div>

<p>Probability estimates.</p>
<p>The returned estimates for all classes are ordered by the
label of classes.</p>
<p>For a multi_class problem, if multi_class is set to be "multinomial"
the softmax function is used to find the predicted probability of
each class.
Else use a one-vs-rest approach, i.e calculate the probability
of each class assuming it to be positive using the logistic function.
and normalize these values across all the classes.</p>
<h4>Parameters</h4>
<details class="info" open="open"><summary>X : array-like of shape (n_samples, n_features)</summary><p>Vector to be scored, where <code>n_samples</code> is the number of samples and
<code>n_features</code> is the number of features.</p>
</details>
<h4>Returns</h4>
<details class="info" open="open"><summary>T : array-like of shape (n_samples, n_classes)</summary><p>Returns the probability of the sample for each class in the model,
where classes are ordered as they are in <code>self.classes_</code>.</p>
</details>
</details>
<h3 id="score_13">score<a class="headerlink" href="#score_13" title="Permanent link">&para;</a></h3>
<details class="note" open="open"><summary>method</summary><div class="highlight"><pre><span></span><code><span class="k">val</span> <span class="n">score</span> <span class="o">:</span>
  <span class="o">?</span><span class="n">sample_weight</span><span class="o">:</span><span class="nn">Arr</span><span class="p">.</span><span class="n">t</span> <span class="o">-&gt;</span>
  <span class="n">x</span><span class="o">:</span><span class="nn">Arr</span><span class="p">.</span><span class="n">t</span> <span class="o">-&gt;</span>
  <span class="n">y</span><span class="o">:</span><span class="nn">Arr</span><span class="p">.</span><span class="n">t</span> <span class="o">-&gt;</span>
  <span class="n">t</span> <span class="o">-&gt;</span>
  <span class="kt">float</span>
</code></pre></div>

<p>Return the mean accuracy on the given test data and labels.</p>
<p>In multi-label classification, this is the subset accuracy
which is a harsh metric since you require for each sample that
each label set be correctly predicted.</p>
<h4>Parameters</h4>
<details class="info" open="open"><summary>X : array-like of shape (n_samples, n_features)</summary><p>Test samples.</p>
</details>
<details class="info" open="open"><summary>y : array-like of shape (n_samples,) or (n_samples, n_outputs)</summary><p>True labels for X.</p>
</details>
<details class="info" open="open"><summary>sample_weight : array-like of shape (n_samples,), default=None</summary><p>Sample weights.</p>
</details>
<h4>Returns</h4>
<details class="info" open="open"><summary>score : float</summary><p>Mean accuracy of self.predict(X) wrt. y.</p>
</details>
</details>
<h3 id="set_params_13">set_params<a class="headerlink" href="#set_params_13" title="Permanent link">&para;</a></h3>
<details class="note" open="open"><summary>method</summary><div class="highlight"><pre><span></span><code><span class="k">val</span> <span class="n">set_params</span> <span class="o">:</span>
  <span class="o">?</span><span class="n">params</span><span class="o">:(</span><span class="kt">string</span> <span class="o">*</span> <span class="nn">Py</span><span class="p">.</span><span class="nn">Object</span><span class="p">.</span><span class="n">t</span><span class="o">)</span> <span class="kt">list</span> <span class="o">-&gt;</span>
  <span class="n">t</span> <span class="o">-&gt;</span>
  <span class="n">t</span>
</code></pre></div>

<p>Set the parameters of this estimator.</p>
<p>The method works on simple estimators as well as on nested objects
(such as pipelines). The latter have parameters of the form
<code>&lt;component&gt;__&lt;parameter&gt;</code> so that it's possible to update each
component of a nested object.</p>
<h4>Parameters</h4>
<details class="info" open="open"><summary>**params : dict</summary><p>Estimator parameters.</p>
</details>
<h4>Returns</h4>
<details class="info" open="open"><summary>self : object</summary><p>Estimator instance.</p>
</details>
</details>
<h3 id="sparsify">sparsify<a class="headerlink" href="#sparsify" title="Permanent link">&para;</a></h3>
<details class="note" open="open"><summary>method</summary><div class="highlight"><pre><span></span><code><span class="k">val</span> <span class="n">sparsify</span> <span class="o">:</span>
  <span class="n">t</span> <span class="o">-&gt;</span>
  <span class="n">t</span>
</code></pre></div>

<p>Convert coefficient matrix to sparse format.</p>
<p>Converts the <code>coef_</code> member to a scipy.sparse matrix, which for
L1-regularized models can be much more memory- and storage-efficient
than the usual numpy.ndarray representation.</p>
<p>The <code>intercept_</code> member is not converted.</p>
<h4>Returns</h4>
<p>self
    Fitted estimator.</p>
<h4>Notes</h4>
<p>For non-sparse models, i.e. when there are not many zeros in <code>coef_</code>,
this may actually <em>increase</em> memory usage, so use this method with
care. A rule of thumb is that the number of zero elements, which can
be computed with <code>(coef_ == 0).sum()</code>, must be more than 50% for this
to provide significant benefits.</p>
<p>After calling this method, further fitting with the partial_fit
method (if any) will not work until you call densify.</p>
</details>
<h3 id="classes_">classes_<a class="headerlink" href="#classes_" title="Permanent link">&para;</a></h3>
<details class="note" open="open"><summary>attribute</summary><div class="highlight"><pre><span></span><code><span class="k">val</span> <span class="n">classes_</span> <span class="o">:</span> <span class="n">t</span> <span class="o">-&gt;</span> <span class="nn">Arr</span><span class="p">.</span><span class="n">t</span>
<span class="k">val</span> <span class="n">classes_opt</span> <span class="o">:</span> <span class="n">t</span> <span class="o">-&gt;</span> <span class="o">(</span><span class="nn">Arr</span><span class="p">.</span><span class="n">t</span><span class="o">)</span> <span class="n">option</span>
</code></pre></div>

<p>This attribute is documented in <code>create</code> above. The first version raises Not_found
if the attribute is None. The _opt version returns an option.</p>
</details>
<h3 id="coef__13">coef_<a class="headerlink" href="#coef__13" title="Permanent link">&para;</a></h3>
<details class="note" open="open"><summary>attribute</summary><div class="highlight"><pre><span></span><code><span class="k">val</span> <span class="n">coef_</span> <span class="o">:</span> <span class="n">t</span> <span class="o">-&gt;</span> <span class="nn">Arr</span><span class="p">.</span><span class="n">t</span>
<span class="k">val</span> <span class="n">coef_opt</span> <span class="o">:</span> <span class="n">t</span> <span class="o">-&gt;</span> <span class="o">(</span><span class="nn">Arr</span><span class="p">.</span><span class="n">t</span><span class="o">)</span> <span class="n">option</span>
</code></pre></div>

<p>This attribute is documented in <code>create</code> above. The first version raises Not_found
if the attribute is None. The _opt version returns an option.</p>
</details>
<h3 id="intercept__13">intercept_<a class="headerlink" href="#intercept__13" title="Permanent link">&para;</a></h3>
<details class="note" open="open"><summary>attribute</summary><div class="highlight"><pre><span></span><code><span class="k">val</span> <span class="n">intercept_</span> <span class="o">:</span> <span class="n">t</span> <span class="o">-&gt;</span> <span class="nn">Arr</span><span class="p">.</span><span class="n">t</span>
<span class="k">val</span> <span class="n">intercept_opt</span> <span class="o">:</span> <span class="n">t</span> <span class="o">-&gt;</span> <span class="o">(</span><span class="nn">Arr</span><span class="p">.</span><span class="n">t</span><span class="o">)</span> <span class="n">option</span>
</code></pre></div>

<p>This attribute is documented in <code>create</code> above. The first version raises Not_found
if the attribute is None. The _opt version returns an option.</p>
</details>
<h3 id="n_iter__11">n_iter_<a class="headerlink" href="#n_iter__11" title="Permanent link">&para;</a></h3>
<details class="note" open="open"><summary>attribute</summary><div class="highlight"><pre><span></span><code><span class="k">val</span> <span class="n">n_iter_</span> <span class="o">:</span> <span class="n">t</span> <span class="o">-&gt;</span> <span class="nn">Arr</span><span class="p">.</span><span class="n">t</span>
<span class="k">val</span> <span class="n">n_iter_opt</span> <span class="o">:</span> <span class="n">t</span> <span class="o">-&gt;</span> <span class="o">(</span><span class="nn">Arr</span><span class="p">.</span><span class="n">t</span><span class="o">)</span> <span class="n">option</span>
</code></pre></div>

<p>This attribute is documented in <code>create</code> above. The first version raises Not_found
if the attribute is None. The _opt version returns an option.</p>
</details>
<h3 id="to_string_13">to_string<a class="headerlink" href="#to_string_13" title="Permanent link">&para;</a></h3>
<details class="note" open="open"><summary>method</summary><div class="highlight"><pre><span></span><code><span class="k">val</span> <span class="n">to_string</span><span class="o">:</span> <span class="n">t</span> <span class="o">-&gt;</span> <span class="kt">string</span>
</code></pre></div>

<p>Print the object to a human-readable representation.</p>
</details>
<h3 id="show_13">show<a class="headerlink" href="#show_13" title="Permanent link">&para;</a></h3>
<details class="note" open="open"><summary>method</summary><div class="highlight"><pre><span></span><code><span class="k">val</span> <span class="n">show</span><span class="o">:</span> <span class="n">t</span> <span class="o">-&gt;</span> <span class="kt">string</span>
</code></pre></div>

<p>Print the object to a human-readable representation.</p>
</details>
<h3 id="pp_13">pp<a class="headerlink" href="#pp_13" title="Permanent link">&para;</a></h3>
<details class="note" open="open"><summary>method</summary><div class="highlight"><pre><span></span><code><span class="k">val</span> <span class="n">pp</span><span class="o">:</span> <span class="nn">Format</span><span class="p">.</span><span class="n">formatter</span> <span class="o">-&gt;</span> <span class="n">t</span> <span class="o">-&gt;</span> <span class="kt">unit</span>
</code></pre></div>

<p>Pretty-print the object to a formatter.</p>
</details>
<h2 id="module-sklearnlinear_modellogisticregressioncv">module Sklearn.​Linear_model.​LogisticRegressionCV<a class="headerlink" href="#module-sklearnlinear_modellogisticregressioncv" title="Permanent link">&para;</a></h2>
<div class="highlight"><pre><span></span><code><span class="k">type</span> <span class="n">t</span>
</code></pre></div>

<h3 id="create_14">create<a class="headerlink" href="#create_14" title="Permanent link">&para;</a></h3>
<details class="note" open="open"><summary>constructor and attributes</summary><div class="highlight"><pre><span></span><code><span class="k">val</span> <span class="n">create</span> <span class="o">:</span>
  <span class="o">?</span><span class="n">cs</span><span class="o">:[`</span><span class="nc">I</span> <span class="k">of</span> <span class="kt">int</span> <span class="o">|</span> <span class="o">`</span><span class="nc">FloatList</span> <span class="k">of</span> <span class="kt">float</span> <span class="kt">list</span><span class="o">]</span> <span class="o">-&gt;</span>
  <span class="o">?</span><span class="n">fit_intercept</span><span class="o">:</span><span class="kt">bool</span> <span class="o">-&gt;</span>
  <span class="o">?</span><span class="n">cv</span><span class="o">:[`</span><span class="nc">I</span> <span class="k">of</span> <span class="kt">int</span> <span class="o">|</span> <span class="o">`</span><span class="nc">CrossValGenerator</span> <span class="k">of</span> <span class="nn">Py</span><span class="p">.</span><span class="nn">Object</span><span class="p">.</span><span class="n">t</span><span class="o">]</span> <span class="o">-&gt;</span>
  <span class="o">?</span><span class="n">dual</span><span class="o">:</span><span class="kt">bool</span> <span class="o">-&gt;</span>
  <span class="o">?</span><span class="n">penalty</span><span class="o">:[`</span><span class="nc">L1</span> <span class="o">|</span> <span class="o">`</span><span class="nc">L2</span> <span class="o">|</span> <span class="o">`</span><span class="nc">Elasticnet</span><span class="o">]</span> <span class="o">-&gt;</span>
  <span class="o">?</span><span class="n">scoring</span><span class="o">:[`</span><span class="nc">S</span> <span class="k">of</span> <span class="kt">string</span> <span class="o">|</span> <span class="o">`</span><span class="nc">Callable</span> <span class="k">of</span> <span class="nn">Py</span><span class="p">.</span><span class="nn">Object</span><span class="p">.</span><span class="n">t</span><span class="o">]</span> <span class="o">-&gt;</span>
  <span class="o">?</span><span class="n">solver</span><span class="o">:[`</span><span class="nc">Newton_cg</span> <span class="o">|</span> <span class="o">`</span><span class="nc">Lbfgs</span> <span class="o">|</span> <span class="o">`</span><span class="nc">Liblinear</span> <span class="o">|</span> <span class="o">`</span><span class="nc">Sag</span> <span class="o">|</span> <span class="o">`</span><span class="nc">Saga</span><span class="o">]</span> <span class="o">-&gt;</span>
  <span class="o">?</span><span class="n">tol</span><span class="o">:</span><span class="kt">float</span> <span class="o">-&gt;</span>
  <span class="o">?</span><span class="n">max_iter</span><span class="o">:</span><span class="kt">int</span> <span class="o">-&gt;</span>
  <span class="o">?</span><span class="n">class_weight</span><span class="o">:[`</span><span class="nc">DictIntToFloat</span> <span class="k">of</span> <span class="o">(</span><span class="kt">int</span> <span class="o">*</span> <span class="kt">float</span><span class="o">)</span> <span class="kt">list</span> <span class="o">|</span> <span class="o">`</span><span class="nc">Balanced</span><span class="o">]</span> <span class="o">-&gt;</span>
  <span class="o">?</span><span class="n">n_jobs</span><span class="o">:</span><span class="kt">int</span> <span class="o">-&gt;</span>
  <span class="o">?</span><span class="n">verbose</span><span class="o">:</span><span class="kt">int</span> <span class="o">-&gt;</span>
  <span class="o">?</span><span class="n">refit</span><span class="o">:</span><span class="kt">bool</span> <span class="o">-&gt;</span>
  <span class="o">?</span><span class="n">intercept_scaling</span><span class="o">:</span><span class="kt">float</span> <span class="o">-&gt;</span>
  <span class="o">?</span><span class="n">multi_class</span><span class="o">:[`</span><span class="nc">T_auto</span> <span class="k">of</span> <span class="nn">Py</span><span class="p">.</span><span class="nn">Object</span><span class="p">.</span><span class="n">t</span> <span class="o">|</span> <span class="o">`</span><span class="nc">Ovr</span> <span class="o">|</span> <span class="o">`</span><span class="nc">Multinomial</span><span class="o">]</span> <span class="o">-&gt;</span>
  <span class="o">?</span><span class="n">random_state</span><span class="o">:</span><span class="kt">int</span> <span class="o">-&gt;</span>
  <span class="o">?</span><span class="n">l1_ratios</span><span class="o">:</span><span class="nn">Py</span><span class="p">.</span><span class="nn">Object</span><span class="p">.</span><span class="n">t</span> <span class="o">-&gt;</span>
  <span class="kt">unit</span> <span class="o">-&gt;</span>
  <span class="n">t</span>
</code></pre></div>

<p>Logistic Regression CV (aka logit, MaxEnt) classifier.</p>
<p>See glossary entry for :term:<code>cross-validation estimator</code>.</p>
<p>This class implements logistic regression using liblinear, newton-cg, sag
of lbfgs optimizer. The newton-cg, sag and lbfgs solvers support only L2
regularization with primal formulation. The liblinear solver supports both
L1 and L2 regularization, with a dual formulation only for the L2 penalty.
Elastic-Net penalty is only supported by the saga solver.</p>
<p>For the grid of <code>Cs</code> values and <code>l1_ratios</code> values, the best hyperparameter
is selected by the cross-validator
:class:<code>~sklearn.model_selection.StratifiedKFold</code>, but it can be changed
using the :term:<code>cv</code> parameter. The 'newton-cg', 'sag', 'saga' and 'lbfgs'
solvers can warm-start the coefficients (see :term:<code>Glossary&lt;warm_start&gt;</code>).</p>
<p>Read more in the :ref:<code>User Guide &lt;logistic_regression&gt;</code>.</p>
<h4>Parameters</h4>
<details class="info" open="open"><summary>Cs : int or list of floats, default=10</summary><p>Each of the values in Cs describes the inverse of regularization
strength. If Cs is as an int, then a grid of Cs values are chosen
in a logarithmic scale between 1e-4 and 1e4.
Like in support vector machines, smaller values specify stronger
regularization.</p>
</details>
<details class="info" open="open"><summary>fit_intercept : bool, default=True</summary><p>Specifies if a constant (a.k.a. bias or intercept) should be
added to the decision function.</p>
</details>
<details class="info" open="open"><summary>cv : int or cross-validation generator, default=None</summary><p>The default cross-validation generator used is Stratified K-Folds.
If an integer is provided, then it is the number of folds used.
See the module :mod:<code>sklearn.model_selection</code> module for the
list of possible cross-validation objects.</p>
<p>.. versionchanged:: 0.22
    <code>cv</code> default value if None changed from 3-fold to 5-fold.</p>
</details>
<details class="info" open="open"><summary>dual : bool, default=False</summary><p>Dual or primal formulation. Dual formulation is only implemented for
l2 penalty with liblinear solver. Prefer dual=False when
n_samples &gt; n_features.</p>
</details>
<details class="info" open="open"><summary>penalty : {'l1', 'l2', 'elasticnet'}, default='l2'</summary><p>Used to specify the norm used in the penalization. The 'newton-cg',
'sag' and 'lbfgs' solvers support only l2 penalties. 'elasticnet' is
only supported by the 'saga' solver.</p>
</details>
<details class="info" open="open"><summary>scoring : str or callable, default=None</summary><p>A string (see model evaluation documentation) or
a scorer callable object / function with signature
<code>scorer(estimator, X, y)</code>. For a list of scoring functions
that can be used, look at :mod:<code>sklearn.metrics</code>. The
default scoring option used is 'accuracy'.</p>
</details>
<details class="info" open="open"><summary>solver : {'newton-cg', 'lbfgs', 'liblinear', 'sag', 'saga'},             default='lbfgs'</summary><p>Algorithm to use in the optimization problem.</p>
<ul>
<li>For small datasets, 'liblinear' is a good choice, whereas 'sag' and
  'saga' are faster for large ones.</li>
<li>For multiclass problems, only 'newton-cg', 'sag', 'saga' and 'lbfgs'
  handle multinomial loss; 'liblinear' is limited to one-versus-rest
  schemes.</li>
<li>'newton-cg', 'lbfgs' and 'sag' only handle L2 penalty, whereas
  'liblinear' and 'saga' handle L1 penalty.</li>
<li>'liblinear' might be slower in LogisticRegressionCV because it does
  not handle warm-starting.</li>
</ul>
<p>Note that 'sag' and 'saga' fast convergence is only guaranteed on
features with approximately the same scale. You can preprocess the data
with a scaler from sklearn.preprocessing.</p>
<p>.. versionadded:: 0.17
   Stochastic Average Gradient descent solver.
.. versionadded:: 0.19
   SAGA solver.</p>
</details>
<details class="info" open="open"><summary>tol : float, default=1e-4</summary><p>Tolerance for stopping criteria.</p>
</details>
<details class="info" open="open"><summary>max_iter : int, default=100</summary><p>Maximum number of iterations of the optimization algorithm.</p>
</details>
<details class="info" open="open"><summary>class_weight : dict or 'balanced', default=None</summary><p>Weights associated with classes in the form <code>{class_label: weight}</code>.
If not given, all classes are supposed to have weight one.</p>
<p>The "balanced" mode uses the values of y to automatically adjust
weights inversely proportional to class frequencies in the input data
as <code>n_samples / (n_classes * np.bincount(y))</code>.</p>
<p>Note that these weights will be multiplied with sample_weight (passed
through the fit method) if sample_weight is specified.</p>
<p>.. versionadded:: 0.17
   class_weight == 'balanced'</p>
</details>
<details class="info" open="open"><summary>n_jobs : int, default=None</summary><p>Number of CPU cores used during the cross-validation loop.
<code>None</code> means 1 unless in a :obj:<code>joblib.parallel_backend</code> context.
<code>-1</code> means using all processors. See :term:<code>Glossary &lt;n_jobs&gt;</code>
for more details.</p>
</details>
<details class="info" open="open"><summary>verbose : int, default=0</summary><p>For the 'liblinear', 'sag' and 'lbfgs' solvers set verbose to any
positive number for verbosity.</p>
</details>
<details class="info" open="open"><summary>refit : bool, default=True</summary><p>If set to True, the scores are averaged across all folds, and the
coefs and the C that corresponds to the best score is taken, and a
final refit is done using these parameters.
Otherwise the coefs, intercepts and C that correspond to the
best scores across folds are averaged.</p>
</details>
<details class="info" open="open"><summary>intercept_scaling : float, default=1</summary><p>Useful only when the solver 'liblinear' is used
and self.fit_intercept is set to True. In this case, x becomes
[x, self.intercept_scaling],
i.e. a "synthetic" feature with constant value equal to
intercept_scaling is appended to the instance vector.
The intercept becomes <code>intercept_scaling * synthetic_feature_weight</code>.</p>
<p>Note! the synthetic feature weight is subject to l1/l2 regularization
as all other features.
To lessen the effect of regularization on synthetic feature weight
(and therefore on the intercept) intercept_scaling has to be increased.</p>
</details>
<details class="info" open="open"><summary>multi_class : {'auto, 'ovr', 'multinomial'}, default='auto'</summary><p>If the option chosen is 'ovr', then a binary problem is fit for each
label. For 'multinomial' the loss minimised is the multinomial loss fit
across the entire probability distribution, <em>even when the data is
binary</em>. 'multinomial' is unavailable when solver='liblinear'.
'auto' selects 'ovr' if the data is binary, or if solver='liblinear',
and otherwise selects 'multinomial'.</p>
<p>.. versionadded:: 0.18
   Stochastic Average Gradient descent solver for 'multinomial' case.
.. versionchanged:: 0.22
    Default changed from 'ovr' to 'auto' in 0.22.</p>
</details>
<details class="info" open="open"><summary>random_state : int, RandomState instance, default=None</summary><p>If int, random_state is the seed used by the random number generator;
If RandomState instance, random_state is the random number generator;
If None, the random number generator is the RandomState instance used
by <code>np.random</code>. Used when <code>solver='sag'</code> or <code>solver='liblinear'</code>.
Note that this only applies to the solver and not the cross-validation
generator.</p>
</details>
<details class="info" open="open"><summary>l1_ratios : list of float, default=None</summary><p>The list of Elastic-Net mixing parameter, with <code>0 &lt;= l1_ratio &lt;= 1</code>.
Only used if <code>penalty='elasticnet'</code>. A value of 0 is equivalent to
using <code>penalty='l2'</code>, while 1 is equivalent to using
<code>penalty='l1'</code>. For <code>0 &lt; l1_ratio &lt;1</code>, the penalty is a combination
of L1 and L2.</p>
</details>
<h4>Attributes</h4>
<details class="info" open="open"><summary>classes_ : ndarray of shape (n_classes, )</summary><p>A list of class labels known to the classifier.</p>
</details>
<details class="info" open="open"><summary>coef_ : ndarray of shape (1, n_features) or (n_classes, n_features)</summary><p>Coefficient of the features in the decision function.</p>
<p><code>coef_</code> is of shape (1, n_features) when the given problem
is binary.</p>
</details>
<details class="info" open="open"><summary>intercept_ : ndarray of shape (1,) or (n_classes,)</summary><p>Intercept (a.k.a. bias) added to the decision function.</p>
<p>If <code>fit_intercept</code> is set to False, the intercept is set to zero.
<code>intercept_</code> is of shape(1,) when the problem is binary.</p>
</details>
<details class="info" open="open"><summary>Cs_ : ndarray of shape (n_cs)</summary><p>Array of C i.e. inverse of regularization parameter values used
for cross-validation.</p>
</details>
<details class="info" open="open"><summary>l1_ratios_ : ndarray of shape (n_l1_ratios)</summary><p>Array of l1_ratios used for cross-validation. If no l1_ratio is used
(i.e. penalty is not 'elasticnet'), this is set to <code>[None]</code></p>
</details>
<details class="info" open="open"><summary>coefs_paths_ : ndarray of shape (n_folds, n_cs, n_features) or                    (n_folds, n_cs, n_features + 1)</summary><p>dict with classes as the keys, and the path of coefficients obtained
during cross-validating across each fold and then across each Cs
after doing an OvR for the corresponding class as values.
If the 'multi_class' option is set to 'multinomial', then
the coefs_paths are the coefficients corresponding to each class.
Each dict value has shape <code>(n_folds, n_cs, n_features)</code> or
<code>(n_folds, n_cs, n_features + 1)</code> depending on whether the
intercept is fit or not. If <code>penalty='elasticnet'</code>, the shape is
<code>(n_folds, n_cs, n_l1_ratios_, n_features)</code> or
<code>(n_folds, n_cs, n_l1_ratios_, n_features + 1)</code>.</p>
</details>
<details class="info" open="open"><summary>scores_ : dict</summary><p>dict with classes as the keys, and the values as the
grid of scores obtained during cross-validating each fold, after doing
an OvR for the corresponding class. If the 'multi_class' option
given is 'multinomial' then the same scores are repeated across
all classes, since this is the multinomial class. Each dict value
has shape <code>(n_folds, n_cs</code> or <code>(n_folds, n_cs, n_l1_ratios)</code> if
<code>penalty='elasticnet'</code>.</p>
</details>
<details class="info" open="open"><summary>C_ : ndarray of shape (n_classes,) or (n_classes - 1,)</summary><p>Array of C that maps to the best scores across every class. If refit is
set to False, then for each class, the best C is the average of the
C's that correspond to the best scores for each fold.
<code>C_</code> is of shape(n_classes,) when the problem is binary.</p>
</details>
<details class="info" open="open"><summary>l1_ratio_ : ndarray of shape (n_classes,) or (n_classes - 1,)</summary><p>Array of l1_ratio that maps to the best scores across every class. If
refit is set to False, then for each class, the best l1_ratio is the
average of the l1_ratio's that correspond to the best scores for each
fold.  <code>l1_ratio_</code> is of shape(n_classes,) when the problem is binary.</p>
</details>
<details class="info" open="open"><summary>n_iter_ : ndarray of shape (n_classes, n_folds, n_cs) or (1, n_folds, n_cs)</summary><p>Actual number of iterations for all classes, folds and Cs.
In the binary or multinomial cases, the first dimension is equal to 1.
If <code>penalty='elasticnet'</code>, the shape is <code>(n_classes, n_folds,
n_cs, n_l1_ratios)</code> or <code>(1, n_folds, n_cs, n_l1_ratios)</code>.</p>
</details>
<h4>Examples</h4>
<div class="highlight"><pre><span></span><code><span class="o">&gt;&gt;&gt;</span> <span class="kn">from</span> <span class="nn">sklearn.datasets</span> <span class="kn">import</span> <span class="n">load_iris</span>
<span class="o">&gt;&gt;&gt;</span> <span class="kn">from</span> <span class="nn">sklearn.linear_model</span> <span class="kn">import</span> <span class="n">LogisticRegressionCV</span>
<span class="o">&gt;&gt;&gt;</span> <span class="n">X</span><span class="p">,</span> <span class="n">y</span> <span class="o">=</span> <span class="n">load_iris</span><span class="p">(</span><span class="n">return_X_y</span><span class="o">=</span><span class="kc">True</span><span class="p">)</span>
<span class="o">&gt;&gt;&gt;</span> <span class="n">clf</span> <span class="o">=</span> <span class="n">LogisticRegressionCV</span><span class="p">(</span><span class="n">cv</span><span class="o">=</span><span class="mi">5</span><span class="p">,</span> <span class="n">random_state</span><span class="o">=</span><span class="mi">0</span><span class="p">)</span><span class="o">.</span><span class="n">fit</span><span class="p">(</span><span class="n">X</span><span class="p">,</span> <span class="n">y</span><span class="p">)</span>
<span class="o">&gt;&gt;&gt;</span> <span class="n">clf</span><span class="o">.</span><span class="n">predict</span><span class="p">(</span><span class="n">X</span><span class="p">[:</span><span class="mi">2</span><span class="p">,</span> <span class="p">:])</span>
<span class="n">array</span><span class="p">([</span><span class="mi">0</span><span class="p">,</span> <span class="mi">0</span><span class="p">])</span>
<span class="o">&gt;&gt;&gt;</span> <span class="n">clf</span><span class="o">.</span><span class="n">predict_proba</span><span class="p">(</span><span class="n">X</span><span class="p">[:</span><span class="mi">2</span><span class="p">,</span> <span class="p">:])</span><span class="o">.</span><span class="n">shape</span>
<span class="p">(</span><span class="mi">2</span><span class="p">,</span> <span class="mi">3</span><span class="p">)</span>
<span class="o">&gt;&gt;&gt;</span> <span class="n">clf</span><span class="o">.</span><span class="n">score</span><span class="p">(</span><span class="n">X</span><span class="p">,</span> <span class="n">y</span><span class="p">)</span>
<span class="mf">0.98</span><span class="o">...</span>
</code></pre></div>

<h4>See also</h4>
<p>LogisticRegression</p>
</details>
<h3 id="decision_function_1">decision_function<a class="headerlink" href="#decision_function_1" title="Permanent link">&para;</a></h3>
<details class="note" open="open"><summary>method</summary><div class="highlight"><pre><span></span><code><span class="k">val</span> <span class="n">decision_function</span> <span class="o">:</span>
  <span class="n">x</span><span class="o">:</span><span class="nn">Arr</span><span class="p">.</span><span class="n">t</span> <span class="o">-&gt;</span>
  <span class="n">t</span> <span class="o">-&gt;</span>
  <span class="nn">Arr</span><span class="p">.</span><span class="n">t</span>
</code></pre></div>

<p>Predict confidence scores for samples.</p>
<p>The confidence score for a sample is the signed distance of that
sample to the hyperplane.</p>
<h4>Parameters</h4>
<details class="info" open="open"><summary>X : array_like or sparse matrix, shape (n_samples, n_features)</summary><p>Samples.</p>
</details>
<h4>Returns</h4>
<p>array, shape=(n_samples,) if n_classes == 2 else (n_samples, n_classes)
    Confidence scores per (sample, class) combination. In the binary
    case, confidence score for self.classes_[1] where &gt;0 means this
    class would be predicted.</p>
</details>
<h3 id="densify_1">densify<a class="headerlink" href="#densify_1" title="Permanent link">&para;</a></h3>
<details class="note" open="open"><summary>method</summary><div class="highlight"><pre><span></span><code><span class="k">val</span> <span class="n">densify</span> <span class="o">:</span>
  <span class="n">t</span> <span class="o">-&gt;</span>
  <span class="n">t</span>
</code></pre></div>

<p>Convert coefficient matrix to dense array format.</p>
<p>Converts the <code>coef_</code> member (back) to a numpy.ndarray. This is the
default format of <code>coef_</code> and is required for fitting, so calling
this method is only required on models that have previously been
sparsified; otherwise, it is a no-op.</p>
<h4>Returns</h4>
<p>self
    Fitted estimator.</p>
</details>
<h3 id="fit_14">fit<a class="headerlink" href="#fit_14" title="Permanent link">&para;</a></h3>
<details class="note" open="open"><summary>method</summary><div class="highlight"><pre><span></span><code><span class="k">val</span> <span class="n">fit</span> <span class="o">:</span>
  <span class="o">?</span><span class="n">sample_weight</span><span class="o">:</span><span class="nn">Arr</span><span class="p">.</span><span class="n">t</span> <span class="o">-&gt;</span>
  <span class="n">x</span><span class="o">:</span><span class="nn">Arr</span><span class="p">.</span><span class="n">t</span> <span class="o">-&gt;</span>
  <span class="n">y</span><span class="o">:</span><span class="nn">Arr</span><span class="p">.</span><span class="n">t</span> <span class="o">-&gt;</span>
  <span class="n">t</span> <span class="o">-&gt;</span>
  <span class="n">t</span>
</code></pre></div>

<p>Fit the model according to the given training data.</p>
<h4>Parameters</h4>
<details class="info" open="open"><summary>X : {array-like, sparse matrix} of shape (n_samples, n_features)</summary><p>Training vector, where n_samples is the number of samples and
n_features is the number of features.</p>
</details>
<details class="info" open="open"><summary>y : array-like of shape (n_samples,)</summary><p>Target vector relative to X.</p>
</details>
<details class="info" open="open"><summary>sample_weight : array-like of shape (n_samples,) default=None</summary><p>Array of weights that are assigned to individual samples.
If not provided, then each sample is given unit weight.</p>
</details>
<h4>Returns</h4>
<details class="info" open="open"><summary>self : object</summary></details>
</details>
<h3 id="get_params_14">get_params<a class="headerlink" href="#get_params_14" title="Permanent link">&para;</a></h3>
<details class="note" open="open"><summary>method</summary><div class="highlight"><pre><span></span><code><span class="k">val</span> <span class="n">get_params</span> <span class="o">:</span>
  <span class="o">?</span><span class="n">deep</span><span class="o">:</span><span class="kt">bool</span> <span class="o">-&gt;</span>
  <span class="n">t</span> <span class="o">-&gt;</span>
  <span class="nn">Dict</span><span class="p">.</span><span class="n">t</span>
</code></pre></div>

<p>Get parameters for this estimator.</p>
<h4>Parameters</h4>
<details class="info" open="open"><summary>deep : bool, default=True</summary><p>If True, will return the parameters for this estimator and
contained subobjects that are estimators.</p>
</details>
<h4>Returns</h4>
<details class="info" open="open"><summary>params : mapping of string to any</summary><p>Parameter names mapped to their values.</p>
</details>
</details>
<h3 id="predict_14">predict<a class="headerlink" href="#predict_14" title="Permanent link">&para;</a></h3>
<details class="note" open="open"><summary>method</summary><div class="highlight"><pre><span></span><code><span class="k">val</span> <span class="n">predict</span> <span class="o">:</span>
  <span class="n">x</span><span class="o">:</span><span class="nn">Arr</span><span class="p">.</span><span class="n">t</span> <span class="o">-&gt;</span>
  <span class="n">t</span> <span class="o">-&gt;</span>
  <span class="nn">Arr</span><span class="p">.</span><span class="n">t</span>
</code></pre></div>

<p>Predict class labels for samples in X.</p>
<h4>Parameters</h4>
<details class="info" open="open"><summary>X : array_like or sparse matrix, shape (n_samples, n_features)</summary><p>Samples.</p>
</details>
<h4>Returns</h4>
<details class="info" open="open"><summary>C : array, shape [n_samples]</summary><p>Predicted class label per sample.</p>
</details>
</details>
<h3 id="predict_log_proba_1">predict_log_proba<a class="headerlink" href="#predict_log_proba_1" title="Permanent link">&para;</a></h3>
<details class="note" open="open"><summary>method</summary><div class="highlight"><pre><span></span><code><span class="k">val</span> <span class="n">predict_log_proba</span> <span class="o">:</span>
  <span class="n">x</span><span class="o">:</span><span class="nn">Arr</span><span class="p">.</span><span class="n">t</span> <span class="o">-&gt;</span>
  <span class="n">t</span> <span class="o">-&gt;</span>
  <span class="nn">Arr</span><span class="p">.</span><span class="n">t</span>
</code></pre></div>

<p>Predict logarithm of probability estimates.</p>
<p>The returned estimates for all classes are ordered by the
label of classes.</p>
<h4>Parameters</h4>
<details class="info" open="open"><summary>X : array-like of shape (n_samples, n_features)</summary><p>Vector to be scored, where <code>n_samples</code> is the number of samples and
<code>n_features</code> is the number of features.</p>
</details>
<h4>Returns</h4>
<details class="info" open="open"><summary>T : array-like of shape (n_samples, n_classes)</summary><p>Returns the log-probability of the sample for each class in the
model, where classes are ordered as they are in <code>self.classes_</code>.</p>
</details>
</details>
<h3 id="predict_proba_1">predict_proba<a class="headerlink" href="#predict_proba_1" title="Permanent link">&para;</a></h3>
<details class="note" open="open"><summary>method</summary><div class="highlight"><pre><span></span><code><span class="k">val</span> <span class="n">predict_proba</span> <span class="o">:</span>
  <span class="n">x</span><span class="o">:</span><span class="nn">Arr</span><span class="p">.</span><span class="n">t</span> <span class="o">-&gt;</span>
  <span class="n">t</span> <span class="o">-&gt;</span>
  <span class="nn">Arr</span><span class="p">.</span><span class="n">t</span>
</code></pre></div>

<p>Probability estimates.</p>
<p>The returned estimates for all classes are ordered by the
label of classes.</p>
<p>For a multi_class problem, if multi_class is set to be "multinomial"
the softmax function is used to find the predicted probability of
each class.
Else use a one-vs-rest approach, i.e calculate the probability
of each class assuming it to be positive using the logistic function.
and normalize these values across all the classes.</p>
<h4>Parameters</h4>
<details class="info" open="open"><summary>X : array-like of shape (n_samples, n_features)</summary><p>Vector to be scored, where <code>n_samples</code> is the number of samples and
<code>n_features</code> is the number of features.</p>
</details>
<h4>Returns</h4>
<details class="info" open="open"><summary>T : array-like of shape (n_samples, n_classes)</summary><p>Returns the probability of the sample for each class in the model,
where classes are ordered as they are in <code>self.classes_</code>.</p>
</details>
</details>
<h3 id="score_14">score<a class="headerlink" href="#score_14" title="Permanent link">&para;</a></h3>
<details class="note" open="open"><summary>method</summary><div class="highlight"><pre><span></span><code><span class="k">val</span> <span class="n">score</span> <span class="o">:</span>
  <span class="o">?</span><span class="n">sample_weight</span><span class="o">:</span><span class="nn">Arr</span><span class="p">.</span><span class="n">t</span> <span class="o">-&gt;</span>
  <span class="n">x</span><span class="o">:</span><span class="nn">Arr</span><span class="p">.</span><span class="n">t</span> <span class="o">-&gt;</span>
  <span class="n">y</span><span class="o">:</span><span class="nn">Arr</span><span class="p">.</span><span class="n">t</span> <span class="o">-&gt;</span>
  <span class="n">t</span> <span class="o">-&gt;</span>
  <span class="kt">float</span>
</code></pre></div>

<p>Returns the score using the <code>scoring</code> option on the given
test data and labels.</p>
<h4>Parameters</h4>
<details class="info" open="open"><summary>X : array-like of shape (n_samples, n_features)</summary><p>Test samples.</p>
</details>
<details class="info" open="open"><summary>y : array-like of shape (n_samples,)</summary><p>True labels for X.</p>
</details>
<details class="info" open="open"><summary>sample_weight : array-like of shape (n_samples,), default=None</summary><p>Sample weights.</p>
</details>
<h4>Returns</h4>
<details class="info" open="open"><summary>score : float</summary><p>Score of self.predict(X) wrt. y.</p>
</details>
</details>
<h3 id="set_params_14">set_params<a class="headerlink" href="#set_params_14" title="Permanent link">&para;</a></h3>
<details class="note" open="open"><summary>method</summary><div class="highlight"><pre><span></span><code><span class="k">val</span> <span class="n">set_params</span> <span class="o">:</span>
  <span class="o">?</span><span class="n">params</span><span class="o">:(</span><span class="kt">string</span> <span class="o">*</span> <span class="nn">Py</span><span class="p">.</span><span class="nn">Object</span><span class="p">.</span><span class="n">t</span><span class="o">)</span> <span class="kt">list</span> <span class="o">-&gt;</span>
  <span class="n">t</span> <span class="o">-&gt;</span>
  <span class="n">t</span>
</code></pre></div>

<p>Set the parameters of this estimator.</p>
<p>The method works on simple estimators as well as on nested objects
(such as pipelines). The latter have parameters of the form
<code>&lt;component&gt;__&lt;parameter&gt;</code> so that it's possible to update each
component of a nested object.</p>
<h4>Parameters</h4>
<details class="info" open="open"><summary>**params : dict</summary><p>Estimator parameters.</p>
</details>
<h4>Returns</h4>
<details class="info" open="open"><summary>self : object</summary><p>Estimator instance.</p>
</details>
</details>
<h3 id="sparsify_1">sparsify<a class="headerlink" href="#sparsify_1" title="Permanent link">&para;</a></h3>
<details class="note" open="open"><summary>method</summary><div class="highlight"><pre><span></span><code><span class="k">val</span> <span class="n">sparsify</span> <span class="o">:</span>
  <span class="n">t</span> <span class="o">-&gt;</span>
  <span class="n">t</span>
</code></pre></div>

<p>Convert coefficient matrix to sparse format.</p>
<p>Converts the <code>coef_</code> member to a scipy.sparse matrix, which for
L1-regularized models can be much more memory- and storage-efficient
than the usual numpy.ndarray representation.</p>
<p>The <code>intercept_</code> member is not converted.</p>
<h4>Returns</h4>
<p>self
    Fitted estimator.</p>
<h4>Notes</h4>
<p>For non-sparse models, i.e. when there are not many zeros in <code>coef_</code>,
this may actually <em>increase</em> memory usage, so use this method with
care. A rule of thumb is that the number of zero elements, which can
be computed with <code>(coef_ == 0).sum()</code>, must be more than 50% for this
to provide significant benefits.</p>
<p>After calling this method, further fitting with the partial_fit
method (if any) will not work until you call densify.</p>
</details>
<h3 id="classes__1">classes_<a class="headerlink" href="#classes__1" title="Permanent link">&para;</a></h3>
<details class="note" open="open"><summary>attribute</summary><div class="highlight"><pre><span></span><code><span class="k">val</span> <span class="n">classes_</span> <span class="o">:</span> <span class="n">t</span> <span class="o">-&gt;</span> <span class="nn">Arr</span><span class="p">.</span><span class="n">t</span>
<span class="k">val</span> <span class="n">classes_opt</span> <span class="o">:</span> <span class="n">t</span> <span class="o">-&gt;</span> <span class="o">(</span><span class="nn">Arr</span><span class="p">.</span><span class="n">t</span><span class="o">)</span> <span class="n">option</span>
</code></pre></div>

<p>This attribute is documented in <code>create</code> above. The first version raises Not_found
if the attribute is None. The _opt version returns an option.</p>
</details>
<h3 id="coef__14">coef_<a class="headerlink" href="#coef__14" title="Permanent link">&para;</a></h3>
<details class="note" open="open"><summary>attribute</summary><div class="highlight"><pre><span></span><code><span class="k">val</span> <span class="n">coef_</span> <span class="o">:</span> <span class="n">t</span> <span class="o">-&gt;</span> <span class="nn">Arr</span><span class="p">.</span><span class="n">t</span>
<span class="k">val</span> <span class="n">coef_opt</span> <span class="o">:</span> <span class="n">t</span> <span class="o">-&gt;</span> <span class="o">(</span><span class="nn">Arr</span><span class="p">.</span><span class="n">t</span><span class="o">)</span> <span class="n">option</span>
</code></pre></div>

<p>This attribute is documented in <code>create</code> above. The first version raises Not_found
if the attribute is None. The _opt version returns an option.</p>
</details>
<h3 id="intercept__14">intercept_<a class="headerlink" href="#intercept__14" title="Permanent link">&para;</a></h3>
<details class="note" open="open"><summary>attribute</summary><div class="highlight"><pre><span></span><code><span class="k">val</span> <span class="n">intercept_</span> <span class="o">:</span> <span class="n">t</span> <span class="o">-&gt;</span> <span class="nn">Arr</span><span class="p">.</span><span class="n">t</span>
<span class="k">val</span> <span class="n">intercept_opt</span> <span class="o">:</span> <span class="n">t</span> <span class="o">-&gt;</span> <span class="o">(</span><span class="nn">Arr</span><span class="p">.</span><span class="n">t</span><span class="o">)</span> <span class="n">option</span>
</code></pre></div>

<p>This attribute is documented in <code>create</code> above. The first version raises Not_found
if the attribute is None. The _opt version returns an option.</p>
</details>
<h3 id="cs_">cs_<a class="headerlink" href="#cs_" title="Permanent link">&para;</a></h3>
<details class="note" open="open"><summary>attribute</summary><div class="highlight"><pre><span></span><code><span class="k">val</span> <span class="n">cs_</span> <span class="o">:</span> <span class="n">t</span> <span class="o">-&gt;</span> <span class="nn">Arr</span><span class="p">.</span><span class="n">t</span>
<span class="k">val</span> <span class="n">cs_opt</span> <span class="o">:</span> <span class="n">t</span> <span class="o">-&gt;</span> <span class="o">(</span><span class="nn">Arr</span><span class="p">.</span><span class="n">t</span><span class="o">)</span> <span class="n">option</span>
</code></pre></div>

<p>This attribute is documented in <code>create</code> above. The first version raises Not_found
if the attribute is None. The _opt version returns an option.</p>
</details>
<h3 id="l1_ratios_">l1_ratios_<a class="headerlink" href="#l1_ratios_" title="Permanent link">&para;</a></h3>
<details class="note" open="open"><summary>attribute</summary><div class="highlight"><pre><span></span><code><span class="k">val</span> <span class="n">l1_ratios_</span> <span class="o">:</span> <span class="n">t</span> <span class="o">-&gt;</span> <span class="nn">Arr</span><span class="p">.</span><span class="n">t</span>
<span class="k">val</span> <span class="n">l1_ratios_opt</span> <span class="o">:</span> <span class="n">t</span> <span class="o">-&gt;</span> <span class="o">(</span><span class="nn">Arr</span><span class="p">.</span><span class="n">t</span><span class="o">)</span> <span class="n">option</span>
</code></pre></div>

<p>This attribute is documented in <code>create</code> above. The first version raises Not_found
if the attribute is None. The _opt version returns an option.</p>
</details>
<h3 id="coefs_paths_">coefs_paths_<a class="headerlink" href="#coefs_paths_" title="Permanent link">&para;</a></h3>
<details class="note" open="open"><summary>attribute</summary><div class="highlight"><pre><span></span><code><span class="k">val</span> <span class="n">coefs_paths_</span> <span class="o">:</span> <span class="n">t</span> <span class="o">-&gt;</span> <span class="nn">Py</span><span class="p">.</span><span class="nn">Object</span><span class="p">.</span><span class="n">t</span>
<span class="k">val</span> <span class="n">coefs_paths_opt</span> <span class="o">:</span> <span class="n">t</span> <span class="o">-&gt;</span> <span class="o">(</span><span class="nn">Py</span><span class="p">.</span><span class="nn">Object</span><span class="p">.</span><span class="n">t</span><span class="o">)</span> <span class="n">option</span>
</code></pre></div>

<p>This attribute is documented in <code>create</code> above. The first version raises Not_found
if the attribute is None. The _opt version returns an option.</p>
</details>
<h3 id="scores__2">scores_<a class="headerlink" href="#scores__2" title="Permanent link">&para;</a></h3>
<details class="note" open="open"><summary>attribute</summary><div class="highlight"><pre><span></span><code><span class="k">val</span> <span class="n">scores_</span> <span class="o">:</span> <span class="n">t</span> <span class="o">-&gt;</span> <span class="nn">Dict</span><span class="p">.</span><span class="n">t</span>
<span class="k">val</span> <span class="n">scores_opt</span> <span class="o">:</span> <span class="n">t</span> <span class="o">-&gt;</span> <span class="o">(</span><span class="nn">Dict</span><span class="p">.</span><span class="n">t</span><span class="o">)</span> <span class="n">option</span>
</code></pre></div>

<p>This attribute is documented in <code>create</code> above. The first version raises Not_found
if the attribute is None. The _opt version returns an option.</p>
</details>
<h3 id="c_">c_<a class="headerlink" href="#c_" title="Permanent link">&para;</a></h3>
<details class="note" open="open"><summary>attribute</summary><div class="highlight"><pre><span></span><code><span class="k">val</span> <span class="n">c_</span> <span class="o">:</span> <span class="n">t</span> <span class="o">-&gt;</span> <span class="nn">Py</span><span class="p">.</span><span class="nn">Object</span><span class="p">.</span><span class="n">t</span>
<span class="k">val</span> <span class="n">c_opt</span> <span class="o">:</span> <span class="n">t</span> <span class="o">-&gt;</span> <span class="o">(</span><span class="nn">Py</span><span class="p">.</span><span class="nn">Object</span><span class="p">.</span><span class="n">t</span><span class="o">)</span> <span class="n">option</span>
</code></pre></div>

<p>This attribute is documented in <code>create</code> above. The first version raises Not_found
if the attribute is None. The _opt version returns an option.</p>
</details>
<h3 id="l1_ratio__1">l1_ratio_<a class="headerlink" href="#l1_ratio__1" title="Permanent link">&para;</a></h3>
<details class="note" open="open"><summary>attribute</summary><div class="highlight"><pre><span></span><code><span class="k">val</span> <span class="n">l1_ratio_</span> <span class="o">:</span> <span class="n">t</span> <span class="o">-&gt;</span> <span class="nn">Py</span><span class="p">.</span><span class="nn">Object</span><span class="p">.</span><span class="n">t</span>
<span class="k">val</span> <span class="n">l1_ratio_opt</span> <span class="o">:</span> <span class="n">t</span> <span class="o">-&gt;</span> <span class="o">(</span><span class="nn">Py</span><span class="p">.</span><span class="nn">Object</span><span class="p">.</span><span class="n">t</span><span class="o">)</span> <span class="n">option</span>
</code></pre></div>

<p>This attribute is documented in <code>create</code> above. The first version raises Not_found
if the attribute is None. The _opt version returns an option.</p>
</details>
<h3 id="n_iter__12">n_iter_<a class="headerlink" href="#n_iter__12" title="Permanent link">&para;</a></h3>
<details class="note" open="open"><summary>attribute</summary><div class="highlight"><pre><span></span><code><span class="k">val</span> <span class="n">n_iter_</span> <span class="o">:</span> <span class="n">t</span> <span class="o">-&gt;</span> <span class="nn">Arr</span><span class="p">.</span><span class="n">t</span>
<span class="k">val</span> <span class="n">n_iter_opt</span> <span class="o">:</span> <span class="n">t</span> <span class="o">-&gt;</span> <span class="o">(</span><span class="nn">Arr</span><span class="p">.</span><span class="n">t</span><span class="o">)</span> <span class="n">option</span>
</code></pre></div>

<p>This attribute is documented in <code>create</code> above. The first version raises Not_found
if the attribute is None. The _opt version returns an option.</p>
</details>
<h3 id="to_string_14">to_string<a class="headerlink" href="#to_string_14" title="Permanent link">&para;</a></h3>
<details class="note" open="open"><summary>method</summary><div class="highlight"><pre><span></span><code><span class="k">val</span> <span class="n">to_string</span><span class="o">:</span> <span class="n">t</span> <span class="o">-&gt;</span> <span class="kt">string</span>
</code></pre></div>

<p>Print the object to a human-readable representation.</p>
</details>
<h3 id="show_14">show<a class="headerlink" href="#show_14" title="Permanent link">&para;</a></h3>
<details class="note" open="open"><summary>method</summary><div class="highlight"><pre><span></span><code><span class="k">val</span> <span class="n">show</span><span class="o">:</span> <span class="n">t</span> <span class="o">-&gt;</span> <span class="kt">string</span>
</code></pre></div>

<p>Print the object to a human-readable representation.</p>
</details>
<h3 id="pp_14">pp<a class="headerlink" href="#pp_14" title="Permanent link">&para;</a></h3>
<details class="note" open="open"><summary>method</summary><div class="highlight"><pre><span></span><code><span class="k">val</span> <span class="n">pp</span><span class="o">:</span> <span class="nn">Format</span><span class="p">.</span><span class="n">formatter</span> <span class="o">-&gt;</span> <span class="n">t</span> <span class="o">-&gt;</span> <span class="kt">unit</span>
</code></pre></div>

<p>Pretty-print the object to a formatter.</p>
</details>
<h2 id="module-sklearnlinear_modelmultitaskelasticnet">module Sklearn.​Linear_model.​MultiTaskElasticNet<a class="headerlink" href="#module-sklearnlinear_modelmultitaskelasticnet" title="Permanent link">&para;</a></h2>
<div class="highlight"><pre><span></span><code><span class="k">type</span> <span class="n">t</span>
</code></pre></div>

<h3 id="create_15">create<a class="headerlink" href="#create_15" title="Permanent link">&para;</a></h3>
<details class="note" open="open"><summary>constructor and attributes</summary><div class="highlight"><pre><span></span><code><span class="k">val</span> <span class="n">create</span> <span class="o">:</span>
  <span class="o">?</span><span class="n">alpha</span><span class="o">:</span><span class="kt">float</span> <span class="o">-&gt;</span>
  <span class="o">?</span><span class="n">l1_ratio</span><span class="o">:</span><span class="kt">float</span> <span class="o">-&gt;</span>
  <span class="o">?</span><span class="n">fit_intercept</span><span class="o">:</span><span class="kt">bool</span> <span class="o">-&gt;</span>
  <span class="o">?</span><span class="n">normalize</span><span class="o">:</span><span class="kt">bool</span> <span class="o">-&gt;</span>
  <span class="o">?</span><span class="n">copy_X</span><span class="o">:</span><span class="kt">bool</span> <span class="o">-&gt;</span>
  <span class="o">?</span><span class="n">max_iter</span><span class="o">:</span><span class="kt">int</span> <span class="o">-&gt;</span>
  <span class="o">?</span><span class="n">tol</span><span class="o">:</span><span class="kt">float</span> <span class="o">-&gt;</span>
  <span class="o">?</span><span class="n">warm_start</span><span class="o">:</span><span class="kt">bool</span> <span class="o">-&gt;</span>
  <span class="o">?</span><span class="n">random_state</span><span class="o">:</span><span class="kt">int</span> <span class="o">-&gt;</span>
  <span class="o">?</span><span class="n">selection</span><span class="o">:</span><span class="kt">string</span> <span class="o">-&gt;</span>
  <span class="kt">unit</span> <span class="o">-&gt;</span>
  <span class="n">t</span>
</code></pre></div>

<p>Multi-task ElasticNet model trained with L1/L2 mixed-norm as regularizer</p>
<p>The optimization objective for MultiTaskElasticNet is::</p>
<div class="codehilite"><pre><span></span><code>(1 / (2 * n_samples)) * ||Y - XW||_Fro^2
+ alpha * l1_ratio * ||W||_21
+ 0.5 * alpha * (1 - l1_ratio) * ||W||_Fro^2
</code></pre></div>


<details class="info" open="open"><summary>Where::</summary><p>||W||_21 = sum_i sqrt(sum_j w_ij ^ 2)</p>
</details>
<p>i.e. the sum of norm of each row.</p>
<p>Read more in the :ref:<code>User Guide &lt;multi_task_elastic_net&gt;</code>.</p>
<h4>Parameters</h4>
<details class="info" open="open"><summary>alpha : float, optional</summary><p>Constant that multiplies the L1/L2 term. Defaults to 1.0</p>
</details>
<details class="info" open="open"><summary>l1_ratio : float</summary><p>The ElasticNet mixing parameter, with 0 &lt; l1_ratio &lt;= 1.
For l1_ratio = 1 the penalty is an L1/L2 penalty. For l1_ratio = 0 it
is an L2 penalty.
For <code>0 &lt; l1_ratio &lt; 1</code>, the penalty is a combination of L1/L2 and L2.</p>
</details>
<details class="info" open="open"><summary>fit_intercept : boolean</summary><p>whether to calculate the intercept for this model. If set
to false, no intercept will be used in calculations
(i.e. data is expected to be centered).</p>
</details>
<details class="info" open="open"><summary>normalize : boolean, optional, default False</summary><p>This parameter is ignored when <code>fit_intercept</code> is set to False.
If True, the regressors X will be normalized before regression by
subtracting the mean and dividing by the l2-norm.
If you wish to standardize, please use
:class:<code>sklearn.preprocessing.StandardScaler</code> before calling <code>fit</code>
on an estimator with <code>normalize=False</code>.</p>
</details>
<details class="info" open="open"><summary>copy_X : boolean, optional, default True</summary><p>If <code>True</code>, X will be copied; else, it may be overwritten.</p>
</details>
<details class="info" open="open"><summary>max_iter : int, optional</summary><p>The maximum number of iterations</p>
</details>
<details class="info" open="open"><summary>tol : float, optional</summary><p>The tolerance for the optimization: if the updates are
smaller than <code>tol</code>, the optimization code checks the
dual gap for optimality and continues until it is smaller
than <code>tol</code>.</p>
</details>
<details class="info" open="open"><summary>warm_start : bool, optional</summary><p>When set to <code>True</code>, reuse the solution of the previous call to fit as
initialization, otherwise, just erase the previous solution.</p>
</details>
<details class="info" open="open"><summary>See :term:<code>the Glossary &lt;warm_start&gt;</code>.</summary></details>
<details class="info" open="open"><summary>random_state : int, RandomState instance or None, optional, default None</summary><p>The seed of the pseudo random number generator that selects a random
feature to update.  If int, random_state is the seed used by the random
number generator; If RandomState instance, random_state is the random
number generator; If None, the random number generator is the
RandomState instance used by <code>np.random</code>. Used when <code>selection</code> ==
'random'.</p>
</details>
<details class="info" open="open"><summary>selection : str, default 'cyclic'</summary><p>If set to 'random', a random coefficient is updated every iteration
rather than looping over features sequentially by default. This
(setting to 'random') often leads to significantly faster convergence
especially when tol is higher than 1e-4.</p>
</details>
<h4>Attributes</h4>
<details class="info" open="open"><summary>intercept_ : array, shape (n_tasks,)</summary><p>Independent term in decision function.</p>
</details>
<details class="info" open="open"><summary>coef_ : array, shape (n_tasks, n_features)</summary><p>Parameter vector (W in the cost function formula). If a 1D y is
passed in at fit (non multi-task usage), <code>coef_</code> is then a 1D array.
Note that <code>coef_</code> stores the transpose of <code>W</code>, <code>W.T</code>.</p>
</details>
<details class="info" open="open"><summary>n_iter_ : int</summary><p>number of iterations run by the coordinate descent solver to reach
the specified tolerance.</p>
</details>
<h4>Examples</h4>
<div class="highlight"><pre><span></span><code><span class="o">&gt;&gt;&gt;</span> <span class="kn">from</span> <span class="nn">sklearn</span> <span class="kn">import</span> <span class="n">linear_model</span>
<span class="o">&gt;&gt;&gt;</span> <span class="n">clf</span> <span class="o">=</span> <span class="n">linear_model</span><span class="o">.</span><span class="n">MultiTaskElasticNet</span><span class="p">(</span><span class="n">alpha</span><span class="o">=</span><span class="mf">0.1</span><span class="p">)</span>
<span class="o">&gt;&gt;&gt;</span> <span class="n">clf</span><span class="o">.</span><span class="n">fit</span><span class="p">([[</span><span class="mi">0</span><span class="p">,</span><span class="mi">0</span><span class="p">],</span> <span class="p">[</span><span class="mi">1</span><span class="p">,</span> <span class="mi">1</span><span class="p">],</span> <span class="p">[</span><span class="mi">2</span><span class="p">,</span> <span class="mi">2</span><span class="p">]],</span> <span class="p">[[</span><span class="mi">0</span><span class="p">,</span> <span class="mi">0</span><span class="p">],</span> <span class="p">[</span><span class="mi">1</span><span class="p">,</span> <span class="mi">1</span><span class="p">],</span> <span class="p">[</span><span class="mi">2</span><span class="p">,</span> <span class="mi">2</span><span class="p">]])</span>
<span class="n">MultiTaskElasticNet</span><span class="p">(</span><span class="n">alpha</span><span class="o">=</span><span class="mf">0.1</span><span class="p">)</span>
<span class="o">&gt;&gt;&gt;</span> <span class="nb">print</span><span class="p">(</span><span class="n">clf</span><span class="o">.</span><span class="n">coef_</span><span class="p">)</span>
<span class="p">[[</span><span class="mf">0.45663524</span> <span class="mf">0.45612256</span><span class="p">]</span>
 <span class="p">[</span><span class="mf">0.45663524</span> <span class="mf">0.45612256</span><span class="p">]]</span>
<span class="o">&gt;&gt;&gt;</span> <span class="nb">print</span><span class="p">(</span><span class="n">clf</span><span class="o">.</span><span class="n">intercept_</span><span class="p">)</span>
<span class="p">[</span><span class="mf">0.0872422</span> <span class="mf">0.0872422</span><span class="p">]</span>
</code></pre></div>

<h4>See also</h4>
<details class="info" open="open"><summary>MultiTaskElasticNet : Multi-task L1/L2 ElasticNet with built-in</summary><p>cross-validation.</p>
</details>
<p>ElasticNet
MultiTaskLasso</p>
<h4>Notes</h4>
<p>The algorithm used to fit the model is coordinate descent.</p>
<p>To avoid unnecessary memory duplication the X argument of the fit method
should be directly passed as a Fortran-contiguous numpy array.</p>
</details>
<h3 id="fit_15">fit<a class="headerlink" href="#fit_15" title="Permanent link">&para;</a></h3>
<details class="note" open="open"><summary>method</summary><div class="highlight"><pre><span></span><code><span class="k">val</span> <span class="n">fit</span> <span class="o">:</span>
  <span class="n">x</span><span class="o">:</span><span class="nn">Arr</span><span class="p">.</span><span class="n">t</span> <span class="o">-&gt;</span>
  <span class="n">y</span><span class="o">:</span><span class="nn">Py</span><span class="p">.</span><span class="nn">Object</span><span class="p">.</span><span class="n">t</span> <span class="o">-&gt;</span>
  <span class="n">t</span> <span class="o">-&gt;</span>
  <span class="n">t</span>
</code></pre></div>

<p>Fit MultiTaskElasticNet model with coordinate descent</p>
<h4>Parameters</h4>
<details class="info" open="open"><summary>X : ndarray, shape (n_samples, n_features)</summary><p>Data</p>
</details>
<details class="info" open="open"><summary>y : ndarray, shape (n_samples, n_tasks)</summary><p>Target. Will be cast to X's dtype if necessary</p>
</details>
<h4>Notes</h4>
<p>Coordinate descent is an algorithm that considers each column of
data at a time hence it will automatically convert the X input
as a Fortran-contiguous numpy array if necessary.</p>
<p>To avoid memory re-allocation it is advised to allocate the
initial data in memory directly using that format.</p>
</details>
<h3 id="get_params_15">get_params<a class="headerlink" href="#get_params_15" title="Permanent link">&para;</a></h3>
<details class="note" open="open"><summary>method</summary><div class="highlight"><pre><span></span><code><span class="k">val</span> <span class="n">get_params</span> <span class="o">:</span>
  <span class="o">?</span><span class="n">deep</span><span class="o">:</span><span class="kt">bool</span> <span class="o">-&gt;</span>
  <span class="n">t</span> <span class="o">-&gt;</span>
  <span class="nn">Dict</span><span class="p">.</span><span class="n">t</span>
</code></pre></div>

<p>Get parameters for this estimator.</p>
<h4>Parameters</h4>
<details class="info" open="open"><summary>deep : bool, default=True</summary><p>If True, will return the parameters for this estimator and
contained subobjects that are estimators.</p>
</details>
<h4>Returns</h4>
<details class="info" open="open"><summary>params : mapping of string to any</summary><p>Parameter names mapped to their values.</p>
</details>
</details>
<h3 id="predict_15">predict<a class="headerlink" href="#predict_15" title="Permanent link">&para;</a></h3>
<details class="note" open="open"><summary>method</summary><div class="highlight"><pre><span></span><code><span class="k">val</span> <span class="n">predict</span> <span class="o">:</span>
  <span class="n">x</span><span class="o">:</span><span class="nn">Arr</span><span class="p">.</span><span class="n">t</span> <span class="o">-&gt;</span>
  <span class="n">t</span> <span class="o">-&gt;</span>
  <span class="nn">Arr</span><span class="p">.</span><span class="n">t</span>
</code></pre></div>

<p>Predict using the linear model.</p>
<h4>Parameters</h4>
<details class="info" open="open"><summary>X : array_like or sparse matrix, shape (n_samples, n_features)</summary><p>Samples.</p>
</details>
<h4>Returns</h4>
<details class="info" open="open"><summary>C : array, shape (n_samples,)</summary><p>Returns predicted values.</p>
</details>
</details>
<h3 id="score_15">score<a class="headerlink" href="#score_15" title="Permanent link">&para;</a></h3>
<details class="note" open="open"><summary>method</summary><div class="highlight"><pre><span></span><code><span class="k">val</span> <span class="n">score</span> <span class="o">:</span>
  <span class="o">?</span><span class="n">sample_weight</span><span class="o">:</span><span class="nn">Arr</span><span class="p">.</span><span class="n">t</span> <span class="o">-&gt;</span>
  <span class="n">x</span><span class="o">:</span><span class="nn">Arr</span><span class="p">.</span><span class="n">t</span> <span class="o">-&gt;</span>
  <span class="n">y</span><span class="o">:</span><span class="nn">Arr</span><span class="p">.</span><span class="n">t</span> <span class="o">-&gt;</span>
  <span class="n">t</span> <span class="o">-&gt;</span>
  <span class="kt">float</span>
</code></pre></div>

<p>Return the coefficient of determination R^2 of the prediction.</p>
<p>The coefficient R^2 is defined as (1 - u/v), where u is the residual
sum of squares ((y_true - y_pred) <strong> 2).sum() and v is the total
sum of squares ((y_true - y_true.mean()) </strong> 2).sum().
The best possible score is 1.0 and it can be negative (because the
model can be arbitrarily worse). A constant model that always
predicts the expected value of y, disregarding the input features,
would get a R^2 score of 0.0.</p>
<h4>Parameters</h4>
<details class="info" open="open"><summary>X : array-like of shape (n_samples, n_features)</summary><p>Test samples. For some estimators this may be a
precomputed kernel matrix or a list of generic objects instead,
shape = (n_samples, n_samples_fitted),
where n_samples_fitted is the number of
samples used in the fitting for the estimator.</p>
</details>
<details class="info" open="open"><summary>y : array-like of shape (n_samples,) or (n_samples, n_outputs)</summary><p>True values for X.</p>
</details>
<details class="info" open="open"><summary>sample_weight : array-like of shape (n_samples,), default=None</summary><p>Sample weights.</p>
</details>
<h4>Returns</h4>
<details class="info" open="open"><summary>score : float</summary><p>R^2 of self.predict(X) wrt. y.</p>
</details>
<h4>Notes</h4>
<p>The R2 score used when calling <code>score</code> on a regressor will use
<code>multioutput='uniform_average'</code> from version 0.23 to keep consistent</p>
<details class="info" open="open"><summary>with :func:<code>~sklearn.metrics.r2_score</code>. This will influence the</summary></details>
<p><code>score</code> method of all the multioutput regressors (except for
:class:<code>~sklearn.multioutput.MultiOutputRegressor</code>). To specify the
default value manually and avoid the warning, please either call
:func:<code>~sklearn.metrics.r2_score</code> directly or make a custom scorer with
:func:<code>~sklearn.metrics.make_scorer</code> (the built-in scorer <code>'r2'</code> uses
<code>multioutput='uniform_average'</code>).</p>
</details>
<h3 id="set_params_15">set_params<a class="headerlink" href="#set_params_15" title="Permanent link">&para;</a></h3>
<details class="note" open="open"><summary>method</summary><div class="highlight"><pre><span></span><code><span class="k">val</span> <span class="n">set_params</span> <span class="o">:</span>
  <span class="o">?</span><span class="n">params</span><span class="o">:(</span><span class="kt">string</span> <span class="o">*</span> <span class="nn">Py</span><span class="p">.</span><span class="nn">Object</span><span class="p">.</span><span class="n">t</span><span class="o">)</span> <span class="kt">list</span> <span class="o">-&gt;</span>
  <span class="n">t</span> <span class="o">-&gt;</span>
  <span class="n">t</span>
</code></pre></div>

<p>Set the parameters of this estimator.</p>
<p>The method works on simple estimators as well as on nested objects
(such as pipelines). The latter have parameters of the form
<code>&lt;component&gt;__&lt;parameter&gt;</code> so that it's possible to update each
component of a nested object.</p>
<h4>Parameters</h4>
<details class="info" open="open"><summary>**params : dict</summary><p>Estimator parameters.</p>
</details>
<h4>Returns</h4>
<details class="info" open="open"><summary>self : object</summary><p>Estimator instance.</p>
</details>
</details>
<h3 id="intercept__15">intercept_<a class="headerlink" href="#intercept__15" title="Permanent link">&para;</a></h3>
<details class="note" open="open"><summary>attribute</summary><div class="highlight"><pre><span></span><code><span class="k">val</span> <span class="n">intercept_</span> <span class="o">:</span> <span class="n">t</span> <span class="o">-&gt;</span> <span class="nn">Arr</span><span class="p">.</span><span class="n">t</span>
<span class="k">val</span> <span class="n">intercept_opt</span> <span class="o">:</span> <span class="n">t</span> <span class="o">-&gt;</span> <span class="o">(</span><span class="nn">Arr</span><span class="p">.</span><span class="n">t</span><span class="o">)</span> <span class="n">option</span>
</code></pre></div>

<p>This attribute is documented in <code>create</code> above. The first version raises Not_found
if the attribute is None. The _opt version returns an option.</p>
</details>
<h3 id="coef__15">coef_<a class="headerlink" href="#coef__15" title="Permanent link">&para;</a></h3>
<details class="note" open="open"><summary>attribute</summary><div class="highlight"><pre><span></span><code><span class="k">val</span> <span class="n">coef_</span> <span class="o">:</span> <span class="n">t</span> <span class="o">-&gt;</span> <span class="nn">Arr</span><span class="p">.</span><span class="n">t</span>
<span class="k">val</span> <span class="n">coef_opt</span> <span class="o">:</span> <span class="n">t</span> <span class="o">-&gt;</span> <span class="o">(</span><span class="nn">Arr</span><span class="p">.</span><span class="n">t</span><span class="o">)</span> <span class="n">option</span>
</code></pre></div>

<p>This attribute is documented in <code>create</code> above. The first version raises Not_found
if the attribute is None. The _opt version returns an option.</p>
</details>
<h3 id="n_iter__13">n_iter_<a class="headerlink" href="#n_iter__13" title="Permanent link">&para;</a></h3>
<details class="note" open="open"><summary>attribute</summary><div class="highlight"><pre><span></span><code><span class="k">val</span> <span class="n">n_iter_</span> <span class="o">:</span> <span class="n">t</span> <span class="o">-&gt;</span> <span class="kt">int</span>
<span class="k">val</span> <span class="n">n_iter_opt</span> <span class="o">:</span> <span class="n">t</span> <span class="o">-&gt;</span> <span class="o">(</span><span class="kt">int</span><span class="o">)</span> <span class="n">option</span>
</code></pre></div>

<p>This attribute is documented in <code>create</code> above. The first version raises Not_found
if the attribute is None. The _opt version returns an option.</p>
</details>
<h3 id="to_string_15">to_string<a class="headerlink" href="#to_string_15" title="Permanent link">&para;</a></h3>
<details class="note" open="open"><summary>method</summary><div class="highlight"><pre><span></span><code><span class="k">val</span> <span class="n">to_string</span><span class="o">:</span> <span class="n">t</span> <span class="o">-&gt;</span> <span class="kt">string</span>
</code></pre></div>

<p>Print the object to a human-readable representation.</p>
</details>
<h3 id="show_15">show<a class="headerlink" href="#show_15" title="Permanent link">&para;</a></h3>
<details class="note" open="open"><summary>method</summary><div class="highlight"><pre><span></span><code><span class="k">val</span> <span class="n">show</span><span class="o">:</span> <span class="n">t</span> <span class="o">-&gt;</span> <span class="kt">string</span>
</code></pre></div>

<p>Print the object to a human-readable representation.</p>
</details>
<h3 id="pp_15">pp<a class="headerlink" href="#pp_15" title="Permanent link">&para;</a></h3>
<details class="note" open="open"><summary>method</summary><div class="highlight"><pre><span></span><code><span class="k">val</span> <span class="n">pp</span><span class="o">:</span> <span class="nn">Format</span><span class="p">.</span><span class="n">formatter</span> <span class="o">-&gt;</span> <span class="n">t</span> <span class="o">-&gt;</span> <span class="kt">unit</span>
</code></pre></div>

<p>Pretty-print the object to a formatter.</p>
</details>
<h2 id="module-sklearnlinear_modelmultitaskelasticnetcv">module Sklearn.​Linear_model.​MultiTaskElasticNetCV<a class="headerlink" href="#module-sklearnlinear_modelmultitaskelasticnetcv" title="Permanent link">&para;</a></h2>
<div class="highlight"><pre><span></span><code><span class="k">type</span> <span class="n">t</span>
</code></pre></div>

<h3 id="create_16">create<a class="headerlink" href="#create_16" title="Permanent link">&para;</a></h3>
<details class="note" open="open"><summary>constructor and attributes</summary><div class="highlight"><pre><span></span><code><span class="k">val</span> <span class="n">create</span> <span class="o">:</span>
  <span class="o">?</span><span class="n">l1_ratio</span><span class="o">:[`</span><span class="nc">F</span> <span class="k">of</span> <span class="kt">float</span> <span class="o">|</span> <span class="o">`</span><span class="nc">Arr</span> <span class="k">of</span> <span class="nn">Arr</span><span class="p">.</span><span class="n">t</span><span class="o">]</span> <span class="o">-&gt;</span>
  <span class="o">?</span><span class="n">eps</span><span class="o">:</span><span class="kt">float</span> <span class="o">-&gt;</span>
  <span class="o">?</span><span class="n">n_alphas</span><span class="o">:</span><span class="kt">int</span> <span class="o">-&gt;</span>
  <span class="o">?</span><span class="n">alphas</span><span class="o">:</span><span class="nn">Arr</span><span class="p">.</span><span class="n">t</span> <span class="o">-&gt;</span>
  <span class="o">?</span><span class="n">fit_intercept</span><span class="o">:</span><span class="kt">bool</span> <span class="o">-&gt;</span>
  <span class="o">?</span><span class="n">normalize</span><span class="o">:</span><span class="kt">bool</span> <span class="o">-&gt;</span>
  <span class="o">?</span><span class="n">max_iter</span><span class="o">:</span><span class="kt">int</span> <span class="o">-&gt;</span>
  <span class="o">?</span><span class="n">tol</span><span class="o">:</span><span class="kt">float</span> <span class="o">-&gt;</span>
  <span class="o">?</span><span class="n">cv</span><span class="o">:[`</span><span class="nc">I</span> <span class="k">of</span> <span class="kt">int</span> <span class="o">|</span> <span class="o">`</span><span class="nc">CrossValGenerator</span> <span class="k">of</span> <span class="nn">Py</span><span class="p">.</span><span class="nn">Object</span><span class="p">.</span><span class="n">t</span> <span class="o">|</span> <span class="o">`</span><span class="nc">Arr</span> <span class="k">of</span> <span class="nn">Arr</span><span class="p">.</span><span class="n">t</span><span class="o">]</span> <span class="o">-&gt;</span>
  <span class="o">?</span><span class="n">copy_X</span><span class="o">:</span><span class="kt">bool</span> <span class="o">-&gt;</span>
  <span class="o">?</span><span class="n">verbose</span><span class="o">:</span><span class="kt">int</span> <span class="o">-&gt;</span>
  <span class="o">?</span><span class="n">n_jobs</span><span class="o">:</span><span class="kt">int</span> <span class="o">-&gt;</span>
  <span class="o">?</span><span class="n">random_state</span><span class="o">:</span><span class="kt">int</span> <span class="o">-&gt;</span>
  <span class="o">?</span><span class="n">selection</span><span class="o">:</span><span class="kt">string</span> <span class="o">-&gt;</span>
  <span class="kt">unit</span> <span class="o">-&gt;</span>
  <span class="n">t</span>
</code></pre></div>

<p>Multi-task L1/L2 ElasticNet with built-in cross-validation.</p>
<p>See glossary entry for :term:<code>cross-validation estimator</code>.</p>
<p>The optimization objective for MultiTaskElasticNet is::</p>
<div class="codehilite"><pre><span></span><code>(1 / (2 * n_samples)) * ||Y - XW||^Fro_2
+ alpha * l1_ratio * ||W||_21
+ 0.5 * alpha * (1 - l1_ratio) * ||W||_Fro^2
</code></pre></div>


<details class="info" open="open"><summary>Where::</summary><p>||W||<em>21 = \sum_i \sqrt{\sum_j w</em>{ij}^2}</p>
</details>
<p>i.e. the sum of norm of each row.</p>
<p>Read more in the :ref:<code>User Guide &lt;multi_task_elastic_net&gt;</code>.</p>
<p>.. versionadded:: 0.15</p>
<h4>Parameters</h4>
<details class="info" open="open"><summary>l1_ratio : float or array of floats</summary><p>The ElasticNet mixing parameter, with 0 &lt; l1_ratio &lt;= 1.
For l1_ratio = 1 the penalty is an L1/L2 penalty. For l1_ratio = 0 it
is an L2 penalty.
For <code>0 &lt; l1_ratio &lt; 1</code>, the penalty is a combination of L1/L2 and L2.
This parameter can be a list, in which case the different
values are tested by cross-validation and the one giving the best
prediction score is used. Note that a good choice of list of
values for l1_ratio is often to put more values close to 1
(i.e. Lasso) and less close to 0 (i.e. Ridge), as in <code>[.1, .5, .7,
.9, .95, .99, 1]</code></p>
</details>
<details class="info" open="open"><summary>eps : float, optional</summary><p>Length of the path. <code>eps=1e-3</code> means that
<code>alpha_min / alpha_max = 1e-3</code>.</p>
</details>
<details class="info" open="open"><summary>n_alphas : int, optional</summary><p>Number of alphas along the regularization path</p>
</details>
<details class="info" open="open"><summary>alphas : array-like, optional</summary><p>List of alphas where to compute the models.
If not provided, set automatically.</p>
</details>
<details class="info" open="open"><summary>fit_intercept : boolean</summary><p>whether to calculate the intercept for this model. If set
to false, no intercept will be used in calculations
(i.e. data is expected to be centered).</p>
</details>
<details class="info" open="open"><summary>normalize : boolean, optional, default False</summary><p>This parameter is ignored when <code>fit_intercept</code> is set to False.
If True, the regressors X will be normalized before regression by
subtracting the mean and dividing by the l2-norm.
If you wish to standardize, please use
:class:<code>sklearn.preprocessing.StandardScaler</code> before calling <code>fit</code>
on an estimator with <code>normalize=False</code>.</p>
</details>
<details class="info" open="open"><summary>max_iter : int, optional</summary><p>The maximum number of iterations</p>
</details>
<details class="info" open="open"><summary>tol : float, optional</summary><p>The tolerance for the optimization: if the updates are
smaller than <code>tol</code>, the optimization code checks the
dual gap for optimality and continues until it is smaller
than <code>tol</code>.</p>
</details>
<details class="info" open="open"><summary>cv : int, cross-validation generator or an iterable, optional</summary><p>Determines the cross-validation splitting strategy.
Possible inputs for cv are:</p>
<ul>
<li>None, to use the default 5-fold cross-validation,</li>
<li>integer, to specify the number of folds.</li>
<li>:term:<code>CV splitter</code>,</li>
<li>An iterable yielding (train, test) splits as arrays of indices.</li>
</ul>
<p>For integer/None inputs, :class:<code>KFold</code> is used.</p>
</details>
<details class="info" open="open"><summary>Refer :ref:<code>User Guide &lt;cross_validation&gt;</code> for the various</summary><p>cross-validation strategies that can be used here.</p>
<p>.. versionchanged:: 0.22
    <code>cv</code> default value if None changed from 3-fold to 5-fold.</p>
</details>
<details class="info" open="open"><summary>copy_X : boolean, optional, default True</summary><p>If <code>True</code>, X will be copied; else, it may be overwritten.</p>
</details>
<details class="info" open="open"><summary>verbose : bool or integer</summary><p>Amount of verbosity.</p>
</details>
<details class="info" open="open"><summary>n_jobs : int or None, optional (default=None)</summary><p>Number of CPUs to use during the cross validation. Note that this is
used only if multiple values for l1_ratio are given.
<code>None</code> means 1 unless in a :obj:<code>joblib.parallel_backend</code> context.
<code>-1</code> means using all processors. See :term:<code>Glossary &lt;n_jobs&gt;</code>
for more details.</p>
</details>
<details class="info" open="open"><summary>random_state : int, RandomState instance or None, optional, default None</summary><p>The seed of the pseudo random number generator that selects a random
feature to update.  If int, random_state is the seed used by the random
number generator; If RandomState instance, random_state is the random
number generator; If None, the random number generator is the
RandomState instance used by <code>np.random</code>. Used when <code>selection</code> ==
'random'.</p>
</details>
<details class="info" open="open"><summary>selection : str, default 'cyclic'</summary><p>If set to 'random', a random coefficient is updated every iteration
rather than looping over features sequentially by default. This
(setting to 'random') often leads to significantly faster convergence
especially when tol is higher than 1e-4.</p>
</details>
<h4>Attributes</h4>
<details class="info" open="open"><summary>intercept_ : array, shape (n_tasks,)</summary><p>Independent term in decision function.</p>
</details>
<details class="info" open="open"><summary>coef_ : array, shape (n_tasks, n_features)</summary><p>Parameter vector (W in the cost function formula).
Note that <code>coef_</code> stores the transpose of <code>W</code>, <code>W.T</code>.</p>
</details>
<details class="info" open="open"><summary>alpha_ : float</summary><p>The amount of penalization chosen by cross validation</p>
</details>
<details class="info" open="open"><summary>mse_path_ : array, shape (n_alphas, n_folds) or                 (n_l1_ratio, n_alphas, n_folds)</summary><p>mean square error for the test set on each fold, varying alpha</p>
</details>
<details class="info" open="open"><summary>alphas_ : numpy array, shape (n_alphas,) or (n_l1_ratio, n_alphas)</summary><p>The grid of alphas used for fitting, for each l1_ratio</p>
</details>
<details class="info" open="open"><summary>l1_ratio_ : float</summary><p>best l1_ratio obtained by cross-validation.</p>
</details>
<details class="info" open="open"><summary>n_iter_ : int</summary><p>number of iterations run by the coordinate descent solver to reach
the specified tolerance for the optimal alpha.</p>
</details>
<h4>Examples</h4>
<div class="highlight"><pre><span></span><code><span class="o">&gt;&gt;&gt;</span> <span class="kn">from</span> <span class="nn">sklearn</span> <span class="kn">import</span> <span class="n">linear_model</span>
<span class="o">&gt;&gt;&gt;</span> <span class="n">clf</span> <span class="o">=</span> <span class="n">linear_model</span><span class="o">.</span><span class="n">MultiTaskElasticNetCV</span><span class="p">(</span><span class="n">cv</span><span class="o">=</span><span class="mi">3</span><span class="p">)</span>
<span class="o">&gt;&gt;&gt;</span> <span class="n">clf</span><span class="o">.</span><span class="n">fit</span><span class="p">([[</span><span class="mi">0</span><span class="p">,</span><span class="mi">0</span><span class="p">],</span> <span class="p">[</span><span class="mi">1</span><span class="p">,</span> <span class="mi">1</span><span class="p">],</span> <span class="p">[</span><span class="mi">2</span><span class="p">,</span> <span class="mi">2</span><span class="p">]],</span>
<span class="o">...</span>         <span class="p">[[</span><span class="mi">0</span><span class="p">,</span> <span class="mi">0</span><span class="p">],</span> <span class="p">[</span><span class="mi">1</span><span class="p">,</span> <span class="mi">1</span><span class="p">],</span> <span class="p">[</span><span class="mi">2</span><span class="p">,</span> <span class="mi">2</span><span class="p">]])</span>
<span class="n">MultiTaskElasticNetCV</span><span class="p">(</span><span class="n">cv</span><span class="o">=</span><span class="mi">3</span><span class="p">)</span>
<span class="o">&gt;&gt;&gt;</span> <span class="nb">print</span><span class="p">(</span><span class="n">clf</span><span class="o">.</span><span class="n">coef_</span><span class="p">)</span>
<span class="p">[[</span><span class="mf">0.52875032</span> <span class="mf">0.46958558</span><span class="p">]</span>
 <span class="p">[</span><span class="mf">0.52875032</span> <span class="mf">0.46958558</span><span class="p">]]</span>
<span class="o">&gt;&gt;&gt;</span> <span class="nb">print</span><span class="p">(</span><span class="n">clf</span><span class="o">.</span><span class="n">intercept_</span><span class="p">)</span>
<span class="p">[</span><span class="mf">0.00166409</span> <span class="mf">0.00166409</span><span class="p">]</span>
</code></pre></div>

<h4>See also</h4>
<p>MultiTaskElasticNet
ElasticNetCV
MultiTaskLassoCV</p>
<h4>Notes</h4>
<p>The algorithm used to fit the model is coordinate descent.</p>
<p>To avoid unnecessary memory duplication the X argument of the fit method
should be directly passed as a Fortran-contiguous numpy array.</p>
</details>
<h3 id="fit_16">fit<a class="headerlink" href="#fit_16" title="Permanent link">&para;</a></h3>
<details class="note" open="open"><summary>method</summary><div class="highlight"><pre><span></span><code><span class="k">val</span> <span class="n">fit</span> <span class="o">:</span>
  <span class="n">x</span><span class="o">:</span><span class="nn">Arr</span><span class="p">.</span><span class="n">t</span> <span class="o">-&gt;</span>
  <span class="n">y</span><span class="o">:</span><span class="nn">Arr</span><span class="p">.</span><span class="n">t</span> <span class="o">-&gt;</span>
  <span class="n">t</span> <span class="o">-&gt;</span>
  <span class="n">t</span>
</code></pre></div>

<p>Fit linear model with coordinate descent</p>
<p>Fit is on grid of alphas and best alpha estimated by cross-validation.</p>
<h4>Parameters</h4>
<details class="info" open="open"><summary>X : {array-like}, shape (n_samples, n_features)</summary><p>Training data. Pass directly as Fortran-contiguous data
to avoid unnecessary memory duplication. If y is mono-output,
X can be sparse.</p>
</details>
<details class="info" open="open"><summary>y : array-like, shape (n_samples,) or (n_samples, n_targets)</summary><p>Target values</p>
</details>
</details>
<h3 id="get_params_16">get_params<a class="headerlink" href="#get_params_16" title="Permanent link">&para;</a></h3>
<details class="note" open="open"><summary>method</summary><div class="highlight"><pre><span></span><code><span class="k">val</span> <span class="n">get_params</span> <span class="o">:</span>
  <span class="o">?</span><span class="n">deep</span><span class="o">:</span><span class="kt">bool</span> <span class="o">-&gt;</span>
  <span class="n">t</span> <span class="o">-&gt;</span>
  <span class="nn">Dict</span><span class="p">.</span><span class="n">t</span>
</code></pre></div>

<p>Get parameters for this estimator.</p>
<h4>Parameters</h4>
<details class="info" open="open"><summary>deep : bool, default=True</summary><p>If True, will return the parameters for this estimator and
contained subobjects that are estimators.</p>
</details>
<h4>Returns</h4>
<details class="info" open="open"><summary>params : mapping of string to any</summary><p>Parameter names mapped to their values.</p>
</details>
</details>
<h3 id="predict_16">predict<a class="headerlink" href="#predict_16" title="Permanent link">&para;</a></h3>
<details class="note" open="open"><summary>method</summary><div class="highlight"><pre><span></span><code><span class="k">val</span> <span class="n">predict</span> <span class="o">:</span>
  <span class="n">x</span><span class="o">:</span><span class="nn">Arr</span><span class="p">.</span><span class="n">t</span> <span class="o">-&gt;</span>
  <span class="n">t</span> <span class="o">-&gt;</span>
  <span class="nn">Arr</span><span class="p">.</span><span class="n">t</span>
</code></pre></div>

<p>Predict using the linear model.</p>
<h4>Parameters</h4>
<details class="info" open="open"><summary>X : array_like or sparse matrix, shape (n_samples, n_features)</summary><p>Samples.</p>
</details>
<h4>Returns</h4>
<details class="info" open="open"><summary>C : array, shape (n_samples,)</summary><p>Returns predicted values.</p>
</details>
</details>
<h3 id="score_16">score<a class="headerlink" href="#score_16" title="Permanent link">&para;</a></h3>
<details class="note" open="open"><summary>method</summary><div class="highlight"><pre><span></span><code><span class="k">val</span> <span class="n">score</span> <span class="o">:</span>
  <span class="o">?</span><span class="n">sample_weight</span><span class="o">:</span><span class="nn">Arr</span><span class="p">.</span><span class="n">t</span> <span class="o">-&gt;</span>
  <span class="n">x</span><span class="o">:</span><span class="nn">Arr</span><span class="p">.</span><span class="n">t</span> <span class="o">-&gt;</span>
  <span class="n">y</span><span class="o">:</span><span class="nn">Arr</span><span class="p">.</span><span class="n">t</span> <span class="o">-&gt;</span>
  <span class="n">t</span> <span class="o">-&gt;</span>
  <span class="kt">float</span>
</code></pre></div>

<p>Return the coefficient of determination R^2 of the prediction.</p>
<p>The coefficient R^2 is defined as (1 - u/v), where u is the residual
sum of squares ((y_true - y_pred) <strong> 2).sum() and v is the total
sum of squares ((y_true - y_true.mean()) </strong> 2).sum().
The best possible score is 1.0 and it can be negative (because the
model can be arbitrarily worse). A constant model that always
predicts the expected value of y, disregarding the input features,
would get a R^2 score of 0.0.</p>
<h4>Parameters</h4>
<details class="info" open="open"><summary>X : array-like of shape (n_samples, n_features)</summary><p>Test samples. For some estimators this may be a
precomputed kernel matrix or a list of generic objects instead,
shape = (n_samples, n_samples_fitted),
where n_samples_fitted is the number of
samples used in the fitting for the estimator.</p>
</details>
<details class="info" open="open"><summary>y : array-like of shape (n_samples,) or (n_samples, n_outputs)</summary><p>True values for X.</p>
</details>
<details class="info" open="open"><summary>sample_weight : array-like of shape (n_samples,), default=None</summary><p>Sample weights.</p>
</details>
<h4>Returns</h4>
<details class="info" open="open"><summary>score : float</summary><p>R^2 of self.predict(X) wrt. y.</p>
</details>
<h4>Notes</h4>
<p>The R2 score used when calling <code>score</code> on a regressor will use
<code>multioutput='uniform_average'</code> from version 0.23 to keep consistent</p>
<details class="info" open="open"><summary>with :func:<code>~sklearn.metrics.r2_score</code>. This will influence the</summary></details>
<p><code>score</code> method of all the multioutput regressors (except for
:class:<code>~sklearn.multioutput.MultiOutputRegressor</code>). To specify the
default value manually and avoid the warning, please either call
:func:<code>~sklearn.metrics.r2_score</code> directly or make a custom scorer with
:func:<code>~sklearn.metrics.make_scorer</code> (the built-in scorer <code>'r2'</code> uses
<code>multioutput='uniform_average'</code>).</p>
</details>
<h3 id="set_params_16">set_params<a class="headerlink" href="#set_params_16" title="Permanent link">&para;</a></h3>
<details class="note" open="open"><summary>method</summary><div class="highlight"><pre><span></span><code><span class="k">val</span> <span class="n">set_params</span> <span class="o">:</span>
  <span class="o">?</span><span class="n">params</span><span class="o">:(</span><span class="kt">string</span> <span class="o">*</span> <span class="nn">Py</span><span class="p">.</span><span class="nn">Object</span><span class="p">.</span><span class="n">t</span><span class="o">)</span> <span class="kt">list</span> <span class="o">-&gt;</span>
  <span class="n">t</span> <span class="o">-&gt;</span>
  <span class="n">t</span>
</code></pre></div>

<p>Set the parameters of this estimator.</p>
<p>The method works on simple estimators as well as on nested objects
(such as pipelines). The latter have parameters of the form
<code>&lt;component&gt;__&lt;parameter&gt;</code> so that it's possible to update each
component of a nested object.</p>
<h4>Parameters</h4>
<details class="info" open="open"><summary>**params : dict</summary><p>Estimator parameters.</p>
</details>
<h4>Returns</h4>
<details class="info" open="open"><summary>self : object</summary><p>Estimator instance.</p>
</details>
</details>
<h3 id="intercept__16">intercept_<a class="headerlink" href="#intercept__16" title="Permanent link">&para;</a></h3>
<details class="note" open="open"><summary>attribute</summary><div class="highlight"><pre><span></span><code><span class="k">val</span> <span class="n">intercept_</span> <span class="o">:</span> <span class="n">t</span> <span class="o">-&gt;</span> <span class="nn">Arr</span><span class="p">.</span><span class="n">t</span>
<span class="k">val</span> <span class="n">intercept_opt</span> <span class="o">:</span> <span class="n">t</span> <span class="o">-&gt;</span> <span class="o">(</span><span class="nn">Arr</span><span class="p">.</span><span class="n">t</span><span class="o">)</span> <span class="n">option</span>
</code></pre></div>

<p>This attribute is documented in <code>create</code> above. The first version raises Not_found
if the attribute is None. The _opt version returns an option.</p>
</details>
<h3 id="coef__16">coef_<a class="headerlink" href="#coef__16" title="Permanent link">&para;</a></h3>
<details class="note" open="open"><summary>attribute</summary><div class="highlight"><pre><span></span><code><span class="k">val</span> <span class="n">coef_</span> <span class="o">:</span> <span class="n">t</span> <span class="o">-&gt;</span> <span class="nn">Arr</span><span class="p">.</span><span class="n">t</span>
<span class="k">val</span> <span class="n">coef_opt</span> <span class="o">:</span> <span class="n">t</span> <span class="o">-&gt;</span> <span class="o">(</span><span class="nn">Arr</span><span class="p">.</span><span class="n">t</span><span class="o">)</span> <span class="n">option</span>
</code></pre></div>

<p>This attribute is documented in <code>create</code> above. The first version raises Not_found
if the attribute is None. The _opt version returns an option.</p>
</details>
<h3 id="alpha__7">alpha_<a class="headerlink" href="#alpha__7" title="Permanent link">&para;</a></h3>
<details class="note" open="open"><summary>attribute</summary><div class="highlight"><pre><span></span><code><span class="k">val</span> <span class="n">alpha_</span> <span class="o">:</span> <span class="n">t</span> <span class="o">-&gt;</span> <span class="kt">float</span>
<span class="k">val</span> <span class="n">alpha_opt</span> <span class="o">:</span> <span class="n">t</span> <span class="o">-&gt;</span> <span class="o">(</span><span class="kt">float</span><span class="o">)</span> <span class="n">option</span>
</code></pre></div>

<p>This attribute is documented in <code>create</code> above. The first version raises Not_found
if the attribute is None. The _opt version returns an option.</p>
</details>
<h3 id="mse_path__4">mse_path_<a class="headerlink" href="#mse_path__4" title="Permanent link">&para;</a></h3>
<details class="note" open="open"><summary>attribute</summary><div class="highlight"><pre><span></span><code><span class="k">val</span> <span class="n">mse_path_</span> <span class="o">:</span> <span class="n">t</span> <span class="o">-&gt;</span> <span class="nn">Arr</span><span class="p">.</span><span class="n">t</span>
<span class="k">val</span> <span class="n">mse_path_opt</span> <span class="o">:</span> <span class="n">t</span> <span class="o">-&gt;</span> <span class="o">(</span><span class="nn">Arr</span><span class="p">.</span><span class="n">t</span><span class="o">)</span> <span class="n">option</span>
</code></pre></div>

<p>This attribute is documented in <code>create</code> above. The first version raises Not_found
if the attribute is None. The _opt version returns an option.</p>
</details>
<h3 id="alphas__6">alphas_<a class="headerlink" href="#alphas__6" title="Permanent link">&para;</a></h3>
<details class="note" open="open"><summary>attribute</summary><div class="highlight"><pre><span></span><code><span class="k">val</span> <span class="n">alphas_</span> <span class="o">:</span> <span class="n">t</span> <span class="o">-&gt;</span> <span class="nn">Arr</span><span class="p">.</span><span class="n">t</span>
<span class="k">val</span> <span class="n">alphas_opt</span> <span class="o">:</span> <span class="n">t</span> <span class="o">-&gt;</span> <span class="o">(</span><span class="nn">Arr</span><span class="p">.</span><span class="n">t</span><span class="o">)</span> <span class="n">option</span>
</code></pre></div>

<p>This attribute is documented in <code>create</code> above. The first version raises Not_found
if the attribute is None. The _opt version returns an option.</p>
</details>
<h3 id="l1_ratio__2">l1_ratio_<a class="headerlink" href="#l1_ratio__2" title="Permanent link">&para;</a></h3>
<details class="note" open="open"><summary>attribute</summary><div class="highlight"><pre><span></span><code><span class="k">val</span> <span class="n">l1_ratio_</span> <span class="o">:</span> <span class="n">t</span> <span class="o">-&gt;</span> <span class="kt">float</span>
<span class="k">val</span> <span class="n">l1_ratio_opt</span> <span class="o">:</span> <span class="n">t</span> <span class="o">-&gt;</span> <span class="o">(</span><span class="kt">float</span><span class="o">)</span> <span class="n">option</span>
</code></pre></div>

<p>This attribute is documented in <code>create</code> above. The first version raises Not_found
if the attribute is None. The _opt version returns an option.</p>
</details>
<h3 id="n_iter__14">n_iter_<a class="headerlink" href="#n_iter__14" title="Permanent link">&para;</a></h3>
<details class="note" open="open"><summary>attribute</summary><div class="highlight"><pre><span></span><code><span class="k">val</span> <span class="n">n_iter_</span> <span class="o">:</span> <span class="n">t</span> <span class="o">-&gt;</span> <span class="kt">int</span>
<span class="k">val</span> <span class="n">n_iter_opt</span> <span class="o">:</span> <span class="n">t</span> <span class="o">-&gt;</span> <span class="o">(</span><span class="kt">int</span><span class="o">)</span> <span class="n">option</span>
</code></pre></div>

<p>This attribute is documented in <code>create</code> above. The first version raises Not_found
if the attribute is None. The _opt version returns an option.</p>
</details>
<h3 id="to_string_16">to_string<a class="headerlink" href="#to_string_16" title="Permanent link">&para;</a></h3>
<details class="note" open="open"><summary>method</summary><div class="highlight"><pre><span></span><code><span class="k">val</span> <span class="n">to_string</span><span class="o">:</span> <span class="n">t</span> <span class="o">-&gt;</span> <span class="kt">string</span>
</code></pre></div>

<p>Print the object to a human-readable representation.</p>
</details>
<h3 id="show_16">show<a class="headerlink" href="#show_16" title="Permanent link">&para;</a></h3>
<details class="note" open="open"><summary>method</summary><div class="highlight"><pre><span></span><code><span class="k">val</span> <span class="n">show</span><span class="o">:</span> <span class="n">t</span> <span class="o">-&gt;</span> <span class="kt">string</span>
</code></pre></div>

<p>Print the object to a human-readable representation.</p>
</details>
<h3 id="pp_16">pp<a class="headerlink" href="#pp_16" title="Permanent link">&para;</a></h3>
<details class="note" open="open"><summary>method</summary><div class="highlight"><pre><span></span><code><span class="k">val</span> <span class="n">pp</span><span class="o">:</span> <span class="nn">Format</span><span class="p">.</span><span class="n">formatter</span> <span class="o">-&gt;</span> <span class="n">t</span> <span class="o">-&gt;</span> <span class="kt">unit</span>
</code></pre></div>

<p>Pretty-print the object to a formatter.</p>
</details>
<h2 id="module-sklearnlinear_modelmultitasklasso">module Sklearn.​Linear_model.​MultiTaskLasso<a class="headerlink" href="#module-sklearnlinear_modelmultitasklasso" title="Permanent link">&para;</a></h2>
<div class="highlight"><pre><span></span><code><span class="k">type</span> <span class="n">t</span>
</code></pre></div>

<h3 id="create_17">create<a class="headerlink" href="#create_17" title="Permanent link">&para;</a></h3>
<details class="note" open="open"><summary>constructor and attributes</summary><div class="highlight"><pre><span></span><code><span class="k">val</span> <span class="n">create</span> <span class="o">:</span>
  <span class="o">?</span><span class="n">alpha</span><span class="o">:</span><span class="kt">float</span> <span class="o">-&gt;</span>
  <span class="o">?</span><span class="n">fit_intercept</span><span class="o">:</span><span class="kt">bool</span> <span class="o">-&gt;</span>
  <span class="o">?</span><span class="n">normalize</span><span class="o">:</span><span class="kt">bool</span> <span class="o">-&gt;</span>
  <span class="o">?</span><span class="n">copy_X</span><span class="o">:</span><span class="kt">bool</span> <span class="o">-&gt;</span>
  <span class="o">?</span><span class="n">max_iter</span><span class="o">:</span><span class="kt">int</span> <span class="o">-&gt;</span>
  <span class="o">?</span><span class="n">tol</span><span class="o">:</span><span class="kt">float</span> <span class="o">-&gt;</span>
  <span class="o">?</span><span class="n">warm_start</span><span class="o">:</span><span class="kt">bool</span> <span class="o">-&gt;</span>
  <span class="o">?</span><span class="n">random_state</span><span class="o">:</span><span class="kt">int</span> <span class="o">-&gt;</span>
  <span class="o">?</span><span class="n">selection</span><span class="o">:</span><span class="kt">string</span> <span class="o">-&gt;</span>
  <span class="kt">unit</span> <span class="o">-&gt;</span>
  <span class="n">t</span>
</code></pre></div>

<p>Multi-task Lasso model trained with L1/L2 mixed-norm as regularizer.</p>
<p>The optimization objective for Lasso is::</p>
<div class="codehilite"><pre><span></span><code>(1 / (2 * n_samples)) * ||Y - XW||^2_Fro + alpha * ||W||_21
</code></pre></div>


<details class="info" open="open"><summary>Where::</summary><p>||W||<em>21 = \sum_i \sqrt{\sum_j w</em>{ij}^2}</p>
</details>
<p>i.e. the sum of norm of each row.</p>
<p>Read more in the :ref:<code>User Guide &lt;multi_task_lasso&gt;</code>.</p>
<h4>Parameters</h4>
<details class="info" open="open"><summary>alpha : float, optional</summary><p>Constant that multiplies the L1/L2 term. Defaults to 1.0</p>
</details>
<details class="info" open="open"><summary>fit_intercept : boolean</summary><p>whether to calculate the intercept for this model. If set
to false, no intercept will be used in calculations
(i.e. data is expected to be centered).</p>
</details>
<details class="info" open="open"><summary>normalize : boolean, optional, default False</summary><p>This parameter is ignored when <code>fit_intercept</code> is set to False.
If True, the regressors X will be normalized before regression by
subtracting the mean and dividing by the l2-norm.
If you wish to standardize, please use
:class:<code>sklearn.preprocessing.StandardScaler</code> before calling <code>fit</code>
on an estimator with <code>normalize=False</code>.</p>
</details>
<details class="info" open="open"><summary>copy_X : boolean, optional, default True</summary><p>If <code>True</code>, X will be copied; else, it may be overwritten.</p>
</details>
<details class="info" open="open"><summary>max_iter : int, optional</summary><p>The maximum number of iterations</p>
</details>
<details class="info" open="open"><summary>tol : float, optional</summary><p>The tolerance for the optimization: if the updates are
smaller than <code>tol</code>, the optimization code checks the
dual gap for optimality and continues until it is smaller
than <code>tol</code>.</p>
</details>
<details class="info" open="open"><summary>warm_start : bool, optional</summary><p>When set to <code>True</code>, reuse the solution of the previous call to fit as
initialization, otherwise, just erase the previous solution.</p>
</details>
<details class="info" open="open"><summary>See :term:<code>the Glossary &lt;warm_start&gt;</code>.</summary></details>
<details class="info" open="open"><summary>random_state : int, RandomState instance or None, optional, default None</summary><p>The seed of the pseudo random number generator that selects a random
feature to update.  If int, random_state is the seed used by the random
number generator; If RandomState instance, random_state is the random
number generator; If None, the random number generator is the
RandomState instance used by <code>np.random</code>. Used when <code>selection</code> ==
'random'.</p>
</details>
<details class="info" open="open"><summary>selection : str, default 'cyclic'</summary><p>If set to 'random', a random coefficient is updated every iteration
rather than looping over features sequentially by default. This
(setting to 'random') often leads to significantly faster convergence
especially when tol is higher than 1e-4</p>
</details>
<h4>Attributes</h4>
<details class="info" open="open"><summary>coef_ : array, shape (n_tasks, n_features)</summary><p>Parameter vector (W in the cost function formula).
Note that <code>coef_</code> stores the transpose of <code>W</code>, <code>W.T</code>.</p>
</details>
<details class="info" open="open"><summary>intercept_ : array, shape (n_tasks,)</summary><p>independent term in decision function.</p>
</details>
<details class="info" open="open"><summary>n_iter_ : int</summary><p>number of iterations run by the coordinate descent solver to reach
the specified tolerance.</p>
</details>
<h4>Examples</h4>
<div class="highlight"><pre><span></span><code><span class="o">&gt;&gt;&gt;</span> <span class="kn">from</span> <span class="nn">sklearn</span> <span class="kn">import</span> <span class="n">linear_model</span>
<span class="o">&gt;&gt;&gt;</span> <span class="n">clf</span> <span class="o">=</span> <span class="n">linear_model</span><span class="o">.</span><span class="n">MultiTaskLasso</span><span class="p">(</span><span class="n">alpha</span><span class="o">=</span><span class="mf">0.1</span><span class="p">)</span>
<span class="o">&gt;&gt;&gt;</span> <span class="n">clf</span><span class="o">.</span><span class="n">fit</span><span class="p">([[</span><span class="mi">0</span><span class="p">,</span><span class="mi">0</span><span class="p">],</span> <span class="p">[</span><span class="mi">1</span><span class="p">,</span> <span class="mi">1</span><span class="p">],</span> <span class="p">[</span><span class="mi">2</span><span class="p">,</span> <span class="mi">2</span><span class="p">]],</span> <span class="p">[[</span><span class="mi">0</span><span class="p">,</span> <span class="mi">0</span><span class="p">],</span> <span class="p">[</span><span class="mi">1</span><span class="p">,</span> <span class="mi">1</span><span class="p">],</span> <span class="p">[</span><span class="mi">2</span><span class="p">,</span> <span class="mi">2</span><span class="p">]])</span>
<span class="n">MultiTaskLasso</span><span class="p">(</span><span class="n">alpha</span><span class="o">=</span><span class="mf">0.1</span><span class="p">)</span>
<span class="o">&gt;&gt;&gt;</span> <span class="nb">print</span><span class="p">(</span><span class="n">clf</span><span class="o">.</span><span class="n">coef_</span><span class="p">)</span>
<span class="p">[[</span><span class="mf">0.89393398</span> <span class="mf">0.</span>        <span class="p">]</span>
 <span class="p">[</span><span class="mf">0.89393398</span> <span class="mf">0.</span>        <span class="p">]]</span>
<span class="o">&gt;&gt;&gt;</span> <span class="nb">print</span><span class="p">(</span><span class="n">clf</span><span class="o">.</span><span class="n">intercept_</span><span class="p">)</span>
<span class="p">[</span><span class="mf">0.10606602</span> <span class="mf">0.10606602</span><span class="p">]</span>
</code></pre></div>

<h4>See also</h4>
<details class="info" open="open"><summary>MultiTaskLasso : Multi-task L1/L2 Lasso with built-in cross-validation</summary></details>
<p>Lasso
MultiTaskElasticNet</p>
<h4>Notes</h4>
<p>The algorithm used to fit the model is coordinate descent.</p>
<p>To avoid unnecessary memory duplication the X argument of the fit method
should be directly passed as a Fortran-contiguous numpy array.</p>
</details>
<h3 id="fit_17">fit<a class="headerlink" href="#fit_17" title="Permanent link">&para;</a></h3>
<details class="note" open="open"><summary>method</summary><div class="highlight"><pre><span></span><code><span class="k">val</span> <span class="n">fit</span> <span class="o">:</span>
  <span class="n">x</span><span class="o">:</span><span class="nn">Arr</span><span class="p">.</span><span class="n">t</span> <span class="o">-&gt;</span>
  <span class="n">y</span><span class="o">:</span><span class="nn">Py</span><span class="p">.</span><span class="nn">Object</span><span class="p">.</span><span class="n">t</span> <span class="o">-&gt;</span>
  <span class="n">t</span> <span class="o">-&gt;</span>
  <span class="n">t</span>
</code></pre></div>

<p>Fit MultiTaskElasticNet model with coordinate descent</p>
<h4>Parameters</h4>
<details class="info" open="open"><summary>X : ndarray, shape (n_samples, n_features)</summary><p>Data</p>
</details>
<details class="info" open="open"><summary>y : ndarray, shape (n_samples, n_tasks)</summary><p>Target. Will be cast to X's dtype if necessary</p>
</details>
<h4>Notes</h4>
<p>Coordinate descent is an algorithm that considers each column of
data at a time hence it will automatically convert the X input
as a Fortran-contiguous numpy array if necessary.</p>
<p>To avoid memory re-allocation it is advised to allocate the
initial data in memory directly using that format.</p>
</details>
<h3 id="get_params_17">get_params<a class="headerlink" href="#get_params_17" title="Permanent link">&para;</a></h3>
<details class="note" open="open"><summary>method</summary><div class="highlight"><pre><span></span><code><span class="k">val</span> <span class="n">get_params</span> <span class="o">:</span>
  <span class="o">?</span><span class="n">deep</span><span class="o">:</span><span class="kt">bool</span> <span class="o">-&gt;</span>
  <span class="n">t</span> <span class="o">-&gt;</span>
  <span class="nn">Dict</span><span class="p">.</span><span class="n">t</span>
</code></pre></div>

<p>Get parameters for this estimator.</p>
<h4>Parameters</h4>
<details class="info" open="open"><summary>deep : bool, default=True</summary><p>If True, will return the parameters for this estimator and
contained subobjects that are estimators.</p>
</details>
<h4>Returns</h4>
<details class="info" open="open"><summary>params : mapping of string to any</summary><p>Parameter names mapped to their values.</p>
</details>
</details>
<h3 id="predict_17">predict<a class="headerlink" href="#predict_17" title="Permanent link">&para;</a></h3>
<details class="note" open="open"><summary>method</summary><div class="highlight"><pre><span></span><code><span class="k">val</span> <span class="n">predict</span> <span class="o">:</span>
  <span class="n">x</span><span class="o">:</span><span class="nn">Arr</span><span class="p">.</span><span class="n">t</span> <span class="o">-&gt;</span>
  <span class="n">t</span> <span class="o">-&gt;</span>
  <span class="nn">Arr</span><span class="p">.</span><span class="n">t</span>
</code></pre></div>

<p>Predict using the linear model.</p>
<h4>Parameters</h4>
<details class="info" open="open"><summary>X : array_like or sparse matrix, shape (n_samples, n_features)</summary><p>Samples.</p>
</details>
<h4>Returns</h4>
<details class="info" open="open"><summary>C : array, shape (n_samples,)</summary><p>Returns predicted values.</p>
</details>
</details>
<h3 id="score_17">score<a class="headerlink" href="#score_17" title="Permanent link">&para;</a></h3>
<details class="note" open="open"><summary>method</summary><div class="highlight"><pre><span></span><code><span class="k">val</span> <span class="n">score</span> <span class="o">:</span>
  <span class="o">?</span><span class="n">sample_weight</span><span class="o">:</span><span class="nn">Arr</span><span class="p">.</span><span class="n">t</span> <span class="o">-&gt;</span>
  <span class="n">x</span><span class="o">:</span><span class="nn">Arr</span><span class="p">.</span><span class="n">t</span> <span class="o">-&gt;</span>
  <span class="n">y</span><span class="o">:</span><span class="nn">Arr</span><span class="p">.</span><span class="n">t</span> <span class="o">-&gt;</span>
  <span class="n">t</span> <span class="o">-&gt;</span>
  <span class="kt">float</span>
</code></pre></div>

<p>Return the coefficient of determination R^2 of the prediction.</p>
<p>The coefficient R^2 is defined as (1 - u/v), where u is the residual
sum of squares ((y_true - y_pred) <strong> 2).sum() and v is the total
sum of squares ((y_true - y_true.mean()) </strong> 2).sum().
The best possible score is 1.0 and it can be negative (because the
model can be arbitrarily worse). A constant model that always
predicts the expected value of y, disregarding the input features,
would get a R^2 score of 0.0.</p>
<h4>Parameters</h4>
<details class="info" open="open"><summary>X : array-like of shape (n_samples, n_features)</summary><p>Test samples. For some estimators this may be a
precomputed kernel matrix or a list of generic objects instead,
shape = (n_samples, n_samples_fitted),
where n_samples_fitted is the number of
samples used in the fitting for the estimator.</p>
</details>
<details class="info" open="open"><summary>y : array-like of shape (n_samples,) or (n_samples, n_outputs)</summary><p>True values for X.</p>
</details>
<details class="info" open="open"><summary>sample_weight : array-like of shape (n_samples,), default=None</summary><p>Sample weights.</p>
</details>
<h4>Returns</h4>
<details class="info" open="open"><summary>score : float</summary><p>R^2 of self.predict(X) wrt. y.</p>
</details>
<h4>Notes</h4>
<p>The R2 score used when calling <code>score</code> on a regressor will use
<code>multioutput='uniform_average'</code> from version 0.23 to keep consistent</p>
<details class="info" open="open"><summary>with :func:<code>~sklearn.metrics.r2_score</code>. This will influence the</summary></details>
<p><code>score</code> method of all the multioutput regressors (except for
:class:<code>~sklearn.multioutput.MultiOutputRegressor</code>). To specify the
default value manually and avoid the warning, please either call
:func:<code>~sklearn.metrics.r2_score</code> directly or make a custom scorer with
:func:<code>~sklearn.metrics.make_scorer</code> (the built-in scorer <code>'r2'</code> uses
<code>multioutput='uniform_average'</code>).</p>
</details>
<h3 id="set_params_17">set_params<a class="headerlink" href="#set_params_17" title="Permanent link">&para;</a></h3>
<details class="note" open="open"><summary>method</summary><div class="highlight"><pre><span></span><code><span class="k">val</span> <span class="n">set_params</span> <span class="o">:</span>
  <span class="o">?</span><span class="n">params</span><span class="o">:(</span><span class="kt">string</span> <span class="o">*</span> <span class="nn">Py</span><span class="p">.</span><span class="nn">Object</span><span class="p">.</span><span class="n">t</span><span class="o">)</span> <span class="kt">list</span> <span class="o">-&gt;</span>
  <span class="n">t</span> <span class="o">-&gt;</span>
  <span class="n">t</span>
</code></pre></div>

<p>Set the parameters of this estimator.</p>
<p>The method works on simple estimators as well as on nested objects
(such as pipelines). The latter have parameters of the form
<code>&lt;component&gt;__&lt;parameter&gt;</code> so that it's possible to update each
component of a nested object.</p>
<h4>Parameters</h4>
<details class="info" open="open"><summary>**params : dict</summary><p>Estimator parameters.</p>
</details>
<h4>Returns</h4>
<details class="info" open="open"><summary>self : object</summary><p>Estimator instance.</p>
</details>
</details>
<h3 id="coef__17">coef_<a class="headerlink" href="#coef__17" title="Permanent link">&para;</a></h3>
<details class="note" open="open"><summary>attribute</summary><div class="highlight"><pre><span></span><code><span class="k">val</span> <span class="n">coef_</span> <span class="o">:</span> <span class="n">t</span> <span class="o">-&gt;</span> <span class="nn">Arr</span><span class="p">.</span><span class="n">t</span>
<span class="k">val</span> <span class="n">coef_opt</span> <span class="o">:</span> <span class="n">t</span> <span class="o">-&gt;</span> <span class="o">(</span><span class="nn">Arr</span><span class="p">.</span><span class="n">t</span><span class="o">)</span> <span class="n">option</span>
</code></pre></div>

<p>This attribute is documented in <code>create</code> above. The first version raises Not_found
if the attribute is None. The _opt version returns an option.</p>
</details>
<h3 id="intercept__17">intercept_<a class="headerlink" href="#intercept__17" title="Permanent link">&para;</a></h3>
<details class="note" open="open"><summary>attribute</summary><div class="highlight"><pre><span></span><code><span class="k">val</span> <span class="n">intercept_</span> <span class="o">:</span> <span class="n">t</span> <span class="o">-&gt;</span> <span class="nn">Arr</span><span class="p">.</span><span class="n">t</span>
<span class="k">val</span> <span class="n">intercept_opt</span> <span class="o">:</span> <span class="n">t</span> <span class="o">-&gt;</span> <span class="o">(</span><span class="nn">Arr</span><span class="p">.</span><span class="n">t</span><span class="o">)</span> <span class="n">option</span>
</code></pre></div>

<p>This attribute is documented in <code>create</code> above. The first version raises Not_found
if the attribute is None. The _opt version returns an option.</p>
</details>
<h3 id="n_iter__15">n_iter_<a class="headerlink" href="#n_iter__15" title="Permanent link">&para;</a></h3>
<details class="note" open="open"><summary>attribute</summary><div class="highlight"><pre><span></span><code><span class="k">val</span> <span class="n">n_iter_</span> <span class="o">:</span> <span class="n">t</span> <span class="o">-&gt;</span> <span class="kt">int</span>
<span class="k">val</span> <span class="n">n_iter_opt</span> <span class="o">:</span> <span class="n">t</span> <span class="o">-&gt;</span> <span class="o">(</span><span class="kt">int</span><span class="o">)</span> <span class="n">option</span>
</code></pre></div>

<p>This attribute is documented in <code>create</code> above. The first version raises Not_found
if the attribute is None. The _opt version returns an option.</p>
</details>
<h3 id="to_string_17">to_string<a class="headerlink" href="#to_string_17" title="Permanent link">&para;</a></h3>
<details class="note" open="open"><summary>method</summary><div class="highlight"><pre><span></span><code><span class="k">val</span> <span class="n">to_string</span><span class="o">:</span> <span class="n">t</span> <span class="o">-&gt;</span> <span class="kt">string</span>
</code></pre></div>

<p>Print the object to a human-readable representation.</p>
</details>
<h3 id="show_17">show<a class="headerlink" href="#show_17" title="Permanent link">&para;</a></h3>
<details class="note" open="open"><summary>method</summary><div class="highlight"><pre><span></span><code><span class="k">val</span> <span class="n">show</span><span class="o">:</span> <span class="n">t</span> <span class="o">-&gt;</span> <span class="kt">string</span>
</code></pre></div>

<p>Print the object to a human-readable representation.</p>
</details>
<h3 id="pp_17">pp<a class="headerlink" href="#pp_17" title="Permanent link">&para;</a></h3>
<details class="note" open="open"><summary>method</summary><div class="highlight"><pre><span></span><code><span class="k">val</span> <span class="n">pp</span><span class="o">:</span> <span class="nn">Format</span><span class="p">.</span><span class="n">formatter</span> <span class="o">-&gt;</span> <span class="n">t</span> <span class="o">-&gt;</span> <span class="kt">unit</span>
</code></pre></div>

<p>Pretty-print the object to a formatter.</p>
</details>
<h2 id="module-sklearnlinear_modelmultitasklassocv">module Sklearn.​Linear_model.​MultiTaskLassoCV<a class="headerlink" href="#module-sklearnlinear_modelmultitasklassocv" title="Permanent link">&para;</a></h2>
<div class="highlight"><pre><span></span><code><span class="k">type</span> <span class="n">t</span>
</code></pre></div>

<h3 id="create_18">create<a class="headerlink" href="#create_18" title="Permanent link">&para;</a></h3>
<details class="note" open="open"><summary>constructor and attributes</summary><div class="highlight"><pre><span></span><code><span class="k">val</span> <span class="n">create</span> <span class="o">:</span>
  <span class="o">?</span><span class="n">eps</span><span class="o">:</span><span class="kt">float</span> <span class="o">-&gt;</span>
  <span class="o">?</span><span class="n">n_alphas</span><span class="o">:</span><span class="kt">int</span> <span class="o">-&gt;</span>
  <span class="o">?</span><span class="n">alphas</span><span class="o">:</span><span class="nn">Arr</span><span class="p">.</span><span class="n">t</span> <span class="o">-&gt;</span>
  <span class="o">?</span><span class="n">fit_intercept</span><span class="o">:</span><span class="kt">bool</span> <span class="o">-&gt;</span>
  <span class="o">?</span><span class="n">normalize</span><span class="o">:</span><span class="kt">bool</span> <span class="o">-&gt;</span>
  <span class="o">?</span><span class="n">max_iter</span><span class="o">:</span><span class="kt">int</span> <span class="o">-&gt;</span>
  <span class="o">?</span><span class="n">tol</span><span class="o">:</span><span class="kt">float</span> <span class="o">-&gt;</span>
  <span class="o">?</span><span class="n">copy_X</span><span class="o">:</span><span class="kt">bool</span> <span class="o">-&gt;</span>
  <span class="o">?</span><span class="n">cv</span><span class="o">:[`</span><span class="nc">I</span> <span class="k">of</span> <span class="kt">int</span> <span class="o">|</span> <span class="o">`</span><span class="nc">CrossValGenerator</span> <span class="k">of</span> <span class="nn">Py</span><span class="p">.</span><span class="nn">Object</span><span class="p">.</span><span class="n">t</span> <span class="o">|</span> <span class="o">`</span><span class="nc">Arr</span> <span class="k">of</span> <span class="nn">Arr</span><span class="p">.</span><span class="n">t</span><span class="o">]</span> <span class="o">-&gt;</span>
  <span class="o">?</span><span class="n">verbose</span><span class="o">:</span><span class="kt">int</span> <span class="o">-&gt;</span>
  <span class="o">?</span><span class="n">n_jobs</span><span class="o">:</span><span class="kt">int</span> <span class="o">-&gt;</span>
  <span class="o">?</span><span class="n">random_state</span><span class="o">:</span><span class="kt">int</span> <span class="o">-&gt;</span>
  <span class="o">?</span><span class="n">selection</span><span class="o">:</span><span class="kt">string</span> <span class="o">-&gt;</span>
  <span class="kt">unit</span> <span class="o">-&gt;</span>
  <span class="n">t</span>
</code></pre></div>

<p>Multi-task Lasso model trained with L1/L2 mixed-norm as regularizer.</p>
<p>See glossary entry for :term:<code>cross-validation estimator</code>.</p>
<p>The optimization objective for MultiTaskLasso is::</p>
<div class="codehilite"><pre><span></span><code>(1 / (2 * n_samples)) * ||Y - XW||^Fro_2 + alpha * ||W||_21
</code></pre></div>


<details class="info" open="open"><summary>Where::</summary><p>||W||<em>21 = \sum_i \sqrt{\sum_j w</em>{ij}^2}</p>
</details>
<p>i.e. the sum of norm of each row.</p>
<p>Read more in the :ref:<code>User Guide &lt;multi_task_lasso&gt;</code>.</p>
<p>.. versionadded:: 0.15</p>
<h4>Parameters</h4>
<details class="info" open="open"><summary>eps : float, optional</summary><p>Length of the path. <code>eps=1e-3</code> means that
<code>alpha_min / alpha_max = 1e-3</code>.</p>
</details>
<details class="info" open="open"><summary>n_alphas : int, optional</summary><p>Number of alphas along the regularization path</p>
</details>
<details class="info" open="open"><summary>alphas : array-like, optional</summary><p>List of alphas where to compute the models.
If not provided, set automatically.</p>
</details>
<details class="info" open="open"><summary>fit_intercept : boolean</summary><p>whether to calculate the intercept for this model. If set
to false, no intercept will be used in calculations
(i.e. data is expected to be centered).</p>
</details>
<details class="info" open="open"><summary>normalize : boolean, optional, default False</summary><p>This parameter is ignored when <code>fit_intercept</code> is set to False.
If True, the regressors X will be normalized before regression by
subtracting the mean and dividing by the l2-norm.
If you wish to standardize, please use
:class:<code>sklearn.preprocessing.StandardScaler</code> before calling <code>fit</code>
on an estimator with <code>normalize=False</code>.</p>
</details>
<details class="info" open="open"><summary>max_iter : int, optional</summary><p>The maximum number of iterations.</p>
</details>
<details class="info" open="open"><summary>tol : float, optional</summary><p>The tolerance for the optimization: if the updates are
smaller than <code>tol</code>, the optimization code checks the
dual gap for optimality and continues until it is smaller
than <code>tol</code>.</p>
</details>
<details class="info" open="open"><summary>copy_X : boolean, optional, default True</summary><p>If <code>True</code>, X will be copied; else, it may be overwritten.</p>
</details>
<details class="info" open="open"><summary>cv : int, cross-validation generator or an iterable, optional</summary><p>Determines the cross-validation splitting strategy.
Possible inputs for cv are:</p>
<ul>
<li>None, to use the default 5-fold cross-validation,</li>
<li>integer, to specify the number of folds.</li>
<li>:term:<code>CV splitter</code>,</li>
<li>An iterable yielding (train, test) splits as arrays of indices.</li>
</ul>
<p>For integer/None inputs, :class:<code>KFold</code> is used.</p>
</details>
<details class="info" open="open"><summary>Refer :ref:<code>User Guide &lt;cross_validation&gt;</code> for the various</summary><p>cross-validation strategies that can be used here.</p>
<p>.. versionchanged:: 0.22
    <code>cv</code> default value if None changed from 3-fold to 5-fold.</p>
</details>
<details class="info" open="open"><summary>verbose : bool or integer</summary><p>Amount of verbosity.</p>
</details>
<details class="info" open="open"><summary>n_jobs : int or None, optional (default=None)</summary><p>Number of CPUs to use during the cross validation. Note that this is
used only if multiple values for l1_ratio are given.
<code>None</code> means 1 unless in a :obj:<code>joblib.parallel_backend</code> context.
<code>-1</code> means using all processors. See :term:<code>Glossary &lt;n_jobs&gt;</code>
for more details.</p>
</details>
<details class="info" open="open"><summary>random_state : int, RandomState instance or None, optional, default None</summary><p>The seed of the pseudo random number generator that selects a random
feature to update.  If int, random_state is the seed used by the random
number generator; If RandomState instance, random_state is the random
number generator; If None, the random number generator is the
RandomState instance used by <code>np.random</code>. Used when <code>selection</code> ==
'random'</p>
</details>
<details class="info" open="open"><summary>selection : str, default 'cyclic'</summary><p>If set to 'random', a random coefficient is updated every iteration
rather than looping over features sequentially by default. This
(setting to 'random') often leads to significantly faster convergence
especially when tol is higher than 1e-4.</p>
</details>
<h4>Attributes</h4>
<details class="info" open="open"><summary>intercept_ : array, shape (n_tasks,)</summary><p>Independent term in decision function.</p>
</details>
<details class="info" open="open"><summary>coef_ : array, shape (n_tasks, n_features)</summary><p>Parameter vector (W in the cost function formula).
Note that <code>coef_</code> stores the transpose of <code>W</code>, <code>W.T</code>.</p>
</details>
<details class="info" open="open"><summary>alpha_ : float</summary><p>The amount of penalization chosen by cross validation</p>
</details>
<details class="info" open="open"><summary>mse_path_ : array, shape (n_alphas, n_folds)</summary><p>mean square error for the test set on each fold, varying alpha</p>
</details>
<details class="info" open="open"><summary>alphas_ : numpy array, shape (n_alphas,)</summary><p>The grid of alphas used for fitting.</p>
</details>
<details class="info" open="open"><summary>n_iter_ : int</summary><p>number of iterations run by the coordinate descent solver to reach
the specified tolerance for the optimal alpha.</p>
</details>
<h4>Examples</h4>
<div class="highlight"><pre><span></span><code><span class="o">&gt;&gt;&gt;</span> <span class="kn">from</span> <span class="nn">sklearn.linear_model</span> <span class="kn">import</span> <span class="n">MultiTaskLassoCV</span>
<span class="o">&gt;&gt;&gt;</span> <span class="kn">from</span> <span class="nn">sklearn.datasets</span> <span class="kn">import</span> <span class="n">make_regression</span>
<span class="o">&gt;&gt;&gt;</span> <span class="kn">from</span> <span class="nn">sklearn.metrics</span> <span class="kn">import</span> <span class="n">r2_score</span>
<span class="o">&gt;&gt;&gt;</span> <span class="n">X</span><span class="p">,</span> <span class="n">y</span> <span class="o">=</span> <span class="n">make_regression</span><span class="p">(</span><span class="n">n_targets</span><span class="o">=</span><span class="mi">2</span><span class="p">,</span> <span class="n">noise</span><span class="o">=</span><span class="mi">4</span><span class="p">,</span> <span class="n">random_state</span><span class="o">=</span><span class="mi">0</span><span class="p">)</span>
<span class="o">&gt;&gt;&gt;</span> <span class="n">reg</span> <span class="o">=</span> <span class="n">MultiTaskLassoCV</span><span class="p">(</span><span class="n">cv</span><span class="o">=</span><span class="mi">5</span><span class="p">,</span> <span class="n">random_state</span><span class="o">=</span><span class="mi">0</span><span class="p">)</span><span class="o">.</span><span class="n">fit</span><span class="p">(</span><span class="n">X</span><span class="p">,</span> <span class="n">y</span><span class="p">)</span>
<span class="o">&gt;&gt;&gt;</span> <span class="n">r2_score</span><span class="p">(</span><span class="n">y</span><span class="p">,</span> <span class="n">reg</span><span class="o">.</span><span class="n">predict</span><span class="p">(</span><span class="n">X</span><span class="p">))</span>
<span class="mf">0.9994</span><span class="o">...</span>
<span class="o">&gt;&gt;&gt;</span> <span class="n">reg</span><span class="o">.</span><span class="n">alpha_</span>
<span class="mf">0.5713</span><span class="o">...</span>
<span class="o">&gt;&gt;&gt;</span> <span class="n">reg</span><span class="o">.</span><span class="n">predict</span><span class="p">(</span><span class="n">X</span><span class="p">[:</span><span class="mi">1</span><span class="p">,])</span>
<span class="n">array</span><span class="p">([[</span><span class="mf">153.7971</span><span class="o">...</span><span class="p">,</span>  <span class="mf">94.9015</span><span class="o">...</span><span class="p">]])</span>
</code></pre></div>

<h4>See also</h4>
<p>MultiTaskElasticNet
ElasticNetCV
MultiTaskElasticNetCV</p>
<h4>Notes</h4>
<p>The algorithm used to fit the model is coordinate descent.</p>
<p>To avoid unnecessary memory duplication the X argument of the fit method
should be directly passed as a Fortran-contiguous numpy array.</p>
</details>
<h3 id="fit_18">fit<a class="headerlink" href="#fit_18" title="Permanent link">&para;</a></h3>
<details class="note" open="open"><summary>method</summary><div class="highlight"><pre><span></span><code><span class="k">val</span> <span class="n">fit</span> <span class="o">:</span>
  <span class="n">x</span><span class="o">:</span><span class="nn">Arr</span><span class="p">.</span><span class="n">t</span> <span class="o">-&gt;</span>
  <span class="n">y</span><span class="o">:</span><span class="nn">Arr</span><span class="p">.</span><span class="n">t</span> <span class="o">-&gt;</span>
  <span class="n">t</span> <span class="o">-&gt;</span>
  <span class="n">t</span>
</code></pre></div>

<p>Fit linear model with coordinate descent</p>
<p>Fit is on grid of alphas and best alpha estimated by cross-validation.</p>
<h4>Parameters</h4>
<details class="info" open="open"><summary>X : {array-like}, shape (n_samples, n_features)</summary><p>Training data. Pass directly as Fortran-contiguous data
to avoid unnecessary memory duplication. If y is mono-output,
X can be sparse.</p>
</details>
<details class="info" open="open"><summary>y : array-like, shape (n_samples,) or (n_samples, n_targets)</summary><p>Target values</p>
</details>
</details>
<h3 id="get_params_18">get_params<a class="headerlink" href="#get_params_18" title="Permanent link">&para;</a></h3>
<details class="note" open="open"><summary>method</summary><div class="highlight"><pre><span></span><code><span class="k">val</span> <span class="n">get_params</span> <span class="o">:</span>
  <span class="o">?</span><span class="n">deep</span><span class="o">:</span><span class="kt">bool</span> <span class="o">-&gt;</span>
  <span class="n">t</span> <span class="o">-&gt;</span>
  <span class="nn">Dict</span><span class="p">.</span><span class="n">t</span>
</code></pre></div>

<p>Get parameters for this estimator.</p>
<h4>Parameters</h4>
<details class="info" open="open"><summary>deep : bool, default=True</summary><p>If True, will return the parameters for this estimator and
contained subobjects that are estimators.</p>
</details>
<h4>Returns</h4>
<details class="info" open="open"><summary>params : mapping of string to any</summary><p>Parameter names mapped to their values.</p>
</details>
</details>
<h3 id="predict_18">predict<a class="headerlink" href="#predict_18" title="Permanent link">&para;</a></h3>
<details class="note" open="open"><summary>method</summary><div class="highlight"><pre><span></span><code><span class="k">val</span> <span class="n">predict</span> <span class="o">:</span>
  <span class="n">x</span><span class="o">:</span><span class="nn">Arr</span><span class="p">.</span><span class="n">t</span> <span class="o">-&gt;</span>
  <span class="n">t</span> <span class="o">-&gt;</span>
  <span class="nn">Arr</span><span class="p">.</span><span class="n">t</span>
</code></pre></div>

<p>Predict using the linear model.</p>
<h4>Parameters</h4>
<details class="info" open="open"><summary>X : array_like or sparse matrix, shape (n_samples, n_features)</summary><p>Samples.</p>
</details>
<h4>Returns</h4>
<details class="info" open="open"><summary>C : array, shape (n_samples,)</summary><p>Returns predicted values.</p>
</details>
</details>
<h3 id="score_18">score<a class="headerlink" href="#score_18" title="Permanent link">&para;</a></h3>
<details class="note" open="open"><summary>method</summary><div class="highlight"><pre><span></span><code><span class="k">val</span> <span class="n">score</span> <span class="o">:</span>
  <span class="o">?</span><span class="n">sample_weight</span><span class="o">:</span><span class="nn">Arr</span><span class="p">.</span><span class="n">t</span> <span class="o">-&gt;</span>
  <span class="n">x</span><span class="o">:</span><span class="nn">Arr</span><span class="p">.</span><span class="n">t</span> <span class="o">-&gt;</span>
  <span class="n">y</span><span class="o">:</span><span class="nn">Arr</span><span class="p">.</span><span class="n">t</span> <span class="o">-&gt;</span>
  <span class="n">t</span> <span class="o">-&gt;</span>
  <span class="kt">float</span>
</code></pre></div>

<p>Return the coefficient of determination R^2 of the prediction.</p>
<p>The coefficient R^2 is defined as (1 - u/v), where u is the residual
sum of squares ((y_true - y_pred) <strong> 2).sum() and v is the total
sum of squares ((y_true - y_true.mean()) </strong> 2).sum().
The best possible score is 1.0 and it can be negative (because the
model can be arbitrarily worse). A constant model that always
predicts the expected value of y, disregarding the input features,
would get a R^2 score of 0.0.</p>
<h4>Parameters</h4>
<details class="info" open="open"><summary>X : array-like of shape (n_samples, n_features)</summary><p>Test samples. For some estimators this may be a
precomputed kernel matrix or a list of generic objects instead,
shape = (n_samples, n_samples_fitted),
where n_samples_fitted is the number of
samples used in the fitting for the estimator.</p>
</details>
<details class="info" open="open"><summary>y : array-like of shape (n_samples,) or (n_samples, n_outputs)</summary><p>True values for X.</p>
</details>
<details class="info" open="open"><summary>sample_weight : array-like of shape (n_samples,), default=None</summary><p>Sample weights.</p>
</details>
<h4>Returns</h4>
<details class="info" open="open"><summary>score : float</summary><p>R^2 of self.predict(X) wrt. y.</p>
</details>
<h4>Notes</h4>
<p>The R2 score used when calling <code>score</code> on a regressor will use
<code>multioutput='uniform_average'</code> from version 0.23 to keep consistent</p>
<details class="info" open="open"><summary>with :func:<code>~sklearn.metrics.r2_score</code>. This will influence the</summary></details>
<p><code>score</code> method of all the multioutput regressors (except for
:class:<code>~sklearn.multioutput.MultiOutputRegressor</code>). To specify the
default value manually and avoid the warning, please either call
:func:<code>~sklearn.metrics.r2_score</code> directly or make a custom scorer with
:func:<code>~sklearn.metrics.make_scorer</code> (the built-in scorer <code>'r2'</code> uses
<code>multioutput='uniform_average'</code>).</p>
</details>
<h3 id="set_params_18">set_params<a class="headerlink" href="#set_params_18" title="Permanent link">&para;</a></h3>
<details class="note" open="open"><summary>method</summary><div class="highlight"><pre><span></span><code><span class="k">val</span> <span class="n">set_params</span> <span class="o">:</span>
  <span class="o">?</span><span class="n">params</span><span class="o">:(</span><span class="kt">string</span> <span class="o">*</span> <span class="nn">Py</span><span class="p">.</span><span class="nn">Object</span><span class="p">.</span><span class="n">t</span><span class="o">)</span> <span class="kt">list</span> <span class="o">-&gt;</span>
  <span class="n">t</span> <span class="o">-&gt;</span>
  <span class="n">t</span>
</code></pre></div>

<p>Set the parameters of this estimator.</p>
<p>The method works on simple estimators as well as on nested objects
(such as pipelines). The latter have parameters of the form
<code>&lt;component&gt;__&lt;parameter&gt;</code> so that it's possible to update each
component of a nested object.</p>
<h4>Parameters</h4>
<details class="info" open="open"><summary>**params : dict</summary><p>Estimator parameters.</p>
</details>
<h4>Returns</h4>
<details class="info" open="open"><summary>self : object</summary><p>Estimator instance.</p>
</details>
</details>
<h3 id="intercept__18">intercept_<a class="headerlink" href="#intercept__18" title="Permanent link">&para;</a></h3>
<details class="note" open="open"><summary>attribute</summary><div class="highlight"><pre><span></span><code><span class="k">val</span> <span class="n">intercept_</span> <span class="o">:</span> <span class="n">t</span> <span class="o">-&gt;</span> <span class="nn">Arr</span><span class="p">.</span><span class="n">t</span>
<span class="k">val</span> <span class="n">intercept_opt</span> <span class="o">:</span> <span class="n">t</span> <span class="o">-&gt;</span> <span class="o">(</span><span class="nn">Arr</span><span class="p">.</span><span class="n">t</span><span class="o">)</span> <span class="n">option</span>
</code></pre></div>

<p>This attribute is documented in <code>create</code> above. The first version raises Not_found
if the attribute is None. The _opt version returns an option.</p>
</details>
<h3 id="coef__18">coef_<a class="headerlink" href="#coef__18" title="Permanent link">&para;</a></h3>
<details class="note" open="open"><summary>attribute</summary><div class="highlight"><pre><span></span><code><span class="k">val</span> <span class="n">coef_</span> <span class="o">:</span> <span class="n">t</span> <span class="o">-&gt;</span> <span class="nn">Arr</span><span class="p">.</span><span class="n">t</span>
<span class="k">val</span> <span class="n">coef_opt</span> <span class="o">:</span> <span class="n">t</span> <span class="o">-&gt;</span> <span class="o">(</span><span class="nn">Arr</span><span class="p">.</span><span class="n">t</span><span class="o">)</span> <span class="n">option</span>
</code></pre></div>

<p>This attribute is documented in <code>create</code> above. The first version raises Not_found
if the attribute is None. The _opt version returns an option.</p>
</details>
<h3 id="alpha__8">alpha_<a class="headerlink" href="#alpha__8" title="Permanent link">&para;</a></h3>
<details class="note" open="open"><summary>attribute</summary><div class="highlight"><pre><span></span><code><span class="k">val</span> <span class="n">alpha_</span> <span class="o">:</span> <span class="n">t</span> <span class="o">-&gt;</span> <span class="kt">float</span>
<span class="k">val</span> <span class="n">alpha_opt</span> <span class="o">:</span> <span class="n">t</span> <span class="o">-&gt;</span> <span class="o">(</span><span class="kt">float</span><span class="o">)</span> <span class="n">option</span>
</code></pre></div>

<p>This attribute is documented in <code>create</code> above. The first version raises Not_found
if the attribute is None. The _opt version returns an option.</p>
</details>
<h3 id="mse_path__5">mse_path_<a class="headerlink" href="#mse_path__5" title="Permanent link">&para;</a></h3>
<details class="note" open="open"><summary>attribute</summary><div class="highlight"><pre><span></span><code><span class="k">val</span> <span class="n">mse_path_</span> <span class="o">:</span> <span class="n">t</span> <span class="o">-&gt;</span> <span class="nn">Arr</span><span class="p">.</span><span class="n">t</span>
<span class="k">val</span> <span class="n">mse_path_opt</span> <span class="o">:</span> <span class="n">t</span> <span class="o">-&gt;</span> <span class="o">(</span><span class="nn">Arr</span><span class="p">.</span><span class="n">t</span><span class="o">)</span> <span class="n">option</span>
</code></pre></div>

<p>This attribute is documented in <code>create</code> above. The first version raises Not_found
if the attribute is None. The _opt version returns an option.</p>
</details>
<h3 id="alphas__7">alphas_<a class="headerlink" href="#alphas__7" title="Permanent link">&para;</a></h3>
<details class="note" open="open"><summary>attribute</summary><div class="highlight"><pre><span></span><code><span class="k">val</span> <span class="n">alphas_</span> <span class="o">:</span> <span class="n">t</span> <span class="o">-&gt;</span> <span class="nn">Arr</span><span class="p">.</span><span class="n">t</span>
<span class="k">val</span> <span class="n">alphas_opt</span> <span class="o">:</span> <span class="n">t</span> <span class="o">-&gt;</span> <span class="o">(</span><span class="nn">Arr</span><span class="p">.</span><span class="n">t</span><span class="o">)</span> <span class="n">option</span>
</code></pre></div>

<p>This attribute is documented in <code>create</code> above. The first version raises Not_found
if the attribute is None. The _opt version returns an option.</p>
</details>
<h3 id="n_iter__16">n_iter_<a class="headerlink" href="#n_iter__16" title="Permanent link">&para;</a></h3>
<details class="note" open="open"><summary>attribute</summary><div class="highlight"><pre><span></span><code><span class="k">val</span> <span class="n">n_iter_</span> <span class="o">:</span> <span class="n">t</span> <span class="o">-&gt;</span> <span class="kt">int</span>
<span class="k">val</span> <span class="n">n_iter_opt</span> <span class="o">:</span> <span class="n">t</span> <span class="o">-&gt;</span> <span class="o">(</span><span class="kt">int</span><span class="o">)</span> <span class="n">option</span>
</code></pre></div>

<p>This attribute is documented in <code>create</code> above. The first version raises Not_found
if the attribute is None. The _opt version returns an option.</p>
</details>
<h3 id="to_string_18">to_string<a class="headerlink" href="#to_string_18" title="Permanent link">&para;</a></h3>
<details class="note" open="open"><summary>method</summary><div class="highlight"><pre><span></span><code><span class="k">val</span> <span class="n">to_string</span><span class="o">:</span> <span class="n">t</span> <span class="o">-&gt;</span> <span class="kt">string</span>
</code></pre></div>

<p>Print the object to a human-readable representation.</p>
</details>
<h3 id="show_18">show<a class="headerlink" href="#show_18" title="Permanent link">&para;</a></h3>
<details class="note" open="open"><summary>method</summary><div class="highlight"><pre><span></span><code><span class="k">val</span> <span class="n">show</span><span class="o">:</span> <span class="n">t</span> <span class="o">-&gt;</span> <span class="kt">string</span>
</code></pre></div>

<p>Print the object to a human-readable representation.</p>
</details>
<h3 id="pp_18">pp<a class="headerlink" href="#pp_18" title="Permanent link">&para;</a></h3>
<details class="note" open="open"><summary>method</summary><div class="highlight"><pre><span></span><code><span class="k">val</span> <span class="n">pp</span><span class="o">:</span> <span class="nn">Format</span><span class="p">.</span><span class="n">formatter</span> <span class="o">-&gt;</span> <span class="n">t</span> <span class="o">-&gt;</span> <span class="kt">unit</span>
</code></pre></div>

<p>Pretty-print the object to a formatter.</p>
</details>
<h2 id="module-sklearnlinear_modelorthogonalmatchingpursuit">module Sklearn.​Linear_model.​OrthogonalMatchingPursuit<a class="headerlink" href="#module-sklearnlinear_modelorthogonalmatchingpursuit" title="Permanent link">&para;</a></h2>
<div class="highlight"><pre><span></span><code><span class="k">type</span> <span class="n">t</span>
</code></pre></div>

<h3 id="create_19">create<a class="headerlink" href="#create_19" title="Permanent link">&para;</a></h3>
<details class="note" open="open"><summary>constructor and attributes</summary><div class="highlight"><pre><span></span><code><span class="k">val</span> <span class="n">create</span> <span class="o">:</span>
  <span class="o">?</span><span class="n">n_nonzero_coefs</span><span class="o">:</span><span class="kt">int</span> <span class="o">-&gt;</span>
  <span class="o">?</span><span class="n">tol</span><span class="o">:</span><span class="kt">float</span> <span class="o">-&gt;</span>
  <span class="o">?</span><span class="n">fit_intercept</span><span class="o">:</span><span class="kt">bool</span> <span class="o">-&gt;</span>
  <span class="o">?</span><span class="n">normalize</span><span class="o">:</span><span class="kt">bool</span> <span class="o">-&gt;</span>
  <span class="o">?</span><span class="n">precompute</span><span class="o">:[`</span><span class="nc">Bool</span> <span class="k">of</span> <span class="kt">bool</span> <span class="o">|</span> <span class="o">`</span><span class="nc">Auto</span><span class="o">]</span> <span class="o">-&gt;</span>
  <span class="kt">unit</span> <span class="o">-&gt;</span>
  <span class="n">t</span>
</code></pre></div>

<p>Orthogonal Matching Pursuit model (OMP)</p>
<p>Read more in the :ref:<code>User Guide &lt;omp&gt;</code>.</p>
<h4>Parameters</h4>
<details class="info" open="open"><summary>n_nonzero_coefs : int, optional</summary><p>Desired number of non-zero entries in the solution. If None (by
default) this value is set to 10% of n_features.</p>
</details>
<details class="info" open="open"><summary>tol : float, optional</summary><p>Maximum norm of the residual. If not None, overrides n_nonzero_coefs.</p>
</details>
<details class="info" open="open"><summary>fit_intercept : boolean, optional</summary><p>whether to calculate the intercept for this model. If set
to false, no intercept will be used in calculations
(i.e. data is expected to be centered).</p>
</details>
<details class="info" open="open"><summary>normalize : boolean, optional, default True</summary><p>This parameter is ignored when <code>fit_intercept</code> is set to False.
If True, the regressors X will be normalized before regression by
subtracting the mean and dividing by the l2-norm.
If you wish to standardize, please use
:class:<code>sklearn.preprocessing.StandardScaler</code> before calling <code>fit</code>
on an estimator with <code>normalize=False</code>.</p>
</details>
<details class="info" open="open"><summary>precompute : {True, False, 'auto'}, default 'auto'</summary><p>Whether to use a precomputed Gram and Xy matrix to speed up
calculations. Improves performance when :term:<code>n_targets</code> or
:term:<code>n_samples</code> is very large. Note that if you already have such
matrices, you can pass them directly to the fit method.</p>
</details>
<h4>Attributes</h4>
<details class="info" open="open"><summary>coef_ : array, shape (n_features,) or (n_targets, n_features)</summary><p>parameter vector (w in the formula)</p>
</details>
<details class="info" open="open"><summary>intercept_ : float or array, shape (n_targets,)</summary><p>independent term in decision function.</p>
</details>
<details class="info" open="open"><summary>n_iter_ : int or array-like</summary><p>Number of active features across every target.</p>
</details>
<h4>Examples</h4>
<div class="highlight"><pre><span></span><code><span class="o">&gt;&gt;&gt;</span> <span class="kn">from</span> <span class="nn">sklearn.linear_model</span> <span class="kn">import</span> <span class="n">OrthogonalMatchingPursuit</span>
<span class="o">&gt;&gt;&gt;</span> <span class="kn">from</span> <span class="nn">sklearn.datasets</span> <span class="kn">import</span> <span class="n">make_regression</span>
<span class="o">&gt;&gt;&gt;</span> <span class="n">X</span><span class="p">,</span> <span class="n">y</span> <span class="o">=</span> <span class="n">make_regression</span><span class="p">(</span><span class="n">noise</span><span class="o">=</span><span class="mi">4</span><span class="p">,</span> <span class="n">random_state</span><span class="o">=</span><span class="mi">0</span><span class="p">)</span>
<span class="o">&gt;&gt;&gt;</span> <span class="n">reg</span> <span class="o">=</span> <span class="n">OrthogonalMatchingPursuit</span><span class="p">()</span><span class="o">.</span><span class="n">fit</span><span class="p">(</span><span class="n">X</span><span class="p">,</span> <span class="n">y</span><span class="p">)</span>
<span class="o">&gt;&gt;&gt;</span> <span class="n">reg</span><span class="o">.</span><span class="n">score</span><span class="p">(</span><span class="n">X</span><span class="p">,</span> <span class="n">y</span><span class="p">)</span>
<span class="mf">0.9991</span><span class="o">...</span>
<span class="o">&gt;&gt;&gt;</span> <span class="n">reg</span><span class="o">.</span><span class="n">predict</span><span class="p">(</span><span class="n">X</span><span class="p">[:</span><span class="mi">1</span><span class="p">,])</span>
<span class="n">array</span><span class="p">([</span><span class="o">-</span><span class="mf">78.3854</span><span class="o">...</span><span class="p">])</span>
</code></pre></div>

<h4>Notes</h4>
<p>Orthogonal matching pursuit was introduced in G. Mallat, Z. Zhang,
Matching pursuits with time-frequency dictionaries, IEEE Transactions on
Signal Processing, Vol. 41, No. 12. (December 1993), pp. 3397-3415.
(http://blanche.polytechnique.fr/~mallat/papiers/MallatPursuit93.pdf)</p>
<p>This implementation is based on Rubinstein, R., Zibulevsky, M. and Elad,
M., Efficient Implementation of the K-SVD Algorithm using Batch Orthogonal
Matching Pursuit Technical Report - CS Technion, April 2008.</p>
<details class="info" open="open"><summary>https://www.cs.technion.ac.il/~ronrubin/Publications/KSVD-OMP-v2.pdf</summary></details>
<h4>See also</h4>
<p>orthogonal_mp
orthogonal_mp_gram
lars_path
Lars
LassoLars
decomposition.sparse_encode
OrthogonalMatchingPursuitCV</p>
</details>
<h3 id="fit_19">fit<a class="headerlink" href="#fit_19" title="Permanent link">&para;</a></h3>
<details class="note" open="open"><summary>method</summary><div class="highlight"><pre><span></span><code><span class="k">val</span> <span class="n">fit</span> <span class="o">:</span>
  <span class="n">x</span><span class="o">:</span><span class="nn">Arr</span><span class="p">.</span><span class="n">t</span> <span class="o">-&gt;</span>
  <span class="n">y</span><span class="o">:</span><span class="nn">Arr</span><span class="p">.</span><span class="n">t</span> <span class="o">-&gt;</span>
  <span class="n">t</span> <span class="o">-&gt;</span>
  <span class="n">t</span>
</code></pre></div>

<p>Fit the model using X, y as training data.</p>
<h4>Parameters</h4>
<details class="info" open="open"><summary>X : array-like, shape (n_samples, n_features)</summary><p>Training data.</p>
</details>
<details class="info" open="open"><summary>y : array-like, shape (n_samples,) or (n_samples, n_targets)</summary><p>Target values. Will be cast to X's dtype if necessary</p>
</details>
<h4>Returns</h4>
<details class="info" open="open"><summary>self : object</summary><p>returns an instance of self.</p>
</details>
</details>
<h3 id="get_params_19">get_params<a class="headerlink" href="#get_params_19" title="Permanent link">&para;</a></h3>
<details class="note" open="open"><summary>method</summary><div class="highlight"><pre><span></span><code><span class="k">val</span> <span class="n">get_params</span> <span class="o">:</span>
  <span class="o">?</span><span class="n">deep</span><span class="o">:</span><span class="kt">bool</span> <span class="o">-&gt;</span>
  <span class="n">t</span> <span class="o">-&gt;</span>
  <span class="nn">Dict</span><span class="p">.</span><span class="n">t</span>
</code></pre></div>

<p>Get parameters for this estimator.</p>
<h4>Parameters</h4>
<details class="info" open="open"><summary>deep : bool, default=True</summary><p>If True, will return the parameters for this estimator and
contained subobjects that are estimators.</p>
</details>
<h4>Returns</h4>
<details class="info" open="open"><summary>params : mapping of string to any</summary><p>Parameter names mapped to their values.</p>
</details>
</details>
<h3 id="predict_19">predict<a class="headerlink" href="#predict_19" title="Permanent link">&para;</a></h3>
<details class="note" open="open"><summary>method</summary><div class="highlight"><pre><span></span><code><span class="k">val</span> <span class="n">predict</span> <span class="o">:</span>
  <span class="n">x</span><span class="o">:</span><span class="nn">Arr</span><span class="p">.</span><span class="n">t</span> <span class="o">-&gt;</span>
  <span class="n">t</span> <span class="o">-&gt;</span>
  <span class="nn">Arr</span><span class="p">.</span><span class="n">t</span>
</code></pre></div>

<p>Predict using the linear model.</p>
<h4>Parameters</h4>
<details class="info" open="open"><summary>X : array_like or sparse matrix, shape (n_samples, n_features)</summary><p>Samples.</p>
</details>
<h4>Returns</h4>
<details class="info" open="open"><summary>C : array, shape (n_samples,)</summary><p>Returns predicted values.</p>
</details>
</details>
<h3 id="score_19">score<a class="headerlink" href="#score_19" title="Permanent link">&para;</a></h3>
<details class="note" open="open"><summary>method</summary><div class="highlight"><pre><span></span><code><span class="k">val</span> <span class="n">score</span> <span class="o">:</span>
  <span class="o">?</span><span class="n">sample_weight</span><span class="o">:</span><span class="nn">Arr</span><span class="p">.</span><span class="n">t</span> <span class="o">-&gt;</span>
  <span class="n">x</span><span class="o">:</span><span class="nn">Arr</span><span class="p">.</span><span class="n">t</span> <span class="o">-&gt;</span>
  <span class="n">y</span><span class="o">:</span><span class="nn">Arr</span><span class="p">.</span><span class="n">t</span> <span class="o">-&gt;</span>
  <span class="n">t</span> <span class="o">-&gt;</span>
  <span class="kt">float</span>
</code></pre></div>

<p>Return the coefficient of determination R^2 of the prediction.</p>
<p>The coefficient R^2 is defined as (1 - u/v), where u is the residual
sum of squares ((y_true - y_pred) <strong> 2).sum() and v is the total
sum of squares ((y_true - y_true.mean()) </strong> 2).sum().
The best possible score is 1.0 and it can be negative (because the
model can be arbitrarily worse). A constant model that always
predicts the expected value of y, disregarding the input features,
would get a R^2 score of 0.0.</p>
<h4>Parameters</h4>
<details class="info" open="open"><summary>X : array-like of shape (n_samples, n_features)</summary><p>Test samples. For some estimators this may be a
precomputed kernel matrix or a list of generic objects instead,
shape = (n_samples, n_samples_fitted),
where n_samples_fitted is the number of
samples used in the fitting for the estimator.</p>
</details>
<details class="info" open="open"><summary>y : array-like of shape (n_samples,) or (n_samples, n_outputs)</summary><p>True values for X.</p>
</details>
<details class="info" open="open"><summary>sample_weight : array-like of shape (n_samples,), default=None</summary><p>Sample weights.</p>
</details>
<h4>Returns</h4>
<details class="info" open="open"><summary>score : float</summary><p>R^2 of self.predict(X) wrt. y.</p>
</details>
<h4>Notes</h4>
<p>The R2 score used when calling <code>score</code> on a regressor will use
<code>multioutput='uniform_average'</code> from version 0.23 to keep consistent</p>
<details class="info" open="open"><summary>with :func:<code>~sklearn.metrics.r2_score</code>. This will influence the</summary></details>
<p><code>score</code> method of all the multioutput regressors (except for
:class:<code>~sklearn.multioutput.MultiOutputRegressor</code>). To specify the
default value manually and avoid the warning, please either call
:func:<code>~sklearn.metrics.r2_score</code> directly or make a custom scorer with
:func:<code>~sklearn.metrics.make_scorer</code> (the built-in scorer <code>'r2'</code> uses
<code>multioutput='uniform_average'</code>).</p>
</details>
<h3 id="set_params_19">set_params<a class="headerlink" href="#set_params_19" title="Permanent link">&para;</a></h3>
<details class="note" open="open"><summary>method</summary><div class="highlight"><pre><span></span><code><span class="k">val</span> <span class="n">set_params</span> <span class="o">:</span>
  <span class="o">?</span><span class="n">params</span><span class="o">:(</span><span class="kt">string</span> <span class="o">*</span> <span class="nn">Py</span><span class="p">.</span><span class="nn">Object</span><span class="p">.</span><span class="n">t</span><span class="o">)</span> <span class="kt">list</span> <span class="o">-&gt;</span>
  <span class="n">t</span> <span class="o">-&gt;</span>
  <span class="n">t</span>
</code></pre></div>

<p>Set the parameters of this estimator.</p>
<p>The method works on simple estimators as well as on nested objects
(such as pipelines). The latter have parameters of the form
<code>&lt;component&gt;__&lt;parameter&gt;</code> so that it's possible to update each
component of a nested object.</p>
<h4>Parameters</h4>
<details class="info" open="open"><summary>**params : dict</summary><p>Estimator parameters.</p>
</details>
<h4>Returns</h4>
<details class="info" open="open"><summary>self : object</summary><p>Estimator instance.</p>
</details>
</details>
<h3 id="coef__19">coef_<a class="headerlink" href="#coef__19" title="Permanent link">&para;</a></h3>
<details class="note" open="open"><summary>attribute</summary><div class="highlight"><pre><span></span><code><span class="k">val</span> <span class="n">coef_</span> <span class="o">:</span> <span class="n">t</span> <span class="o">-&gt;</span> <span class="nn">Arr</span><span class="p">.</span><span class="n">t</span>
<span class="k">val</span> <span class="n">coef_opt</span> <span class="o">:</span> <span class="n">t</span> <span class="o">-&gt;</span> <span class="o">(</span><span class="nn">Arr</span><span class="p">.</span><span class="n">t</span><span class="o">)</span> <span class="n">option</span>
</code></pre></div>

<p>This attribute is documented in <code>create</code> above. The first version raises Not_found
if the attribute is None. The _opt version returns an option.</p>
</details>
<h3 id="intercept__19">intercept_<a class="headerlink" href="#intercept__19" title="Permanent link">&para;</a></h3>
<details class="note" open="open"><summary>attribute</summary><div class="highlight"><pre><span></span><code><span class="k">val</span> <span class="n">intercept_</span> <span class="o">:</span> <span class="n">t</span> <span class="o">-&gt;</span> <span class="nn">Arr</span><span class="p">.</span><span class="n">t</span>
<span class="k">val</span> <span class="n">intercept_opt</span> <span class="o">:</span> <span class="n">t</span> <span class="o">-&gt;</span> <span class="o">(</span><span class="nn">Arr</span><span class="p">.</span><span class="n">t</span><span class="o">)</span> <span class="n">option</span>
</code></pre></div>

<p>This attribute is documented in <code>create</code> above. The first version raises Not_found
if the attribute is None. The _opt version returns an option.</p>
</details>
<h3 id="n_iter__17">n_iter_<a class="headerlink" href="#n_iter__17" title="Permanent link">&para;</a></h3>
<details class="note" open="open"><summary>attribute</summary><div class="highlight"><pre><span></span><code><span class="k">val</span> <span class="n">n_iter_</span> <span class="o">:</span> <span class="n">t</span> <span class="o">-&gt;</span> <span class="o">[`</span><span class="nc">I</span> <span class="k">of</span> <span class="kt">int</span> <span class="o">|</span> <span class="o">`</span><span class="nc">Arr</span> <span class="k">of</span> <span class="nn">Arr</span><span class="p">.</span><span class="n">t</span><span class="o">]</span>
<span class="k">val</span> <span class="n">n_iter_opt</span> <span class="o">:</span> <span class="n">t</span> <span class="o">-&gt;</span> <span class="o">([`</span><span class="nc">I</span> <span class="k">of</span> <span class="kt">int</span> <span class="o">|</span> <span class="o">`</span><span class="nc">Arr</span> <span class="k">of</span> <span class="nn">Arr</span><span class="p">.</span><span class="n">t</span><span class="o">])</span> <span class="n">option</span>
</code></pre></div>

<p>This attribute is documented in <code>create</code> above. The first version raises Not_found
if the attribute is None. The _opt version returns an option.</p>
</details>
<h3 id="to_string_19">to_string<a class="headerlink" href="#to_string_19" title="Permanent link">&para;</a></h3>
<details class="note" open="open"><summary>method</summary><div class="highlight"><pre><span></span><code><span class="k">val</span> <span class="n">to_string</span><span class="o">:</span> <span class="n">t</span> <span class="o">-&gt;</span> <span class="kt">string</span>
</code></pre></div>

<p>Print the object to a human-readable representation.</p>
</details>
<h3 id="show_19">show<a class="headerlink" href="#show_19" title="Permanent link">&para;</a></h3>
<details class="note" open="open"><summary>method</summary><div class="highlight"><pre><span></span><code><span class="k">val</span> <span class="n">show</span><span class="o">:</span> <span class="n">t</span> <span class="o">-&gt;</span> <span class="kt">string</span>
</code></pre></div>

<p>Print the object to a human-readable representation.</p>
</details>
<h3 id="pp_19">pp<a class="headerlink" href="#pp_19" title="Permanent link">&para;</a></h3>
<details class="note" open="open"><summary>method</summary><div class="highlight"><pre><span></span><code><span class="k">val</span> <span class="n">pp</span><span class="o">:</span> <span class="nn">Format</span><span class="p">.</span><span class="n">formatter</span> <span class="o">-&gt;</span> <span class="n">t</span> <span class="o">-&gt;</span> <span class="kt">unit</span>
</code></pre></div>

<p>Pretty-print the object to a formatter.</p>
</details>
<h2 id="module-sklearnlinear_modelorthogonalmatchingpursuitcv">module Sklearn.​Linear_model.​OrthogonalMatchingPursuitCV<a class="headerlink" href="#module-sklearnlinear_modelorthogonalmatchingpursuitcv" title="Permanent link">&para;</a></h2>
<div class="highlight"><pre><span></span><code><span class="k">type</span> <span class="n">t</span>
</code></pre></div>

<h3 id="create_20">create<a class="headerlink" href="#create_20" title="Permanent link">&para;</a></h3>
<details class="note" open="open"><summary>constructor and attributes</summary><div class="highlight"><pre><span></span><code><span class="k">val</span> <span class="n">create</span> <span class="o">:</span>
  <span class="o">?</span><span class="n">copy</span><span class="o">:</span><span class="kt">bool</span> <span class="o">-&gt;</span>
  <span class="o">?</span><span class="n">fit_intercept</span><span class="o">:</span><span class="kt">bool</span> <span class="o">-&gt;</span>
  <span class="o">?</span><span class="n">normalize</span><span class="o">:</span><span class="kt">bool</span> <span class="o">-&gt;</span>
  <span class="o">?</span><span class="n">max_iter</span><span class="o">:</span><span class="kt">int</span> <span class="o">-&gt;</span>
  <span class="o">?</span><span class="n">cv</span><span class="o">:[`</span><span class="nc">I</span> <span class="k">of</span> <span class="kt">int</span> <span class="o">|</span> <span class="o">`</span><span class="nc">CrossValGenerator</span> <span class="k">of</span> <span class="nn">Py</span><span class="p">.</span><span class="nn">Object</span><span class="p">.</span><span class="n">t</span> <span class="o">|</span> <span class="o">`</span><span class="nc">Arr</span> <span class="k">of</span> <span class="nn">Arr</span><span class="p">.</span><span class="n">t</span><span class="o">]</span> <span class="o">-&gt;</span>
  <span class="o">?</span><span class="n">n_jobs</span><span class="o">:</span><span class="kt">int</span> <span class="o">-&gt;</span>
  <span class="o">?</span><span class="n">verbose</span><span class="o">:</span><span class="kt">int</span> <span class="o">-&gt;</span>
  <span class="kt">unit</span> <span class="o">-&gt;</span>
  <span class="n">t</span>
</code></pre></div>

<p>Cross-validated Orthogonal Matching Pursuit model (OMP).</p>
<p>See glossary entry for :term:<code>cross-validation estimator</code>.</p>
<p>Read more in the :ref:<code>User Guide &lt;omp&gt;</code>.</p>
<h4>Parameters</h4>
<details class="info" open="open"><summary>copy : bool, optional</summary><p>Whether the design matrix X must be copied by the algorithm. A false
value is only helpful if X is already Fortran-ordered, otherwise a
copy is made anyway.</p>
</details>
<details class="info" open="open"><summary>fit_intercept : boolean, optional</summary><p>whether to calculate the intercept for this model. If set
to false, no intercept will be used in calculations
(i.e. data is expected to be centered).</p>
</details>
<details class="info" open="open"><summary>normalize : boolean, optional, default True</summary><p>This parameter is ignored when <code>fit_intercept</code> is set to False.
If True, the regressors X will be normalized before regression by
subtracting the mean and dividing by the l2-norm.
If you wish to standardize, please use
:class:<code>sklearn.preprocessing.StandardScaler</code> before calling <code>fit</code>
on an estimator with <code>normalize=False</code>.</p>
</details>
<details class="info" open="open"><summary>max_iter : integer, optional</summary><p>Maximum numbers of iterations to perform, therefore maximum features
to include. 10% of <code>n_features</code> but at least 5 if available.</p>
</details>
<details class="info" open="open"><summary>cv : int, cross-validation generator or an iterable, optional</summary><p>Determines the cross-validation splitting strategy.
Possible inputs for cv are:</p>
<ul>
<li>None, to use the default 5-fold cross-validation,</li>
<li>integer, to specify the number of folds.</li>
<li>:term:<code>CV splitter</code>,</li>
<li>An iterable yielding (train, test) splits as arrays of indices.</li>
</ul>
<p>For integer/None inputs, :class:<code>KFold</code> is used.</p>
</details>
<details class="info" open="open"><summary>Refer :ref:<code>User Guide &lt;cross_validation&gt;</code> for the various</summary><p>cross-validation strategies that can be used here.</p>
<p>.. versionchanged:: 0.22
    <code>cv</code> default value if None changed from 3-fold to 5-fold.</p>
</details>
<details class="info" open="open"><summary>n_jobs : int or None, optional (default=None)</summary><p>Number of CPUs to use during the cross validation.
<code>None</code> means 1 unless in a :obj:<code>joblib.parallel_backend</code> context.
<code>-1</code> means using all processors. See :term:<code>Glossary &lt;n_jobs&gt;</code>
for more details.</p>
</details>
<details class="info" open="open"><summary>verbose : boolean or integer, optional</summary><p>Sets the verbosity amount</p>
</details>
<h4>Attributes</h4>
<details class="info" open="open"><summary>intercept_ : float or array, shape (n_targets,)</summary><p>Independent term in decision function.</p>
</details>
<details class="info" open="open"><summary>coef_ : array, shape (n_features,) or (n_targets, n_features)</summary><p>Parameter vector (w in the problem formulation).</p>
</details>
<details class="info" open="open"><summary>n_nonzero_coefs_ : int</summary><p>Estimated number of non-zero coefficients giving the best mean squared
error over the cross-validation folds.</p>
</details>
<details class="info" open="open"><summary>n_iter_ : int or array-like</summary><p>Number of active features across every target for the model refit with
the best hyperparameters got by cross-validating across all folds.</p>
</details>
<h4>Examples</h4>
<div class="highlight"><pre><span></span><code><span class="o">&gt;&gt;&gt;</span> <span class="kn">from</span> <span class="nn">sklearn.linear_model</span> <span class="kn">import</span> <span class="n">OrthogonalMatchingPursuitCV</span>
<span class="o">&gt;&gt;&gt;</span> <span class="kn">from</span> <span class="nn">sklearn.datasets</span> <span class="kn">import</span> <span class="n">make_regression</span>
<span class="o">&gt;&gt;&gt;</span> <span class="n">X</span><span class="p">,</span> <span class="n">y</span> <span class="o">=</span> <span class="n">make_regression</span><span class="p">(</span><span class="n">n_features</span><span class="o">=</span><span class="mi">100</span><span class="p">,</span> <span class="n">n_informative</span><span class="o">=</span><span class="mi">10</span><span class="p">,</span>
<span class="o">...</span>                        <span class="n">noise</span><span class="o">=</span><span class="mi">4</span><span class="p">,</span> <span class="n">random_state</span><span class="o">=</span><span class="mi">0</span><span class="p">)</span>
<span class="o">&gt;&gt;&gt;</span> <span class="n">reg</span> <span class="o">=</span> <span class="n">OrthogonalMatchingPursuitCV</span><span class="p">(</span><span class="n">cv</span><span class="o">=</span><span class="mi">5</span><span class="p">)</span><span class="o">.</span><span class="n">fit</span><span class="p">(</span><span class="n">X</span><span class="p">,</span> <span class="n">y</span><span class="p">)</span>
<span class="o">&gt;&gt;&gt;</span> <span class="n">reg</span><span class="o">.</span><span class="n">score</span><span class="p">(</span><span class="n">X</span><span class="p">,</span> <span class="n">y</span><span class="p">)</span>
<span class="mf">0.9991</span><span class="o">...</span>
<span class="o">&gt;&gt;&gt;</span> <span class="n">reg</span><span class="o">.</span><span class="n">n_nonzero_coefs_</span>
<span class="mi">10</span>
<span class="o">&gt;&gt;&gt;</span> <span class="n">reg</span><span class="o">.</span><span class="n">predict</span><span class="p">(</span><span class="n">X</span><span class="p">[:</span><span class="mi">1</span><span class="p">,])</span>
<span class="n">array</span><span class="p">([</span><span class="o">-</span><span class="mf">78.3854</span><span class="o">...</span><span class="p">])</span>
</code></pre></div>

<h4>See also</h4>
<p>orthogonal_mp
orthogonal_mp_gram
lars_path
Lars
LassoLars
OrthogonalMatchingPursuit
LarsCV
LassoLarsCV
decomposition.sparse_encode</p>
</details>
<h3 id="fit_20">fit<a class="headerlink" href="#fit_20" title="Permanent link">&para;</a></h3>
<details class="note" open="open"><summary>method</summary><div class="highlight"><pre><span></span><code><span class="k">val</span> <span class="n">fit</span> <span class="o">:</span>
  <span class="n">x</span><span class="o">:</span><span class="nn">Arr</span><span class="p">.</span><span class="n">t</span> <span class="o">-&gt;</span>
  <span class="n">y</span><span class="o">:</span><span class="nn">Arr</span><span class="p">.</span><span class="n">t</span> <span class="o">-&gt;</span>
  <span class="n">t</span> <span class="o">-&gt;</span>
  <span class="n">t</span>
</code></pre></div>

<p>Fit the model using X, y as training data.</p>
<h4>Parameters</h4>
<details class="info" open="open"><summary>X : array-like, shape [n_samples, n_features]</summary><p>Training data.</p>
</details>
<details class="info" open="open"><summary>y : array-like, shape [n_samples]</summary><p>Target values. Will be cast to X's dtype if necessary</p>
</details>
<h4>Returns</h4>
<details class="info" open="open"><summary>self : object</summary><p>returns an instance of self.</p>
</details>
</details>
<h3 id="get_params_20">get_params<a class="headerlink" href="#get_params_20" title="Permanent link">&para;</a></h3>
<details class="note" open="open"><summary>method</summary><div class="highlight"><pre><span></span><code><span class="k">val</span> <span class="n">get_params</span> <span class="o">:</span>
  <span class="o">?</span><span class="n">deep</span><span class="o">:</span><span class="kt">bool</span> <span class="o">-&gt;</span>
  <span class="n">t</span> <span class="o">-&gt;</span>
  <span class="nn">Dict</span><span class="p">.</span><span class="n">t</span>
</code></pre></div>

<p>Get parameters for this estimator.</p>
<h4>Parameters</h4>
<details class="info" open="open"><summary>deep : bool, default=True</summary><p>If True, will return the parameters for this estimator and
contained subobjects that are estimators.</p>
</details>
<h4>Returns</h4>
<details class="info" open="open"><summary>params : mapping of string to any</summary><p>Parameter names mapped to their values.</p>
</details>
</details>
<h3 id="predict_20">predict<a class="headerlink" href="#predict_20" title="Permanent link">&para;</a></h3>
<details class="note" open="open"><summary>method</summary><div class="highlight"><pre><span></span><code><span class="k">val</span> <span class="n">predict</span> <span class="o">:</span>
  <span class="n">x</span><span class="o">:</span><span class="nn">Arr</span><span class="p">.</span><span class="n">t</span> <span class="o">-&gt;</span>
  <span class="n">t</span> <span class="o">-&gt;</span>
  <span class="nn">Arr</span><span class="p">.</span><span class="n">t</span>
</code></pre></div>

<p>Predict using the linear model.</p>
<h4>Parameters</h4>
<details class="info" open="open"><summary>X : array_like or sparse matrix, shape (n_samples, n_features)</summary><p>Samples.</p>
</details>
<h4>Returns</h4>
<details class="info" open="open"><summary>C : array, shape (n_samples,)</summary><p>Returns predicted values.</p>
</details>
</details>
<h3 id="score_20">score<a class="headerlink" href="#score_20" title="Permanent link">&para;</a></h3>
<details class="note" open="open"><summary>method</summary><div class="highlight"><pre><span></span><code><span class="k">val</span> <span class="n">score</span> <span class="o">:</span>
  <span class="o">?</span><span class="n">sample_weight</span><span class="o">:</span><span class="nn">Arr</span><span class="p">.</span><span class="n">t</span> <span class="o">-&gt;</span>
  <span class="n">x</span><span class="o">:</span><span class="nn">Arr</span><span class="p">.</span><span class="n">t</span> <span class="o">-&gt;</span>
  <span class="n">y</span><span class="o">:</span><span class="nn">Arr</span><span class="p">.</span><span class="n">t</span> <span class="o">-&gt;</span>
  <span class="n">t</span> <span class="o">-&gt;</span>
  <span class="kt">float</span>
</code></pre></div>

<p>Return the coefficient of determination R^2 of the prediction.</p>
<p>The coefficient R^2 is defined as (1 - u/v), where u is the residual
sum of squares ((y_true - y_pred) <strong> 2).sum() and v is the total
sum of squares ((y_true - y_true.mean()) </strong> 2).sum().
The best possible score is 1.0 and it can be negative (because the
model can be arbitrarily worse). A constant model that always
predicts the expected value of y, disregarding the input features,
would get a R^2 score of 0.0.</p>
<h4>Parameters</h4>
<details class="info" open="open"><summary>X : array-like of shape (n_samples, n_features)</summary><p>Test samples. For some estimators this may be a
precomputed kernel matrix or a list of generic objects instead,
shape = (n_samples, n_samples_fitted),
where n_samples_fitted is the number of
samples used in the fitting for the estimator.</p>
</details>
<details class="info" open="open"><summary>y : array-like of shape (n_samples,) or (n_samples, n_outputs)</summary><p>True values for X.</p>
</details>
<details class="info" open="open"><summary>sample_weight : array-like of shape (n_samples,), default=None</summary><p>Sample weights.</p>
</details>
<h4>Returns</h4>
<details class="info" open="open"><summary>score : float</summary><p>R^2 of self.predict(X) wrt. y.</p>
</details>
<h4>Notes</h4>
<p>The R2 score used when calling <code>score</code> on a regressor will use
<code>multioutput='uniform_average'</code> from version 0.23 to keep consistent</p>
<details class="info" open="open"><summary>with :func:<code>~sklearn.metrics.r2_score</code>. This will influence the</summary></details>
<p><code>score</code> method of all the multioutput regressors (except for
:class:<code>~sklearn.multioutput.MultiOutputRegressor</code>). To specify the
default value manually and avoid the warning, please either call
:func:<code>~sklearn.metrics.r2_score</code> directly or make a custom scorer with
:func:<code>~sklearn.metrics.make_scorer</code> (the built-in scorer <code>'r2'</code> uses
<code>multioutput='uniform_average'</code>).</p>
</details>
<h3 id="set_params_20">set_params<a class="headerlink" href="#set_params_20" title="Permanent link">&para;</a></h3>
<details class="note" open="open"><summary>method</summary><div class="highlight"><pre><span></span><code><span class="k">val</span> <span class="n">set_params</span> <span class="o">:</span>
  <span class="o">?</span><span class="n">params</span><span class="o">:(</span><span class="kt">string</span> <span class="o">*</span> <span class="nn">Py</span><span class="p">.</span><span class="nn">Object</span><span class="p">.</span><span class="n">t</span><span class="o">)</span> <span class="kt">list</span> <span class="o">-&gt;</span>
  <span class="n">t</span> <span class="o">-&gt;</span>
  <span class="n">t</span>
</code></pre></div>

<p>Set the parameters of this estimator.</p>
<p>The method works on simple estimators as well as on nested objects
(such as pipelines). The latter have parameters of the form
<code>&lt;component&gt;__&lt;parameter&gt;</code> so that it's possible to update each
component of a nested object.</p>
<h4>Parameters</h4>
<details class="info" open="open"><summary>**params : dict</summary><p>Estimator parameters.</p>
</details>
<h4>Returns</h4>
<details class="info" open="open"><summary>self : object</summary><p>Estimator instance.</p>
</details>
</details>
<h3 id="intercept__20">intercept_<a class="headerlink" href="#intercept__20" title="Permanent link">&para;</a></h3>
<details class="note" open="open"><summary>attribute</summary><div class="highlight"><pre><span></span><code><span class="k">val</span> <span class="n">intercept_</span> <span class="o">:</span> <span class="n">t</span> <span class="o">-&gt;</span> <span class="nn">Arr</span><span class="p">.</span><span class="n">t</span>
<span class="k">val</span> <span class="n">intercept_opt</span> <span class="o">:</span> <span class="n">t</span> <span class="o">-&gt;</span> <span class="o">(</span><span class="nn">Arr</span><span class="p">.</span><span class="n">t</span><span class="o">)</span> <span class="n">option</span>
</code></pre></div>

<p>This attribute is documented in <code>create</code> above. The first version raises Not_found
if the attribute is None. The _opt version returns an option.</p>
</details>
<h3 id="coef__20">coef_<a class="headerlink" href="#coef__20" title="Permanent link">&para;</a></h3>
<details class="note" open="open"><summary>attribute</summary><div class="highlight"><pre><span></span><code><span class="k">val</span> <span class="n">coef_</span> <span class="o">:</span> <span class="n">t</span> <span class="o">-&gt;</span> <span class="nn">Arr</span><span class="p">.</span><span class="n">t</span>
<span class="k">val</span> <span class="n">coef_opt</span> <span class="o">:</span> <span class="n">t</span> <span class="o">-&gt;</span> <span class="o">(</span><span class="nn">Arr</span><span class="p">.</span><span class="n">t</span><span class="o">)</span> <span class="n">option</span>
</code></pre></div>

<p>This attribute is documented in <code>create</code> above. The first version raises Not_found
if the attribute is None. The _opt version returns an option.</p>
</details>
<h3 id="n_nonzero_coefs_">n_nonzero_coefs_<a class="headerlink" href="#n_nonzero_coefs_" title="Permanent link">&para;</a></h3>
<details class="note" open="open"><summary>attribute</summary><div class="highlight"><pre><span></span><code><span class="k">val</span> <span class="n">n_nonzero_coefs_</span> <span class="o">:</span> <span class="n">t</span> <span class="o">-&gt;</span> <span class="kt">int</span>
<span class="k">val</span> <span class="n">n_nonzero_coefs_opt</span> <span class="o">:</span> <span class="n">t</span> <span class="o">-&gt;</span> <span class="o">(</span><span class="kt">int</span><span class="o">)</span> <span class="n">option</span>
</code></pre></div>

<p>This attribute is documented in <code>create</code> above. The first version raises Not_found
if the attribute is None. The _opt version returns an option.</p>
</details>
<h3 id="n_iter__18">n_iter_<a class="headerlink" href="#n_iter__18" title="Permanent link">&para;</a></h3>
<details class="note" open="open"><summary>attribute</summary><div class="highlight"><pre><span></span><code><span class="k">val</span> <span class="n">n_iter_</span> <span class="o">:</span> <span class="n">t</span> <span class="o">-&gt;</span> <span class="o">[`</span><span class="nc">I</span> <span class="k">of</span> <span class="kt">int</span> <span class="o">|</span> <span class="o">`</span><span class="nc">Arr</span> <span class="k">of</span> <span class="nn">Arr</span><span class="p">.</span><span class="n">t</span><span class="o">]</span>
<span class="k">val</span> <span class="n">n_iter_opt</span> <span class="o">:</span> <span class="n">t</span> <span class="o">-&gt;</span> <span class="o">([`</span><span class="nc">I</span> <span class="k">of</span> <span class="kt">int</span> <span class="o">|</span> <span class="o">`</span><span class="nc">Arr</span> <span class="k">of</span> <span class="nn">Arr</span><span class="p">.</span><span class="n">t</span><span class="o">])</span> <span class="n">option</span>
</code></pre></div>

<p>This attribute is documented in <code>create</code> above. The first version raises Not_found
if the attribute is None. The _opt version returns an option.</p>
</details>
<h3 id="to_string_20">to_string<a class="headerlink" href="#to_string_20" title="Permanent link">&para;</a></h3>
<details class="note" open="open"><summary>method</summary><div class="highlight"><pre><span></span><code><span class="k">val</span> <span class="n">to_string</span><span class="o">:</span> <span class="n">t</span> <span class="o">-&gt;</span> <span class="kt">string</span>
</code></pre></div>

<p>Print the object to a human-readable representation.</p>
</details>
<h3 id="show_20">show<a class="headerlink" href="#show_20" title="Permanent link">&para;</a></h3>
<details class="note" open="open"><summary>method</summary><div class="highlight"><pre><span></span><code><span class="k">val</span> <span class="n">show</span><span class="o">:</span> <span class="n">t</span> <span class="o">-&gt;</span> <span class="kt">string</span>
</code></pre></div>

<p>Print the object to a human-readable representation.</p>
</details>
<h3 id="pp_20">pp<a class="headerlink" href="#pp_20" title="Permanent link">&para;</a></h3>
<details class="note" open="open"><summary>method</summary><div class="highlight"><pre><span></span><code><span class="k">val</span> <span class="n">pp</span><span class="o">:</span> <span class="nn">Format</span><span class="p">.</span><span class="n">formatter</span> <span class="o">-&gt;</span> <span class="n">t</span> <span class="o">-&gt;</span> <span class="kt">unit</span>
</code></pre></div>

<p>Pretty-print the object to a formatter.</p>
</details>
<h2 id="module-sklearnlinear_modelransacregressor">module Sklearn.​Linear_model.​RANSACRegressor<a class="headerlink" href="#module-sklearnlinear_modelransacregressor" title="Permanent link">&para;</a></h2>
<div class="highlight"><pre><span></span><code><span class="k">type</span> <span class="n">t</span>
</code></pre></div>

<h3 id="create_21">create<a class="headerlink" href="#create_21" title="Permanent link">&para;</a></h3>
<details class="note" open="open"><summary>constructor and attributes</summary><div class="highlight"><pre><span></span><code><span class="k">val</span> <span class="n">create</span> <span class="o">:</span>
  <span class="o">?</span><span class="n">base_estimator</span><span class="o">:</span><span class="nn">Py</span><span class="p">.</span><span class="nn">Object</span><span class="p">.</span><span class="n">t</span> <span class="o">-&gt;</span>
  <span class="o">?</span><span class="n">min_samples</span><span class="o">:[`</span><span class="nc">I</span> <span class="k">of</span> <span class="kt">int</span> <span class="o">|</span> <span class="o">`</span><span class="nc">F</span> <span class="k">of</span> <span class="kt">float</span><span class="o">]</span> <span class="o">-&gt;</span>
  <span class="o">?</span><span class="n">residual_threshold</span><span class="o">:</span><span class="kt">float</span> <span class="o">-&gt;</span>
  <span class="o">?</span><span class="n">is_data_valid</span><span class="o">:</span><span class="nn">Py</span><span class="p">.</span><span class="nn">Object</span><span class="p">.</span><span class="n">t</span> <span class="o">-&gt;</span>
  <span class="o">?</span><span class="n">is_model_valid</span><span class="o">:</span><span class="nn">Py</span><span class="p">.</span><span class="nn">Object</span><span class="p">.</span><span class="n">t</span> <span class="o">-&gt;</span>
  <span class="o">?</span><span class="n">max_trials</span><span class="o">:</span><span class="kt">int</span> <span class="o">-&gt;</span>
  <span class="o">?</span><span class="n">max_skips</span><span class="o">:</span><span class="kt">int</span> <span class="o">-&gt;</span>
  <span class="o">?</span><span class="n">stop_n_inliers</span><span class="o">:</span><span class="kt">int</span> <span class="o">-&gt;</span>
  <span class="o">?</span><span class="n">stop_score</span><span class="o">:</span><span class="kt">float</span> <span class="o">-&gt;</span>
  <span class="o">?</span><span class="n">stop_probability</span><span class="o">:</span><span class="kt">float</span> <span class="o">-&gt;</span>
  <span class="o">?</span><span class="n">loss</span><span class="o">:[`</span><span class="nc">S</span> <span class="k">of</span> <span class="kt">string</span> <span class="o">|</span> <span class="o">`</span><span class="nc">Callable</span> <span class="k">of</span> <span class="nn">Py</span><span class="p">.</span><span class="nn">Object</span><span class="p">.</span><span class="n">t</span><span class="o">]</span> <span class="o">-&gt;</span>
  <span class="o">?</span><span class="n">random_state</span><span class="o">:</span><span class="kt">int</span> <span class="o">-&gt;</span>
  <span class="kt">unit</span> <span class="o">-&gt;</span>
  <span class="n">t</span>
</code></pre></div>

<p>RANSAC (RANdom SAmple Consensus) algorithm.</p>
<p>RANSAC is an iterative algorithm for the robust estimation of parameters
from a subset of inliers from the complete data set.</p>
<p>Read more in the :ref:<code>User Guide &lt;ransac_regression&gt;</code>.</p>
<h4>Parameters</h4>
<details class="info" open="open"><summary>base_estimator : object, optional</summary><p>Base estimator object which implements the following methods:</p>
<ul>
<li><code>fit(X, y)</code>: Fit model to given training data and target values.</li>
<li><code>score(X, y)</code>: Returns the mean accuracy on the given test data,
   which is used for the stop criterion defined by <code>stop_score</code>.
   Additionally, the score is used to decide which of two equally
   large consensus sets is chosen as the better one.</li>
<li><code>predict(X)</code>: Returns predicted values using the linear model,
   which is used to compute residual error using loss function.</li>
</ul>
<p>If <code>base_estimator</code> is None, then
<code>base_estimator=sklearn.linear_model.LinearRegression()</code> is used for
target values of dtype float.</p>
<p>Note that the current implementation only supports regression
estimators.</p>
</details>
<details class="info" open="open"><summary>min_samples : int (&gt;= 1) or float ([0, 1]), optional</summary><p>Minimum number of samples chosen randomly from original data. Treated
as an absolute number of samples for <code>min_samples &gt;= 1</code>, treated as a
relative number <code>ceil(min_samples * X.shape[0]</code>) for
<code>min_samples &lt; 1</code>. This is typically chosen as the minimal number of
samples necessary to estimate the given <code>base_estimator</code>. By default a
<code>sklearn.linear_model.LinearRegression()</code> estimator is assumed and
<code>min_samples</code> is chosen as <code>X.shape[1] + 1</code>.</p>
</details>
<details class="info" open="open"><summary>residual_threshold : float, optional</summary><p>Maximum residual for a data sample to be classified as an inlier.
By default the threshold is chosen as the MAD (median absolute
deviation) of the target values <code>y</code>.</p>
</details>
<details class="info" open="open"><summary>is_data_valid : callable, optional</summary><p>This function is called with the randomly selected data before the
model is fitted to it: <code>is_data_valid(X, y)</code>. If its return value is
False the current randomly chosen sub-sample is skipped.</p>
</details>
<details class="info" open="open"><summary>is_model_valid : callable, optional</summary><p>This function is called with the estimated model and the randomly
selected data: <code>is_model_valid(model, X, y)</code>. If its return value is
False the current randomly chosen sub-sample is skipped.
Rejecting samples with this function is computationally costlier than
with <code>is_data_valid</code>. <code>is_model_valid</code> should therefore only be used if
the estimated model is needed for making the rejection decision.</p>
</details>
<details class="info" open="open"><summary>max_trials : int, optional</summary><p>Maximum number of iterations for random sample selection.</p>
</details>
<details class="info" open="open"><summary>max_skips : int, optional</summary><p>Maximum number of iterations that can be skipped due to finding zero
inliers or invalid data defined by <code>is_data_valid</code> or invalid models
defined by <code>is_model_valid</code>.</p>
<p>.. versionadded:: 0.19</p>
</details>
<details class="info" open="open"><summary>stop_n_inliers : int, optional</summary><p>Stop iteration if at least this number of inliers are found.</p>
</details>
<details class="info" open="open"><summary>stop_score : float, optional</summary><p>Stop iteration if score is greater equal than this threshold.</p>
</details>
<details class="info" open="open"><summary>stop_probability : float in range [0, 1], optional</summary><p>RANSAC iteration stops if at least one outlier-free set of the training
data is sampled in RANSAC. This requires to generate at least N
samples (iterations)::</p>
<div class="codehilite"><pre><span></span><code>N &gt;= log(1 - probability) / log(1 - e**m)
</code></pre></div>


<p>where the probability (confidence) is typically set to high value such
as 0.99 (the default) and e is the current fraction of inliers w.r.t.
the total number of samples.</p>
</details>
<details class="info" open="open"><summary>loss : string, callable, optional, default "absolute_loss"</summary><p>String inputs, "absolute_loss" and "squared_loss" are supported which
find the absolute loss and squared loss per sample
respectively.</p>
<p>If <code>loss</code> is a callable, then it should be a function that takes
two arrays as inputs, the true and predicted value and returns a 1-D
array with the i-th value of the array corresponding to the loss
on <code>X[i]</code>.</p>
<p>If the loss on a sample is greater than the <code>residual_threshold</code>,
then this sample is classified as an outlier.</p>
</details>
<details class="info" open="open"><summary>random_state : int, RandomState instance or None, optional, default None</summary><p>The generator used to initialize the centers.  If int, random_state is
the seed used by the random number generator; If RandomState instance,
random_state is the random number generator; If None, the random number
generator is the RandomState instance used by <code>np.random</code>.</p>
</details>
<h4>Attributes</h4>
<details class="info" open="open"><summary>estimator_ : object</summary><p>Best fitted model (copy of the <code>base_estimator</code> object).</p>
</details>
<details class="info" open="open"><summary>n_trials_ : int</summary><p>Number of random selection trials until one of the stop criteria is
met. It is always <code>&lt;= max_trials</code>.</p>
</details>
<details class="info" open="open"><summary>inlier_mask_ : bool array of shape [n_samples]</summary><p>Boolean mask of inliers classified as <code>True</code>.</p>
</details>
<details class="info" open="open"><summary>n_skips_no_inliers_ : int</summary><p>Number of iterations skipped due to finding zero inliers.</p>
<p>.. versionadded:: 0.19</p>
</details>
<details class="info" open="open"><summary>n_skips_invalid_data_ : int</summary><p>Number of iterations skipped due to invalid data defined by
<code>is_data_valid</code>.</p>
<p>.. versionadded:: 0.19</p>
</details>
<details class="info" open="open"><summary>n_skips_invalid_model_ : int</summary><p>Number of iterations skipped due to an invalid model defined by
<code>is_model_valid</code>.</p>
<p>.. versionadded:: 0.19</p>
</details>
<h4>Examples</h4>
<div class="highlight"><pre><span></span><code><span class="o">&gt;&gt;&gt;</span> <span class="kn">from</span> <span class="nn">sklearn.linear_model</span> <span class="kn">import</span> <span class="n">RANSACRegressor</span>
<span class="o">&gt;&gt;&gt;</span> <span class="kn">from</span> <span class="nn">sklearn.datasets</span> <span class="kn">import</span> <span class="n">make_regression</span>
<span class="o">&gt;&gt;&gt;</span> <span class="n">X</span><span class="p">,</span> <span class="n">y</span> <span class="o">=</span> <span class="n">make_regression</span><span class="p">(</span>
<span class="o">...</span>     <span class="n">n_samples</span><span class="o">=</span><span class="mi">200</span><span class="p">,</span> <span class="n">n_features</span><span class="o">=</span><span class="mi">2</span><span class="p">,</span> <span class="n">noise</span><span class="o">=</span><span class="mf">4.0</span><span class="p">,</span> <span class="n">random_state</span><span class="o">=</span><span class="mi">0</span><span class="p">)</span>
<span class="o">&gt;&gt;&gt;</span> <span class="n">reg</span> <span class="o">=</span> <span class="n">RANSACRegressor</span><span class="p">(</span><span class="n">random_state</span><span class="o">=</span><span class="mi">0</span><span class="p">)</span><span class="o">.</span><span class="n">fit</span><span class="p">(</span><span class="n">X</span><span class="p">,</span> <span class="n">y</span><span class="p">)</span>
<span class="o">&gt;&gt;&gt;</span> <span class="n">reg</span><span class="o">.</span><span class="n">score</span><span class="p">(</span><span class="n">X</span><span class="p">,</span> <span class="n">y</span><span class="p">)</span>
<span class="mf">0.9885</span><span class="o">...</span>
<span class="o">&gt;&gt;&gt;</span> <span class="n">reg</span><span class="o">.</span><span class="n">predict</span><span class="p">(</span><span class="n">X</span><span class="p">[:</span><span class="mi">1</span><span class="p">,])</span>
<span class="n">array</span><span class="p">([</span><span class="o">-</span><span class="mf">31.9417</span><span class="o">...</span><span class="p">])</span>
</code></pre></div>

<h4>References</h4>
<p>.. [1] https://en.wikipedia.org/wiki/RANSAC
.. [2] https://www.sri.com/sites/default/files/publications/ransac-publication.pdf
.. [3] http://www.bmva.org/bmvc/2009/Papers/Paper355/Paper355.pdf</p>
</details>
<h3 id="fit_21">fit<a class="headerlink" href="#fit_21" title="Permanent link">&para;</a></h3>
<details class="note" open="open"><summary>method</summary><div class="highlight"><pre><span></span><code><span class="k">val</span> <span class="n">fit</span> <span class="o">:</span>
  <span class="o">?</span><span class="n">sample_weight</span><span class="o">:</span><span class="nn">Arr</span><span class="p">.</span><span class="n">t</span> <span class="o">-&gt;</span>
  <span class="n">x</span><span class="o">:</span><span class="nn">Arr</span><span class="p">.</span><span class="n">t</span> <span class="o">-&gt;</span>
  <span class="n">y</span><span class="o">:</span><span class="nn">Arr</span><span class="p">.</span><span class="n">t</span> <span class="o">-&gt;</span>
  <span class="n">t</span> <span class="o">-&gt;</span>
  <span class="n">t</span>
</code></pre></div>

<p>Fit estimator using RANSAC algorithm.</p>
<h4>Parameters</h4>
<details class="info" open="open"><summary>X : array-like or sparse matrix, shape [n_samples, n_features]</summary><p>Training data.</p>
</details>
<details class="info" open="open"><summary>y : array-like of shape (n_samples,) or (n_samples, n_targets)</summary><p>Target values.</p>
</details>
<details class="info" open="open"><summary>sample_weight : array-like of shape (n_samples,), default=None</summary><p>Individual weights for each sample
raises error if sample_weight is passed and base_estimator
fit method does not support it.</p>
</details>
<h4>Raises</h4>
<p>ValueError
    If no valid consensus set could be found. This occurs if
    <code>is_data_valid</code> and <code>is_model_valid</code> return False for all
    <code>max_trials</code> randomly chosen sub-samples.</p>
</details>
<h3 id="get_params_21">get_params<a class="headerlink" href="#get_params_21" title="Permanent link">&para;</a></h3>
<details class="note" open="open"><summary>method</summary><div class="highlight"><pre><span></span><code><span class="k">val</span> <span class="n">get_params</span> <span class="o">:</span>
  <span class="o">?</span><span class="n">deep</span><span class="o">:</span><span class="kt">bool</span> <span class="o">-&gt;</span>
  <span class="n">t</span> <span class="o">-&gt;</span>
  <span class="nn">Dict</span><span class="p">.</span><span class="n">t</span>
</code></pre></div>

<p>Get parameters for this estimator.</p>
<h4>Parameters</h4>
<details class="info" open="open"><summary>deep : bool, default=True</summary><p>If True, will return the parameters for this estimator and
contained subobjects that are estimators.</p>
</details>
<h4>Returns</h4>
<details class="info" open="open"><summary>params : mapping of string to any</summary><p>Parameter names mapped to their values.</p>
</details>
</details>
<h3 id="predict_21">predict<a class="headerlink" href="#predict_21" title="Permanent link">&para;</a></h3>
<details class="note" open="open"><summary>method</summary><div class="highlight"><pre><span></span><code><span class="k">val</span> <span class="n">predict</span> <span class="o">:</span>
  <span class="n">x</span><span class="o">:</span><span class="nn">Arr</span><span class="p">.</span><span class="n">t</span> <span class="o">-&gt;</span>
  <span class="n">t</span> <span class="o">-&gt;</span>
  <span class="nn">Arr</span><span class="p">.</span><span class="n">t</span>
</code></pre></div>

<p>Predict using the estimated model.</p>
<p>This is a wrapper for <code>estimator_.predict(X)</code>.</p>
<h4>Parameters</h4>
<details class="info" open="open"><summary>X : numpy array of shape [n_samples, n_features]</summary></details>
<h4>Returns</h4>
<details class="info" open="open"><summary>y : array, shape = [n_samples] or [n_samples, n_targets]</summary><p>Returns predicted values.</p>
</details>
</details>
<h3 id="score_21">score<a class="headerlink" href="#score_21" title="Permanent link">&para;</a></h3>
<details class="note" open="open"><summary>method</summary><div class="highlight"><pre><span></span><code><span class="k">val</span> <span class="n">score</span> <span class="o">:</span>
  <span class="n">x</span><span class="o">:</span><span class="nn">Arr</span><span class="p">.</span><span class="n">t</span> <span class="o">-&gt;</span>
  <span class="n">y</span><span class="o">:</span><span class="nn">Arr</span><span class="p">.</span><span class="n">t</span> <span class="o">-&gt;</span>
  <span class="n">t</span> <span class="o">-&gt;</span>
  <span class="kt">float</span>
</code></pre></div>

<p>Returns the score of the prediction.</p>
<p>This is a wrapper for <code>estimator_.score(X, y)</code>.</p>
<h4>Parameters</h4>
<details class="info" open="open"><summary>X : numpy array or sparse matrix of shape [n_samples, n_features]</summary><p>Training data.</p>
</details>
<details class="info" open="open"><summary>y : array, shape = [n_samples] or [n_samples, n_targets]</summary><p>Target values.</p>
</details>
<h4>Returns</h4>
<details class="info" open="open"><summary>z : float</summary><p>Score of the prediction.</p>
</details>
</details>
<h3 id="set_params_21">set_params<a class="headerlink" href="#set_params_21" title="Permanent link">&para;</a></h3>
<details class="note" open="open"><summary>method</summary><div class="highlight"><pre><span></span><code><span class="k">val</span> <span class="n">set_params</span> <span class="o">:</span>
  <span class="o">?</span><span class="n">params</span><span class="o">:(</span><span class="kt">string</span> <span class="o">*</span> <span class="nn">Py</span><span class="p">.</span><span class="nn">Object</span><span class="p">.</span><span class="n">t</span><span class="o">)</span> <span class="kt">list</span> <span class="o">-&gt;</span>
  <span class="n">t</span> <span class="o">-&gt;</span>
  <span class="n">t</span>
</code></pre></div>

<p>Set the parameters of this estimator.</p>
<p>The method works on simple estimators as well as on nested objects
(such as pipelines). The latter have parameters of the form
<code>&lt;component&gt;__&lt;parameter&gt;</code> so that it's possible to update each
component of a nested object.</p>
<h4>Parameters</h4>
<details class="info" open="open"><summary>**params : dict</summary><p>Estimator parameters.</p>
</details>
<h4>Returns</h4>
<details class="info" open="open"><summary>self : object</summary><p>Estimator instance.</p>
</details>
</details>
<h3 id="estimator_">estimator_<a class="headerlink" href="#estimator_" title="Permanent link">&para;</a></h3>
<details class="note" open="open"><summary>attribute</summary><div class="highlight"><pre><span></span><code><span class="k">val</span> <span class="n">estimator_</span> <span class="o">:</span> <span class="n">t</span> <span class="o">-&gt;</span> <span class="nn">Py</span><span class="p">.</span><span class="nn">Object</span><span class="p">.</span><span class="n">t</span>
<span class="k">val</span> <span class="n">estimator_opt</span> <span class="o">:</span> <span class="n">t</span> <span class="o">-&gt;</span> <span class="o">(</span><span class="nn">Py</span><span class="p">.</span><span class="nn">Object</span><span class="p">.</span><span class="n">t</span><span class="o">)</span> <span class="n">option</span>
</code></pre></div>

<p>This attribute is documented in <code>create</code> above. The first version raises Not_found
if the attribute is None. The _opt version returns an option.</p>
</details>
<h3 id="n_trials_">n_trials_<a class="headerlink" href="#n_trials_" title="Permanent link">&para;</a></h3>
<details class="note" open="open"><summary>attribute</summary><div class="highlight"><pre><span></span><code><span class="k">val</span> <span class="n">n_trials_</span> <span class="o">:</span> <span class="n">t</span> <span class="o">-&gt;</span> <span class="kt">int</span>
<span class="k">val</span> <span class="n">n_trials_opt</span> <span class="o">:</span> <span class="n">t</span> <span class="o">-&gt;</span> <span class="o">(</span><span class="kt">int</span><span class="o">)</span> <span class="n">option</span>
</code></pre></div>

<p>This attribute is documented in <code>create</code> above. The first version raises Not_found
if the attribute is None. The _opt version returns an option.</p>
</details>
<h3 id="inlier_mask_">inlier_mask_<a class="headerlink" href="#inlier_mask_" title="Permanent link">&para;</a></h3>
<details class="note" open="open"><summary>attribute</summary><div class="highlight"><pre><span></span><code><span class="k">val</span> <span class="n">inlier_mask_</span> <span class="o">:</span> <span class="n">t</span> <span class="o">-&gt;</span> <span class="nn">Arr</span><span class="p">.</span><span class="n">t</span>
<span class="k">val</span> <span class="n">inlier_mask_opt</span> <span class="o">:</span> <span class="n">t</span> <span class="o">-&gt;</span> <span class="o">(</span><span class="nn">Arr</span><span class="p">.</span><span class="n">t</span><span class="o">)</span> <span class="n">option</span>
</code></pre></div>

<p>This attribute is documented in <code>create</code> above. The first version raises Not_found
if the attribute is None. The _opt version returns an option.</p>
</details>
<h3 id="n_skips_no_inliers_">n_skips_no_inliers_<a class="headerlink" href="#n_skips_no_inliers_" title="Permanent link">&para;</a></h3>
<details class="note" open="open"><summary>attribute</summary><div class="highlight"><pre><span></span><code><span class="k">val</span> <span class="n">n_skips_no_inliers_</span> <span class="o">:</span> <span class="n">t</span> <span class="o">-&gt;</span> <span class="kt">int</span>
<span class="k">val</span> <span class="n">n_skips_no_inliers_opt</span> <span class="o">:</span> <span class="n">t</span> <span class="o">-&gt;</span> <span class="o">(</span><span class="kt">int</span><span class="o">)</span> <span class="n">option</span>
</code></pre></div>

<p>This attribute is documented in <code>create</code> above. The first version raises Not_found
if the attribute is None. The _opt version returns an option.</p>
</details>
<h3 id="n_skips_invalid_data_">n_skips_invalid_data_<a class="headerlink" href="#n_skips_invalid_data_" title="Permanent link">&para;</a></h3>
<details class="note" open="open"><summary>attribute</summary><div class="highlight"><pre><span></span><code><span class="k">val</span> <span class="n">n_skips_invalid_data_</span> <span class="o">:</span> <span class="n">t</span> <span class="o">-&gt;</span> <span class="kt">int</span>
<span class="k">val</span> <span class="n">n_skips_invalid_data_opt</span> <span class="o">:</span> <span class="n">t</span> <span class="o">-&gt;</span> <span class="o">(</span><span class="kt">int</span><span class="o">)</span> <span class="n">option</span>
</code></pre></div>

<p>This attribute is documented in <code>create</code> above. The first version raises Not_found
if the attribute is None. The _opt version returns an option.</p>
</details>
<h3 id="n_skips_invalid_model_">n_skips_invalid_model_<a class="headerlink" href="#n_skips_invalid_model_" title="Permanent link">&para;</a></h3>
<details class="note" open="open"><summary>attribute</summary><div class="highlight"><pre><span></span><code><span class="k">val</span> <span class="n">n_skips_invalid_model_</span> <span class="o">:</span> <span class="n">t</span> <span class="o">-&gt;</span> <span class="kt">int</span>
<span class="k">val</span> <span class="n">n_skips_invalid_model_opt</span> <span class="o">:</span> <span class="n">t</span> <span class="o">-&gt;</span> <span class="o">(</span><span class="kt">int</span><span class="o">)</span> <span class="n">option</span>
</code></pre></div>

<p>This attribute is documented in <code>create</code> above. The first version raises Not_found
if the attribute is None. The _opt version returns an option.</p>
</details>
<h3 id="to_string_21">to_string<a class="headerlink" href="#to_string_21" title="Permanent link">&para;</a></h3>
<details class="note" open="open"><summary>method</summary><div class="highlight"><pre><span></span><code><span class="k">val</span> <span class="n">to_string</span><span class="o">:</span> <span class="n">t</span> <span class="o">-&gt;</span> <span class="kt">string</span>
</code></pre></div>

<p>Print the object to a human-readable representation.</p>
</details>
<h3 id="show_21">show<a class="headerlink" href="#show_21" title="Permanent link">&para;</a></h3>
<details class="note" open="open"><summary>method</summary><div class="highlight"><pre><span></span><code><span class="k">val</span> <span class="n">show</span><span class="o">:</span> <span class="n">t</span> <span class="o">-&gt;</span> <span class="kt">string</span>
</code></pre></div>

<p>Print the object to a human-readable representation.</p>
</details>
<h3 id="pp_21">pp<a class="headerlink" href="#pp_21" title="Permanent link">&para;</a></h3>
<details class="note" open="open"><summary>method</summary><div class="highlight"><pre><span></span><code><span class="k">val</span> <span class="n">pp</span><span class="o">:</span> <span class="nn">Format</span><span class="p">.</span><span class="n">formatter</span> <span class="o">-&gt;</span> <span class="n">t</span> <span class="o">-&gt;</span> <span class="kt">unit</span>
</code></pre></div>

<p>Pretty-print the object to a formatter.</p>
</details>
<h2 id="module-sklearnlinear_modelridge">module Sklearn.​Linear_model.​Ridge<a class="headerlink" href="#module-sklearnlinear_modelridge" title="Permanent link">&para;</a></h2>
<div class="highlight"><pre><span></span><code><span class="k">type</span> <span class="n">t</span>
</code></pre></div>

<h3 id="create_22">create<a class="headerlink" href="#create_22" title="Permanent link">&para;</a></h3>
<details class="note" open="open"><summary>constructor and attributes</summary><div class="highlight"><pre><span></span><code><span class="k">val</span> <span class="n">create</span> <span class="o">:</span>
  <span class="o">?</span><span class="n">alpha</span><span class="o">:[`</span><span class="nc">F</span> <span class="k">of</span> <span class="kt">float</span> <span class="o">|</span> <span class="o">`</span><span class="nc">Arr</span> <span class="k">of</span> <span class="nn">Arr</span><span class="p">.</span><span class="n">t</span><span class="o">]</span> <span class="o">-&gt;</span>
  <span class="o">?</span><span class="n">fit_intercept</span><span class="o">:</span><span class="kt">bool</span> <span class="o">-&gt;</span>
  <span class="o">?</span><span class="n">normalize</span><span class="o">:</span><span class="kt">bool</span> <span class="o">-&gt;</span>
  <span class="o">?</span><span class="n">copy_X</span><span class="o">:</span><span class="kt">bool</span> <span class="o">-&gt;</span>
  <span class="o">?</span><span class="n">max_iter</span><span class="o">:</span><span class="kt">int</span> <span class="o">-&gt;</span>
  <span class="o">?</span><span class="n">tol</span><span class="o">:</span><span class="kt">float</span> <span class="o">-&gt;</span>
  <span class="o">?</span><span class="n">solver</span><span class="o">:[`</span><span class="nc">Auto</span> <span class="o">|</span> <span class="o">`</span><span class="nc">Svd</span> <span class="o">|</span> <span class="o">`</span><span class="nc">Cholesky</span> <span class="o">|</span> <span class="o">`</span><span class="nc">Lsqr</span> <span class="o">|</span> <span class="o">`</span><span class="nc">Sparse_cg</span> <span class="o">|</span> <span class="o">`</span><span class="nc">Sag</span> <span class="o">|</span> <span class="o">`</span><span class="nc">Saga</span><span class="o">]</span> <span class="o">-&gt;</span>
  <span class="o">?</span><span class="n">random_state</span><span class="o">:</span><span class="kt">int</span> <span class="o">-&gt;</span>
  <span class="kt">unit</span> <span class="o">-&gt;</span>
  <span class="n">t</span>
</code></pre></div>

<p>Linear least squares with l2 regularization.</p>
<p>Minimizes the objective function::</p>
<p>||y - Xw||^2_2 + alpha * ||w||^2_2</p>
<p>This model solves a regression model where the loss function is
the linear least squares function and regularization is given by
the l2-norm. Also known as Ridge Regression or Tikhonov regularization.
This estimator has built-in support for multi-variate regression
(i.e., when y is a 2d-array of shape (n_samples, n_targets)).</p>
<p>Read more in the :ref:<code>User Guide &lt;ridge_regression&gt;</code>.</p>
<h4>Parameters</h4>
<details class="info" open="open"><summary>alpha : {float, ndarray of shape (n_targets,)}, default=1.0</summary><p>Regularization strength; must be a positive float. Regularization
improves the conditioning of the problem and reduces the variance of
the estimates. Larger values specify stronger regularization.
Alpha corresponds to <code>C^-1</code> in other linear models such as
LogisticRegression or LinearSVC. If an array is passed, penalties are
assumed to be specific to the targets. Hence they must correspond in
number.</p>
</details>
<details class="info" open="open"><summary>fit_intercept : bool, default=True</summary><p>Whether to calculate the intercept for this model. If set
to false, no intercept will be used in calculations
(i.e. data is expected to be centered).</p>
</details>
<details class="info" open="open"><summary>normalize : bool, default=False</summary><p>This parameter is ignored when <code>fit_intercept</code> is set to False.
If True, the regressors X will be normalized before regression by
subtracting the mean and dividing by the l2-norm.
If you wish to standardize, please use
:class:<code>sklearn.preprocessing.StandardScaler</code> before calling <code>fit</code>
on an estimator with <code>normalize=False</code>.</p>
</details>
<details class="info" open="open"><summary>copy_X : bool, default=True</summary><p>If True, X will be copied; else, it may be overwritten.</p>
</details>
<details class="info" open="open"><summary>max_iter : int, default=None</summary><p>Maximum number of iterations for conjugate gradient solver.
For 'sparse_cg' and 'lsqr' solvers, the default value is determined
by scipy.sparse.linalg. For 'sag' solver, the default value is 1000.</p>
</details>
<details class="info" open="open"><summary>tol : float, default=1e-3</summary><p>Precision of the solution.</p>
</details>
<details class="info" open="open"><summary>solver : {'auto', 'svd', 'cholesky', 'lsqr', 'sparse_cg', 'sag', 'saga'},         default='auto'</summary><p>Solver to use in the computational routines:</p>
<ul>
<li>
<p>'auto' chooses the solver automatically based on the type of data.</p>
</li>
<li>
<p>'svd' uses a Singular Value Decomposition of X to compute the Ridge
  coefficients. More stable for singular matrices than
  'cholesky'.</p>
</li>
<li>
<p>'cholesky' uses the standard scipy.linalg.solve function to
  obtain a closed-form solution.</p>
</li>
<li>
<p>'sparse_cg' uses the conjugate gradient solver as found in
  scipy.sparse.linalg.cg. As an iterative algorithm, this solver is
  more appropriate than 'cholesky' for large-scale data
  (possibility to set <code>tol</code> and <code>max_iter</code>).</p>
</li>
<li>
<p>'lsqr' uses the dedicated regularized least-squares routine
  scipy.sparse.linalg.lsqr. It is the fastest and uses an iterative
  procedure.</p>
</li>
<li>
<p>'sag' uses a Stochastic Average Gradient descent, and 'saga' uses
  its improved, unbiased version named SAGA. Both methods also use an
  iterative procedure, and are often faster than other solvers when
  both n_samples and n_features are large. Note that 'sag' and
  'saga' fast convergence is only guaranteed on features with
  approximately the same scale. You can preprocess the data with a
  scaler from sklearn.preprocessing.</p>
</li>
</ul>
<p>All last five solvers support both dense and sparse data. However, only
'sparse_cg' supports sparse input when <code>fit_intercept</code> is True.</p>
<p>.. versionadded:: 0.17
   Stochastic Average Gradient descent solver.
.. versionadded:: 0.19
   SAGA solver.</p>
</details>
<details class="info" open="open"><summary>random_state : int, RandomState instance, default=None</summary><p>The seed of the pseudo random number generator to use when shuffling
the data.  If int, random_state is the seed used by the random number
generator; If RandomState instance, random_state is the random number
generator; If None, the random number generator is the RandomState
instance used by <code>np.random</code>. Used when <code>solver</code> == 'sag'.</p>
<p>.. versionadded:: 0.17
   <em>random_state</em> to support Stochastic Average Gradient.</p>
</details>
<h4>Attributes</h4>
<details class="info" open="open"><summary>coef_ : ndarray of shape (n_features,) or (n_targets, n_features)</summary><p>Weight vector(s).</p>
</details>
<details class="info" open="open"><summary>intercept_ : float or ndarray of shape (n_targets,)</summary><p>Independent term in decision function. Set to 0.0 if
<code>fit_intercept = False</code>.</p>
</details>
<details class="info" open="open"><summary>n_iter_ : None or ndarray of shape (n_targets,)</summary><p>Actual number of iterations for each target. Available only for
sag and lsqr solvers. Other solvers will return None.</p>
<p>.. versionadded:: 0.17</p>
</details>
<h4>See also</h4>
<details class="info" open="open"><summary>RidgeClassifier : Ridge classifier</summary></details>
<details class="info" open="open"><summary>RidgeCV : Ridge regression with built-in cross validation</summary></details>
<p>:class:<code>sklearn.kernel_ridge.KernelRidge</code> : Kernel ridge regression
    combines ridge regression with the kernel trick</p>
<h4>Examples</h4>
<div class="highlight"><pre><span></span><code><span class="o">&gt;&gt;&gt;</span> <span class="kn">from</span> <span class="nn">sklearn.linear_model</span> <span class="kn">import</span> <span class="n">Ridge</span>
<span class="o">&gt;&gt;&gt;</span> <span class="kn">import</span> <span class="nn">numpy</span> <span class="k">as</span> <span class="nn">np</span>
<span class="o">&gt;&gt;&gt;</span> <span class="n">n_samples</span><span class="p">,</span> <span class="n">n_features</span> <span class="o">=</span> <span class="mi">10</span><span class="p">,</span> <span class="mi">5</span>
<span class="o">&gt;&gt;&gt;</span> <span class="n">rng</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">random</span><span class="o">.</span><span class="n">RandomState</span><span class="p">(</span><span class="mi">0</span><span class="p">)</span>
<span class="o">&gt;&gt;&gt;</span> <span class="n">y</span> <span class="o">=</span> <span class="n">rng</span><span class="o">.</span><span class="n">randn</span><span class="p">(</span><span class="n">n_samples</span><span class="p">)</span>
<span class="o">&gt;&gt;&gt;</span> <span class="n">X</span> <span class="o">=</span> <span class="n">rng</span><span class="o">.</span><span class="n">randn</span><span class="p">(</span><span class="n">n_samples</span><span class="p">,</span> <span class="n">n_features</span><span class="p">)</span>
<span class="o">&gt;&gt;&gt;</span> <span class="n">clf</span> <span class="o">=</span> <span class="n">Ridge</span><span class="p">(</span><span class="n">alpha</span><span class="o">=</span><span class="mf">1.0</span><span class="p">)</span>
<span class="o">&gt;&gt;&gt;</span> <span class="n">clf</span><span class="o">.</span><span class="n">fit</span><span class="p">(</span><span class="n">X</span><span class="p">,</span> <span class="n">y</span><span class="p">)</span>
<span class="n">Ridge</span><span class="p">()</span>
</code></pre></div>

</details>
<h3 id="fit_22">fit<a class="headerlink" href="#fit_22" title="Permanent link">&para;</a></h3>
<details class="note" open="open"><summary>method</summary><div class="highlight"><pre><span></span><code><span class="k">val</span> <span class="n">fit</span> <span class="o">:</span>
  <span class="o">?</span><span class="n">sample_weight</span><span class="o">:[`</span><span class="nc">F</span> <span class="k">of</span> <span class="kt">float</span> <span class="o">|</span> <span class="o">`</span><span class="nc">Arr</span> <span class="k">of</span> <span class="nn">Arr</span><span class="p">.</span><span class="n">t</span><span class="o">]</span> <span class="o">-&gt;</span>
  <span class="n">x</span><span class="o">:</span><span class="nn">Arr</span><span class="p">.</span><span class="n">t</span> <span class="o">-&gt;</span>
  <span class="n">y</span><span class="o">:</span><span class="nn">Arr</span><span class="p">.</span><span class="n">t</span> <span class="o">-&gt;</span>
  <span class="n">t</span> <span class="o">-&gt;</span>
  <span class="n">t</span>
</code></pre></div>

<p>Fit Ridge regression model.</p>
<h4>Parameters</h4>
<details class="info" open="open"><summary>X : {ndarray, sparse matrix} of shape (n_samples, n_features)</summary><p>Training data</p>
</details>
<details class="info" open="open"><summary>y : ndarray of shape (n_samples,) or (n_samples, n_targets)</summary><p>Target values</p>
</details>
<details class="info" open="open"><summary>sample_weight : float or ndarray of shape (n_samples,), default=None</summary><p>Individual weights for each sample. If given a float, every sample
will have the same weight.</p>
</details>
<h4>Returns</h4>
<details class="info" open="open"><summary>self : returns an instance of self.</summary></details>
</details>
<h3 id="get_params_22">get_params<a class="headerlink" href="#get_params_22" title="Permanent link">&para;</a></h3>
<details class="note" open="open"><summary>method</summary><div class="highlight"><pre><span></span><code><span class="k">val</span> <span class="n">get_params</span> <span class="o">:</span>
  <span class="o">?</span><span class="n">deep</span><span class="o">:</span><span class="kt">bool</span> <span class="o">-&gt;</span>
  <span class="n">t</span> <span class="o">-&gt;</span>
  <span class="nn">Dict</span><span class="p">.</span><span class="n">t</span>
</code></pre></div>

<p>Get parameters for this estimator.</p>
<h4>Parameters</h4>
<details class="info" open="open"><summary>deep : bool, default=True</summary><p>If True, will return the parameters for this estimator and
contained subobjects that are estimators.</p>
</details>
<h4>Returns</h4>
<details class="info" open="open"><summary>params : mapping of string to any</summary><p>Parameter names mapped to their values.</p>
</details>
</details>
<h3 id="predict_22">predict<a class="headerlink" href="#predict_22" title="Permanent link">&para;</a></h3>
<details class="note" open="open"><summary>method</summary><div class="highlight"><pre><span></span><code><span class="k">val</span> <span class="n">predict</span> <span class="o">:</span>
  <span class="n">x</span><span class="o">:</span><span class="nn">Arr</span><span class="p">.</span><span class="n">t</span> <span class="o">-&gt;</span>
  <span class="n">t</span> <span class="o">-&gt;</span>
  <span class="nn">Arr</span><span class="p">.</span><span class="n">t</span>
</code></pre></div>

<p>Predict using the linear model.</p>
<h4>Parameters</h4>
<details class="info" open="open"><summary>X : array_like or sparse matrix, shape (n_samples, n_features)</summary><p>Samples.</p>
</details>
<h4>Returns</h4>
<details class="info" open="open"><summary>C : array, shape (n_samples,)</summary><p>Returns predicted values.</p>
</details>
</details>
<h3 id="score_22">score<a class="headerlink" href="#score_22" title="Permanent link">&para;</a></h3>
<details class="note" open="open"><summary>method</summary><div class="highlight"><pre><span></span><code><span class="k">val</span> <span class="n">score</span> <span class="o">:</span>
  <span class="o">?</span><span class="n">sample_weight</span><span class="o">:</span><span class="nn">Arr</span><span class="p">.</span><span class="n">t</span> <span class="o">-&gt;</span>
  <span class="n">x</span><span class="o">:</span><span class="nn">Arr</span><span class="p">.</span><span class="n">t</span> <span class="o">-&gt;</span>
  <span class="n">y</span><span class="o">:</span><span class="nn">Arr</span><span class="p">.</span><span class="n">t</span> <span class="o">-&gt;</span>
  <span class="n">t</span> <span class="o">-&gt;</span>
  <span class="kt">float</span>
</code></pre></div>

<p>Return the coefficient of determination R^2 of the prediction.</p>
<p>The coefficient R^2 is defined as (1 - u/v), where u is the residual
sum of squares ((y_true - y_pred) <strong> 2).sum() and v is the total
sum of squares ((y_true - y_true.mean()) </strong> 2).sum().
The best possible score is 1.0 and it can be negative (because the
model can be arbitrarily worse). A constant model that always
predicts the expected value of y, disregarding the input features,
would get a R^2 score of 0.0.</p>
<h4>Parameters</h4>
<details class="info" open="open"><summary>X : array-like of shape (n_samples, n_features)</summary><p>Test samples. For some estimators this may be a
precomputed kernel matrix or a list of generic objects instead,
shape = (n_samples, n_samples_fitted),
where n_samples_fitted is the number of
samples used in the fitting for the estimator.</p>
</details>
<details class="info" open="open"><summary>y : array-like of shape (n_samples,) or (n_samples, n_outputs)</summary><p>True values for X.</p>
</details>
<details class="info" open="open"><summary>sample_weight : array-like of shape (n_samples,), default=None</summary><p>Sample weights.</p>
</details>
<h4>Returns</h4>
<details class="info" open="open"><summary>score : float</summary><p>R^2 of self.predict(X) wrt. y.</p>
</details>
<h4>Notes</h4>
<p>The R2 score used when calling <code>score</code> on a regressor will use
<code>multioutput='uniform_average'</code> from version 0.23 to keep consistent</p>
<details class="info" open="open"><summary>with :func:<code>~sklearn.metrics.r2_score</code>. This will influence the</summary></details>
<p><code>score</code> method of all the multioutput regressors (except for
:class:<code>~sklearn.multioutput.MultiOutputRegressor</code>). To specify the
default value manually and avoid the warning, please either call
:func:<code>~sklearn.metrics.r2_score</code> directly or make a custom scorer with
:func:<code>~sklearn.metrics.make_scorer</code> (the built-in scorer <code>'r2'</code> uses
<code>multioutput='uniform_average'</code>).</p>
</details>
<h3 id="set_params_22">set_params<a class="headerlink" href="#set_params_22" title="Permanent link">&para;</a></h3>
<details class="note" open="open"><summary>method</summary><div class="highlight"><pre><span></span><code><span class="k">val</span> <span class="n">set_params</span> <span class="o">:</span>
  <span class="o">?</span><span class="n">params</span><span class="o">:(</span><span class="kt">string</span> <span class="o">*</span> <span class="nn">Py</span><span class="p">.</span><span class="nn">Object</span><span class="p">.</span><span class="n">t</span><span class="o">)</span> <span class="kt">list</span> <span class="o">-&gt;</span>
  <span class="n">t</span> <span class="o">-&gt;</span>
  <span class="n">t</span>
</code></pre></div>

<p>Set the parameters of this estimator.</p>
<p>The method works on simple estimators as well as on nested objects
(such as pipelines). The latter have parameters of the form
<code>&lt;component&gt;__&lt;parameter&gt;</code> so that it's possible to update each
component of a nested object.</p>
<h4>Parameters</h4>
<details class="info" open="open"><summary>**params : dict</summary><p>Estimator parameters.</p>
</details>
<h4>Returns</h4>
<details class="info" open="open"><summary>self : object</summary><p>Estimator instance.</p>
</details>
</details>
<h3 id="coef__21">coef_<a class="headerlink" href="#coef__21" title="Permanent link">&para;</a></h3>
<details class="note" open="open"><summary>attribute</summary><div class="highlight"><pre><span></span><code><span class="k">val</span> <span class="n">coef_</span> <span class="o">:</span> <span class="n">t</span> <span class="o">-&gt;</span> <span class="nn">Arr</span><span class="p">.</span><span class="n">t</span>
<span class="k">val</span> <span class="n">coef_opt</span> <span class="o">:</span> <span class="n">t</span> <span class="o">-&gt;</span> <span class="o">(</span><span class="nn">Arr</span><span class="p">.</span><span class="n">t</span><span class="o">)</span> <span class="n">option</span>
</code></pre></div>

<p>This attribute is documented in <code>create</code> above. The first version raises Not_found
if the attribute is None. The _opt version returns an option.</p>
</details>
<h3 id="intercept__21">intercept_<a class="headerlink" href="#intercept__21" title="Permanent link">&para;</a></h3>
<details class="note" open="open"><summary>attribute</summary><div class="highlight"><pre><span></span><code><span class="k">val</span> <span class="n">intercept_</span> <span class="o">:</span> <span class="n">t</span> <span class="o">-&gt;</span> <span class="nn">Arr</span><span class="p">.</span><span class="n">t</span>
<span class="k">val</span> <span class="n">intercept_opt</span> <span class="o">:</span> <span class="n">t</span> <span class="o">-&gt;</span> <span class="o">(</span><span class="nn">Arr</span><span class="p">.</span><span class="n">t</span><span class="o">)</span> <span class="n">option</span>
</code></pre></div>

<p>This attribute is documented in <code>create</code> above. The first version raises Not_found
if the attribute is None. The _opt version returns an option.</p>
</details>
<h3 id="n_iter__19">n_iter_<a class="headerlink" href="#n_iter__19" title="Permanent link">&para;</a></h3>
<details class="note" open="open"><summary>attribute</summary><div class="highlight"><pre><span></span><code><span class="k">val</span> <span class="n">n_iter_</span> <span class="o">:</span> <span class="n">t</span> <span class="o">-&gt;</span> <span class="nn">Arr</span><span class="p">.</span><span class="n">t</span>
<span class="k">val</span> <span class="n">n_iter_opt</span> <span class="o">:</span> <span class="n">t</span> <span class="o">-&gt;</span> <span class="o">(</span><span class="nn">Arr</span><span class="p">.</span><span class="n">t</span><span class="o">)</span> <span class="n">option</span>
</code></pre></div>

<p>This attribute is documented in <code>create</code> above. The first version raises Not_found
if the attribute is None. The _opt version returns an option.</p>
</details>
<h3 id="to_string_22">to_string<a class="headerlink" href="#to_string_22" title="Permanent link">&para;</a></h3>
<details class="note" open="open"><summary>method</summary><div class="highlight"><pre><span></span><code><span class="k">val</span> <span class="n">to_string</span><span class="o">:</span> <span class="n">t</span> <span class="o">-&gt;</span> <span class="kt">string</span>
</code></pre></div>

<p>Print the object to a human-readable representation.</p>
</details>
<h3 id="show_22">show<a class="headerlink" href="#show_22" title="Permanent link">&para;</a></h3>
<details class="note" open="open"><summary>method</summary><div class="highlight"><pre><span></span><code><span class="k">val</span> <span class="n">show</span><span class="o">:</span> <span class="n">t</span> <span class="o">-&gt;</span> <span class="kt">string</span>
</code></pre></div>

<p>Print the object to a human-readable representation.</p>
</details>
<h3 id="pp_22">pp<a class="headerlink" href="#pp_22" title="Permanent link">&para;</a></h3>
<details class="note" open="open"><summary>method</summary><div class="highlight"><pre><span></span><code><span class="k">val</span> <span class="n">pp</span><span class="o">:</span> <span class="nn">Format</span><span class="p">.</span><span class="n">formatter</span> <span class="o">-&gt;</span> <span class="n">t</span> <span class="o">-&gt;</span> <span class="kt">unit</span>
</code></pre></div>

<p>Pretty-print the object to a formatter.</p>
</details>
<h2 id="module-sklearnlinear_modelridgecv">module Sklearn.​Linear_model.​RidgeCV<a class="headerlink" href="#module-sklearnlinear_modelridgecv" title="Permanent link">&para;</a></h2>
<div class="highlight"><pre><span></span><code><span class="k">type</span> <span class="n">t</span>
</code></pre></div>

<h3 id="create_23">create<a class="headerlink" href="#create_23" title="Permanent link">&para;</a></h3>
<details class="note" open="open"><summary>constructor and attributes</summary><div class="highlight"><pre><span></span><code><span class="k">val</span> <span class="n">create</span> <span class="o">:</span>
  <span class="o">?</span><span class="n">alphas</span><span class="o">:</span><span class="nn">Arr</span><span class="p">.</span><span class="n">t</span> <span class="o">-&gt;</span>
  <span class="o">?</span><span class="n">fit_intercept</span><span class="o">:</span><span class="kt">bool</span> <span class="o">-&gt;</span>
  <span class="o">?</span><span class="n">normalize</span><span class="o">:</span><span class="kt">bool</span> <span class="o">-&gt;</span>
  <span class="o">?</span><span class="n">scoring</span><span class="o">:[`</span><span class="nc">S</span> <span class="k">of</span> <span class="kt">string</span> <span class="o">|</span> <span class="o">`</span><span class="nc">Callable</span> <span class="k">of</span> <span class="nn">Py</span><span class="p">.</span><span class="nn">Object</span><span class="p">.</span><span class="n">t</span><span class="o">]</span> <span class="o">-&gt;</span>
  <span class="o">?</span><span class="n">cv</span><span class="o">:[`</span><span class="nc">I</span> <span class="k">of</span> <span class="kt">int</span> <span class="o">|</span> <span class="o">`</span><span class="nc">CrossValGenerator</span> <span class="k">of</span> <span class="nn">Py</span><span class="p">.</span><span class="nn">Object</span><span class="p">.</span><span class="n">t</span> <span class="o">|</span> <span class="o">`</span><span class="nc">Arr</span> <span class="k">of</span> <span class="nn">Arr</span><span class="p">.</span><span class="n">t</span><span class="o">]</span> <span class="o">-&gt;</span>
  <span class="o">?</span><span class="n">gcv_mode</span><span class="o">:[`</span><span class="nc">Auto</span> <span class="o">|</span> <span class="o">`</span><span class="nc">Svd</span> <span class="o">|</span> <span class="o">`</span><span class="nc">Eigen</span><span class="o">]</span> <span class="o">-&gt;</span>
  <span class="o">?</span><span class="n">store_cv_values</span><span class="o">:</span><span class="kt">bool</span> <span class="o">-&gt;</span>
  <span class="kt">unit</span> <span class="o">-&gt;</span>
  <span class="n">t</span>
</code></pre></div>

<p>Ridge regression with built-in cross-validation.</p>
<p>See glossary entry for :term:<code>cross-validation estimator</code>.</p>
<p>By default, it performs Generalized Cross-Validation, which is a form of
efficient Leave-One-Out cross-validation.</p>
<p>Read more in the :ref:<code>User Guide &lt;ridge_regression&gt;</code>.</p>
<h4>Parameters</h4>
<details class="info" open="open"><summary>alphas : ndarray of shape (n_alphas,), default=(0.1, 1.0, 10.0)</summary><p>Array of alpha values to try.
Regularization strength; must be a positive float. Regularization
improves the conditioning of the problem and reduces the variance of
the estimates. Larger values specify stronger regularization.
Alpha corresponds to <code>C^-1</code> in other linear models such as
LogisticRegression or LinearSVC.
If using generalized cross-validation, alphas must be positive.</p>
</details>
<details class="info" open="open"><summary>fit_intercept : bool, default=True</summary><p>Whether to calculate the intercept for this model. If set
to false, no intercept will be used in calculations
(i.e. data is expected to be centered).</p>
</details>
<details class="info" open="open"><summary>normalize : bool, default=False</summary><p>This parameter is ignored when <code>fit_intercept</code> is set to False.
If True, the regressors X will be normalized before regression by
subtracting the mean and dividing by the l2-norm.
If you wish to standardize, please use
:class:<code>sklearn.preprocessing.StandardScaler</code> before calling <code>fit</code>
on an estimator with <code>normalize=False</code>.</p>
</details>
<details class="info" open="open"><summary>scoring : string, callable, default=None</summary><p>A string (see model evaluation documentation) or
a scorer callable object / function with signature
<code>scorer(estimator, X, y)</code>.
If None, the negative mean squared error if cv is 'auto' or None
(i.e. when using generalized cross-validation), and r2 score otherwise.</p>
</details>
<details class="info" open="open"><summary>cv : int, cross-validation generator or an iterable, default=None</summary><p>Determines the cross-validation splitting strategy.
Possible inputs for cv are:</p>
<ul>
<li>None, to use the efficient Leave-One-Out cross-validation
  (also known as Generalized Cross-Validation).</li>
<li>integer, to specify the number of folds.</li>
<li>:term:<code>CV splitter</code>,</li>
<li>An iterable yielding (train, test) splits as arrays of indices.</li>
</ul>
<p>For integer/None inputs, if <code>y</code> is binary or multiclass,
:class:<code>sklearn.model_selection.StratifiedKFold</code> is used, else,
:class:<code>sklearn.model_selection.KFold</code> is used.</p>
</details>
<details class="info" open="open"><summary>Refer :ref:<code>User Guide &lt;cross_validation&gt;</code> for the various</summary><p>cross-validation strategies that can be used here.</p>
</details>
<details class="info" open="open"><summary>gcv_mode : {'auto', 'svd', eigen'}, default='auto'</summary><p>Flag indicating which strategy to use when performing
Generalized Cross-Validation. Options are::</p>
<div class="codehilite"><pre><span></span><code>&#39;auto&#39; : use &#39;svd&#39; if n_samples &gt; n_features, otherwise use &#39;eigen&#39;
&#39;svd&#39; : force use of singular value decomposition of X when X is
    dense, eigenvalue decomposition of X^T.X when X is sparse.
&#39;eigen&#39; : force computation via eigendecomposition of X.X^T
</code></pre></div>


<p>The 'auto' mode is the default and is intended to pick the cheaper
option of the two depending on the shape of the training data.</p>
</details>
<details class="info" open="open"><summary>store_cv_values : bool, default=False</summary><p>Flag indicating if the cross-validation values corresponding to
each alpha should be stored in the <code>cv_values_</code> attribute (see
below). This flag is only compatible with <code>cv=None</code> (i.e. using
Generalized Cross-Validation).</p>
</details>
<h4>Attributes</h4>
<details class="info" open="open"><summary>cv_values_ : ndarray of shape (n_samples, n_alphas) or         shape (n_samples, n_targets, n_alphas), optional</summary><p>Cross-validation values for each alpha (if <code>store_cv_values=True</code>        and <code>cv=None</code>). After <code>fit()</code> has been called, this attribute         will contain the mean squared errors (by default) or the values         of the <code>{loss,score}_func</code> function (if provided in the constructor).</p>
</details>
<details class="info" open="open"><summary>coef_ : ndarray of shape (n_features) or (n_targets, n_features)</summary><p>Weight vector(s).</p>
</details>
<details class="info" open="open"><summary>intercept_ : float or ndarray of shape (n_targets,)</summary><p>Independent term in decision function. Set to 0.0 if
<code>fit_intercept = False</code>.</p>
</details>
<details class="info" open="open"><summary>alpha_ : float</summary><p>Estimated regularization parameter.</p>
</details>
<h4>Examples</h4>
<div class="highlight"><pre><span></span><code><span class="o">&gt;&gt;&gt;</span> <span class="kn">from</span> <span class="nn">sklearn.datasets</span> <span class="kn">import</span> <span class="n">load_diabetes</span>
<span class="o">&gt;&gt;&gt;</span> <span class="kn">from</span> <span class="nn">sklearn.linear_model</span> <span class="kn">import</span> <span class="n">RidgeCV</span>
<span class="o">&gt;&gt;&gt;</span> <span class="n">X</span><span class="p">,</span> <span class="n">y</span> <span class="o">=</span> <span class="n">load_diabetes</span><span class="p">(</span><span class="n">return_X_y</span><span class="o">=</span><span class="kc">True</span><span class="p">)</span>
<span class="o">&gt;&gt;&gt;</span> <span class="n">clf</span> <span class="o">=</span> <span class="n">RidgeCV</span><span class="p">(</span><span class="n">alphas</span><span class="o">=</span><span class="p">[</span><span class="mf">1e-3</span><span class="p">,</span> <span class="mf">1e-2</span><span class="p">,</span> <span class="mf">1e-1</span><span class="p">,</span> <span class="mi">1</span><span class="p">])</span><span class="o">.</span><span class="n">fit</span><span class="p">(</span><span class="n">X</span><span class="p">,</span> <span class="n">y</span><span class="p">)</span>
<span class="o">&gt;&gt;&gt;</span> <span class="n">clf</span><span class="o">.</span><span class="n">score</span><span class="p">(</span><span class="n">X</span><span class="p">,</span> <span class="n">y</span><span class="p">)</span>
<span class="mf">0.5166</span><span class="o">...</span>
</code></pre></div>

<h4>See also</h4>
<details class="info" open="open"><summary>Ridge : Ridge regression</summary></details>
<details class="info" open="open"><summary>RidgeClassifier : Ridge classifier</summary></details>
<details class="info" open="open"><summary>RidgeClassifierCV : Ridge classifier with built-in cross validation</summary></details>
</details>
<h3 id="fit_23">fit<a class="headerlink" href="#fit_23" title="Permanent link">&para;</a></h3>
<details class="note" open="open"><summary>method</summary><div class="highlight"><pre><span></span><code><span class="k">val</span> <span class="n">fit</span> <span class="o">:</span>
  <span class="o">?</span><span class="n">sample_weight</span><span class="o">:[`</span><span class="nc">F</span> <span class="k">of</span> <span class="kt">float</span> <span class="o">|</span> <span class="o">`</span><span class="nc">Arr</span> <span class="k">of</span> <span class="nn">Arr</span><span class="p">.</span><span class="n">t</span><span class="o">]</span> <span class="o">-&gt;</span>
  <span class="n">x</span><span class="o">:</span><span class="nn">Arr</span><span class="p">.</span><span class="n">t</span> <span class="o">-&gt;</span>
  <span class="n">y</span><span class="o">:</span><span class="nn">Arr</span><span class="p">.</span><span class="n">t</span> <span class="o">-&gt;</span>
  <span class="n">t</span> <span class="o">-&gt;</span>
  <span class="n">t</span>
</code></pre></div>

<p>Fit Ridge regression model with cv.</p>
<h4>Parameters</h4>
<details class="info" open="open"><summary>X : ndarray of shape (n_samples, n_features)</summary><p>Training data. If using GCV, will be cast to float64
if necessary.</p>
</details>
<details class="info" open="open"><summary>y : ndarray of shape (n_samples,) or (n_samples, n_targets)</summary><p>Target values. Will be cast to X's dtype if necessary.</p>
</details>
<details class="info" open="open"><summary>sample_weight : float or ndarray of shape (n_samples,), default=None</summary><p>Individual weights for each sample. If given a float, every sample
will have the same weight.</p>
</details>
<h4>Returns</h4>
<details class="info" open="open"><summary>self : object</summary></details>
<h4>Notes</h4>
<p>When sample_weight is provided, the selected hyperparameter may depend
on whether we use generalized cross-validation (cv=None or cv='auto')
or another form of cross-validation, because only generalized
cross-validation takes the sample weights into account when computing
the validation score.</p>
</details>
<h3 id="get_params_23">get_params<a class="headerlink" href="#get_params_23" title="Permanent link">&para;</a></h3>
<details class="note" open="open"><summary>method</summary><div class="highlight"><pre><span></span><code><span class="k">val</span> <span class="n">get_params</span> <span class="o">:</span>
  <span class="o">?</span><span class="n">deep</span><span class="o">:</span><span class="kt">bool</span> <span class="o">-&gt;</span>
  <span class="n">t</span> <span class="o">-&gt;</span>
  <span class="nn">Dict</span><span class="p">.</span><span class="n">t</span>
</code></pre></div>

<p>Get parameters for this estimator.</p>
<h4>Parameters</h4>
<details class="info" open="open"><summary>deep : bool, default=True</summary><p>If True, will return the parameters for this estimator and
contained subobjects that are estimators.</p>
</details>
<h4>Returns</h4>
<details class="info" open="open"><summary>params : mapping of string to any</summary><p>Parameter names mapped to their values.</p>
</details>
</details>
<h3 id="predict_23">predict<a class="headerlink" href="#predict_23" title="Permanent link">&para;</a></h3>
<details class="note" open="open"><summary>method</summary><div class="highlight"><pre><span></span><code><span class="k">val</span> <span class="n">predict</span> <span class="o">:</span>
  <span class="n">x</span><span class="o">:</span><span class="nn">Arr</span><span class="p">.</span><span class="n">t</span> <span class="o">-&gt;</span>
  <span class="n">t</span> <span class="o">-&gt;</span>
  <span class="nn">Arr</span><span class="p">.</span><span class="n">t</span>
</code></pre></div>

<p>Predict using the linear model.</p>
<h4>Parameters</h4>
<details class="info" open="open"><summary>X : array_like or sparse matrix, shape (n_samples, n_features)</summary><p>Samples.</p>
</details>
<h4>Returns</h4>
<details class="info" open="open"><summary>C : array, shape (n_samples,)</summary><p>Returns predicted values.</p>
</details>
</details>
<h3 id="score_23">score<a class="headerlink" href="#score_23" title="Permanent link">&para;</a></h3>
<details class="note" open="open"><summary>method</summary><div class="highlight"><pre><span></span><code><span class="k">val</span> <span class="n">score</span> <span class="o">:</span>
  <span class="o">?</span><span class="n">sample_weight</span><span class="o">:</span><span class="nn">Arr</span><span class="p">.</span><span class="n">t</span> <span class="o">-&gt;</span>
  <span class="n">x</span><span class="o">:</span><span class="nn">Arr</span><span class="p">.</span><span class="n">t</span> <span class="o">-&gt;</span>
  <span class="n">y</span><span class="o">:</span><span class="nn">Arr</span><span class="p">.</span><span class="n">t</span> <span class="o">-&gt;</span>
  <span class="n">t</span> <span class="o">-&gt;</span>
  <span class="kt">float</span>
</code></pre></div>

<p>Return the coefficient of determination R^2 of the prediction.</p>
<p>The coefficient R^2 is defined as (1 - u/v), where u is the residual
sum of squares ((y_true - y_pred) <strong> 2).sum() and v is the total
sum of squares ((y_true - y_true.mean()) </strong> 2).sum().
The best possible score is 1.0 and it can be negative (because the
model can be arbitrarily worse). A constant model that always
predicts the expected value of y, disregarding the input features,
would get a R^2 score of 0.0.</p>
<h4>Parameters</h4>
<details class="info" open="open"><summary>X : array-like of shape (n_samples, n_features)</summary><p>Test samples. For some estimators this may be a
precomputed kernel matrix or a list of generic objects instead,
shape = (n_samples, n_samples_fitted),
where n_samples_fitted is the number of
samples used in the fitting for the estimator.</p>
</details>
<details class="info" open="open"><summary>y : array-like of shape (n_samples,) or (n_samples, n_outputs)</summary><p>True values for X.</p>
</details>
<details class="info" open="open"><summary>sample_weight : array-like of shape (n_samples,), default=None</summary><p>Sample weights.</p>
</details>
<h4>Returns</h4>
<details class="info" open="open"><summary>score : float</summary><p>R^2 of self.predict(X) wrt. y.</p>
</details>
<h4>Notes</h4>
<p>The R2 score used when calling <code>score</code> on a regressor will use
<code>multioutput='uniform_average'</code> from version 0.23 to keep consistent</p>
<details class="info" open="open"><summary>with :func:<code>~sklearn.metrics.r2_score</code>. This will influence the</summary></details>
<p><code>score</code> method of all the multioutput regressors (except for
:class:<code>~sklearn.multioutput.MultiOutputRegressor</code>). To specify the
default value manually and avoid the warning, please either call
:func:<code>~sklearn.metrics.r2_score</code> directly or make a custom scorer with
:func:<code>~sklearn.metrics.make_scorer</code> (the built-in scorer <code>'r2'</code> uses
<code>multioutput='uniform_average'</code>).</p>
</details>
<h3 id="set_params_23">set_params<a class="headerlink" href="#set_params_23" title="Permanent link">&para;</a></h3>
<details class="note" open="open"><summary>method</summary><div class="highlight"><pre><span></span><code><span class="k">val</span> <span class="n">set_params</span> <span class="o">:</span>
  <span class="o">?</span><span class="n">params</span><span class="o">:(</span><span class="kt">string</span> <span class="o">*</span> <span class="nn">Py</span><span class="p">.</span><span class="nn">Object</span><span class="p">.</span><span class="n">t</span><span class="o">)</span> <span class="kt">list</span> <span class="o">-&gt;</span>
  <span class="n">t</span> <span class="o">-&gt;</span>
  <span class="n">t</span>
</code></pre></div>

<p>Set the parameters of this estimator.</p>
<p>The method works on simple estimators as well as on nested objects
(such as pipelines). The latter have parameters of the form
<code>&lt;component&gt;__&lt;parameter&gt;</code> so that it's possible to update each
component of a nested object.</p>
<h4>Parameters</h4>
<details class="info" open="open"><summary>**params : dict</summary><p>Estimator parameters.</p>
</details>
<h4>Returns</h4>
<details class="info" open="open"><summary>self : object</summary><p>Estimator instance.</p>
</details>
</details>
<h3 id="cv_values_">cv_values_<a class="headerlink" href="#cv_values_" title="Permanent link">&para;</a></h3>
<details class="note" open="open"><summary>attribute</summary><div class="highlight"><pre><span></span><code><span class="k">val</span> <span class="n">cv_values_</span> <span class="o">:</span> <span class="n">t</span> <span class="o">-&gt;</span> <span class="nn">Py</span><span class="p">.</span><span class="nn">Object</span><span class="p">.</span><span class="n">t</span>
<span class="k">val</span> <span class="n">cv_values_opt</span> <span class="o">:</span> <span class="n">t</span> <span class="o">-&gt;</span> <span class="o">(</span><span class="nn">Py</span><span class="p">.</span><span class="nn">Object</span><span class="p">.</span><span class="n">t</span><span class="o">)</span> <span class="n">option</span>
</code></pre></div>

<p>This attribute is documented in <code>create</code> above. The first version raises Not_found
if the attribute is None. The _opt version returns an option.</p>
</details>
<h3 id="coef__22">coef_<a class="headerlink" href="#coef__22" title="Permanent link">&para;</a></h3>
<details class="note" open="open"><summary>attribute</summary><div class="highlight"><pre><span></span><code><span class="k">val</span> <span class="n">coef_</span> <span class="o">:</span> <span class="n">t</span> <span class="o">-&gt;</span> <span class="nn">Arr</span><span class="p">.</span><span class="n">t</span>
<span class="k">val</span> <span class="n">coef_opt</span> <span class="o">:</span> <span class="n">t</span> <span class="o">-&gt;</span> <span class="o">(</span><span class="nn">Arr</span><span class="p">.</span><span class="n">t</span><span class="o">)</span> <span class="n">option</span>
</code></pre></div>

<p>This attribute is documented in <code>create</code> above. The first version raises Not_found
if the attribute is None. The _opt version returns an option.</p>
</details>
<h3 id="intercept__22">intercept_<a class="headerlink" href="#intercept__22" title="Permanent link">&para;</a></h3>
<details class="note" open="open"><summary>attribute</summary><div class="highlight"><pre><span></span><code><span class="k">val</span> <span class="n">intercept_</span> <span class="o">:</span> <span class="n">t</span> <span class="o">-&gt;</span> <span class="nn">Arr</span><span class="p">.</span><span class="n">t</span>
<span class="k">val</span> <span class="n">intercept_opt</span> <span class="o">:</span> <span class="n">t</span> <span class="o">-&gt;</span> <span class="o">(</span><span class="nn">Arr</span><span class="p">.</span><span class="n">t</span><span class="o">)</span> <span class="n">option</span>
</code></pre></div>

<p>This attribute is documented in <code>create</code> above. The first version raises Not_found
if the attribute is None. The _opt version returns an option.</p>
</details>
<h3 id="alpha__9">alpha_<a class="headerlink" href="#alpha__9" title="Permanent link">&para;</a></h3>
<details class="note" open="open"><summary>attribute</summary><div class="highlight"><pre><span></span><code><span class="k">val</span> <span class="n">alpha_</span> <span class="o">:</span> <span class="n">t</span> <span class="o">-&gt;</span> <span class="kt">float</span>
<span class="k">val</span> <span class="n">alpha_opt</span> <span class="o">:</span> <span class="n">t</span> <span class="o">-&gt;</span> <span class="o">(</span><span class="kt">float</span><span class="o">)</span> <span class="n">option</span>
</code></pre></div>

<p>This attribute is documented in <code>create</code> above. The first version raises Not_found
if the attribute is None. The _opt version returns an option.</p>
</details>
<h3 id="to_string_23">to_string<a class="headerlink" href="#to_string_23" title="Permanent link">&para;</a></h3>
<details class="note" open="open"><summary>method</summary><div class="highlight"><pre><span></span><code><span class="k">val</span> <span class="n">to_string</span><span class="o">:</span> <span class="n">t</span> <span class="o">-&gt;</span> <span class="kt">string</span>
</code></pre></div>

<p>Print the object to a human-readable representation.</p>
</details>
<h3 id="show_23">show<a class="headerlink" href="#show_23" title="Permanent link">&para;</a></h3>
<details class="note" open="open"><summary>method</summary><div class="highlight"><pre><span></span><code><span class="k">val</span> <span class="n">show</span><span class="o">:</span> <span class="n">t</span> <span class="o">-&gt;</span> <span class="kt">string</span>
</code></pre></div>

<p>Print the object to a human-readable representation.</p>
</details>
<h3 id="pp_23">pp<a class="headerlink" href="#pp_23" title="Permanent link">&para;</a></h3>
<details class="note" open="open"><summary>method</summary><div class="highlight"><pre><span></span><code><span class="k">val</span> <span class="n">pp</span><span class="o">:</span> <span class="nn">Format</span><span class="p">.</span><span class="n">formatter</span> <span class="o">-&gt;</span> <span class="n">t</span> <span class="o">-&gt;</span> <span class="kt">unit</span>
</code></pre></div>

<p>Pretty-print the object to a formatter.</p>
</details>
<h2 id="module-sklearnlinear_modelridgeclassifier">module Sklearn.​Linear_model.​RidgeClassifier<a class="headerlink" href="#module-sklearnlinear_modelridgeclassifier" title="Permanent link">&para;</a></h2>
<div class="highlight"><pre><span></span><code><span class="k">type</span> <span class="n">t</span>
</code></pre></div>

<h3 id="create_24">create<a class="headerlink" href="#create_24" title="Permanent link">&para;</a></h3>
<details class="note" open="open"><summary>constructor and attributes</summary><div class="highlight"><pre><span></span><code><span class="k">val</span> <span class="n">create</span> <span class="o">:</span>
  <span class="o">?</span><span class="n">alpha</span><span class="o">:</span><span class="kt">float</span> <span class="o">-&gt;</span>
  <span class="o">?</span><span class="n">fit_intercept</span><span class="o">:</span><span class="kt">bool</span> <span class="o">-&gt;</span>
  <span class="o">?</span><span class="n">normalize</span><span class="o">:</span><span class="kt">bool</span> <span class="o">-&gt;</span>
  <span class="o">?</span><span class="n">copy_X</span><span class="o">:</span><span class="kt">bool</span> <span class="o">-&gt;</span>
  <span class="o">?</span><span class="n">max_iter</span><span class="o">:</span><span class="kt">int</span> <span class="o">-&gt;</span>
  <span class="o">?</span><span class="n">tol</span><span class="o">:</span><span class="kt">float</span> <span class="o">-&gt;</span>
  <span class="o">?</span><span class="n">class_weight</span><span class="o">:[`</span><span class="nc">DictIntToFloat</span> <span class="k">of</span> <span class="o">(</span><span class="kt">int</span> <span class="o">*</span> <span class="kt">float</span><span class="o">)</span> <span class="kt">list</span> <span class="o">|</span> <span class="o">`</span><span class="nc">Balanced</span><span class="o">]</span> <span class="o">-&gt;</span>
  <span class="o">?</span><span class="n">solver</span><span class="o">:[`</span><span class="nc">Auto</span> <span class="o">|</span> <span class="o">`</span><span class="nc">Svd</span> <span class="o">|</span> <span class="o">`</span><span class="nc">Cholesky</span> <span class="o">|</span> <span class="o">`</span><span class="nc">Lsqr</span> <span class="o">|</span> <span class="o">`</span><span class="nc">Sparse_cg</span> <span class="o">|</span> <span class="o">`</span><span class="nc">Sag</span> <span class="o">|</span> <span class="o">`</span><span class="nc">Saga</span><span class="o">]</span> <span class="o">-&gt;</span>
  <span class="o">?</span><span class="n">random_state</span><span class="o">:</span><span class="kt">int</span> <span class="o">-&gt;</span>
  <span class="kt">unit</span> <span class="o">-&gt;</span>
  <span class="n">t</span>
</code></pre></div>

<p>Classifier using Ridge regression.</p>
<p>This classifier first converts the target values into <code>{-1, 1}</code> and
then treats the problem as a regression task (multi-output regression in
the multiclass case).</p>
<p>Read more in the :ref:<code>User Guide &lt;ridge_regression&gt;</code>.</p>
<h4>Parameters</h4>
<details class="info" open="open"><summary>alpha : float, default=1.0</summary><p>Regularization strength; must be a positive float. Regularization
improves the conditioning of the problem and reduces the variance of
the estimates. Larger values specify stronger regularization.
Alpha corresponds to <code>C^-1</code> in other linear models such as
LogisticRegression or LinearSVC.</p>
</details>
<details class="info" open="open"><summary>fit_intercept : bool, default=True</summary><p>Whether to calculate the intercept for this model. If set to false, no
intercept will be used in calculations (e.g. data is expected to be
already centered).</p>
</details>
<details class="info" open="open"><summary>normalize : bool, default=False</summary><p>This parameter is ignored when <code>fit_intercept</code> is set to False.
If True, the regressors X will be normalized before regression by
subtracting the mean and dividing by the l2-norm.
If you wish to standardize, please use
:class:<code>sklearn.preprocessing.StandardScaler</code> before calling <code>fit</code>
on an estimator with <code>normalize=False</code>.</p>
</details>
<details class="info" open="open"><summary>copy_X : bool, default=True</summary><p>If True, X will be copied; else, it may be overwritten.</p>
</details>
<details class="info" open="open"><summary>max_iter : int, default=None</summary><p>Maximum number of iterations for conjugate gradient solver.
The default value is determined by scipy.sparse.linalg.</p>
</details>
<details class="info" open="open"><summary>tol : float, default=1e-3</summary><p>Precision of the solution.</p>
</details>
<details class="info" open="open"><summary>class_weight : dict or 'balanced', default=None</summary><p>Weights associated with classes in the form <code>{class_label: weight}</code>.
If not given, all classes are supposed to have weight one.</p>
<p>The "balanced" mode uses the values of y to automatically adjust
weights inversely proportional to class frequencies in the input data
as <code>n_samples / (n_classes * np.bincount(y))</code>.</p>
</details>
<details class="info" open="open"><summary>solver : {'auto', 'svd', 'cholesky', 'lsqr', 'sparse_cg', 'sag', 'saga'},         default='auto'</summary><p>Solver to use in the computational routines:</p>
<ul>
<li>
<p>'auto' chooses the solver automatically based on the type of data.</p>
</li>
<li>
<p>'svd' uses a Singular Value Decomposition of X to compute the Ridge
  coefficients. More stable for singular matrices than
  'cholesky'.</p>
</li>
<li>
<p>'cholesky' uses the standard scipy.linalg.solve function to
  obtain a closed-form solution.</p>
</li>
<li>
<p>'sparse_cg' uses the conjugate gradient solver as found in
  scipy.sparse.linalg.cg. As an iterative algorithm, this solver is
  more appropriate than 'cholesky' for large-scale data
  (possibility to set <code>tol</code> and <code>max_iter</code>).</p>
</li>
<li>
<p>'lsqr' uses the dedicated regularized least-squares routine
  scipy.sparse.linalg.lsqr. It is the fastest and uses an iterative
  procedure.</p>
</li>
<li>
<p>'sag' uses a Stochastic Average Gradient descent, and 'saga' uses
  its unbiased and more flexible version named SAGA. Both methods
  use an iterative procedure, and are often faster than other solvers
  when both n_samples and n_features are large. Note that 'sag' and
  'saga' fast convergence is only guaranteed on features with
  approximately the same scale. You can preprocess the data with a
  scaler from sklearn.preprocessing.</p>
</li>
</ul>
<p>.. versionadded:: 0.17
     Stochastic Average Gradient descent solver.
  .. versionadded:: 0.19
   SAGA solver.</p>
</details>
<details class="info" open="open"><summary>random_state : int, RandomState instance, default=None</summary><p>The seed of the pseudo random number generator to use when shuffling
the data.  If int, random_state is the seed used by the random number
generator; If RandomState instance, random_state is the random number
generator; If None, the random number generator is the RandomState
instance used by <code>np.random</code>. Used when <code>solver</code> == 'sag'.</p>
</details>
<h4>Attributes</h4>
<details class="info" open="open"><summary>coef_ : ndarray of shape (1, n_features) or (n_classes, n_features)</summary><p>Coefficient of the features in the decision function.</p>
<p><code>coef_</code> is of shape (1, n_features) when the given problem is binary.</p>
</details>
<details class="info" open="open"><summary>intercept_ : float or ndarray of shape (n_targets,)</summary><p>Independent term in decision function. Set to 0.0 if
<code>fit_intercept = False</code>.</p>
</details>
<details class="info" open="open"><summary>n_iter_ : None or ndarray of shape (n_targets,)</summary><p>Actual number of iterations for each target. Available only for
sag and lsqr solvers. Other solvers will return None.</p>
</details>
<details class="info" open="open"><summary>classes_ : ndarray of shape (n_classes,)</summary><p>The classes labels.</p>
</details>
<h4>See Also</h4>
<details class="info" open="open"><summary>Ridge : Ridge regression.</summary></details>
<details class="info" open="open"><summary>RidgeClassifierCV :  Ridge classifier with built-in cross validation.</summary></details>
<h4>Notes</h4>
<p>For multi-class classification, n_class classifiers are trained in
a one-versus-all approach. Concretely, this is implemented by taking
advantage of the multi-variate response support in Ridge.</p>
<h4>Examples</h4>
<div class="highlight"><pre><span></span><code><span class="o">&gt;&gt;&gt;</span> <span class="kn">from</span> <span class="nn">sklearn.datasets</span> <span class="kn">import</span> <span class="n">load_breast_cancer</span>
<span class="o">&gt;&gt;&gt;</span> <span class="kn">from</span> <span class="nn">sklearn.linear_model</span> <span class="kn">import</span> <span class="n">RidgeClassifier</span>
<span class="o">&gt;&gt;&gt;</span> <span class="n">X</span><span class="p">,</span> <span class="n">y</span> <span class="o">=</span> <span class="n">load_breast_cancer</span><span class="p">(</span><span class="n">return_X_y</span><span class="o">=</span><span class="kc">True</span><span class="p">)</span>
<span class="o">&gt;&gt;&gt;</span> <span class="n">clf</span> <span class="o">=</span> <span class="n">RidgeClassifier</span><span class="p">()</span><span class="o">.</span><span class="n">fit</span><span class="p">(</span><span class="n">X</span><span class="p">,</span> <span class="n">y</span><span class="p">)</span>
<span class="o">&gt;&gt;&gt;</span> <span class="n">clf</span><span class="o">.</span><span class="n">score</span><span class="p">(</span><span class="n">X</span><span class="p">,</span> <span class="n">y</span><span class="p">)</span>
<span class="mf">0.9595</span><span class="o">...</span>
</code></pre></div>

</details>
<h3 id="decision_function_2">decision_function<a class="headerlink" href="#decision_function_2" title="Permanent link">&para;</a></h3>
<details class="note" open="open"><summary>method</summary><div class="highlight"><pre><span></span><code><span class="k">val</span> <span class="n">decision_function</span> <span class="o">:</span>
  <span class="n">x</span><span class="o">:</span><span class="nn">Arr</span><span class="p">.</span><span class="n">t</span> <span class="o">-&gt;</span>
  <span class="n">t</span> <span class="o">-&gt;</span>
  <span class="nn">Arr</span><span class="p">.</span><span class="n">t</span>
</code></pre></div>

<p>Predict confidence scores for samples.</p>
<p>The confidence score for a sample is the signed distance of that
sample to the hyperplane.</p>
<h4>Parameters</h4>
<details class="info" open="open"><summary>X : array_like or sparse matrix, shape (n_samples, n_features)</summary><p>Samples.</p>
</details>
<h4>Returns</h4>
<p>array, shape=(n_samples,) if n_classes == 2 else (n_samples, n_classes)
    Confidence scores per (sample, class) combination. In the binary
    case, confidence score for self.classes_[1] where &gt;0 means this
    class would be predicted.</p>
</details>
<h3 id="fit_24">fit<a class="headerlink" href="#fit_24" title="Permanent link">&para;</a></h3>
<details class="note" open="open"><summary>method</summary><div class="highlight"><pre><span></span><code><span class="k">val</span> <span class="n">fit</span> <span class="o">:</span>
  <span class="o">?</span><span class="n">sample_weight</span><span class="o">:[`</span><span class="nc">F</span> <span class="k">of</span> <span class="kt">float</span> <span class="o">|</span> <span class="o">`</span><span class="nc">Arr</span> <span class="k">of</span> <span class="nn">Arr</span><span class="p">.</span><span class="n">t</span><span class="o">]</span> <span class="o">-&gt;</span>
  <span class="n">x</span><span class="o">:</span><span class="nn">Arr</span><span class="p">.</span><span class="n">t</span> <span class="o">-&gt;</span>
  <span class="n">y</span><span class="o">:</span><span class="nn">Arr</span><span class="p">.</span><span class="n">t</span> <span class="o">-&gt;</span>
  <span class="n">t</span> <span class="o">-&gt;</span>
  <span class="n">t</span>
</code></pre></div>

<p>Fit Ridge classifier model.</p>
<h4>Parameters</h4>
<details class="info" open="open"><summary>X : {ndarray, sparse matrix} of shape (n_samples, n_features)</summary><p>Training data.</p>
</details>
<details class="info" open="open"><summary>y : ndarray of shape (n_samples,)</summary><p>Target values.</p>
</details>
<details class="info" open="open"><summary>sample_weight : float or ndarray of shape (n_samples,), default=None</summary><p>Individual weights for each sample. If given a float, every sample
will have the same weight.</p>
<p>.. versionadded:: 0.17
   <em>sample_weight</em> support to Classifier.</p>
</details>
<h4>Returns</h4>
<details class="info" open="open"><summary>self : object</summary><p>Instance of the estimator.</p>
</details>
</details>
<h3 id="get_params_24">get_params<a class="headerlink" href="#get_params_24" title="Permanent link">&para;</a></h3>
<details class="note" open="open"><summary>method</summary><div class="highlight"><pre><span></span><code><span class="k">val</span> <span class="n">get_params</span> <span class="o">:</span>
  <span class="o">?</span><span class="n">deep</span><span class="o">:</span><span class="kt">bool</span> <span class="o">-&gt;</span>
  <span class="n">t</span> <span class="o">-&gt;</span>
  <span class="nn">Dict</span><span class="p">.</span><span class="n">t</span>
</code></pre></div>

<p>Get parameters for this estimator.</p>
<h4>Parameters</h4>
<details class="info" open="open"><summary>deep : bool, default=True</summary><p>If True, will return the parameters for this estimator and
contained subobjects that are estimators.</p>
</details>
<h4>Returns</h4>
<details class="info" open="open"><summary>params : mapping of string to any</summary><p>Parameter names mapped to their values.</p>
</details>
</details>
<h3 id="predict_24">predict<a class="headerlink" href="#predict_24" title="Permanent link">&para;</a></h3>
<details class="note" open="open"><summary>method</summary><div class="highlight"><pre><span></span><code><span class="k">val</span> <span class="n">predict</span> <span class="o">:</span>
  <span class="n">x</span><span class="o">:</span><span class="nn">Arr</span><span class="p">.</span><span class="n">t</span> <span class="o">-&gt;</span>
  <span class="n">t</span> <span class="o">-&gt;</span>
  <span class="nn">Arr</span><span class="p">.</span><span class="n">t</span>
</code></pre></div>

<p>Predict class labels for samples in X.</p>
<h4>Parameters</h4>
<details class="info" open="open"><summary>X : array_like or sparse matrix, shape (n_samples, n_features)</summary><p>Samples.</p>
</details>
<h4>Returns</h4>
<details class="info" open="open"><summary>C : array, shape [n_samples]</summary><p>Predicted class label per sample.</p>
</details>
</details>
<h3 id="score_24">score<a class="headerlink" href="#score_24" title="Permanent link">&para;</a></h3>
<details class="note" open="open"><summary>method</summary><div class="highlight"><pre><span></span><code><span class="k">val</span> <span class="n">score</span> <span class="o">:</span>
  <span class="o">?</span><span class="n">sample_weight</span><span class="o">:</span><span class="nn">Arr</span><span class="p">.</span><span class="n">t</span> <span class="o">-&gt;</span>
  <span class="n">x</span><span class="o">:</span><span class="nn">Arr</span><span class="p">.</span><span class="n">t</span> <span class="o">-&gt;</span>
  <span class="n">y</span><span class="o">:</span><span class="nn">Arr</span><span class="p">.</span><span class="n">t</span> <span class="o">-&gt;</span>
  <span class="n">t</span> <span class="o">-&gt;</span>
  <span class="kt">float</span>
</code></pre></div>

<p>Return the mean accuracy on the given test data and labels.</p>
<p>In multi-label classification, this is the subset accuracy
which is a harsh metric since you require for each sample that
each label set be correctly predicted.</p>
<h4>Parameters</h4>
<details class="info" open="open"><summary>X : array-like of shape (n_samples, n_features)</summary><p>Test samples.</p>
</details>
<details class="info" open="open"><summary>y : array-like of shape (n_samples,) or (n_samples, n_outputs)</summary><p>True labels for X.</p>
</details>
<details class="info" open="open"><summary>sample_weight : array-like of shape (n_samples,), default=None</summary><p>Sample weights.</p>
</details>
<h4>Returns</h4>
<details class="info" open="open"><summary>score : float</summary><p>Mean accuracy of self.predict(X) wrt. y.</p>
</details>
</details>
<h3 id="set_params_24">set_params<a class="headerlink" href="#set_params_24" title="Permanent link">&para;</a></h3>
<details class="note" open="open"><summary>method</summary><div class="highlight"><pre><span></span><code><span class="k">val</span> <span class="n">set_params</span> <span class="o">:</span>
  <span class="o">?</span><span class="n">params</span><span class="o">:(</span><span class="kt">string</span> <span class="o">*</span> <span class="nn">Py</span><span class="p">.</span><span class="nn">Object</span><span class="p">.</span><span class="n">t</span><span class="o">)</span> <span class="kt">list</span> <span class="o">-&gt;</span>
  <span class="n">t</span> <span class="o">-&gt;</span>
  <span class="n">t</span>
</code></pre></div>

<p>Set the parameters of this estimator.</p>
<p>The method works on simple estimators as well as on nested objects
(such as pipelines). The latter have parameters of the form
<code>&lt;component&gt;__&lt;parameter&gt;</code> so that it's possible to update each
component of a nested object.</p>
<h4>Parameters</h4>
<details class="info" open="open"><summary>**params : dict</summary><p>Estimator parameters.</p>
</details>
<h4>Returns</h4>
<details class="info" open="open"><summary>self : object</summary><p>Estimator instance.</p>
</details>
</details>
<h3 id="coef__23">coef_<a class="headerlink" href="#coef__23" title="Permanent link">&para;</a></h3>
<details class="note" open="open"><summary>attribute</summary><div class="highlight"><pre><span></span><code><span class="k">val</span> <span class="n">coef_</span> <span class="o">:</span> <span class="n">t</span> <span class="o">-&gt;</span> <span class="nn">Arr</span><span class="p">.</span><span class="n">t</span>
<span class="k">val</span> <span class="n">coef_opt</span> <span class="o">:</span> <span class="n">t</span> <span class="o">-&gt;</span> <span class="o">(</span><span class="nn">Arr</span><span class="p">.</span><span class="n">t</span><span class="o">)</span> <span class="n">option</span>
</code></pre></div>

<p>This attribute is documented in <code>create</code> above. The first version raises Not_found
if the attribute is None. The _opt version returns an option.</p>
</details>
<h3 id="intercept__23">intercept_<a class="headerlink" href="#intercept__23" title="Permanent link">&para;</a></h3>
<details class="note" open="open"><summary>attribute</summary><div class="highlight"><pre><span></span><code><span class="k">val</span> <span class="n">intercept_</span> <span class="o">:</span> <span class="n">t</span> <span class="o">-&gt;</span> <span class="nn">Arr</span><span class="p">.</span><span class="n">t</span>
<span class="k">val</span> <span class="n">intercept_opt</span> <span class="o">:</span> <span class="n">t</span> <span class="o">-&gt;</span> <span class="o">(</span><span class="nn">Arr</span><span class="p">.</span><span class="n">t</span><span class="o">)</span> <span class="n">option</span>
</code></pre></div>

<p>This attribute is documented in <code>create</code> above. The first version raises Not_found
if the attribute is None. The _opt version returns an option.</p>
</details>
<h3 id="n_iter__20">n_iter_<a class="headerlink" href="#n_iter__20" title="Permanent link">&para;</a></h3>
<details class="note" open="open"><summary>attribute</summary><div class="highlight"><pre><span></span><code><span class="k">val</span> <span class="n">n_iter_</span> <span class="o">:</span> <span class="n">t</span> <span class="o">-&gt;</span> <span class="nn">Arr</span><span class="p">.</span><span class="n">t</span>
<span class="k">val</span> <span class="n">n_iter_opt</span> <span class="o">:</span> <span class="n">t</span> <span class="o">-&gt;</span> <span class="o">(</span><span class="nn">Arr</span><span class="p">.</span><span class="n">t</span><span class="o">)</span> <span class="n">option</span>
</code></pre></div>

<p>This attribute is documented in <code>create</code> above. The first version raises Not_found
if the attribute is None. The _opt version returns an option.</p>
</details>
<h3 id="classes__2">classes_<a class="headerlink" href="#classes__2" title="Permanent link">&para;</a></h3>
<details class="note" open="open"><summary>attribute</summary><div class="highlight"><pre><span></span><code><span class="k">val</span> <span class="n">classes_</span> <span class="o">:</span> <span class="n">t</span> <span class="o">-&gt;</span> <span class="nn">Arr</span><span class="p">.</span><span class="n">t</span>
<span class="k">val</span> <span class="n">classes_opt</span> <span class="o">:</span> <span class="n">t</span> <span class="o">-&gt;</span> <span class="o">(</span><span class="nn">Arr</span><span class="p">.</span><span class="n">t</span><span class="o">)</span> <span class="n">option</span>
</code></pre></div>

<p>This attribute is documented in <code>create</code> above. The first version raises Not_found
if the attribute is None. The _opt version returns an option.</p>
</details>
<h3 id="to_string_24">to_string<a class="headerlink" href="#to_string_24" title="Permanent link">&para;</a></h3>
<details class="note" open="open"><summary>method</summary><div class="highlight"><pre><span></span><code><span class="k">val</span> <span class="n">to_string</span><span class="o">:</span> <span class="n">t</span> <span class="o">-&gt;</span> <span class="kt">string</span>
</code></pre></div>

<p>Print the object to a human-readable representation.</p>
</details>
<h3 id="show_24">show<a class="headerlink" href="#show_24" title="Permanent link">&para;</a></h3>
<details class="note" open="open"><summary>method</summary><div class="highlight"><pre><span></span><code><span class="k">val</span> <span class="n">show</span><span class="o">:</span> <span class="n">t</span> <span class="o">-&gt;</span> <span class="kt">string</span>
</code></pre></div>

<p>Print the object to a human-readable representation.</p>
</details>
<h3 id="pp_24">pp<a class="headerlink" href="#pp_24" title="Permanent link">&para;</a></h3>
<details class="note" open="open"><summary>method</summary><div class="highlight"><pre><span></span><code><span class="k">val</span> <span class="n">pp</span><span class="o">:</span> <span class="nn">Format</span><span class="p">.</span><span class="n">formatter</span> <span class="o">-&gt;</span> <span class="n">t</span> <span class="o">-&gt;</span> <span class="kt">unit</span>
</code></pre></div>

<p>Pretty-print the object to a formatter.</p>
</details>
<h2 id="module-sklearnlinear_modelridgeclassifiercv">module Sklearn.​Linear_model.​RidgeClassifierCV<a class="headerlink" href="#module-sklearnlinear_modelridgeclassifiercv" title="Permanent link">&para;</a></h2>
<div class="highlight"><pre><span></span><code><span class="k">type</span> <span class="n">t</span>
</code></pre></div>

<h3 id="create_25">create<a class="headerlink" href="#create_25" title="Permanent link">&para;</a></h3>
<details class="note" open="open"><summary>constructor and attributes</summary><div class="highlight"><pre><span></span><code><span class="k">val</span> <span class="n">create</span> <span class="o">:</span>
  <span class="o">?</span><span class="n">alphas</span><span class="o">:</span><span class="nn">Arr</span><span class="p">.</span><span class="n">t</span> <span class="o">-&gt;</span>
  <span class="o">?</span><span class="n">fit_intercept</span><span class="o">:</span><span class="kt">bool</span> <span class="o">-&gt;</span>
  <span class="o">?</span><span class="n">normalize</span><span class="o">:</span><span class="kt">bool</span> <span class="o">-&gt;</span>
  <span class="o">?</span><span class="n">scoring</span><span class="o">:[`</span><span class="nc">S</span> <span class="k">of</span> <span class="kt">string</span> <span class="o">|</span> <span class="o">`</span><span class="nc">Callable</span> <span class="k">of</span> <span class="nn">Py</span><span class="p">.</span><span class="nn">Object</span><span class="p">.</span><span class="n">t</span><span class="o">]</span> <span class="o">-&gt;</span>
  <span class="o">?</span><span class="n">cv</span><span class="o">:[`</span><span class="nc">I</span> <span class="k">of</span> <span class="kt">int</span> <span class="o">|</span> <span class="o">`</span><span class="nc">CrossValGenerator</span> <span class="k">of</span> <span class="nn">Py</span><span class="p">.</span><span class="nn">Object</span><span class="p">.</span><span class="n">t</span> <span class="o">|</span> <span class="o">`</span><span class="nc">Arr</span> <span class="k">of</span> <span class="nn">Arr</span><span class="p">.</span><span class="n">t</span><span class="o">]</span> <span class="o">-&gt;</span>
  <span class="o">?</span><span class="n">class_weight</span><span class="o">:[`</span><span class="nc">DictIntToFloat</span> <span class="k">of</span> <span class="o">(</span><span class="kt">int</span> <span class="o">*</span> <span class="kt">float</span><span class="o">)</span> <span class="kt">list</span> <span class="o">|</span> <span class="o">`</span><span class="nc">Balanced</span><span class="o">]</span> <span class="o">-&gt;</span>
  <span class="o">?</span><span class="n">store_cv_values</span><span class="o">:</span><span class="kt">bool</span> <span class="o">-&gt;</span>
  <span class="kt">unit</span> <span class="o">-&gt;</span>
  <span class="n">t</span>
</code></pre></div>

<p>Ridge classifier with built-in cross-validation.</p>
<p>See glossary entry for :term:<code>cross-validation estimator</code>.</p>
<p>By default, it performs Generalized Cross-Validation, which is a form of
efficient Leave-One-Out cross-validation. Currently, only the n_features &gt;
n_samples case is handled efficiently.</p>
<p>Read more in the :ref:<code>User Guide &lt;ridge_regression&gt;</code>.</p>
<h4>Parameters</h4>
<details class="info" open="open"><summary>alphas : ndarray of shape (n_alphas,), default=(0.1, 1.0, 10.0)</summary><p>Array of alpha values to try.
Regularization strength; must be a positive float. Regularization
improves the conditioning of the problem and reduces the variance of
the estimates. Larger values specify stronger regularization.
Alpha corresponds to <code>C^-1</code> in other linear models such as
LogisticRegression or LinearSVC.</p>
</details>
<details class="info" open="open"><summary>fit_intercept : bool, default=True</summary><p>Whether to calculate the intercept for this model. If set
to false, no intercept will be used in calculations
(i.e. data is expected to be centered).</p>
</details>
<details class="info" open="open"><summary>normalize : bool, default=False</summary><p>This parameter is ignored when <code>fit_intercept</code> is set to False.
If True, the regressors X will be normalized before regression by
subtracting the mean and dividing by the l2-norm.
If you wish to standardize, please use
:class:<code>sklearn.preprocessing.StandardScaler</code> before calling <code>fit</code>
on an estimator with <code>normalize=False</code>.</p>
</details>
<details class="info" open="open"><summary>scoring : string, callable, default=None</summary><p>A string (see model evaluation documentation) or
a scorer callable object / function with signature
<code>scorer(estimator, X, y)</code>.</p>
</details>
<details class="info" open="open"><summary>cv : int, cross-validation generator or an iterable, default=None</summary><p>Determines the cross-validation splitting strategy.
Possible inputs for cv are:</p>
<ul>
<li>None, to use the efficient Leave-One-Out cross-validation</li>
<li>integer, to specify the number of folds.</li>
<li>:term:<code>CV splitter</code>,</li>
<li>An iterable yielding (train, test) splits as arrays of indices.</li>
</ul>
</details>
<details class="info" open="open"><summary>Refer :ref:<code>User Guide &lt;cross_validation&gt;</code> for the various</summary><p>cross-validation strategies that can be used here.</p>
</details>
<details class="info" open="open"><summary>class_weight : dict or 'balanced', default=None</summary><p>Weights associated with classes in the form <code>{class_label: weight}</code>.
If not given, all classes are supposed to have weight one.</p>
<p>The "balanced" mode uses the values of y to automatically adjust
weights inversely proportional to class frequencies in the input data
as <code>n_samples / (n_classes * np.bincount(y))</code></p>
</details>
<details class="info" open="open"><summary>store_cv_values : bool, default=False</summary><p>Flag indicating if the cross-validation values corresponding to
each alpha should be stored in the <code>cv_values_</code> attribute (see
below). This flag is only compatible with <code>cv=None</code> (i.e. using
Generalized Cross-Validation).</p>
</details>
<h4>Attributes</h4>
<details class="info" open="open"><summary>cv_values_ : ndarray of shape (n_samples, n_targets, n_alphas), optional</summary><p>Cross-validation values for each alpha (if <code>store_cv_values=True</code> and
<code>cv=None</code>). After <code>fit()</code> has been called, this attribute will
contain the mean squared errors (by default) or the values of the
<code>{loss,score}_func</code> function (if provided in the constructor). This
attribute exists only when <code>store_cv_values</code> is True.</p>
</details>
<details class="info" open="open"><summary>coef_ : ndarray of shape (1, n_features) or (n_targets, n_features)</summary><p>Coefficient of the features in the decision function.</p>
<p><code>coef_</code> is of shape (1, n_features) when the given problem is binary.</p>
</details>
<details class="info" open="open"><summary>intercept_ : float or ndarray of shape (n_targets,)</summary><p>Independent term in decision function. Set to 0.0 if
<code>fit_intercept = False</code>.</p>
</details>
<details class="info" open="open"><summary>alpha_ : float</summary><p>Estimated regularization parameter</p>
</details>
<details class="info" open="open"><summary>classes_ : ndarray of shape (n_classes,)</summary><p>The classes labels.</p>
</details>
<h4>Examples</h4>
<div class="highlight"><pre><span></span><code><span class="o">&gt;&gt;&gt;</span> <span class="kn">from</span> <span class="nn">sklearn.datasets</span> <span class="kn">import</span> <span class="n">load_breast_cancer</span>
<span class="o">&gt;&gt;&gt;</span> <span class="kn">from</span> <span class="nn">sklearn.linear_model</span> <span class="kn">import</span> <span class="n">RidgeClassifierCV</span>
<span class="o">&gt;&gt;&gt;</span> <span class="n">X</span><span class="p">,</span> <span class="n">y</span> <span class="o">=</span> <span class="n">load_breast_cancer</span><span class="p">(</span><span class="n">return_X_y</span><span class="o">=</span><span class="kc">True</span><span class="p">)</span>
<span class="o">&gt;&gt;&gt;</span> <span class="n">clf</span> <span class="o">=</span> <span class="n">RidgeClassifierCV</span><span class="p">(</span><span class="n">alphas</span><span class="o">=</span><span class="p">[</span><span class="mf">1e-3</span><span class="p">,</span> <span class="mf">1e-2</span><span class="p">,</span> <span class="mf">1e-1</span><span class="p">,</span> <span class="mi">1</span><span class="p">])</span><span class="o">.</span><span class="n">fit</span><span class="p">(</span><span class="n">X</span><span class="p">,</span> <span class="n">y</span><span class="p">)</span>
<span class="o">&gt;&gt;&gt;</span> <span class="n">clf</span><span class="o">.</span><span class="n">score</span><span class="p">(</span><span class="n">X</span><span class="p">,</span> <span class="n">y</span><span class="p">)</span>
<span class="mf">0.9630</span><span class="o">...</span>
</code></pre></div>

<h4>See also</h4>
<details class="info" open="open"><summary>Ridge : Ridge regression</summary></details>
<details class="info" open="open"><summary>RidgeClassifier : Ridge classifier</summary></details>
<details class="info" open="open"><summary>RidgeCV : Ridge regression with built-in cross validation</summary></details>
<h4>Notes</h4>
<p>For multi-class classification, n_class classifiers are trained in
a one-versus-all approach. Concretely, this is implemented by taking
advantage of the multi-variate response support in Ridge.</p>
</details>
<h3 id="decision_function_3">decision_function<a class="headerlink" href="#decision_function_3" title="Permanent link">&para;</a></h3>
<details class="note" open="open"><summary>method</summary><div class="highlight"><pre><span></span><code><span class="k">val</span> <span class="n">decision_function</span> <span class="o">:</span>
  <span class="n">x</span><span class="o">:</span><span class="nn">Arr</span><span class="p">.</span><span class="n">t</span> <span class="o">-&gt;</span>
  <span class="n">t</span> <span class="o">-&gt;</span>
  <span class="nn">Arr</span><span class="p">.</span><span class="n">t</span>
</code></pre></div>

<p>Predict confidence scores for samples.</p>
<p>The confidence score for a sample is the signed distance of that
sample to the hyperplane.</p>
<h4>Parameters</h4>
<details class="info" open="open"><summary>X : array_like or sparse matrix, shape (n_samples, n_features)</summary><p>Samples.</p>
</details>
<h4>Returns</h4>
<p>array, shape=(n_samples,) if n_classes == 2 else (n_samples, n_classes)
    Confidence scores per (sample, class) combination. In the binary
    case, confidence score for self.classes_[1] where &gt;0 means this
    class would be predicted.</p>
</details>
<h3 id="fit_25">fit<a class="headerlink" href="#fit_25" title="Permanent link">&para;</a></h3>
<details class="note" open="open"><summary>method</summary><div class="highlight"><pre><span></span><code><span class="k">val</span> <span class="n">fit</span> <span class="o">:</span>
  <span class="o">?</span><span class="n">sample_weight</span><span class="o">:[`</span><span class="nc">F</span> <span class="k">of</span> <span class="kt">float</span> <span class="o">|</span> <span class="o">`</span><span class="nc">Arr</span> <span class="k">of</span> <span class="nn">Arr</span><span class="p">.</span><span class="n">t</span><span class="o">]</span> <span class="o">-&gt;</span>
  <span class="n">x</span><span class="o">:</span><span class="nn">Arr</span><span class="p">.</span><span class="n">t</span> <span class="o">-&gt;</span>
  <span class="n">y</span><span class="o">:</span><span class="nn">Arr</span><span class="p">.</span><span class="n">t</span> <span class="o">-&gt;</span>
  <span class="n">t</span> <span class="o">-&gt;</span>
  <span class="n">t</span>
</code></pre></div>

<p>Fit Ridge classifier with cv.</p>
<h4>Parameters</h4>
<details class="info" open="open"><summary>X : ndarray of shape (n_samples, n_features)</summary><p>Training vectors, where n_samples is the number of samples
and n_features is the number of features. When using GCV,
will be cast to float64 if necessary.</p>
</details>
<details class="info" open="open"><summary>y : ndarray of shape (n_samples,)</summary><p>Target values. Will be cast to X's dtype if necessary.</p>
</details>
<details class="info" open="open"><summary>sample_weight : float or ndarray of shape (n_samples,), default=None</summary><p>Individual weights for each sample. If given a float, every sample
will have the same weight.</p>
</details>
<h4>Returns</h4>
<details class="info" open="open"><summary>self : object</summary></details>
</details>
<h3 id="get_params_25">get_params<a class="headerlink" href="#get_params_25" title="Permanent link">&para;</a></h3>
<details class="note" open="open"><summary>method</summary><div class="highlight"><pre><span></span><code><span class="k">val</span> <span class="n">get_params</span> <span class="o">:</span>
  <span class="o">?</span><span class="n">deep</span><span class="o">:</span><span class="kt">bool</span> <span class="o">-&gt;</span>
  <span class="n">t</span> <span class="o">-&gt;</span>
  <span class="nn">Dict</span><span class="p">.</span><span class="n">t</span>
</code></pre></div>

<p>Get parameters for this estimator.</p>
<h4>Parameters</h4>
<details class="info" open="open"><summary>deep : bool, default=True</summary><p>If True, will return the parameters for this estimator and
contained subobjects that are estimators.</p>
</details>
<h4>Returns</h4>
<details class="info" open="open"><summary>params : mapping of string to any</summary><p>Parameter names mapped to their values.</p>
</details>
</details>
<h3 id="predict_25">predict<a class="headerlink" href="#predict_25" title="Permanent link">&para;</a></h3>
<details class="note" open="open"><summary>method</summary><div class="highlight"><pre><span></span><code><span class="k">val</span> <span class="n">predict</span> <span class="o">:</span>
  <span class="n">x</span><span class="o">:</span><span class="nn">Arr</span><span class="p">.</span><span class="n">t</span> <span class="o">-&gt;</span>
  <span class="n">t</span> <span class="o">-&gt;</span>
  <span class="nn">Arr</span><span class="p">.</span><span class="n">t</span>
</code></pre></div>

<p>Predict class labels for samples in X.</p>
<h4>Parameters</h4>
<details class="info" open="open"><summary>X : array_like or sparse matrix, shape (n_samples, n_features)</summary><p>Samples.</p>
</details>
<h4>Returns</h4>
<details class="info" open="open"><summary>C : array, shape [n_samples]</summary><p>Predicted class label per sample.</p>
</details>
</details>
<h3 id="score_25">score<a class="headerlink" href="#score_25" title="Permanent link">&para;</a></h3>
<details class="note" open="open"><summary>method</summary><div class="highlight"><pre><span></span><code><span class="k">val</span> <span class="n">score</span> <span class="o">:</span>
  <span class="o">?</span><span class="n">sample_weight</span><span class="o">:</span><span class="nn">Arr</span><span class="p">.</span><span class="n">t</span> <span class="o">-&gt;</span>
  <span class="n">x</span><span class="o">:</span><span class="nn">Arr</span><span class="p">.</span><span class="n">t</span> <span class="o">-&gt;</span>
  <span class="n">y</span><span class="o">:</span><span class="nn">Arr</span><span class="p">.</span><span class="n">t</span> <span class="o">-&gt;</span>
  <span class="n">t</span> <span class="o">-&gt;</span>
  <span class="kt">float</span>
</code></pre></div>

<p>Return the mean accuracy on the given test data and labels.</p>
<p>In multi-label classification, this is the subset accuracy
which is a harsh metric since you require for each sample that
each label set be correctly predicted.</p>
<h4>Parameters</h4>
<details class="info" open="open"><summary>X : array-like of shape (n_samples, n_features)</summary><p>Test samples.</p>
</details>
<details class="info" open="open"><summary>y : array-like of shape (n_samples,) or (n_samples, n_outputs)</summary><p>True labels for X.</p>
</details>
<details class="info" open="open"><summary>sample_weight : array-like of shape (n_samples,), default=None</summary><p>Sample weights.</p>
</details>
<h4>Returns</h4>
<details class="info" open="open"><summary>score : float</summary><p>Mean accuracy of self.predict(X) wrt. y.</p>
</details>
</details>
<h3 id="set_params_25">set_params<a class="headerlink" href="#set_params_25" title="Permanent link">&para;</a></h3>
<details class="note" open="open"><summary>method</summary><div class="highlight"><pre><span></span><code><span class="k">val</span> <span class="n">set_params</span> <span class="o">:</span>
  <span class="o">?</span><span class="n">params</span><span class="o">:(</span><span class="kt">string</span> <span class="o">*</span> <span class="nn">Py</span><span class="p">.</span><span class="nn">Object</span><span class="p">.</span><span class="n">t</span><span class="o">)</span> <span class="kt">list</span> <span class="o">-&gt;</span>
  <span class="n">t</span> <span class="o">-&gt;</span>
  <span class="n">t</span>
</code></pre></div>

<p>Set the parameters of this estimator.</p>
<p>The method works on simple estimators as well as on nested objects
(such as pipelines). The latter have parameters of the form
<code>&lt;component&gt;__&lt;parameter&gt;</code> so that it's possible to update each
component of a nested object.</p>
<h4>Parameters</h4>
<details class="info" open="open"><summary>**params : dict</summary><p>Estimator parameters.</p>
</details>
<h4>Returns</h4>
<details class="info" open="open"><summary>self : object</summary><p>Estimator instance.</p>
</details>
</details>
<h3 id="cv_values__1">cv_values_<a class="headerlink" href="#cv_values__1" title="Permanent link">&para;</a></h3>
<details class="note" open="open"><summary>attribute</summary><div class="highlight"><pre><span></span><code><span class="k">val</span> <span class="n">cv_values_</span> <span class="o">:</span> <span class="n">t</span> <span class="o">-&gt;</span> <span class="nn">Arr</span><span class="p">.</span><span class="n">t</span>
<span class="k">val</span> <span class="n">cv_values_opt</span> <span class="o">:</span> <span class="n">t</span> <span class="o">-&gt;</span> <span class="o">(</span><span class="nn">Arr</span><span class="p">.</span><span class="n">t</span><span class="o">)</span> <span class="n">option</span>
</code></pre></div>

<p>This attribute is documented in <code>create</code> above. The first version raises Not_found
if the attribute is None. The _opt version returns an option.</p>
</details>
<h3 id="coef__24">coef_<a class="headerlink" href="#coef__24" title="Permanent link">&para;</a></h3>
<details class="note" open="open"><summary>attribute</summary><div class="highlight"><pre><span></span><code><span class="k">val</span> <span class="n">coef_</span> <span class="o">:</span> <span class="n">t</span> <span class="o">-&gt;</span> <span class="nn">Arr</span><span class="p">.</span><span class="n">t</span>
<span class="k">val</span> <span class="n">coef_opt</span> <span class="o">:</span> <span class="n">t</span> <span class="o">-&gt;</span> <span class="o">(</span><span class="nn">Arr</span><span class="p">.</span><span class="n">t</span><span class="o">)</span> <span class="n">option</span>
</code></pre></div>

<p>This attribute is documented in <code>create</code> above. The first version raises Not_found
if the attribute is None. The _opt version returns an option.</p>
</details>
<h3 id="intercept__24">intercept_<a class="headerlink" href="#intercept__24" title="Permanent link">&para;</a></h3>
<details class="note" open="open"><summary>attribute</summary><div class="highlight"><pre><span></span><code><span class="k">val</span> <span class="n">intercept_</span> <span class="o">:</span> <span class="n">t</span> <span class="o">-&gt;</span> <span class="nn">Arr</span><span class="p">.</span><span class="n">t</span>
<span class="k">val</span> <span class="n">intercept_opt</span> <span class="o">:</span> <span class="n">t</span> <span class="o">-&gt;</span> <span class="o">(</span><span class="nn">Arr</span><span class="p">.</span><span class="n">t</span><span class="o">)</span> <span class="n">option</span>
</code></pre></div>

<p>This attribute is documented in <code>create</code> above. The first version raises Not_found
if the attribute is None. The _opt version returns an option.</p>
</details>
<h3 id="alpha__10">alpha_<a class="headerlink" href="#alpha__10" title="Permanent link">&para;</a></h3>
<details class="note" open="open"><summary>attribute</summary><div class="highlight"><pre><span></span><code><span class="k">val</span> <span class="n">alpha_</span> <span class="o">:</span> <span class="n">t</span> <span class="o">-&gt;</span> <span class="kt">float</span>
<span class="k">val</span> <span class="n">alpha_opt</span> <span class="o">:</span> <span class="n">t</span> <span class="o">-&gt;</span> <span class="o">(</span><span class="kt">float</span><span class="o">)</span> <span class="n">option</span>
</code></pre></div>

<p>This attribute is documented in <code>create</code> above. The first version raises Not_found
if the attribute is None. The _opt version returns an option.</p>
</details>
<h3 id="classes__3">classes_<a class="headerlink" href="#classes__3" title="Permanent link">&para;</a></h3>
<details class="note" open="open"><summary>attribute</summary><div class="highlight"><pre><span></span><code><span class="k">val</span> <span class="n">classes_</span> <span class="o">:</span> <span class="n">t</span> <span class="o">-&gt;</span> <span class="nn">Arr</span><span class="p">.</span><span class="n">t</span>
<span class="k">val</span> <span class="n">classes_opt</span> <span class="o">:</span> <span class="n">t</span> <span class="o">-&gt;</span> <span class="o">(</span><span class="nn">Arr</span><span class="p">.</span><span class="n">t</span><span class="o">)</span> <span class="n">option</span>
</code></pre></div>

<p>This attribute is documented in <code>create</code> above. The first version raises Not_found
if the attribute is None. The _opt version returns an option.</p>
</details>
<h3 id="to_string_25">to_string<a class="headerlink" href="#to_string_25" title="Permanent link">&para;</a></h3>
<details class="note" open="open"><summary>method</summary><div class="highlight"><pre><span></span><code><span class="k">val</span> <span class="n">to_string</span><span class="o">:</span> <span class="n">t</span> <span class="o">-&gt;</span> <span class="kt">string</span>
</code></pre></div>

<p>Print the object to a human-readable representation.</p>
</details>
<h3 id="show_25">show<a class="headerlink" href="#show_25" title="Permanent link">&para;</a></h3>
<details class="note" open="open"><summary>method</summary><div class="highlight"><pre><span></span><code><span class="k">val</span> <span class="n">show</span><span class="o">:</span> <span class="n">t</span> <span class="o">-&gt;</span> <span class="kt">string</span>
</code></pre></div>

<p>Print the object to a human-readable representation.</p>
</details>
<h3 id="pp_25">pp<a class="headerlink" href="#pp_25" title="Permanent link">&para;</a></h3>
<details class="note" open="open"><summary>method</summary><div class="highlight"><pre><span></span><code><span class="k">val</span> <span class="n">pp</span><span class="o">:</span> <span class="nn">Format</span><span class="p">.</span><span class="n">formatter</span> <span class="o">-&gt;</span> <span class="n">t</span> <span class="o">-&gt;</span> <span class="kt">unit</span>
</code></pre></div>

<p>Pretty-print the object to a formatter.</p>
</details>
<h2 id="module-sklearnlinear_modeltheilsenregressor">module Sklearn.​Linear_model.​TheilSenRegressor<a class="headerlink" href="#module-sklearnlinear_modeltheilsenregressor" title="Permanent link">&para;</a></h2>
<div class="highlight"><pre><span></span><code><span class="k">type</span> <span class="n">t</span>
</code></pre></div>

<h3 id="create_26">create<a class="headerlink" href="#create_26" title="Permanent link">&para;</a></h3>
<details class="note" open="open"><summary>constructor and attributes</summary><div class="highlight"><pre><span></span><code><span class="k">val</span> <span class="n">create</span> <span class="o">:</span>
  <span class="o">?</span><span class="n">fit_intercept</span><span class="o">:</span><span class="kt">bool</span> <span class="o">-&gt;</span>
  <span class="o">?</span><span class="n">copy_X</span><span class="o">:</span><span class="kt">bool</span> <span class="o">-&gt;</span>
  <span class="o">?</span><span class="n">max_subpopulation</span><span class="o">:</span><span class="kt">int</span> <span class="o">-&gt;</span>
  <span class="o">?</span><span class="n">n_subsamples</span><span class="o">:</span><span class="kt">int</span> <span class="o">-&gt;</span>
  <span class="o">?</span><span class="n">max_iter</span><span class="o">:</span><span class="kt">int</span> <span class="o">-&gt;</span>
  <span class="o">?</span><span class="n">tol</span><span class="o">:</span><span class="kt">float</span> <span class="o">-&gt;</span>
  <span class="o">?</span><span class="n">random_state</span><span class="o">:</span><span class="kt">int</span> <span class="o">-&gt;</span>
  <span class="o">?</span><span class="n">n_jobs</span><span class="o">:</span><span class="kt">int</span> <span class="o">-&gt;</span>
  <span class="o">?</span><span class="n">verbose</span><span class="o">:</span><span class="kt">int</span> <span class="o">-&gt;</span>
  <span class="kt">unit</span> <span class="o">-&gt;</span>
  <span class="n">t</span>
</code></pre></div>

<p>Theil-Sen Estimator: robust multivariate regression model.</p>
<p>The algorithm calculates least square solutions on subsets with size
n_subsamples of the samples in X. Any value of n_subsamples between the
number of features and samples leads to an estimator with a compromise
between robustness and efficiency. Since the number of least square
solutions is "n_samples choose n_subsamples", it can be extremely large
and can therefore be limited with max_subpopulation. If this limit is
reached, the subsets are chosen randomly. In a final step, the spatial
median (or L1 median) is calculated of all least square solutions.</p>
<p>Read more in the :ref:<code>User Guide &lt;theil_sen_regression&gt;</code>.</p>
<h4>Parameters</h4>
<details class="info" open="open"><summary>fit_intercept : boolean, optional, default True</summary><p>Whether to calculate the intercept for this model. If set
to false, no intercept will be used in calculations.</p>
</details>
<details class="info" open="open"><summary>copy_X : boolean, optional, default True</summary><p>If True, X will be copied; else, it may be overwritten.</p>
</details>
<details class="info" open="open"><summary>max_subpopulation : int, optional, default 1e4</summary><p>Instead of computing with a set of cardinality 'n choose k', where n is
the number of samples and k is the number of subsamples (at least
number of features), consider only a stochastic subpopulation of a
given maximal size if 'n choose k' is larger than max_subpopulation.
For other than small problem sizes this parameter will determine
memory usage and runtime if n_subsamples is not changed.</p>
</details>
<details class="info" open="open"><summary>n_subsamples : int, optional, default None</summary><p>Number of samples to calculate the parameters. This is at least the
number of features (plus 1 if fit_intercept=True) and the number of
samples as a maximum. A lower number leads to a higher breakdown
point and a low efficiency while a high number leads to a low
breakdown point and a high efficiency. If None, take the
minimum number of subsamples leading to maximal robustness.
If n_subsamples is set to n_samples, Theil-Sen is identical to least
squares.</p>
</details>
<details class="info" open="open"><summary>max_iter : int, optional, default 300</summary><p>Maximum number of iterations for the calculation of spatial median.</p>
</details>
<details class="info" open="open"><summary>tol : float, optional, default 1.e-3</summary><p>Tolerance when calculating spatial median.</p>
</details>
<details class="info" open="open"><summary>random_state : int, RandomState instance or None, optional, default None</summary><p>A random number generator instance to define the state of the random
permutations generator.  If int, random_state is the seed used by the
random number generator; If RandomState instance, random_state is the
random number generator; If None, the random number generator is the
RandomState instance used by <code>np.random</code>.</p>
</details>
<details class="info" open="open"><summary>n_jobs : int or None, optional (default=None)</summary><p>Number of CPUs to use during the cross validation.
<code>None</code> means 1 unless in a :obj:<code>joblib.parallel_backend</code> context.
<code>-1</code> means using all processors. See :term:<code>Glossary &lt;n_jobs&gt;</code>
for more details.</p>
</details>
<details class="info" open="open"><summary>verbose : boolean, optional, default False</summary><p>Verbose mode when fitting the model.</p>
</details>
<h4>Attributes</h4>
<details class="info" open="open"><summary>coef_ : array, shape = (n_features)</summary><p>Coefficients of the regression model (median of distribution).</p>
</details>
<details class="info" open="open"><summary>intercept_ : float</summary><p>Estimated intercept of regression model.</p>
</details>
<details class="info" open="open"><summary>breakdown_ : float</summary><p>Approximated breakdown point.</p>
</details>
<details class="info" open="open"><summary>n_iter_ : int</summary><p>Number of iterations needed for the spatial median.</p>
</details>
<details class="info" open="open"><summary>n_subpopulation_ : int</summary><p>Number of combinations taken into account from 'n choose k', where n is
the number of samples and k is the number of subsamples.</p>
</details>
<h4>Examples</h4>
<div class="highlight"><pre><span></span><code><span class="o">&gt;&gt;&gt;</span> <span class="kn">from</span> <span class="nn">sklearn.linear_model</span> <span class="kn">import</span> <span class="n">TheilSenRegressor</span>
<span class="o">&gt;&gt;&gt;</span> <span class="kn">from</span> <span class="nn">sklearn.datasets</span> <span class="kn">import</span> <span class="n">make_regression</span>
<span class="o">&gt;&gt;&gt;</span> <span class="n">X</span><span class="p">,</span> <span class="n">y</span> <span class="o">=</span> <span class="n">make_regression</span><span class="p">(</span>
<span class="o">...</span>     <span class="n">n_samples</span><span class="o">=</span><span class="mi">200</span><span class="p">,</span> <span class="n">n_features</span><span class="o">=</span><span class="mi">2</span><span class="p">,</span> <span class="n">noise</span><span class="o">=</span><span class="mf">4.0</span><span class="p">,</span> <span class="n">random_state</span><span class="o">=</span><span class="mi">0</span><span class="p">)</span>
<span class="o">&gt;&gt;&gt;</span> <span class="n">reg</span> <span class="o">=</span> <span class="n">TheilSenRegressor</span><span class="p">(</span><span class="n">random_state</span><span class="o">=</span><span class="mi">0</span><span class="p">)</span><span class="o">.</span><span class="n">fit</span><span class="p">(</span><span class="n">X</span><span class="p">,</span> <span class="n">y</span><span class="p">)</span>
<span class="o">&gt;&gt;&gt;</span> <span class="n">reg</span><span class="o">.</span><span class="n">score</span><span class="p">(</span><span class="n">X</span><span class="p">,</span> <span class="n">y</span><span class="p">)</span>
<span class="mf">0.9884</span><span class="o">...</span>
<span class="o">&gt;&gt;&gt;</span> <span class="n">reg</span><span class="o">.</span><span class="n">predict</span><span class="p">(</span><span class="n">X</span><span class="p">[:</span><span class="mi">1</span><span class="p">,])</span>
<span class="n">array</span><span class="p">([</span><span class="o">-</span><span class="mf">31.5871</span><span class="o">...</span><span class="p">])</span>
</code></pre></div>

<h4>References</h4>
<ul>
<li>Theil-Sen Estimators in a Multiple Linear Regression Model, 2009
  Xin Dang, Hanxiang Peng, Xueqin Wang and Heping Zhang</li>
</ul>
<details class="info" open="open"><summary>http://home.olemiss.edu/~xdang/papers/MTSE.pdf</summary></details>
</details>
<h3 id="fit_26">fit<a class="headerlink" href="#fit_26" title="Permanent link">&para;</a></h3>
<details class="note" open="open"><summary>method</summary><div class="highlight"><pre><span></span><code><span class="k">val</span> <span class="n">fit</span> <span class="o">:</span>
  <span class="n">x</span><span class="o">:</span><span class="nn">Arr</span><span class="p">.</span><span class="n">t</span> <span class="o">-&gt;</span>
  <span class="n">y</span><span class="o">:</span><span class="nn">Py</span><span class="p">.</span><span class="nn">Object</span><span class="p">.</span><span class="n">t</span> <span class="o">-&gt;</span>
  <span class="n">t</span> <span class="o">-&gt;</span>
  <span class="n">t</span>
</code></pre></div>

<p>Fit linear model.</p>
<h4>Parameters</h4>
<details class="info" open="open"><summary>X : numpy array of shape [n_samples, n_features]</summary><p>Training data</p>
</details>
<details class="info" open="open"><summary>y : numpy array of shape [n_samples]</summary><p>Target values</p>
</details>
<h4>Returns</h4>
<details class="info" open="open"><summary>self : returns an instance of self.</summary></details>
</details>
<h3 id="get_params_26">get_params<a class="headerlink" href="#get_params_26" title="Permanent link">&para;</a></h3>
<details class="note" open="open"><summary>method</summary><div class="highlight"><pre><span></span><code><span class="k">val</span> <span class="n">get_params</span> <span class="o">:</span>
  <span class="o">?</span><span class="n">deep</span><span class="o">:</span><span class="kt">bool</span> <span class="o">-&gt;</span>
  <span class="n">t</span> <span class="o">-&gt;</span>
  <span class="nn">Dict</span><span class="p">.</span><span class="n">t</span>
</code></pre></div>

<p>Get parameters for this estimator.</p>
<h4>Parameters</h4>
<details class="info" open="open"><summary>deep : bool, default=True</summary><p>If True, will return the parameters for this estimator and
contained subobjects that are estimators.</p>
</details>
<h4>Returns</h4>
<details class="info" open="open"><summary>params : mapping of string to any</summary><p>Parameter names mapped to their values.</p>
</details>
</details>
<h3 id="predict_26">predict<a class="headerlink" href="#predict_26" title="Permanent link">&para;</a></h3>
<details class="note" open="open"><summary>method</summary><div class="highlight"><pre><span></span><code><span class="k">val</span> <span class="n">predict</span> <span class="o">:</span>
  <span class="n">x</span><span class="o">:</span><span class="nn">Arr</span><span class="p">.</span><span class="n">t</span> <span class="o">-&gt;</span>
  <span class="n">t</span> <span class="o">-&gt;</span>
  <span class="nn">Arr</span><span class="p">.</span><span class="n">t</span>
</code></pre></div>

<p>Predict using the linear model.</p>
<h4>Parameters</h4>
<details class="info" open="open"><summary>X : array_like or sparse matrix, shape (n_samples, n_features)</summary><p>Samples.</p>
</details>
<h4>Returns</h4>
<details class="info" open="open"><summary>C : array, shape (n_samples,)</summary><p>Returns predicted values.</p>
</details>
</details>
<h3 id="score_26">score<a class="headerlink" href="#score_26" title="Permanent link">&para;</a></h3>
<details class="note" open="open"><summary>method</summary><div class="highlight"><pre><span></span><code><span class="k">val</span> <span class="n">score</span> <span class="o">:</span>
  <span class="o">?</span><span class="n">sample_weight</span><span class="o">:</span><span class="nn">Arr</span><span class="p">.</span><span class="n">t</span> <span class="o">-&gt;</span>
  <span class="n">x</span><span class="o">:</span><span class="nn">Arr</span><span class="p">.</span><span class="n">t</span> <span class="o">-&gt;</span>
  <span class="n">y</span><span class="o">:</span><span class="nn">Arr</span><span class="p">.</span><span class="n">t</span> <span class="o">-&gt;</span>
  <span class="n">t</span> <span class="o">-&gt;</span>
  <span class="kt">float</span>
</code></pre></div>

<p>Return the coefficient of determination R^2 of the prediction.</p>
<p>The coefficient R^2 is defined as (1 - u/v), where u is the residual
sum of squares ((y_true - y_pred) <strong> 2).sum() and v is the total
sum of squares ((y_true - y_true.mean()) </strong> 2).sum().
The best possible score is 1.0 and it can be negative (because the
model can be arbitrarily worse). A constant model that always
predicts the expected value of y, disregarding the input features,
would get a R^2 score of 0.0.</p>
<h4>Parameters</h4>
<details class="info" open="open"><summary>X : array-like of shape (n_samples, n_features)</summary><p>Test samples. For some estimators this may be a
precomputed kernel matrix or a list of generic objects instead,
shape = (n_samples, n_samples_fitted),
where n_samples_fitted is the number of
samples used in the fitting for the estimator.</p>
</details>
<details class="info" open="open"><summary>y : array-like of shape (n_samples,) or (n_samples, n_outputs)</summary><p>True values for X.</p>
</details>
<details class="info" open="open"><summary>sample_weight : array-like of shape (n_samples,), default=None</summary><p>Sample weights.</p>
</details>
<h4>Returns</h4>
<details class="info" open="open"><summary>score : float</summary><p>R^2 of self.predict(X) wrt. y.</p>
</details>
<h4>Notes</h4>
<p>The R2 score used when calling <code>score</code> on a regressor will use
<code>multioutput='uniform_average'</code> from version 0.23 to keep consistent</p>
<details class="info" open="open"><summary>with :func:<code>~sklearn.metrics.r2_score</code>. This will influence the</summary></details>
<p><code>score</code> method of all the multioutput regressors (except for
:class:<code>~sklearn.multioutput.MultiOutputRegressor</code>). To specify the
default value manually and avoid the warning, please either call
:func:<code>~sklearn.metrics.r2_score</code> directly or make a custom scorer with
:func:<code>~sklearn.metrics.make_scorer</code> (the built-in scorer <code>'r2'</code> uses
<code>multioutput='uniform_average'</code>).</p>
</details>
<h3 id="set_params_26">set_params<a class="headerlink" href="#set_params_26" title="Permanent link">&para;</a></h3>
<details class="note" open="open"><summary>method</summary><div class="highlight"><pre><span></span><code><span class="k">val</span> <span class="n">set_params</span> <span class="o">:</span>
  <span class="o">?</span><span class="n">params</span><span class="o">:(</span><span class="kt">string</span> <span class="o">*</span> <span class="nn">Py</span><span class="p">.</span><span class="nn">Object</span><span class="p">.</span><span class="n">t</span><span class="o">)</span> <span class="kt">list</span> <span class="o">-&gt;</span>
  <span class="n">t</span> <span class="o">-&gt;</span>
  <span class="n">t</span>
</code></pre></div>

<p>Set the parameters of this estimator.</p>
<p>The method works on simple estimators as well as on nested objects
(such as pipelines). The latter have parameters of the form
<code>&lt;component&gt;__&lt;parameter&gt;</code> so that it's possible to update each
component of a nested object.</p>
<h4>Parameters</h4>
<details class="info" open="open"><summary>**params : dict</summary><p>Estimator parameters.</p>
</details>
<h4>Returns</h4>
<details class="info" open="open"><summary>self : object</summary><p>Estimator instance.</p>
</details>
</details>
<h3 id="coef__25">coef_<a class="headerlink" href="#coef__25" title="Permanent link">&para;</a></h3>
<details class="note" open="open"><summary>attribute</summary><div class="highlight"><pre><span></span><code><span class="k">val</span> <span class="n">coef_</span> <span class="o">:</span> <span class="n">t</span> <span class="o">-&gt;</span> <span class="nn">Arr</span><span class="p">.</span><span class="n">t</span>
<span class="k">val</span> <span class="n">coef_opt</span> <span class="o">:</span> <span class="n">t</span> <span class="o">-&gt;</span> <span class="o">(</span><span class="nn">Arr</span><span class="p">.</span><span class="n">t</span><span class="o">)</span> <span class="n">option</span>
</code></pre></div>

<p>This attribute is documented in <code>create</code> above. The first version raises Not_found
if the attribute is None. The _opt version returns an option.</p>
</details>
<h3 id="intercept__25">intercept_<a class="headerlink" href="#intercept__25" title="Permanent link">&para;</a></h3>
<details class="note" open="open"><summary>attribute</summary><div class="highlight"><pre><span></span><code><span class="k">val</span> <span class="n">intercept_</span> <span class="o">:</span> <span class="n">t</span> <span class="o">-&gt;</span> <span class="nn">Arr</span><span class="p">.</span><span class="n">t</span>
<span class="k">val</span> <span class="n">intercept_opt</span> <span class="o">:</span> <span class="n">t</span> <span class="o">-&gt;</span> <span class="o">(</span><span class="nn">Arr</span><span class="p">.</span><span class="n">t</span><span class="o">)</span> <span class="n">option</span>
</code></pre></div>

<p>This attribute is documented in <code>create</code> above. The first version raises Not_found
if the attribute is None. The _opt version returns an option.</p>
</details>
<h3 id="breakdown_">breakdown_<a class="headerlink" href="#breakdown_" title="Permanent link">&para;</a></h3>
<details class="note" open="open"><summary>attribute</summary><div class="highlight"><pre><span></span><code><span class="k">val</span> <span class="n">breakdown_</span> <span class="o">:</span> <span class="n">t</span> <span class="o">-&gt;</span> <span class="kt">float</span>
<span class="k">val</span> <span class="n">breakdown_opt</span> <span class="o">:</span> <span class="n">t</span> <span class="o">-&gt;</span> <span class="o">(</span><span class="kt">float</span><span class="o">)</span> <span class="n">option</span>
</code></pre></div>

<p>This attribute is documented in <code>create</code> above. The first version raises Not_found
if the attribute is None. The _opt version returns an option.</p>
</details>
<h3 id="n_iter__21">n_iter_<a class="headerlink" href="#n_iter__21" title="Permanent link">&para;</a></h3>
<details class="note" open="open"><summary>attribute</summary><div class="highlight"><pre><span></span><code><span class="k">val</span> <span class="n">n_iter_</span> <span class="o">:</span> <span class="n">t</span> <span class="o">-&gt;</span> <span class="kt">int</span>
<span class="k">val</span> <span class="n">n_iter_opt</span> <span class="o">:</span> <span class="n">t</span> <span class="o">-&gt;</span> <span class="o">(</span><span class="kt">int</span><span class="o">)</span> <span class="n">option</span>
</code></pre></div>

<p>This attribute is documented in <code>create</code> above. The first version raises Not_found
if the attribute is None. The _opt version returns an option.</p>
</details>
<h3 id="n_subpopulation_">n_subpopulation_<a class="headerlink" href="#n_subpopulation_" title="Permanent link">&para;</a></h3>
<details class="note" open="open"><summary>attribute</summary><div class="highlight"><pre><span></span><code><span class="k">val</span> <span class="n">n_subpopulation_</span> <span class="o">:</span> <span class="n">t</span> <span class="o">-&gt;</span> <span class="kt">int</span>
<span class="k">val</span> <span class="n">n_subpopulation_opt</span> <span class="o">:</span> <span class="n">t</span> <span class="o">-&gt;</span> <span class="o">(</span><span class="kt">int</span><span class="o">)</span> <span class="n">option</span>
</code></pre></div>

<p>This attribute is documented in <code>create</code> above. The first version raises Not_found
if the attribute is None. The _opt version returns an option.</p>
</details>
<h3 id="to_string_26">to_string<a class="headerlink" href="#to_string_26" title="Permanent link">&para;</a></h3>
<details class="note" open="open"><summary>method</summary><div class="highlight"><pre><span></span><code><span class="k">val</span> <span class="n">to_string</span><span class="o">:</span> <span class="n">t</span> <span class="o">-&gt;</span> <span class="kt">string</span>
</code></pre></div>

<p>Print the object to a human-readable representation.</p>
</details>
<h3 id="show_26">show<a class="headerlink" href="#show_26" title="Permanent link">&para;</a></h3>
<details class="note" open="open"><summary>method</summary><div class="highlight"><pre><span></span><code><span class="k">val</span> <span class="n">show</span><span class="o">:</span> <span class="n">t</span> <span class="o">-&gt;</span> <span class="kt">string</span>
</code></pre></div>

<p>Print the object to a human-readable representation.</p>
</details>
<h3 id="pp_26">pp<a class="headerlink" href="#pp_26" title="Permanent link">&para;</a></h3>
<details class="note" open="open"><summary>method</summary><div class="highlight"><pre><span></span><code><span class="k">val</span> <span class="n">pp</span><span class="o">:</span> <span class="nn">Format</span><span class="p">.</span><span class="n">formatter</span> <span class="o">-&gt;</span> <span class="n">t</span> <span class="o">-&gt;</span> <span class="kt">unit</span>
</code></pre></div>

<p>Pretty-print the object to a formatter.</p>
</details>
<h3 id="enet_path">enet_path<a class="headerlink" href="#enet_path" title="Permanent link">&para;</a></h3>
<details class="note" open="open"><summary>function</summary><div class="highlight"><pre><span></span><code><span class="k">val</span> <span class="n">enet_path</span> <span class="o">:</span>
  <span class="o">?</span><span class="n">l1_ratio</span><span class="o">:</span><span class="kt">float</span> <span class="o">-&gt;</span>
  <span class="o">?</span><span class="n">eps</span><span class="o">:</span><span class="kt">float</span> <span class="o">-&gt;</span>
  <span class="o">?</span><span class="n">n_alphas</span><span class="o">:</span><span class="kt">int</span> <span class="o">-&gt;</span>
  <span class="o">?</span><span class="n">alphas</span><span class="o">:</span><span class="nn">Arr</span><span class="p">.</span><span class="n">t</span> <span class="o">-&gt;</span>
  <span class="o">?</span><span class="n">precompute</span><span class="o">:[`</span><span class="nc">Bool</span> <span class="k">of</span> <span class="kt">bool</span> <span class="o">|</span> <span class="o">`</span><span class="nc">Auto</span> <span class="o">|</span> <span class="o">`</span><span class="nc">Arr</span> <span class="k">of</span> <span class="nn">Arr</span><span class="p">.</span><span class="n">t</span><span class="o">]</span> <span class="o">-&gt;</span>
  <span class="o">?</span><span class="n">xy</span><span class="o">:</span><span class="nn">Arr</span><span class="p">.</span><span class="n">t</span> <span class="o">-&gt;</span>
  <span class="o">?</span><span class="n">copy_X</span><span class="o">:</span><span class="kt">bool</span> <span class="o">-&gt;</span>
  <span class="o">?</span><span class="n">coef_init</span><span class="o">:</span><span class="nn">Arr</span><span class="p">.</span><span class="n">t</span> <span class="o">-&gt;</span>
  <span class="o">?</span><span class="n">verbose</span><span class="o">:</span><span class="kt">int</span> <span class="o">-&gt;</span>
  <span class="o">?</span><span class="n">return_n_iter</span><span class="o">:</span><span class="kt">bool</span> <span class="o">-&gt;</span>
  <span class="o">?</span><span class="n">positive</span><span class="o">:</span><span class="kt">bool</span> <span class="o">-&gt;</span>
  <span class="o">?</span><span class="n">check_input</span><span class="o">:</span><span class="kt">bool</span> <span class="o">-&gt;</span>
  <span class="o">?</span><span class="n">params</span><span class="o">:(</span><span class="kt">string</span> <span class="o">*</span> <span class="nn">Py</span><span class="p">.</span><span class="nn">Object</span><span class="p">.</span><span class="n">t</span><span class="o">)</span> <span class="kt">list</span> <span class="o">-&gt;</span>
  <span class="n">x</span><span class="o">:</span><span class="nn">Arr</span><span class="p">.</span><span class="n">t</span> <span class="o">-&gt;</span>
  <span class="n">y</span><span class="o">:</span><span class="nn">Arr</span><span class="p">.</span><span class="n">t</span> <span class="o">-&gt;</span>
  <span class="kt">unit</span> <span class="o">-&gt;</span>
  <span class="o">(</span><span class="nn">Arr</span><span class="p">.</span><span class="n">t</span> <span class="o">*</span> <span class="nn">Arr</span><span class="p">.</span><span class="n">t</span> <span class="o">*</span> <span class="nn">Arr</span><span class="p">.</span><span class="n">t</span> <span class="o">*</span> <span class="nn">Arr</span><span class="p">.</span><span class="n">t</span><span class="o">)</span>
</code></pre></div>

<p>Compute elastic net path with coordinate descent.</p>
<p>The elastic net optimization function varies for mono and multi-outputs.</p>
<p>For mono-output tasks it is::</p>
<div class="codehilite"><pre><span></span><code>1 / (2 * n_samples) * ||y - Xw||^2_2
+ alpha * l1_ratio * ||w||_1
+ 0.5 * alpha * (1 - l1_ratio) * ||w||^2_2
</code></pre></div>


<p>For multi-output tasks it is::</p>
<div class="codehilite"><pre><span></span><code>(1 / (2 * n_samples)) * ||Y - XW||^Fro_2
+ alpha * l1_ratio * ||W||_21
+ 0.5 * alpha * (1 - l1_ratio) * ||W||_Fro^2
</code></pre></div>


<details class="info" open="open"><summary>Where::</summary><p>||W||<em>21 = \sum_i \sqrt{\sum_j w</em>{ij}^2}</p>
</details>
<p>i.e. the sum of norm of each row.</p>
<p>Read more in the :ref:<code>User Guide &lt;elastic_net&gt;</code>.</p>
<h4>Parameters</h4>
<details class="info" open="open"><summary>X : {array-like}, shape (n_samples, n_features)</summary><p>Training data. Pass directly as Fortran-contiguous data to avoid
unnecessary memory duplication. If <code>y</code> is mono-output then <code>X</code>
can be sparse.</p>
</details>
<details class="info" open="open"><summary>y : ndarray, shape (n_samples,) or (n_samples, n_outputs)</summary><p>Target values.</p>
</details>
<details class="info" open="open"><summary>l1_ratio : float, optional</summary><p>Number between 0 and 1 passed to elastic net (scaling between
l1 and l2 penalties). <code>l1_ratio=1</code> corresponds to the Lasso.</p>
</details>
<details class="info" open="open"><summary>eps : float</summary><p>Length of the path. <code>eps=1e-3</code> means that
<code>alpha_min / alpha_max = 1e-3</code>.</p>
</details>
<details class="info" open="open"><summary>n_alphas : int, optional</summary><p>Number of alphas along the regularization path.</p>
</details>
<details class="info" open="open"><summary>alphas : ndarray, optional</summary><p>List of alphas where to compute the models.
If None alphas are set automatically.</p>
</details>
<details class="info" open="open"><summary>precompute : True | False | 'auto' | array-like</summary><p>Whether to use a precomputed Gram matrix to speed up
calculations. If set to <code>'auto'</code> let us decide. The Gram
matrix can also be passed as argument.</p>
</details>
<details class="info" open="open"><summary>Xy : array-like, optional</summary><p>Xy = np.dot(X.T, y) that can be precomputed. It is useful
only when the Gram matrix is precomputed.</p>
</details>
<details class="info" open="open"><summary>copy_X : bool, optional, default True</summary><p>If <code>True</code>, X will be copied; else, it may be overwritten.</p>
</details>
<details class="info" open="open"><summary>coef_init : array, shape (n_features, ) | None</summary><p>The initial values of the coefficients.</p>
</details>
<details class="info" open="open"><summary>verbose : bool or int</summary><p>Amount of verbosity.</p>
</details>
<details class="info" open="open"><summary>return_n_iter : bool</summary><p>Whether to return the number of iterations or not.</p>
</details>
<details class="info" open="open"><summary>positive : bool, default False</summary><p>If set to True, forces coefficients to be positive.
(Only allowed when <code>y.ndim == 1</code>).</p>
</details>
<details class="info" open="open"><summary>check_input : bool, default True</summary><p>Skip input validation checks, including the Gram matrix when provided
assuming there are handled by the caller when check_input=False.</p>
</details>
<details class="info" open="open"><summary>**params : kwargs</summary><p>Keyword arguments passed to the coordinate descent solver.</p>
</details>
<h4>Returns</h4>
<details class="info" open="open"><summary>alphas : array, shape (n_alphas,)</summary><p>The alphas along the path where models are computed.</p>
</details>
<details class="info" open="open"><summary>coefs : array, shape (n_features, n_alphas) or             (n_outputs, n_features, n_alphas)</summary><p>Coefficients along the path.</p>
</details>
<details class="info" open="open"><summary>dual_gaps : array, shape (n_alphas,)</summary><p>The dual gaps at the end of the optimization for each alpha.</p>
</details>
<details class="info" open="open"><summary>n_iters : array-like, shape (n_alphas,)</summary><p>The number of iterations taken by the coordinate descent optimizer to
reach the specified tolerance for each alpha.
(Is returned when <code>return_n_iter</code> is set to True).</p>
</details>
<h4>See Also</h4>
<p>MultiTaskElasticNet
MultiTaskElasticNetCV
ElasticNet
ElasticNetCV</p>
<h4>Notes</h4>
<p>For an example, see
:ref:<code>examples/linear_model/plot_lasso_coordinate_descent_path.py
&lt;sphx_glr_auto_examples_linear_model_plot_lasso_coordinate_descent_path.py&gt;</code>.</p>
</details>
<h3 id="lars_path">lars_path<a class="headerlink" href="#lars_path" title="Permanent link">&para;</a></h3>
<details class="note" open="open"><summary>function</summary><div class="highlight"><pre><span></span><code><span class="k">val</span> <span class="n">lars_path</span> <span class="o">:</span>
  <span class="o">?</span><span class="n">xy</span><span class="o">:</span><span class="nn">Arr</span><span class="p">.</span><span class="n">t</span> <span class="o">-&gt;</span>
  <span class="o">?</span><span class="n">gram</span><span class="o">:[`</span><span class="nc">Auto</span> <span class="o">|</span> <span class="o">`</span><span class="nc">Arr</span> <span class="k">of</span> <span class="nn">Arr</span><span class="p">.</span><span class="n">t</span><span class="o">]</span> <span class="o">-&gt;</span>
  <span class="o">?</span><span class="n">max_iter</span><span class="o">:</span><span class="kt">int</span> <span class="o">-&gt;</span>
  <span class="o">?</span><span class="n">alpha_min</span><span class="o">:</span><span class="kt">float</span> <span class="o">-&gt;</span>
  <span class="o">?</span><span class="n">method_</span><span class="o">:[`</span><span class="nc">Lar</span> <span class="o">|</span> <span class="o">`</span><span class="nc">Lasso</span><span class="o">]</span> <span class="o">-&gt;</span>
  <span class="o">?</span><span class="n">copy_X</span><span class="o">:</span><span class="kt">bool</span> <span class="o">-&gt;</span>
  <span class="o">?</span><span class="n">eps</span><span class="o">:</span><span class="kt">float</span> <span class="o">-&gt;</span>
  <span class="o">?</span><span class="n">copy_Gram</span><span class="o">:</span><span class="kt">bool</span> <span class="o">-&gt;</span>
  <span class="o">?</span><span class="n">verbose</span><span class="o">:</span><span class="kt">int</span> <span class="o">-&gt;</span>
  <span class="o">?</span><span class="n">return_path</span><span class="o">:</span><span class="kt">bool</span> <span class="o">-&gt;</span>
  <span class="o">?</span><span class="n">return_n_iter</span><span class="o">:</span><span class="kt">bool</span> <span class="o">-&gt;</span>
  <span class="o">?</span><span class="n">positive</span><span class="o">:</span><span class="kt">bool</span> <span class="o">-&gt;</span>
  <span class="n">x</span><span class="o">:[`</span><span class="nc">Arr</span> <span class="k">of</span> <span class="nn">Arr</span><span class="p">.</span><span class="n">t</span> <span class="o">|</span> <span class="o">`</span><span class="nc">None</span><span class="o">]</span> <span class="o">-&gt;</span>
  <span class="n">y</span><span class="o">:[`</span><span class="nc">Arr</span> <span class="k">of</span> <span class="nn">Arr</span><span class="p">.</span><span class="n">t</span> <span class="o">|</span> <span class="o">`</span><span class="nc">None</span><span class="o">]</span> <span class="o">-&gt;</span>
  <span class="kt">unit</span> <span class="o">-&gt;</span>
  <span class="o">(</span><span class="nn">Arr</span><span class="p">.</span><span class="n">t</span> <span class="o">*</span> <span class="nn">Arr</span><span class="p">.</span><span class="n">t</span> <span class="o">*</span> <span class="nn">Arr</span><span class="p">.</span><span class="n">t</span> <span class="o">*</span> <span class="kt">int</span><span class="o">)</span>
</code></pre></div>

<p>Compute Least Angle Regression or Lasso path using LARS algorithm [1]</p>
<p>The optimization objective for the case method='lasso' is::</p>
<p>(1 / (2 * n_samples)) * ||y - Xw||^2_2 + alpha * ||w||_1</p>
<p>in the case of method='lars', the objective function is only known in
the form of an implicit equation (see discussion in [1])</p>
<p>Read more in the :ref:<code>User Guide &lt;least_angle_regression&gt;</code>.</p>
<h4>Parameters</h4>
<details class="info" open="open"><summary>X : None or array-like of shape (n_samples, n_features)</summary><p>Input data. Note that if X is None then the Gram matrix must be
specified, i.e., cannot be None or False.</p>
<p>.. deprecated:: 0.21</p>
<p>The use of <code>X</code> is <code>None</code> in combination with <code>Gram</code> is not
   <code>None</code> will be removed in v0.23. Use :func:<code>lars_path_gram</code>
   instead.</p>
</details>
<details class="info" open="open"><summary>y : None or array-like of shape (n_samples,)</summary><p>Input targets.</p>
</details>
<details class="info" open="open"><summary>Xy : array-like of shape (n_samples,) or (n_samples, n_targets),             default=None</summary><p>Xy = np.dot(X.T, y) that can be precomputed. It is useful
only when the Gram matrix is precomputed.</p>
</details>
<details class="info" open="open"><summary>Gram : None, 'auto', array-like of shape (n_features, n_features),             default=None</summary><p>Precomputed Gram matrix (X' * X), if <code>'auto'</code>, the Gram
matrix is precomputed from the given X, if there are more samples
than features.</p>
<p>.. deprecated:: 0.21</p>
<p>The use of <code>X</code> is <code>None</code> in combination with <code>Gram</code> is not
   None will be removed in v0.23. Use :func:<code>lars_path_gram</code> instead.</p>
</details>
<details class="info" open="open"><summary>max_iter : int, default=500</summary><p>Maximum number of iterations to perform, set to infinity for no limit.</p>
</details>
<details class="info" open="open"><summary>alpha_min : float, default=0</summary><p>Minimum correlation along the path. It corresponds to the
regularization parameter alpha parameter in the Lasso.</p>
</details>
<details class="info" open="open"><summary>method : {'lar', 'lasso'}, default='lar'</summary><p>Specifies the returned model. Select <code>'lar'</code> for Least Angle
Regression, <code>'lasso'</code> for the Lasso.</p>
</details>
<details class="info" open="open"><summary>copy_X : bool, default=True</summary><p>If <code>False</code>, <code>X</code> is overwritten.</p>
</details>
<details class="info" open="open"><summary>eps : float, optional</summary><p>The machine-precision regularization in the computation of the
Cholesky diagonal factors. Increase this for very ill-conditioned
systems. By default, <code>np.finfo(np.float).eps</code> is used.</p>
</details>
<details class="info" open="open"><summary>copy_Gram : bool, default=True</summary><p>If <code>False</code>, <code>Gram</code> is overwritten.</p>
</details>
<details class="info" open="open"><summary>verbose : int, default=0</summary><p>Controls output verbosity.</p>
</details>
<details class="info" open="open"><summary>return_path : bool, default=True</summary><p>If <code>return_path==True</code> returns the entire path, else returns only the
last point of the path.</p>
</details>
<details class="info" open="open"><summary>return_n_iter : bool, default=False</summary><p>Whether to return the number of iterations.</p>
</details>
<details class="info" open="open"><summary>positive : bool, default=False</summary><p>Restrict coefficients to be &gt;= 0.
This option is only allowed with method 'lasso'. Note that the model
coefficients will not converge to the ordinary-least-squares solution
for small values of alpha. Only coefficients up to the smallest alpha
value (<code>alphas_[alphas_ &gt; 0.].min()</code> when fit_path=True) reached by
the stepwise Lars-Lasso algorithm are typically in congruence with the
solution of the coordinate descent lasso_path function.</p>
</details>
<h4>Returns</h4>
<details class="info" open="open"><summary>alphas : array-like of shape (n_alphas + 1,)</summary><p>Maximum of covariances (in absolute value) at each iteration.
<code>n_alphas</code> is either <code>max_iter</code>, <code>n_features</code> or the
number of nodes in the path with <code>alpha &gt;= alpha_min</code>, whichever
is smaller.</p>
</details>
<details class="info" open="open"><summary>active : array-like of shape (n_alphas,)</summary><p>Indices of active variables at the end of the path.</p>
</details>
<details class="info" open="open"><summary>coefs : array-like of shape (n_features, n_alphas + 1)</summary><p>Coefficients along the path</p>
</details>
<details class="info" open="open"><summary>n_iter : int</summary><p>Number of iterations run. Returned only if return_n_iter is set
to True.</p>
</details>
<h4>See also</h4>
<p>lars_path_gram
lasso_path
lasso_path_gram
LassoLars
Lars
LassoLarsCV
LarsCV
sklearn.decomposition.sparse_encode</p>
<h4>References</h4>
<p>.. [1] "Least Angle Regression", Efron et al.</p>
<details class="info" open="open"><summary>http://statweb.stanford.edu/~tibs/ftp/lars.pdf</summary></details>
<p>.. [2] <code>Wikipedia entry on the Least-angle regression
       &lt;https://en.wikipedia.org/wiki/Least-angle_regression&gt;</code>_</p>
<p>.. [3] <code>Wikipedia entry on the Lasso
       &lt;https://en.wikipedia.org/wiki/Lasso_(statistics)&gt;</code>_</p>
</details>
<h3 id="lars_path_gram">lars_path_gram<a class="headerlink" href="#lars_path_gram" title="Permanent link">&para;</a></h3>
<details class="note" open="open"><summary>function</summary><div class="highlight"><pre><span></span><code><span class="k">val</span> <span class="n">lars_path_gram</span> <span class="o">:</span>
  <span class="o">?</span><span class="n">max_iter</span><span class="o">:</span><span class="kt">int</span> <span class="o">-&gt;</span>
  <span class="o">?</span><span class="n">alpha_min</span><span class="o">:</span><span class="kt">float</span> <span class="o">-&gt;</span>
  <span class="o">?</span><span class="n">method_</span><span class="o">:[`</span><span class="nc">Lar</span> <span class="o">|</span> <span class="o">`</span><span class="nc">Lasso</span><span class="o">]</span> <span class="o">-&gt;</span>
  <span class="o">?</span><span class="n">copy_X</span><span class="o">:</span><span class="kt">bool</span> <span class="o">-&gt;</span>
  <span class="o">?</span><span class="n">eps</span><span class="o">:</span><span class="kt">float</span> <span class="o">-&gt;</span>
  <span class="o">?</span><span class="n">copy_Gram</span><span class="o">:</span><span class="kt">bool</span> <span class="o">-&gt;</span>
  <span class="o">?</span><span class="n">verbose</span><span class="o">:</span><span class="kt">int</span> <span class="o">-&gt;</span>
  <span class="o">?</span><span class="n">return_path</span><span class="o">:</span><span class="kt">bool</span> <span class="o">-&gt;</span>
  <span class="o">?</span><span class="n">return_n_iter</span><span class="o">:</span><span class="kt">bool</span> <span class="o">-&gt;</span>
  <span class="o">?</span><span class="n">positive</span><span class="o">:</span><span class="kt">bool</span> <span class="o">-&gt;</span>
  <span class="n">xy</span><span class="o">:</span><span class="nn">Arr</span><span class="p">.</span><span class="n">t</span> <span class="o">-&gt;</span>
  <span class="n">gram</span><span class="o">:</span><span class="nn">Arr</span><span class="p">.</span><span class="n">t</span> <span class="o">-&gt;</span>
  <span class="n">n_samples</span><span class="o">:[`</span><span class="nc">I</span> <span class="k">of</span> <span class="kt">int</span> <span class="o">|</span> <span class="o">`</span><span class="nc">F</span> <span class="k">of</span> <span class="kt">float</span><span class="o">]</span> <span class="o">-&gt;</span>
  <span class="kt">unit</span> <span class="o">-&gt;</span>
  <span class="o">(</span><span class="nn">Arr</span><span class="p">.</span><span class="n">t</span> <span class="o">*</span> <span class="nn">Arr</span><span class="p">.</span><span class="n">t</span> <span class="o">*</span> <span class="nn">Arr</span><span class="p">.</span><span class="n">t</span> <span class="o">*</span> <span class="kt">int</span><span class="o">)</span>
</code></pre></div>

<p>lars_path in the sufficient stats mode [1]</p>
<p>The optimization objective for the case method='lasso' is::</p>
<p>(1 / (2 * n_samples)) * ||y - Xw||^2_2 + alpha * ||w||_1</p>
<p>in the case of method='lars', the objective function is only known in
the form of an implicit equation (see discussion in [1])</p>
<p>Read more in the :ref:<code>User Guide &lt;least_angle_regression&gt;</code>.</p>
<h4>Parameters</h4>
<details class="info" open="open"><summary>Xy : array-like of shape (n_samples,) or (n_samples, n_targets)</summary><p>Xy = np.dot(X.T, y).</p>
</details>
<details class="info" open="open"><summary>Gram : array-like of shape (n_features, n_features)</summary><p>Gram = np.dot(X.T * X).</p>
</details>
<details class="info" open="open"><summary>n_samples : int or float</summary><p>Equivalent size of sample.</p>
</details>
<details class="info" open="open"><summary>max_iter : int, default=500</summary><p>Maximum number of iterations to perform, set to infinity for no limit.</p>
</details>
<details class="info" open="open"><summary>alpha_min : float, default=0</summary><p>Minimum correlation along the path. It corresponds to the
regularization parameter alpha parameter in the Lasso.</p>
</details>
<details class="info" open="open"><summary>method : {'lar', 'lasso'}, default='lar'</summary><p>Specifies the returned model. Select <code>'lar'</code> for Least Angle
Regression, <code>'lasso'</code> for the Lasso.</p>
</details>
<details class="info" open="open"><summary>copy_X : bool, default=True</summary><p>If <code>False</code>, <code>X</code> is overwritten.</p>
</details>
<details class="info" open="open"><summary>eps : float, optional</summary><p>The machine-precision regularization in the computation of the
Cholesky diagonal factors. Increase this for very ill-conditioned
systems. By default, <code>np.finfo(np.float).eps</code> is used.</p>
</details>
<details class="info" open="open"><summary>copy_Gram : bool, default=True</summary><p>If <code>False</code>, <code>Gram</code> is overwritten.</p>
</details>
<details class="info" open="open"><summary>verbose : int, default=0</summary><p>Controls output verbosity.</p>
</details>
<details class="info" open="open"><summary>return_path : bool, default=True</summary><p>If <code>return_path==True</code> returns the entire path, else returns only the
last point of the path.</p>
</details>
<details class="info" open="open"><summary>return_n_iter : bool, default=False</summary><p>Whether to return the number of iterations.</p>
</details>
<details class="info" open="open"><summary>positive : bool, default=False</summary><p>Restrict coefficients to be &gt;= 0.
This option is only allowed with method 'lasso'. Note that the model
coefficients will not converge to the ordinary-least-squares solution
for small values of alpha. Only coefficients up to the smallest alpha
value (<code>alphas_[alphas_ &gt; 0.].min()</code> when fit_path=True) reached by
the stepwise Lars-Lasso algorithm are typically in congruence with the
solution of the coordinate descent lasso_path function.</p>
</details>
<h4>Returns</h4>
<details class="info" open="open"><summary>alphas : array-like of shape (n_alphas + 1,)</summary><p>Maximum of covariances (in absolute value) at each iteration.
<code>n_alphas</code> is either <code>max_iter</code>, <code>n_features</code> or the
number of nodes in the path with <code>alpha &gt;= alpha_min</code>, whichever
is smaller.</p>
</details>
<details class="info" open="open"><summary>active : array-like of shape (n_alphas,)</summary><p>Indices of active variables at the end of the path.</p>
</details>
<details class="info" open="open"><summary>coefs : array-like of shape (n_features, n_alphas + 1)</summary><p>Coefficients along the path</p>
</details>
<details class="info" open="open"><summary>n_iter : int</summary><p>Number of iterations run. Returned only if return_n_iter is set
to True.</p>
</details>
<h4>See also</h4>
<p>lars_path
lasso_path
lasso_path_gram
LassoLars
Lars
LassoLarsCV
LarsCV
sklearn.decomposition.sparse_encode</p>
<h4>References</h4>
<p>.. [1] "Least Angle Regression", Efron et al.</p>
<details class="info" open="open"><summary>http://statweb.stanford.edu/~tibs/ftp/lars.pdf</summary></details>
<p>.. [2] <code>Wikipedia entry on the Least-angle regression
       &lt;https://en.wikipedia.org/wiki/Least-angle_regression&gt;</code>_</p>
<p>.. [3] <code>Wikipedia entry on the Lasso
       &lt;https://en.wikipedia.org/wiki/Lasso_(statistics)&gt;</code>_</p>
</details>
<h3 id="lasso_path">lasso_path<a class="headerlink" href="#lasso_path" title="Permanent link">&para;</a></h3>
<details class="note" open="open"><summary>function</summary><div class="highlight"><pre><span></span><code><span class="k">val</span> <span class="n">lasso_path</span> <span class="o">:</span>
  <span class="o">?</span><span class="n">eps</span><span class="o">:</span><span class="kt">float</span> <span class="o">-&gt;</span>
  <span class="o">?</span><span class="n">n_alphas</span><span class="o">:</span><span class="kt">int</span> <span class="o">-&gt;</span>
  <span class="o">?</span><span class="n">alphas</span><span class="o">:</span><span class="nn">Arr</span><span class="p">.</span><span class="n">t</span> <span class="o">-&gt;</span>
  <span class="o">?</span><span class="n">precompute</span><span class="o">:[`</span><span class="nc">Bool</span> <span class="k">of</span> <span class="kt">bool</span> <span class="o">|</span> <span class="o">`</span><span class="nc">Auto</span> <span class="o">|</span> <span class="o">`</span><span class="nc">Arr</span> <span class="k">of</span> <span class="nn">Arr</span><span class="p">.</span><span class="n">t</span><span class="o">]</span> <span class="o">-&gt;</span>
  <span class="o">?</span><span class="n">xy</span><span class="o">:</span><span class="nn">Arr</span><span class="p">.</span><span class="n">t</span> <span class="o">-&gt;</span>
  <span class="o">?</span><span class="n">copy_X</span><span class="o">:</span><span class="kt">bool</span> <span class="o">-&gt;</span>
  <span class="o">?</span><span class="n">coef_init</span><span class="o">:</span><span class="nn">Arr</span><span class="p">.</span><span class="n">t</span> <span class="o">-&gt;</span>
  <span class="o">?</span><span class="n">verbose</span><span class="o">:</span><span class="kt">int</span> <span class="o">-&gt;</span>
  <span class="o">?</span><span class="n">return_n_iter</span><span class="o">:</span><span class="kt">bool</span> <span class="o">-&gt;</span>
  <span class="o">?</span><span class="n">positive</span><span class="o">:</span><span class="kt">bool</span> <span class="o">-&gt;</span>
  <span class="o">?</span><span class="n">params</span><span class="o">:(</span><span class="kt">string</span> <span class="o">*</span> <span class="nn">Py</span><span class="p">.</span><span class="nn">Object</span><span class="p">.</span><span class="n">t</span><span class="o">)</span> <span class="kt">list</span> <span class="o">-&gt;</span>
  <span class="n">x</span><span class="o">:</span><span class="nn">Arr</span><span class="p">.</span><span class="n">t</span> <span class="o">-&gt;</span>
  <span class="n">y</span><span class="o">:</span><span class="nn">Arr</span><span class="p">.</span><span class="n">t</span> <span class="o">-&gt;</span>
  <span class="kt">unit</span> <span class="o">-&gt;</span>
  <span class="o">(</span><span class="nn">Arr</span><span class="p">.</span><span class="n">t</span> <span class="o">*</span> <span class="nn">Arr</span><span class="p">.</span><span class="n">t</span> <span class="o">*</span> <span class="nn">Arr</span><span class="p">.</span><span class="n">t</span> <span class="o">*</span> <span class="nn">Arr</span><span class="p">.</span><span class="n">t</span><span class="o">)</span>
</code></pre></div>

<p>Compute Lasso path with coordinate descent</p>
<p>The Lasso optimization function varies for mono and multi-outputs.</p>
<p>For mono-output tasks it is::</p>
<div class="codehilite"><pre><span></span><code>(1 / (2 * n_samples)) * ||y - Xw||^2_2 + alpha * ||w||_1
</code></pre></div>


<p>For multi-output tasks it is::</p>
<div class="codehilite"><pre><span></span><code>(1 / (2 * n_samples)) * ||Y - XW||^2_Fro + alpha * ||W||_21
</code></pre></div>


<details class="info" open="open"><summary>Where::</summary><p>||W||<em>21 = \sum_i \sqrt{\sum_j w</em>{ij}^2}</p>
</details>
<p>i.e. the sum of norm of each row.</p>
<p>Read more in the :ref:<code>User Guide &lt;lasso&gt;</code>.</p>
<h4>Parameters</h4>
<details class="info" open="open"><summary>X : {array-like, sparse matrix}, shape (n_samples, n_features)</summary><p>Training data. Pass directly as Fortran-contiguous data to avoid
unnecessary memory duplication. If <code>y</code> is mono-output then <code>X</code>
can be sparse.</p>
</details>
<details class="info" open="open"><summary>y : ndarray, shape (n_samples,), or (n_samples, n_outputs)</summary><p>Target values</p>
</details>
<details class="info" open="open"><summary>eps : float, optional</summary><p>Length of the path. <code>eps=1e-3</code> means that
<code>alpha_min / alpha_max = 1e-3</code></p>
</details>
<details class="info" open="open"><summary>n_alphas : int, optional</summary><p>Number of alphas along the regularization path</p>
</details>
<details class="info" open="open"><summary>alphas : ndarray, optional</summary><p>List of alphas where to compute the models.
If <code>None</code> alphas are set automatically</p>
</details>
<details class="info" open="open"><summary>precompute : True | False | 'auto' | array-like</summary><p>Whether to use a precomputed Gram matrix to speed up
calculations. If set to <code>'auto'</code> let us decide. The Gram
matrix can also be passed as argument.</p>
</details>
<details class="info" open="open"><summary>Xy : array-like, optional</summary><p>Xy = np.dot(X.T, y) that can be precomputed. It is useful
only when the Gram matrix is precomputed.</p>
</details>
<details class="info" open="open"><summary>copy_X : boolean, optional, default True</summary><p>If <code>True</code>, X will be copied; else, it may be overwritten.</p>
</details>
<details class="info" open="open"><summary>coef_init : array, shape (n_features, ) | None</summary><p>The initial values of the coefficients.</p>
</details>
<details class="info" open="open"><summary>verbose : bool or integer</summary><p>Amount of verbosity.</p>
</details>
<details class="info" open="open"><summary>return_n_iter : bool</summary><p>whether to return the number of iterations or not.</p>
</details>
<details class="info" open="open"><summary>positive : bool, default False</summary><p>If set to True, forces coefficients to be positive.
(Only allowed when <code>y.ndim == 1</code>).</p>
</details>
<details class="info" open="open"><summary>**params : kwargs</summary><p>keyword arguments passed to the coordinate descent solver.</p>
</details>
<h4>Returns</h4>
<details class="info" open="open"><summary>alphas : array, shape (n_alphas,)</summary><p>The alphas along the path where models are computed.</p>
</details>
<details class="info" open="open"><summary>coefs : array, shape (n_features, n_alphas) or             (n_outputs, n_features, n_alphas)</summary><p>Coefficients along the path.</p>
</details>
<details class="info" open="open"><summary>dual_gaps : array, shape (n_alphas,)</summary><p>The dual gaps at the end of the optimization for each alpha.</p>
</details>
<details class="info" open="open"><summary>n_iters : array-like, shape (n_alphas,)</summary><p>The number of iterations taken by the coordinate descent optimizer to
reach the specified tolerance for each alpha.</p>
</details>
<h4>Notes</h4>
<p>For an example, see
:ref:<code>examples/linear_model/plot_lasso_coordinate_descent_path.py
&lt;sphx_glr_auto_examples_linear_model_plot_lasso_coordinate_descent_path.py&gt;</code>.</p>
<p>To avoid unnecessary memory duplication the X argument of the fit method
should be directly passed as a Fortran-contiguous numpy array.</p>
<p>Note that in certain cases, the Lars solver may be significantly
faster to implement this functionality. In particular, linear
interpolation can be used to retrieve model coefficients between the
values output by lars_path</p>
<h4>Examples</h4>
<p>Comparing lasso_path and lars_path with interpolation:</p>
<div class="highlight"><pre><span></span><code><span class="o">&gt;&gt;&gt;</span> <span class="n">X</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">array</span><span class="p">([[</span><span class="mi">1</span><span class="p">,</span> <span class="mi">2</span><span class="p">,</span> <span class="mf">3.1</span><span class="p">],</span> <span class="p">[</span><span class="mf">2.3</span><span class="p">,</span> <span class="mf">5.4</span><span class="p">,</span> <span class="mf">4.3</span><span class="p">]])</span><span class="o">.</span><span class="n">T</span>
<span class="o">&gt;&gt;&gt;</span> <span class="n">y</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">array</span><span class="p">([</span><span class="mi">1</span><span class="p">,</span> <span class="mi">2</span><span class="p">,</span> <span class="mf">3.1</span><span class="p">])</span>
<span class="o">&gt;&gt;&gt;</span> <span class="c1"># Use lasso_path to compute a coefficient path</span>
<span class="o">&gt;&gt;&gt;</span> <span class="n">_</span><span class="p">,</span> <span class="n">coef_path</span><span class="p">,</span> <span class="n">_</span> <span class="o">=</span> <span class="n">lasso_path</span><span class="p">(</span><span class="n">X</span><span class="p">,</span> <span class="n">y</span><span class="p">,</span> <span class="n">alphas</span><span class="o">=</span><span class="p">[</span><span class="mf">5.</span><span class="p">,</span> <span class="mf">1.</span><span class="p">,</span> <span class="o">.</span><span class="mi">5</span><span class="p">])</span>
<span class="o">&gt;&gt;&gt;</span> <span class="nb">print</span><span class="p">(</span><span class="n">coef_path</span><span class="p">)</span>
<span class="p">[[</span><span class="mf">0.</span>         <span class="mf">0.</span>         <span class="mf">0.46874778</span><span class="p">]</span>
 <span class="p">[</span><span class="mf">0.2159048</span>  <span class="mf">0.4425765</span>  <span class="mf">0.23689075</span><span class="p">]]</span>
</code></pre></div>

<div class="highlight"><pre><span></span><code><span class="o">&gt;&gt;&gt;</span> <span class="c1"># Now use lars_path and 1D linear interpolation to compute the</span>
<span class="o">&gt;&gt;&gt;</span> <span class="c1"># same path</span>
<span class="o">&gt;&gt;&gt;</span> <span class="kn">from</span> <span class="nn">sklearn.linear_model</span> <span class="kn">import</span> <span class="n">lars_path</span>
<span class="o">&gt;&gt;&gt;</span> <span class="n">alphas</span><span class="p">,</span> <span class="n">active</span><span class="p">,</span> <span class="n">coef_path_lars</span> <span class="o">=</span> <span class="n">lars_path</span><span class="p">(</span><span class="n">X</span><span class="p">,</span> <span class="n">y</span><span class="p">,</span> <span class="n">method</span><span class="o">=</span><span class="s1">&#39;lasso&#39;</span><span class="p">)</span>
<span class="o">&gt;&gt;&gt;</span> <span class="kn">from</span> <span class="nn">scipy</span> <span class="kn">import</span> <span class="n">interpolate</span>
<span class="o">&gt;&gt;&gt;</span> <span class="n">coef_path_continuous</span> <span class="o">=</span> <span class="n">interpolate</span><span class="o">.</span><span class="n">interp1d</span><span class="p">(</span><span class="n">alphas</span><span class="p">[::</span><span class="o">-</span><span class="mi">1</span><span class="p">],</span>
<span class="o">...</span>                                             <span class="n">coef_path_lars</span><span class="p">[:,</span> <span class="p">::</span><span class="o">-</span><span class="mi">1</span><span class="p">])</span>
<span class="o">&gt;&gt;&gt;</span> <span class="nb">print</span><span class="p">(</span><span class="n">coef_path_continuous</span><span class="p">([</span><span class="mf">5.</span><span class="p">,</span> <span class="mf">1.</span><span class="p">,</span> <span class="o">.</span><span class="mi">5</span><span class="p">]))</span>
<span class="p">[[</span><span class="mf">0.</span>         <span class="mf">0.</span>         <span class="mf">0.46915237</span><span class="p">]</span>
 <span class="p">[</span><span class="mf">0.2159048</span>  <span class="mf">0.4425765</span>  <span class="mf">0.23668876</span><span class="p">]]</span>
</code></pre></div>

<h4>See also</h4>
<p>lars_path
Lasso
LassoLars
LassoCV
LassoLarsCV
sklearn.decomposition.sparse_encode</p>
</details>
<h3 id="logistic_regression_path">logistic_regression_path<a class="headerlink" href="#logistic_regression_path" title="Permanent link">&para;</a></h3>
<details class="note" open="open"><summary>function</summary><div class="highlight"><pre><span></span><code><span class="k">val</span> <span class="n">logistic_regression_path</span> <span class="o">:</span>
  <span class="o">?</span><span class="n">pos_class</span><span class="o">:</span><span class="kt">int</span> <span class="o">-&gt;</span>
  <span class="o">?</span><span class="n">cs</span><span class="o">:[`</span><span class="nc">I</span> <span class="k">of</span> <span class="kt">int</span> <span class="o">|</span> <span class="o">`</span><span class="nc">Arr</span> <span class="k">of</span> <span class="nn">Arr</span><span class="p">.</span><span class="n">t</span><span class="o">]</span> <span class="o">-&gt;</span>
  <span class="o">?</span><span class="n">fit_intercept</span><span class="o">:</span><span class="kt">bool</span> <span class="o">-&gt;</span>
  <span class="o">?</span><span class="n">max_iter</span><span class="o">:</span><span class="kt">int</span> <span class="o">-&gt;</span>
  <span class="o">?</span><span class="n">tol</span><span class="o">:</span><span class="kt">float</span> <span class="o">-&gt;</span>
  <span class="o">?</span><span class="n">verbose</span><span class="o">:</span><span class="kt">int</span> <span class="o">-&gt;</span>
  <span class="o">?</span><span class="n">solver</span><span class="o">:[`</span><span class="nc">Lbfgs</span> <span class="o">|</span> <span class="o">`</span><span class="nc">Newton_cg</span> <span class="o">|</span> <span class="o">`</span><span class="nc">Liblinear</span> <span class="o">|</span> <span class="o">`</span><span class="nc">Sag</span> <span class="o">|</span> <span class="o">`</span><span class="nc">Saga</span><span class="o">]</span> <span class="o">-&gt;</span>
  <span class="o">?</span><span class="n">coef</span><span class="o">:</span><span class="nn">Arr</span><span class="p">.</span><span class="n">t</span> <span class="o">-&gt;</span>
  <span class="o">?</span><span class="n">class_weight</span><span class="o">:[`</span><span class="nc">DictIntToFloat</span> <span class="k">of</span> <span class="o">(</span><span class="kt">int</span> <span class="o">*</span> <span class="kt">float</span><span class="o">)</span> <span class="kt">list</span> <span class="o">|</span> <span class="o">`</span><span class="nc">Balanced</span><span class="o">]</span> <span class="o">-&gt;</span>
  <span class="o">?</span><span class="n">dual</span><span class="o">:</span><span class="kt">bool</span> <span class="o">-&gt;</span>
  <span class="o">?</span><span class="n">penalty</span><span class="o">:[`</span><span class="nc">L1</span> <span class="o">|</span> <span class="o">`</span><span class="nc">L2</span> <span class="o">|</span> <span class="o">`</span><span class="nc">Elasticnet</span><span class="o">]</span> <span class="o">-&gt;</span>
  <span class="o">?</span><span class="n">intercept_scaling</span><span class="o">:</span><span class="kt">float</span> <span class="o">-&gt;</span>
  <span class="o">?</span><span class="n">multi_class</span><span class="o">:[`</span><span class="nc">Ovr</span> <span class="o">|</span> <span class="o">`</span><span class="nc">Multinomial</span> <span class="o">|</span> <span class="o">`</span><span class="nc">Auto</span><span class="o">]</span> <span class="o">-&gt;</span>
  <span class="o">?</span><span class="n">random_state</span><span class="o">:</span><span class="kt">int</span> <span class="o">-&gt;</span>
  <span class="o">?</span><span class="n">check_input</span><span class="o">:</span><span class="kt">bool</span> <span class="o">-&gt;</span>
  <span class="o">?</span><span class="n">max_squared_sum</span><span class="o">:</span><span class="kt">float</span> <span class="o">-&gt;</span>
  <span class="o">?</span><span class="n">sample_weight</span><span class="o">:</span><span class="nn">Arr</span><span class="p">.</span><span class="n">t</span> <span class="o">-&gt;</span>
  <span class="o">?</span><span class="n">l1_ratio</span><span class="o">:</span><span class="kt">float</span> <span class="o">-&gt;</span>
  <span class="n">x</span><span class="o">:</span><span class="nn">Arr</span><span class="p">.</span><span class="n">t</span> <span class="o">-&gt;</span>
  <span class="n">y</span><span class="o">:</span><span class="nn">Arr</span><span class="p">.</span><span class="n">t</span> <span class="o">-&gt;</span>
  <span class="kt">unit</span> <span class="o">-&gt;</span>
  <span class="o">(</span><span class="nn">Py</span><span class="p">.</span><span class="nn">Object</span><span class="p">.</span><span class="n">t</span> <span class="o">*</span> <span class="nn">Arr</span><span class="p">.</span><span class="n">t</span> <span class="o">*</span> <span class="nn">Arr</span><span class="p">.</span><span class="n">t</span><span class="o">)</span>
</code></pre></div>

<details class="info" open="open"><summary>DEPRECATED: logistic_regression_path was deprecated in version 0.21 and will be removed in version 0.23.0</summary></details>
<p>Compute a Logistic Regression model for a list of regularization
    parameters.</p>
<div class="codehilite"><pre><span></span><code>This is an implementation that uses the result of the previous model
to speed up computations along the set of solutions, making it faster
than sequentially calling LogisticRegression for the different parameters.
Note that there will be no speedup with liblinear solver, since it does
not handle warm-starting.

.. deprecated:: 0.21
    ``logistic_regression_path`` was deprecated in version 0.21 and will
    be removed in 0.23.

Read more in the :ref:`User Guide &lt;logistic_regression&gt;`.

Parameters
----------
</code></pre></div>


<details class="info" open="open"><summary>X : array-like or sparse matrix, shape (n_samples, n_features)</summary><div class="codehilite"><pre><span></span><code>Input data.
</code></pre></div>


</details>
<details class="info" open="open"><summary>y : array-like, shape (n_samples,) or (n_samples, n_targets)</summary><div class="codehilite"><pre><span></span><code>Input data, target values.
</code></pre></div>


</details>
<details class="info" open="open"><summary>pos_class : int, None</summary><div class="codehilite"><pre><span></span><code>The class with respect to which we perform a one-vs-all fit.
If None, then it is assumed that the given problem is binary.
</code></pre></div>


</details>
<details class="info" open="open"><summary>Cs : int | array-like, shape (n_cs,)</summary><div class="codehilite"><pre><span></span><code>List of values for the regularization parameter or integer specifying
the number of regularization parameters that should be used. In this
case, the parameters will be chosen in a logarithmic scale between
1e-4 and 1e4.
</code></pre></div>


</details>
<details class="info" open="open"><summary>fit_intercept : bool</summary><div class="codehilite"><pre><span></span><code>Whether to fit an intercept for the model. In this case the shape of
the returned array is (n_cs, n_features + 1).
</code></pre></div>


</details>
<details class="info" open="open"><summary>max_iter : int</summary><div class="codehilite"><pre><span></span><code>Maximum number of iterations for the solver.
</code></pre></div>


</details>
<details class="info" open="open"><summary>tol : float</summary><div class="codehilite"><pre><span></span><code>Stopping criterion. For the newton-cg and lbfgs solvers, the iteration
will stop when ``max{ |g_i | i = 1, ..., n} &lt;= tol``
where ``g_i`` is the i-th component of the gradient.
</code></pre></div>


</details>
<details class="info" open="open"><summary>verbose : int</summary><div class="codehilite"><pre><span></span><code>For the liblinear and lbfgs solvers set verbose to any positive
number for verbosity.
</code></pre></div>


</details>
<details class="info" open="open"><summary>solver : {'lbfgs', 'newton-cg', 'liblinear', 'sag', 'saga'}</summary><div class="codehilite"><pre><span></span><code>Numerical solver to use.
</code></pre></div>


</details>
<details class="info" open="open"><summary>coef : array-like, shape (n_features,), default None</summary><div class="codehilite"><pre><span></span><code>Initialization value for coefficients of logistic regression.
Useless for liblinear solver.
</code></pre></div>


</details>
<details class="info" open="open"><summary>class_weight : dict or 'balanced', optional</summary><div class="codehilite"><pre><span></span><code>Weights associated with classes in the form ``{class_label: weight}``.
If not given, all classes are supposed to have weight one.

The &quot;balanced&quot; mode uses the values of y to automatically adjust
weights inversely proportional to class frequencies in the input data
as ``n_samples / (n_classes * np.bincount(y))``.

Note that these weights will be multiplied with sample_weight (passed
through the fit method) if sample_weight is specified.
</code></pre></div>


</details>
<details class="info" open="open"><summary>dual : bool</summary><div class="codehilite"><pre><span></span><code>Dual or primal formulation. Dual formulation is only implemented for
l2 penalty with liblinear solver. Prefer dual=False when
n_samples &gt; n_features.
</code></pre></div>


</details>
<details class="info" open="open"><summary>penalty : str, 'l1', 'l2', or 'elasticnet'</summary><div class="codehilite"><pre><span></span><code>Used to specify the norm used in the penalization. The &#39;newton-cg&#39;,
&#39;sag&#39; and &#39;lbfgs&#39; solvers support only l2 penalties. &#39;elasticnet&#39; is
only supported by the &#39;saga&#39; solver.
</code></pre></div>


</details>
<details class="info" open="open"><summary>intercept_scaling : float, default 1.</summary><div class="codehilite"><pre><span></span><code>Useful only when the solver &#39;liblinear&#39; is used
and self.fit_intercept is set to True. In this case, x becomes
[x, self.intercept_scaling],
i.e. a &quot;synthetic&quot; feature with constant value equal to
intercept_scaling is appended to the instance vector.
The intercept becomes ``intercept_scaling * synthetic_feature_weight``.

Note! the synthetic feature weight is subject to l1/l2 regularization
as all other features.
To lessen the effect of regularization on synthetic feature weight
(and therefore on the intercept) intercept_scaling has to be increased.
</code></pre></div>


</details>
<details class="info" open="open"><summary>multi_class : {'ovr', 'multinomial', 'auto'}, default='auto'</summary><div class="codehilite"><pre><span></span><code>If the option chosen is &#39;ovr&#39;, then a binary problem is fit for each
label. For &#39;multinomial&#39; the loss minimised is the multinomial loss fit
across the entire probability distribution, *even when the data is
binary*. &#39;multinomial&#39; is unavailable when solver=&#39;liblinear&#39;.
&#39;auto&#39; selects &#39;ovr&#39; if the data is binary, or if solver=&#39;liblinear&#39;,
and otherwise selects &#39;multinomial&#39;.

.. versionadded:: 0.18
   Stochastic Average Gradient descent solver for &#39;multinomial&#39; case.
.. versionchanged:: 0.22
    Default changed from &#39;ovr&#39; to &#39;auto&#39; in 0.22.
</code></pre></div>


</details>
<details class="info" open="open"><summary>random_state : int, RandomState instance or None, optional, default None</summary><div class="codehilite"><pre><span></span><code>The seed of the pseudo random number generator to use when shuffling
the data.  If int, random_state is the seed used by the random number
generator; If RandomState instance, random_state is the random number
generator; If None, the random number generator is the RandomState
instance used by `np.random`. Used when ``solver`` == &#39;sag&#39; or
&#39;liblinear&#39;.
</code></pre></div>


</details>
<details class="info" open="open"><summary>check_input : bool, default True</summary><div class="codehilite"><pre><span></span><code>If False, the input arrays X and y will not be checked.
</code></pre></div>


</details>
<details class="info" open="open"><summary>max_squared_sum : float, default None</summary><div class="codehilite"><pre><span></span><code>Maximum squared sum of X over samples. Used only in SAG solver.
If None, it will be computed, going through all the samples.
The value should be precomputed to speed up cross validation.
</code></pre></div>


</details>
<details class="info" open="open"><summary>sample_weight : array-like, shape(n_samples,) optional</summary><div class="codehilite"><pre><span></span><code>Array of weights that are assigned to individual samples.
If not provided, then each sample is given unit weight.
</code></pre></div>


</details>
<details class="info" open="open"><summary>l1_ratio : float or None, optional (default=None)</summary><div class="codehilite"><pre><span></span><code>The Elastic-Net mixing parameter, with ``0 &lt;= l1_ratio &lt;= 1``. Only
used if ``penalty=&#39;elasticnet&#39;``. Setting ``l1_ratio=0`` is equivalent
to using ``penalty=&#39;l2&#39;``, while setting ``l1_ratio=1`` is equivalent
to using ``penalty=&#39;l1&#39;``. For ``0 &lt; l1_ratio &lt;1``, the penalty is a
combination of L1 and L2.
</code></pre></div>


<h2 id="returns">Returns<a class="headerlink" href="#returns" title="Permanent link">&para;</a></h2>
</details>
<details class="info" open="open"><summary>coefs : ndarray, shape (n_cs, n_features) or (n_cs, n_features + 1)</summary><div class="codehilite"><pre><span></span><code>List of coefficients for the Logistic Regression model. If
fit_intercept is set to True then the second dimension will be
n_features + 1, where the last item represents the intercept. For
``multiclass=&#39;multinomial&#39;``, the shape is (n_classes, n_cs,
n_features) or (n_classes, n_cs, n_features + 1).
</code></pre></div>


</details>
<details class="info" open="open"><summary>Cs : ndarray</summary><div class="codehilite"><pre><span></span><code>Grid of Cs used for cross-validation.
</code></pre></div>


</details>
<details class="info" open="open"><summary>n_iter : array, shape (n_cs,)</summary><div class="codehilite"><pre><span></span><code>Actual number of iteration for each Cs.
</code></pre></div>


<h2 id="notes">Notes<a class="headerlink" href="#notes" title="Permanent link">&para;</a></h2>
<p>You might get slightly different results with the solver liblinear than
with the others since this uses LIBLINEAR which penalizes the intercept.</p>
<p>.. versionchanged:: 0.19
    The "copy" parameter was removed.</p>
</details>
</details>
<h3 id="orthogonal_mp">orthogonal_mp<a class="headerlink" href="#orthogonal_mp" title="Permanent link">&para;</a></h3>
<details class="note" open="open"><summary>function</summary><div class="highlight"><pre><span></span><code><span class="k">val</span> <span class="n">orthogonal_mp</span> <span class="o">:</span>
  <span class="o">?</span><span class="n">n_nonzero_coefs</span><span class="o">:</span><span class="kt">int</span> <span class="o">-&gt;</span>
  <span class="o">?</span><span class="n">tol</span><span class="o">:</span><span class="kt">float</span> <span class="o">-&gt;</span>
  <span class="o">?</span><span class="n">precompute</span><span class="o">:[`</span><span class="nc">Bool</span> <span class="k">of</span> <span class="kt">bool</span> <span class="o">|</span> <span class="o">`</span><span class="nc">Auto</span><span class="o">]</span> <span class="o">-&gt;</span>
  <span class="o">?</span><span class="n">copy_X</span><span class="o">:</span><span class="kt">bool</span> <span class="o">-&gt;</span>
  <span class="o">?</span><span class="n">return_path</span><span class="o">:</span><span class="kt">bool</span> <span class="o">-&gt;</span>
  <span class="o">?</span><span class="n">return_n_iter</span><span class="o">:</span><span class="kt">bool</span> <span class="o">-&gt;</span>
  <span class="n">x</span><span class="o">:</span><span class="nn">Arr</span><span class="p">.</span><span class="n">t</span> <span class="o">-&gt;</span>
  <span class="n">y</span><span class="o">:</span><span class="nn">Arr</span><span class="p">.</span><span class="n">t</span> <span class="o">-&gt;</span>
  <span class="kt">unit</span> <span class="o">-&gt;</span>
  <span class="o">(</span><span class="nn">Arr</span><span class="p">.</span><span class="n">t</span> <span class="o">*</span> <span class="o">[`</span><span class="nc">Arr</span> <span class="k">of</span> <span class="nn">Arr</span><span class="p">.</span><span class="n">t</span> <span class="o">|</span> <span class="o">`</span><span class="nc">I</span> <span class="k">of</span> <span class="kt">int</span><span class="o">])</span>
</code></pre></div>

<p>Orthogonal Matching Pursuit (OMP)</p>
<p>Solves n_targets Orthogonal Matching Pursuit problems.
An instance of the problem has the form:</p>
<p>When parametrized by the number of non-zero coefficients using
<code>n_nonzero_coefs</code>:
argmin ||y - X\gamma||^2 subject to ||\gamma||<em>0 &lt;= n</em>{nonzero coefs}</p>
<p>When parametrized by error using the parameter <code>tol</code>:
argmin ||\gamma||_0 subject to ||y - X\gamma||^2 &lt;= tol</p>
<p>Read more in the :ref:<code>User Guide &lt;omp&gt;</code>.</p>
<h4>Parameters</h4>
<details class="info" open="open"><summary>X : array, shape (n_samples, n_features)</summary><p>Input data. Columns are assumed to have unit norm.</p>
</details>
<details class="info" open="open"><summary>y : array, shape (n_samples,) or (n_samples, n_targets)</summary><p>Input targets</p>
</details>
<details class="info" open="open"><summary>n_nonzero_coefs : int</summary><p>Desired number of non-zero entries in the solution. If None (by
default) this value is set to 10% of n_features.</p>
</details>
<details class="info" open="open"><summary>tol : float</summary><p>Maximum norm of the residual. If not None, overrides n_nonzero_coefs.</p>
</details>
<details class="info" open="open"><summary>precompute : {True, False, 'auto'},</summary><p>Whether to perform precomputations. Improves performance when n_targets
or n_samples is very large.</p>
</details>
<details class="info" open="open"><summary>copy_X : bool, optional</summary><p>Whether the design matrix X must be copied by the algorithm. A false
value is only helpful if X is already Fortran-ordered, otherwise a
copy is made anyway.</p>
</details>
<details class="info" open="open"><summary>return_path : bool, optional. Default: False</summary><p>Whether to return every value of the nonzero coefficients along the
forward path. Useful for cross-validation.</p>
</details>
<details class="info" open="open"><summary>return_n_iter : bool, optional default False</summary><p>Whether or not to return the number of iterations.</p>
</details>
<h4>Returns</h4>
<details class="info" open="open"><summary>coef : array, shape (n_features,) or (n_features, n_targets)</summary><p>Coefficients of the OMP solution. If <code>return_path=True</code>, this contains
the whole coefficient path. In this case its shape is
(n_features, n_features) or (n_features, n_targets, n_features) and
iterating over the last axis yields coefficients in increasing order
of active features.</p>
</details>
<details class="info" open="open"><summary>n_iters : array-like or int</summary><p>Number of active features across every target. Returned only if
<code>return_n_iter</code> is set to True.</p>
</details>
<h4>See also</h4>
<p>OrthogonalMatchingPursuit
orthogonal_mp_gram
lars_path
decomposition.sparse_encode</p>
<h4>Notes</h4>
<p>Orthogonal matching pursuit was introduced in S. Mallat, Z. Zhang,
Matching pursuits with time-frequency dictionaries, IEEE Transactions on
Signal Processing, Vol. 41, No. 12. (December 1993), pp. 3397-3415.
(http://blanche.polytechnique.fr/~mallat/papiers/MallatPursuit93.pdf)</p>
<p>This implementation is based on Rubinstein, R., Zibulevsky, M. and Elad,
M., Efficient Implementation of the K-SVD Algorithm using Batch Orthogonal
Matching Pursuit Technical Report - CS Technion, April 2008.</p>
<details class="info" open="open"><summary>https://www.cs.technion.ac.il/~ronrubin/Publications/KSVD-OMP-v2.pdf</summary></details>
</details>
<h3 id="orthogonal_mp_gram">orthogonal_mp_gram<a class="headerlink" href="#orthogonal_mp_gram" title="Permanent link">&para;</a></h3>
<details class="note" open="open"><summary>function</summary><div class="highlight"><pre><span></span><code><span class="k">val</span> <span class="n">orthogonal_mp_gram</span> <span class="o">:</span>
  <span class="o">?</span><span class="n">n_nonzero_coefs</span><span class="o">:</span><span class="kt">int</span> <span class="o">-&gt;</span>
  <span class="o">?</span><span class="n">tol</span><span class="o">:</span><span class="kt">float</span> <span class="o">-&gt;</span>
  <span class="o">?</span><span class="n">norms_squared</span><span class="o">:</span><span class="nn">Arr</span><span class="p">.</span><span class="n">t</span> <span class="o">-&gt;</span>
  <span class="o">?</span><span class="n">copy_Gram</span><span class="o">:</span><span class="kt">bool</span> <span class="o">-&gt;</span>
  <span class="o">?</span><span class="n">copy_Xy</span><span class="o">:</span><span class="kt">bool</span> <span class="o">-&gt;</span>
  <span class="o">?</span><span class="n">return_path</span><span class="o">:</span><span class="kt">bool</span> <span class="o">-&gt;</span>
  <span class="o">?</span><span class="n">return_n_iter</span><span class="o">:</span><span class="kt">bool</span> <span class="o">-&gt;</span>
  <span class="n">gram</span><span class="o">:</span><span class="nn">Arr</span><span class="p">.</span><span class="n">t</span> <span class="o">-&gt;</span>
  <span class="n">xy</span><span class="o">:</span><span class="nn">Arr</span><span class="p">.</span><span class="n">t</span> <span class="o">-&gt;</span>
  <span class="kt">unit</span> <span class="o">-&gt;</span>
  <span class="o">(</span><span class="nn">Arr</span><span class="p">.</span><span class="n">t</span> <span class="o">*</span> <span class="o">[`</span><span class="nc">Arr</span> <span class="k">of</span> <span class="nn">Arr</span><span class="p">.</span><span class="n">t</span> <span class="o">|</span> <span class="o">`</span><span class="nc">I</span> <span class="k">of</span> <span class="kt">int</span><span class="o">])</span>
</code></pre></div>

<p>Gram Orthogonal Matching Pursuit (OMP)</p>
<p>Solves n_targets Orthogonal Matching Pursuit problems using only
the Gram matrix X.T * X and the product X.T * y.</p>
<p>Read more in the :ref:<code>User Guide &lt;omp&gt;</code>.</p>
<h4>Parameters</h4>
<details class="info" open="open"><summary>Gram : array, shape (n_features, n_features)</summary><p>Gram matrix of the input data: X.T * X</p>
</details>
<details class="info" open="open"><summary>Xy : array, shape (n_features,) or (n_features, n_targets)</summary><p>Input targets multiplied by X: X.T * y</p>
</details>
<details class="info" open="open"><summary>n_nonzero_coefs : int</summary><p>Desired number of non-zero entries in the solution. If None (by
default) this value is set to 10% of n_features.</p>
</details>
<details class="info" open="open"><summary>tol : float</summary><p>Maximum norm of the residual. If not None, overrides n_nonzero_coefs.</p>
</details>
<details class="info" open="open"><summary>norms_squared : array-like, shape (n_targets,)</summary><p>Squared L2 norms of the lines of y. Required if tol is not None.</p>
</details>
<details class="info" open="open"><summary>copy_Gram : bool, optional</summary><p>Whether the gram matrix must be copied by the algorithm. A false
value is only helpful if it is already Fortran-ordered, otherwise a
copy is made anyway.</p>
</details>
<details class="info" open="open"><summary>copy_Xy : bool, optional</summary><p>Whether the covariance vector Xy must be copied by the algorithm.
If False, it may be overwritten.</p>
</details>
<details class="info" open="open"><summary>return_path : bool, optional. Default: False</summary><p>Whether to return every value of the nonzero coefficients along the
forward path. Useful for cross-validation.</p>
</details>
<details class="info" open="open"><summary>return_n_iter : bool, optional default False</summary><p>Whether or not to return the number of iterations.</p>
</details>
<h4>Returns</h4>
<details class="info" open="open"><summary>coef : array, shape (n_features,) or (n_features, n_targets)</summary><p>Coefficients of the OMP solution. If <code>return_path=True</code>, this contains
the whole coefficient path. In this case its shape is
(n_features, n_features) or (n_features, n_targets, n_features) and
iterating over the last axis yields coefficients in increasing order
of active features.</p>
</details>
<details class="info" open="open"><summary>n_iters : array-like or int</summary><p>Number of active features across every target. Returned only if
<code>return_n_iter</code> is set to True.</p>
</details>
<h4>See also</h4>
<p>OrthogonalMatchingPursuit
orthogonal_mp
lars_path
decomposition.sparse_encode</p>
<h4>Notes</h4>
<p>Orthogonal matching pursuit was introduced in G. Mallat, Z. Zhang,
Matching pursuits with time-frequency dictionaries, IEEE Transactions on
Signal Processing, Vol. 41, No. 12. (December 1993), pp. 3397-3415.
(http://blanche.polytechnique.fr/~mallat/papiers/MallatPursuit93.pdf)</p>
<p>This implementation is based on Rubinstein, R., Zibulevsky, M. and Elad,
M., Efficient Implementation of the K-SVD Algorithm using Batch Orthogonal
Matching Pursuit Technical Report - CS Technion, April 2008.</p>
<details class="info" open="open"><summary>https://www.cs.technion.ac.il/~ronrubin/Publications/KSVD-OMP-v2.pdf</summary></details>
</details>
<h3 id="ridge_regression">ridge_regression<a class="headerlink" href="#ridge_regression" title="Permanent link">&para;</a></h3>
<details class="note" open="open"><summary>function</summary><div class="highlight"><pre><span></span><code><span class="k">val</span> <span class="n">ridge_regression</span> <span class="o">:</span>
  <span class="o">?</span><span class="n">sample_weight</span><span class="o">:[`</span><span class="nc">F</span> <span class="k">of</span> <span class="kt">float</span> <span class="o">|</span> <span class="o">`</span><span class="nc">Arr</span> <span class="k">of</span> <span class="nn">Arr</span><span class="p">.</span><span class="n">t</span><span class="o">]</span> <span class="o">-&gt;</span>
  <span class="o">?</span><span class="n">solver</span><span class="o">:[`</span><span class="nc">Auto</span> <span class="o">|</span> <span class="o">`</span><span class="nc">Svd</span> <span class="o">|</span> <span class="o">`</span><span class="nc">Cholesky</span> <span class="o">|</span> <span class="o">`</span><span class="nc">Lsqr</span> <span class="o">|</span> <span class="o">`</span><span class="nc">Sparse_cg</span> <span class="o">|</span> <span class="o">`</span><span class="nc">Sag</span> <span class="o">|</span> <span class="o">`</span><span class="nc">Saga</span><span class="o">]</span> <span class="o">-&gt;</span>
  <span class="o">?</span><span class="n">max_iter</span><span class="o">:</span><span class="kt">int</span> <span class="o">-&gt;</span>
  <span class="o">?</span><span class="n">tol</span><span class="o">:</span><span class="kt">float</span> <span class="o">-&gt;</span>
  <span class="o">?</span><span class="n">verbose</span><span class="o">:</span><span class="kt">int</span> <span class="o">-&gt;</span>
  <span class="o">?</span><span class="n">random_state</span><span class="o">:</span><span class="kt">int</span> <span class="o">-&gt;</span>
  <span class="o">?</span><span class="n">return_n_iter</span><span class="o">:</span><span class="kt">bool</span> <span class="o">-&gt;</span>
  <span class="o">?</span><span class="n">return_intercept</span><span class="o">:</span><span class="kt">bool</span> <span class="o">-&gt;</span>
  <span class="o">?</span><span class="n">check_input</span><span class="o">:</span><span class="kt">bool</span> <span class="o">-&gt;</span>
  <span class="n">x</span><span class="o">:[`</span><span class="nc">Arr</span> <span class="k">of</span> <span class="nn">Arr</span><span class="p">.</span><span class="n">t</span> <span class="o">|</span> <span class="o">`</span><span class="nc">LinearOperator</span> <span class="k">of</span> <span class="nn">Py</span><span class="p">.</span><span class="nn">Object</span><span class="p">.</span><span class="n">t</span><span class="o">]</span> <span class="o">-&gt;</span>
  <span class="n">y</span><span class="o">:</span><span class="nn">Arr</span><span class="p">.</span><span class="n">t</span> <span class="o">-&gt;</span>
  <span class="n">alpha</span><span class="o">:[`</span><span class="nc">F</span> <span class="k">of</span> <span class="kt">float</span> <span class="o">|</span> <span class="o">`</span><span class="nc">Arr</span> <span class="k">of</span> <span class="nn">Arr</span><span class="p">.</span><span class="n">t</span><span class="o">]</span> <span class="o">-&gt;</span>
  <span class="kt">unit</span> <span class="o">-&gt;</span>
  <span class="o">(</span><span class="nn">Arr</span><span class="p">.</span><span class="n">t</span> <span class="o">*</span> <span class="kt">int</span> <span class="o">*</span> <span class="o">[`</span><span class="nc">F</span> <span class="k">of</span> <span class="kt">float</span> <span class="o">|</span> <span class="o">`</span><span class="nc">Arr</span> <span class="k">of</span> <span class="nn">Arr</span><span class="p">.</span><span class="n">t</span><span class="o">])</span>
</code></pre></div>

<p>Solve the ridge equation by the method of normal equations.</p>
<p>Read more in the :ref:<code>User Guide &lt;ridge_regression&gt;</code>.</p>
<h4>Parameters</h4>
<details class="info" open="open"><summary>X : {ndarray, sparse matrix, LinearOperator} of shape         (n_samples, n_features)</summary><p>Training data</p>
</details>
<details class="info" open="open"><summary>y : ndarray of shape (n_samples,) or (n_samples, n_targets)</summary><p>Target values</p>
</details>
<details class="info" open="open"><summary>alpha : float or array-like of shape (n_targets,)</summary><p>Regularization strength; must be a positive float. Regularization
improves the conditioning of the problem and reduces the variance of
the estimates. Larger values specify stronger regularization.
Alpha corresponds to <code>C^-1</code> in other linear models such as
LogisticRegression or LinearSVC. If an array is passed, penalties are
assumed to be specific to the targets. Hence they must correspond in
number.</p>
</details>
<details class="info" open="open"><summary>sample_weight : float or array-like of shape (n_samples,), default=None</summary><p>Individual weights for each sample. If given a float, every sample
will have the same weight. If sample_weight is not None and
solver='auto', the solver will be set to 'cholesky'.</p>
<p>.. versionadded:: 0.17</p>
</details>
<details class="info" open="open"><summary>solver : {'auto', 'svd', 'cholesky', 'lsqr', 'sparse_cg', 'sag', 'saga'},         default='auto'</summary><p>Solver to use in the computational routines:</p>
<ul>
<li>
<p>'auto' chooses the solver automatically based on the type of data.</p>
</li>
<li>
<p>'svd' uses a Singular Value Decomposition of X to compute the Ridge
  coefficients. More stable for singular matrices than
  'cholesky'.</p>
</li>
<li>
<p>'cholesky' uses the standard scipy.linalg.solve function to
  obtain a closed-form solution via a Cholesky decomposition of
  dot(X.T, X)</p>
</li>
<li>
<p>'sparse_cg' uses the conjugate gradient solver as found in
  scipy.sparse.linalg.cg. As an iterative algorithm, this solver is
  more appropriate than 'cholesky' for large-scale data
  (possibility to set <code>tol</code> and <code>max_iter</code>).</p>
</li>
<li>
<p>'lsqr' uses the dedicated regularized least-squares routine
  scipy.sparse.linalg.lsqr. It is the fastest and uses an iterative
  procedure.</p>
</li>
<li>
<p>'sag' uses a Stochastic Average Gradient descent, and 'saga' uses
  its improved, unbiased version named SAGA. Both methods also use an
  iterative procedure, and are often faster than other solvers when
  both n_samples and n_features are large. Note that 'sag' and
  'saga' fast convergence is only guaranteed on features with
  approximately the same scale. You can preprocess the data with a
  scaler from sklearn.preprocessing.</p>
</li>
</ul>
<p>All last five solvers support both dense and sparse data. However, only
'sag' and 'sparse_cg' supports sparse input when<code>fit_intercept</code> is
True.</p>
<p>.. versionadded:: 0.17
   Stochastic Average Gradient descent solver.
.. versionadded:: 0.19
   SAGA solver.</p>
</details>
<details class="info" open="open"><summary>max_iter : int, default=None</summary><p>Maximum number of iterations for conjugate gradient solver.
For the 'sparse_cg' and 'lsqr' solvers, the default value is determined
by scipy.sparse.linalg. For 'sag' and saga solver, the default value is
1000.</p>
</details>
<details class="info" open="open"><summary>tol : float, default=1e-3</summary><p>Precision of the solution.</p>
</details>
<details class="info" open="open"><summary>verbose : int, default=0</summary><p>Verbosity level. Setting verbose &gt; 0 will display additional
information depending on the solver used.</p>
</details>
<details class="info" open="open"><summary>random_state : int, RandomState instance, default=None</summary><p>The seed of the pseudo random number generator to use when shuffling
the data.  If int, random_state is the seed used by the random number
generator; If RandomState instance, random_state is the random number
generator; If None, the random number generator is the RandomState
instance used by <code>np.random</code>. Used when <code>solver</code> == 'sag'.</p>
</details>
<details class="info" open="open"><summary>return_n_iter : bool, default=False</summary><p>If True, the method also returns <code>n_iter</code>, the actual number of
iteration performed by the solver.</p>
<p>.. versionadded:: 0.17</p>
</details>
<details class="info" open="open"><summary>return_intercept : bool, default=False</summary><p>If True and if X is sparse, the method also returns the intercept,
and the solver is automatically changed to 'sag'. This is only a
temporary fix for fitting the intercept with sparse data. For dense
data, use sklearn.linear_model._preprocess_data before your regression.</p>
<p>.. versionadded:: 0.17</p>
</details>
<details class="info" open="open"><summary>check_input : bool, default=True</summary><p>If False, the input arrays X and y will not be checked.</p>
<p>.. versionadded:: 0.21</p>
</details>
<h4>Returns</h4>
<details class="info" open="open"><summary>coef : ndarray of shape (n_features,) or (n_targets, n_features)</summary><p>Weight vector(s).</p>
</details>
<details class="info" open="open"><summary>n_iter : int, optional</summary><p>The actual number of iteration performed by the solver.
Only returned if <code>return_n_iter</code> is True.</p>
</details>
<details class="info" open="open"><summary>intercept : float or ndarray of shape (n_targets,)</summary><p>The intercept of the model. Only returned if <code>return_intercept</code>
is True and if X is a scipy sparse array.</p>
</details>
<h4>Notes</h4>
<p>This function won't compute the intercept.</p>
</details>
                
              
              
                


              
            </article>
          </div>
        </div>
      </main>
      
        
<footer class="md-footer">
  
    <div class="md-footer-nav">
      <nav class="md-footer-nav__inner md-grid" aria-label="Footer">
        
          <a href="../kernel_ridge/" title="Kernel ridge" class="md-footer-nav__link md-footer-nav__link--prev" rel="prev">
            <div class="md-footer-nav__button md-icon">
              <svg xmlns="http://www.w3.org/2000/svg" viewBox="0 0 24 24"><path d="M20,11V13H8L13.5,18.5L12.08,19.92L4.16,12L12.08,4.08L13.5,5.5L8,11H20Z" /></svg>
            </div>
            <div class="md-footer-nav__title">
              <div class="md-ellipsis">
                <span class="md-footer-nav__direction">
                  Previous
                </span>
                Kernel ridge
              </div>
            </div>
          </a>
        
        
          <a href="../manifold/" title="Manifold" class="md-footer-nav__link md-footer-nav__link--next" rel="next">
            <div class="md-footer-nav__title">
              <div class="md-ellipsis">
                <span class="md-footer-nav__direction">
                  Next
                </span>
                Manifold
              </div>
            </div>
            <div class="md-footer-nav__button md-icon">
              <svg xmlns="http://www.w3.org/2000/svg" viewBox="0 0 24 24"><path d="M4,11V13H16L10.5,18.5L11.92,19.92L19.84,12L11.92,4.08L10.5,5.5L16,11H4Z" /></svg>
            </div>
          </a>
        
      </nav>
    </div>
  
  <div class="md-footer-meta md-typeset">
    <div class="md-footer-meta__inner md-grid">
      <div class="md-footer-copyright">
        
        Made with
        <a href="https://squidfunk.github.io/mkdocs-material/" target="_blank" rel="noopener">
          Material for MkDocs
        </a>
      </div>
      
    </div>
  </div>
</footer>
      
    </div>
    
      <script src="../assets/javascripts/vendor.36cbf620.min.js"></script>
      <script src="../assets/javascripts/bundle.00c583dd.min.js"></script><script id="__lang" type="application/json">{"clipboard.copy": "Copy to clipboard", "clipboard.copied": "Copied to clipboard", "search.config.lang": "en", "search.config.pipeline": "trimmer, stopWordFilter", "search.config.separator": "[\\s\\-]+", "search.result.placeholder": "Type to start searching", "search.result.none": "No matching documents", "search.result.one": "1 matching document", "search.result.other": "# matching documents"}</script>
      
      <script>
        app = initialize({
          base: "..",
          features: ["instant"],
          search: Object.assign({
            worker: "../assets/javascripts/worker/search.7f7c8775.min.js"
          }, typeof search !== "undefined" && search)
        })
      </script>
      
        <script src="https://cdnjs.cloudflare.com/ajax/libs/mathjax/2.7.0/MathJax.js?config=TeX-MML-AM_CHTML"></script>
      
    
  </body>
</html>