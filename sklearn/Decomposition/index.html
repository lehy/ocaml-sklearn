


<!doctype html>
<html lang="en" class="no-js">
  <head>
    
      <meta charset="utf-8">
      <meta name="viewport" content="width=device-width,initial-scale=1">
      
      
      
      <link rel="shortcut icon" href="../../assets/images/favicon.png">
      <meta name="generator" content="mkdocs-1.1.2, mkdocs-material-5.2.3">
    
    
      
        <title>Decomposition - OCaml scikit-learn interface</title>
      
    
    
      <link rel="stylesheet" href="../../assets/stylesheets/main.6e35a1a6.min.css">
      
        <link rel="stylesheet" href="../../assets/stylesheets/palette.a46bcfb3.min.css">
      
      
        
        
        <meta name="theme-color" content="#3f51b5">
      
    
    
    
      
        <link href="https://fonts.gstatic.com" rel="preconnect" crossorigin>
        <link rel="stylesheet" href="https://fonts.googleapis.com/css?family=Roboto:300,400,400i,700%7CRoboto+Mono&display=fallback">
        <style>body,input{font-family:"Roboto",-apple-system,BlinkMacSystemFont,Helvetica,Arial,sans-serif}code,kbd,pre{font-family:"Roboto Mono",SFMono-Regular,Consolas,Menlo,monospace}</style>
      
    
    
    
    
      
    
    
  </head>
  
  
    
    
    
    <body dir="ltr" data-md-color-scheme="" data-md-color-primary="indigo" data-md-color-accent="indigo">
  
    <input class="md-toggle" data-md-toggle="drawer" type="checkbox" id="__drawer" autocomplete="off">
    <input class="md-toggle" data-md-toggle="search" type="checkbox" id="__search" autocomplete="off">
    <label class="md-overlay" for="__drawer"></label>
    <div data-md-component="skip">
      
        
        <a href="#parameters" class="md-skip">
          Skip to content
        </a>
      
    </div>
    <div data-md-component="announce">
      
    </div>
    
      <header class="md-header" data-md-component="header">
  <nav class="md-header-nav md-grid" aria-label="Header">
    <a href="../.." title="OCaml scikit-learn interface" class="md-header-nav__button md-logo" aria-label="OCaml scikit-learn interface">
      
  
  <svg xmlns="http://www.w3.org/2000/svg" viewBox="0 0 24 24"><path d="M12 8a3 3 0 003-3 3 3 0 00-3-3 3 3 0 00-3 3 3 3 0 003 3m0 3.54C9.64 9.35 6.5 8 3 8v11c3.5 0 6.64 1.35 9 3.54 2.36-2.19 5.5-3.54 9-3.54V8c-3.5 0-6.64 1.35-9 3.54z"/></svg>

    </a>
    <label class="md-header-nav__button md-icon" for="__drawer">
      <svg xmlns="http://www.w3.org/2000/svg" viewBox="0 0 24 24"><path d="M3 6h18v2H3V6m0 5h18v2H3v-2m0 5h18v2H3v-2z"/></svg>
    </label>
    <div class="md-header-nav__title" data-md-component="header-title">
      
        <div class="md-header-nav__ellipsis">
          <span class="md-header-nav__topic md-ellipsis">
            OCaml scikit-learn interface
          </span>
          <span class="md-header-nav__topic md-ellipsis">
            
              Decomposition
            
          </span>
        </div>
      
    </div>
    
      <label class="md-header-nav__button md-icon" for="__search">
        <svg xmlns="http://www.w3.org/2000/svg" viewBox="0 0 24 24"><path d="M9.5 3A6.5 6.5 0 0116 9.5c0 1.61-.59 3.09-1.56 4.23l.27.27h.79l5 5-1.5 1.5-5-5v-.79l-.27-.27A6.516 6.516 0 019.5 16 6.5 6.5 0 013 9.5 6.5 6.5 0 019.5 3m0 2C7 5 5 7 5 9.5S7 14 9.5 14 14 12 14 9.5 12 5 9.5 5z"/></svg>
      </label>
      
<div class="md-search" data-md-component="search" role="dialog">
  <label class="md-search__overlay" for="__search"></label>
  <div class="md-search__inner" role="search">
    <form class="md-search__form" name="search">
      <input type="text" class="md-search__input" name="query" aria-label="Search" placeholder="Search" autocapitalize="off" autocorrect="off" autocomplete="off" spellcheck="false" data-md-component="search-query" data-md-state="active">
      <label class="md-search__icon md-icon" for="__search">
        <svg xmlns="http://www.w3.org/2000/svg" viewBox="0 0 24 24"><path d="M9.5 3A6.5 6.5 0 0116 9.5c0 1.61-.59 3.09-1.56 4.23l.27.27h.79l5 5-1.5 1.5-5-5v-.79l-.27-.27A6.516 6.516 0 019.5 16 6.5 6.5 0 013 9.5 6.5 6.5 0 019.5 3m0 2C7 5 5 7 5 9.5S7 14 9.5 14 14 12 14 9.5 12 5 9.5 5z"/></svg>
        <svg xmlns="http://www.w3.org/2000/svg" viewBox="0 0 24 24"><path d="M20 11v2H8l5.5 5.5-1.42 1.42L4.16 12l7.92-7.92L13.5 5.5 8 11h12z"/></svg>
      </label>
      <button type="reset" class="md-search__icon md-icon" aria-label="Clear" data-md-component="search-reset" tabindex="-1">
        <svg xmlns="http://www.w3.org/2000/svg" viewBox="0 0 24 24"><path d="M19 6.41L17.59 5 12 10.59 6.41 5 5 6.41 10.59 12 5 17.59 6.41 19 12 13.41 17.59 19 19 17.59 13.41 12 19 6.41z"/></svg>
      </button>
    </form>
    <div class="md-search__output">
      <div class="md-search__scrollwrap" data-md-scrollfix>
        <div class="md-search-result" data-md-component="search-result">
          <div class="md-search-result__meta">
            Initializing search
          </div>
          <ol class="md-search-result__list"></ol>
        </div>
      </div>
    </div>
  </div>
</div>
    
    
      <div class="md-header-nav__source">
        
<a href="https://github.com/lehy/ocaml-sklearn/" title="Go to repository" class="md-source">
  <div class="md-source__icon md-icon">
    
    <svg xmlns="http://www.w3.org/2000/svg" viewBox="0 0 448 512"><path d="M439.55 236.05L244 40.45a28.87 28.87 0 00-40.81 0l-40.66 40.63 51.52 51.52c27.06-9.14 52.68 16.77 43.39 43.68l49.66 49.66c34.23-11.8 61.18 31 35.47 56.69-26.49 26.49-70.21-2.87-56-37.34L240.22 199v121.85c25.3 12.54 22.26 41.85 9.08 55a34.34 34.34 0 01-48.55 0c-17.57-17.6-11.07-46.91 11.25-56v-123c-20.8-8.51-24.6-30.74-18.64-45L142.57 101 8.45 235.14a28.86 28.86 0 000 40.81l195.61 195.6a28.86 28.86 0 0040.8 0l194.69-194.69a28.86 28.86 0 000-40.81z"/></svg>
  </div>
  <div class="md-source__repository">
    lehy/ocaml-sklearn
  </div>
</a>
      </div>
    
  </nav>
</header>
    
    <div class="md-container" data-md-component="container">
      
        
      
      
        
          

  

<nav class="md-tabs md-tabs--active" aria-label="Tabs" data-md-component="tabs">
  <div class="md-tabs__inner md-grid">
    <ul class="md-tabs__list">
      
        
  <li class="md-tabs__item">
    
      <a href="../.." class="md-tabs__link">
        Home
      </a>
    
  </li>

      
        
  
  
    <li class="md-tabs__item">
      
        <a href="../../np/" class="md-tabs__link">
          Np
        </a>
      
    </li>
  

      
        
  
  
    <li class="md-tabs__item">
      
        <a href="../../scipy/" class="md-tabs__link">
          Scipy
        </a>
      
    </li>
  

      
        
  
  
    <li class="md-tabs__item">
      
        <a href="../Base/" class="md-tabs__link md-tabs__link--active">
          Sklearn
        </a>
      
    </li>
  

      
    </ul>
  </div>
</nav>
        
      
      <main class="md-main" data-md-component="main">
        <div class="md-main__inner md-grid">
          
            
              <div class="md-sidebar md-sidebar--primary" data-md-component="navigation">
                <div class="md-sidebar__scrollwrap">
                  <div class="md-sidebar__inner">
                    <nav class="md-nav md-nav--primary" aria-label="Navigation" data-md-level="0">
  <label class="md-nav__title" for="__drawer">
    <a href="../.." title="OCaml scikit-learn interface" class="md-nav__button md-logo" aria-label="OCaml scikit-learn interface">
      
  
  <svg xmlns="http://www.w3.org/2000/svg" viewBox="0 0 24 24"><path d="M12 8a3 3 0 003-3 3 3 0 00-3-3 3 3 0 00-3 3 3 3 0 003 3m0 3.54C9.64 9.35 6.5 8 3 8v11c3.5 0 6.64 1.35 9 3.54 2.36-2.19 5.5-3.54 9-3.54V8c-3.5 0-6.64 1.35-9 3.54z"/></svg>

    </a>
    OCaml scikit-learn interface
  </label>
  
    <div class="md-nav__source">
      
<a href="https://github.com/lehy/ocaml-sklearn/" title="Go to repository" class="md-source">
  <div class="md-source__icon md-icon">
    
    <svg xmlns="http://www.w3.org/2000/svg" viewBox="0 0 448 512"><path d="M439.55 236.05L244 40.45a28.87 28.87 0 00-40.81 0l-40.66 40.63 51.52 51.52c27.06-9.14 52.68 16.77 43.39 43.68l49.66 49.66c34.23-11.8 61.18 31 35.47 56.69-26.49 26.49-70.21-2.87-56-37.34L240.22 199v121.85c25.3 12.54 22.26 41.85 9.08 55a34.34 34.34 0 01-48.55 0c-17.57-17.6-11.07-46.91 11.25-56v-123c-20.8-8.51-24.6-30.74-18.64-45L142.57 101 8.45 235.14a28.86 28.86 0 000 40.81l195.61 195.6a28.86 28.86 0 0040.8 0l194.69-194.69a28.86 28.86 0 000-40.81z"/></svg>
  </div>
  <div class="md-source__repository">
    lehy/ocaml-sklearn
  </div>
</a>
    </div>
  
  <ul class="md-nav__list" data-md-scrollfix>
    
      
      
      


  <li class="md-nav__item">
    <a href="../.." title="Home" class="md-nav__link">
      Home
    </a>
  </li>

    
      
      
      


  <li class="md-nav__item md-nav__item--nested">
    
      <input class="md-nav__toggle md-toggle" data-md-toggle="nav-2" type="checkbox" id="nav-2">
    
    <label class="md-nav__link" for="nav-2">
      Np
      <span class="md-nav__icon md-icon">
        <svg xmlns="http://www.w3.org/2000/svg" viewBox="0 0 24 24"><path d="M8.59 16.58L13.17 12 8.59 7.41 10 6l6 6-6 6-1.41-1.42z"/></svg>
      </span>
    </label>
    <nav class="md-nav" aria-label="Np" data-md-level="1">
      <label class="md-nav__title" for="nav-2">
        <span class="md-nav__icon md-icon">
          <svg xmlns="http://www.w3.org/2000/svg" viewBox="0 0 24 24"><path d="M20 11v2H8l5.5 5.5-1.42 1.42L4.16 12l7.92-7.92L13.5 5.5 8 11h12z"/></svg>
        </span>
        Np
      </label>
      <ul class="md-nav__list" data-md-scrollfix>
        
        
          
          
          


  <li class="md-nav__item">
    <a href="../../np/" title="Numpy for OCaml" class="md-nav__link">
      Numpy for OCaml
    </a>
  </li>

        
          
          
          


  <li class="md-nav__item">
    <a href="../../np/Numpy/" title="Numpy" class="md-nav__link">
      Numpy
    </a>
  </li>

        
          
          
          


  <li class="md-nav__item">
    <a href="../../np/NumpyRaw/" title="NumpyRaw" class="md-nav__link">
      NumpyRaw
    </a>
  </li>

        
          
          
          


  <li class="md-nav__item">
    <a href="../../np/PyList/" title="PyList" class="md-nav__link">
      PyList
    </a>
  </li>

        
          
          
          


  <li class="md-nav__item">
    <a href="../../np/dtype/" title="Dtype" class="md-nav__link">
      Dtype
    </a>
  </li>

        
          
          
          


  <li class="md-nav__item">
    <a href="../../np/obj/" title="Obj" class="md-nav__link">
      Obj
    </a>
  </li>

        
      </ul>
    </nav>
  </li>

    
      
      
      


  <li class="md-nav__item md-nav__item--nested">
    
      <input class="md-nav__toggle md-toggle" data-md-toggle="nav-3" type="checkbox" id="nav-3">
    
    <label class="md-nav__link" for="nav-3">
      Scipy
      <span class="md-nav__icon md-icon">
        <svg xmlns="http://www.w3.org/2000/svg" viewBox="0 0 24 24"><path d="M8.59 16.58L13.17 12 8.59 7.41 10 6l6 6-6 6-1.41-1.42z"/></svg>
      </span>
    </label>
    <nav class="md-nav" aria-label="Scipy" data-md-level="1">
      <label class="md-nav__title" for="nav-3">
        <span class="md-nav__icon md-icon">
          <svg xmlns="http://www.w3.org/2000/svg" viewBox="0 0 24 24"><path d="M20 11v2H8l5.5 5.5-1.42 1.42L4.16 12l7.92-7.92L13.5 5.5 8 11h12z"/></svg>
        </span>
        Scipy
      </label>
      <ul class="md-nav__list" data-md-scrollfix>
        
        
          
          
          


  <li class="md-nav__item">
    <a href="../../scipy/" title="SciPy library for OCaml" class="md-nav__link">
      SciPy library for OCaml
    </a>
  </li>

        
          
          
          


  <li class="md-nav__item">
    <a href="../../scipy/Cluster/" title="Cluster" class="md-nav__link">
      Cluster
    </a>
  </li>

        
          
          
          


  <li class="md-nav__item">
    <a href="../../scipy/Conftest/" title="Conftest" class="md-nav__link">
      Conftest
    </a>
  </li>

        
          
          
          


  <li class="md-nav__item">
    <a href="../../scipy/Constants/" title="Constants" class="md-nav__link">
      Constants
    </a>
  </li>

        
          
          
          


  <li class="md-nav__item">
    <a href="../../scipy/Fft/" title="Fft" class="md-nav__link">
      Fft
    </a>
  </li>

        
          
          
          


  <li class="md-nav__item">
    <a href="../../scipy/Fftpack/" title="Fftpack" class="md-nav__link">
      Fftpack
    </a>
  </li>

        
          
          
          


  <li class="md-nav__item">
    <a href="../../scipy/Integrate/" title="Integrate" class="md-nav__link">
      Integrate
    </a>
  </li>

        
          
          
          


  <li class="md-nav__item">
    <a href="../../scipy/Interpolate/" title="Interpolate" class="md-nav__link">
      Interpolate
    </a>
  </li>

        
          
          
          


  <li class="md-nav__item">
    <a href="../../scipy/Io/" title="Io" class="md-nav__link">
      Io
    </a>
  </li>

        
          
          
          


  <li class="md-nav__item">
    <a href="../../scipy/Linalg/" title="Linalg" class="md-nav__link">
      Linalg
    </a>
  </li>

        
          
          
          


  <li class="md-nav__item">
    <a href="../../scipy/Misc/" title="Misc" class="md-nav__link">
      Misc
    </a>
  </li>

        
          
          
          


  <li class="md-nav__item">
    <a href="../../scipy/Ndimage/" title="Ndimage" class="md-nav__link">
      Ndimage
    </a>
  </li>

        
          
          
          


  <li class="md-nav__item">
    <a href="../../scipy/Odr/" title="Odr" class="md-nav__link">
      Odr
    </a>
  </li>

        
          
          
          


  <li class="md-nav__item">
    <a href="../../scipy/Optimize/" title="Optimize" class="md-nav__link">
      Optimize
    </a>
  </li>

        
          
          
          


  <li class="md-nav__item">
    <a href="../../scipy/Setup/" title="Setup" class="md-nav__link">
      Setup
    </a>
  </li>

        
          
          
          


  <li class="md-nav__item">
    <a href="../../scipy/Signal/" title="Signal" class="md-nav__link">
      Signal
    </a>
  </li>

        
          
          
          


  <li class="md-nav__item">
    <a href="../../scipy/Sparse/" title="Sparse" class="md-nav__link">
      Sparse
    </a>
  </li>

        
          
          
          


  <li class="md-nav__item">
    <a href="../../scipy/Spatial/" title="Spatial" class="md-nav__link">
      Spatial
    </a>
  </li>

        
          
          
          


  <li class="md-nav__item">
    <a href="../../scipy/Special/" title="Special" class="md-nav__link">
      Special
    </a>
  </li>

        
          
          
          


  <li class="md-nav__item">
    <a href="../../scipy/Stats/" title="Stats" class="md-nav__link">
      Stats
    </a>
  </li>

        
          
          
          


  <li class="md-nav__item">
    <a href="../../scipy/Version/" title="Version" class="md-nav__link">
      Version
    </a>
  </li>

        
          
          
          


  <li class="md-nav__item">
    <a href="../../scipy/wrap_version/" title="Wrap version" class="md-nav__link">
      Wrap version
    </a>
  </li>

        
      </ul>
    </nav>
  </li>

    
      
      
      

  


  <li class="md-nav__item md-nav__item--active md-nav__item--nested">
    
      <input class="md-nav__toggle md-toggle" data-md-toggle="nav-4" type="checkbox" id="nav-4" checked>
    
    <label class="md-nav__link" for="nav-4">
      Sklearn
      <span class="md-nav__icon md-icon">
        <svg xmlns="http://www.w3.org/2000/svg" viewBox="0 0 24 24"><path d="M8.59 16.58L13.17 12 8.59 7.41 10 6l6 6-6 6-1.41-1.42z"/></svg>
      </span>
    </label>
    <nav class="md-nav" aria-label="Sklearn" data-md-level="1">
      <label class="md-nav__title" for="nav-4">
        <span class="md-nav__icon md-icon">
          <svg xmlns="http://www.w3.org/2000/svg" viewBox="0 0 24 24"><path d="M20 11v2H8l5.5 5.5-1.42 1.42L4.16 12l7.92-7.92L13.5 5.5 8 11h12z"/></svg>
        </span>
        Sklearn
      </label>
      <ul class="md-nav__list" data-md-scrollfix>
        
        
          
          
          


  <li class="md-nav__item">
    <a href="../Base/" title="Base" class="md-nav__link">
      Base
    </a>
  </li>

        
          
          
          


  <li class="md-nav__item">
    <a href="../Calibration/" title="Calibration" class="md-nav__link">
      Calibration
    </a>
  </li>

        
          
          
          


  <li class="md-nav__item">
    <a href="../Cluster/" title="Cluster" class="md-nav__link">
      Cluster
    </a>
  </li>

        
          
          
          


  <li class="md-nav__item">
    <a href="../Compose/" title="Compose" class="md-nav__link">
      Compose
    </a>
  </li>

        
          
          
          


  <li class="md-nav__item">
    <a href="../Conftest/" title="Conftest" class="md-nav__link">
      Conftest
    </a>
  </li>

        
          
          
          


  <li class="md-nav__item">
    <a href="../Covariance/" title="Covariance" class="md-nav__link">
      Covariance
    </a>
  </li>

        
          
          
          


  <li class="md-nav__item">
    <a href="../Cross_decomposition/" title="Cross decomposition" class="md-nav__link">
      Cross decomposition
    </a>
  </li>

        
          
          
          


  <li class="md-nav__item">
    <a href="../Datasets/" title="Datasets" class="md-nav__link">
      Datasets
    </a>
  </li>

        
          
          
          

  


  <li class="md-nav__item md-nav__item--active">
    
    <input class="md-nav__toggle md-toggle" data-md-toggle="toc" type="checkbox" id="__toc">
    
      
    
    
    <a href="./" title="Decomposition" class="md-nav__link md-nav__link--active">
      Decomposition
    </a>
    
  </li>

        
          
          
          


  <li class="md-nav__item">
    <a href="../Discriminant_analysis/" title="Discriminant analysis" class="md-nav__link">
      Discriminant analysis
    </a>
  </li>

        
          
          
          


  <li class="md-nav__item">
    <a href="../Dummy/" title="Dummy" class="md-nav__link">
      Dummy
    </a>
  </li>

        
          
          
          


  <li class="md-nav__item">
    <a href="../Ensemble/" title="Ensemble" class="md-nav__link">
      Ensemble
    </a>
  </li>

        
          
          
          


  <li class="md-nav__item">
    <a href="../Exceptions/" title="Exceptions" class="md-nav__link">
      Exceptions
    </a>
  </li>

        
          
          
          


  <li class="md-nav__item">
    <a href="../Experimental/" title="Experimental" class="md-nav__link">
      Experimental
    </a>
  </li>

        
          
          
          


  <li class="md-nav__item">
    <a href="../Externals/" title="Externals" class="md-nav__link">
      Externals
    </a>
  </li>

        
          
          
          


  <li class="md-nav__item">
    <a href="../Feature_extraction/" title="Feature extraction" class="md-nav__link">
      Feature extraction
    </a>
  </li>

        
          
          
          


  <li class="md-nav__item">
    <a href="../Feature_selection/" title="Feature selection" class="md-nav__link">
      Feature selection
    </a>
  </li>

        
          
          
          


  <li class="md-nav__item">
    <a href="../Gaussian_process/" title="Gaussian process" class="md-nav__link">
      Gaussian process
    </a>
  </li>

        
          
          
          


  <li class="md-nav__item">
    <a href="../Impute/" title="Impute" class="md-nav__link">
      Impute
    </a>
  </li>

        
          
          
          


  <li class="md-nav__item">
    <a href="../Inspection/" title="Inspection" class="md-nav__link">
      Inspection
    </a>
  </li>

        
          
          
          


  <li class="md-nav__item">
    <a href="../Isotonic/" title="Isotonic" class="md-nav__link">
      Isotonic
    </a>
  </li>

        
          
          
          


  <li class="md-nav__item">
    <a href="../Kernel_approximation/" title="Kernel approximation" class="md-nav__link">
      Kernel approximation
    </a>
  </li>

        
          
          
          


  <li class="md-nav__item">
    <a href="../Kernel_ridge/" title="Kernel ridge" class="md-nav__link">
      Kernel ridge
    </a>
  </li>

        
          
          
          


  <li class="md-nav__item">
    <a href="../Linear_model/" title="Linear model" class="md-nav__link">
      Linear model
    </a>
  </li>

        
          
          
          


  <li class="md-nav__item">
    <a href="../Manifold/" title="Manifold" class="md-nav__link">
      Manifold
    </a>
  </li>

        
          
          
          


  <li class="md-nav__item">
    <a href="../Metrics/" title="Metrics" class="md-nav__link">
      Metrics
    </a>
  </li>

        
          
          
          


  <li class="md-nav__item">
    <a href="../Mixture/" title="Mixture" class="md-nav__link">
      Mixture
    </a>
  </li>

        
          
          
          


  <li class="md-nav__item">
    <a href="../Model_selection/" title="Model selection" class="md-nav__link">
      Model selection
    </a>
  </li>

        
          
          
          


  <li class="md-nav__item">
    <a href="../Multiclass/" title="Multiclass" class="md-nav__link">
      Multiclass
    </a>
  </li>

        
          
          
          


  <li class="md-nav__item">
    <a href="../Multioutput/" title="Multioutput" class="md-nav__link">
      Multioutput
    </a>
  </li>

        
          
          
          


  <li class="md-nav__item">
    <a href="../Naive_bayes/" title="Naive bayes" class="md-nav__link">
      Naive bayes
    </a>
  </li>

        
          
          
          


  <li class="md-nav__item">
    <a href="../Neighbors/" title="Neighbors" class="md-nav__link">
      Neighbors
    </a>
  </li>

        
          
          
          


  <li class="md-nav__item">
    <a href="../Neural_network/" title="Neural network" class="md-nav__link">
      Neural network
    </a>
  </li>

        
          
          
          


  <li class="md-nav__item">
    <a href="../Pipeline/" title="Pipeline" class="md-nav__link">
      Pipeline
    </a>
  </li>

        
          
          
          


  <li class="md-nav__item">
    <a href="../Preprocessing/" title="Preprocessing" class="md-nav__link">
      Preprocessing
    </a>
  </li>

        
          
          
          


  <li class="md-nav__item">
    <a href="../Random_projection/" title="Random projection" class="md-nav__link">
      Random projection
    </a>
  </li>

        
          
          
          


  <li class="md-nav__item">
    <a href="../Semi_supervised/" title="Semi supervised" class="md-nav__link">
      Semi supervised
    </a>
  </li>

        
          
          
          


  <li class="md-nav__item">
    <a href="../Setup/" title="Setup" class="md-nav__link">
      Setup
    </a>
  </li>

        
          
          
          


  <li class="md-nav__item">
    <a href="../Svm/" title="Svm" class="md-nav__link">
      Svm
    </a>
  </li>

        
          
          
          


  <li class="md-nav__item">
    <a href="../Tests/" title="Tests" class="md-nav__link">
      Tests
    </a>
  </li>

        
          
          
          


  <li class="md-nav__item">
    <a href="../Tree/" title="Tree" class="md-nav__link">
      Tree
    </a>
  </li>

        
          
          
          


  <li class="md-nav__item">
    <a href="../Utils/" title="Utils" class="md-nav__link">
      Utils
    </a>
  </li>

        
          
          
          


  <li class="md-nav__item">
    <a href="../arr/" title="Arr" class="md-nav__link">
      Arr
    </a>
  </li>

        
          
          
          


  <li class="md-nav__item">
    <a href="../dict/" title="Dict" class="md-nav__link">
      Dict
    </a>
  </li>

        
          
          
          


  <li class="md-nav__item">
    <a href="../wrap_version/" title="Wrap version" class="md-nav__link">
      Wrap version
    </a>
  </li>

        
      </ul>
    </nav>
  </li>

    
  </ul>
</nav>
                  </div>
                </div>
              </div>
            
            
              <div class="md-sidebar md-sidebar--secondary" data-md-component="toc">
                <div class="md-sidebar__scrollwrap">
                  <div class="md-sidebar__inner">
                    
<nav class="md-nav md-nav--secondary" aria-label="Table of contents">
  
  
    
  
  
</nav>
                  </div>
                </div>
              </div>
            
          
          <div class="md-content">
            <article class="md-content__inner md-typeset">
              
                
                  <a href="https://github.com/lehy/ocaml-sklearn/edit/master/docs/sklearn/Decomposition.md" title="Edit this page" class="md-content__button md-icon">
                    <svg xmlns="http://www.w3.org/2000/svg" viewBox="0 0 24 24"><path d="M20.71 7.04c.39-.39.39-1.04 0-1.41l-2.34-2.34c-.37-.39-1.02-.39-1.41 0l-1.84 1.83 3.75 3.75M3 17.25V21h3.75L17.81 9.93l-3.75-3.75L3 17.25z"/></svg>
                  </a>
                
                
                  
                
                
                <p>Get an attribute of this module as a Py.Object.t.
This is useful to pass a Python function to another function.</p>
<div class="highlight"><pre><span></span><code><span class="k">val</span> <span class="n">get_py</span> <span class="o">:</span> <span class="kt">string</span> <span class="o">-&gt;</span> <span class="nn">Py</span><span class="p">.</span><span class="nn">Object</span><span class="p">.</span><span class="n">t</span>

<span class="k">module</span> <span class="nc">DictionaryLearning</span> <span class="o">:</span> <span class="k">sig</span>
<span class="k">type</span> <span class="n">tag</span> <span class="o">=</span> <span class="o">[`</span><span class="nc">DictionaryLearning</span><span class="o">]</span>
<span class="k">type</span> <span class="n">t</span> <span class="o">=</span> <span class="o">[`</span><span class="nc">BaseEstimator</span> <span class="o">|</span> <span class="o">`</span><span class="nc">DictionaryLearning</span> <span class="o">|</span> <span class="o">`</span><span class="nc">Object</span> <span class="o">|</span> <span class="o">`</span><span class="nc">SparseCodingMixin</span> <span class="o">|</span> <span class="o">`</span><span class="nc">TransformerMixin</span><span class="o">]</span> <span class="nn">Obj</span><span class="p">.</span><span class="n">t</span>
<span class="k">val</span> <span class="n">of_pyobject</span> <span class="o">:</span> <span class="nn">Py</span><span class="p">.</span><span class="nn">Object</span><span class="p">.</span><span class="n">t</span> <span class="o">-&gt;</span> <span class="n">t</span>
<span class="k">val</span> <span class="n">to_pyobject</span> <span class="o">:</span> <span class="o">[&gt;</span> <span class="n">tag</span><span class="o">]</span> <span class="nn">Obj</span><span class="p">.</span><span class="n">t</span> <span class="o">-&gt;</span> <span class="nn">Py</span><span class="p">.</span><span class="nn">Object</span><span class="p">.</span><span class="n">t</span>

<span class="k">val</span> <span class="n">as_transformer</span> <span class="o">:</span> <span class="n">t</span> <span class="o">-&gt;</span> <span class="o">[`</span><span class="nc">TransformerMixin</span><span class="o">]</span> <span class="nn">Obj</span><span class="p">.</span><span class="n">t</span>
<span class="k">val</span> <span class="n">as_estimator</span> <span class="o">:</span> <span class="n">t</span> <span class="o">-&gt;</span> <span class="o">[`</span><span class="nc">BaseEstimator</span><span class="o">]</span> <span class="nn">Obj</span><span class="p">.</span><span class="n">t</span>
<span class="k">val</span> <span class="n">as_sparse_coding</span> <span class="o">:</span> <span class="n">t</span> <span class="o">-&gt;</span> <span class="o">[`</span><span class="nc">SparseCodingMixin</span><span class="o">]</span> <span class="nn">Obj</span><span class="p">.</span><span class="n">t</span>
<span class="k">val</span> <span class="n">create</span> <span class="o">:</span> <span class="o">?</span><span class="n">n_components</span><span class="o">:</span><span class="kt">int</span> <span class="o">-&gt;</span> <span class="o">?</span><span class="n">alpha</span><span class="o">:</span><span class="kt">float</span> <span class="o">-&gt;</span> <span class="o">?</span><span class="n">max_iter</span><span class="o">:</span><span class="kt">int</span> <span class="o">-&gt;</span> <span class="o">?</span><span class="n">tol</span><span class="o">:</span><span class="kt">float</span> <span class="o">-&gt;</span> <span class="o">?</span><span class="n">fit_algorithm</span><span class="o">:[`</span><span class="nc">Lars</span> <span class="o">|</span> <span class="o">`</span><span class="nc">Cd</span><span class="o">]</span> <span class="o">-&gt;</span> <span class="o">?</span><span class="n">transform_algorithm</span><span class="o">:[`</span><span class="nc">Lasso_lars</span> <span class="o">|</span> <span class="o">`</span><span class="nc">Lasso_cd</span> <span class="o">|</span> <span class="o">`</span><span class="nc">Lars</span> <span class="o">|</span> <span class="o">`</span><span class="nc">Omp</span> <span class="o">|</span> <span class="o">`</span><span class="nc">Threshold</span><span class="o">]</span> <span class="o">-&gt;</span> <span class="o">?</span><span class="n">transform_n_nonzero_coefs</span><span class="o">:</span><span class="kt">int</span> <span class="o">-&gt;</span> <span class="o">?</span><span class="n">transform_alpha</span><span class="o">:</span><span class="kt">float</span> <span class="o">-&gt;</span> <span class="o">?</span><span class="n">n_jobs</span><span class="o">:</span><span class="kt">int</span> <span class="o">-&gt;</span> <span class="o">?</span><span class="n">code_init</span><span class="o">:[&gt;`</span><span class="nc">ArrayLike</span><span class="o">]</span> <span class="nn">Np</span><span class="p">.</span><span class="nn">Obj</span><span class="p">.</span><span class="n">t</span> <span class="o">-&gt;</span> <span class="o">?</span><span class="n">dict_init</span><span class="o">:[&gt;`</span><span class="nc">ArrayLike</span><span class="o">]</span> <span class="nn">Np</span><span class="p">.</span><span class="nn">Obj</span><span class="p">.</span><span class="n">t</span> <span class="o">-&gt;</span> <span class="o">?</span><span class="n">verbose</span><span class="o">:</span><span class="kt">int</span> <span class="o">-&gt;</span> <span class="o">?</span><span class="n">split_sign</span><span class="o">:</span><span class="kt">bool</span> <span class="o">-&gt;</span> <span class="o">?</span><span class="n">random_state</span><span class="o">:</span><span class="kt">int</span> <span class="o">-&gt;</span> <span class="o">?</span><span class="n">positive_code</span><span class="o">:</span><span class="kt">bool</span> <span class="o">-&gt;</span> <span class="o">?</span><span class="n">positive_dict</span><span class="o">:</span><span class="kt">bool</span> <span class="o">-&gt;</span> <span class="o">?</span><span class="n">transform_max_iter</span><span class="o">:</span><span class="kt">int</span> <span class="o">-&gt;</span> <span class="kt">unit</span> <span class="o">-&gt;</span> <span class="n">t</span>
</code></pre></div>

<p>Dictionary learning</p>
<p>Finds a dictionary (a set of atoms) that can best be used to represent data
using a sparse code.</p>
<p>Solves the optimization problem::</p>
<p>(U^<em>,V^</em> ) = argmin 0.5 || Y - U V ||_2^2 + alpha * || U ||_1
(U,V)
with || V_k ||_2 = 1 for all  0 &lt;= k &lt; n_components</p>
<p>Read more in the :ref:<code>User Guide &lt;DictionaryLearning&gt;</code>.</p>
<h2 id="parameters">Parameters<a class="headerlink" href="#parameters" title="Permanent link">&para;</a></h2>
<p>n_components : int, default=n_features
number of dictionary elements to extract</p>
<p>alpha : float, default=1.0
sparsity controlling parameter</p>
<p>max_iter : int, default=1000
maximum number of iterations to perform</p>
<p>tol : float, default=1e-8
tolerance for numerical error</p>
<p>fit_algorithm : {'lars', 'cd'}, default='lars'
lars: uses the least angle regression method to solve the lasso problem
(linear_model.lars_path)
cd: uses the coordinate descent method to compute the
Lasso solution (linear_model.Lasso). Lars will be faster if
the estimated components are sparse.</p>
<p>.. versionadded:: 0.17
<em>cd</em> coordinate descent method to improve speed.</p>
<p>transform_algorithm : {'lasso_lars', 'lasso_cd', 'lars', 'omp',     'threshold'}, default='omp'
Algorithm used to transform the data
lars: uses the least angle regression method (linear_model.lars_path)
lasso_lars: uses Lars to compute the Lasso solution
lasso_cd: uses the coordinate descent method to compute the
Lasso solution (linear_model.Lasso). lasso_lars will be faster if
the estimated components are sparse.
omp: uses orthogonal matching pursuit to estimate the sparse solution
threshold: squashes to zero all coefficients less than alpha from
the projection <code>dictionary * X'</code></p>
<p>.. versionadded:: 0.17
<em>lasso_cd</em> coordinate descent method to improve speed.</p>
<p>transform_n_nonzero_coefs : int, default=0.1*n_features
Number of nonzero coefficients to target in each column of the
solution. This is only used by <code>algorithm='lars'</code> and <code>algorithm='omp'</code>
and is overridden by <code>alpha</code> in the <code>omp</code> case.</p>
<p>transform_alpha : float, default=1.0
If <code>algorithm='lasso_lars'</code> or <code>algorithm='lasso_cd'</code>, <code>alpha</code> is the
penalty applied to the L1 norm.
If <code>algorithm='threshold'</code>, <code>alpha</code> is the absolute value of the
threshold below which coefficients will be squashed to zero.
If <code>algorithm='omp'</code>, <code>alpha</code> is the tolerance parameter: the value of
the reconstruction error targeted. In this case, it overrides
<code>n_nonzero_coefs</code>.</p>
<p>n_jobs : int or None, default=None
Number of parallel jobs to run.
<code>None</code> means 1 unless in a :obj:<code>joblib.parallel_backend</code> context.
<code>-1</code> means using all processors. See :term:<code>Glossary &lt;n_jobs&gt;</code>
for more details.</p>
<p>code_init : array of shape (n_samples, n_components), default=None
initial value for the code, for warm restart</p>
<p>dict_init : array of shape (n_components, n_features), default=None
initial values for the dictionary, for warm restart</p>
<p>verbose : bool, default=False
To control the verbosity of the procedure.</p>
<p>split_sign : bool, default=False
Whether to split the sparse feature vector into the concatenation of
its negative part and its positive part. This can improve the
performance of downstream classifiers.</p>
<p>random_state : int, RandomState instance or None, default=None
If int, random_state is the seed used by the random number generator;
If RandomState instance, random_state is the random number generator;
If None, the random number generator is the RandomState instance used
by <code>np.random</code>.</p>
<p>positive_code : bool, default=False
Whether to enforce positivity when finding the code.</p>
<p>.. versionadded:: 0.20</p>
<p>positive_dict : bool, default=False
Whether to enforce positivity when finding the dictionary</p>
<p>.. versionadded:: 0.20</p>
<p>transform_max_iter : int, default=1000
Maximum number of iterations to perform if <code>algorithm='lasso_cd'</code> or
<code>lasso_lars</code>.</p>
<p>.. versionadded:: 0.22</p>
<h2 id="attributes">Attributes<a class="headerlink" href="#attributes" title="Permanent link">&para;</a></h2>
<p>components_ : array, [n_components, n_features]
dictionary atoms extracted from the data</p>
<p>error_ : array
vector of errors at each iteration</p>
<p>n_iter_ : int
Number of iterations run.</p>
<h2 id="notes">Notes<a class="headerlink" href="#notes" title="Permanent link">&para;</a></h2>
<p><strong>References:</strong></p>
<p>J. Mairal, F. Bach, J. Ponce, G. Sapiro, 2009: Online dictionary learning
for sparse coding (https://www.di.ens.fr/sierra/pdfs/icml09.pdf)</p>
<h2 id="see-also">See also<a class="headerlink" href="#see-also" title="Permanent link">&para;</a></h2>
<p>SparseCoder
MiniBatchDictionaryLearning
SparsePCA
MiniBatchSparsePCA</p>
<div class="highlight"><pre><span></span><code><span class="k">val</span> <span class="n">fit</span> <span class="o">:</span> <span class="o">?</span><span class="n">y</span><span class="o">:</span><span class="nn">Py</span><span class="p">.</span><span class="nn">Object</span><span class="p">.</span><span class="n">t</span> <span class="o">-&gt;</span> <span class="n">x</span><span class="o">:[&gt;`</span><span class="nc">ArrayLike</span><span class="o">]</span> <span class="nn">Np</span><span class="p">.</span><span class="nn">Obj</span><span class="p">.</span><span class="n">t</span> <span class="o">-&gt;</span> <span class="o">[&gt;</span> <span class="n">tag</span><span class="o">]</span> <span class="nn">Obj</span><span class="p">.</span><span class="n">t</span> <span class="o">-&gt;</span> <span class="n">t</span>
</code></pre></div>

<p>Fit the model from data in X.</p>
<h2 id="parameters_1">Parameters<a class="headerlink" href="#parameters_1" title="Permanent link">&para;</a></h2>
<p>X : array-like, shape (n_samples, n_features)
Training vector, where n_samples in the number of samples
and n_features is the number of features.</p>
<p>y : Ignored</p>
<h2 id="returns">Returns<a class="headerlink" href="#returns" title="Permanent link">&para;</a></h2>
<p>self : object
Returns the object itself</p>
<div class="highlight"><pre><span></span><code><span class="k">val</span> <span class="n">fit_transform</span> <span class="o">:</span> <span class="o">?</span><span class="n">y</span><span class="o">:[&gt;`</span><span class="nc">ArrayLike</span><span class="o">]</span> <span class="nn">Np</span><span class="p">.</span><span class="nn">Obj</span><span class="p">.</span><span class="n">t</span> <span class="o">-&gt;</span> <span class="o">?</span><span class="n">fit_params</span><span class="o">:(</span><span class="kt">string</span> <span class="o">*</span> <span class="nn">Py</span><span class="p">.</span><span class="nn">Object</span><span class="p">.</span><span class="n">t</span><span class="o">)</span> <span class="kt">list</span> <span class="o">-&gt;</span> <span class="n">x</span><span class="o">:[&gt;`</span><span class="nc">ArrayLike</span><span class="o">]</span> <span class="nn">Np</span><span class="p">.</span><span class="nn">Obj</span><span class="p">.</span><span class="n">t</span> <span class="o">-&gt;</span> <span class="o">[&gt;</span> <span class="n">tag</span><span class="o">]</span> <span class="nn">Obj</span><span class="p">.</span><span class="n">t</span> <span class="o">-&gt;</span> <span class="o">[&gt;`</span><span class="nc">ArrayLike</span><span class="o">]</span> <span class="nn">Np</span><span class="p">.</span><span class="nn">Obj</span><span class="p">.</span><span class="n">t</span>
</code></pre></div>

<p>Fit to data, then transform it.</p>
<p>Fits transformer to X and y with optional parameters fit_params
and returns a transformed version of X.</p>
<h2 id="parameters_2">Parameters<a class="headerlink" href="#parameters_2" title="Permanent link">&para;</a></h2>
<p>X : numpy array of shape [n_samples, n_features]
Training set.</p>
<p>y : numpy array of shape [n_samples]
Target values.</p>
<p>**fit_params : dict
Additional fit parameters.</p>
<h2 id="returns_1">Returns<a class="headerlink" href="#returns_1" title="Permanent link">&para;</a></h2>
<p>X_new : numpy array of shape [n_samples, n_features_new]
Transformed array.</p>
<div class="highlight"><pre><span></span><code><span class="k">val</span> <span class="n">get_params</span> <span class="o">:</span> <span class="o">?</span><span class="n">deep</span><span class="o">:</span><span class="kt">bool</span> <span class="o">-&gt;</span> <span class="o">[&gt;</span> <span class="n">tag</span><span class="o">]</span> <span class="nn">Obj</span><span class="p">.</span><span class="n">t</span> <span class="o">-&gt;</span> <span class="nn">Dict</span><span class="p">.</span><span class="n">t</span>
</code></pre></div>

<p>Get parameters for this estimator.</p>
<h2 id="parameters_3">Parameters<a class="headerlink" href="#parameters_3" title="Permanent link">&para;</a></h2>
<p>deep : bool, default=True
If True, will return the parameters for this estimator and
contained subobjects that are estimators.</p>
<h2 id="returns_2">Returns<a class="headerlink" href="#returns_2" title="Permanent link">&para;</a></h2>
<p>params : mapping of string to any
Parameter names mapped to their values.</p>
<div class="highlight"><pre><span></span><code><span class="k">val</span> <span class="n">set_params</span> <span class="o">:</span> <span class="o">?</span><span class="n">params</span><span class="o">:(</span><span class="kt">string</span> <span class="o">*</span> <span class="nn">Py</span><span class="p">.</span><span class="nn">Object</span><span class="p">.</span><span class="n">t</span><span class="o">)</span> <span class="kt">list</span> <span class="o">-&gt;</span> <span class="o">[&gt;</span> <span class="n">tag</span><span class="o">]</span> <span class="nn">Obj</span><span class="p">.</span><span class="n">t</span> <span class="o">-&gt;</span> <span class="n">t</span>
</code></pre></div>

<p>Set the parameters of this estimator.</p>
<p>The method works on simple estimators as well as on nested objects
(such as pipelines). The latter have parameters of the form
<code>&lt;component&gt;__&lt;parameter&gt;</code> so that it's possible to update each
component of a nested object.</p>
<h2 id="parameters_4">Parameters<a class="headerlink" href="#parameters_4" title="Permanent link">&para;</a></h2>
<p>**params : dict
Estimator parameters.</p>
<h2 id="returns_3">Returns<a class="headerlink" href="#returns_3" title="Permanent link">&para;</a></h2>
<p>self : object
Estimator instance.</p>
<div class="highlight"><pre><span></span><code><span class="k">val</span> <span class="n">transform</span> <span class="o">:</span> <span class="n">x</span><span class="o">:[&gt;`</span><span class="nc">ArrayLike</span><span class="o">]</span> <span class="nn">Np</span><span class="p">.</span><span class="nn">Obj</span><span class="p">.</span><span class="n">t</span> <span class="o">-&gt;</span> <span class="o">[&gt;</span> <span class="n">tag</span><span class="o">]</span> <span class="nn">Obj</span><span class="p">.</span><span class="n">t</span> <span class="o">-&gt;</span> <span class="o">[&gt;`</span><span class="nc">ArrayLike</span><span class="o">]</span> <span class="nn">Np</span><span class="p">.</span><span class="nn">Obj</span><span class="p">.</span><span class="n">t</span>
</code></pre></div>

<p>Encode the data as a sparse combination of the dictionary atoms.</p>
<p>Coding method is determined by the object parameter
<code>transform_algorithm</code>.</p>
<h2 id="parameters_5">Parameters<a class="headerlink" href="#parameters_5" title="Permanent link">&para;</a></h2>
<p>X : array of shape (n_samples, n_features)
Test data to be transformed, must have the same number of
features as the data used to train the model.</p>
<h2 id="returns_4">Returns<a class="headerlink" href="#returns_4" title="Permanent link">&para;</a></h2>
<p>X_new : array, shape (n_samples, n_components)
Transformed data</p>
<p>Attribute components_: get value or raise Not_found if None.</p>
<div class="highlight"><pre><span></span><code><span class="k">val</span> <span class="n">components_</span> <span class="o">:</span> <span class="n">t</span> <span class="o">-&gt;</span> <span class="o">[&gt;`</span><span class="nc">ArrayLike</span><span class="o">]</span> <span class="nn">Np</span><span class="p">.</span><span class="nn">Obj</span><span class="p">.</span><span class="n">t</span>
</code></pre></div>

<p>Attribute components_: get value as an option.</p>
<div class="highlight"><pre><span></span><code><span class="k">val</span> <span class="n">components_opt</span> <span class="o">:</span> <span class="n">t</span> <span class="o">-&gt;</span> <span class="o">([&gt;`</span><span class="nc">ArrayLike</span><span class="o">]</span> <span class="nn">Np</span><span class="p">.</span><span class="nn">Obj</span><span class="p">.</span><span class="n">t</span><span class="o">)</span> <span class="n">option</span>
</code></pre></div>

<p>Attribute error_: get value or raise Not_found if None.</p>
<div class="highlight"><pre><span></span><code><span class="k">val</span> <span class="n">error_</span> <span class="o">:</span> <span class="n">t</span> <span class="o">-&gt;</span> <span class="o">[&gt;`</span><span class="nc">ArrayLike</span><span class="o">]</span> <span class="nn">Np</span><span class="p">.</span><span class="nn">Obj</span><span class="p">.</span><span class="n">t</span>
</code></pre></div>

<p>Attribute error_: get value as an option.</p>
<div class="highlight"><pre><span></span><code><span class="k">val</span> <span class="n">error_opt</span> <span class="o">:</span> <span class="n">t</span> <span class="o">-&gt;</span> <span class="o">([&gt;`</span><span class="nc">ArrayLike</span><span class="o">]</span> <span class="nn">Np</span><span class="p">.</span><span class="nn">Obj</span><span class="p">.</span><span class="n">t</span><span class="o">)</span> <span class="n">option</span>
</code></pre></div>

<p>Attribute n_iter_: get value or raise Not_found if None.</p>
<div class="highlight"><pre><span></span><code><span class="k">val</span> <span class="n">n_iter_</span> <span class="o">:</span> <span class="n">t</span> <span class="o">-&gt;</span> <span class="kt">int</span>
</code></pre></div>

<p>Attribute n_iter_: get value as an option.</p>
<div class="highlight"><pre><span></span><code><span class="k">val</span> <span class="n">n_iter_opt</span> <span class="o">:</span> <span class="n">t</span> <span class="o">-&gt;</span> <span class="o">(</span><span class="kt">int</span><span class="o">)</span> <span class="n">option</span>
</code></pre></div>

<p>Print the object to a human-readable representation.</p>
<div class="highlight"><pre><span></span><code><span class="k">val</span> <span class="n">to_string</span> <span class="o">:</span> <span class="n">t</span> <span class="o">-&gt;</span> <span class="kt">string</span>
</code></pre></div>

<p>Print the object to a human-readable representation.</p>
<div class="highlight"><pre><span></span><code><span class="k">val</span> <span class="n">show</span> <span class="o">:</span> <span class="n">t</span> <span class="o">-&gt;</span> <span class="kt">string</span>
</code></pre></div>

<p>Pretty-print the object to a formatter.</p>
<div class="highlight"><pre><span></span><code><span class="k">val</span> <span class="n">pp</span> <span class="o">:</span> <span class="nn">Format</span><span class="p">.</span><span class="n">formatter</span> <span class="o">-&gt;</span> <span class="n">t</span> <span class="o">-&gt;</span> <span class="kt">unit</span> <span class="o">[@@</span><span class="n">ocaml</span><span class="o">.</span><span class="n">toplevel_printer</span><span class="o">]</span>



<span class="k">module</span> <span class="nc">FactorAnalysis</span> <span class="o">:</span> <span class="k">sig</span>
<span class="k">type</span> <span class="n">tag</span> <span class="o">=</span> <span class="o">[`</span><span class="nc">FactorAnalysis</span><span class="o">]</span>
<span class="k">type</span> <span class="n">t</span> <span class="o">=</span> <span class="o">[`</span><span class="nc">BaseEstimator</span> <span class="o">|</span> <span class="o">`</span><span class="nc">FactorAnalysis</span> <span class="o">|</span> <span class="o">`</span><span class="nc">Object</span> <span class="o">|</span> <span class="o">`</span><span class="nc">TransformerMixin</span><span class="o">]</span> <span class="nn">Obj</span><span class="p">.</span><span class="n">t</span>
<span class="k">val</span> <span class="n">of_pyobject</span> <span class="o">:</span> <span class="nn">Py</span><span class="p">.</span><span class="nn">Object</span><span class="p">.</span><span class="n">t</span> <span class="o">-&gt;</span> <span class="n">t</span>
<span class="k">val</span> <span class="n">to_pyobject</span> <span class="o">:</span> <span class="o">[&gt;</span> <span class="n">tag</span><span class="o">]</span> <span class="nn">Obj</span><span class="p">.</span><span class="n">t</span> <span class="o">-&gt;</span> <span class="nn">Py</span><span class="p">.</span><span class="nn">Object</span><span class="p">.</span><span class="n">t</span>

<span class="k">val</span> <span class="n">as_transformer</span> <span class="o">:</span> <span class="n">t</span> <span class="o">-&gt;</span> <span class="o">[`</span><span class="nc">TransformerMixin</span><span class="o">]</span> <span class="nn">Obj</span><span class="p">.</span><span class="n">t</span>
<span class="k">val</span> <span class="n">as_estimator</span> <span class="o">:</span> <span class="n">t</span> <span class="o">-&gt;</span> <span class="o">[`</span><span class="nc">BaseEstimator</span><span class="o">]</span> <span class="nn">Obj</span><span class="p">.</span><span class="n">t</span>
<span class="k">val</span> <span class="n">create</span> <span class="o">:</span> <span class="o">?</span><span class="n">n_components</span><span class="o">:</span><span class="kt">int</span> <span class="o">-&gt;</span> <span class="o">?</span><span class="n">tol</span><span class="o">:</span><span class="kt">float</span> <span class="o">-&gt;</span> <span class="o">?</span><span class="n">copy</span><span class="o">:</span><span class="kt">bool</span> <span class="o">-&gt;</span> <span class="o">?</span><span class="n">max_iter</span><span class="o">:</span><span class="kt">int</span> <span class="o">-&gt;</span> <span class="o">?</span><span class="n">noise_variance_init</span><span class="o">:[&gt;`</span><span class="nc">ArrayLike</span><span class="o">]</span> <span class="nn">Np</span><span class="p">.</span><span class="nn">Obj</span><span class="p">.</span><span class="n">t</span> <span class="o">-&gt;</span> <span class="o">?</span><span class="n">svd_method</span><span class="o">:[`</span><span class="nc">Lapack</span> <span class="o">|</span> <span class="o">`</span><span class="nc">Randomized</span><span class="o">]</span> <span class="o">-&gt;</span> <span class="o">?</span><span class="n">iterated_power</span><span class="o">:</span><span class="kt">int</span> <span class="o">-&gt;</span> <span class="o">?</span><span class="n">random_state</span><span class="o">:</span><span class="kt">int</span> <span class="o">-&gt;</span> <span class="kt">unit</span> <span class="o">-&gt;</span> <span class="n">t</span>
</code></pre></div>

<p>Factor Analysis (FA)</p>
<p>A simple linear generative model with Gaussian latent variables.</p>
<p>The observations are assumed to be caused by a linear transformation of
lower dimensional latent factors and added Gaussian noise.
Without loss of generality the factors are distributed according to a
Gaussian with zero mean and unit covariance. The noise is also zero mean
and has an arbitrary diagonal covariance matrix.</p>
<p>If we would restrict the model further, by assuming that the Gaussian
noise is even isotropic (all diagonal entries are the same) we would obtain
:class:<code>PPCA</code>.</p>
<p>FactorAnalysis performs a maximum likelihood estimate of the so-called
<code>loading</code> matrix, the transformation of the latent variables to the
observed ones, using SVD based approach.</p>
<p>Read more in the :ref:<code>User Guide &lt;FA&gt;</code>.</p>
<p>.. versionadded:: 0.13</p>
<h2 id="parameters_6">Parameters<a class="headerlink" href="#parameters_6" title="Permanent link">&para;</a></h2>
<p>n_components : int | None
Dimensionality of latent space, the number of components
of <code>X</code> that are obtained after <code>transform</code>.
If None, n_components is set to the number of features.</p>
<p>tol : float
Stopping tolerance for log-likelihood increase.</p>
<p>copy : bool
Whether to make a copy of X. If <code>False</code>, the input X gets overwritten
during fitting.</p>
<p>max_iter : int
Maximum number of iterations.</p>
<p>noise_variance_init : None | array, shape=(n_features,)
The initial guess of the noise variance for each feature.
If None, it defaults to np.ones(n_features)</p>
<p>svd_method : {'lapack', 'randomized'}
Which SVD method to use. If 'lapack' use standard SVD from
scipy.linalg, if 'randomized' use fast <code>randomized_svd</code> function.
Defaults to 'randomized'. For most applications 'randomized' will
be sufficiently precise while providing significant speed gains.
Accuracy can also be improved by setting higher values for
<code>iterated_power</code>. If this is not sufficient, for maximum precision
you should choose 'lapack'.</p>
<p>iterated_power : int, optional
Number of iterations for the power method. 3 by default. Only used
if <code>svd_method</code> equals 'randomized'</p>
<p>random_state : int, RandomState instance or None, optional (default=0)
If int, random_state is the seed used by the random number generator;
If RandomState instance, random_state is the random number generator;
If None, the random number generator is the RandomState instance used
by <code>np.random</code>. Only used when <code>svd_method</code> equals 'randomized'.</p>
<h2 id="attributes_1">Attributes<a class="headerlink" href="#attributes_1" title="Permanent link">&para;</a></h2>
<p>components_ : array, [n_components, n_features]
Components with maximum variance.</p>
<p>loglike_ : list, [n_iterations]
The log likelihood at each iteration.</p>
<p>noise_variance_ : array, shape=(n_features,)
The estimated noise variance for each feature.</p>
<p>n_iter_ : int
Number of iterations run.</p>
<p>mean_ : array, shape (n_features,)
Per-feature empirical mean, estimated from the training set.</p>
<h2 id="examples">Examples<a class="headerlink" href="#examples" title="Permanent link">&para;</a></h2>
<blockquote>
<blockquote>
<blockquote>
<p>from sklearn.datasets import load_digits
from sklearn.decomposition import FactorAnalysis
X, _ = load_digits(return_X_y=True)
transformer = FactorAnalysis(n_components=7, random_state=0)
X_transformed = transformer.fit_transform(X)
X_transformed.shape
(1797, 7)</p>
</blockquote>
</blockquote>
</blockquote>
<h2 id="references">References<a class="headerlink" href="#references" title="Permanent link">&para;</a></h2>
<p>.. David Barber, Bayesian Reasoning and Machine Learning,
Algorithm 21.1</p>
<p>.. Christopher M. Bishop: Pattern Recognition and Machine Learning,
Chapter 12.2.4</p>
<h2 id="see-also_1">See also<a class="headerlink" href="#see-also_1" title="Permanent link">&para;</a></h2>
<p>PCA: Principal component analysis is also a latent linear variable model
which however assumes equal noise variance for each feature.
This extra assumption makes probabilistic PCA faster as it can be
computed in closed form.
FastICA: Independent component analysis, a latent variable model with
non-Gaussian latent variables.</p>
<div class="highlight"><pre><span></span><code><span class="k">val</span> <span class="n">fit</span> <span class="o">:</span> <span class="o">?</span><span class="n">y</span><span class="o">:</span><span class="nn">Py</span><span class="p">.</span><span class="nn">Object</span><span class="p">.</span><span class="n">t</span> <span class="o">-&gt;</span> <span class="n">x</span><span class="o">:[&gt;`</span><span class="nc">ArrayLike</span><span class="o">]</span> <span class="nn">Np</span><span class="p">.</span><span class="nn">Obj</span><span class="p">.</span><span class="n">t</span> <span class="o">-&gt;</span> <span class="o">[&gt;</span> <span class="n">tag</span><span class="o">]</span> <span class="nn">Obj</span><span class="p">.</span><span class="n">t</span> <span class="o">-&gt;</span> <span class="n">t</span>
</code></pre></div>

<p>Fit the FactorAnalysis model to X using SVD based approach</p>
<h2 id="parameters_7">Parameters<a class="headerlink" href="#parameters_7" title="Permanent link">&para;</a></h2>
<p>X : array-like, shape (n_samples, n_features)
Training data.</p>
<p>y : Ignored</p>
<h2 id="returns_5">Returns<a class="headerlink" href="#returns_5" title="Permanent link">&para;</a></h2>
<p>self</p>
<div class="highlight"><pre><span></span><code><span class="k">val</span> <span class="n">fit_transform</span> <span class="o">:</span> <span class="o">?</span><span class="n">y</span><span class="o">:[&gt;`</span><span class="nc">ArrayLike</span><span class="o">]</span> <span class="nn">Np</span><span class="p">.</span><span class="nn">Obj</span><span class="p">.</span><span class="n">t</span> <span class="o">-&gt;</span> <span class="o">?</span><span class="n">fit_params</span><span class="o">:(</span><span class="kt">string</span> <span class="o">*</span> <span class="nn">Py</span><span class="p">.</span><span class="nn">Object</span><span class="p">.</span><span class="n">t</span><span class="o">)</span> <span class="kt">list</span> <span class="o">-&gt;</span> <span class="n">x</span><span class="o">:[&gt;`</span><span class="nc">ArrayLike</span><span class="o">]</span> <span class="nn">Np</span><span class="p">.</span><span class="nn">Obj</span><span class="p">.</span><span class="n">t</span> <span class="o">-&gt;</span> <span class="o">[&gt;</span> <span class="n">tag</span><span class="o">]</span> <span class="nn">Obj</span><span class="p">.</span><span class="n">t</span> <span class="o">-&gt;</span> <span class="o">[&gt;`</span><span class="nc">ArrayLike</span><span class="o">]</span> <span class="nn">Np</span><span class="p">.</span><span class="nn">Obj</span><span class="p">.</span><span class="n">t</span>
</code></pre></div>

<p>Fit to data, then transform it.</p>
<p>Fits transformer to X and y with optional parameters fit_params
and returns a transformed version of X.</p>
<h2 id="parameters_8">Parameters<a class="headerlink" href="#parameters_8" title="Permanent link">&para;</a></h2>
<p>X : numpy array of shape [n_samples, n_features]
Training set.</p>
<p>y : numpy array of shape [n_samples]
Target values.</p>
<p>**fit_params : dict
Additional fit parameters.</p>
<h2 id="returns_6">Returns<a class="headerlink" href="#returns_6" title="Permanent link">&para;</a></h2>
<p>X_new : numpy array of shape [n_samples, n_features_new]
Transformed array.</p>
<div class="highlight"><pre><span></span><code><span class="k">val</span> <span class="n">get_covariance</span> <span class="o">:</span> <span class="o">[&gt;</span> <span class="n">tag</span><span class="o">]</span> <span class="nn">Obj</span><span class="p">.</span><span class="n">t</span> <span class="o">-&gt;</span> <span class="o">[&gt;`</span><span class="nc">ArrayLike</span><span class="o">]</span> <span class="nn">Np</span><span class="p">.</span><span class="nn">Obj</span><span class="p">.</span><span class="n">t</span>
</code></pre></div>

<p>Compute data covariance with the FactorAnalysis model.</p>
<p><code>cov = components_.T * components_ + diag(noise_variance)</code></p>
<h2 id="returns_7">Returns<a class="headerlink" href="#returns_7" title="Permanent link">&para;</a></h2>
<p>cov : array, shape (n_features, n_features)
Estimated covariance of data.</p>
<div class="highlight"><pre><span></span><code><span class="k">val</span> <span class="n">get_params</span> <span class="o">:</span> <span class="o">?</span><span class="n">deep</span><span class="o">:</span><span class="kt">bool</span> <span class="o">-&gt;</span> <span class="o">[&gt;</span> <span class="n">tag</span><span class="o">]</span> <span class="nn">Obj</span><span class="p">.</span><span class="n">t</span> <span class="o">-&gt;</span> <span class="nn">Dict</span><span class="p">.</span><span class="n">t</span>
</code></pre></div>

<p>Get parameters for this estimator.</p>
<h2 id="parameters_9">Parameters<a class="headerlink" href="#parameters_9" title="Permanent link">&para;</a></h2>
<p>deep : bool, default=True
If True, will return the parameters for this estimator and
contained subobjects that are estimators.</p>
<h2 id="returns_8">Returns<a class="headerlink" href="#returns_8" title="Permanent link">&para;</a></h2>
<p>params : mapping of string to any
Parameter names mapped to their values.</p>
<div class="highlight"><pre><span></span><code><span class="k">val</span> <span class="n">get_precision</span> <span class="o">:</span> <span class="o">[&gt;</span> <span class="n">tag</span><span class="o">]</span> <span class="nn">Obj</span><span class="p">.</span><span class="n">t</span> <span class="o">-&gt;</span> <span class="o">[&gt;`</span><span class="nc">ArrayLike</span><span class="o">]</span> <span class="nn">Np</span><span class="p">.</span><span class="nn">Obj</span><span class="p">.</span><span class="n">t</span>
</code></pre></div>

<p>Compute data precision matrix with the FactorAnalysis model.</p>
<h2 id="returns_9">Returns<a class="headerlink" href="#returns_9" title="Permanent link">&para;</a></h2>
<p>precision : array, shape (n_features, n_features)
Estimated precision of data.</p>
<div class="highlight"><pre><span></span><code><span class="k">val</span> <span class="n">score</span> <span class="o">:</span> <span class="o">?</span><span class="n">y</span><span class="o">:</span><span class="nn">Py</span><span class="p">.</span><span class="nn">Object</span><span class="p">.</span><span class="n">t</span> <span class="o">-&gt;</span> <span class="n">x</span><span class="o">:[&gt;`</span><span class="nc">ArrayLike</span><span class="o">]</span> <span class="nn">Np</span><span class="p">.</span><span class="nn">Obj</span><span class="p">.</span><span class="n">t</span> <span class="o">-&gt;</span> <span class="o">[&gt;</span> <span class="n">tag</span><span class="o">]</span> <span class="nn">Obj</span><span class="p">.</span><span class="n">t</span> <span class="o">-&gt;</span> <span class="kt">float</span>
</code></pre></div>

<p>Compute the average log-likelihood of the samples</p>
<h2 id="parameters_10">Parameters<a class="headerlink" href="#parameters_10" title="Permanent link">&para;</a></h2>
<p>X : array, shape (n_samples, n_features)
The data</p>
<p>y : Ignored</p>
<h2 id="returns_10">Returns<a class="headerlink" href="#returns_10" title="Permanent link">&para;</a></h2>
<p>ll : float
Average log-likelihood of the samples under the current model</p>
<div class="highlight"><pre><span></span><code><span class="k">val</span> <span class="n">score_samples</span> <span class="o">:</span> <span class="n">x</span><span class="o">:[&gt;`</span><span class="nc">ArrayLike</span><span class="o">]</span> <span class="nn">Np</span><span class="p">.</span><span class="nn">Obj</span><span class="p">.</span><span class="n">t</span> <span class="o">-&gt;</span> <span class="o">[&gt;</span> <span class="n">tag</span><span class="o">]</span> <span class="nn">Obj</span><span class="p">.</span><span class="n">t</span> <span class="o">-&gt;</span> <span class="o">[&gt;`</span><span class="nc">ArrayLike</span><span class="o">]</span> <span class="nn">Np</span><span class="p">.</span><span class="nn">Obj</span><span class="p">.</span><span class="n">t</span>
</code></pre></div>

<p>Compute the log-likelihood of each sample</p>
<h2 id="parameters_11">Parameters<a class="headerlink" href="#parameters_11" title="Permanent link">&para;</a></h2>
<p>X : array, shape (n_samples, n_features)
The data</p>
<h2 id="returns_11">Returns<a class="headerlink" href="#returns_11" title="Permanent link">&para;</a></h2>
<p>ll : array, shape (n_samples,)
Log-likelihood of each sample under the current model</p>
<div class="highlight"><pre><span></span><code><span class="k">val</span> <span class="n">set_params</span> <span class="o">:</span> <span class="o">?</span><span class="n">params</span><span class="o">:(</span><span class="kt">string</span> <span class="o">*</span> <span class="nn">Py</span><span class="p">.</span><span class="nn">Object</span><span class="p">.</span><span class="n">t</span><span class="o">)</span> <span class="kt">list</span> <span class="o">-&gt;</span> <span class="o">[&gt;</span> <span class="n">tag</span><span class="o">]</span> <span class="nn">Obj</span><span class="p">.</span><span class="n">t</span> <span class="o">-&gt;</span> <span class="n">t</span>
</code></pre></div>

<p>Set the parameters of this estimator.</p>
<p>The method works on simple estimators as well as on nested objects
(such as pipelines). The latter have parameters of the form
<code>&lt;component&gt;__&lt;parameter&gt;</code> so that it's possible to update each
component of a nested object.</p>
<h2 id="parameters_12">Parameters<a class="headerlink" href="#parameters_12" title="Permanent link">&para;</a></h2>
<p>**params : dict
Estimator parameters.</p>
<h2 id="returns_12">Returns<a class="headerlink" href="#returns_12" title="Permanent link">&para;</a></h2>
<p>self : object
Estimator instance.</p>
<div class="highlight"><pre><span></span><code><span class="k">val</span> <span class="n">transform</span> <span class="o">:</span> <span class="n">x</span><span class="o">:[&gt;`</span><span class="nc">ArrayLike</span><span class="o">]</span> <span class="nn">Np</span><span class="p">.</span><span class="nn">Obj</span><span class="p">.</span><span class="n">t</span> <span class="o">-&gt;</span> <span class="o">[&gt;</span> <span class="n">tag</span><span class="o">]</span> <span class="nn">Obj</span><span class="p">.</span><span class="n">t</span> <span class="o">-&gt;</span> <span class="o">[&gt;`</span><span class="nc">ArrayLike</span><span class="o">]</span> <span class="nn">Np</span><span class="p">.</span><span class="nn">Obj</span><span class="p">.</span><span class="n">t</span>
</code></pre></div>

<p>Apply dimensionality reduction to X using the model.</p>
<p>Compute the expected mean of the latent variables.
See Barber, 21.2.33 (or Bishop, 12.66).</p>
<h2 id="parameters_13">Parameters<a class="headerlink" href="#parameters_13" title="Permanent link">&para;</a></h2>
<p>X : array-like, shape (n_samples, n_features)
Training data.</p>
<h2 id="returns_13">Returns<a class="headerlink" href="#returns_13" title="Permanent link">&para;</a></h2>
<p>X_new : array-like, shape (n_samples, n_components)
The latent variables of X.</p>
<p>Attribute components_: get value or raise Not_found if None.</p>
<div class="highlight"><pre><span></span><code><span class="k">val</span> <span class="n">components_</span> <span class="o">:</span> <span class="n">t</span> <span class="o">-&gt;</span> <span class="o">[&gt;`</span><span class="nc">ArrayLike</span><span class="o">]</span> <span class="nn">Np</span><span class="p">.</span><span class="nn">Obj</span><span class="p">.</span><span class="n">t</span>
</code></pre></div>

<p>Attribute components_: get value as an option.</p>
<div class="highlight"><pre><span></span><code><span class="k">val</span> <span class="n">components_opt</span> <span class="o">:</span> <span class="n">t</span> <span class="o">-&gt;</span> <span class="o">([&gt;`</span><span class="nc">ArrayLike</span><span class="o">]</span> <span class="nn">Np</span><span class="p">.</span><span class="nn">Obj</span><span class="p">.</span><span class="n">t</span><span class="o">)</span> <span class="n">option</span>
</code></pre></div>

<p>Attribute loglike_: get value or raise Not_found if None.</p>
<div class="highlight"><pre><span></span><code><span class="k">val</span> <span class="n">loglike_</span> <span class="o">:</span> <span class="n">t</span> <span class="o">-&gt;</span> <span class="nn">Py</span><span class="p">.</span><span class="nn">Object</span><span class="p">.</span><span class="n">t</span>
</code></pre></div>

<p>Attribute loglike_: get value as an option.</p>
<div class="highlight"><pre><span></span><code><span class="k">val</span> <span class="n">loglike_opt</span> <span class="o">:</span> <span class="n">t</span> <span class="o">-&gt;</span> <span class="o">(</span><span class="nn">Py</span><span class="p">.</span><span class="nn">Object</span><span class="p">.</span><span class="n">t</span><span class="o">)</span> <span class="n">option</span>
</code></pre></div>

<p>Attribute noise_variance_: get value or raise Not_found if None.</p>
<div class="highlight"><pre><span></span><code><span class="k">val</span> <span class="n">noise_variance_</span> <span class="o">:</span> <span class="n">t</span> <span class="o">-&gt;</span> <span class="o">[&gt;`</span><span class="nc">ArrayLike</span><span class="o">]</span> <span class="nn">Np</span><span class="p">.</span><span class="nn">Obj</span><span class="p">.</span><span class="n">t</span>
</code></pre></div>

<p>Attribute noise_variance_: get value as an option.</p>
<div class="highlight"><pre><span></span><code><span class="k">val</span> <span class="n">noise_variance_opt</span> <span class="o">:</span> <span class="n">t</span> <span class="o">-&gt;</span> <span class="o">([&gt;`</span><span class="nc">ArrayLike</span><span class="o">]</span> <span class="nn">Np</span><span class="p">.</span><span class="nn">Obj</span><span class="p">.</span><span class="n">t</span><span class="o">)</span> <span class="n">option</span>
</code></pre></div>

<p>Attribute n_iter_: get value or raise Not_found if None.</p>
<div class="highlight"><pre><span></span><code><span class="k">val</span> <span class="n">n_iter_</span> <span class="o">:</span> <span class="n">t</span> <span class="o">-&gt;</span> <span class="kt">int</span>
</code></pre></div>

<p>Attribute n_iter_: get value as an option.</p>
<div class="highlight"><pre><span></span><code><span class="k">val</span> <span class="n">n_iter_opt</span> <span class="o">:</span> <span class="n">t</span> <span class="o">-&gt;</span> <span class="o">(</span><span class="kt">int</span><span class="o">)</span> <span class="n">option</span>
</code></pre></div>

<p>Attribute mean_: get value or raise Not_found if None.</p>
<div class="highlight"><pre><span></span><code><span class="k">val</span> <span class="n">mean_</span> <span class="o">:</span> <span class="n">t</span> <span class="o">-&gt;</span> <span class="o">[&gt;`</span><span class="nc">ArrayLike</span><span class="o">]</span> <span class="nn">Np</span><span class="p">.</span><span class="nn">Obj</span><span class="p">.</span><span class="n">t</span>
</code></pre></div>

<p>Attribute mean_: get value as an option.</p>
<div class="highlight"><pre><span></span><code><span class="k">val</span> <span class="n">mean_opt</span> <span class="o">:</span> <span class="n">t</span> <span class="o">-&gt;</span> <span class="o">([&gt;`</span><span class="nc">ArrayLike</span><span class="o">]</span> <span class="nn">Np</span><span class="p">.</span><span class="nn">Obj</span><span class="p">.</span><span class="n">t</span><span class="o">)</span> <span class="n">option</span>
</code></pre></div>

<p>Print the object to a human-readable representation.</p>
<div class="highlight"><pre><span></span><code><span class="k">val</span> <span class="n">to_string</span> <span class="o">:</span> <span class="n">t</span> <span class="o">-&gt;</span> <span class="kt">string</span>
</code></pre></div>

<p>Print the object to a human-readable representation.</p>
<div class="highlight"><pre><span></span><code><span class="k">val</span> <span class="n">show</span> <span class="o">:</span> <span class="n">t</span> <span class="o">-&gt;</span> <span class="kt">string</span>
</code></pre></div>

<p>Pretty-print the object to a formatter.</p>
<div class="highlight"><pre><span></span><code><span class="k">val</span> <span class="n">pp</span> <span class="o">:</span> <span class="nn">Format</span><span class="p">.</span><span class="n">formatter</span> <span class="o">-&gt;</span> <span class="n">t</span> <span class="o">-&gt;</span> <span class="kt">unit</span> <span class="o">[@@</span><span class="n">ocaml</span><span class="o">.</span><span class="n">toplevel_printer</span><span class="o">]</span>



<span class="k">module</span> <span class="nc">FastICA</span> <span class="o">:</span> <span class="k">sig</span>
<span class="k">type</span> <span class="n">tag</span> <span class="o">=</span> <span class="o">[`</span><span class="nc">FastICA</span><span class="o">]</span>
<span class="k">type</span> <span class="n">t</span> <span class="o">=</span> <span class="o">[`</span><span class="nc">BaseEstimator</span> <span class="o">|</span> <span class="o">`</span><span class="nc">FastICA</span> <span class="o">|</span> <span class="o">`</span><span class="nc">Object</span> <span class="o">|</span> <span class="o">`</span><span class="nc">TransformerMixin</span><span class="o">]</span> <span class="nn">Obj</span><span class="p">.</span><span class="n">t</span>
<span class="k">val</span> <span class="n">of_pyobject</span> <span class="o">:</span> <span class="nn">Py</span><span class="p">.</span><span class="nn">Object</span><span class="p">.</span><span class="n">t</span> <span class="o">-&gt;</span> <span class="n">t</span>
<span class="k">val</span> <span class="n">to_pyobject</span> <span class="o">:</span> <span class="o">[&gt;</span> <span class="n">tag</span><span class="o">]</span> <span class="nn">Obj</span><span class="p">.</span><span class="n">t</span> <span class="o">-&gt;</span> <span class="nn">Py</span><span class="p">.</span><span class="nn">Object</span><span class="p">.</span><span class="n">t</span>

<span class="k">val</span> <span class="n">as_transformer</span> <span class="o">:</span> <span class="n">t</span> <span class="o">-&gt;</span> <span class="o">[`</span><span class="nc">TransformerMixin</span><span class="o">]</span> <span class="nn">Obj</span><span class="p">.</span><span class="n">t</span>
<span class="k">val</span> <span class="n">as_estimator</span> <span class="o">:</span> <span class="n">t</span> <span class="o">-&gt;</span> <span class="o">[`</span><span class="nc">BaseEstimator</span><span class="o">]</span> <span class="nn">Obj</span><span class="p">.</span><span class="n">t</span>
<span class="k">val</span> <span class="n">create</span> <span class="o">:</span> <span class="o">?</span><span class="n">n_components</span><span class="o">:</span><span class="kt">int</span> <span class="o">-&gt;</span> <span class="o">?</span><span class="n">algorithm</span><span class="o">:[`</span><span class="nc">Parallel</span> <span class="o">|</span> <span class="o">`</span><span class="nc">Deflation</span><span class="o">]</span> <span class="o">-&gt;</span> <span class="o">?</span><span class="n">whiten</span><span class="o">:</span><span class="kt">bool</span> <span class="o">-&gt;</span> <span class="o">?</span><span class="n">fun_</span><span class="o">:[`</span><span class="nc">Callable</span> <span class="k">of</span> <span class="nn">Py</span><span class="p">.</span><span class="nn">Object</span><span class="p">.</span><span class="n">t</span> <span class="o">|</span> <span class="o">`</span><span class="nc">S</span> <span class="k">of</span> <span class="kt">string</span><span class="o">]</span> <span class="o">-&gt;</span> <span class="o">?</span><span class="n">fun_args</span><span class="o">:</span><span class="nn">Dict</span><span class="p">.</span><span class="n">t</span> <span class="o">-&gt;</span> <span class="o">?</span><span class="n">max_iter</span><span class="o">:</span><span class="kt">int</span> <span class="o">-&gt;</span> <span class="o">?</span><span class="n">tol</span><span class="o">:</span><span class="kt">float</span> <span class="o">-&gt;</span> <span class="o">?</span><span class="n">w_init</span><span class="o">:</span><span class="nn">Py</span><span class="p">.</span><span class="nn">Object</span><span class="p">.</span><span class="n">t</span> <span class="o">-&gt;</span> <span class="o">?</span><span class="n">random_state</span><span class="o">:</span><span class="kt">int</span> <span class="o">-&gt;</span> <span class="kt">unit</span> <span class="o">-&gt;</span> <span class="n">t</span>
</code></pre></div>

<p>FastICA: a fast algorithm for Independent Component Analysis.</p>
<p>Read more in the :ref:<code>User Guide &lt;ICA&gt;</code>.</p>
<h2 id="parameters_14">Parameters<a class="headerlink" href="#parameters_14" title="Permanent link">&para;</a></h2>
<p>n_components : int, optional
Number of components to use. If none is passed, all are used.</p>
<p>algorithm : {'parallel', 'deflation'}
Apply parallel or deflational algorithm for FastICA.</p>
<p>whiten : boolean, optional
If whiten is false, the data is already considered to be
whitened, and no whitening is performed.</p>
<p>fun : string or function, optional. Default: 'logcosh'
The functional form of the G function used in the
approximation to neg-entropy. Could be either 'logcosh', 'exp',
or 'cube'.
You can also provide your own function. It should return a tuple
containing the value of the function, and of its derivative, in the
point. Example:</p>
<p>def my_g(x):
return x <strong> 3, (3 * x </strong> 2).mean(axis=-1)</p>
<p>fun_args : dictionary, optional
Arguments to send to the functional form.
If empty and if fun='logcosh', fun_args will take value
{'alpha' : 1.0}.</p>
<p>max_iter : int, optional
Maximum number of iterations during fit.</p>
<p>tol : float, optional
Tolerance on update at each iteration.</p>
<p>w_init : None of an (n_components, n_components) ndarray
The mixing matrix to be used to initialize the algorithm.</p>
<p>random_state : int, RandomState instance or None, optional (default=None)
If int, random_state is the seed used by the random number generator;
If RandomState instance, random_state is the random number generator;
If None, the random number generator is the RandomState instance used
by <code>np.random</code>.</p>
<h2 id="attributes_2">Attributes<a class="headerlink" href="#attributes_2" title="Permanent link">&para;</a></h2>
<p>components_ : 2D array, shape (n_components, n_features)
The linear operator to apply to the data to get the independent
sources. This is equal to the unmixing matrix when <code>whiten</code> is
False, and equal to <code>np.dot(unmixing_matrix, self.whitening_)</code> when
<code>whiten</code> is True.</p>
<p>mixing_ : array, shape (n_features, n_components)
The pseudo-inverse of <code>components_</code>. It is the linear operator
that maps independent sources to the data.</p>
<p>mean_ : array, shape(n_features)
The mean over features. Only set if <code>self.whiten</code> is True.</p>
<p>n_iter_ : int
If the algorithm is 'deflation', n_iter is the
maximum number of iterations run across all components. Else
they are just the number of iterations taken to converge.</p>
<p>whitening_ : array, shape (n_components, n_features)
Only set if whiten is 'True'. This is the pre-whitening matrix
that projects data onto the first <code>n_components</code> principal components.</p>
<h2 id="examples_1">Examples<a class="headerlink" href="#examples_1" title="Permanent link">&para;</a></h2>
<blockquote>
<blockquote>
<blockquote>
<p>from sklearn.datasets import load_digits
from sklearn.decomposition import FastICA
X, _ = load_digits(return_X_y=True)
transformer = FastICA(n_components=7,
...         random_state=0)
X_transformed = transformer.fit_transform(X)
X_transformed.shape
(1797, 7)</p>
</blockquote>
</blockquote>
</blockquote>
<h2 id="notes_1">Notes<a class="headerlink" href="#notes_1" title="Permanent link">&para;</a></h2>
<p>Implementation based on
<em>A. Hyvarinen and E. Oja, Independent Component Analysis:
Algorithms and Applications, Neural Networks, 13(4-5), 2000,
pp. 411-430</em></p>
<div class="highlight"><pre><span></span><code><span class="k">val</span> <span class="n">fit</span> <span class="o">:</span> <span class="o">?</span><span class="n">y</span><span class="o">:</span><span class="nn">Py</span><span class="p">.</span><span class="nn">Object</span><span class="p">.</span><span class="n">t</span> <span class="o">-&gt;</span> <span class="n">x</span><span class="o">:[&gt;`</span><span class="nc">ArrayLike</span><span class="o">]</span> <span class="nn">Np</span><span class="p">.</span><span class="nn">Obj</span><span class="p">.</span><span class="n">t</span> <span class="o">-&gt;</span> <span class="o">[&gt;</span> <span class="n">tag</span><span class="o">]</span> <span class="nn">Obj</span><span class="p">.</span><span class="n">t</span> <span class="o">-&gt;</span> <span class="n">t</span>
</code></pre></div>

<p>Fit the model to X.</p>
<h2 id="parameters_15">Parameters<a class="headerlink" href="#parameters_15" title="Permanent link">&para;</a></h2>
<p>X : array-like, shape (n_samples, n_features)
Training data, where n_samples is the number of samples
and n_features is the number of features.</p>
<p>y : Ignored</p>
<h2 id="returns_14">Returns<a class="headerlink" href="#returns_14" title="Permanent link">&para;</a></h2>
<p>self</p>
<div class="highlight"><pre><span></span><code><span class="k">val</span> <span class="n">fit_transform</span> <span class="o">:</span> <span class="o">?</span><span class="n">y</span><span class="o">:</span><span class="nn">Py</span><span class="p">.</span><span class="nn">Object</span><span class="p">.</span><span class="n">t</span> <span class="o">-&gt;</span> <span class="n">x</span><span class="o">:[&gt;`</span><span class="nc">ArrayLike</span><span class="o">]</span> <span class="nn">Np</span><span class="p">.</span><span class="nn">Obj</span><span class="p">.</span><span class="n">t</span> <span class="o">-&gt;</span> <span class="o">[&gt;</span> <span class="n">tag</span><span class="o">]</span> <span class="nn">Obj</span><span class="p">.</span><span class="n">t</span> <span class="o">-&gt;</span> <span class="o">[&gt;`</span><span class="nc">ArrayLike</span><span class="o">]</span> <span class="nn">Np</span><span class="p">.</span><span class="nn">Obj</span><span class="p">.</span><span class="n">t</span>
</code></pre></div>

<p>Fit the model and recover the sources from X.</p>
<h2 id="parameters_16">Parameters<a class="headerlink" href="#parameters_16" title="Permanent link">&para;</a></h2>
<p>X : array-like, shape (n_samples, n_features)
Training data, where n_samples is the number of samples
and n_features is the number of features.</p>
<p>y : Ignored</p>
<h2 id="returns_15">Returns<a class="headerlink" href="#returns_15" title="Permanent link">&para;</a></h2>
<p>X_new : array-like, shape (n_samples, n_components)</p>
<div class="highlight"><pre><span></span><code><span class="k">val</span> <span class="n">get_params</span> <span class="o">:</span> <span class="o">?</span><span class="n">deep</span><span class="o">:</span><span class="kt">bool</span> <span class="o">-&gt;</span> <span class="o">[&gt;</span> <span class="n">tag</span><span class="o">]</span> <span class="nn">Obj</span><span class="p">.</span><span class="n">t</span> <span class="o">-&gt;</span> <span class="nn">Dict</span><span class="p">.</span><span class="n">t</span>
</code></pre></div>

<p>Get parameters for this estimator.</p>
<h2 id="parameters_17">Parameters<a class="headerlink" href="#parameters_17" title="Permanent link">&para;</a></h2>
<p>deep : bool, default=True
If True, will return the parameters for this estimator and
contained subobjects that are estimators.</p>
<h2 id="returns_16">Returns<a class="headerlink" href="#returns_16" title="Permanent link">&para;</a></h2>
<p>params : mapping of string to any
Parameter names mapped to their values.</p>
<div class="highlight"><pre><span></span><code><span class="k">val</span> <span class="n">inverse_transform</span> <span class="o">:</span> <span class="o">?</span><span class="n">copy</span><span class="o">:</span><span class="kt">bool</span> <span class="o">-&gt;</span> <span class="n">x</span><span class="o">:[&gt;`</span><span class="nc">ArrayLike</span><span class="o">]</span> <span class="nn">Np</span><span class="p">.</span><span class="nn">Obj</span><span class="p">.</span><span class="n">t</span> <span class="o">-&gt;</span> <span class="o">[&gt;</span> <span class="n">tag</span><span class="o">]</span> <span class="nn">Obj</span><span class="p">.</span><span class="n">t</span> <span class="o">-&gt;</span> <span class="o">[&gt;`</span><span class="nc">ArrayLike</span><span class="o">]</span> <span class="nn">Np</span><span class="p">.</span><span class="nn">Obj</span><span class="p">.</span><span class="n">t</span>
</code></pre></div>

<p>Transform the sources back to the mixed data (apply mixing matrix).</p>
<h2 id="parameters_18">Parameters<a class="headerlink" href="#parameters_18" title="Permanent link">&para;</a></h2>
<p>X : array-like, shape (n_samples, n_components)
Sources, where n_samples is the number of samples
and n_components is the number of components.
copy : bool (optional)
If False, data passed to fit are overwritten. Defaults to True.</p>
<h2 id="returns_17">Returns<a class="headerlink" href="#returns_17" title="Permanent link">&para;</a></h2>
<p>X_new : array-like, shape (n_samples, n_features)</p>
<div class="highlight"><pre><span></span><code><span class="k">val</span> <span class="n">set_params</span> <span class="o">:</span> <span class="o">?</span><span class="n">params</span><span class="o">:(</span><span class="kt">string</span> <span class="o">*</span> <span class="nn">Py</span><span class="p">.</span><span class="nn">Object</span><span class="p">.</span><span class="n">t</span><span class="o">)</span> <span class="kt">list</span> <span class="o">-&gt;</span> <span class="o">[&gt;</span> <span class="n">tag</span><span class="o">]</span> <span class="nn">Obj</span><span class="p">.</span><span class="n">t</span> <span class="o">-&gt;</span> <span class="n">t</span>
</code></pre></div>

<p>Set the parameters of this estimator.</p>
<p>The method works on simple estimators as well as on nested objects
(such as pipelines). The latter have parameters of the form
<code>&lt;component&gt;__&lt;parameter&gt;</code> so that it's possible to update each
component of a nested object.</p>
<h2 id="parameters_19">Parameters<a class="headerlink" href="#parameters_19" title="Permanent link">&para;</a></h2>
<p>**params : dict
Estimator parameters.</p>
<h2 id="returns_18">Returns<a class="headerlink" href="#returns_18" title="Permanent link">&para;</a></h2>
<p>self : object
Estimator instance.</p>
<div class="highlight"><pre><span></span><code><span class="k">val</span> <span class="n">transform</span> <span class="o">:</span> <span class="o">?</span><span class="n">copy</span><span class="o">:</span><span class="kt">bool</span> <span class="o">-&gt;</span> <span class="n">x</span><span class="o">:[&gt;`</span><span class="nc">ArrayLike</span><span class="o">]</span> <span class="nn">Np</span><span class="p">.</span><span class="nn">Obj</span><span class="p">.</span><span class="n">t</span> <span class="o">-&gt;</span> <span class="o">[&gt;</span> <span class="n">tag</span><span class="o">]</span> <span class="nn">Obj</span><span class="p">.</span><span class="n">t</span> <span class="o">-&gt;</span> <span class="o">[&gt;`</span><span class="nc">ArrayLike</span><span class="o">]</span> <span class="nn">Np</span><span class="p">.</span><span class="nn">Obj</span><span class="p">.</span><span class="n">t</span>
</code></pre></div>

<p>Recover the sources from X (apply the unmixing matrix).</p>
<h2 id="parameters_20">Parameters<a class="headerlink" href="#parameters_20" title="Permanent link">&para;</a></h2>
<p>X : array-like, shape (n_samples, n_features)
Data to transform, where n_samples is the number of samples
and n_features is the number of features.</p>
<p>copy : bool (optional)
If False, data passed to fit are overwritten. Defaults to True.</p>
<h2 id="returns_19">Returns<a class="headerlink" href="#returns_19" title="Permanent link">&para;</a></h2>
<p>X_new : array-like, shape (n_samples, n_components)</p>
<p>Attribute components_: get value or raise Not_found if None.</p>
<div class="highlight"><pre><span></span><code><span class="k">val</span> <span class="n">components_</span> <span class="o">:</span> <span class="n">t</span> <span class="o">-&gt;</span> <span class="o">[&gt;`</span><span class="nc">ArrayLike</span><span class="o">]</span> <span class="nn">Np</span><span class="p">.</span><span class="nn">Obj</span><span class="p">.</span><span class="n">t</span>
</code></pre></div>

<p>Attribute components_: get value as an option.</p>
<div class="highlight"><pre><span></span><code><span class="k">val</span> <span class="n">components_opt</span> <span class="o">:</span> <span class="n">t</span> <span class="o">-&gt;</span> <span class="o">([&gt;`</span><span class="nc">ArrayLike</span><span class="o">]</span> <span class="nn">Np</span><span class="p">.</span><span class="nn">Obj</span><span class="p">.</span><span class="n">t</span><span class="o">)</span> <span class="n">option</span>
</code></pre></div>

<p>Attribute mixing_: get value or raise Not_found if None.</p>
<div class="highlight"><pre><span></span><code><span class="k">val</span> <span class="n">mixing_</span> <span class="o">:</span> <span class="n">t</span> <span class="o">-&gt;</span> <span class="o">[&gt;`</span><span class="nc">ArrayLike</span><span class="o">]</span> <span class="nn">Np</span><span class="p">.</span><span class="nn">Obj</span><span class="p">.</span><span class="n">t</span>
</code></pre></div>

<p>Attribute mixing_: get value as an option.</p>
<div class="highlight"><pre><span></span><code><span class="k">val</span> <span class="n">mixing_opt</span> <span class="o">:</span> <span class="n">t</span> <span class="o">-&gt;</span> <span class="o">([&gt;`</span><span class="nc">ArrayLike</span><span class="o">]</span> <span class="nn">Np</span><span class="p">.</span><span class="nn">Obj</span><span class="p">.</span><span class="n">t</span><span class="o">)</span> <span class="n">option</span>
</code></pre></div>

<p>Attribute mean_: get value or raise Not_found if None.</p>
<div class="highlight"><pre><span></span><code><span class="k">val</span> <span class="n">mean_</span> <span class="o">:</span> <span class="n">t</span> <span class="o">-&gt;</span> <span class="o">[&gt;`</span><span class="nc">ArrayLike</span><span class="o">]</span> <span class="nn">Np</span><span class="p">.</span><span class="nn">Obj</span><span class="p">.</span><span class="n">t</span>
</code></pre></div>

<p>Attribute mean_: get value as an option.</p>
<div class="highlight"><pre><span></span><code><span class="k">val</span> <span class="n">mean_opt</span> <span class="o">:</span> <span class="n">t</span> <span class="o">-&gt;</span> <span class="o">([&gt;`</span><span class="nc">ArrayLike</span><span class="o">]</span> <span class="nn">Np</span><span class="p">.</span><span class="nn">Obj</span><span class="p">.</span><span class="n">t</span><span class="o">)</span> <span class="n">option</span>
</code></pre></div>

<p>Attribute n_iter_: get value or raise Not_found if None.</p>
<div class="highlight"><pre><span></span><code><span class="k">val</span> <span class="n">n_iter_</span> <span class="o">:</span> <span class="n">t</span> <span class="o">-&gt;</span> <span class="kt">int</span>
</code></pre></div>

<p>Attribute n_iter_: get value as an option.</p>
<div class="highlight"><pre><span></span><code><span class="k">val</span> <span class="n">n_iter_opt</span> <span class="o">:</span> <span class="n">t</span> <span class="o">-&gt;</span> <span class="o">(</span><span class="kt">int</span><span class="o">)</span> <span class="n">option</span>
</code></pre></div>

<p>Attribute whitening_: get value or raise Not_found if None.</p>
<div class="highlight"><pre><span></span><code><span class="k">val</span> <span class="n">whitening_</span> <span class="o">:</span> <span class="n">t</span> <span class="o">-&gt;</span> <span class="o">[&gt;`</span><span class="nc">ArrayLike</span><span class="o">]</span> <span class="nn">Np</span><span class="p">.</span><span class="nn">Obj</span><span class="p">.</span><span class="n">t</span>
</code></pre></div>

<p>Attribute whitening_: get value as an option.</p>
<div class="highlight"><pre><span></span><code><span class="k">val</span> <span class="n">whitening_opt</span> <span class="o">:</span> <span class="n">t</span> <span class="o">-&gt;</span> <span class="o">([&gt;`</span><span class="nc">ArrayLike</span><span class="o">]</span> <span class="nn">Np</span><span class="p">.</span><span class="nn">Obj</span><span class="p">.</span><span class="n">t</span><span class="o">)</span> <span class="n">option</span>
</code></pre></div>

<p>Print the object to a human-readable representation.</p>
<div class="highlight"><pre><span></span><code><span class="k">val</span> <span class="n">to_string</span> <span class="o">:</span> <span class="n">t</span> <span class="o">-&gt;</span> <span class="kt">string</span>
</code></pre></div>

<p>Print the object to a human-readable representation.</p>
<div class="highlight"><pre><span></span><code><span class="k">val</span> <span class="n">show</span> <span class="o">:</span> <span class="n">t</span> <span class="o">-&gt;</span> <span class="kt">string</span>
</code></pre></div>

<p>Pretty-print the object to a formatter.</p>
<div class="highlight"><pre><span></span><code><span class="k">val</span> <span class="n">pp</span> <span class="o">:</span> <span class="nn">Format</span><span class="p">.</span><span class="n">formatter</span> <span class="o">-&gt;</span> <span class="n">t</span> <span class="o">-&gt;</span> <span class="kt">unit</span> <span class="o">[@@</span><span class="n">ocaml</span><span class="o">.</span><span class="n">toplevel_printer</span><span class="o">]</span>



<span class="k">module</span> <span class="nc">IncrementalPCA</span> <span class="o">:</span> <span class="k">sig</span>
<span class="k">type</span> <span class="n">tag</span> <span class="o">=</span> <span class="o">[`</span><span class="nc">IncrementalPCA</span><span class="o">]</span>
<span class="k">type</span> <span class="n">t</span> <span class="o">=</span> <span class="o">[`</span><span class="nc">BaseEstimator</span> <span class="o">|</span> <span class="o">`</span><span class="nc">IncrementalPCA</span> <span class="o">|</span> <span class="o">`</span><span class="nc">Object</span> <span class="o">|</span> <span class="o">`</span><span class="nc">TransformerMixin</span><span class="o">]</span> <span class="nn">Obj</span><span class="p">.</span><span class="n">t</span>
<span class="k">val</span> <span class="n">of_pyobject</span> <span class="o">:</span> <span class="nn">Py</span><span class="p">.</span><span class="nn">Object</span><span class="p">.</span><span class="n">t</span> <span class="o">-&gt;</span> <span class="n">t</span>
<span class="k">val</span> <span class="n">to_pyobject</span> <span class="o">:</span> <span class="o">[&gt;</span> <span class="n">tag</span><span class="o">]</span> <span class="nn">Obj</span><span class="p">.</span><span class="n">t</span> <span class="o">-&gt;</span> <span class="nn">Py</span><span class="p">.</span><span class="nn">Object</span><span class="p">.</span><span class="n">t</span>

<span class="k">val</span> <span class="n">as_transformer</span> <span class="o">:</span> <span class="n">t</span> <span class="o">-&gt;</span> <span class="o">[`</span><span class="nc">TransformerMixin</span><span class="o">]</span> <span class="nn">Obj</span><span class="p">.</span><span class="n">t</span>
<span class="k">val</span> <span class="n">as_estimator</span> <span class="o">:</span> <span class="n">t</span> <span class="o">-&gt;</span> <span class="o">[`</span><span class="nc">BaseEstimator</span><span class="o">]</span> <span class="nn">Obj</span><span class="p">.</span><span class="n">t</span>
<span class="k">val</span> <span class="n">create</span> <span class="o">:</span> <span class="o">?</span><span class="n">n_components</span><span class="o">:</span><span class="kt">int</span> <span class="o">-&gt;</span> <span class="o">?</span><span class="n">whiten</span><span class="o">:</span><span class="kt">bool</span> <span class="o">-&gt;</span> <span class="o">?</span><span class="n">copy</span><span class="o">:</span><span class="kt">bool</span> <span class="o">-&gt;</span> <span class="o">?</span><span class="n">batch_size</span><span class="o">:</span><span class="kt">int</span> <span class="o">-&gt;</span> <span class="kt">unit</span> <span class="o">-&gt;</span> <span class="n">t</span>
</code></pre></div>

<p>Incremental principal components analysis (IPCA).</p>
<p>Linear dimensionality reduction using Singular Value Decomposition of
the data, keeping only the most significant singular vectors to
project the data to a lower dimensional space. The input data is centered
but not scaled for each feature before applying the SVD.</p>
<p>Depending on the size of the input data, this algorithm can be much more
memory efficient than a PCA, and allows sparse input.</p>
<p>This algorithm has constant memory complexity, on the order
of <code>batch_size * n_features</code>, enabling use of np.memmap files without
loading the entire file into memory. For sparse matrices, the input
is converted to dense in batches (in order to be able to subtract the
mean) which avoids storing the entire dense matrix at any one time.</p>
<p>The computational overhead of each SVD is
<code>O(batch_size * n_features ** 2)</code>, but only 2 * batch_size samples
remain in memory at a time. There will be <code>n_samples / batch_size</code> SVD
computations to get the principal components, versus 1 large SVD of
complexity <code>O(n_samples * n_features ** 2)</code> for PCA.</p>
<p>Read more in the :ref:<code>User Guide &lt;IncrementalPCA&gt;</code>.</p>
<p>.. versionadded:: 0.16</p>
<h2 id="parameters_21">Parameters<a class="headerlink" href="#parameters_21" title="Permanent link">&para;</a></h2>
<p>n_components : int or None, (default=None)
Number of components to keep. If <code>n_components</code> is <code>None</code>,
then <code>n_components</code> is set to <code>min(n_samples, n_features)</code>.</p>
<p>whiten : bool, optional
When True (False by default) the <code>components_</code> vectors are divided
by <code>n_samples</code> times <code>components_</code> to ensure uncorrelated outputs
with unit component-wise variances.</p>
<p>Whitening will remove some information from the transformed signal
(the relative variance scales of the components) but can sometimes
improve the predictive accuracy of the downstream estimators by
making data respect some hard-wired assumptions.</p>
<p>copy : bool, (default=True)
If False, X will be overwritten. <code>copy=False</code> can be used to
save memory but is unsafe for general use.</p>
<p>batch_size : int or None, (default=None)
The number of samples to use for each batch. Only used when calling
<code>fit</code>. If <code>batch_size</code> is <code>None</code>, then <code>batch_size</code>
is inferred from the data and set to <code>5 * n_features</code>, to provide a
balance between approximation accuracy and memory consumption.</p>
<h2 id="attributes_3">Attributes<a class="headerlink" href="#attributes_3" title="Permanent link">&para;</a></h2>
<p>components_ : array, shape (n_components, n_features)
Components with maximum variance.</p>
<p>explained_variance_ : array, shape (n_components,)
Variance explained by each of the selected components.</p>
<p>explained_variance_ratio_ : array, shape (n_components,)
Percentage of variance explained by each of the selected components.
If all components are stored, the sum of explained variances is equal
to 1.0.</p>
<p>singular_values_ : array, shape (n_components,)
The singular values corresponding to each of the selected components.
The singular values are equal to the 2-norms of the <code>n_components</code>
variables in the lower-dimensional space.</p>
<p>mean_ : array, shape (n_features,)
Per-feature empirical mean, aggregate over calls to <code>partial_fit</code>.</p>
<p>var_ : array, shape (n_features,)
Per-feature empirical variance, aggregate over calls to
<code>partial_fit</code>.</p>
<p>noise_variance_ : float
The estimated noise covariance following the Probabilistic PCA model
from Tipping and Bishop 1999. See 'Pattern Recognition and
Machine Learning' by C. Bishop, 12.2.1 p. 574 or
http://www.miketipping.com/papers/met-mppca.pdf.</p>
<p>n_components_ : int
The estimated number of components. Relevant when
<code>n_components=None</code>.</p>
<p>n_samples_seen_ : int
The number of samples processed by the estimator. Will be reset on
new calls to fit, but increments across <code>partial_fit</code> calls.</p>
<h2 id="examples_2">Examples<a class="headerlink" href="#examples_2" title="Permanent link">&para;</a></h2>
<blockquote>
<blockquote>
<blockquote>
<p>from sklearn.datasets import load_digits
from sklearn.decomposition import IncrementalPCA
from scipy import sparse
X, _ = load_digits(return_X_y=True)
transformer = IncrementalPCA(n_components=7, batch_size=200)</p>
<h1 id="either-partially-fit-on-smaller-batches-of-data">either partially fit on smaller batches of data<a class="headerlink" href="#either-partially-fit-on-smaller-batches-of-data" title="Permanent link">&para;</a></h1>
<p>transformer.partial_fit(X[:100, :])
IncrementalPCA(batch_size=200, n_components=7)</p>
<h1 id="or-let-the-fit-function-itself-divide-the-data-into-batches">or let the fit function itself divide the data into batches<a class="headerlink" href="#or-let-the-fit-function-itself-divide-the-data-into-batches" title="Permanent link">&para;</a></h1>
<p>X_sparse = sparse.csr_matrix(X)
X_transformed = transformer.fit_transform(X_sparse)
X_transformed.shape
(1797, 7)</p>
</blockquote>
</blockquote>
</blockquote>
<h2 id="notes_2">Notes<a class="headerlink" href="#notes_2" title="Permanent link">&para;</a></h2>
<p>Implements the incremental PCA model from:
<em>D. Ross, J. Lim, R. Lin, M. Yang, Incremental Learning for Robust Visual
Tracking, International Journal of Computer Vision, Volume 77, Issue 1-3,
pp. 125-141, May 2008.</em>
See https://www.cs.toronto.edu/~dross/ivt/RossLimLinYang_ijcv.pdf</p>
<p>This model is an extension of the Sequential Karhunen-Loeve Transform from:
<em>A. Levy and M. Lindenbaum, Sequential Karhunen-Loeve Basis Extraction and
its Application to Images, IEEE Transactions on Image Processing, Volume 9,
Number 8, pp. 1371-1374, August 2000.</em>
See https://www.cs.technion.ac.il/~mic/doc/skl-ip.pdf</p>
<p>We have specifically abstained from an optimization used by authors of both
papers, a QR decomposition used in specific situations to reduce the
algorithmic complexity of the SVD. The source for this technique is
<em>Matrix Computations, Third Edition, G. Holub and C. Van Loan, Chapter 5,
section 5.4.4, pp 252-253.</em>. This technique has been omitted because it is
advantageous only when decomposing a matrix with <code>n_samples</code> (rows)</p>
<blockquote>
<p>= 5/3 * <code>n_features</code> (columns), and hurts the readability of the
implemented algorithm. This would be a good opportunity for future
optimization, if it is deemed necessary.</p>
</blockquote>
<h2 id="references_1">References<a class="headerlink" href="#references_1" title="Permanent link">&para;</a></h2>
<p>D. Ross, J. Lim, R. Lin, M. Yang. Incremental Learning for Robust Visual
Tracking, International Journal of Computer Vision, Volume 77,
Issue 1-3, pp. 125-141, May 2008.</p>
<p>G. Golub and C. Van Loan. Matrix Computations, Third Edition, Chapter 5,
Section 5.4.4, pp. 252-253.</p>
<h2 id="see-also_2">See also<a class="headerlink" href="#see-also_2" title="Permanent link">&para;</a></h2>
<p>PCA
KernelPCA
SparsePCA
TruncatedSVD</p>
<div class="highlight"><pre><span></span><code><span class="k">val</span> <span class="n">fit</span> <span class="o">:</span> <span class="o">?</span><span class="n">y</span><span class="o">:</span><span class="nn">Py</span><span class="p">.</span><span class="nn">Object</span><span class="p">.</span><span class="n">t</span> <span class="o">-&gt;</span> <span class="n">x</span><span class="o">:[&gt;`</span><span class="nc">ArrayLike</span><span class="o">]</span> <span class="nn">Np</span><span class="p">.</span><span class="nn">Obj</span><span class="p">.</span><span class="n">t</span> <span class="o">-&gt;</span> <span class="o">[&gt;</span> <span class="n">tag</span><span class="o">]</span> <span class="nn">Obj</span><span class="p">.</span><span class="n">t</span> <span class="o">-&gt;</span> <span class="n">t</span>
</code></pre></div>

<p>Fit the model with X, using minibatches of size batch_size.</p>
<h2 id="parameters_22">Parameters<a class="headerlink" href="#parameters_22" title="Permanent link">&para;</a></h2>
<p>X : array-like or sparse matrix, shape (n_samples, n_features)
Training data, where n_samples is the number of samples and
n_features is the number of features.</p>
<p>y : Ignored</p>
<h2 id="returns_20">Returns<a class="headerlink" href="#returns_20" title="Permanent link">&para;</a></h2>
<p>self : object
Returns the instance itself.</p>
<div class="highlight"><pre><span></span><code><span class="k">val</span> <span class="n">fit_transform</span> <span class="o">:</span> <span class="o">?</span><span class="n">y</span><span class="o">:[&gt;`</span><span class="nc">ArrayLike</span><span class="o">]</span> <span class="nn">Np</span><span class="p">.</span><span class="nn">Obj</span><span class="p">.</span><span class="n">t</span> <span class="o">-&gt;</span> <span class="o">?</span><span class="n">fit_params</span><span class="o">:(</span><span class="kt">string</span> <span class="o">*</span> <span class="nn">Py</span><span class="p">.</span><span class="nn">Object</span><span class="p">.</span><span class="n">t</span><span class="o">)</span> <span class="kt">list</span> <span class="o">-&gt;</span> <span class="n">x</span><span class="o">:[&gt;`</span><span class="nc">ArrayLike</span><span class="o">]</span> <span class="nn">Np</span><span class="p">.</span><span class="nn">Obj</span><span class="p">.</span><span class="n">t</span> <span class="o">-&gt;</span> <span class="o">[&gt;</span> <span class="n">tag</span><span class="o">]</span> <span class="nn">Obj</span><span class="p">.</span><span class="n">t</span> <span class="o">-&gt;</span> <span class="o">[&gt;`</span><span class="nc">ArrayLike</span><span class="o">]</span> <span class="nn">Np</span><span class="p">.</span><span class="nn">Obj</span><span class="p">.</span><span class="n">t</span>
</code></pre></div>

<p>Fit to data, then transform it.</p>
<p>Fits transformer to X and y with optional parameters fit_params
and returns a transformed version of X.</p>
<h2 id="parameters_23">Parameters<a class="headerlink" href="#parameters_23" title="Permanent link">&para;</a></h2>
<p>X : numpy array of shape [n_samples, n_features]
Training set.</p>
<p>y : numpy array of shape [n_samples]
Target values.</p>
<p>**fit_params : dict
Additional fit parameters.</p>
<h2 id="returns_21">Returns<a class="headerlink" href="#returns_21" title="Permanent link">&para;</a></h2>
<p>X_new : numpy array of shape [n_samples, n_features_new]
Transformed array.</p>
<div class="highlight"><pre><span></span><code><span class="k">val</span> <span class="n">get_covariance</span> <span class="o">:</span> <span class="o">[&gt;</span> <span class="n">tag</span><span class="o">]</span> <span class="nn">Obj</span><span class="p">.</span><span class="n">t</span> <span class="o">-&gt;</span> <span class="o">[&gt;`</span><span class="nc">ArrayLike</span><span class="o">]</span> <span class="nn">Np</span><span class="p">.</span><span class="nn">Obj</span><span class="p">.</span><span class="n">t</span>
</code></pre></div>

<p>Compute data covariance with the generative model.</p>
<p><code>cov = components_.T * S**2 * components_ + sigma2 * eye(n_features)</code>
where S**2 contains the explained variances, and sigma2 contains the
noise variances.</p>
<h2 id="returns_22">Returns<a class="headerlink" href="#returns_22" title="Permanent link">&para;</a></h2>
<p>cov : array, shape=(n_features, n_features)
Estimated covariance of data.</p>
<div class="highlight"><pre><span></span><code><span class="k">val</span> <span class="n">get_params</span> <span class="o">:</span> <span class="o">?</span><span class="n">deep</span><span class="o">:</span><span class="kt">bool</span> <span class="o">-&gt;</span> <span class="o">[&gt;</span> <span class="n">tag</span><span class="o">]</span> <span class="nn">Obj</span><span class="p">.</span><span class="n">t</span> <span class="o">-&gt;</span> <span class="nn">Dict</span><span class="p">.</span><span class="n">t</span>
</code></pre></div>

<p>Get parameters for this estimator.</p>
<h2 id="parameters_24">Parameters<a class="headerlink" href="#parameters_24" title="Permanent link">&para;</a></h2>
<p>deep : bool, default=True
If True, will return the parameters for this estimator and
contained subobjects that are estimators.</p>
<h2 id="returns_23">Returns<a class="headerlink" href="#returns_23" title="Permanent link">&para;</a></h2>
<p>params : mapping of string to any
Parameter names mapped to their values.</p>
<div class="highlight"><pre><span></span><code><span class="k">val</span> <span class="n">get_precision</span> <span class="o">:</span> <span class="o">[&gt;</span> <span class="n">tag</span><span class="o">]</span> <span class="nn">Obj</span><span class="p">.</span><span class="n">t</span> <span class="o">-&gt;</span> <span class="o">[&gt;`</span><span class="nc">ArrayLike</span><span class="o">]</span> <span class="nn">Np</span><span class="p">.</span><span class="nn">Obj</span><span class="p">.</span><span class="n">t</span>
</code></pre></div>

<p>Compute data precision matrix with the generative model.</p>
<p>Equals the inverse of the covariance but computed with
the matrix inversion lemma for efficiency.</p>
<h2 id="returns_24">Returns<a class="headerlink" href="#returns_24" title="Permanent link">&para;</a></h2>
<p>precision : array, shape=(n_features, n_features)
Estimated precision of data.</p>
<div class="highlight"><pre><span></span><code><span class="k">val</span> <span class="n">inverse_transform</span> <span class="o">:</span> <span class="n">x</span><span class="o">:[&gt;`</span><span class="nc">ArrayLike</span><span class="o">]</span> <span class="nn">Np</span><span class="p">.</span><span class="nn">Obj</span><span class="p">.</span><span class="n">t</span> <span class="o">-&gt;</span> <span class="o">[&gt;</span> <span class="n">tag</span><span class="o">]</span> <span class="nn">Obj</span><span class="p">.</span><span class="n">t</span> <span class="o">-&gt;</span> <span class="nn">Py</span><span class="p">.</span><span class="nn">Object</span><span class="p">.</span><span class="n">t</span>
</code></pre></div>

<p>Transform data back to its original space.</p>
<p>In other words, return an input X_original whose transform would be X.</p>
<h2 id="parameters_25">Parameters<a class="headerlink" href="#parameters_25" title="Permanent link">&para;</a></h2>
<p>X : array-like, shape (n_samples, n_components)
New data, where n_samples is the number of samples
and n_components is the number of components.</p>
<h2 id="returns_25">Returns<a class="headerlink" href="#returns_25" title="Permanent link">&para;</a></h2>
<p>X_original array-like, shape (n_samples, n_features)</p>
<h2 id="notes_3">Notes<a class="headerlink" href="#notes_3" title="Permanent link">&para;</a></h2>
<p>If whitening is enabled, inverse_transform will compute the
exact inverse operation, which includes reversing whitening.</p>
<div class="highlight"><pre><span></span><code><span class="k">val</span> <span class="n">partial_fit</span> <span class="o">:</span> <span class="o">?</span><span class="n">y</span><span class="o">:</span><span class="nn">Py</span><span class="p">.</span><span class="nn">Object</span><span class="p">.</span><span class="n">t</span> <span class="o">-&gt;</span> <span class="o">?</span><span class="n">check_input</span><span class="o">:</span><span class="kt">bool</span> <span class="o">-&gt;</span> <span class="n">x</span><span class="o">:[&gt;`</span><span class="nc">ArrayLike</span><span class="o">]</span> <span class="nn">Np</span><span class="p">.</span><span class="nn">Obj</span><span class="p">.</span><span class="n">t</span> <span class="o">-&gt;</span> <span class="o">[&gt;</span> <span class="n">tag</span><span class="o">]</span> <span class="nn">Obj</span><span class="p">.</span><span class="n">t</span> <span class="o">-&gt;</span> <span class="n">t</span>
</code></pre></div>

<p>Incremental fit with X. All of X is processed as a single batch.</p>
<h2 id="parameters_26">Parameters<a class="headerlink" href="#parameters_26" title="Permanent link">&para;</a></h2>
<p>X : array-like, shape (n_samples, n_features)
Training data, where n_samples is the number of samples and
n_features is the number of features.
check_input : bool
Run check_array on X.</p>
<p>y : Ignored</p>
<h2 id="returns_26">Returns<a class="headerlink" href="#returns_26" title="Permanent link">&para;</a></h2>
<p>self : object
Returns the instance itself.</p>
<div class="highlight"><pre><span></span><code><span class="k">val</span> <span class="n">set_params</span> <span class="o">:</span> <span class="o">?</span><span class="n">params</span><span class="o">:(</span><span class="kt">string</span> <span class="o">*</span> <span class="nn">Py</span><span class="p">.</span><span class="nn">Object</span><span class="p">.</span><span class="n">t</span><span class="o">)</span> <span class="kt">list</span> <span class="o">-&gt;</span> <span class="o">[&gt;</span> <span class="n">tag</span><span class="o">]</span> <span class="nn">Obj</span><span class="p">.</span><span class="n">t</span> <span class="o">-&gt;</span> <span class="n">t</span>
</code></pre></div>

<p>Set the parameters of this estimator.</p>
<p>The method works on simple estimators as well as on nested objects
(such as pipelines). The latter have parameters of the form
<code>&lt;component&gt;__&lt;parameter&gt;</code> so that it's possible to update each
component of a nested object.</p>
<h2 id="parameters_27">Parameters<a class="headerlink" href="#parameters_27" title="Permanent link">&para;</a></h2>
<p>**params : dict
Estimator parameters.</p>
<h2 id="returns_27">Returns<a class="headerlink" href="#returns_27" title="Permanent link">&para;</a></h2>
<p>self : object
Estimator instance.</p>
<div class="highlight"><pre><span></span><code><span class="k">val</span> <span class="n">transform</span> <span class="o">:</span> <span class="n">x</span><span class="o">:[&gt;`</span><span class="nc">ArrayLike</span><span class="o">]</span> <span class="nn">Np</span><span class="p">.</span><span class="nn">Obj</span><span class="p">.</span><span class="n">t</span> <span class="o">-&gt;</span> <span class="o">[&gt;</span> <span class="n">tag</span><span class="o">]</span> <span class="nn">Obj</span><span class="p">.</span><span class="n">t</span> <span class="o">-&gt;</span> <span class="o">[&gt;`</span><span class="nc">ArrayLike</span><span class="o">]</span> <span class="nn">Np</span><span class="p">.</span><span class="nn">Obj</span><span class="p">.</span><span class="n">t</span>
</code></pre></div>

<p>Apply dimensionality reduction to X.</p>
<p>X is projected on the first principal components previously extracted
from a training set, using minibatches of size batch_size if X is
sparse.</p>
<h2 id="parameters_28">Parameters<a class="headerlink" href="#parameters_28" title="Permanent link">&para;</a></h2>
<p>X : array-like, shape (n_samples, n_features)
New data, where n_samples is the number of samples
and n_features is the number of features.</p>
<h2 id="returns_28">Returns<a class="headerlink" href="#returns_28" title="Permanent link">&para;</a></h2>
<p>X_new : array-like, shape (n_samples, n_components)</p>
<h2 id="examples_3">Examples<a class="headerlink" href="#examples_3" title="Permanent link">&para;</a></h2>
<blockquote>
<blockquote>
<blockquote>
<p>import numpy as np
from sklearn.decomposition import IncrementalPCA
X = np.array([[-1, -1], [-2, -1], [-3, -2],
...               [1, 1], [2, 1], [3, 2]])
ipca = IncrementalPCA(n_components=2, batch_size=3)
ipca.fit(X)
IncrementalPCA(batch_size=3, n_components=2)
ipca.transform(X) # doctest: +SKIP</p>
</blockquote>
</blockquote>
</blockquote>
<p>Attribute components_: get value or raise Not_found if None.</p>
<div class="highlight"><pre><span></span><code><span class="k">val</span> <span class="n">components_</span> <span class="o">:</span> <span class="n">t</span> <span class="o">-&gt;</span> <span class="o">[&gt;`</span><span class="nc">ArrayLike</span><span class="o">]</span> <span class="nn">Np</span><span class="p">.</span><span class="nn">Obj</span><span class="p">.</span><span class="n">t</span>
</code></pre></div>

<p>Attribute components_: get value as an option.</p>
<div class="highlight"><pre><span></span><code><span class="k">val</span> <span class="n">components_opt</span> <span class="o">:</span> <span class="n">t</span> <span class="o">-&gt;</span> <span class="o">([&gt;`</span><span class="nc">ArrayLike</span><span class="o">]</span> <span class="nn">Np</span><span class="p">.</span><span class="nn">Obj</span><span class="p">.</span><span class="n">t</span><span class="o">)</span> <span class="n">option</span>
</code></pre></div>

<p>Attribute explained_variance_: get value or raise Not_found if None.</p>
<div class="highlight"><pre><span></span><code><span class="k">val</span> <span class="n">explained_variance_</span> <span class="o">:</span> <span class="n">t</span> <span class="o">-&gt;</span> <span class="o">[&gt;`</span><span class="nc">ArrayLike</span><span class="o">]</span> <span class="nn">Np</span><span class="p">.</span><span class="nn">Obj</span><span class="p">.</span><span class="n">t</span>
</code></pre></div>

<p>Attribute explained_variance_: get value as an option.</p>
<div class="highlight"><pre><span></span><code><span class="k">val</span> <span class="n">explained_variance_opt</span> <span class="o">:</span> <span class="n">t</span> <span class="o">-&gt;</span> <span class="o">([&gt;`</span><span class="nc">ArrayLike</span><span class="o">]</span> <span class="nn">Np</span><span class="p">.</span><span class="nn">Obj</span><span class="p">.</span><span class="n">t</span><span class="o">)</span> <span class="n">option</span>
</code></pre></div>

<p>Attribute explained_variance_ratio_: get value or raise Not_found if None.</p>
<div class="highlight"><pre><span></span><code><span class="k">val</span> <span class="n">explained_variance_ratio_</span> <span class="o">:</span> <span class="n">t</span> <span class="o">-&gt;</span> <span class="o">[&gt;`</span><span class="nc">ArrayLike</span><span class="o">]</span> <span class="nn">Np</span><span class="p">.</span><span class="nn">Obj</span><span class="p">.</span><span class="n">t</span>
</code></pre></div>

<p>Attribute explained_variance_ratio_: get value as an option.</p>
<div class="highlight"><pre><span></span><code><span class="k">val</span> <span class="n">explained_variance_ratio_opt</span> <span class="o">:</span> <span class="n">t</span> <span class="o">-&gt;</span> <span class="o">([&gt;`</span><span class="nc">ArrayLike</span><span class="o">]</span> <span class="nn">Np</span><span class="p">.</span><span class="nn">Obj</span><span class="p">.</span><span class="n">t</span><span class="o">)</span> <span class="n">option</span>
</code></pre></div>

<p>Attribute singular_values_: get value or raise Not_found if None.</p>
<div class="highlight"><pre><span></span><code><span class="k">val</span> <span class="n">singular_values_</span> <span class="o">:</span> <span class="n">t</span> <span class="o">-&gt;</span> <span class="o">[&gt;`</span><span class="nc">ArrayLike</span><span class="o">]</span> <span class="nn">Np</span><span class="p">.</span><span class="nn">Obj</span><span class="p">.</span><span class="n">t</span>
</code></pre></div>

<p>Attribute singular_values_: get value as an option.</p>
<div class="highlight"><pre><span></span><code><span class="k">val</span> <span class="n">singular_values_opt</span> <span class="o">:</span> <span class="n">t</span> <span class="o">-&gt;</span> <span class="o">([&gt;`</span><span class="nc">ArrayLike</span><span class="o">]</span> <span class="nn">Np</span><span class="p">.</span><span class="nn">Obj</span><span class="p">.</span><span class="n">t</span><span class="o">)</span> <span class="n">option</span>
</code></pre></div>

<p>Attribute mean_: get value or raise Not_found if None.</p>
<div class="highlight"><pre><span></span><code><span class="k">val</span> <span class="n">mean_</span> <span class="o">:</span> <span class="n">t</span> <span class="o">-&gt;</span> <span class="o">[&gt;`</span><span class="nc">ArrayLike</span><span class="o">]</span> <span class="nn">Np</span><span class="p">.</span><span class="nn">Obj</span><span class="p">.</span><span class="n">t</span>
</code></pre></div>

<p>Attribute mean_: get value as an option.</p>
<div class="highlight"><pre><span></span><code><span class="k">val</span> <span class="n">mean_opt</span> <span class="o">:</span> <span class="n">t</span> <span class="o">-&gt;</span> <span class="o">([&gt;`</span><span class="nc">ArrayLike</span><span class="o">]</span> <span class="nn">Np</span><span class="p">.</span><span class="nn">Obj</span><span class="p">.</span><span class="n">t</span><span class="o">)</span> <span class="n">option</span>
</code></pre></div>

<p>Attribute var_: get value or raise Not_found if None.</p>
<div class="highlight"><pre><span></span><code><span class="k">val</span> <span class="n">var_</span> <span class="o">:</span> <span class="n">t</span> <span class="o">-&gt;</span> <span class="o">[&gt;`</span><span class="nc">ArrayLike</span><span class="o">]</span> <span class="nn">Np</span><span class="p">.</span><span class="nn">Obj</span><span class="p">.</span><span class="n">t</span>
</code></pre></div>

<p>Attribute var_: get value as an option.</p>
<div class="highlight"><pre><span></span><code><span class="k">val</span> <span class="n">var_opt</span> <span class="o">:</span> <span class="n">t</span> <span class="o">-&gt;</span> <span class="o">([&gt;`</span><span class="nc">ArrayLike</span><span class="o">]</span> <span class="nn">Np</span><span class="p">.</span><span class="nn">Obj</span><span class="p">.</span><span class="n">t</span><span class="o">)</span> <span class="n">option</span>
</code></pre></div>

<p>Attribute noise_variance_: get value or raise Not_found if None.</p>
<div class="highlight"><pre><span></span><code><span class="k">val</span> <span class="n">noise_variance_</span> <span class="o">:</span> <span class="n">t</span> <span class="o">-&gt;</span> <span class="kt">float</span>
</code></pre></div>

<p>Attribute noise_variance_: get value as an option.</p>
<div class="highlight"><pre><span></span><code><span class="k">val</span> <span class="n">noise_variance_opt</span> <span class="o">:</span> <span class="n">t</span> <span class="o">-&gt;</span> <span class="o">(</span><span class="kt">float</span><span class="o">)</span> <span class="n">option</span>
</code></pre></div>

<p>Attribute n_components_: get value or raise Not_found if None.</p>
<div class="highlight"><pre><span></span><code><span class="k">val</span> <span class="n">n_components_</span> <span class="o">:</span> <span class="n">t</span> <span class="o">-&gt;</span> <span class="kt">int</span>
</code></pre></div>

<p>Attribute n_components_: get value as an option.</p>
<div class="highlight"><pre><span></span><code><span class="k">val</span> <span class="n">n_components_opt</span> <span class="o">:</span> <span class="n">t</span> <span class="o">-&gt;</span> <span class="o">(</span><span class="kt">int</span><span class="o">)</span> <span class="n">option</span>
</code></pre></div>

<p>Attribute n_samples_seen_: get value or raise Not_found if None.</p>
<div class="highlight"><pre><span></span><code><span class="k">val</span> <span class="n">n_samples_seen_</span> <span class="o">:</span> <span class="n">t</span> <span class="o">-&gt;</span> <span class="kt">int</span>
</code></pre></div>

<p>Attribute n_samples_seen_: get value as an option.</p>
<div class="highlight"><pre><span></span><code><span class="k">val</span> <span class="n">n_samples_seen_opt</span> <span class="o">:</span> <span class="n">t</span> <span class="o">-&gt;</span> <span class="o">(</span><span class="kt">int</span><span class="o">)</span> <span class="n">option</span>
</code></pre></div>

<p>Print the object to a human-readable representation.</p>
<div class="highlight"><pre><span></span><code><span class="k">val</span> <span class="n">to_string</span> <span class="o">:</span> <span class="n">t</span> <span class="o">-&gt;</span> <span class="kt">string</span>
</code></pre></div>

<p>Print the object to a human-readable representation.</p>
<div class="highlight"><pre><span></span><code><span class="k">val</span> <span class="n">show</span> <span class="o">:</span> <span class="n">t</span> <span class="o">-&gt;</span> <span class="kt">string</span>
</code></pre></div>

<p>Pretty-print the object to a formatter.</p>
<div class="highlight"><pre><span></span><code><span class="k">val</span> <span class="n">pp</span> <span class="o">:</span> <span class="nn">Format</span><span class="p">.</span><span class="n">formatter</span> <span class="o">-&gt;</span> <span class="n">t</span> <span class="o">-&gt;</span> <span class="kt">unit</span> <span class="o">[@@</span><span class="n">ocaml</span><span class="o">.</span><span class="n">toplevel_printer</span><span class="o">]</span>



<span class="k">module</span> <span class="nc">KernelPCA</span> <span class="o">:</span> <span class="k">sig</span>
<span class="k">type</span> <span class="n">tag</span> <span class="o">=</span> <span class="o">[`</span><span class="nc">KernelPCA</span><span class="o">]</span>
<span class="k">type</span> <span class="n">t</span> <span class="o">=</span> <span class="o">[`</span><span class="nc">BaseEstimator</span> <span class="o">|</span> <span class="o">`</span><span class="nc">KernelPCA</span> <span class="o">|</span> <span class="o">`</span><span class="nc">Object</span> <span class="o">|</span> <span class="o">`</span><span class="nc">TransformerMixin</span><span class="o">]</span> <span class="nn">Obj</span><span class="p">.</span><span class="n">t</span>
<span class="k">val</span> <span class="n">of_pyobject</span> <span class="o">:</span> <span class="nn">Py</span><span class="p">.</span><span class="nn">Object</span><span class="p">.</span><span class="n">t</span> <span class="o">-&gt;</span> <span class="n">t</span>
<span class="k">val</span> <span class="n">to_pyobject</span> <span class="o">:</span> <span class="o">[&gt;</span> <span class="n">tag</span><span class="o">]</span> <span class="nn">Obj</span><span class="p">.</span><span class="n">t</span> <span class="o">-&gt;</span> <span class="nn">Py</span><span class="p">.</span><span class="nn">Object</span><span class="p">.</span><span class="n">t</span>

<span class="k">val</span> <span class="n">as_transformer</span> <span class="o">:</span> <span class="n">t</span> <span class="o">-&gt;</span> <span class="o">[`</span><span class="nc">TransformerMixin</span><span class="o">]</span> <span class="nn">Obj</span><span class="p">.</span><span class="n">t</span>
<span class="k">val</span> <span class="n">as_estimator</span> <span class="o">:</span> <span class="n">t</span> <span class="o">-&gt;</span> <span class="o">[`</span><span class="nc">BaseEstimator</span><span class="o">]</span> <span class="nn">Obj</span><span class="p">.</span><span class="n">t</span>
<span class="k">val</span> <span class="n">create</span> <span class="o">:</span> <span class="o">?</span><span class="n">n_components</span><span class="o">:</span><span class="kt">int</span> <span class="o">-&gt;</span> <span class="o">?</span><span class="n">kernel</span><span class="o">:[`</span><span class="nc">Linear</span> <span class="o">|</span> <span class="o">`</span><span class="nc">Poly</span> <span class="o">|</span> <span class="o">`</span><span class="nc">Rbf</span> <span class="o">|</span> <span class="o">`</span><span class="nc">Sigmoid</span> <span class="o">|</span> <span class="o">`</span><span class="nc">Cosine</span> <span class="o">|</span> <span class="o">`</span><span class="nc">Precomputed</span><span class="o">]</span> <span class="o">-&gt;</span> <span class="o">?</span><span class="n">gamma</span><span class="o">:</span><span class="kt">float</span> <span class="o">-&gt;</span> <span class="o">?</span><span class="n">degree</span><span class="o">:</span><span class="kt">int</span> <span class="o">-&gt;</span> <span class="o">?</span><span class="n">coef0</span><span class="o">:</span><span class="kt">float</span> <span class="o">-&gt;</span> <span class="o">?</span><span class="n">kernel_params</span><span class="o">:</span><span class="nn">Dict</span><span class="p">.</span><span class="n">t</span> <span class="o">-&gt;</span> <span class="o">?</span><span class="n">alpha</span><span class="o">:</span><span class="kt">int</span> <span class="o">-&gt;</span> <span class="o">?</span><span class="n">fit_inverse_transform</span><span class="o">:</span><span class="kt">bool</span> <span class="o">-&gt;</span> <span class="o">?</span><span class="n">eigen_solver</span><span class="o">:[`</span><span class="nc">Auto</span> <span class="o">|</span> <span class="o">`</span><span class="nc">Dense</span> <span class="o">|</span> <span class="o">`</span><span class="nc">Arpack</span><span class="o">]</span> <span class="o">-&gt;</span> <span class="o">?</span><span class="n">tol</span><span class="o">:</span><span class="kt">float</span> <span class="o">-&gt;</span> <span class="o">?</span><span class="n">max_iter</span><span class="o">:</span><span class="kt">int</span> <span class="o">-&gt;</span> <span class="o">?</span><span class="n">remove_zero_eig</span><span class="o">:</span><span class="kt">bool</span> <span class="o">-&gt;</span> <span class="o">?</span><span class="n">random_state</span><span class="o">:</span><span class="kt">int</span> <span class="o">-&gt;</span> <span class="o">?</span><span class="n">copy_X</span><span class="o">:</span><span class="kt">bool</span> <span class="o">-&gt;</span> <span class="o">?</span><span class="n">n_jobs</span><span class="o">:</span><span class="kt">int</span> <span class="o">-&gt;</span> <span class="kt">unit</span> <span class="o">-&gt;</span> <span class="n">t</span>
</code></pre></div>

<p>Kernel Principal component analysis (KPCA)</p>
<p>Non-linear dimensionality reduction through the use of kernels (see
:ref:<code>metrics</code>).</p>
<p>Read more in the :ref:<code>User Guide &lt;kernel_PCA&gt;</code>.</p>
<h2 id="parameters_29">Parameters<a class="headerlink" href="#parameters_29" title="Permanent link">&para;</a></h2>
<p>n_components : int, default=None
Number of components. If None, all non-zero components are kept.</p>
<p>kernel : 'linear' | 'poly' | 'rbf' | 'sigmoid' | 'cosine' | 'precomputed'
Kernel. Default='linear'.</p>
<p>gamma : float, default=1/n_features
Kernel coefficient for rbf, poly and sigmoid kernels. Ignored by other
kernels.</p>
<p>degree : int, default=3
Degree for poly kernels. Ignored by other kernels.</p>
<p>coef0 : float, default=1
Independent term in poly and sigmoid kernels.
Ignored by other kernels.</p>
<p>kernel_params : mapping of string to any, default=None
Parameters (keyword arguments) and values for kernel passed as
callable object. Ignored by other kernels.</p>
<p>alpha : int, default=1.0
Hyperparameter of the ridge regression that learns the
inverse transform (when fit_inverse_transform=True).</p>
<p>fit_inverse_transform : bool, default=False
Learn the inverse transform for non-precomputed kernels.
(i.e. learn to find the pre-image of a point)</p>
<p>eigen_solver : string ['auto'|'dense'|'arpack'], default='auto'
Select eigensolver to use. If n_components is much less than
the number of training samples, arpack may be more efficient
than the dense eigensolver.</p>
<p>tol : float, default=0
Convergence tolerance for arpack.
If 0, optimal value will be chosen by arpack.</p>
<p>max_iter : int, default=None
Maximum number of iterations for arpack.
If None, optimal value will be chosen by arpack.</p>
<p>remove_zero_eig : boolean, default=False
If True, then all components with zero eigenvalues are removed, so
that the number of components in the output may be &lt; n_components
(and sometimes even zero due to numerical instability).
When n_components is None, this parameter is ignored and components
with zero eigenvalues are removed regardless.</p>
<p>random_state : int, RandomState instance or None, optional (default=None)
If int, random_state is the seed used by the random number generator;
If RandomState instance, random_state is the random number generator;
If None, the random number generator is the RandomState instance used
by <code>np.random</code>. Used when <code>eigen_solver</code> == 'arpack'.</p>
<p>.. versionadded:: 0.18</p>
<p>copy_X : boolean, default=True
If True, input X is copied and stored by the model in the <code>X_fit_</code>
attribute. If no further changes will be done to X, setting
<code>copy_X=False</code> saves memory by storing a reference.</p>
<p>.. versionadded:: 0.18</p>
<p>n_jobs : int or None, optional (default=None)
The number of parallel jobs to run.
<code>None</code> means 1 unless in a :obj:<code>joblib.parallel_backend</code> context.
<code>-1</code> means using all processors. See :term:<code>Glossary &lt;n_jobs&gt;</code>
for more details.</p>
<p>.. versionadded:: 0.18</p>
<h2 id="attributes_4">Attributes<a class="headerlink" href="#attributes_4" title="Permanent link">&para;</a></h2>
<p>lambdas_ : array, (n_components,)
Eigenvalues of the centered kernel matrix in decreasing order.
If <code>n_components</code> and <code>remove_zero_eig</code> are not set,
then all values are stored.</p>
<p>alphas_ : array, (n_samples, n_components)
Eigenvectors of the centered kernel matrix. If <code>n_components</code> and
<code>remove_zero_eig</code> are not set, then all components are stored.</p>
<p>dual_coef_ : array, (n_samples, n_features)
Inverse transform matrix. Only available when
<code>fit_inverse_transform</code> is True.</p>
<p>X_transformed_fit_ : array, (n_samples, n_components)
Projection of the fitted data on the kernel principal components.
Only available when <code>fit_inverse_transform</code> is True.</p>
<p>X_fit_ : (n_samples, n_features)
The data used to fit the model. If <code>copy_X=False</code>, then <code>X_fit_</code> is
a reference. This attribute is used for the calls to transform.</p>
<h2 id="examples_4">Examples<a class="headerlink" href="#examples_4" title="Permanent link">&para;</a></h2>
<blockquote>
<blockquote>
<blockquote>
<p>from sklearn.datasets import load_digits
from sklearn.decomposition import KernelPCA
X, _ = load_digits(return_X_y=True)
transformer = KernelPCA(n_components=7, kernel='linear')
X_transformed = transformer.fit_transform(X)
X_transformed.shape
(1797, 7)</p>
</blockquote>
</blockquote>
</blockquote>
<h2 id="references_2">References<a class="headerlink" href="#references_2" title="Permanent link">&para;</a></h2>
<p>Kernel PCA was introduced in:
Bernhard Schoelkopf, Alexander J. Smola,
and Klaus-Robert Mueller. 1999. Kernel principal
component analysis. In Advances in kernel methods,
MIT Press, Cambridge, MA, USA 327-352.</p>
<div class="highlight"><pre><span></span><code><span class="k">val</span> <span class="n">fit</span> <span class="o">:</span> <span class="o">?</span><span class="n">y</span><span class="o">:</span><span class="nn">Py</span><span class="p">.</span><span class="nn">Object</span><span class="p">.</span><span class="n">t</span> <span class="o">-&gt;</span> <span class="n">x</span><span class="o">:[&gt;`</span><span class="nc">ArrayLike</span><span class="o">]</span> <span class="nn">Np</span><span class="p">.</span><span class="nn">Obj</span><span class="p">.</span><span class="n">t</span> <span class="o">-&gt;</span> <span class="o">[&gt;</span> <span class="n">tag</span><span class="o">]</span> <span class="nn">Obj</span><span class="p">.</span><span class="n">t</span> <span class="o">-&gt;</span> <span class="n">t</span>
</code></pre></div>

<p>Fit the model from data in X.</p>
<h2 id="parameters_30">Parameters<a class="headerlink" href="#parameters_30" title="Permanent link">&para;</a></h2>
<p>X : array-like, shape (n_samples, n_features)
Training vector, where n_samples in the number of samples
and n_features is the number of features.</p>
<h2 id="returns_29">Returns<a class="headerlink" href="#returns_29" title="Permanent link">&para;</a></h2>
<p>self : object
Returns the instance itself.</p>
<div class="highlight"><pre><span></span><code><span class="k">val</span> <span class="n">fit_transform</span> <span class="o">:</span> <span class="o">?</span><span class="n">y</span><span class="o">:</span><span class="nn">Py</span><span class="p">.</span><span class="nn">Object</span><span class="p">.</span><span class="n">t</span> <span class="o">-&gt;</span> <span class="o">?</span><span class="n">params</span><span class="o">:(</span><span class="kt">string</span> <span class="o">*</span> <span class="nn">Py</span><span class="p">.</span><span class="nn">Object</span><span class="p">.</span><span class="n">t</span><span class="o">)</span> <span class="kt">list</span> <span class="o">-&gt;</span> <span class="n">x</span><span class="o">:[&gt;`</span><span class="nc">ArrayLike</span><span class="o">]</span> <span class="nn">Np</span><span class="p">.</span><span class="nn">Obj</span><span class="p">.</span><span class="n">t</span> <span class="o">-&gt;</span> <span class="o">[&gt;</span> <span class="n">tag</span><span class="o">]</span> <span class="nn">Obj</span><span class="p">.</span><span class="n">t</span> <span class="o">-&gt;</span> <span class="o">[&gt;`</span><span class="nc">ArrayLike</span><span class="o">]</span> <span class="nn">Np</span><span class="p">.</span><span class="nn">Obj</span><span class="p">.</span><span class="n">t</span>
</code></pre></div>

<p>Fit the model from data in X and transform X.</p>
<h2 id="parameters_31">Parameters<a class="headerlink" href="#parameters_31" title="Permanent link">&para;</a></h2>
<p>X : array-like, shape (n_samples, n_features)
Training vector, where n_samples in the number of samples
and n_features is the number of features.</p>
<h2 id="returns_30">Returns<a class="headerlink" href="#returns_30" title="Permanent link">&para;</a></h2>
<p>X_new : array-like, shape (n_samples, n_components)</p>
<div class="highlight"><pre><span></span><code><span class="k">val</span> <span class="n">get_params</span> <span class="o">:</span> <span class="o">?</span><span class="n">deep</span><span class="o">:</span><span class="kt">bool</span> <span class="o">-&gt;</span> <span class="o">[&gt;</span> <span class="n">tag</span><span class="o">]</span> <span class="nn">Obj</span><span class="p">.</span><span class="n">t</span> <span class="o">-&gt;</span> <span class="nn">Dict</span><span class="p">.</span><span class="n">t</span>
</code></pre></div>

<p>Get parameters for this estimator.</p>
<h2 id="parameters_32">Parameters<a class="headerlink" href="#parameters_32" title="Permanent link">&para;</a></h2>
<p>deep : bool, default=True
If True, will return the parameters for this estimator and
contained subobjects that are estimators.</p>
<h2 id="returns_31">Returns<a class="headerlink" href="#returns_31" title="Permanent link">&para;</a></h2>
<p>params : mapping of string to any
Parameter names mapped to their values.</p>
<div class="highlight"><pre><span></span><code><span class="k">val</span> <span class="n">inverse_transform</span> <span class="o">:</span> <span class="n">x</span><span class="o">:[&gt;`</span><span class="nc">ArrayLike</span><span class="o">]</span> <span class="nn">Np</span><span class="p">.</span><span class="nn">Obj</span><span class="p">.</span><span class="n">t</span> <span class="o">-&gt;</span> <span class="o">[&gt;</span> <span class="n">tag</span><span class="o">]</span> <span class="nn">Obj</span><span class="p">.</span><span class="n">t</span> <span class="o">-&gt;</span> <span class="o">[&gt;`</span><span class="nc">ArrayLike</span><span class="o">]</span> <span class="nn">Np</span><span class="p">.</span><span class="nn">Obj</span><span class="p">.</span><span class="n">t</span>
</code></pre></div>

<p>Transform X back to original space.</p>
<h2 id="parameters_33">Parameters<a class="headerlink" href="#parameters_33" title="Permanent link">&para;</a></h2>
<p>X : array-like, shape (n_samples, n_components)</p>
<h2 id="returns_32">Returns<a class="headerlink" href="#returns_32" title="Permanent link">&para;</a></h2>
<p>X_new : array-like, shape (n_samples, n_features)</p>
<h2 id="references_3">References<a class="headerlink" href="#references_3" title="Permanent link">&para;</a></h2>
<p>'Learning to Find Pre-Images', G BakIr et al, 2004.</p>
<div class="highlight"><pre><span></span><code><span class="k">val</span> <span class="n">set_params</span> <span class="o">:</span> <span class="o">?</span><span class="n">params</span><span class="o">:(</span><span class="kt">string</span> <span class="o">*</span> <span class="nn">Py</span><span class="p">.</span><span class="nn">Object</span><span class="p">.</span><span class="n">t</span><span class="o">)</span> <span class="kt">list</span> <span class="o">-&gt;</span> <span class="o">[&gt;</span> <span class="n">tag</span><span class="o">]</span> <span class="nn">Obj</span><span class="p">.</span><span class="n">t</span> <span class="o">-&gt;</span> <span class="n">t</span>
</code></pre></div>

<p>Set the parameters of this estimator.</p>
<p>The method works on simple estimators as well as on nested objects
(such as pipelines). The latter have parameters of the form
<code>&lt;component&gt;__&lt;parameter&gt;</code> so that it's possible to update each
component of a nested object.</p>
<h2 id="parameters_34">Parameters<a class="headerlink" href="#parameters_34" title="Permanent link">&para;</a></h2>
<p>**params : dict
Estimator parameters.</p>
<h2 id="returns_33">Returns<a class="headerlink" href="#returns_33" title="Permanent link">&para;</a></h2>
<p>self : object
Estimator instance.</p>
<div class="highlight"><pre><span></span><code><span class="k">val</span> <span class="n">transform</span> <span class="o">:</span> <span class="n">x</span><span class="o">:[&gt;`</span><span class="nc">ArrayLike</span><span class="o">]</span> <span class="nn">Np</span><span class="p">.</span><span class="nn">Obj</span><span class="p">.</span><span class="n">t</span> <span class="o">-&gt;</span> <span class="o">[&gt;</span> <span class="n">tag</span><span class="o">]</span> <span class="nn">Obj</span><span class="p">.</span><span class="n">t</span> <span class="o">-&gt;</span> <span class="o">[&gt;`</span><span class="nc">ArrayLike</span><span class="o">]</span> <span class="nn">Np</span><span class="p">.</span><span class="nn">Obj</span><span class="p">.</span><span class="n">t</span>
</code></pre></div>

<p>Transform X.</p>
<h2 id="parameters_35">Parameters<a class="headerlink" href="#parameters_35" title="Permanent link">&para;</a></h2>
<p>X : array-like, shape (n_samples, n_features)</p>
<h2 id="returns_34">Returns<a class="headerlink" href="#returns_34" title="Permanent link">&para;</a></h2>
<p>X_new : array-like, shape (n_samples, n_components)</p>
<p>Attribute lambdas_: get value or raise Not_found if None.</p>
<div class="highlight"><pre><span></span><code><span class="k">val</span> <span class="n">lambdas_</span> <span class="o">:</span> <span class="n">t</span> <span class="o">-&gt;</span> <span class="o">[&gt;`</span><span class="nc">ArrayLike</span><span class="o">]</span> <span class="nn">Np</span><span class="p">.</span><span class="nn">Obj</span><span class="p">.</span><span class="n">t</span>
</code></pre></div>

<p>Attribute lambdas_: get value as an option.</p>
<div class="highlight"><pre><span></span><code><span class="k">val</span> <span class="n">lambdas_opt</span> <span class="o">:</span> <span class="n">t</span> <span class="o">-&gt;</span> <span class="o">([&gt;`</span><span class="nc">ArrayLike</span><span class="o">]</span> <span class="nn">Np</span><span class="p">.</span><span class="nn">Obj</span><span class="p">.</span><span class="n">t</span><span class="o">)</span> <span class="n">option</span>
</code></pre></div>

<p>Attribute alphas_: get value or raise Not_found if None.</p>
<div class="highlight"><pre><span></span><code><span class="k">val</span> <span class="n">alphas_</span> <span class="o">:</span> <span class="n">t</span> <span class="o">-&gt;</span> <span class="o">[&gt;`</span><span class="nc">ArrayLike</span><span class="o">]</span> <span class="nn">Np</span><span class="p">.</span><span class="nn">Obj</span><span class="p">.</span><span class="n">t</span>
</code></pre></div>

<p>Attribute alphas_: get value as an option.</p>
<div class="highlight"><pre><span></span><code><span class="k">val</span> <span class="n">alphas_opt</span> <span class="o">:</span> <span class="n">t</span> <span class="o">-&gt;</span> <span class="o">([&gt;`</span><span class="nc">ArrayLike</span><span class="o">]</span> <span class="nn">Np</span><span class="p">.</span><span class="nn">Obj</span><span class="p">.</span><span class="n">t</span><span class="o">)</span> <span class="n">option</span>
</code></pre></div>

<p>Attribute dual_coef_: get value or raise Not_found if None.</p>
<div class="highlight"><pre><span></span><code><span class="k">val</span> <span class="n">dual_coef_</span> <span class="o">:</span> <span class="n">t</span> <span class="o">-&gt;</span> <span class="o">[&gt;`</span><span class="nc">ArrayLike</span><span class="o">]</span> <span class="nn">Np</span><span class="p">.</span><span class="nn">Obj</span><span class="p">.</span><span class="n">t</span>
</code></pre></div>

<p>Attribute dual_coef_: get value as an option.</p>
<div class="highlight"><pre><span></span><code><span class="k">val</span> <span class="n">dual_coef_opt</span> <span class="o">:</span> <span class="n">t</span> <span class="o">-&gt;</span> <span class="o">([&gt;`</span><span class="nc">ArrayLike</span><span class="o">]</span> <span class="nn">Np</span><span class="p">.</span><span class="nn">Obj</span><span class="p">.</span><span class="n">t</span><span class="o">)</span> <span class="n">option</span>
</code></pre></div>

<p>Attribute X_transformed_fit_: get value or raise Not_found if None.</p>
<div class="highlight"><pre><span></span><code><span class="k">val</span> <span class="n">x_transformed_fit_</span> <span class="o">:</span> <span class="n">t</span> <span class="o">-&gt;</span> <span class="o">[&gt;`</span><span class="nc">ArrayLike</span><span class="o">]</span> <span class="nn">Np</span><span class="p">.</span><span class="nn">Obj</span><span class="p">.</span><span class="n">t</span>
</code></pre></div>

<p>Attribute X_transformed_fit_: get value as an option.</p>
<div class="highlight"><pre><span></span><code><span class="k">val</span> <span class="n">x_transformed_fit_opt</span> <span class="o">:</span> <span class="n">t</span> <span class="o">-&gt;</span> <span class="o">([&gt;`</span><span class="nc">ArrayLike</span><span class="o">]</span> <span class="nn">Np</span><span class="p">.</span><span class="nn">Obj</span><span class="p">.</span><span class="n">t</span><span class="o">)</span> <span class="n">option</span>
</code></pre></div>

<p>Print the object to a human-readable representation.</p>
<div class="highlight"><pre><span></span><code><span class="k">val</span> <span class="n">to_string</span> <span class="o">:</span> <span class="n">t</span> <span class="o">-&gt;</span> <span class="kt">string</span>
</code></pre></div>

<p>Print the object to a human-readable representation.</p>
<div class="highlight"><pre><span></span><code><span class="k">val</span> <span class="n">show</span> <span class="o">:</span> <span class="n">t</span> <span class="o">-&gt;</span> <span class="kt">string</span>
</code></pre></div>

<p>Pretty-print the object to a formatter.</p>
<div class="highlight"><pre><span></span><code><span class="k">val</span> <span class="n">pp</span> <span class="o">:</span> <span class="nn">Format</span><span class="p">.</span><span class="n">formatter</span> <span class="o">-&gt;</span> <span class="n">t</span> <span class="o">-&gt;</span> <span class="kt">unit</span> <span class="o">[@@</span><span class="n">ocaml</span><span class="o">.</span><span class="n">toplevel_printer</span><span class="o">]</span>



<span class="k">module</span> <span class="nc">LatentDirichletAllocation</span> <span class="o">:</span> <span class="k">sig</span>
<span class="k">type</span> <span class="n">tag</span> <span class="o">=</span> <span class="o">[`</span><span class="nc">LatentDirichletAllocation</span><span class="o">]</span>
<span class="k">type</span> <span class="n">t</span> <span class="o">=</span> <span class="o">[`</span><span class="nc">BaseEstimator</span> <span class="o">|</span> <span class="o">`</span><span class="nc">LatentDirichletAllocation</span> <span class="o">|</span> <span class="o">`</span><span class="nc">Object</span> <span class="o">|</span> <span class="o">`</span><span class="nc">TransformerMixin</span><span class="o">]</span> <span class="nn">Obj</span><span class="p">.</span><span class="n">t</span>
<span class="k">val</span> <span class="n">of_pyobject</span> <span class="o">:</span> <span class="nn">Py</span><span class="p">.</span><span class="nn">Object</span><span class="p">.</span><span class="n">t</span> <span class="o">-&gt;</span> <span class="n">t</span>
<span class="k">val</span> <span class="n">to_pyobject</span> <span class="o">:</span> <span class="o">[&gt;</span> <span class="n">tag</span><span class="o">]</span> <span class="nn">Obj</span><span class="p">.</span><span class="n">t</span> <span class="o">-&gt;</span> <span class="nn">Py</span><span class="p">.</span><span class="nn">Object</span><span class="p">.</span><span class="n">t</span>

<span class="k">val</span> <span class="n">as_transformer</span> <span class="o">:</span> <span class="n">t</span> <span class="o">-&gt;</span> <span class="o">[`</span><span class="nc">TransformerMixin</span><span class="o">]</span> <span class="nn">Obj</span><span class="p">.</span><span class="n">t</span>
<span class="k">val</span> <span class="n">as_estimator</span> <span class="o">:</span> <span class="n">t</span> <span class="o">-&gt;</span> <span class="o">[`</span><span class="nc">BaseEstimator</span><span class="o">]</span> <span class="nn">Obj</span><span class="p">.</span><span class="n">t</span>
<span class="k">val</span> <span class="n">create</span> <span class="o">:</span> <span class="o">?</span><span class="n">n_components</span><span class="o">:</span><span class="kt">int</span> <span class="o">-&gt;</span> <span class="o">?</span><span class="n">doc_topic_prior</span><span class="o">:</span><span class="kt">float</span> <span class="o">-&gt;</span> <span class="o">?</span><span class="n">topic_word_prior</span><span class="o">:</span><span class="kt">float</span> <span class="o">-&gt;</span> <span class="o">?</span><span class="n">learning_method</span><span class="o">:[`</span><span class="nc">Batch</span> <span class="o">|</span> <span class="o">`</span><span class="nc">Online</span><span class="o">]</span> <span class="o">-&gt;</span> <span class="o">?</span><span class="n">learning_decay</span><span class="o">:</span><span class="kt">float</span> <span class="o">-&gt;</span> <span class="o">?</span><span class="n">learning_offset</span><span class="o">:</span><span class="kt">float</span> <span class="o">-&gt;</span> <span class="o">?</span><span class="n">max_iter</span><span class="o">:</span><span class="kt">int</span> <span class="o">-&gt;</span> <span class="o">?</span><span class="n">batch_size</span><span class="o">:</span><span class="kt">int</span> <span class="o">-&gt;</span> <span class="o">?</span><span class="n">evaluate_every</span><span class="o">:</span><span class="kt">int</span> <span class="o">-&gt;</span> <span class="o">?</span><span class="n">total_samples</span><span class="o">:</span><span class="kt">int</span> <span class="o">-&gt;</span> <span class="o">?</span><span class="n">perp_tol</span><span class="o">:</span><span class="kt">float</span> <span class="o">-&gt;</span> <span class="o">?</span><span class="n">mean_change_tol</span><span class="o">:</span><span class="kt">float</span> <span class="o">-&gt;</span> <span class="o">?</span><span class="n">max_doc_update_iter</span><span class="o">:</span><span class="kt">int</span> <span class="o">-&gt;</span> <span class="o">?</span><span class="n">n_jobs</span><span class="o">:</span><span class="kt">int</span> <span class="o">-&gt;</span> <span class="o">?</span><span class="n">verbose</span><span class="o">:</span><span class="kt">int</span> <span class="o">-&gt;</span> <span class="o">?</span><span class="n">random_state</span><span class="o">:</span><span class="kt">int</span> <span class="o">-&gt;</span> <span class="kt">unit</span> <span class="o">-&gt;</span> <span class="n">t</span>
</code></pre></div>

<p>Latent Dirichlet Allocation with online variational Bayes algorithm</p>
<p>.. versionadded:: 0.17</p>
<p>Read more in the :ref:<code>User Guide &lt;LatentDirichletAllocation&gt;</code>.</p>
<h2 id="parameters_36">Parameters<a class="headerlink" href="#parameters_36" title="Permanent link">&para;</a></h2>
<p>n_components : int, optional (default=10)
Number of topics.</p>
<p>doc_topic_prior : float, optional (default=None)
Prior of document topic distribution <code>theta</code>. If the value is None,
defaults to <code>1 / n_components</code>.
In [1]_, this is called <code>alpha</code>.</p>
<p>topic_word_prior : float, optional (default=None)
Prior of topic word distribution <code>beta</code>. If the value is None, defaults
to <code>1 / n_components</code>.
In [1]_, this is called <code>eta</code>.</p>
<p>learning_method : 'batch' | 'online', default='batch'
Method used to update <code>_component</code>. Only used in :meth:<code>fit</code> method.
In general, if the data size is large, the online update will be much
faster than the batch update.</p>
<p>Valid options::</p>
<p>'batch': Batch variational Bayes method. Use all training data in
each EM update.
Old <code>components_</code> will be overwritten in each iteration.
'online': Online variational Bayes method. In each EM update, use
mini-batch of training data to update the <code>components_</code>
variable incrementally. The learning rate is controlled by the
<code>learning_decay</code> and the <code>learning_offset</code> parameters.</p>
<p>.. versionchanged:: 0.20
The default learning method is now <code>'batch'</code>.</p>
<p>learning_decay : float, optional (default=0.7)
It is a parameter that control learning rate in the online learning
method. The value should be set between (0.5, 1.0] to guarantee
asymptotic convergence. When the value is 0.0 and batch_size is
<code>n_samples</code>, the update method is same as batch learning. In the
literature, this is called kappa.</p>
<p>learning_offset : float, optional (default=10.)
A (positive) parameter that downweights early iterations in online
learning.  It should be greater than 1.0. In the literature, this is
called tau_0.</p>
<p>max_iter : integer, optional (default=10)
The maximum number of iterations.</p>
<p>batch_size : int, optional (default=128)
Number of documents to use in each EM iteration. Only used in online
learning.</p>
<p>evaluate_every : int, optional (default=0)
How often to evaluate perplexity. Only used in <code>fit</code> method.
set it to 0 or negative number to not evaluate perplexity in
training at all. Evaluating perplexity can help you check convergence
in training process, but it will also increase total training time.
Evaluating perplexity in every iteration might increase training time
up to two-fold.</p>
<p>total_samples : int, optional (default=1e6)
Total number of documents. Only used in the :meth:<code>partial_fit</code> method.</p>
<p>perp_tol : float, optional (default=1e-1)
Perplexity tolerance in batch learning. Only used when
<code>evaluate_every</code> is greater than 0.</p>
<p>mean_change_tol : float, optional (default=1e-3)
Stopping tolerance for updating document topic distribution in E-step.</p>
<p>max_doc_update_iter : int (default=100)
Max number of iterations for updating document topic distribution in
the E-step.</p>
<p>n_jobs : int or None, optional (default=None)
The number of jobs to use in the E-step.
<code>None</code> means 1 unless in a :obj:<code>joblib.parallel_backend</code> context.
<code>-1</code> means using all processors. See :term:<code>Glossary &lt;n_jobs&gt;</code>
for more details.</p>
<p>verbose : int, optional (default=0)
Verbosity level.</p>
<p>random_state : int, RandomState instance or None, optional (default=None)
If int, random_state is the seed used by the random number generator;
If RandomState instance, random_state is the random number generator;
If None, the random number generator is the RandomState instance used
by <code>np.random</code>.</p>
<h2 id="attributes_5">Attributes<a class="headerlink" href="#attributes_5" title="Permanent link">&para;</a></h2>
<p>components_ : array, [n_components, n_features]
Variational parameters for topic word distribution. Since the complete
conditional for topic word distribution is a Dirichlet,
<code>components_[i, j]</code> can be viewed as pseudocount that represents the
number of times word <code>j</code> was assigned to topic <code>i</code>.
It can also be viewed as distribution over the words for each topic
after normalization:
<code>model.components_ / model.components_.sum(axis=1)[:, np.newaxis]</code>.</p>
<p>n_batch_iter_ : int
Number of iterations of the EM step.</p>
<p>n_iter_ : int
Number of passes over the dataset.</p>
<p>bound_ : float
Final perplexity score on training set.</p>
<p>doc_topic_prior_ : float
Prior of document topic distribution <code>theta</code>. If the value is None,
it is <code>1 / n_components</code>.</p>
<p>topic_word_prior_ : float
Prior of topic word distribution <code>beta</code>. If the value is None, it is
<code>1 / n_components</code>.</p>
<h2 id="examples_5">Examples<a class="headerlink" href="#examples_5" title="Permanent link">&para;</a></h2>
<blockquote>
<blockquote>
<blockquote>
<p>from sklearn.decomposition import LatentDirichletAllocation
from sklearn.datasets import make_multilabel_classification</p>
<h1 id="this-produces-a-feature-matrix-of-token-counts-similar-to-what">This produces a feature matrix of token counts, similar to what<a class="headerlink" href="#this-produces-a-feature-matrix-of-token-counts-similar-to-what" title="Permanent link">&para;</a></h1>
<h1 id="countvectorizer-would-produce-on-text">CountVectorizer would produce on text.<a class="headerlink" href="#countvectorizer-would-produce-on-text" title="Permanent link">&para;</a></h1>
<p>X, _ = make_multilabel_classification(random_state=0)
lda = LatentDirichletAllocation(n_components=5,
...     random_state=0)
lda.fit(X)
LatentDirichletAllocation(...)</p>
<h1 id="get-topics-for-some-given-samples">get topics for some given samples:<a class="headerlink" href="#get-topics-for-some-given-samples" title="Permanent link">&para;</a></h1>
<p>lda.transform(X[-2:])
array([[0.00360392, 0.25499205, 0.0036211 , 0.64236448, 0.09541846],
[0.15297572, 0.00362644, 0.44412786, 0.39568399, 0.003586  ]])</p>
</blockquote>
</blockquote>
</blockquote>
<h2 id="references_4">References<a class="headerlink" href="#references_4" title="Permanent link">&para;</a></h2>
<p>.. [1] 'Online Learning for Latent Dirichlet Allocation', Matthew D.
Hoffman, David M. Blei, Francis Bach, 2010</p>
<p>[2] 'Stochastic Variational Inference', Matthew D. Hoffman, David M. Blei,
Chong Wang, John Paisley, 2013</p>
<p>[3] Matthew D. Hoffman's onlineldavb code. Link:
https://github.com/blei-lab/onlineldavb</p>
<div class="highlight"><pre><span></span><code><span class="k">val</span> <span class="n">fit</span> <span class="o">:</span> <span class="o">?</span><span class="n">y</span><span class="o">:</span><span class="nn">Py</span><span class="p">.</span><span class="nn">Object</span><span class="p">.</span><span class="n">t</span> <span class="o">-&gt;</span> <span class="n">x</span><span class="o">:[&gt;`</span><span class="nc">ArrayLike</span><span class="o">]</span> <span class="nn">Np</span><span class="p">.</span><span class="nn">Obj</span><span class="p">.</span><span class="n">t</span> <span class="o">-&gt;</span> <span class="o">[&gt;</span> <span class="n">tag</span><span class="o">]</span> <span class="nn">Obj</span><span class="p">.</span><span class="n">t</span> <span class="o">-&gt;</span> <span class="n">t</span>
</code></pre></div>

<p>Learn model for the data X with variational Bayes method.</p>
<p>When <code>learning_method</code> is 'online', use mini-batch update.
Otherwise, use batch update.</p>
<h2 id="parameters_37">Parameters<a class="headerlink" href="#parameters_37" title="Permanent link">&para;</a></h2>
<p>X : array-like or sparse matrix, shape=(n_samples, n_features)
Document word matrix.</p>
<p>y : Ignored</p>
<h2 id="returns_35">Returns<a class="headerlink" href="#returns_35" title="Permanent link">&para;</a></h2>
<p>self</p>
<div class="highlight"><pre><span></span><code><span class="k">val</span> <span class="n">fit_transform</span> <span class="o">:</span> <span class="o">?</span><span class="n">y</span><span class="o">:[&gt;`</span><span class="nc">ArrayLike</span><span class="o">]</span> <span class="nn">Np</span><span class="p">.</span><span class="nn">Obj</span><span class="p">.</span><span class="n">t</span> <span class="o">-&gt;</span> <span class="o">?</span><span class="n">fit_params</span><span class="o">:(</span><span class="kt">string</span> <span class="o">*</span> <span class="nn">Py</span><span class="p">.</span><span class="nn">Object</span><span class="p">.</span><span class="n">t</span><span class="o">)</span> <span class="kt">list</span> <span class="o">-&gt;</span> <span class="n">x</span><span class="o">:[&gt;`</span><span class="nc">ArrayLike</span><span class="o">]</span> <span class="nn">Np</span><span class="p">.</span><span class="nn">Obj</span><span class="p">.</span><span class="n">t</span> <span class="o">-&gt;</span> <span class="o">[&gt;</span> <span class="n">tag</span><span class="o">]</span> <span class="nn">Obj</span><span class="p">.</span><span class="n">t</span> <span class="o">-&gt;</span> <span class="o">[&gt;`</span><span class="nc">ArrayLike</span><span class="o">]</span> <span class="nn">Np</span><span class="p">.</span><span class="nn">Obj</span><span class="p">.</span><span class="n">t</span>
</code></pre></div>

<p>Fit to data, then transform it.</p>
<p>Fits transformer to X and y with optional parameters fit_params
and returns a transformed version of X.</p>
<h2 id="parameters_38">Parameters<a class="headerlink" href="#parameters_38" title="Permanent link">&para;</a></h2>
<p>X : numpy array of shape [n_samples, n_features]
Training set.</p>
<p>y : numpy array of shape [n_samples]
Target values.</p>
<p>**fit_params : dict
Additional fit parameters.</p>
<h2 id="returns_36">Returns<a class="headerlink" href="#returns_36" title="Permanent link">&para;</a></h2>
<p>X_new : numpy array of shape [n_samples, n_features_new]
Transformed array.</p>
<div class="highlight"><pre><span></span><code><span class="k">val</span> <span class="n">get_params</span> <span class="o">:</span> <span class="o">?</span><span class="n">deep</span><span class="o">:</span><span class="kt">bool</span> <span class="o">-&gt;</span> <span class="o">[&gt;</span> <span class="n">tag</span><span class="o">]</span> <span class="nn">Obj</span><span class="p">.</span><span class="n">t</span> <span class="o">-&gt;</span> <span class="nn">Dict</span><span class="p">.</span><span class="n">t</span>
</code></pre></div>

<p>Get parameters for this estimator.</p>
<h2 id="parameters_39">Parameters<a class="headerlink" href="#parameters_39" title="Permanent link">&para;</a></h2>
<p>deep : bool, default=True
If True, will return the parameters for this estimator and
contained subobjects that are estimators.</p>
<h2 id="returns_37">Returns<a class="headerlink" href="#returns_37" title="Permanent link">&para;</a></h2>
<p>params : mapping of string to any
Parameter names mapped to their values.</p>
<div class="highlight"><pre><span></span><code><span class="k">val</span> <span class="n">partial_fit</span> <span class="o">:</span> <span class="o">?</span><span class="n">y</span><span class="o">:</span><span class="nn">Py</span><span class="p">.</span><span class="nn">Object</span><span class="p">.</span><span class="n">t</span> <span class="o">-&gt;</span> <span class="n">x</span><span class="o">:[&gt;`</span><span class="nc">ArrayLike</span><span class="o">]</span> <span class="nn">Np</span><span class="p">.</span><span class="nn">Obj</span><span class="p">.</span><span class="n">t</span> <span class="o">-&gt;</span> <span class="o">[&gt;</span> <span class="n">tag</span><span class="o">]</span> <span class="nn">Obj</span><span class="p">.</span><span class="n">t</span> <span class="o">-&gt;</span> <span class="n">t</span>
</code></pre></div>

<p>Online VB with Mini-Batch update.</p>
<h2 id="parameters_40">Parameters<a class="headerlink" href="#parameters_40" title="Permanent link">&para;</a></h2>
<p>X : array-like or sparse matrix, shape=(n_samples, n_features)
Document word matrix.</p>
<p>y : Ignored</p>
<h2 id="returns_38">Returns<a class="headerlink" href="#returns_38" title="Permanent link">&para;</a></h2>
<p>self</p>
<div class="highlight"><pre><span></span><code><span class="k">val</span> <span class="n">perplexity</span> <span class="o">:</span> <span class="o">?</span><span class="n">sub_sampling</span><span class="o">:</span><span class="kt">bool</span> <span class="o">-&gt;</span> <span class="n">x</span><span class="o">:[&gt;`</span><span class="nc">ArrayLike</span><span class="o">]</span> <span class="nn">Np</span><span class="p">.</span><span class="nn">Obj</span><span class="p">.</span><span class="n">t</span> <span class="o">-&gt;</span> <span class="o">[&gt;</span> <span class="n">tag</span><span class="o">]</span> <span class="nn">Obj</span><span class="p">.</span><span class="n">t</span> <span class="o">-&gt;</span> <span class="kt">float</span>
</code></pre></div>

<p>Calculate approximate perplexity for data X.</p>
<p>Perplexity is defined as exp(-1. * log-likelihood per word)</p>
<p>.. versionchanged:: 0.19
<em>doc_topic_distr</em> argument has been deprecated and is ignored
because user no longer has access to unnormalized distribution</p>
<h2 id="parameters_41">Parameters<a class="headerlink" href="#parameters_41" title="Permanent link">&para;</a></h2>
<p>X : array-like or sparse matrix, [n_samples, n_features]
Document word matrix.</p>
<p>sub_sampling : bool
Do sub-sampling or not.</p>
<h2 id="returns_39">Returns<a class="headerlink" href="#returns_39" title="Permanent link">&para;</a></h2>
<p>score : float
Perplexity score.</p>
<div class="highlight"><pre><span></span><code><span class="k">val</span> <span class="n">score</span> <span class="o">:</span> <span class="o">?</span><span class="n">y</span><span class="o">:</span><span class="nn">Py</span><span class="p">.</span><span class="nn">Object</span><span class="p">.</span><span class="n">t</span> <span class="o">-&gt;</span> <span class="n">x</span><span class="o">:[&gt;`</span><span class="nc">ArrayLike</span><span class="o">]</span> <span class="nn">Np</span><span class="p">.</span><span class="nn">Obj</span><span class="p">.</span><span class="n">t</span> <span class="o">-&gt;</span> <span class="o">[&gt;</span> <span class="n">tag</span><span class="o">]</span> <span class="nn">Obj</span><span class="p">.</span><span class="n">t</span> <span class="o">-&gt;</span> <span class="kt">float</span>
</code></pre></div>

<p>Calculate approximate log-likelihood as score.</p>
<h2 id="parameters_42">Parameters<a class="headerlink" href="#parameters_42" title="Permanent link">&para;</a></h2>
<p>X : array-like or sparse matrix, shape=(n_samples, n_features)
Document word matrix.</p>
<p>y : Ignored</p>
<h2 id="returns_40">Returns<a class="headerlink" href="#returns_40" title="Permanent link">&para;</a></h2>
<p>score : float
Use approximate bound as score.</p>
<div class="highlight"><pre><span></span><code><span class="k">val</span> <span class="n">set_params</span> <span class="o">:</span> <span class="o">?</span><span class="n">params</span><span class="o">:(</span><span class="kt">string</span> <span class="o">*</span> <span class="nn">Py</span><span class="p">.</span><span class="nn">Object</span><span class="p">.</span><span class="n">t</span><span class="o">)</span> <span class="kt">list</span> <span class="o">-&gt;</span> <span class="o">[&gt;</span> <span class="n">tag</span><span class="o">]</span> <span class="nn">Obj</span><span class="p">.</span><span class="n">t</span> <span class="o">-&gt;</span> <span class="n">t</span>
</code></pre></div>

<p>Set the parameters of this estimator.</p>
<p>The method works on simple estimators as well as on nested objects
(such as pipelines). The latter have parameters of the form
<code>&lt;component&gt;__&lt;parameter&gt;</code> so that it's possible to update each
component of a nested object.</p>
<h2 id="parameters_43">Parameters<a class="headerlink" href="#parameters_43" title="Permanent link">&para;</a></h2>
<p>**params : dict
Estimator parameters.</p>
<h2 id="returns_41">Returns<a class="headerlink" href="#returns_41" title="Permanent link">&para;</a></h2>
<p>self : object
Estimator instance.</p>
<div class="highlight"><pre><span></span><code><span class="k">val</span> <span class="n">transform</span> <span class="o">:</span> <span class="n">x</span><span class="o">:[&gt;`</span><span class="nc">ArrayLike</span><span class="o">]</span> <span class="nn">Np</span><span class="p">.</span><span class="nn">Obj</span><span class="p">.</span><span class="n">t</span> <span class="o">-&gt;</span> <span class="o">[&gt;</span> <span class="n">tag</span><span class="o">]</span> <span class="nn">Obj</span><span class="p">.</span><span class="n">t</span> <span class="o">-&gt;</span> <span class="o">[&gt;`</span><span class="nc">ArrayLike</span><span class="o">]</span> <span class="nn">Np</span><span class="p">.</span><span class="nn">Obj</span><span class="p">.</span><span class="n">t</span>
</code></pre></div>

<p>Transform data X according to the fitted model.</p>
<p>.. versionchanged:: 0.18
<em>doc_topic_distr</em> is now normalized</p>
<h2 id="parameters_44">Parameters<a class="headerlink" href="#parameters_44" title="Permanent link">&para;</a></h2>
<p>X : array-like or sparse matrix, shape=(n_samples, n_features)
Document word matrix.</p>
<h2 id="returns_42">Returns<a class="headerlink" href="#returns_42" title="Permanent link">&para;</a></h2>
<p>doc_topic_distr : shape=(n_samples, n_components)
Document topic distribution for X.</p>
<p>Attribute components_: get value or raise Not_found if None.</p>
<div class="highlight"><pre><span></span><code><span class="k">val</span> <span class="n">components_</span> <span class="o">:</span> <span class="n">t</span> <span class="o">-&gt;</span> <span class="o">[&gt;`</span><span class="nc">ArrayLike</span><span class="o">]</span> <span class="nn">Np</span><span class="p">.</span><span class="nn">Obj</span><span class="p">.</span><span class="n">t</span>
</code></pre></div>

<p>Attribute components_: get value as an option.</p>
<div class="highlight"><pre><span></span><code><span class="k">val</span> <span class="n">components_opt</span> <span class="o">:</span> <span class="n">t</span> <span class="o">-&gt;</span> <span class="o">([&gt;`</span><span class="nc">ArrayLike</span><span class="o">]</span> <span class="nn">Np</span><span class="p">.</span><span class="nn">Obj</span><span class="p">.</span><span class="n">t</span><span class="o">)</span> <span class="n">option</span>
</code></pre></div>

<p>Attribute n_batch_iter_: get value or raise Not_found if None.</p>
<div class="highlight"><pre><span></span><code><span class="k">val</span> <span class="n">n_batch_iter_</span> <span class="o">:</span> <span class="n">t</span> <span class="o">-&gt;</span> <span class="kt">int</span>
</code></pre></div>

<p>Attribute n_batch_iter_: get value as an option.</p>
<div class="highlight"><pre><span></span><code><span class="k">val</span> <span class="n">n_batch_iter_opt</span> <span class="o">:</span> <span class="n">t</span> <span class="o">-&gt;</span> <span class="o">(</span><span class="kt">int</span><span class="o">)</span> <span class="n">option</span>
</code></pre></div>

<p>Attribute n_iter_: get value or raise Not_found if None.</p>
<div class="highlight"><pre><span></span><code><span class="k">val</span> <span class="n">n_iter_</span> <span class="o">:</span> <span class="n">t</span> <span class="o">-&gt;</span> <span class="kt">int</span>
</code></pre></div>

<p>Attribute n_iter_: get value as an option.</p>
<div class="highlight"><pre><span></span><code><span class="k">val</span> <span class="n">n_iter_opt</span> <span class="o">:</span> <span class="n">t</span> <span class="o">-&gt;</span> <span class="o">(</span><span class="kt">int</span><span class="o">)</span> <span class="n">option</span>
</code></pre></div>

<p>Attribute bound_: get value or raise Not_found if None.</p>
<div class="highlight"><pre><span></span><code><span class="k">val</span> <span class="n">bound_</span> <span class="o">:</span> <span class="n">t</span> <span class="o">-&gt;</span> <span class="kt">float</span>
</code></pre></div>

<p>Attribute bound_: get value as an option.</p>
<div class="highlight"><pre><span></span><code><span class="k">val</span> <span class="n">bound_opt</span> <span class="o">:</span> <span class="n">t</span> <span class="o">-&gt;</span> <span class="o">(</span><span class="kt">float</span><span class="o">)</span> <span class="n">option</span>
</code></pre></div>

<p>Attribute doc_topic_prior_: get value or raise Not_found if None.</p>
<div class="highlight"><pre><span></span><code><span class="k">val</span> <span class="n">doc_topic_prior_</span> <span class="o">:</span> <span class="n">t</span> <span class="o">-&gt;</span> <span class="kt">float</span>
</code></pre></div>

<p>Attribute doc_topic_prior_: get value as an option.</p>
<div class="highlight"><pre><span></span><code><span class="k">val</span> <span class="n">doc_topic_prior_opt</span> <span class="o">:</span> <span class="n">t</span> <span class="o">-&gt;</span> <span class="o">(</span><span class="kt">float</span><span class="o">)</span> <span class="n">option</span>
</code></pre></div>

<p>Attribute topic_word_prior_: get value or raise Not_found if None.</p>
<div class="highlight"><pre><span></span><code><span class="k">val</span> <span class="n">topic_word_prior_</span> <span class="o">:</span> <span class="n">t</span> <span class="o">-&gt;</span> <span class="kt">float</span>
</code></pre></div>

<p>Attribute topic_word_prior_: get value as an option.</p>
<div class="highlight"><pre><span></span><code><span class="k">val</span> <span class="n">topic_word_prior_opt</span> <span class="o">:</span> <span class="n">t</span> <span class="o">-&gt;</span> <span class="o">(</span><span class="kt">float</span><span class="o">)</span> <span class="n">option</span>
</code></pre></div>

<p>Print the object to a human-readable representation.</p>
<div class="highlight"><pre><span></span><code><span class="k">val</span> <span class="n">to_string</span> <span class="o">:</span> <span class="n">t</span> <span class="o">-&gt;</span> <span class="kt">string</span>
</code></pre></div>

<p>Print the object to a human-readable representation.</p>
<div class="highlight"><pre><span></span><code><span class="k">val</span> <span class="n">show</span> <span class="o">:</span> <span class="n">t</span> <span class="o">-&gt;</span> <span class="kt">string</span>
</code></pre></div>

<p>Pretty-print the object to a formatter.</p>
<div class="highlight"><pre><span></span><code><span class="k">val</span> <span class="n">pp</span> <span class="o">:</span> <span class="nn">Format</span><span class="p">.</span><span class="n">formatter</span> <span class="o">-&gt;</span> <span class="n">t</span> <span class="o">-&gt;</span> <span class="kt">unit</span> <span class="o">[@@</span><span class="n">ocaml</span><span class="o">.</span><span class="n">toplevel_printer</span><span class="o">]</span>



<span class="k">module</span> <span class="nc">MiniBatchDictionaryLearning</span> <span class="o">:</span> <span class="k">sig</span>
<span class="k">type</span> <span class="n">tag</span> <span class="o">=</span> <span class="o">[`</span><span class="nc">MiniBatchDictionaryLearning</span><span class="o">]</span>
<span class="k">type</span> <span class="n">t</span> <span class="o">=</span> <span class="o">[`</span><span class="nc">BaseEstimator</span> <span class="o">|</span> <span class="o">`</span><span class="nc">MiniBatchDictionaryLearning</span> <span class="o">|</span> <span class="o">`</span><span class="nc">Object</span> <span class="o">|</span> <span class="o">`</span><span class="nc">SparseCodingMixin</span> <span class="o">|</span> <span class="o">`</span><span class="nc">TransformerMixin</span><span class="o">]</span> <span class="nn">Obj</span><span class="p">.</span><span class="n">t</span>
<span class="k">val</span> <span class="n">of_pyobject</span> <span class="o">:</span> <span class="nn">Py</span><span class="p">.</span><span class="nn">Object</span><span class="p">.</span><span class="n">t</span> <span class="o">-&gt;</span> <span class="n">t</span>
<span class="k">val</span> <span class="n">to_pyobject</span> <span class="o">:</span> <span class="o">[&gt;</span> <span class="n">tag</span><span class="o">]</span> <span class="nn">Obj</span><span class="p">.</span><span class="n">t</span> <span class="o">-&gt;</span> <span class="nn">Py</span><span class="p">.</span><span class="nn">Object</span><span class="p">.</span><span class="n">t</span>

<span class="k">val</span> <span class="n">as_transformer</span> <span class="o">:</span> <span class="n">t</span> <span class="o">-&gt;</span> <span class="o">[`</span><span class="nc">TransformerMixin</span><span class="o">]</span> <span class="nn">Obj</span><span class="p">.</span><span class="n">t</span>
<span class="k">val</span> <span class="n">as_estimator</span> <span class="o">:</span> <span class="n">t</span> <span class="o">-&gt;</span> <span class="o">[`</span><span class="nc">BaseEstimator</span><span class="o">]</span> <span class="nn">Obj</span><span class="p">.</span><span class="n">t</span>
<span class="k">val</span> <span class="n">as_sparse_coding</span> <span class="o">:</span> <span class="n">t</span> <span class="o">-&gt;</span> <span class="o">[`</span><span class="nc">SparseCodingMixin</span><span class="o">]</span> <span class="nn">Obj</span><span class="p">.</span><span class="n">t</span>
<span class="k">val</span> <span class="n">create</span> <span class="o">:</span> <span class="o">?</span><span class="n">n_components</span><span class="o">:</span><span class="kt">int</span> <span class="o">-&gt;</span> <span class="o">?</span><span class="n">alpha</span><span class="o">:</span><span class="kt">float</span> <span class="o">-&gt;</span> <span class="o">?</span><span class="n">n_iter</span><span class="o">:</span><span class="kt">int</span> <span class="o">-&gt;</span> <span class="o">?</span><span class="n">fit_algorithm</span><span class="o">:[`</span><span class="nc">Lars</span> <span class="o">|</span> <span class="o">`</span><span class="nc">Cd</span><span class="o">]</span> <span class="o">-&gt;</span> <span class="o">?</span><span class="n">n_jobs</span><span class="o">:</span><span class="kt">int</span> <span class="o">-&gt;</span> <span class="o">?</span><span class="n">batch_size</span><span class="o">:</span><span class="kt">int</span> <span class="o">-&gt;</span> <span class="o">?</span><span class="n">shuffle</span><span class="o">:</span><span class="kt">bool</span> <span class="o">-&gt;</span> <span class="o">?</span><span class="n">dict_init</span><span class="o">:[&gt;`</span><span class="nc">ArrayLike</span><span class="o">]</span> <span class="nn">Np</span><span class="p">.</span><span class="nn">Obj</span><span class="p">.</span><span class="n">t</span> <span class="o">-&gt;</span> <span class="o">?</span><span class="n">transform_algorithm</span><span class="o">:[`</span><span class="nc">Lasso_lars</span> <span class="o">|</span> <span class="o">`</span><span class="nc">Lasso_cd</span> <span class="o">|</span> <span class="o">`</span><span class="nc">Lars</span> <span class="o">|</span> <span class="o">`</span><span class="nc">Omp</span> <span class="o">|</span> <span class="o">`</span><span class="nc">Threshold</span><span class="o">]</span> <span class="o">-&gt;</span> <span class="o">?</span><span class="n">transform_n_nonzero_coefs</span><span class="o">:[`</span><span class="nc">I</span> <span class="k">of</span> <span class="kt">int</span> <span class="o">|</span> <span class="o">`</span><span class="nc">T_0_1_</span> <span class="k">of</span> <span class="nn">Py</span><span class="p">.</span><span class="nn">Object</span><span class="p">.</span><span class="n">t</span><span class="o">]</span> <span class="o">-&gt;</span> <span class="o">?</span><span class="n">transform_alpha</span><span class="o">:</span><span class="kt">float</span> <span class="o">-&gt;</span> <span class="o">?</span><span class="n">verbose</span><span class="o">:</span><span class="kt">int</span> <span class="o">-&gt;</span> <span class="o">?</span><span class="n">split_sign</span><span class="o">:</span><span class="kt">bool</span> <span class="o">-&gt;</span> <span class="o">?</span><span class="n">random_state</span><span class="o">:</span><span class="kt">int</span> <span class="o">-&gt;</span> <span class="o">?</span><span class="n">positive_code</span><span class="o">:</span><span class="kt">bool</span> <span class="o">-&gt;</span> <span class="o">?</span><span class="n">positive_dict</span><span class="o">:</span><span class="kt">bool</span> <span class="o">-&gt;</span> <span class="o">?</span><span class="n">transform_max_iter</span><span class="o">:</span><span class="kt">int</span> <span class="o">-&gt;</span> <span class="kt">unit</span> <span class="o">-&gt;</span> <span class="n">t</span>
</code></pre></div>

<p>Mini-batch dictionary learning</p>
<p>Finds a dictionary (a set of atoms) that can best be used to represent data
using a sparse code.</p>
<p>Solves the optimization problem::</p>
<p>(U^<em>,V^</em> ) = argmin 0.5 || Y - U V ||_2^2 + alpha * || U ||_1
(U,V)
with || V_k ||_2 = 1 for all  0 &lt;= k &lt; n_components</p>
<p>Read more in the :ref:<code>User Guide &lt;DictionaryLearning&gt;</code>.</p>
<h2 id="parameters_45">Parameters<a class="headerlink" href="#parameters_45" title="Permanent link">&para;</a></h2>
<p>n_components : int,
number of dictionary elements to extract</p>
<p>alpha : float,
sparsity controlling parameter</p>
<p>n_iter : int,
total number of iterations to perform</p>
<p>fit_algorithm : {'lars', 'cd'}
lars: uses the least angle regression method to solve the lasso problem
(linear_model.lars_path)
cd: uses the coordinate descent method to compute the
Lasso solution (linear_model.Lasso). Lars will be faster if
the estimated components are sparse.</p>
<p>n_jobs : int or None, optional (default=None)
Number of parallel jobs to run.
<code>None</code> means 1 unless in a :obj:<code>joblib.parallel_backend</code> context.
<code>-1</code> means using all processors. See :term:<code>Glossary &lt;n_jobs&gt;</code>
for more details.</p>
<p>batch_size : int,
number of samples in each mini-batch</p>
<p>shuffle : bool,
whether to shuffle the samples before forming batches</p>
<p>dict_init : array of shape (n_components, n_features),
initial value of the dictionary for warm restart scenarios</p>
<p>transform_algorithm : {'lasso_lars', 'lasso_cd', 'lars', 'omp',     'threshold'}
Algorithm used to transform the data.
lars: uses the least angle regression method (linear_model.lars_path)
lasso_lars: uses Lars to compute the Lasso solution
lasso_cd: uses the coordinate descent method to compute the
Lasso solution (linear_model.Lasso). lasso_lars will be faster if
the estimated components are sparse.
omp: uses orthogonal matching pursuit to estimate the sparse solution
threshold: squashes to zero all coefficients less than alpha from
the projection dictionary * X'</p>
<p>transform_n_nonzero_coefs : int, <code>0.1 * n_features</code> by default
Number of nonzero coefficients to target in each column of the
solution. This is only used by <code>algorithm='lars'</code> and <code>algorithm='omp'</code>
and is overridden by <code>alpha</code> in the <code>omp</code> case.</p>
<p>transform_alpha : float, 1. by default
If <code>algorithm='lasso_lars'</code> or <code>algorithm='lasso_cd'</code>, <code>alpha</code> is the
penalty applied to the L1 norm.
If <code>algorithm='threshold'</code>, <code>alpha</code> is the absolute value of the
threshold below which coefficients will be squashed to zero.
If <code>algorithm='omp'</code>, <code>alpha</code> is the tolerance parameter: the value of
the reconstruction error targeted. In this case, it overrides
<code>n_nonzero_coefs</code>.</p>
<p>verbose : bool, optional (default: False)
To control the verbosity of the procedure.</p>
<p>split_sign : bool, False by default
Whether to split the sparse feature vector into the concatenation of
its negative part and its positive part. This can improve the
performance of downstream classifiers.</p>
<p>random_state : int, RandomState instance or None, optional (default=None)
If int, random_state is the seed used by the random number generator;
If RandomState instance, random_state is the random number generator;
If None, the random number generator is the RandomState instance used
by <code>np.random</code>.</p>
<p>positive_code : bool
Whether to enforce positivity when finding the code.</p>
<p>.. versionadded:: 0.20</p>
<p>positive_dict : bool
Whether to enforce positivity when finding the dictionary.</p>
<p>.. versionadded:: 0.20</p>
<p>transform_max_iter : int, optional (default=1000)
Maximum number of iterations to perform if <code>algorithm='lasso_cd'</code> or
<code>lasso_lars</code>.</p>
<p>.. versionadded:: 0.22</p>
<h2 id="attributes_6">Attributes<a class="headerlink" href="#attributes_6" title="Permanent link">&para;</a></h2>
<p>components_ : array, [n_components, n_features]
components extracted from the data</p>
<p>inner_stats_ : tuple of (A, B) ndarrays
Internal sufficient statistics that are kept by the algorithm.
Keeping them is useful in online settings, to avoid losing the
history of the evolution, but they shouldn't have any use for the
end user.
A (n_components, n_components) is the dictionary covariance matrix.
B (n_features, n_components) is the data approximation matrix</p>
<p>n_iter_ : int
Number of iterations run.</p>
<p>iter_offset_ : int
The number of iteration on data batches that has been
performed before.</p>
<p>random_state_ : RandomState
RandomState instance that is generated either from a seed, the random
number generattor or by <code>np.random</code>.</p>
<h2 id="notes_4">Notes<a class="headerlink" href="#notes_4" title="Permanent link">&para;</a></h2>
<p><strong>References:</strong></p>
<p>J. Mairal, F. Bach, J. Ponce, G. Sapiro, 2009: Online dictionary learning
for sparse coding (https://www.di.ens.fr/sierra/pdfs/icml09.pdf)</p>
<h2 id="see-also_3">See also<a class="headerlink" href="#see-also_3" title="Permanent link">&para;</a></h2>
<p>SparseCoder
DictionaryLearning
SparsePCA
MiniBatchSparsePCA</p>
<div class="highlight"><pre><span></span><code><span class="k">val</span> <span class="n">fit</span> <span class="o">:</span> <span class="o">?</span><span class="n">y</span><span class="o">:</span><span class="nn">Py</span><span class="p">.</span><span class="nn">Object</span><span class="p">.</span><span class="n">t</span> <span class="o">-&gt;</span> <span class="n">x</span><span class="o">:[&gt;`</span><span class="nc">ArrayLike</span><span class="o">]</span> <span class="nn">Np</span><span class="p">.</span><span class="nn">Obj</span><span class="p">.</span><span class="n">t</span> <span class="o">-&gt;</span> <span class="o">[&gt;</span> <span class="n">tag</span><span class="o">]</span> <span class="nn">Obj</span><span class="p">.</span><span class="n">t</span> <span class="o">-&gt;</span> <span class="n">t</span>
</code></pre></div>

<p>Fit the model from data in X.</p>
<h2 id="parameters_46">Parameters<a class="headerlink" href="#parameters_46" title="Permanent link">&para;</a></h2>
<p>X : array-like, shape (n_samples, n_features)
Training vector, where n_samples in the number of samples
and n_features is the number of features.</p>
<p>y : Ignored</p>
<h2 id="returns_43">Returns<a class="headerlink" href="#returns_43" title="Permanent link">&para;</a></h2>
<p>self : object
Returns the instance itself.</p>
<div class="highlight"><pre><span></span><code><span class="k">val</span> <span class="n">fit_transform</span> <span class="o">:</span> <span class="o">?</span><span class="n">y</span><span class="o">:[&gt;`</span><span class="nc">ArrayLike</span><span class="o">]</span> <span class="nn">Np</span><span class="p">.</span><span class="nn">Obj</span><span class="p">.</span><span class="n">t</span> <span class="o">-&gt;</span> <span class="o">?</span><span class="n">fit_params</span><span class="o">:(</span><span class="kt">string</span> <span class="o">*</span> <span class="nn">Py</span><span class="p">.</span><span class="nn">Object</span><span class="p">.</span><span class="n">t</span><span class="o">)</span> <span class="kt">list</span> <span class="o">-&gt;</span> <span class="n">x</span><span class="o">:[&gt;`</span><span class="nc">ArrayLike</span><span class="o">]</span> <span class="nn">Np</span><span class="p">.</span><span class="nn">Obj</span><span class="p">.</span><span class="n">t</span> <span class="o">-&gt;</span> <span class="o">[&gt;</span> <span class="n">tag</span><span class="o">]</span> <span class="nn">Obj</span><span class="p">.</span><span class="n">t</span> <span class="o">-&gt;</span> <span class="o">[&gt;`</span><span class="nc">ArrayLike</span><span class="o">]</span> <span class="nn">Np</span><span class="p">.</span><span class="nn">Obj</span><span class="p">.</span><span class="n">t</span>
</code></pre></div>

<p>Fit to data, then transform it.</p>
<p>Fits transformer to X and y with optional parameters fit_params
and returns a transformed version of X.</p>
<h2 id="parameters_47">Parameters<a class="headerlink" href="#parameters_47" title="Permanent link">&para;</a></h2>
<p>X : numpy array of shape [n_samples, n_features]
Training set.</p>
<p>y : numpy array of shape [n_samples]
Target values.</p>
<p>**fit_params : dict
Additional fit parameters.</p>
<h2 id="returns_44">Returns<a class="headerlink" href="#returns_44" title="Permanent link">&para;</a></h2>
<p>X_new : numpy array of shape [n_samples, n_features_new]
Transformed array.</p>
<div class="highlight"><pre><span></span><code><span class="k">val</span> <span class="n">get_params</span> <span class="o">:</span> <span class="o">?</span><span class="n">deep</span><span class="o">:</span><span class="kt">bool</span> <span class="o">-&gt;</span> <span class="o">[&gt;</span> <span class="n">tag</span><span class="o">]</span> <span class="nn">Obj</span><span class="p">.</span><span class="n">t</span> <span class="o">-&gt;</span> <span class="nn">Dict</span><span class="p">.</span><span class="n">t</span>
</code></pre></div>

<p>Get parameters for this estimator.</p>
<h2 id="parameters_48">Parameters<a class="headerlink" href="#parameters_48" title="Permanent link">&para;</a></h2>
<p>deep : bool, default=True
If True, will return the parameters for this estimator and
contained subobjects that are estimators.</p>
<h2 id="returns_45">Returns<a class="headerlink" href="#returns_45" title="Permanent link">&para;</a></h2>
<p>params : mapping of string to any
Parameter names mapped to their values.</p>
<div class="highlight"><pre><span></span><code><span class="k">val</span> <span class="n">partial_fit</span> <span class="o">:</span> <span class="o">?</span><span class="n">y</span><span class="o">:</span><span class="nn">Py</span><span class="p">.</span><span class="nn">Object</span><span class="p">.</span><span class="n">t</span> <span class="o">-&gt;</span> <span class="o">?</span><span class="n">iter_offset</span><span class="o">:</span><span class="kt">int</span> <span class="o">-&gt;</span> <span class="n">x</span><span class="o">:[&gt;`</span><span class="nc">ArrayLike</span><span class="o">]</span> <span class="nn">Np</span><span class="p">.</span><span class="nn">Obj</span><span class="p">.</span><span class="n">t</span> <span class="o">-&gt;</span> <span class="o">[&gt;</span> <span class="n">tag</span><span class="o">]</span> <span class="nn">Obj</span><span class="p">.</span><span class="n">t</span> <span class="o">-&gt;</span> <span class="n">t</span>
</code></pre></div>

<p>Updates the model using the data in X as a mini-batch.</p>
<h2 id="parameters_49">Parameters<a class="headerlink" href="#parameters_49" title="Permanent link">&para;</a></h2>
<p>X : array-like, shape (n_samples, n_features)
Training vector, where n_samples in the number of samples
and n_features is the number of features.</p>
<p>y : Ignored</p>
<p>iter_offset : integer, optional
The number of iteration on data batches that has been
performed before this call to partial_fit. This is optional:
if no number is passed, the memory of the object is
used.</p>
<h2 id="returns_46">Returns<a class="headerlink" href="#returns_46" title="Permanent link">&para;</a></h2>
<p>self : object
Returns the instance itself.</p>
<div class="highlight"><pre><span></span><code><span class="k">val</span> <span class="n">set_params</span> <span class="o">:</span> <span class="o">?</span><span class="n">params</span><span class="o">:(</span><span class="kt">string</span> <span class="o">*</span> <span class="nn">Py</span><span class="p">.</span><span class="nn">Object</span><span class="p">.</span><span class="n">t</span><span class="o">)</span> <span class="kt">list</span> <span class="o">-&gt;</span> <span class="o">[&gt;</span> <span class="n">tag</span><span class="o">]</span> <span class="nn">Obj</span><span class="p">.</span><span class="n">t</span> <span class="o">-&gt;</span> <span class="n">t</span>
</code></pre></div>

<p>Set the parameters of this estimator.</p>
<p>The method works on simple estimators as well as on nested objects
(such as pipelines). The latter have parameters of the form
<code>&lt;component&gt;__&lt;parameter&gt;</code> so that it's possible to update each
component of a nested object.</p>
<h2 id="parameters_50">Parameters<a class="headerlink" href="#parameters_50" title="Permanent link">&para;</a></h2>
<p>**params : dict
Estimator parameters.</p>
<h2 id="returns_47">Returns<a class="headerlink" href="#returns_47" title="Permanent link">&para;</a></h2>
<p>self : object
Estimator instance.</p>
<div class="highlight"><pre><span></span><code><span class="k">val</span> <span class="n">transform</span> <span class="o">:</span> <span class="n">x</span><span class="o">:[&gt;`</span><span class="nc">ArrayLike</span><span class="o">]</span> <span class="nn">Np</span><span class="p">.</span><span class="nn">Obj</span><span class="p">.</span><span class="n">t</span> <span class="o">-&gt;</span> <span class="o">[&gt;</span> <span class="n">tag</span><span class="o">]</span> <span class="nn">Obj</span><span class="p">.</span><span class="n">t</span> <span class="o">-&gt;</span> <span class="o">[&gt;`</span><span class="nc">ArrayLike</span><span class="o">]</span> <span class="nn">Np</span><span class="p">.</span><span class="nn">Obj</span><span class="p">.</span><span class="n">t</span>
</code></pre></div>

<p>Encode the data as a sparse combination of the dictionary atoms.</p>
<p>Coding method is determined by the object parameter
<code>transform_algorithm</code>.</p>
<h2 id="parameters_51">Parameters<a class="headerlink" href="#parameters_51" title="Permanent link">&para;</a></h2>
<p>X : array of shape (n_samples, n_features)
Test data to be transformed, must have the same number of
features as the data used to train the model.</p>
<h2 id="returns_48">Returns<a class="headerlink" href="#returns_48" title="Permanent link">&para;</a></h2>
<p>X_new : array, shape (n_samples, n_components)
Transformed data</p>
<p>Attribute components_: get value or raise Not_found if None.</p>
<div class="highlight"><pre><span></span><code><span class="k">val</span> <span class="n">components_</span> <span class="o">:</span> <span class="n">t</span> <span class="o">-&gt;</span> <span class="o">[&gt;`</span><span class="nc">ArrayLike</span><span class="o">]</span> <span class="nn">Np</span><span class="p">.</span><span class="nn">Obj</span><span class="p">.</span><span class="n">t</span>
</code></pre></div>

<p>Attribute components_: get value as an option.</p>
<div class="highlight"><pre><span></span><code><span class="k">val</span> <span class="n">components_opt</span> <span class="o">:</span> <span class="n">t</span> <span class="o">-&gt;</span> <span class="o">([&gt;`</span><span class="nc">ArrayLike</span><span class="o">]</span> <span class="nn">Np</span><span class="p">.</span><span class="nn">Obj</span><span class="p">.</span><span class="n">t</span><span class="o">)</span> <span class="n">option</span>
</code></pre></div>

<p>Attribute inner_stats_: get value or raise Not_found if None.</p>
<div class="highlight"><pre><span></span><code><span class="k">val</span> <span class="n">inner_stats_</span> <span class="o">:</span> <span class="n">t</span> <span class="o">-&gt;</span> <span class="o">([&gt;`</span><span class="nc">ArrayLike</span><span class="o">]</span> <span class="nn">Np</span><span class="p">.</span><span class="nn">Obj</span><span class="p">.</span><span class="n">t</span> <span class="o">*</span> <span class="o">[&gt;`</span><span class="nc">ArrayLike</span><span class="o">]</span> <span class="nn">Np</span><span class="p">.</span><span class="nn">Obj</span><span class="p">.</span><span class="n">t</span><span class="o">)</span>
</code></pre></div>

<p>Attribute inner_stats_: get value as an option.</p>
<div class="highlight"><pre><span></span><code><span class="k">val</span> <span class="n">inner_stats_opt</span> <span class="o">:</span> <span class="n">t</span> <span class="o">-&gt;</span> <span class="o">(([&gt;`</span><span class="nc">ArrayLike</span><span class="o">]</span> <span class="nn">Np</span><span class="p">.</span><span class="nn">Obj</span><span class="p">.</span><span class="n">t</span> <span class="o">*</span> <span class="o">[&gt;`</span><span class="nc">ArrayLike</span><span class="o">]</span> <span class="nn">Np</span><span class="p">.</span><span class="nn">Obj</span><span class="p">.</span><span class="n">t</span><span class="o">))</span> <span class="n">option</span>
</code></pre></div>

<p>Attribute n_iter_: get value or raise Not_found if None.</p>
<div class="highlight"><pre><span></span><code><span class="k">val</span> <span class="n">n_iter_</span> <span class="o">:</span> <span class="n">t</span> <span class="o">-&gt;</span> <span class="kt">int</span>
</code></pre></div>

<p>Attribute n_iter_: get value as an option.</p>
<div class="highlight"><pre><span></span><code><span class="k">val</span> <span class="n">n_iter_opt</span> <span class="o">:</span> <span class="n">t</span> <span class="o">-&gt;</span> <span class="o">(</span><span class="kt">int</span><span class="o">)</span> <span class="n">option</span>
</code></pre></div>

<p>Attribute iter_offset_: get value or raise Not_found if None.</p>
<div class="highlight"><pre><span></span><code><span class="k">val</span> <span class="n">iter_offset_</span> <span class="o">:</span> <span class="n">t</span> <span class="o">-&gt;</span> <span class="kt">int</span>
</code></pre></div>

<p>Attribute iter_offset_: get value as an option.</p>
<div class="highlight"><pre><span></span><code><span class="k">val</span> <span class="n">iter_offset_opt</span> <span class="o">:</span> <span class="n">t</span> <span class="o">-&gt;</span> <span class="o">(</span><span class="kt">int</span><span class="o">)</span> <span class="n">option</span>
</code></pre></div>

<p>Attribute random_state_: get value or raise Not_found if None.</p>
<div class="highlight"><pre><span></span><code><span class="k">val</span> <span class="n">random_state_</span> <span class="o">:</span> <span class="n">t</span> <span class="o">-&gt;</span> <span class="nn">Py</span><span class="p">.</span><span class="nn">Object</span><span class="p">.</span><span class="n">t</span>
</code></pre></div>

<p>Attribute random_state_: get value as an option.</p>
<div class="highlight"><pre><span></span><code><span class="k">val</span> <span class="n">random_state_opt</span> <span class="o">:</span> <span class="n">t</span> <span class="o">-&gt;</span> <span class="o">(</span><span class="nn">Py</span><span class="p">.</span><span class="nn">Object</span><span class="p">.</span><span class="n">t</span><span class="o">)</span> <span class="n">option</span>
</code></pre></div>

<p>Print the object to a human-readable representation.</p>
<div class="highlight"><pre><span></span><code><span class="k">val</span> <span class="n">to_string</span> <span class="o">:</span> <span class="n">t</span> <span class="o">-&gt;</span> <span class="kt">string</span>
</code></pre></div>

<p>Print the object to a human-readable representation.</p>
<div class="highlight"><pre><span></span><code><span class="k">val</span> <span class="n">show</span> <span class="o">:</span> <span class="n">t</span> <span class="o">-&gt;</span> <span class="kt">string</span>
</code></pre></div>

<p>Pretty-print the object to a formatter.</p>
<div class="highlight"><pre><span></span><code><span class="k">val</span> <span class="n">pp</span> <span class="o">:</span> <span class="nn">Format</span><span class="p">.</span><span class="n">formatter</span> <span class="o">-&gt;</span> <span class="n">t</span> <span class="o">-&gt;</span> <span class="kt">unit</span> <span class="o">[@@</span><span class="n">ocaml</span><span class="o">.</span><span class="n">toplevel_printer</span><span class="o">]</span>



<span class="k">module</span> <span class="nc">MiniBatchSparsePCA</span> <span class="o">:</span> <span class="k">sig</span>
<span class="k">type</span> <span class="n">tag</span> <span class="o">=</span> <span class="o">[`</span><span class="nc">MiniBatchSparsePCA</span><span class="o">]</span>
<span class="k">type</span> <span class="n">t</span> <span class="o">=</span> <span class="o">[`</span><span class="nc">BaseEstimator</span> <span class="o">|</span> <span class="o">`</span><span class="nc">MiniBatchSparsePCA</span> <span class="o">|</span> <span class="o">`</span><span class="nc">Object</span> <span class="o">|</span> <span class="o">`</span><span class="nc">TransformerMixin</span><span class="o">]</span> <span class="nn">Obj</span><span class="p">.</span><span class="n">t</span>
<span class="k">val</span> <span class="n">of_pyobject</span> <span class="o">:</span> <span class="nn">Py</span><span class="p">.</span><span class="nn">Object</span><span class="p">.</span><span class="n">t</span> <span class="o">-&gt;</span> <span class="n">t</span>
<span class="k">val</span> <span class="n">to_pyobject</span> <span class="o">:</span> <span class="o">[&gt;</span> <span class="n">tag</span><span class="o">]</span> <span class="nn">Obj</span><span class="p">.</span><span class="n">t</span> <span class="o">-&gt;</span> <span class="nn">Py</span><span class="p">.</span><span class="nn">Object</span><span class="p">.</span><span class="n">t</span>

<span class="k">val</span> <span class="n">as_transformer</span> <span class="o">:</span> <span class="n">t</span> <span class="o">-&gt;</span> <span class="o">[`</span><span class="nc">TransformerMixin</span><span class="o">]</span> <span class="nn">Obj</span><span class="p">.</span><span class="n">t</span>
<span class="k">val</span> <span class="n">as_estimator</span> <span class="o">:</span> <span class="n">t</span> <span class="o">-&gt;</span> <span class="o">[`</span><span class="nc">BaseEstimator</span><span class="o">]</span> <span class="nn">Obj</span><span class="p">.</span><span class="n">t</span>
<span class="k">val</span> <span class="n">create</span> <span class="o">:</span> <span class="o">?</span><span class="n">n_components</span><span class="o">:</span><span class="kt">int</span> <span class="o">-&gt;</span> <span class="o">?</span><span class="n">alpha</span><span class="o">:</span><span class="kt">int</span> <span class="o">-&gt;</span> <span class="o">?</span><span class="n">ridge_alpha</span><span class="o">:</span><span class="kt">float</span> <span class="o">-&gt;</span> <span class="o">?</span><span class="n">n_iter</span><span class="o">:</span><span class="kt">int</span> <span class="o">-&gt;</span> <span class="o">?</span><span class="n">callback</span><span class="o">:</span><span class="nn">Py</span><span class="p">.</span><span class="nn">Object</span><span class="p">.</span><span class="n">t</span> <span class="o">-&gt;</span> <span class="o">?</span><span class="n">batch_size</span><span class="o">:</span><span class="kt">int</span> <span class="o">-&gt;</span> <span class="o">?</span><span class="n">verbose</span><span class="o">:</span><span class="kt">int</span> <span class="o">-&gt;</span> <span class="o">?</span><span class="n">shuffle</span><span class="o">:</span><span class="kt">bool</span> <span class="o">-&gt;</span> <span class="o">?</span><span class="n">n_jobs</span><span class="o">:</span><span class="kt">int</span> <span class="o">-&gt;</span> <span class="o">?</span><span class="n">method_</span><span class="o">:[`</span><span class="nc">Lars</span> <span class="o">|</span> <span class="o">`</span><span class="nc">Cd</span><span class="o">]</span> <span class="o">-&gt;</span> <span class="o">?</span><span class="n">random_state</span><span class="o">:</span><span class="kt">int</span> <span class="o">-&gt;</span> <span class="o">?</span><span class="n">normalize_components</span><span class="o">:[`</span><span class="nc">Deprecated</span><span class="o">]</span> <span class="o">-&gt;</span> <span class="kt">unit</span> <span class="o">-&gt;</span> <span class="n">t</span>
</code></pre></div>

<p>Mini-batch Sparse Principal Components Analysis</p>
<p>Finds the set of sparse components that can optimally reconstruct
the data.  The amount of sparseness is controllable by the coefficient
of the L1 penalty, given by the parameter alpha.</p>
<p>Read more in the :ref:<code>User Guide &lt;SparsePCA&gt;</code>.</p>
<h2 id="parameters_52">Parameters<a class="headerlink" href="#parameters_52" title="Permanent link">&para;</a></h2>
<p>n_components : int,
number of sparse atoms to extract</p>
<p>alpha : int,
Sparsity controlling parameter. Higher values lead to sparser
components.</p>
<p>ridge_alpha : float,
Amount of ridge shrinkage to apply in order to improve
conditioning when calling the transform method.</p>
<p>n_iter : int,
number of iterations to perform for each mini batch</p>
<p>callback : callable or None, optional (default: None)
callable that gets invoked every five iterations</p>
<p>batch_size : int,
the number of features to take in each mini batch</p>
<p>verbose : int
Controls the verbosity; the higher, the more messages. Defaults to 0.</p>
<p>shuffle : boolean,
whether to shuffle the data before splitting it in batches</p>
<p>n_jobs : int or None, optional (default=None)
Number of parallel jobs to run.
<code>None</code> means 1 unless in a :obj:<code>joblib.parallel_backend</code> context.
<code>-1</code> means using all processors. See :term:<code>Glossary &lt;n_jobs&gt;</code>
for more details.</p>
<p>method : {'lars', 'cd'}
lars: uses the least angle regression method to solve the lasso problem
(linear_model.lars_path)
cd: uses the coordinate descent method to compute the
Lasso solution (linear_model.Lasso). Lars will be faster if
the estimated components are sparse.</p>
<p>random_state : int, RandomState instance or None, optional (default=None)
If int, random_state is the seed used by the random number generator;
If RandomState instance, random_state is the random number generator;
If None, the random number generator is the RandomState instance used
by <code>np.random</code>.</p>
<p>normalize_components : 'deprecated'
This parameter does not have any effect. The components are always
normalized.</p>
<p>.. versionadded:: 0.20</p>
<p>.. deprecated:: 0.22
<code>normalize_components</code> is deprecated in 0.22 and will be removed
in 0.24.</p>
<h2 id="attributes_7">Attributes<a class="headerlink" href="#attributes_7" title="Permanent link">&para;</a></h2>
<p>components_ : array, [n_components, n_features]
Sparse components extracted from the data.</p>
<p>n_iter_ : int
Number of iterations run.</p>
<p>mean_ : array, shape (n_features,)
Per-feature empirical mean, estimated from the training set.
Equal to <code>X.mean(axis=0)</code>.</p>
<h2 id="examples_6">Examples<a class="headerlink" href="#examples_6" title="Permanent link">&para;</a></h2>
<blockquote>
<blockquote>
<blockquote>
<p>import numpy as np
from sklearn.datasets import make_friedman1
from sklearn.decomposition import MiniBatchSparsePCA
X, _ = make_friedman1(n_samples=200, n_features=30, random_state=0)
transformer = MiniBatchSparsePCA(n_components=5, batch_size=50,
...                                  random_state=0)
transformer.fit(X)
MiniBatchSparsePCA(...)
X_transformed = transformer.transform(X)
X_transformed.shape
(200, 5)</p>
<h1 id="most-values-in-the-components_-are-zero-sparsity">most values in the components_ are zero (sparsity)<a class="headerlink" href="#most-values-in-the-components_-are-zero-sparsity" title="Permanent link">&para;</a></h1>
<p>np.mean(transformer.components_ == 0)
0.94</p>
</blockquote>
</blockquote>
</blockquote>
<h2 id="see-also_4">See also<a class="headerlink" href="#see-also_4" title="Permanent link">&para;</a></h2>
<p>PCA
SparsePCA
DictionaryLearning</p>
<div class="highlight"><pre><span></span><code><span class="k">val</span> <span class="n">fit</span> <span class="o">:</span> <span class="o">?</span><span class="n">y</span><span class="o">:</span><span class="nn">Py</span><span class="p">.</span><span class="nn">Object</span><span class="p">.</span><span class="n">t</span> <span class="o">-&gt;</span> <span class="n">x</span><span class="o">:[&gt;`</span><span class="nc">ArrayLike</span><span class="o">]</span> <span class="nn">Np</span><span class="p">.</span><span class="nn">Obj</span><span class="p">.</span><span class="n">t</span> <span class="o">-&gt;</span> <span class="o">[&gt;</span> <span class="n">tag</span><span class="o">]</span> <span class="nn">Obj</span><span class="p">.</span><span class="n">t</span> <span class="o">-&gt;</span> <span class="n">t</span>
</code></pre></div>

<p>Fit the model from data in X.</p>
<h2 id="parameters_53">Parameters<a class="headerlink" href="#parameters_53" title="Permanent link">&para;</a></h2>
<p>X : array-like, shape (n_samples, n_features)
Training vector, where n_samples in the number of samples
and n_features is the number of features.</p>
<p>y : Ignored</p>
<h2 id="returns_49">Returns<a class="headerlink" href="#returns_49" title="Permanent link">&para;</a></h2>
<p>self : object
Returns the instance itself.</p>
<div class="highlight"><pre><span></span><code><span class="k">val</span> <span class="n">fit_transform</span> <span class="o">:</span> <span class="o">?</span><span class="n">y</span><span class="o">:[&gt;`</span><span class="nc">ArrayLike</span><span class="o">]</span> <span class="nn">Np</span><span class="p">.</span><span class="nn">Obj</span><span class="p">.</span><span class="n">t</span> <span class="o">-&gt;</span> <span class="o">?</span><span class="n">fit_params</span><span class="o">:(</span><span class="kt">string</span> <span class="o">*</span> <span class="nn">Py</span><span class="p">.</span><span class="nn">Object</span><span class="p">.</span><span class="n">t</span><span class="o">)</span> <span class="kt">list</span> <span class="o">-&gt;</span> <span class="n">x</span><span class="o">:[&gt;`</span><span class="nc">ArrayLike</span><span class="o">]</span> <span class="nn">Np</span><span class="p">.</span><span class="nn">Obj</span><span class="p">.</span><span class="n">t</span> <span class="o">-&gt;</span> <span class="o">[&gt;</span> <span class="n">tag</span><span class="o">]</span> <span class="nn">Obj</span><span class="p">.</span><span class="n">t</span> <span class="o">-&gt;</span> <span class="o">[&gt;`</span><span class="nc">ArrayLike</span><span class="o">]</span> <span class="nn">Np</span><span class="p">.</span><span class="nn">Obj</span><span class="p">.</span><span class="n">t</span>
</code></pre></div>

<p>Fit to data, then transform it.</p>
<p>Fits transformer to X and y with optional parameters fit_params
and returns a transformed version of X.</p>
<h2 id="parameters_54">Parameters<a class="headerlink" href="#parameters_54" title="Permanent link">&para;</a></h2>
<p>X : numpy array of shape [n_samples, n_features]
Training set.</p>
<p>y : numpy array of shape [n_samples]
Target values.</p>
<p>**fit_params : dict
Additional fit parameters.</p>
<h2 id="returns_50">Returns<a class="headerlink" href="#returns_50" title="Permanent link">&para;</a></h2>
<p>X_new : numpy array of shape [n_samples, n_features_new]
Transformed array.</p>
<div class="highlight"><pre><span></span><code><span class="k">val</span> <span class="n">get_params</span> <span class="o">:</span> <span class="o">?</span><span class="n">deep</span><span class="o">:</span><span class="kt">bool</span> <span class="o">-&gt;</span> <span class="o">[&gt;</span> <span class="n">tag</span><span class="o">]</span> <span class="nn">Obj</span><span class="p">.</span><span class="n">t</span> <span class="o">-&gt;</span> <span class="nn">Dict</span><span class="p">.</span><span class="n">t</span>
</code></pre></div>

<p>Get parameters for this estimator.</p>
<h2 id="parameters_55">Parameters<a class="headerlink" href="#parameters_55" title="Permanent link">&para;</a></h2>
<p>deep : bool, default=True
If True, will return the parameters for this estimator and
contained subobjects that are estimators.</p>
<h2 id="returns_51">Returns<a class="headerlink" href="#returns_51" title="Permanent link">&para;</a></h2>
<p>params : mapping of string to any
Parameter names mapped to their values.</p>
<div class="highlight"><pre><span></span><code><span class="k">val</span> <span class="n">set_params</span> <span class="o">:</span> <span class="o">?</span><span class="n">params</span><span class="o">:(</span><span class="kt">string</span> <span class="o">*</span> <span class="nn">Py</span><span class="p">.</span><span class="nn">Object</span><span class="p">.</span><span class="n">t</span><span class="o">)</span> <span class="kt">list</span> <span class="o">-&gt;</span> <span class="o">[&gt;</span> <span class="n">tag</span><span class="o">]</span> <span class="nn">Obj</span><span class="p">.</span><span class="n">t</span> <span class="o">-&gt;</span> <span class="n">t</span>
</code></pre></div>

<p>Set the parameters of this estimator.</p>
<p>The method works on simple estimators as well as on nested objects
(such as pipelines). The latter have parameters of the form
<code>&lt;component&gt;__&lt;parameter&gt;</code> so that it's possible to update each
component of a nested object.</p>
<h2 id="parameters_56">Parameters<a class="headerlink" href="#parameters_56" title="Permanent link">&para;</a></h2>
<p>**params : dict
Estimator parameters.</p>
<h2 id="returns_52">Returns<a class="headerlink" href="#returns_52" title="Permanent link">&para;</a></h2>
<p>self : object
Estimator instance.</p>
<div class="highlight"><pre><span></span><code><span class="k">val</span> <span class="n">transform</span> <span class="o">:</span> <span class="n">x</span><span class="o">:[&gt;`</span><span class="nc">ArrayLike</span><span class="o">]</span> <span class="nn">Np</span><span class="p">.</span><span class="nn">Obj</span><span class="p">.</span><span class="n">t</span> <span class="o">-&gt;</span> <span class="o">[&gt;</span> <span class="n">tag</span><span class="o">]</span> <span class="nn">Obj</span><span class="p">.</span><span class="n">t</span> <span class="o">-&gt;</span> <span class="o">[&gt;`</span><span class="nc">ArrayLike</span><span class="o">]</span> <span class="nn">Np</span><span class="p">.</span><span class="nn">Obj</span><span class="p">.</span><span class="n">t</span>
</code></pre></div>

<p>Least Squares projection of the data onto the sparse components.</p>
<p>To avoid instability issues in case the system is under-determined,
regularization can be applied (Ridge regression) via the
<code>ridge_alpha</code> parameter.</p>
<p>Note that Sparse PCA components orthogonality is not enforced as in PCA
hence one cannot use a simple linear projection.</p>
<h2 id="parameters_57">Parameters<a class="headerlink" href="#parameters_57" title="Permanent link">&para;</a></h2>
<p>X : array of shape (n_samples, n_features)
Test data to be transformed, must have the same number of
features as the data used to train the model.</p>
<h2 id="returns_53">Returns<a class="headerlink" href="#returns_53" title="Permanent link">&para;</a></h2>
<p>X_new array, shape (n_samples, n_components)
Transformed data.</p>
<p>Attribute components_: get value or raise Not_found if None.</p>
<div class="highlight"><pre><span></span><code><span class="k">val</span> <span class="n">components_</span> <span class="o">:</span> <span class="n">t</span> <span class="o">-&gt;</span> <span class="o">[&gt;`</span><span class="nc">ArrayLike</span><span class="o">]</span> <span class="nn">Np</span><span class="p">.</span><span class="nn">Obj</span><span class="p">.</span><span class="n">t</span>
</code></pre></div>

<p>Attribute components_: get value as an option.</p>
<div class="highlight"><pre><span></span><code><span class="k">val</span> <span class="n">components_opt</span> <span class="o">:</span> <span class="n">t</span> <span class="o">-&gt;</span> <span class="o">([&gt;`</span><span class="nc">ArrayLike</span><span class="o">]</span> <span class="nn">Np</span><span class="p">.</span><span class="nn">Obj</span><span class="p">.</span><span class="n">t</span><span class="o">)</span> <span class="n">option</span>
</code></pre></div>

<p>Attribute n_iter_: get value or raise Not_found if None.</p>
<div class="highlight"><pre><span></span><code><span class="k">val</span> <span class="n">n_iter_</span> <span class="o">:</span> <span class="n">t</span> <span class="o">-&gt;</span> <span class="kt">int</span>
</code></pre></div>

<p>Attribute n_iter_: get value as an option.</p>
<div class="highlight"><pre><span></span><code><span class="k">val</span> <span class="n">n_iter_opt</span> <span class="o">:</span> <span class="n">t</span> <span class="o">-&gt;</span> <span class="o">(</span><span class="kt">int</span><span class="o">)</span> <span class="n">option</span>
</code></pre></div>

<p>Attribute mean_: get value or raise Not_found if None.</p>
<div class="highlight"><pre><span></span><code><span class="k">val</span> <span class="n">mean_</span> <span class="o">:</span> <span class="n">t</span> <span class="o">-&gt;</span> <span class="o">[&gt;`</span><span class="nc">ArrayLike</span><span class="o">]</span> <span class="nn">Np</span><span class="p">.</span><span class="nn">Obj</span><span class="p">.</span><span class="n">t</span>
</code></pre></div>

<p>Attribute mean_: get value as an option.</p>
<div class="highlight"><pre><span></span><code><span class="k">val</span> <span class="n">mean_opt</span> <span class="o">:</span> <span class="n">t</span> <span class="o">-&gt;</span> <span class="o">([&gt;`</span><span class="nc">ArrayLike</span><span class="o">]</span> <span class="nn">Np</span><span class="p">.</span><span class="nn">Obj</span><span class="p">.</span><span class="n">t</span><span class="o">)</span> <span class="n">option</span>
</code></pre></div>

<p>Print the object to a human-readable representation.</p>
<div class="highlight"><pre><span></span><code><span class="k">val</span> <span class="n">to_string</span> <span class="o">:</span> <span class="n">t</span> <span class="o">-&gt;</span> <span class="kt">string</span>
</code></pre></div>

<p>Print the object to a human-readable representation.</p>
<div class="highlight"><pre><span></span><code><span class="k">val</span> <span class="n">show</span> <span class="o">:</span> <span class="n">t</span> <span class="o">-&gt;</span> <span class="kt">string</span>
</code></pre></div>

<p>Pretty-print the object to a formatter.</p>
<div class="highlight"><pre><span></span><code><span class="k">val</span> <span class="n">pp</span> <span class="o">:</span> <span class="nn">Format</span><span class="p">.</span><span class="n">formatter</span> <span class="o">-&gt;</span> <span class="n">t</span> <span class="o">-&gt;</span> <span class="kt">unit</span> <span class="o">[@@</span><span class="n">ocaml</span><span class="o">.</span><span class="n">toplevel_printer</span><span class="o">]</span>



<span class="k">module</span> <span class="nc">NMF</span> <span class="o">:</span> <span class="k">sig</span>
<span class="k">type</span> <span class="n">tag</span> <span class="o">=</span> <span class="o">[`</span><span class="nc">NMF</span><span class="o">]</span>
<span class="k">type</span> <span class="n">t</span> <span class="o">=</span> <span class="o">[`</span><span class="nc">BaseEstimator</span> <span class="o">|</span> <span class="o">`</span><span class="nc">NMF</span> <span class="o">|</span> <span class="o">`</span><span class="nc">Object</span> <span class="o">|</span> <span class="o">`</span><span class="nc">TransformerMixin</span><span class="o">]</span> <span class="nn">Obj</span><span class="p">.</span><span class="n">t</span>
<span class="k">val</span> <span class="n">of_pyobject</span> <span class="o">:</span> <span class="nn">Py</span><span class="p">.</span><span class="nn">Object</span><span class="p">.</span><span class="n">t</span> <span class="o">-&gt;</span> <span class="n">t</span>
<span class="k">val</span> <span class="n">to_pyobject</span> <span class="o">:</span> <span class="o">[&gt;</span> <span class="n">tag</span><span class="o">]</span> <span class="nn">Obj</span><span class="p">.</span><span class="n">t</span> <span class="o">-&gt;</span> <span class="nn">Py</span><span class="p">.</span><span class="nn">Object</span><span class="p">.</span><span class="n">t</span>

<span class="k">val</span> <span class="n">as_transformer</span> <span class="o">:</span> <span class="n">t</span> <span class="o">-&gt;</span> <span class="o">[`</span><span class="nc">TransformerMixin</span><span class="o">]</span> <span class="nn">Obj</span><span class="p">.</span><span class="n">t</span>
<span class="k">val</span> <span class="n">as_estimator</span> <span class="o">:</span> <span class="n">t</span> <span class="o">-&gt;</span> <span class="o">[`</span><span class="nc">BaseEstimator</span><span class="o">]</span> <span class="nn">Obj</span><span class="p">.</span><span class="n">t</span>
<span class="k">val</span> <span class="n">create</span> <span class="o">:</span> <span class="o">?</span><span class="n">n_components</span><span class="o">:</span><span class="kt">int</span> <span class="o">-&gt;</span> <span class="o">?</span><span class="n">init</span><span class="o">:[`</span><span class="nc">Custom</span> <span class="o">|</span> <span class="o">`</span><span class="nc">Random</span> <span class="o">|</span> <span class="o">`</span><span class="nc">Nndsvda</span> <span class="o">|</span> <span class="o">`</span><span class="nc">Nndsvd</span> <span class="o">|</span> <span class="o">`</span><span class="nc">Nndsvdar</span><span class="o">]</span> <span class="o">-&gt;</span> <span class="o">?</span><span class="n">solver</span><span class="o">:[`</span><span class="nc">Cd</span> <span class="o">|</span> <span class="o">`</span><span class="nc">Mu</span><span class="o">]</span> <span class="o">-&gt;</span> <span class="o">?</span><span class="n">beta_loss</span><span class="o">:[`</span><span class="nc">F</span> <span class="k">of</span> <span class="kt">float</span> <span class="o">|</span> <span class="o">`</span><span class="nc">S</span> <span class="k">of</span> <span class="kt">string</span><span class="o">]</span> <span class="o">-&gt;</span> <span class="o">?</span><span class="n">tol</span><span class="o">:</span><span class="kt">float</span> <span class="o">-&gt;</span> <span class="o">?</span><span class="n">max_iter</span><span class="o">:</span><span class="kt">int</span> <span class="o">-&gt;</span> <span class="o">?</span><span class="n">random_state</span><span class="o">:</span><span class="kt">int</span> <span class="o">-&gt;</span> <span class="o">?</span><span class="n">alpha</span><span class="o">:</span><span class="kt">float</span> <span class="o">-&gt;</span> <span class="o">?</span><span class="n">l1_ratio</span><span class="o">:</span><span class="kt">float</span> <span class="o">-&gt;</span> <span class="o">?</span><span class="n">verbose</span><span class="o">:</span><span class="kt">int</span> <span class="o">-&gt;</span> <span class="o">?</span><span class="n">shuffle</span><span class="o">:</span><span class="kt">bool</span> <span class="o">-&gt;</span> <span class="kt">unit</span> <span class="o">-&gt;</span> <span class="n">t</span>
</code></pre></div>

<p>Non-Negative Matrix Factorization (NMF)</p>
<p>Find two non-negative matrices (W, H) whose product approximates the non-
negative matrix X. This factorization can be used for example for
dimensionality reduction, source separation or topic extraction.</p>
<p>The objective function is::</p>
<p>0.5 * ||X - WH||_Fro^2
+ alpha * l1_ratio * ||vec(W)||_1
+ alpha * l1_ratio * ||vec(H)||_1
+ 0.5 * alpha * (1 - l1_ratio) * ||W||_Fro^2
+ 0.5 * alpha * (1 - l1_ratio) * ||H||_Fro^2</p>
<p>Where::</p>
<p>||A||<em>Fro^2 = \sum</em>{i,j} A_{ij}^2 (Frobenius norm)
||vec(A)||<em>1 = \sum</em>{i,j} abs(A_{ij}) (Elementwise L1 norm)</p>
<p>For multiplicative-update ('mu') solver, the Frobenius norm
(0.5 * ||X - WH||_Fro^2) can be changed into another beta-divergence loss,
by changing the beta_loss parameter.</p>
<p>The objective function is minimized with an alternating minimization of W
and H.</p>
<p>Read more in the :ref:<code>User Guide &lt;NMF&gt;</code>.</p>
<h2 id="parameters_58">Parameters<a class="headerlink" href="#parameters_58" title="Permanent link">&para;</a></h2>
<p>n_components : int or None
Number of components, if n_components is not set all features
are kept.</p>
<p>init : None | 'random' | 'nndsvd' |  'nndsvda' | 'nndsvdar' | 'custom'
Method used to initialize the procedure.
Default: None.
Valid options:</p>
<ul>
<li>
<p>None: 'nndsvd' if n_components &lt;= min(n_samples, n_features),
otherwise random.</p>
</li>
<li>
<p>'random': non-negative random matrices, scaled with:
sqrt(X.mean() / n_components)</p>
</li>
<li>
<p>'nndsvd': Nonnegative Double Singular Value Decomposition (NNDSVD)
initialization (better for sparseness)</p>
</li>
<li>
<p>'nndsvda': NNDSVD with zeros filled with the average of X
(better when sparsity is not desired)</p>
</li>
<li>
<p>'nndsvdar': NNDSVD with zeros filled with small random values
(generally faster, less accurate alternative to NNDSVDa
for when sparsity is not desired)</p>
</li>
<li>
<p>'custom': use custom matrices W and H</p>
</li>
</ul>
<p>solver : 'cd' | 'mu'
Numerical solver to use:
'cd' is a Coordinate Descent solver.
'mu' is a Multiplicative Update solver.</p>
<p>.. versionadded:: 0.17
Coordinate Descent solver.</p>
<p>.. versionadded:: 0.19
Multiplicative Update solver.</p>
<p>beta_loss : float or string, default 'frobenius'
String must be in {'frobenius', 'kullback-leibler', 'itakura-saito'}.
Beta divergence to be minimized, measuring the distance between X
and the dot product WH. Note that values different from 'frobenius'
(or 2) and 'kullback-leibler' (or 1) lead to significantly slower
fits. Note that for beta_loss &lt;= 0 (or 'itakura-saito'), the input
matrix X cannot contain zeros. Used only in 'mu' solver.</p>
<p>.. versionadded:: 0.19</p>
<p>tol : float, default: 1e-4
Tolerance of the stopping condition.</p>
<p>max_iter : integer, default: 200
Maximum number of iterations before timing out.</p>
<p>random_state : int, RandomState instance or None, optional, default: None
If int, random_state is the seed used by the random number generator;
If RandomState instance, random_state is the random number generator;
If None, the random number generator is the RandomState instance used
by <code>np.random</code>.</p>
<p>alpha : double, default: 0.
Constant that multiplies the regularization terms. Set it to zero to
have no regularization.</p>
<p>.. versionadded:: 0.17
<em>alpha</em> used in the Coordinate Descent solver.</p>
<p>l1_ratio : double, default: 0.
The regularization mixing parameter, with 0 &lt;= l1_ratio &lt;= 1.
For l1_ratio = 0 the penalty is an elementwise L2 penalty
(aka Frobenius Norm).
For l1_ratio = 1 it is an elementwise L1 penalty.
For 0 &lt; l1_ratio &lt; 1, the penalty is a combination of L1 and L2.</p>
<p>.. versionadded:: 0.17
Regularization parameter <em>l1_ratio</em> used in the Coordinate Descent
solver.</p>
<p>verbose : bool, default=False
Whether to be verbose.</p>
<p>shuffle : boolean, default: False
If true, randomize the order of coordinates in the CD solver.</p>
<p>.. versionadded:: 0.17
<em>shuffle</em> parameter used in the Coordinate Descent solver.</p>
<h2 id="attributes_8">Attributes<a class="headerlink" href="#attributes_8" title="Permanent link">&para;</a></h2>
<p>components_ : array, [n_components, n_features]
Factorization matrix, sometimes called 'dictionary'.</p>
<p>n_components_ : integer
The number of components. It is same as the <code>n_components</code> parameter
if it was given. Otherwise, it will be same as the number of
features.</p>
<p>reconstruction_err_ : number
Frobenius norm of the matrix difference, or beta-divergence, between
the training data <code>X</code> and the reconstructed data <code>WH</code> from
the fitted model.</p>
<p>n_iter_ : int
Actual number of iterations.</p>
<h2 id="examples_7">Examples<a class="headerlink" href="#examples_7" title="Permanent link">&para;</a></h2>
<blockquote>
<blockquote>
<blockquote>
<p>import numpy as np
X = np.array([[1, 1], [2, 1], [3, 1.2], [4, 1], [5, 0.8], [6, 1]])
from sklearn.decomposition import NMF
model = NMF(n_components=2, init='random', random_state=0)
W = model.fit_transform(X)
H = model.components_</p>
</blockquote>
</blockquote>
</blockquote>
<h2 id="references_5">References<a class="headerlink" href="#references_5" title="Permanent link">&para;</a></h2>
<p>Cichocki, Andrzej, and P. H. A. N. Anh-Huy. 'Fast local algorithms for
large scale nonnegative matrix and tensor factorizations.'
IEICE transactions on fundamentals of electronics, communications and
computer sciences 92.3: 708-721, 2009.</p>
<p>Fevotte, C., &amp; Idier, J. (2011). Algorithms for nonnegative matrix
factorization with the beta-divergence. Neural Computation, 23(9).</p>
<div class="highlight"><pre><span></span><code><span class="k">val</span> <span class="n">fit</span> <span class="o">:</span> <span class="o">?</span><span class="n">y</span><span class="o">:</span><span class="nn">Py</span><span class="p">.</span><span class="nn">Object</span><span class="p">.</span><span class="n">t</span> <span class="o">-&gt;</span> <span class="o">?</span><span class="n">params</span><span class="o">:(</span><span class="kt">string</span> <span class="o">*</span> <span class="nn">Py</span><span class="p">.</span><span class="nn">Object</span><span class="p">.</span><span class="n">t</span><span class="o">)</span> <span class="kt">list</span> <span class="o">-&gt;</span> <span class="n">x</span><span class="o">:[&gt;`</span><span class="nc">ArrayLike</span><span class="o">]</span> <span class="nn">Np</span><span class="p">.</span><span class="nn">Obj</span><span class="p">.</span><span class="n">t</span> <span class="o">-&gt;</span> <span class="o">[&gt;</span> <span class="n">tag</span><span class="o">]</span> <span class="nn">Obj</span><span class="p">.</span><span class="n">t</span> <span class="o">-&gt;</span> <span class="n">t</span>
</code></pre></div>

<p>Learn a NMF model for the data X.</p>
<h2 id="parameters_59">Parameters<a class="headerlink" href="#parameters_59" title="Permanent link">&para;</a></h2>
<p>X : {array-like, sparse matrix}, shape (n_samples, n_features)
Data matrix to be decomposed</p>
<p>y : Ignored</p>
<h2 id="returns_54">Returns<a class="headerlink" href="#returns_54" title="Permanent link">&para;</a></h2>
<p>self</p>
<div class="highlight"><pre><span></span><code><span class="k">val</span> <span class="n">fit_transform</span> <span class="o">:</span> <span class="o">?</span><span class="n">y</span><span class="o">:</span><span class="nn">Py</span><span class="p">.</span><span class="nn">Object</span><span class="p">.</span><span class="n">t</span> <span class="o">-&gt;</span> <span class="o">?</span><span class="n">w</span><span class="o">:[&gt;`</span><span class="nc">ArrayLike</span><span class="o">]</span> <span class="nn">Np</span><span class="p">.</span><span class="nn">Obj</span><span class="p">.</span><span class="n">t</span> <span class="o">-&gt;</span> <span class="o">?</span><span class="n">h</span><span class="o">:[&gt;`</span><span class="nc">ArrayLike</span><span class="o">]</span> <span class="nn">Np</span><span class="p">.</span><span class="nn">Obj</span><span class="p">.</span><span class="n">t</span> <span class="o">-&gt;</span> <span class="n">x</span><span class="o">:[&gt;`</span><span class="nc">ArrayLike</span><span class="o">]</span> <span class="nn">Np</span><span class="p">.</span><span class="nn">Obj</span><span class="p">.</span><span class="n">t</span> <span class="o">-&gt;</span> <span class="o">[&gt;</span> <span class="n">tag</span><span class="o">]</span> <span class="nn">Obj</span><span class="p">.</span><span class="n">t</span> <span class="o">-&gt;</span> <span class="o">[&gt;`</span><span class="nc">ArrayLike</span><span class="o">]</span> <span class="nn">Np</span><span class="p">.</span><span class="nn">Obj</span><span class="p">.</span><span class="n">t</span>
</code></pre></div>

<p>Learn a NMF model for the data X and returns the transformed data.</p>
<p>This is more efficient than calling fit followed by transform.</p>
<h2 id="parameters_60">Parameters<a class="headerlink" href="#parameters_60" title="Permanent link">&para;</a></h2>
<p>X : {array-like, sparse matrix}, shape (n_samples, n_features)
Data matrix to be decomposed</p>
<p>y : Ignored</p>
<p>W : array-like, shape (n_samples, n_components)
If init='custom', it is used as initial guess for the solution.</p>
<p>H : array-like, shape (n_components, n_features)
If init='custom', it is used as initial guess for the solution.</p>
<h2 id="returns_55">Returns<a class="headerlink" href="#returns_55" title="Permanent link">&para;</a></h2>
<p>W : array, shape (n_samples, n_components)
Transformed data.</p>
<div class="highlight"><pre><span></span><code><span class="k">val</span> <span class="n">get_params</span> <span class="o">:</span> <span class="o">?</span><span class="n">deep</span><span class="o">:</span><span class="kt">bool</span> <span class="o">-&gt;</span> <span class="o">[&gt;</span> <span class="n">tag</span><span class="o">]</span> <span class="nn">Obj</span><span class="p">.</span><span class="n">t</span> <span class="o">-&gt;</span> <span class="nn">Dict</span><span class="p">.</span><span class="n">t</span>
</code></pre></div>

<p>Get parameters for this estimator.</p>
<h2 id="parameters_61">Parameters<a class="headerlink" href="#parameters_61" title="Permanent link">&para;</a></h2>
<p>deep : bool, default=True
If True, will return the parameters for this estimator and
contained subobjects that are estimators.</p>
<h2 id="returns_56">Returns<a class="headerlink" href="#returns_56" title="Permanent link">&para;</a></h2>
<p>params : mapping of string to any
Parameter names mapped to their values.</p>
<div class="highlight"><pre><span></span><code><span class="k">val</span> <span class="n">inverse_transform</span> <span class="o">:</span> <span class="n">w</span><span class="o">:[&gt;`</span><span class="nc">ArrayLike</span><span class="o">]</span> <span class="nn">Np</span><span class="p">.</span><span class="nn">Obj</span><span class="p">.</span><span class="n">t</span> <span class="o">-&gt;</span> <span class="o">[&gt;</span> <span class="n">tag</span><span class="o">]</span> <span class="nn">Obj</span><span class="p">.</span><span class="n">t</span> <span class="o">-&gt;</span> <span class="o">[&gt;`</span><span class="nc">ArrayLike</span><span class="o">]</span> <span class="nn">Np</span><span class="p">.</span><span class="nn">Obj</span><span class="p">.</span><span class="n">t</span>
</code></pre></div>

<p>Transform data back to its original space.</p>
<h2 id="parameters_62">Parameters<a class="headerlink" href="#parameters_62" title="Permanent link">&para;</a></h2>
<p>W : {array-like, sparse matrix}, shape (n_samples, n_components)
Transformed data matrix</p>
<h2 id="returns_57">Returns<a class="headerlink" href="#returns_57" title="Permanent link">&para;</a></h2>
<p>X : {array-like, sparse matrix}, shape (n_samples, n_features)
Data matrix of original shape</p>
<p>.. versionadded:: 0.18</p>
<div class="highlight"><pre><span></span><code><span class="k">val</span> <span class="n">set_params</span> <span class="o">:</span> <span class="o">?</span><span class="n">params</span><span class="o">:(</span><span class="kt">string</span> <span class="o">*</span> <span class="nn">Py</span><span class="p">.</span><span class="nn">Object</span><span class="p">.</span><span class="n">t</span><span class="o">)</span> <span class="kt">list</span> <span class="o">-&gt;</span> <span class="o">[&gt;</span> <span class="n">tag</span><span class="o">]</span> <span class="nn">Obj</span><span class="p">.</span><span class="n">t</span> <span class="o">-&gt;</span> <span class="n">t</span>
</code></pre></div>

<p>Set the parameters of this estimator.</p>
<p>The method works on simple estimators as well as on nested objects
(such as pipelines). The latter have parameters of the form
<code>&lt;component&gt;__&lt;parameter&gt;</code> so that it's possible to update each
component of a nested object.</p>
<h2 id="parameters_63">Parameters<a class="headerlink" href="#parameters_63" title="Permanent link">&para;</a></h2>
<p>**params : dict
Estimator parameters.</p>
<h2 id="returns_58">Returns<a class="headerlink" href="#returns_58" title="Permanent link">&para;</a></h2>
<p>self : object
Estimator instance.</p>
<div class="highlight"><pre><span></span><code><span class="k">val</span> <span class="n">transform</span> <span class="o">:</span> <span class="n">x</span><span class="o">:[&gt;`</span><span class="nc">ArrayLike</span><span class="o">]</span> <span class="nn">Np</span><span class="p">.</span><span class="nn">Obj</span><span class="p">.</span><span class="n">t</span> <span class="o">-&gt;</span> <span class="o">[&gt;</span> <span class="n">tag</span><span class="o">]</span> <span class="nn">Obj</span><span class="p">.</span><span class="n">t</span> <span class="o">-&gt;</span> <span class="o">[&gt;`</span><span class="nc">ArrayLike</span><span class="o">]</span> <span class="nn">Np</span><span class="p">.</span><span class="nn">Obj</span><span class="p">.</span><span class="n">t</span>
</code></pre></div>

<p>Transform the data X according to the fitted NMF model</p>
<h2 id="parameters_64">Parameters<a class="headerlink" href="#parameters_64" title="Permanent link">&para;</a></h2>
<p>X : {array-like, sparse matrix}, shape (n_samples, n_features)
Data matrix to be transformed by the model</p>
<h2 id="returns_59">Returns<a class="headerlink" href="#returns_59" title="Permanent link">&para;</a></h2>
<p>W : array, shape (n_samples, n_components)
Transformed data</p>
<p>Attribute components_: get value or raise Not_found if None.</p>
<div class="highlight"><pre><span></span><code><span class="k">val</span> <span class="n">components_</span> <span class="o">:</span> <span class="n">t</span> <span class="o">-&gt;</span> <span class="o">[&gt;`</span><span class="nc">ArrayLike</span><span class="o">]</span> <span class="nn">Np</span><span class="p">.</span><span class="nn">Obj</span><span class="p">.</span><span class="n">t</span>
</code></pre></div>

<p>Attribute components_: get value as an option.</p>
<div class="highlight"><pre><span></span><code><span class="k">val</span> <span class="n">components_opt</span> <span class="o">:</span> <span class="n">t</span> <span class="o">-&gt;</span> <span class="o">([&gt;`</span><span class="nc">ArrayLike</span><span class="o">]</span> <span class="nn">Np</span><span class="p">.</span><span class="nn">Obj</span><span class="p">.</span><span class="n">t</span><span class="o">)</span> <span class="n">option</span>
</code></pre></div>

<p>Attribute n_components_: get value or raise Not_found if None.</p>
<div class="highlight"><pre><span></span><code><span class="k">val</span> <span class="n">n_components_</span> <span class="o">:</span> <span class="n">t</span> <span class="o">-&gt;</span> <span class="kt">int</span>
</code></pre></div>

<p>Attribute n_components_: get value as an option.</p>
<div class="highlight"><pre><span></span><code><span class="k">val</span> <span class="n">n_components_opt</span> <span class="o">:</span> <span class="n">t</span> <span class="o">-&gt;</span> <span class="o">(</span><span class="kt">int</span><span class="o">)</span> <span class="n">option</span>
</code></pre></div>

<p>Attribute reconstruction_err_: get value or raise Not_found if None.</p>
<div class="highlight"><pre><span></span><code><span class="k">val</span> <span class="n">reconstruction_err_</span> <span class="o">:</span> <span class="n">t</span> <span class="o">-&gt;</span> <span class="o">[`</span><span class="nc">F</span> <span class="k">of</span> <span class="kt">float</span> <span class="o">|</span> <span class="o">`</span><span class="nc">I</span> <span class="k">of</span> <span class="kt">int</span><span class="o">]</span>
</code></pre></div>

<p>Attribute reconstruction_err_: get value as an option.</p>
<div class="highlight"><pre><span></span><code><span class="k">val</span> <span class="n">reconstruction_err_opt</span> <span class="o">:</span> <span class="n">t</span> <span class="o">-&gt;</span> <span class="o">([`</span><span class="nc">F</span> <span class="k">of</span> <span class="kt">float</span> <span class="o">|</span> <span class="o">`</span><span class="nc">I</span> <span class="k">of</span> <span class="kt">int</span><span class="o">])</span> <span class="n">option</span>
</code></pre></div>

<p>Attribute n_iter_: get value or raise Not_found if None.</p>
<div class="highlight"><pre><span></span><code><span class="k">val</span> <span class="n">n_iter_</span> <span class="o">:</span> <span class="n">t</span> <span class="o">-&gt;</span> <span class="kt">int</span>
</code></pre></div>

<p>Attribute n_iter_: get value as an option.</p>
<div class="highlight"><pre><span></span><code><span class="k">val</span> <span class="n">n_iter_opt</span> <span class="o">:</span> <span class="n">t</span> <span class="o">-&gt;</span> <span class="o">(</span><span class="kt">int</span><span class="o">)</span> <span class="n">option</span>
</code></pre></div>

<p>Print the object to a human-readable representation.</p>
<div class="highlight"><pre><span></span><code><span class="k">val</span> <span class="n">to_string</span> <span class="o">:</span> <span class="n">t</span> <span class="o">-&gt;</span> <span class="kt">string</span>
</code></pre></div>

<p>Print the object to a human-readable representation.</p>
<div class="highlight"><pre><span></span><code><span class="k">val</span> <span class="n">show</span> <span class="o">:</span> <span class="n">t</span> <span class="o">-&gt;</span> <span class="kt">string</span>
</code></pre></div>

<p>Pretty-print the object to a formatter.</p>
<div class="highlight"><pre><span></span><code><span class="k">val</span> <span class="n">pp</span> <span class="o">:</span> <span class="nn">Format</span><span class="p">.</span><span class="n">formatter</span> <span class="o">-&gt;</span> <span class="n">t</span> <span class="o">-&gt;</span> <span class="kt">unit</span> <span class="o">[@@</span><span class="n">ocaml</span><span class="o">.</span><span class="n">toplevel_printer</span><span class="o">]</span>



<span class="k">module</span> <span class="nc">PCA</span> <span class="o">:</span> <span class="k">sig</span>
<span class="k">type</span> <span class="n">tag</span> <span class="o">=</span> <span class="o">[`</span><span class="nc">PCA</span><span class="o">]</span>
<span class="k">type</span> <span class="n">t</span> <span class="o">=</span> <span class="o">[`</span><span class="nc">BaseEstimator</span> <span class="o">|</span> <span class="o">`</span><span class="nc">Object</span> <span class="o">|</span> <span class="o">`</span><span class="nc">PCA</span> <span class="o">|</span> <span class="o">`</span><span class="nc">TransformerMixin</span><span class="o">]</span> <span class="nn">Obj</span><span class="p">.</span><span class="n">t</span>
<span class="k">val</span> <span class="n">of_pyobject</span> <span class="o">:</span> <span class="nn">Py</span><span class="p">.</span><span class="nn">Object</span><span class="p">.</span><span class="n">t</span> <span class="o">-&gt;</span> <span class="n">t</span>
<span class="k">val</span> <span class="n">to_pyobject</span> <span class="o">:</span> <span class="o">[&gt;</span> <span class="n">tag</span><span class="o">]</span> <span class="nn">Obj</span><span class="p">.</span><span class="n">t</span> <span class="o">-&gt;</span> <span class="nn">Py</span><span class="p">.</span><span class="nn">Object</span><span class="p">.</span><span class="n">t</span>

<span class="k">val</span> <span class="n">as_transformer</span> <span class="o">:</span> <span class="n">t</span> <span class="o">-&gt;</span> <span class="o">[`</span><span class="nc">TransformerMixin</span><span class="o">]</span> <span class="nn">Obj</span><span class="p">.</span><span class="n">t</span>
<span class="k">val</span> <span class="n">as_estimator</span> <span class="o">:</span> <span class="n">t</span> <span class="o">-&gt;</span> <span class="o">[`</span><span class="nc">BaseEstimator</span><span class="o">]</span> <span class="nn">Obj</span><span class="p">.</span><span class="n">t</span>
<span class="k">val</span> <span class="n">create</span> <span class="o">:</span> <span class="o">?</span><span class="n">n_components</span><span class="o">:[`</span><span class="nc">F</span> <span class="k">of</span> <span class="kt">float</span> <span class="o">|</span> <span class="o">`</span><span class="nc">S</span> <span class="k">of</span> <span class="kt">string</span> <span class="o">|</span> <span class="o">`</span><span class="nc">I</span> <span class="k">of</span> <span class="kt">int</span><span class="o">]</span> <span class="o">-&gt;</span> <span class="o">?</span><span class="n">copy</span><span class="o">:</span><span class="kt">bool</span> <span class="o">-&gt;</span> <span class="o">?</span><span class="n">whiten</span><span class="o">:</span><span class="kt">bool</span> <span class="o">-&gt;</span> <span class="o">?</span><span class="n">svd_solver</span><span class="o">:[`</span><span class="nc">Auto</span> <span class="o">|</span> <span class="o">`</span><span class="nc">Full</span> <span class="o">|</span> <span class="o">`</span><span class="nc">Arpack</span> <span class="o">|</span> <span class="o">`</span><span class="nc">Randomized</span><span class="o">]</span> <span class="o">-&gt;</span> <span class="o">?</span><span class="n">tol</span><span class="o">:</span><span class="kt">float</span> <span class="o">-&gt;</span> <span class="o">?</span><span class="n">iterated_power</span><span class="o">:[`</span><span class="nc">Auto</span> <span class="o">|</span> <span class="o">`</span><span class="nc">I</span> <span class="k">of</span> <span class="kt">int</span><span class="o">]</span> <span class="o">-&gt;</span> <span class="o">?</span><span class="n">random_state</span><span class="o">:</span><span class="kt">int</span> <span class="o">-&gt;</span> <span class="kt">unit</span> <span class="o">-&gt;</span> <span class="n">t</span>
</code></pre></div>

<p>Principal component analysis (PCA).</p>
<p>Linear dimensionality reduction using Singular Value Decomposition of the
data to project it to a lower dimensional space. The input data is centered
but not scaled for each feature before applying the SVD.</p>
<p>It uses the LAPACK implementation of the full SVD or a randomized truncated
SVD by the method of Halko et al. 2009, depending on the shape of the input
data and the number of components to extract.</p>
<p>It can also use the scipy.sparse.linalg ARPACK implementation of the
truncated SVD.</p>
<p>Notice that this class does not support sparse input. See
:class:<code>TruncatedSVD</code> for an alternative with sparse data.</p>
<p>Read more in the :ref:<code>User Guide &lt;PCA&gt;</code>.</p>
<h2 id="parameters_65">Parameters<a class="headerlink" href="#parameters_65" title="Permanent link">&para;</a></h2>
<p>n_components : int, float, None or str
Number of components to keep.
if n_components is not set all components are kept::</p>
<p>n_components == min(n_samples, n_features)</p>
<p>If <code>n_components == 'mle'</code> and <code>svd_solver == 'full'</code>, Minka's
MLE is used to guess the dimension. Use of <code>n_components == 'mle'</code>
will interpret <code>svd_solver == 'auto'</code> as <code>svd_solver == 'full'</code>.</p>
<p>If <code>0 &lt; n_components &lt; 1</code> and <code>svd_solver == 'full'</code>, select the
number of components such that the amount of variance that needs to be
explained is greater than the percentage specified by n_components.</p>
<p>If <code>svd_solver == 'arpack'</code>, the number of components must be
strictly less than the minimum of n_features and n_samples.</p>
<p>Hence, the None case results in::</p>
<p>n_components == min(n_samples, n_features) - 1</p>
<p>copy : bool, default=True
If False, data passed to fit are overwritten and running
fit(X).transform(X) will not yield the expected results,
use fit_transform(X) instead.</p>
<p>whiten : bool, optional (default False)
When True (False by default) the <code>components_</code> vectors are multiplied
by the square root of n_samples and then divided by the singular values
to ensure uncorrelated outputs with unit component-wise variances.</p>
<p>Whitening will remove some information from the transformed signal
(the relative variance scales of the components) but can sometime
improve the predictive accuracy of the downstream estimators by
making their data respect some hard-wired assumptions.</p>
<p>svd_solver : str {'auto', 'full', 'arpack', 'randomized'}
If auto :
The solver is selected by a default policy based on <code>X.shape</code> and
<code>n_components</code>: if the input data is larger than 500x500 and the
number of components to extract is lower than 80% of the smallest
dimension of the data, then the more efficient 'randomized'
method is enabled. Otherwise the exact full SVD is computed and
optionally truncated afterwards.
If full :
run exact full SVD calling the standard LAPACK solver via
<code>scipy.linalg.svd</code> and select the components by postprocessing
If arpack :
run SVD truncated to n_components calling ARPACK solver via
<code>scipy.sparse.linalg.svds</code>. It requires strictly
0 &lt; n_components &lt; min(X.shape)
If randomized :
run randomized SVD by the method of Halko et al.</p>
<p>.. versionadded:: 0.18.0</p>
<p>tol : float &gt;= 0, optional (default .0)
Tolerance for singular values computed by svd_solver == 'arpack'.</p>
<p>.. versionadded:: 0.18.0</p>
<p>iterated_power : int &gt;= 0, or 'auto', (default 'auto')
Number of iterations for the power method computed by
svd_solver == 'randomized'.</p>
<p>.. versionadded:: 0.18.0</p>
<p>random_state : int, RandomState instance or None, optional (default None)
If int, random_state is the seed used by the random number generator;
If RandomState instance, random_state is the random number generator;
If None, the random number generator is the RandomState instance used
by <code>np.random</code>. Used when <code>svd_solver</code> == 'arpack' or 'randomized'.</p>
<p>.. versionadded:: 0.18.0</p>
<h2 id="attributes_9">Attributes<a class="headerlink" href="#attributes_9" title="Permanent link">&para;</a></h2>
<p>components_ : array, shape (n_components, n_features)
Principal axes in feature space, representing the directions of
maximum variance in the data. The components are sorted by
<code>explained_variance_</code>.</p>
<p>explained_variance_ : array, shape (n_components,)
The amount of variance explained by each of the selected components.</p>
<p>Equal to n_components largest eigenvalues
of the covariance matrix of X.</p>
<p>.. versionadded:: 0.18</p>
<p>explained_variance_ratio_ : array, shape (n_components,)
Percentage of variance explained by each of the selected components.</p>
<p>If <code>n_components</code> is not set then all components are stored and the
sum of the ratios is equal to 1.0.</p>
<p>singular_values_ : array, shape (n_components,)
The singular values corresponding to each of the selected components.
The singular values are equal to the 2-norms of the <code>n_components</code>
variables in the lower-dimensional space.</p>
<p>.. versionadded:: 0.19</p>
<p>mean_ : array, shape (n_features,)
Per-feature empirical mean, estimated from the training set.</p>
<p>Equal to <code>X.mean(axis=0)</code>.</p>
<p>n_components_ : int
The estimated number of components. When n_components is set
to 'mle' or a number between 0 and 1 (with svd_solver == 'full') this
number is estimated from input data. Otherwise it equals the parameter
n_components, or the lesser value of n_features and n_samples
if n_components is None.</p>
<p>n_features_ : int
Number of features in the training data.</p>
<p>n_samples_ : int
Number of samples in the training data.</p>
<p>noise_variance_ : float
The estimated noise covariance following the Probabilistic PCA model
from Tipping and Bishop 1999. See 'Pattern Recognition and
Machine Learning' by C. Bishop, 12.2.1 p. 574 or
http://www.miketipping.com/papers/met-mppca.pdf. It is required to
compute the estimated data covariance and score samples.</p>
<p>Equal to the average of (min(n_features, n_samples) - n_components)
smallest eigenvalues of the covariance matrix of X.</p>
<h2 id="see-also_5">See Also<a class="headerlink" href="#see-also_5" title="Permanent link">&para;</a></h2>
<p>KernelPCA : Kernel Principal Component Analysis.
SparsePCA : Sparse Principal Component Analysis.
TruncatedSVD : Dimensionality reduction using truncated SVD.
IncrementalPCA : Incremental Principal Component Analysis.</p>
<h2 id="references_6">References<a class="headerlink" href="#references_6" title="Permanent link">&para;</a></h2>
<p>For n_components == 'mle', this class uses the method of <em>Minka, T. P.
'Automatic choice of dimensionality for PCA'. In NIPS, pp. 598-604</em></p>
<p>Implements the probabilistic PCA model from:
Tipping, M. E., and Bishop, C. M. (1999). 'Probabilistic principal
component analysis'. Journal of the Royal Statistical Society:
Series B (Statistical Methodology), 61(3), 611-622.
via the score and score_samples methods.
See http://www.miketipping.com/papers/met-mppca.pdf</p>
<p>For svd_solver == 'arpack', refer to <code>scipy.sparse.linalg.svds</code>.</p>
<p>For svd_solver == 'randomized', see:
<em>Halko, N., Martinsson, P. G., and Tropp, J. A. (2011).
'Finding structure with randomness: Probabilistic algorithms for
constructing approximate matrix decompositions'.
SIAM review, 53(2), 217-288.</em> and also
<em>Martinsson, P. G., Rokhlin, V., and Tygert, M. (2011).
'A randomized algorithm for the decomposition of matrices'.
Applied and Computational Harmonic Analysis, 30(1), 47-68.</em></p>
<h2 id="examples_8">Examples<a class="headerlink" href="#examples_8" title="Permanent link">&para;</a></h2>
<blockquote>
<blockquote>
<blockquote>
<p>import numpy as np
from sklearn.decomposition import PCA
X = np.array([[-1, -1], [-2, -1], [-3, -2], [1, 1], [2, 1], [3, 2]])
pca = PCA(n_components=2)
pca.fit(X)
PCA(n_components=2)
print(pca.explained_variance_ratio_)
[0.9924... 0.0075...]
print(pca.singular_values_)
[6.30061... 0.54980...]</p>
<p>pca = PCA(n_components=2, svd_solver='full')
pca.fit(X)
PCA(n_components=2, svd_solver='full')
print(pca.explained_variance_ratio_)
[0.9924... 0.00755...]
print(pca.singular_values_)
[6.30061... 0.54980...]</p>
<p>pca = PCA(n_components=1, svd_solver='arpack')
pca.fit(X)
PCA(n_components=1, svd_solver='arpack')
print(pca.explained_variance_ratio_)
[0.99244...]
print(pca.singular_values_)
[6.30061...]</p>
</blockquote>
</blockquote>
</blockquote>
<div class="highlight"><pre><span></span><code><span class="k">val</span> <span class="n">fit</span> <span class="o">:</span> <span class="o">?</span><span class="n">y</span><span class="o">:</span><span class="nn">Py</span><span class="p">.</span><span class="nn">Object</span><span class="p">.</span><span class="n">t</span> <span class="o">-&gt;</span> <span class="n">x</span><span class="o">:[&gt;`</span><span class="nc">ArrayLike</span><span class="o">]</span> <span class="nn">Np</span><span class="p">.</span><span class="nn">Obj</span><span class="p">.</span><span class="n">t</span> <span class="o">-&gt;</span> <span class="o">[&gt;</span> <span class="n">tag</span><span class="o">]</span> <span class="nn">Obj</span><span class="p">.</span><span class="n">t</span> <span class="o">-&gt;</span> <span class="n">t</span>
</code></pre></div>

<p>Fit the model with X.</p>
<h2 id="parameters_66">Parameters<a class="headerlink" href="#parameters_66" title="Permanent link">&para;</a></h2>
<p>X : array-like, shape (n_samples, n_features)
Training data, where n_samples is the number of samples
and n_features is the number of features.</p>
<p>y : None
Ignored variable.</p>
<h2 id="returns_60">Returns<a class="headerlink" href="#returns_60" title="Permanent link">&para;</a></h2>
<p>self : object
Returns the instance itself.</p>
<div class="highlight"><pre><span></span><code><span class="k">val</span> <span class="n">fit_transform</span> <span class="o">:</span> <span class="o">?</span><span class="n">y</span><span class="o">:</span><span class="nn">Py</span><span class="p">.</span><span class="nn">Object</span><span class="p">.</span><span class="n">t</span> <span class="o">-&gt;</span> <span class="n">x</span><span class="o">:[&gt;`</span><span class="nc">ArrayLike</span><span class="o">]</span> <span class="nn">Np</span><span class="p">.</span><span class="nn">Obj</span><span class="p">.</span><span class="n">t</span> <span class="o">-&gt;</span> <span class="o">[&gt;</span> <span class="n">tag</span><span class="o">]</span> <span class="nn">Obj</span><span class="p">.</span><span class="n">t</span> <span class="o">-&gt;</span> <span class="o">[&gt;`</span><span class="nc">ArrayLike</span><span class="o">]</span> <span class="nn">Np</span><span class="p">.</span><span class="nn">Obj</span><span class="p">.</span><span class="n">t</span>
</code></pre></div>

<p>Fit the model with X and apply the dimensionality reduction on X.</p>
<h2 id="parameters_67">Parameters<a class="headerlink" href="#parameters_67" title="Permanent link">&para;</a></h2>
<p>X : array-like, shape (n_samples, n_features)
Training data, where n_samples is the number of samples
and n_features is the number of features.</p>
<p>y : None
Ignored variable.</p>
<h2 id="returns_61">Returns<a class="headerlink" href="#returns_61" title="Permanent link">&para;</a></h2>
<p>X_new : array-like, shape (n_samples, n_components)
Transformed values.</p>
<h2 id="notes_5">Notes<a class="headerlink" href="#notes_5" title="Permanent link">&para;</a></h2>
<p>This method returns a Fortran-ordered array. To convert it to a
C-ordered array, use 'np.ascontiguousarray'.</p>
<div class="highlight"><pre><span></span><code><span class="k">val</span> <span class="n">get_covariance</span> <span class="o">:</span> <span class="o">[&gt;</span> <span class="n">tag</span><span class="o">]</span> <span class="nn">Obj</span><span class="p">.</span><span class="n">t</span> <span class="o">-&gt;</span> <span class="o">[&gt;`</span><span class="nc">ArrayLike</span><span class="o">]</span> <span class="nn">Np</span><span class="p">.</span><span class="nn">Obj</span><span class="p">.</span><span class="n">t</span>
</code></pre></div>

<p>Compute data covariance with the generative model.</p>
<p><code>cov = components_.T * S**2 * components_ + sigma2 * eye(n_features)</code>
where S**2 contains the explained variances, and sigma2 contains the
noise variances.</p>
<h2 id="returns_62">Returns<a class="headerlink" href="#returns_62" title="Permanent link">&para;</a></h2>
<p>cov : array, shape=(n_features, n_features)
Estimated covariance of data.</p>
<div class="highlight"><pre><span></span><code><span class="k">val</span> <span class="n">get_params</span> <span class="o">:</span> <span class="o">?</span><span class="n">deep</span><span class="o">:</span><span class="kt">bool</span> <span class="o">-&gt;</span> <span class="o">[&gt;</span> <span class="n">tag</span><span class="o">]</span> <span class="nn">Obj</span><span class="p">.</span><span class="n">t</span> <span class="o">-&gt;</span> <span class="nn">Dict</span><span class="p">.</span><span class="n">t</span>
</code></pre></div>

<p>Get parameters for this estimator.</p>
<h2 id="parameters_68">Parameters<a class="headerlink" href="#parameters_68" title="Permanent link">&para;</a></h2>
<p>deep : bool, default=True
If True, will return the parameters for this estimator and
contained subobjects that are estimators.</p>
<h2 id="returns_63">Returns<a class="headerlink" href="#returns_63" title="Permanent link">&para;</a></h2>
<p>params : mapping of string to any
Parameter names mapped to their values.</p>
<div class="highlight"><pre><span></span><code><span class="k">val</span> <span class="n">get_precision</span> <span class="o">:</span> <span class="o">[&gt;</span> <span class="n">tag</span><span class="o">]</span> <span class="nn">Obj</span><span class="p">.</span><span class="n">t</span> <span class="o">-&gt;</span> <span class="o">[&gt;`</span><span class="nc">ArrayLike</span><span class="o">]</span> <span class="nn">Np</span><span class="p">.</span><span class="nn">Obj</span><span class="p">.</span><span class="n">t</span>
</code></pre></div>

<p>Compute data precision matrix with the generative model.</p>
<p>Equals the inverse of the covariance but computed with
the matrix inversion lemma for efficiency.</p>
<h2 id="returns_64">Returns<a class="headerlink" href="#returns_64" title="Permanent link">&para;</a></h2>
<p>precision : array, shape=(n_features, n_features)
Estimated precision of data.</p>
<div class="highlight"><pre><span></span><code><span class="k">val</span> <span class="n">inverse_transform</span> <span class="o">:</span> <span class="n">x</span><span class="o">:[&gt;`</span><span class="nc">ArrayLike</span><span class="o">]</span> <span class="nn">Np</span><span class="p">.</span><span class="nn">Obj</span><span class="p">.</span><span class="n">t</span> <span class="o">-&gt;</span> <span class="o">[&gt;</span> <span class="n">tag</span><span class="o">]</span> <span class="nn">Obj</span><span class="p">.</span><span class="n">t</span> <span class="o">-&gt;</span> <span class="nn">Py</span><span class="p">.</span><span class="nn">Object</span><span class="p">.</span><span class="n">t</span>
</code></pre></div>

<p>Transform data back to its original space.</p>
<p>In other words, return an input X_original whose transform would be X.</p>
<h2 id="parameters_69">Parameters<a class="headerlink" href="#parameters_69" title="Permanent link">&para;</a></h2>
<p>X : array-like, shape (n_samples, n_components)
New data, where n_samples is the number of samples
and n_components is the number of components.</p>
<h2 id="returns_65">Returns<a class="headerlink" href="#returns_65" title="Permanent link">&para;</a></h2>
<p>X_original array-like, shape (n_samples, n_features)</p>
<h2 id="notes_6">Notes<a class="headerlink" href="#notes_6" title="Permanent link">&para;</a></h2>
<p>If whitening is enabled, inverse_transform will compute the
exact inverse operation, which includes reversing whitening.</p>
<div class="highlight"><pre><span></span><code><span class="k">val</span> <span class="n">score</span> <span class="o">:</span> <span class="o">?</span><span class="n">y</span><span class="o">:</span><span class="nn">Py</span><span class="p">.</span><span class="nn">Object</span><span class="p">.</span><span class="n">t</span> <span class="o">-&gt;</span> <span class="n">x</span><span class="o">:[&gt;`</span><span class="nc">ArrayLike</span><span class="o">]</span> <span class="nn">Np</span><span class="p">.</span><span class="nn">Obj</span><span class="p">.</span><span class="n">t</span> <span class="o">-&gt;</span> <span class="o">[&gt;</span> <span class="n">tag</span><span class="o">]</span> <span class="nn">Obj</span><span class="p">.</span><span class="n">t</span> <span class="o">-&gt;</span> <span class="kt">float</span>
</code></pre></div>

<p>Return the average log-likelihood of all samples.</p>
<p>See. 'Pattern Recognition and Machine Learning'
by C. Bishop, 12.2.1 p. 574
or http://www.miketipping.com/papers/met-mppca.pdf</p>
<h2 id="parameters_70">Parameters<a class="headerlink" href="#parameters_70" title="Permanent link">&para;</a></h2>
<p>X : array, shape(n_samples, n_features)
The data.</p>
<p>y : None
Ignored variable.</p>
<h2 id="returns_66">Returns<a class="headerlink" href="#returns_66" title="Permanent link">&para;</a></h2>
<p>ll : float
Average log-likelihood of the samples under the current model.</p>
<div class="highlight"><pre><span></span><code><span class="k">val</span> <span class="n">score_samples</span> <span class="o">:</span> <span class="n">x</span><span class="o">:[&gt;`</span><span class="nc">ArrayLike</span><span class="o">]</span> <span class="nn">Np</span><span class="p">.</span><span class="nn">Obj</span><span class="p">.</span><span class="n">t</span> <span class="o">-&gt;</span> <span class="o">[&gt;</span> <span class="n">tag</span><span class="o">]</span> <span class="nn">Obj</span><span class="p">.</span><span class="n">t</span> <span class="o">-&gt;</span> <span class="o">[&gt;`</span><span class="nc">ArrayLike</span><span class="o">]</span> <span class="nn">Np</span><span class="p">.</span><span class="nn">Obj</span><span class="p">.</span><span class="n">t</span>
</code></pre></div>

<p>Return the log-likelihood of each sample.</p>
<p>See. 'Pattern Recognition and Machine Learning'
by C. Bishop, 12.2.1 p. 574
or http://www.miketipping.com/papers/met-mppca.pdf</p>
<h2 id="parameters_71">Parameters<a class="headerlink" href="#parameters_71" title="Permanent link">&para;</a></h2>
<p>X : array, shape(n_samples, n_features)
The data.</p>
<h2 id="returns_67">Returns<a class="headerlink" href="#returns_67" title="Permanent link">&para;</a></h2>
<p>ll : array, shape (n_samples,)
Log-likelihood of each sample under the current model.</p>
<div class="highlight"><pre><span></span><code><span class="k">val</span> <span class="n">set_params</span> <span class="o">:</span> <span class="o">?</span><span class="n">params</span><span class="o">:(</span><span class="kt">string</span> <span class="o">*</span> <span class="nn">Py</span><span class="p">.</span><span class="nn">Object</span><span class="p">.</span><span class="n">t</span><span class="o">)</span> <span class="kt">list</span> <span class="o">-&gt;</span> <span class="o">[&gt;</span> <span class="n">tag</span><span class="o">]</span> <span class="nn">Obj</span><span class="p">.</span><span class="n">t</span> <span class="o">-&gt;</span> <span class="n">t</span>
</code></pre></div>

<p>Set the parameters of this estimator.</p>
<p>The method works on simple estimators as well as on nested objects
(such as pipelines). The latter have parameters of the form
<code>&lt;component&gt;__&lt;parameter&gt;</code> so that it's possible to update each
component of a nested object.</p>
<h2 id="parameters_72">Parameters<a class="headerlink" href="#parameters_72" title="Permanent link">&para;</a></h2>
<p>**params : dict
Estimator parameters.</p>
<h2 id="returns_68">Returns<a class="headerlink" href="#returns_68" title="Permanent link">&para;</a></h2>
<p>self : object
Estimator instance.</p>
<div class="highlight"><pre><span></span><code><span class="k">val</span> <span class="n">transform</span> <span class="o">:</span> <span class="n">x</span><span class="o">:[&gt;`</span><span class="nc">ArrayLike</span><span class="o">]</span> <span class="nn">Np</span><span class="p">.</span><span class="nn">Obj</span><span class="p">.</span><span class="n">t</span> <span class="o">-&gt;</span> <span class="o">[&gt;</span> <span class="n">tag</span><span class="o">]</span> <span class="nn">Obj</span><span class="p">.</span><span class="n">t</span> <span class="o">-&gt;</span> <span class="o">[&gt;`</span><span class="nc">ArrayLike</span><span class="o">]</span> <span class="nn">Np</span><span class="p">.</span><span class="nn">Obj</span><span class="p">.</span><span class="n">t</span>
</code></pre></div>

<p>Apply dimensionality reduction to X.</p>
<p>X is projected on the first principal components previously extracted
from a training set.</p>
<h2 id="parameters_73">Parameters<a class="headerlink" href="#parameters_73" title="Permanent link">&para;</a></h2>
<p>X : array-like, shape (n_samples, n_features)
New data, where n_samples is the number of samples
and n_features is the number of features.</p>
<h2 id="returns_69">Returns<a class="headerlink" href="#returns_69" title="Permanent link">&para;</a></h2>
<p>X_new : array-like, shape (n_samples, n_components)</p>
<h2 id="examples_9">Examples<a class="headerlink" href="#examples_9" title="Permanent link">&para;</a></h2>
<blockquote>
<blockquote>
<blockquote>
<p>import numpy as np
from sklearn.decomposition import IncrementalPCA
X = np.array([[-1, -1], [-2, -1], [-3, -2], [1, 1], [2, 1], [3, 2]])
ipca = IncrementalPCA(n_components=2, batch_size=3)
ipca.fit(X)
IncrementalPCA(batch_size=3, n_components=2)
ipca.transform(X) # doctest: +SKIP</p>
</blockquote>
</blockquote>
</blockquote>
<p>Attribute components_: get value or raise Not_found if None.</p>
<div class="highlight"><pre><span></span><code><span class="k">val</span> <span class="n">components_</span> <span class="o">:</span> <span class="n">t</span> <span class="o">-&gt;</span> <span class="o">[&gt;`</span><span class="nc">ArrayLike</span><span class="o">]</span> <span class="nn">Np</span><span class="p">.</span><span class="nn">Obj</span><span class="p">.</span><span class="n">t</span>
</code></pre></div>

<p>Attribute components_: get value as an option.</p>
<div class="highlight"><pre><span></span><code><span class="k">val</span> <span class="n">components_opt</span> <span class="o">:</span> <span class="n">t</span> <span class="o">-&gt;</span> <span class="o">([&gt;`</span><span class="nc">ArrayLike</span><span class="o">]</span> <span class="nn">Np</span><span class="p">.</span><span class="nn">Obj</span><span class="p">.</span><span class="n">t</span><span class="o">)</span> <span class="n">option</span>
</code></pre></div>

<p>Attribute explained_variance_: get value or raise Not_found if None.</p>
<div class="highlight"><pre><span></span><code><span class="k">val</span> <span class="n">explained_variance_</span> <span class="o">:</span> <span class="n">t</span> <span class="o">-&gt;</span> <span class="o">[&gt;`</span><span class="nc">ArrayLike</span><span class="o">]</span> <span class="nn">Np</span><span class="p">.</span><span class="nn">Obj</span><span class="p">.</span><span class="n">t</span>
</code></pre></div>

<p>Attribute explained_variance_: get value as an option.</p>
<div class="highlight"><pre><span></span><code><span class="k">val</span> <span class="n">explained_variance_opt</span> <span class="o">:</span> <span class="n">t</span> <span class="o">-&gt;</span> <span class="o">([&gt;`</span><span class="nc">ArrayLike</span><span class="o">]</span> <span class="nn">Np</span><span class="p">.</span><span class="nn">Obj</span><span class="p">.</span><span class="n">t</span><span class="o">)</span> <span class="n">option</span>
</code></pre></div>

<p>Attribute explained_variance_ratio_: get value or raise Not_found if None.</p>
<div class="highlight"><pre><span></span><code><span class="k">val</span> <span class="n">explained_variance_ratio_</span> <span class="o">:</span> <span class="n">t</span> <span class="o">-&gt;</span> <span class="o">[&gt;`</span><span class="nc">ArrayLike</span><span class="o">]</span> <span class="nn">Np</span><span class="p">.</span><span class="nn">Obj</span><span class="p">.</span><span class="n">t</span>
</code></pre></div>

<p>Attribute explained_variance_ratio_: get value as an option.</p>
<div class="highlight"><pre><span></span><code><span class="k">val</span> <span class="n">explained_variance_ratio_opt</span> <span class="o">:</span> <span class="n">t</span> <span class="o">-&gt;</span> <span class="o">([&gt;`</span><span class="nc">ArrayLike</span><span class="o">]</span> <span class="nn">Np</span><span class="p">.</span><span class="nn">Obj</span><span class="p">.</span><span class="n">t</span><span class="o">)</span> <span class="n">option</span>
</code></pre></div>

<p>Attribute singular_values_: get value or raise Not_found if None.</p>
<div class="highlight"><pre><span></span><code><span class="k">val</span> <span class="n">singular_values_</span> <span class="o">:</span> <span class="n">t</span> <span class="o">-&gt;</span> <span class="o">[&gt;`</span><span class="nc">ArrayLike</span><span class="o">]</span> <span class="nn">Np</span><span class="p">.</span><span class="nn">Obj</span><span class="p">.</span><span class="n">t</span>
</code></pre></div>

<p>Attribute singular_values_: get value as an option.</p>
<div class="highlight"><pre><span></span><code><span class="k">val</span> <span class="n">singular_values_opt</span> <span class="o">:</span> <span class="n">t</span> <span class="o">-&gt;</span> <span class="o">([&gt;`</span><span class="nc">ArrayLike</span><span class="o">]</span> <span class="nn">Np</span><span class="p">.</span><span class="nn">Obj</span><span class="p">.</span><span class="n">t</span><span class="o">)</span> <span class="n">option</span>
</code></pre></div>

<p>Attribute mean_: get value or raise Not_found if None.</p>
<div class="highlight"><pre><span></span><code><span class="k">val</span> <span class="n">mean_</span> <span class="o">:</span> <span class="n">t</span> <span class="o">-&gt;</span> <span class="o">[&gt;`</span><span class="nc">ArrayLike</span><span class="o">]</span> <span class="nn">Np</span><span class="p">.</span><span class="nn">Obj</span><span class="p">.</span><span class="n">t</span>
</code></pre></div>

<p>Attribute mean_: get value as an option.</p>
<div class="highlight"><pre><span></span><code><span class="k">val</span> <span class="n">mean_opt</span> <span class="o">:</span> <span class="n">t</span> <span class="o">-&gt;</span> <span class="o">([&gt;`</span><span class="nc">ArrayLike</span><span class="o">]</span> <span class="nn">Np</span><span class="p">.</span><span class="nn">Obj</span><span class="p">.</span><span class="n">t</span><span class="o">)</span> <span class="n">option</span>
</code></pre></div>

<p>Attribute n_components_: get value or raise Not_found if None.</p>
<div class="highlight"><pre><span></span><code><span class="k">val</span> <span class="n">n_components_</span> <span class="o">:</span> <span class="n">t</span> <span class="o">-&gt;</span> <span class="kt">int</span>
</code></pre></div>

<p>Attribute n_components_: get value as an option.</p>
<div class="highlight"><pre><span></span><code><span class="k">val</span> <span class="n">n_components_opt</span> <span class="o">:</span> <span class="n">t</span> <span class="o">-&gt;</span> <span class="o">(</span><span class="kt">int</span><span class="o">)</span> <span class="n">option</span>
</code></pre></div>

<p>Attribute n_features_: get value or raise Not_found if None.</p>
<div class="highlight"><pre><span></span><code><span class="k">val</span> <span class="n">n_features_</span> <span class="o">:</span> <span class="n">t</span> <span class="o">-&gt;</span> <span class="kt">int</span>
</code></pre></div>

<p>Attribute n_features_: get value as an option.</p>
<div class="highlight"><pre><span></span><code><span class="k">val</span> <span class="n">n_features_opt</span> <span class="o">:</span> <span class="n">t</span> <span class="o">-&gt;</span> <span class="o">(</span><span class="kt">int</span><span class="o">)</span> <span class="n">option</span>
</code></pre></div>

<p>Attribute n_samples_: get value or raise Not_found if None.</p>
<div class="highlight"><pre><span></span><code><span class="k">val</span> <span class="n">n_samples_</span> <span class="o">:</span> <span class="n">t</span> <span class="o">-&gt;</span> <span class="kt">int</span>
</code></pre></div>

<p>Attribute n_samples_: get value as an option.</p>
<div class="highlight"><pre><span></span><code><span class="k">val</span> <span class="n">n_samples_opt</span> <span class="o">:</span> <span class="n">t</span> <span class="o">-&gt;</span> <span class="o">(</span><span class="kt">int</span><span class="o">)</span> <span class="n">option</span>
</code></pre></div>

<p>Attribute noise_variance_: get value or raise Not_found if None.</p>
<div class="highlight"><pre><span></span><code><span class="k">val</span> <span class="n">noise_variance_</span> <span class="o">:</span> <span class="n">t</span> <span class="o">-&gt;</span> <span class="kt">float</span>
</code></pre></div>

<p>Attribute noise_variance_: get value as an option.</p>
<div class="highlight"><pre><span></span><code><span class="k">val</span> <span class="n">noise_variance_opt</span> <span class="o">:</span> <span class="n">t</span> <span class="o">-&gt;</span> <span class="o">(</span><span class="kt">float</span><span class="o">)</span> <span class="n">option</span>
</code></pre></div>

<p>Print the object to a human-readable representation.</p>
<div class="highlight"><pre><span></span><code><span class="k">val</span> <span class="n">to_string</span> <span class="o">:</span> <span class="n">t</span> <span class="o">-&gt;</span> <span class="kt">string</span>
</code></pre></div>

<p>Print the object to a human-readable representation.</p>
<div class="highlight"><pre><span></span><code><span class="k">val</span> <span class="n">show</span> <span class="o">:</span> <span class="n">t</span> <span class="o">-&gt;</span> <span class="kt">string</span>
</code></pre></div>

<p>Pretty-print the object to a formatter.</p>
<div class="highlight"><pre><span></span><code><span class="k">val</span> <span class="n">pp</span> <span class="o">:</span> <span class="nn">Format</span><span class="p">.</span><span class="n">formatter</span> <span class="o">-&gt;</span> <span class="n">t</span> <span class="o">-&gt;</span> <span class="kt">unit</span> <span class="o">[@@</span><span class="n">ocaml</span><span class="o">.</span><span class="n">toplevel_printer</span><span class="o">]</span>



<span class="k">module</span> <span class="nc">SparseCoder</span> <span class="o">:</span> <span class="k">sig</span>
<span class="k">type</span> <span class="n">tag</span> <span class="o">=</span> <span class="o">[`</span><span class="nc">SparseCoder</span><span class="o">]</span>
<span class="k">type</span> <span class="n">t</span> <span class="o">=</span> <span class="o">[`</span><span class="nc">BaseEstimator</span> <span class="o">|</span> <span class="o">`</span><span class="nc">Object</span> <span class="o">|</span> <span class="o">`</span><span class="nc">SparseCoder</span> <span class="o">|</span> <span class="o">`</span><span class="nc">SparseCodingMixin</span> <span class="o">|</span> <span class="o">`</span><span class="nc">TransformerMixin</span><span class="o">]</span> <span class="nn">Obj</span><span class="p">.</span><span class="n">t</span>
<span class="k">val</span> <span class="n">of_pyobject</span> <span class="o">:</span> <span class="nn">Py</span><span class="p">.</span><span class="nn">Object</span><span class="p">.</span><span class="n">t</span> <span class="o">-&gt;</span> <span class="n">t</span>
<span class="k">val</span> <span class="n">to_pyobject</span> <span class="o">:</span> <span class="o">[&gt;</span> <span class="n">tag</span><span class="o">]</span> <span class="nn">Obj</span><span class="p">.</span><span class="n">t</span> <span class="o">-&gt;</span> <span class="nn">Py</span><span class="p">.</span><span class="nn">Object</span><span class="p">.</span><span class="n">t</span>

<span class="k">val</span> <span class="n">as_transformer</span> <span class="o">:</span> <span class="n">t</span> <span class="o">-&gt;</span> <span class="o">[`</span><span class="nc">TransformerMixin</span><span class="o">]</span> <span class="nn">Obj</span><span class="p">.</span><span class="n">t</span>
<span class="k">val</span> <span class="n">as_estimator</span> <span class="o">:</span> <span class="n">t</span> <span class="o">-&gt;</span> <span class="o">[`</span><span class="nc">BaseEstimator</span><span class="o">]</span> <span class="nn">Obj</span><span class="p">.</span><span class="n">t</span>
<span class="k">val</span> <span class="n">as_sparse_coding</span> <span class="o">:</span> <span class="n">t</span> <span class="o">-&gt;</span> <span class="o">[`</span><span class="nc">SparseCodingMixin</span><span class="o">]</span> <span class="nn">Obj</span><span class="p">.</span><span class="n">t</span>
<span class="k">val</span> <span class="n">create</span> <span class="o">:</span> <span class="o">?</span><span class="n">transform_algorithm</span><span class="o">:[`</span><span class="nc">Lasso_lars</span> <span class="o">|</span> <span class="o">`</span><span class="nc">Lasso_cd</span> <span class="o">|</span> <span class="o">`</span><span class="nc">Lars</span> <span class="o">|</span> <span class="o">`</span><span class="nc">Omp</span> <span class="o">|</span> <span class="o">`</span><span class="nc">Threshold</span><span class="o">]</span> <span class="o">-&gt;</span> <span class="o">?</span><span class="n">transform_n_nonzero_coefs</span><span class="o">:</span><span class="kt">int</span> <span class="o">-&gt;</span> <span class="o">?</span><span class="n">transform_alpha</span><span class="o">:</span><span class="kt">float</span> <span class="o">-&gt;</span> <span class="o">?</span><span class="n">split_sign</span><span class="o">:</span><span class="kt">bool</span> <span class="o">-&gt;</span> <span class="o">?</span><span class="n">n_jobs</span><span class="o">:</span><span class="kt">int</span> <span class="o">-&gt;</span> <span class="o">?</span><span class="n">positive_code</span><span class="o">:</span><span class="kt">bool</span> <span class="o">-&gt;</span> <span class="o">?</span><span class="n">transform_max_iter</span><span class="o">:</span><span class="kt">int</span> <span class="o">-&gt;</span> <span class="n">dictionary</span><span class="o">:[&gt;`</span><span class="nc">ArrayLike</span><span class="o">]</span> <span class="nn">Np</span><span class="p">.</span><span class="nn">Obj</span><span class="p">.</span><span class="n">t</span> <span class="o">-&gt;</span> <span class="kt">unit</span> <span class="o">-&gt;</span> <span class="n">t</span>
</code></pre></div>

<p>Sparse coding</p>
<p>Finds a sparse representation of data against a fixed, precomputed
dictionary.</p>
<p>Each row of the result is the solution to a sparse coding problem.
The goal is to find a sparse array <code>code</code> such that::</p>
<p>X ~= code * dictionary</p>
<p>Read more in the :ref:<code>User Guide &lt;SparseCoder&gt;</code>.</p>
<h2 id="parameters_74">Parameters<a class="headerlink" href="#parameters_74" title="Permanent link">&para;</a></h2>
<p>dictionary : array, [n_components, n_features]
The dictionary atoms used for sparse coding. Lines are assumed to be
normalized to unit norm.</p>
<p>transform_algorithm : {'lasso_lars', 'lasso_cd', 'lars', 'omp',     'threshold'}, default='omp'
Algorithm used to transform the data:
lars: uses the least angle regression method (linear_model.lars_path)
lasso_lars: uses Lars to compute the Lasso solution
lasso_cd: uses the coordinate descent method to compute the
Lasso solution (linear_model.Lasso). lasso_lars will be faster if
the estimated components are sparse.
omp: uses orthogonal matching pursuit to estimate the sparse solution
threshold: squashes to zero all coefficients less than alpha from
the projection <code>dictionary * X'</code></p>
<p>transform_n_nonzero_coefs : int, default=0.1*n_features
Number of nonzero coefficients to target in each column of the
solution. This is only used by <code>algorithm='lars'</code> and <code>algorithm='omp'</code>
and is overridden by <code>alpha</code> in the <code>omp</code> case.</p>
<p>transform_alpha : float, default=1.
If <code>algorithm='lasso_lars'</code> or <code>algorithm='lasso_cd'</code>, <code>alpha</code> is the
penalty applied to the L1 norm.
If <code>algorithm='threshold'</code>, <code>alpha</code> is the absolute value of the
threshold below which coefficients will be squashed to zero.
If <code>algorithm='omp'</code>, <code>alpha</code> is the tolerance parameter: the value of
the reconstruction error targeted. In this case, it overrides
<code>n_nonzero_coefs</code>.</p>
<p>split_sign : bool, default=False
Whether to split the sparse feature vector into the concatenation of
its negative part and its positive part. This can improve the
performance of downstream classifiers.</p>
<p>n_jobs : int or None, default=None
Number of parallel jobs to run.
<code>None</code> means 1 unless in a :obj:<code>joblib.parallel_backend</code> context.
<code>-1</code> means using all processors. See :term:<code>Glossary &lt;n_jobs&gt;</code>
for more details.</p>
<p>positive_code : bool, default=False
Whether to enforce positivity when finding the code.</p>
<p>.. versionadded:: 0.20</p>
<p>transform_max_iter : int, default=1000
Maximum number of iterations to perform if <code>algorithm='lasso_cd'</code> or
<code>lasso_lars</code>.</p>
<p>.. versionadded:: 0.22</p>
<h2 id="attributes_10">Attributes<a class="headerlink" href="#attributes_10" title="Permanent link">&para;</a></h2>
<p>components_ : array, [n_components, n_features]
The unchanged dictionary atoms</p>
<h2 id="see-also_6">See also<a class="headerlink" href="#see-also_6" title="Permanent link">&para;</a></h2>
<p>DictionaryLearning
MiniBatchDictionaryLearning
SparsePCA
MiniBatchSparsePCA
sparse_encode</p>
<div class="highlight"><pre><span></span><code><span class="k">val</span> <span class="n">fit</span> <span class="o">:</span> <span class="o">?</span><span class="n">y</span><span class="o">:</span><span class="nn">Py</span><span class="p">.</span><span class="nn">Object</span><span class="p">.</span><span class="n">t</span> <span class="o">-&gt;</span> <span class="n">x</span><span class="o">:</span><span class="nn">Py</span><span class="p">.</span><span class="nn">Object</span><span class="p">.</span><span class="n">t</span> <span class="o">-&gt;</span> <span class="o">[&gt;</span> <span class="n">tag</span><span class="o">]</span> <span class="nn">Obj</span><span class="p">.</span><span class="n">t</span> <span class="o">-&gt;</span> <span class="n">t</span>
</code></pre></div>

<p>Do nothing and return the estimator unchanged</p>
<p>This method is just there to implement the usual API and hence
work in pipelines.</p>
<h2 id="parameters_75">Parameters<a class="headerlink" href="#parameters_75" title="Permanent link">&para;</a></h2>
<p>X : Ignored</p>
<p>y : Ignored</p>
<h2 id="returns_70">Returns<a class="headerlink" href="#returns_70" title="Permanent link">&para;</a></h2>
<p>self : object
Returns the object itself</p>
<div class="highlight"><pre><span></span><code><span class="k">val</span> <span class="n">fit_transform</span> <span class="o">:</span> <span class="o">?</span><span class="n">y</span><span class="o">:[&gt;`</span><span class="nc">ArrayLike</span><span class="o">]</span> <span class="nn">Np</span><span class="p">.</span><span class="nn">Obj</span><span class="p">.</span><span class="n">t</span> <span class="o">-&gt;</span> <span class="o">?</span><span class="n">fit_params</span><span class="o">:(</span><span class="kt">string</span> <span class="o">*</span> <span class="nn">Py</span><span class="p">.</span><span class="nn">Object</span><span class="p">.</span><span class="n">t</span><span class="o">)</span> <span class="kt">list</span> <span class="o">-&gt;</span> <span class="n">x</span><span class="o">:[&gt;`</span><span class="nc">ArrayLike</span><span class="o">]</span> <span class="nn">Np</span><span class="p">.</span><span class="nn">Obj</span><span class="p">.</span><span class="n">t</span> <span class="o">-&gt;</span> <span class="o">[&gt;</span> <span class="n">tag</span><span class="o">]</span> <span class="nn">Obj</span><span class="p">.</span><span class="n">t</span> <span class="o">-&gt;</span> <span class="o">[&gt;`</span><span class="nc">ArrayLike</span><span class="o">]</span> <span class="nn">Np</span><span class="p">.</span><span class="nn">Obj</span><span class="p">.</span><span class="n">t</span>
</code></pre></div>

<p>Fit to data, then transform it.</p>
<p>Fits transformer to X and y with optional parameters fit_params
and returns a transformed version of X.</p>
<h2 id="parameters_76">Parameters<a class="headerlink" href="#parameters_76" title="Permanent link">&para;</a></h2>
<p>X : numpy array of shape [n_samples, n_features]
Training set.</p>
<p>y : numpy array of shape [n_samples]
Target values.</p>
<p>**fit_params : dict
Additional fit parameters.</p>
<h2 id="returns_71">Returns<a class="headerlink" href="#returns_71" title="Permanent link">&para;</a></h2>
<p>X_new : numpy array of shape [n_samples, n_features_new]
Transformed array.</p>
<div class="highlight"><pre><span></span><code><span class="k">val</span> <span class="n">get_params</span> <span class="o">:</span> <span class="o">?</span><span class="n">deep</span><span class="o">:</span><span class="kt">bool</span> <span class="o">-&gt;</span> <span class="o">[&gt;</span> <span class="n">tag</span><span class="o">]</span> <span class="nn">Obj</span><span class="p">.</span><span class="n">t</span> <span class="o">-&gt;</span> <span class="nn">Dict</span><span class="p">.</span><span class="n">t</span>
</code></pre></div>

<p>Get parameters for this estimator.</p>
<h2 id="parameters_77">Parameters<a class="headerlink" href="#parameters_77" title="Permanent link">&para;</a></h2>
<p>deep : bool, default=True
If True, will return the parameters for this estimator and
contained subobjects that are estimators.</p>
<h2 id="returns_72">Returns<a class="headerlink" href="#returns_72" title="Permanent link">&para;</a></h2>
<p>params : mapping of string to any
Parameter names mapped to their values.</p>
<div class="highlight"><pre><span></span><code><span class="k">val</span> <span class="n">set_params</span> <span class="o">:</span> <span class="o">?</span><span class="n">params</span><span class="o">:(</span><span class="kt">string</span> <span class="o">*</span> <span class="nn">Py</span><span class="p">.</span><span class="nn">Object</span><span class="p">.</span><span class="n">t</span><span class="o">)</span> <span class="kt">list</span> <span class="o">-&gt;</span> <span class="o">[&gt;</span> <span class="n">tag</span><span class="o">]</span> <span class="nn">Obj</span><span class="p">.</span><span class="n">t</span> <span class="o">-&gt;</span> <span class="n">t</span>
</code></pre></div>

<p>Set the parameters of this estimator.</p>
<p>The method works on simple estimators as well as on nested objects
(such as pipelines). The latter have parameters of the form
<code>&lt;component&gt;__&lt;parameter&gt;</code> so that it's possible to update each
component of a nested object.</p>
<h2 id="parameters_78">Parameters<a class="headerlink" href="#parameters_78" title="Permanent link">&para;</a></h2>
<p>**params : dict
Estimator parameters.</p>
<h2 id="returns_73">Returns<a class="headerlink" href="#returns_73" title="Permanent link">&para;</a></h2>
<p>self : object
Estimator instance.</p>
<div class="highlight"><pre><span></span><code><span class="k">val</span> <span class="n">transform</span> <span class="o">:</span> <span class="n">x</span><span class="o">:[&gt;`</span><span class="nc">ArrayLike</span><span class="o">]</span> <span class="nn">Np</span><span class="p">.</span><span class="nn">Obj</span><span class="p">.</span><span class="n">t</span> <span class="o">-&gt;</span> <span class="o">[&gt;</span> <span class="n">tag</span><span class="o">]</span> <span class="nn">Obj</span><span class="p">.</span><span class="n">t</span> <span class="o">-&gt;</span> <span class="o">[&gt;`</span><span class="nc">ArrayLike</span><span class="o">]</span> <span class="nn">Np</span><span class="p">.</span><span class="nn">Obj</span><span class="p">.</span><span class="n">t</span>
</code></pre></div>

<p>Encode the data as a sparse combination of the dictionary atoms.</p>
<p>Coding method is determined by the object parameter
<code>transform_algorithm</code>.</p>
<h2 id="parameters_79">Parameters<a class="headerlink" href="#parameters_79" title="Permanent link">&para;</a></h2>
<p>X : array of shape (n_samples, n_features)
Test data to be transformed, must have the same number of
features as the data used to train the model.</p>
<h2 id="returns_74">Returns<a class="headerlink" href="#returns_74" title="Permanent link">&para;</a></h2>
<p>X_new : array, shape (n_samples, n_components)
Transformed data</p>
<p>Attribute components_: get value or raise Not_found if None.</p>
<div class="highlight"><pre><span></span><code><span class="k">val</span> <span class="n">components_</span> <span class="o">:</span> <span class="n">t</span> <span class="o">-&gt;</span> <span class="o">[&gt;`</span><span class="nc">ArrayLike</span><span class="o">]</span> <span class="nn">Np</span><span class="p">.</span><span class="nn">Obj</span><span class="p">.</span><span class="n">t</span>
</code></pre></div>

<p>Attribute components_: get value as an option.</p>
<div class="highlight"><pre><span></span><code><span class="k">val</span> <span class="n">components_opt</span> <span class="o">:</span> <span class="n">t</span> <span class="o">-&gt;</span> <span class="o">([&gt;`</span><span class="nc">ArrayLike</span><span class="o">]</span> <span class="nn">Np</span><span class="p">.</span><span class="nn">Obj</span><span class="p">.</span><span class="n">t</span><span class="o">)</span> <span class="n">option</span>
</code></pre></div>

<p>Print the object to a human-readable representation.</p>
<div class="highlight"><pre><span></span><code><span class="k">val</span> <span class="n">to_string</span> <span class="o">:</span> <span class="n">t</span> <span class="o">-&gt;</span> <span class="kt">string</span>
</code></pre></div>

<p>Print the object to a human-readable representation.</p>
<div class="highlight"><pre><span></span><code><span class="k">val</span> <span class="n">show</span> <span class="o">:</span> <span class="n">t</span> <span class="o">-&gt;</span> <span class="kt">string</span>
</code></pre></div>

<p>Pretty-print the object to a formatter.</p>
<div class="highlight"><pre><span></span><code><span class="k">val</span> <span class="n">pp</span> <span class="o">:</span> <span class="nn">Format</span><span class="p">.</span><span class="n">formatter</span> <span class="o">-&gt;</span> <span class="n">t</span> <span class="o">-&gt;</span> <span class="kt">unit</span> <span class="o">[@@</span><span class="n">ocaml</span><span class="o">.</span><span class="n">toplevel_printer</span><span class="o">]</span>



<span class="k">module</span> <span class="nc">SparsePCA</span> <span class="o">:</span> <span class="k">sig</span>
<span class="k">type</span> <span class="n">tag</span> <span class="o">=</span> <span class="o">[`</span><span class="nc">SparsePCA</span><span class="o">]</span>
<span class="k">type</span> <span class="n">t</span> <span class="o">=</span> <span class="o">[`</span><span class="nc">BaseEstimator</span> <span class="o">|</span> <span class="o">`</span><span class="nc">Object</span> <span class="o">|</span> <span class="o">`</span><span class="nc">SparsePCA</span> <span class="o">|</span> <span class="o">`</span><span class="nc">TransformerMixin</span><span class="o">]</span> <span class="nn">Obj</span><span class="p">.</span><span class="n">t</span>
<span class="k">val</span> <span class="n">of_pyobject</span> <span class="o">:</span> <span class="nn">Py</span><span class="p">.</span><span class="nn">Object</span><span class="p">.</span><span class="n">t</span> <span class="o">-&gt;</span> <span class="n">t</span>
<span class="k">val</span> <span class="n">to_pyobject</span> <span class="o">:</span> <span class="o">[&gt;</span> <span class="n">tag</span><span class="o">]</span> <span class="nn">Obj</span><span class="p">.</span><span class="n">t</span> <span class="o">-&gt;</span> <span class="nn">Py</span><span class="p">.</span><span class="nn">Object</span><span class="p">.</span><span class="n">t</span>

<span class="k">val</span> <span class="n">as_transformer</span> <span class="o">:</span> <span class="n">t</span> <span class="o">-&gt;</span> <span class="o">[`</span><span class="nc">TransformerMixin</span><span class="o">]</span> <span class="nn">Obj</span><span class="p">.</span><span class="n">t</span>
<span class="k">val</span> <span class="n">as_estimator</span> <span class="o">:</span> <span class="n">t</span> <span class="o">-&gt;</span> <span class="o">[`</span><span class="nc">BaseEstimator</span><span class="o">]</span> <span class="nn">Obj</span><span class="p">.</span><span class="n">t</span>
<span class="k">val</span> <span class="n">create</span> <span class="o">:</span> <span class="o">?</span><span class="n">n_components</span><span class="o">:</span><span class="kt">int</span> <span class="o">-&gt;</span> <span class="o">?</span><span class="n">alpha</span><span class="o">:</span><span class="kt">float</span> <span class="o">-&gt;</span> <span class="o">?</span><span class="n">ridge_alpha</span><span class="o">:</span><span class="kt">float</span> <span class="o">-&gt;</span> <span class="o">?</span><span class="n">max_iter</span><span class="o">:</span><span class="kt">int</span> <span class="o">-&gt;</span> <span class="o">?</span><span class="n">tol</span><span class="o">:</span><span class="kt">float</span> <span class="o">-&gt;</span> <span class="o">?</span><span class="n">method_</span><span class="o">:[`</span><span class="nc">Lars</span> <span class="o">|</span> <span class="o">`</span><span class="nc">Cd</span><span class="o">]</span> <span class="o">-&gt;</span> <span class="o">?</span><span class="n">n_jobs</span><span class="o">:</span><span class="kt">int</span> <span class="o">-&gt;</span> <span class="o">?</span><span class="n">u_init</span><span class="o">:[&gt;`</span><span class="nc">ArrayLike</span><span class="o">]</span> <span class="nn">Np</span><span class="p">.</span><span class="nn">Obj</span><span class="p">.</span><span class="n">t</span> <span class="o">-&gt;</span> <span class="o">?</span><span class="n">v_init</span><span class="o">:[&gt;`</span><span class="nc">ArrayLike</span><span class="o">]</span> <span class="nn">Np</span><span class="p">.</span><span class="nn">Obj</span><span class="p">.</span><span class="n">t</span> <span class="o">-&gt;</span> <span class="o">?</span><span class="n">verbose</span><span class="o">:</span><span class="kt">int</span> <span class="o">-&gt;</span> <span class="o">?</span><span class="n">random_state</span><span class="o">:</span><span class="kt">int</span> <span class="o">-&gt;</span> <span class="o">?</span><span class="n">normalize_components</span><span class="o">:[`</span><span class="nc">Deprecated</span><span class="o">]</span> <span class="o">-&gt;</span> <span class="kt">unit</span> <span class="o">-&gt;</span> <span class="n">t</span>
</code></pre></div>

<p>Sparse Principal Components Analysis (SparsePCA)</p>
<p>Finds the set of sparse components that can optimally reconstruct
the data.  The amount of sparseness is controllable by the coefficient
of the L1 penalty, given by the parameter alpha.</p>
<p>Read more in the :ref:<code>User Guide &lt;SparsePCA&gt;</code>.</p>
<h2 id="parameters_80">Parameters<a class="headerlink" href="#parameters_80" title="Permanent link">&para;</a></h2>
<p>n_components : int,
Number of sparse atoms to extract.</p>
<p>alpha : float,
Sparsity controlling parameter. Higher values lead to sparser
components.</p>
<p>ridge_alpha : float,
Amount of ridge shrinkage to apply in order to improve
conditioning when calling the transform method.</p>
<p>max_iter : int,
Maximum number of iterations to perform.</p>
<p>tol : float,
Tolerance for the stopping condition.</p>
<p>method : {'lars', 'cd'}
lars: uses the least angle regression method to solve the lasso problem
(linear_model.lars_path)
cd: uses the coordinate descent method to compute the
Lasso solution (linear_model.Lasso). Lars will be faster if
the estimated components are sparse.</p>
<p>n_jobs : int or None, optional (default=None)
Number of parallel jobs to run.
<code>None</code> means 1 unless in a :obj:<code>joblib.parallel_backend</code> context.
<code>-1</code> means using all processors. See :term:<code>Glossary &lt;n_jobs&gt;</code>
for more details.</p>
<p>U_init : array of shape (n_samples, n_components),
Initial values for the loadings for warm restart scenarios.</p>
<p>V_init : array of shape (n_components, n_features),
Initial values for the components for warm restart scenarios.</p>
<p>verbose : int
Controls the verbosity; the higher, the more messages. Defaults to 0.</p>
<p>random_state : int, RandomState instance or None, optional (default=None)
If int, random_state is the seed used by the random number generator;
If RandomState instance, random_state is the random number generator;
If None, the random number generator is the RandomState instance used
by <code>np.random</code>.</p>
<p>normalize_components : 'deprecated'
This parameter does not have any effect. The components are always
normalized.</p>
<p>.. versionadded:: 0.20</p>
<p>.. deprecated:: 0.22
<code>normalize_components</code> is deprecated in 0.22 and will be removed
in 0.24.</p>
<h2 id="attributes_11">Attributes<a class="headerlink" href="#attributes_11" title="Permanent link">&para;</a></h2>
<p>components_ : array, [n_components, n_features]
Sparse components extracted from the data.</p>
<p>error_ : array
Vector of errors at each iteration.</p>
<p>n_iter_ : int
Number of iterations run.</p>
<p>mean_ : array, shape (n_features,)
Per-feature empirical mean, estimated from the training set.
Equal to <code>X.mean(axis=0)</code>.</p>
<h2 id="examples_10">Examples<a class="headerlink" href="#examples_10" title="Permanent link">&para;</a></h2>
<blockquote>
<blockquote>
<blockquote>
<p>import numpy as np
from sklearn.datasets import make_friedman1
from sklearn.decomposition import SparsePCA
X, _ = make_friedman1(n_samples=200, n_features=30, random_state=0)
transformer = SparsePCA(n_components=5, random_state=0)
transformer.fit(X)
SparsePCA(...)
X_transformed = transformer.transform(X)
X_transformed.shape
(200, 5)</p>
<h1 id="most-values-in-the-components_-are-zero-sparsity_1">most values in the components_ are zero (sparsity)<a class="headerlink" href="#most-values-in-the-components_-are-zero-sparsity_1" title="Permanent link">&para;</a></h1>
<p>np.mean(transformer.components_ == 0)
0.9666...</p>
</blockquote>
</blockquote>
</blockquote>
<h2 id="see-also_7">See also<a class="headerlink" href="#see-also_7" title="Permanent link">&para;</a></h2>
<p>PCA
MiniBatchSparsePCA
DictionaryLearning</p>
<div class="highlight"><pre><span></span><code><span class="k">val</span> <span class="n">fit</span> <span class="o">:</span> <span class="o">?</span><span class="n">y</span><span class="o">:</span><span class="nn">Py</span><span class="p">.</span><span class="nn">Object</span><span class="p">.</span><span class="n">t</span> <span class="o">-&gt;</span> <span class="n">x</span><span class="o">:[&gt;`</span><span class="nc">ArrayLike</span><span class="o">]</span> <span class="nn">Np</span><span class="p">.</span><span class="nn">Obj</span><span class="p">.</span><span class="n">t</span> <span class="o">-&gt;</span> <span class="o">[&gt;</span> <span class="n">tag</span><span class="o">]</span> <span class="nn">Obj</span><span class="p">.</span><span class="n">t</span> <span class="o">-&gt;</span> <span class="n">t</span>
</code></pre></div>

<p>Fit the model from data in X.</p>
<h2 id="parameters_81">Parameters<a class="headerlink" href="#parameters_81" title="Permanent link">&para;</a></h2>
<p>X : array-like, shape (n_samples, n_features)
Training vector, where n_samples in the number of samples
and n_features is the number of features.</p>
<p>y : Ignored</p>
<h2 id="returns_75">Returns<a class="headerlink" href="#returns_75" title="Permanent link">&para;</a></h2>
<p>self : object
Returns the instance itself.</p>
<div class="highlight"><pre><span></span><code><span class="k">val</span> <span class="n">fit_transform</span> <span class="o">:</span> <span class="o">?</span><span class="n">y</span><span class="o">:[&gt;`</span><span class="nc">ArrayLike</span><span class="o">]</span> <span class="nn">Np</span><span class="p">.</span><span class="nn">Obj</span><span class="p">.</span><span class="n">t</span> <span class="o">-&gt;</span> <span class="o">?</span><span class="n">fit_params</span><span class="o">:(</span><span class="kt">string</span> <span class="o">*</span> <span class="nn">Py</span><span class="p">.</span><span class="nn">Object</span><span class="p">.</span><span class="n">t</span><span class="o">)</span> <span class="kt">list</span> <span class="o">-&gt;</span> <span class="n">x</span><span class="o">:[&gt;`</span><span class="nc">ArrayLike</span><span class="o">]</span> <span class="nn">Np</span><span class="p">.</span><span class="nn">Obj</span><span class="p">.</span><span class="n">t</span> <span class="o">-&gt;</span> <span class="o">[&gt;</span> <span class="n">tag</span><span class="o">]</span> <span class="nn">Obj</span><span class="p">.</span><span class="n">t</span> <span class="o">-&gt;</span> <span class="o">[&gt;`</span><span class="nc">ArrayLike</span><span class="o">]</span> <span class="nn">Np</span><span class="p">.</span><span class="nn">Obj</span><span class="p">.</span><span class="n">t</span>
</code></pre></div>

<p>Fit to data, then transform it.</p>
<p>Fits transformer to X and y with optional parameters fit_params
and returns a transformed version of X.</p>
<h2 id="parameters_82">Parameters<a class="headerlink" href="#parameters_82" title="Permanent link">&para;</a></h2>
<p>X : numpy array of shape [n_samples, n_features]
Training set.</p>
<p>y : numpy array of shape [n_samples]
Target values.</p>
<p>**fit_params : dict
Additional fit parameters.</p>
<h2 id="returns_76">Returns<a class="headerlink" href="#returns_76" title="Permanent link">&para;</a></h2>
<p>X_new : numpy array of shape [n_samples, n_features_new]
Transformed array.</p>
<div class="highlight"><pre><span></span><code><span class="k">val</span> <span class="n">get_params</span> <span class="o">:</span> <span class="o">?</span><span class="n">deep</span><span class="o">:</span><span class="kt">bool</span> <span class="o">-&gt;</span> <span class="o">[&gt;</span> <span class="n">tag</span><span class="o">]</span> <span class="nn">Obj</span><span class="p">.</span><span class="n">t</span> <span class="o">-&gt;</span> <span class="nn">Dict</span><span class="p">.</span><span class="n">t</span>
</code></pre></div>

<p>Get parameters for this estimator.</p>
<h2 id="parameters_83">Parameters<a class="headerlink" href="#parameters_83" title="Permanent link">&para;</a></h2>
<p>deep : bool, default=True
If True, will return the parameters for this estimator and
contained subobjects that are estimators.</p>
<h2 id="returns_77">Returns<a class="headerlink" href="#returns_77" title="Permanent link">&para;</a></h2>
<p>params : mapping of string to any
Parameter names mapped to their values.</p>
<div class="highlight"><pre><span></span><code><span class="k">val</span> <span class="n">set_params</span> <span class="o">:</span> <span class="o">?</span><span class="n">params</span><span class="o">:(</span><span class="kt">string</span> <span class="o">*</span> <span class="nn">Py</span><span class="p">.</span><span class="nn">Object</span><span class="p">.</span><span class="n">t</span><span class="o">)</span> <span class="kt">list</span> <span class="o">-&gt;</span> <span class="o">[&gt;</span> <span class="n">tag</span><span class="o">]</span> <span class="nn">Obj</span><span class="p">.</span><span class="n">t</span> <span class="o">-&gt;</span> <span class="n">t</span>
</code></pre></div>

<p>Set the parameters of this estimator.</p>
<p>The method works on simple estimators as well as on nested objects
(such as pipelines). The latter have parameters of the form
<code>&lt;component&gt;__&lt;parameter&gt;</code> so that it's possible to update each
component of a nested object.</p>
<h2 id="parameters_84">Parameters<a class="headerlink" href="#parameters_84" title="Permanent link">&para;</a></h2>
<p>**params : dict
Estimator parameters.</p>
<h2 id="returns_78">Returns<a class="headerlink" href="#returns_78" title="Permanent link">&para;</a></h2>
<p>self : object
Estimator instance.</p>
<div class="highlight"><pre><span></span><code><span class="k">val</span> <span class="n">transform</span> <span class="o">:</span> <span class="n">x</span><span class="o">:[&gt;`</span><span class="nc">ArrayLike</span><span class="o">]</span> <span class="nn">Np</span><span class="p">.</span><span class="nn">Obj</span><span class="p">.</span><span class="n">t</span> <span class="o">-&gt;</span> <span class="o">[&gt;</span> <span class="n">tag</span><span class="o">]</span> <span class="nn">Obj</span><span class="p">.</span><span class="n">t</span> <span class="o">-&gt;</span> <span class="o">[&gt;`</span><span class="nc">ArrayLike</span><span class="o">]</span> <span class="nn">Np</span><span class="p">.</span><span class="nn">Obj</span><span class="p">.</span><span class="n">t</span>
</code></pre></div>

<p>Least Squares projection of the data onto the sparse components.</p>
<p>To avoid instability issues in case the system is under-determined,
regularization can be applied (Ridge regression) via the
<code>ridge_alpha</code> parameter.</p>
<p>Note that Sparse PCA components orthogonality is not enforced as in PCA
hence one cannot use a simple linear projection.</p>
<h2 id="parameters_85">Parameters<a class="headerlink" href="#parameters_85" title="Permanent link">&para;</a></h2>
<p>X : array of shape (n_samples, n_features)
Test data to be transformed, must have the same number of
features as the data used to train the model.</p>
<h2 id="returns_79">Returns<a class="headerlink" href="#returns_79" title="Permanent link">&para;</a></h2>
<p>X_new array, shape (n_samples, n_components)
Transformed data.</p>
<p>Attribute components_: get value or raise Not_found if None.</p>
<div class="highlight"><pre><span></span><code><span class="k">val</span> <span class="n">components_</span> <span class="o">:</span> <span class="n">t</span> <span class="o">-&gt;</span> <span class="o">[&gt;`</span><span class="nc">ArrayLike</span><span class="o">]</span> <span class="nn">Np</span><span class="p">.</span><span class="nn">Obj</span><span class="p">.</span><span class="n">t</span>
</code></pre></div>

<p>Attribute components_: get value as an option.</p>
<div class="highlight"><pre><span></span><code><span class="k">val</span> <span class="n">components_opt</span> <span class="o">:</span> <span class="n">t</span> <span class="o">-&gt;</span> <span class="o">([&gt;`</span><span class="nc">ArrayLike</span><span class="o">]</span> <span class="nn">Np</span><span class="p">.</span><span class="nn">Obj</span><span class="p">.</span><span class="n">t</span><span class="o">)</span> <span class="n">option</span>
</code></pre></div>

<p>Attribute error_: get value or raise Not_found if None.</p>
<div class="highlight"><pre><span></span><code><span class="k">val</span> <span class="n">error_</span> <span class="o">:</span> <span class="n">t</span> <span class="o">-&gt;</span> <span class="o">[&gt;`</span><span class="nc">ArrayLike</span><span class="o">]</span> <span class="nn">Np</span><span class="p">.</span><span class="nn">Obj</span><span class="p">.</span><span class="n">t</span>
</code></pre></div>

<p>Attribute error_: get value as an option.</p>
<div class="highlight"><pre><span></span><code><span class="k">val</span> <span class="n">error_opt</span> <span class="o">:</span> <span class="n">t</span> <span class="o">-&gt;</span> <span class="o">([&gt;`</span><span class="nc">ArrayLike</span><span class="o">]</span> <span class="nn">Np</span><span class="p">.</span><span class="nn">Obj</span><span class="p">.</span><span class="n">t</span><span class="o">)</span> <span class="n">option</span>
</code></pre></div>

<p>Attribute n_iter_: get value or raise Not_found if None.</p>
<div class="highlight"><pre><span></span><code><span class="k">val</span> <span class="n">n_iter_</span> <span class="o">:</span> <span class="n">t</span> <span class="o">-&gt;</span> <span class="kt">int</span>
</code></pre></div>

<p>Attribute n_iter_: get value as an option.</p>
<div class="highlight"><pre><span></span><code><span class="k">val</span> <span class="n">n_iter_opt</span> <span class="o">:</span> <span class="n">t</span> <span class="o">-&gt;</span> <span class="o">(</span><span class="kt">int</span><span class="o">)</span> <span class="n">option</span>
</code></pre></div>

<p>Attribute mean_: get value or raise Not_found if None.</p>
<div class="highlight"><pre><span></span><code><span class="k">val</span> <span class="n">mean_</span> <span class="o">:</span> <span class="n">t</span> <span class="o">-&gt;</span> <span class="o">[&gt;`</span><span class="nc">ArrayLike</span><span class="o">]</span> <span class="nn">Np</span><span class="p">.</span><span class="nn">Obj</span><span class="p">.</span><span class="n">t</span>
</code></pre></div>

<p>Attribute mean_: get value as an option.</p>
<div class="highlight"><pre><span></span><code><span class="k">val</span> <span class="n">mean_opt</span> <span class="o">:</span> <span class="n">t</span> <span class="o">-&gt;</span> <span class="o">([&gt;`</span><span class="nc">ArrayLike</span><span class="o">]</span> <span class="nn">Np</span><span class="p">.</span><span class="nn">Obj</span><span class="p">.</span><span class="n">t</span><span class="o">)</span> <span class="n">option</span>
</code></pre></div>

<p>Print the object to a human-readable representation.</p>
<div class="highlight"><pre><span></span><code><span class="k">val</span> <span class="n">to_string</span> <span class="o">:</span> <span class="n">t</span> <span class="o">-&gt;</span> <span class="kt">string</span>
</code></pre></div>

<p>Print the object to a human-readable representation.</p>
<div class="highlight"><pre><span></span><code><span class="k">val</span> <span class="n">show</span> <span class="o">:</span> <span class="n">t</span> <span class="o">-&gt;</span> <span class="kt">string</span>
</code></pre></div>

<p>Pretty-print the object to a formatter.</p>
<div class="highlight"><pre><span></span><code><span class="k">val</span> <span class="n">pp</span> <span class="o">:</span> <span class="nn">Format</span><span class="p">.</span><span class="n">formatter</span> <span class="o">-&gt;</span> <span class="n">t</span> <span class="o">-&gt;</span> <span class="kt">unit</span> <span class="o">[@@</span><span class="n">ocaml</span><span class="o">.</span><span class="n">toplevel_printer</span><span class="o">]</span>



<span class="k">module</span> <span class="nc">TruncatedSVD</span> <span class="o">:</span> <span class="k">sig</span>
<span class="k">type</span> <span class="n">tag</span> <span class="o">=</span> <span class="o">[`</span><span class="nc">TruncatedSVD</span><span class="o">]</span>
<span class="k">type</span> <span class="n">t</span> <span class="o">=</span> <span class="o">[`</span><span class="nc">BaseEstimator</span> <span class="o">|</span> <span class="o">`</span><span class="nc">Object</span> <span class="o">|</span> <span class="o">`</span><span class="nc">TransformerMixin</span> <span class="o">|</span> <span class="o">`</span><span class="nc">TruncatedSVD</span><span class="o">]</span> <span class="nn">Obj</span><span class="p">.</span><span class="n">t</span>
<span class="k">val</span> <span class="n">of_pyobject</span> <span class="o">:</span> <span class="nn">Py</span><span class="p">.</span><span class="nn">Object</span><span class="p">.</span><span class="n">t</span> <span class="o">-&gt;</span> <span class="n">t</span>
<span class="k">val</span> <span class="n">to_pyobject</span> <span class="o">:</span> <span class="o">[&gt;</span> <span class="n">tag</span><span class="o">]</span> <span class="nn">Obj</span><span class="p">.</span><span class="n">t</span> <span class="o">-&gt;</span> <span class="nn">Py</span><span class="p">.</span><span class="nn">Object</span><span class="p">.</span><span class="n">t</span>

<span class="k">val</span> <span class="n">as_transformer</span> <span class="o">:</span> <span class="n">t</span> <span class="o">-&gt;</span> <span class="o">[`</span><span class="nc">TransformerMixin</span><span class="o">]</span> <span class="nn">Obj</span><span class="p">.</span><span class="n">t</span>
<span class="k">val</span> <span class="n">as_estimator</span> <span class="o">:</span> <span class="n">t</span> <span class="o">-&gt;</span> <span class="o">[`</span><span class="nc">BaseEstimator</span><span class="o">]</span> <span class="nn">Obj</span><span class="p">.</span><span class="n">t</span>
<span class="k">val</span> <span class="n">create</span> <span class="o">:</span> <span class="o">?</span><span class="n">n_components</span><span class="o">:</span><span class="kt">int</span> <span class="o">-&gt;</span> <span class="o">?</span><span class="n">algorithm</span><span class="o">:</span><span class="kt">string</span> <span class="o">-&gt;</span> <span class="o">?</span><span class="n">n_iter</span><span class="o">:</span><span class="kt">int</span> <span class="o">-&gt;</span> <span class="o">?</span><span class="n">random_state</span><span class="o">:</span><span class="kt">int</span> <span class="o">-&gt;</span> <span class="o">?</span><span class="n">tol</span><span class="o">:</span><span class="kt">float</span> <span class="o">-&gt;</span> <span class="kt">unit</span> <span class="o">-&gt;</span> <span class="n">t</span>
</code></pre></div>

<p>Dimensionality reduction using truncated SVD (aka LSA).</p>
<p>This transformer performs linear dimensionality reduction by means of
truncated singular value decomposition (SVD). Contrary to PCA, this
estimator does not center the data before computing the singular value
decomposition. This means it can work with scipy.sparse matrices
efficiently.</p>
<p>In particular, truncated SVD works on term count/tf-idf matrices as
returned by the vectorizers in sklearn.feature_extraction.text. In that
context, it is known as latent semantic analysis (LSA).</p>
<p>This estimator supports two algorithms: a fast randomized SVD solver, and
a 'naive' algorithm that uses ARPACK as an eigensolver on (X * X.T) or
(X.T * X), whichever is more efficient.</p>
<p>Read more in the :ref:<code>User Guide &lt;LSA&gt;</code>.</p>
<h2 id="parameters_86">Parameters<a class="headerlink" href="#parameters_86" title="Permanent link">&para;</a></h2>
<p>n_components : int, default = 2
Desired dimensionality of output data.
Must be strictly less than the number of features.
The default value is useful for visualisation. For LSA, a value of
100 is recommended.</p>
<p>algorithm : string, default = 'randomized'
SVD solver to use. Either 'arpack' for the ARPACK wrapper in SciPy
(scipy.sparse.linalg.svds), or 'randomized' for the randomized
algorithm due to Halko (2009).</p>
<p>n_iter : int, optional (default 5)
Number of iterations for randomized SVD solver. Not used by ARPACK. The
default is larger than the default in
<code>~sklearn.utils.extmath.randomized_svd</code> to handle sparse matrices that
may have large slowly decaying spectrum.</p>
<p>random_state : int, RandomState instance or None, optional, default = None
If int, random_state is the seed used by the random number generator;
If RandomState instance, random_state is the random number generator;
If None, the random number generator is the RandomState instance used
by <code>np.random</code>.</p>
<p>tol : float, optional
Tolerance for ARPACK. 0 means machine precision. Ignored by randomized
SVD solver.</p>
<h2 id="attributes_12">Attributes<a class="headerlink" href="#attributes_12" title="Permanent link">&para;</a></h2>
<p>components_ : array, shape (n_components, n_features)</p>
<p>explained_variance_ : array, shape (n_components,)
The variance of the training samples transformed by a projection to
each component.</p>
<p>explained_variance_ratio_ : array, shape (n_components,)
Percentage of variance explained by each of the selected components.</p>
<p>singular_values_ : array, shape (n_components,)
The singular values corresponding to each of the selected components.
The singular values are equal to the 2-norms of the <code>n_components</code>
variables in the lower-dimensional space.</p>
<h2 id="examples_11">Examples<a class="headerlink" href="#examples_11" title="Permanent link">&para;</a></h2>
<blockquote>
<blockquote>
<blockquote>
<p>from sklearn.decomposition import TruncatedSVD
from scipy.sparse import random as sparse_random
from sklearn.random_projection import sparse_random_matrix
X = sparse_random(100, 100, density=0.01, format='csr',
...                   random_state=42)
svd = TruncatedSVD(n_components=5, n_iter=7, random_state=42)
svd.fit(X)
TruncatedSVD(n_components=5, n_iter=7, random_state=42)
print(svd.explained_variance_ratio_)
[0.0646... 0.0633... 0.0639... 0.0535... 0.0406...]
print(svd.explained_variance_ratio_.sum())
0.286...
print(svd.singular_values_)
[1.553... 1.512...  1.510... 1.370... 1.199...]</p>
</blockquote>
</blockquote>
</blockquote>
<h2 id="see-also_8">See also<a class="headerlink" href="#see-also_8" title="Permanent link">&para;</a></h2>
<p>PCA</p>
<h2 id="references_7">References<a class="headerlink" href="#references_7" title="Permanent link">&para;</a></h2>
<p>Finding structure with randomness: Stochastic algorithms for constructing
approximate matrix decompositions
Halko, et al., 2009 (arXiv:909) https://arxiv.org/pdf/0909.4061.pdf</p>
<h2 id="notes_7">Notes<a class="headerlink" href="#notes_7" title="Permanent link">&para;</a></h2>
<p>SVD suffers from a problem called 'sign indeterminacy', which means the
sign of the <code>components_</code> and the output from transform depend on the
algorithm and random state. To work around this, fit instances of this
class to data once, then keep the instance around to do transformations.</p>
<div class="highlight"><pre><span></span><code><span class="k">val</span> <span class="n">fit</span> <span class="o">:</span> <span class="o">?</span><span class="n">y</span><span class="o">:</span><span class="nn">Py</span><span class="p">.</span><span class="nn">Object</span><span class="p">.</span><span class="n">t</span> <span class="o">-&gt;</span> <span class="n">x</span><span class="o">:[&gt;`</span><span class="nc">ArrayLike</span><span class="o">]</span> <span class="nn">Np</span><span class="p">.</span><span class="nn">Obj</span><span class="p">.</span><span class="n">t</span> <span class="o">-&gt;</span> <span class="o">[&gt;</span> <span class="n">tag</span><span class="o">]</span> <span class="nn">Obj</span><span class="p">.</span><span class="n">t</span> <span class="o">-&gt;</span> <span class="n">t</span>
</code></pre></div>

<p>Fit LSI model on training data X.</p>
<h2 id="parameters_87">Parameters<a class="headerlink" href="#parameters_87" title="Permanent link">&para;</a></h2>
<p>X : {array-like, sparse matrix}, shape (n_samples, n_features)
Training data.</p>
<p>y : Ignored</p>
<h2 id="returns_80">Returns<a class="headerlink" href="#returns_80" title="Permanent link">&para;</a></h2>
<p>self : object
Returns the transformer object.</p>
<div class="highlight"><pre><span></span><code><span class="k">val</span> <span class="n">fit_transform</span> <span class="o">:</span> <span class="o">?</span><span class="n">y</span><span class="o">:</span><span class="nn">Py</span><span class="p">.</span><span class="nn">Object</span><span class="p">.</span><span class="n">t</span> <span class="o">-&gt;</span> <span class="n">x</span><span class="o">:[&gt;`</span><span class="nc">ArrayLike</span><span class="o">]</span> <span class="nn">Np</span><span class="p">.</span><span class="nn">Obj</span><span class="p">.</span><span class="n">t</span> <span class="o">-&gt;</span> <span class="o">[&gt;</span> <span class="n">tag</span><span class="o">]</span> <span class="nn">Obj</span><span class="p">.</span><span class="n">t</span> <span class="o">-&gt;</span> <span class="o">[&gt;`</span><span class="nc">ArrayLike</span><span class="o">]</span> <span class="nn">Np</span><span class="p">.</span><span class="nn">Obj</span><span class="p">.</span><span class="n">t</span>
</code></pre></div>

<p>Fit LSI model to X and perform dimensionality reduction on X.</p>
<h2 id="parameters_88">Parameters<a class="headerlink" href="#parameters_88" title="Permanent link">&para;</a></h2>
<p>X : {array-like, sparse matrix}, shape (n_samples, n_features)
Training data.</p>
<p>y : Ignored</p>
<h2 id="returns_81">Returns<a class="headerlink" href="#returns_81" title="Permanent link">&para;</a></h2>
<p>X_new : array, shape (n_samples, n_components)
Reduced version of X. This will always be a dense array.</p>
<div class="highlight"><pre><span></span><code><span class="k">val</span> <span class="n">get_params</span> <span class="o">:</span> <span class="o">?</span><span class="n">deep</span><span class="o">:</span><span class="kt">bool</span> <span class="o">-&gt;</span> <span class="o">[&gt;</span> <span class="n">tag</span><span class="o">]</span> <span class="nn">Obj</span><span class="p">.</span><span class="n">t</span> <span class="o">-&gt;</span> <span class="nn">Dict</span><span class="p">.</span><span class="n">t</span>
</code></pre></div>

<p>Get parameters for this estimator.</p>
<h2 id="parameters_89">Parameters<a class="headerlink" href="#parameters_89" title="Permanent link">&para;</a></h2>
<p>deep : bool, default=True
If True, will return the parameters for this estimator and
contained subobjects that are estimators.</p>
<h2 id="returns_82">Returns<a class="headerlink" href="#returns_82" title="Permanent link">&para;</a></h2>
<p>params : mapping of string to any
Parameter names mapped to their values.</p>
<div class="highlight"><pre><span></span><code><span class="k">val</span> <span class="n">inverse_transform</span> <span class="o">:</span> <span class="n">x</span><span class="o">:[&gt;`</span><span class="nc">ArrayLike</span><span class="o">]</span> <span class="nn">Np</span><span class="p">.</span><span class="nn">Obj</span><span class="p">.</span><span class="n">t</span> <span class="o">-&gt;</span> <span class="o">[&gt;</span> <span class="n">tag</span><span class="o">]</span> <span class="nn">Obj</span><span class="p">.</span><span class="n">t</span> <span class="o">-&gt;</span> <span class="o">[&gt;`</span><span class="nc">ArrayLike</span><span class="o">]</span> <span class="nn">Np</span><span class="p">.</span><span class="nn">Obj</span><span class="p">.</span><span class="n">t</span>
</code></pre></div>

<p>Transform X back to its original space.</p>
<p>Returns an array X_original whose transform would be X.</p>
<h2 id="parameters_90">Parameters<a class="headerlink" href="#parameters_90" title="Permanent link">&para;</a></h2>
<p>X : array-like, shape (n_samples, n_components)
New data.</p>
<h2 id="returns_83">Returns<a class="headerlink" href="#returns_83" title="Permanent link">&para;</a></h2>
<p>X_original : array, shape (n_samples, n_features)
Note that this is always a dense array.</p>
<div class="highlight"><pre><span></span><code><span class="k">val</span> <span class="n">set_params</span> <span class="o">:</span> <span class="o">?</span><span class="n">params</span><span class="o">:(</span><span class="kt">string</span> <span class="o">*</span> <span class="nn">Py</span><span class="p">.</span><span class="nn">Object</span><span class="p">.</span><span class="n">t</span><span class="o">)</span> <span class="kt">list</span> <span class="o">-&gt;</span> <span class="o">[&gt;</span> <span class="n">tag</span><span class="o">]</span> <span class="nn">Obj</span><span class="p">.</span><span class="n">t</span> <span class="o">-&gt;</span> <span class="n">t</span>
</code></pre></div>

<p>Set the parameters of this estimator.</p>
<p>The method works on simple estimators as well as on nested objects
(such as pipelines). The latter have parameters of the form
<code>&lt;component&gt;__&lt;parameter&gt;</code> so that it's possible to update each
component of a nested object.</p>
<h2 id="parameters_91">Parameters<a class="headerlink" href="#parameters_91" title="Permanent link">&para;</a></h2>
<p>**params : dict
Estimator parameters.</p>
<h2 id="returns_84">Returns<a class="headerlink" href="#returns_84" title="Permanent link">&para;</a></h2>
<p>self : object
Estimator instance.</p>
<div class="highlight"><pre><span></span><code><span class="k">val</span> <span class="n">transform</span> <span class="o">:</span> <span class="n">x</span><span class="o">:[&gt;`</span><span class="nc">ArrayLike</span><span class="o">]</span> <span class="nn">Np</span><span class="p">.</span><span class="nn">Obj</span><span class="p">.</span><span class="n">t</span> <span class="o">-&gt;</span> <span class="o">[&gt;</span> <span class="n">tag</span><span class="o">]</span> <span class="nn">Obj</span><span class="p">.</span><span class="n">t</span> <span class="o">-&gt;</span> <span class="o">[&gt;`</span><span class="nc">ArrayLike</span><span class="o">]</span> <span class="nn">Np</span><span class="p">.</span><span class="nn">Obj</span><span class="p">.</span><span class="n">t</span>
</code></pre></div>

<p>Perform dimensionality reduction on X.</p>
<h2 id="parameters_92">Parameters<a class="headerlink" href="#parameters_92" title="Permanent link">&para;</a></h2>
<p>X : {array-like, sparse matrix}, shape (n_samples, n_features)
New data.</p>
<h2 id="returns_85">Returns<a class="headerlink" href="#returns_85" title="Permanent link">&para;</a></h2>
<p>X_new : array, shape (n_samples, n_components)
Reduced version of X. This will always be a dense array.</p>
<p>Attribute components_: get value or raise Not_found if None.</p>
<div class="highlight"><pre><span></span><code><span class="k">val</span> <span class="n">components_</span> <span class="o">:</span> <span class="n">t</span> <span class="o">-&gt;</span> <span class="o">[&gt;`</span><span class="nc">ArrayLike</span><span class="o">]</span> <span class="nn">Np</span><span class="p">.</span><span class="nn">Obj</span><span class="p">.</span><span class="n">t</span>
</code></pre></div>

<p>Attribute components_: get value as an option.</p>
<div class="highlight"><pre><span></span><code><span class="k">val</span> <span class="n">components_opt</span> <span class="o">:</span> <span class="n">t</span> <span class="o">-&gt;</span> <span class="o">([&gt;`</span><span class="nc">ArrayLike</span><span class="o">]</span> <span class="nn">Np</span><span class="p">.</span><span class="nn">Obj</span><span class="p">.</span><span class="n">t</span><span class="o">)</span> <span class="n">option</span>
</code></pre></div>

<p>Attribute explained_variance_: get value or raise Not_found if None.</p>
<div class="highlight"><pre><span></span><code><span class="k">val</span> <span class="n">explained_variance_</span> <span class="o">:</span> <span class="n">t</span> <span class="o">-&gt;</span> <span class="o">[&gt;`</span><span class="nc">ArrayLike</span><span class="o">]</span> <span class="nn">Np</span><span class="p">.</span><span class="nn">Obj</span><span class="p">.</span><span class="n">t</span>
</code></pre></div>

<p>Attribute explained_variance_: get value as an option.</p>
<div class="highlight"><pre><span></span><code><span class="k">val</span> <span class="n">explained_variance_opt</span> <span class="o">:</span> <span class="n">t</span> <span class="o">-&gt;</span> <span class="o">([&gt;`</span><span class="nc">ArrayLike</span><span class="o">]</span> <span class="nn">Np</span><span class="p">.</span><span class="nn">Obj</span><span class="p">.</span><span class="n">t</span><span class="o">)</span> <span class="n">option</span>
</code></pre></div>

<p>Attribute explained_variance_ratio_: get value or raise Not_found if None.</p>
<div class="highlight"><pre><span></span><code><span class="k">val</span> <span class="n">explained_variance_ratio_</span> <span class="o">:</span> <span class="n">t</span> <span class="o">-&gt;</span> <span class="o">[&gt;`</span><span class="nc">ArrayLike</span><span class="o">]</span> <span class="nn">Np</span><span class="p">.</span><span class="nn">Obj</span><span class="p">.</span><span class="n">t</span>
</code></pre></div>

<p>Attribute explained_variance_ratio_: get value as an option.</p>
<div class="highlight"><pre><span></span><code><span class="k">val</span> <span class="n">explained_variance_ratio_opt</span> <span class="o">:</span> <span class="n">t</span> <span class="o">-&gt;</span> <span class="o">([&gt;`</span><span class="nc">ArrayLike</span><span class="o">]</span> <span class="nn">Np</span><span class="p">.</span><span class="nn">Obj</span><span class="p">.</span><span class="n">t</span><span class="o">)</span> <span class="n">option</span>
</code></pre></div>

<p>Attribute singular_values_: get value or raise Not_found if None.</p>
<div class="highlight"><pre><span></span><code><span class="k">val</span> <span class="n">singular_values_</span> <span class="o">:</span> <span class="n">t</span> <span class="o">-&gt;</span> <span class="o">[&gt;`</span><span class="nc">ArrayLike</span><span class="o">]</span> <span class="nn">Np</span><span class="p">.</span><span class="nn">Obj</span><span class="p">.</span><span class="n">t</span>
</code></pre></div>

<p>Attribute singular_values_: get value as an option.</p>
<div class="highlight"><pre><span></span><code><span class="k">val</span> <span class="n">singular_values_opt</span> <span class="o">:</span> <span class="n">t</span> <span class="o">-&gt;</span> <span class="o">([&gt;`</span><span class="nc">ArrayLike</span><span class="o">]</span> <span class="nn">Np</span><span class="p">.</span><span class="nn">Obj</span><span class="p">.</span><span class="n">t</span><span class="o">)</span> <span class="n">option</span>
</code></pre></div>

<p>Print the object to a human-readable representation.</p>
<div class="highlight"><pre><span></span><code><span class="k">val</span> <span class="n">to_string</span> <span class="o">:</span> <span class="n">t</span> <span class="o">-&gt;</span> <span class="kt">string</span>
</code></pre></div>

<p>Print the object to a human-readable representation.</p>
<div class="highlight"><pre><span></span><code><span class="k">val</span> <span class="n">show</span> <span class="o">:</span> <span class="n">t</span> <span class="o">-&gt;</span> <span class="kt">string</span>
</code></pre></div>

<p>Pretty-print the object to a formatter.</p>
<div class="highlight"><pre><span></span><code><span class="k">val</span> <span class="n">pp</span> <span class="o">:</span> <span class="nn">Format</span><span class="p">.</span><span class="n">formatter</span> <span class="o">-&gt;</span> <span class="n">t</span> <span class="o">-&gt;</span> <span class="kt">unit</span> <span class="o">[@@</span><span class="n">ocaml</span><span class="o">.</span><span class="n">toplevel_printer</span><span class="o">]</span>



<span class="k">val</span> <span class="n">dict_learning</span> <span class="o">:</span> <span class="o">?</span><span class="n">max_iter</span><span class="o">:</span><span class="kt">int</span> <span class="o">-&gt;</span> <span class="o">?</span><span class="n">tol</span><span class="o">:</span><span class="kt">float</span> <span class="o">-&gt;</span> <span class="o">?</span><span class="n">method_</span><span class="o">:[`</span><span class="nc">Lars</span> <span class="o">|</span> <span class="o">`</span><span class="nc">Cd</span><span class="o">]</span> <span class="o">-&gt;</span> <span class="o">?</span><span class="n">n_jobs</span><span class="o">:</span><span class="kt">int</span> <span class="o">-&gt;</span> <span class="o">?</span><span class="n">dict_init</span><span class="o">:[&gt;`</span><span class="nc">ArrayLike</span><span class="o">]</span> <span class="nn">Np</span><span class="p">.</span><span class="nn">Obj</span><span class="p">.</span><span class="n">t</span> <span class="o">-&gt;</span> <span class="o">?</span><span class="n">code_init</span><span class="o">:[&gt;`</span><span class="nc">ArrayLike</span><span class="o">]</span> <span class="nn">Np</span><span class="p">.</span><span class="nn">Obj</span><span class="p">.</span><span class="n">t</span> <span class="o">-&gt;</span> <span class="o">?</span><span class="n">callback</span><span class="o">:</span><span class="nn">Py</span><span class="p">.</span><span class="nn">Object</span><span class="p">.</span><span class="n">t</span> <span class="o">-&gt;</span> <span class="o">?</span><span class="n">verbose</span><span class="o">:</span><span class="kt">int</span> <span class="o">-&gt;</span> <span class="o">?</span><span class="n">random_state</span><span class="o">:</span><span class="kt">int</span> <span class="o">-&gt;</span> <span class="o">?</span><span class="n">return_n_iter</span><span class="o">:</span><span class="kt">bool</span> <span class="o">-&gt;</span> <span class="o">?</span><span class="n">positive_dict</span><span class="o">:</span><span class="kt">bool</span> <span class="o">-&gt;</span> <span class="o">?</span><span class="n">positive_code</span><span class="o">:</span><span class="kt">bool</span> <span class="o">-&gt;</span> <span class="o">?</span><span class="n">method_max_iter</span><span class="o">:</span><span class="kt">int</span> <span class="o">-&gt;</span> <span class="n">x</span><span class="o">:[&gt;`</span><span class="nc">ArrayLike</span><span class="o">]</span> <span class="nn">Np</span><span class="p">.</span><span class="nn">Obj</span><span class="p">.</span><span class="n">t</span> <span class="o">-&gt;</span> <span class="n">n_components</span><span class="o">:</span><span class="kt">int</span> <span class="o">-&gt;</span> <span class="n">alpha</span><span class="o">:</span><span class="kt">int</span> <span class="o">-&gt;</span> <span class="kt">unit</span> <span class="o">-&gt;</span> <span class="o">([&gt;`</span><span class="nc">ArrayLike</span><span class="o">]</span> <span class="nn">Np</span><span class="p">.</span><span class="nn">Obj</span><span class="p">.</span><span class="n">t</span> <span class="o">*</span> <span class="o">[&gt;`</span><span class="nc">ArrayLike</span><span class="o">]</span> <span class="nn">Np</span><span class="p">.</span><span class="nn">Obj</span><span class="p">.</span><span class="n">t</span> <span class="o">*</span> <span class="o">[&gt;`</span><span class="nc">ArrayLike</span><span class="o">]</span> <span class="nn">Np</span><span class="p">.</span><span class="nn">Obj</span><span class="p">.</span><span class="n">t</span> <span class="o">*</span> <span class="kt">int</span><span class="o">)</span>
</code></pre></div>

<p>Solves a dictionary learning matrix factorization problem.</p>
<p>Finds the best dictionary and the corresponding sparse code for
approximating the data matrix X by solving::</p>
<p>(U^<em>, V^</em> ) = argmin 0.5 || X - U V ||_2^2 + alpha * || U ||_1
(U,V)
with || V_k ||_2 = 1 for all  0 &lt;= k &lt; n_components</p>
<p>where V is the dictionary and U is the sparse code.</p>
<p>Read more in the :ref:<code>User Guide &lt;DictionaryLearning&gt;</code>.</p>
<h2 id="parameters_93">Parameters<a class="headerlink" href="#parameters_93" title="Permanent link">&para;</a></h2>
<p>X : array of shape (n_samples, n_features)
Data matrix.</p>
<p>n_components : int,
Number of dictionary atoms to extract.</p>
<p>alpha : int,
Sparsity controlling parameter.</p>
<p>max_iter : int,
Maximum number of iterations to perform.</p>
<p>tol : float,
Tolerance for the stopping condition.</p>
<p>method : {'lars', 'cd'}
lars: uses the least angle regression method to solve the lasso problem
(linear_model.lars_path)
cd: uses the coordinate descent method to compute the
Lasso solution (linear_model.Lasso). Lars will be faster if
the estimated components are sparse.</p>
<p>n_jobs : int or None, optional (default=None)
Number of parallel jobs to run.
<code>None</code> means 1 unless in a :obj:<code>joblib.parallel_backend</code> context.
<code>-1</code> means using all processors. See :term:<code>Glossary &lt;n_jobs&gt;</code>
for more details.</p>
<p>dict_init : array of shape (n_components, n_features),
Initial value for the dictionary for warm restart scenarios.</p>
<p>code_init : array of shape (n_samples, n_components),
Initial value for the sparse code for warm restart scenarios.</p>
<p>callback : callable or None, optional (default: None)
Callable that gets invoked every five iterations</p>
<p>verbose : bool, optional (default: False)
To control the verbosity of the procedure.</p>
<p>random_state : int, RandomState instance or None, optional (default=None)
If int, random_state is the seed used by the random number generator;
If RandomState instance, random_state is the random number generator;
If None, the random number generator is the RandomState instance used
by <code>np.random</code>.</p>
<p>return_n_iter : bool
Whether or not to return the number of iterations.</p>
<p>positive_dict : bool
Whether to enforce positivity when finding the dictionary.</p>
<p>.. versionadded:: 0.20</p>
<p>positive_code : bool
Whether to enforce positivity when finding the code.</p>
<p>.. versionadded:: 0.20</p>
<p>method_max_iter : int, optional (default=1000)
Maximum number of iterations to perform.</p>
<p>.. versionadded:: 0.22</p>
<h2 id="returns_86">Returns<a class="headerlink" href="#returns_86" title="Permanent link">&para;</a></h2>
<p>code : array of shape (n_samples, n_components)
The sparse code factor in the matrix factorization.</p>
<p>dictionary : array of shape (n_components, n_features),
The dictionary factor in the matrix factorization.</p>
<p>errors : array
Vector of errors at each iteration.</p>
<p>n_iter : int
Number of iterations run. Returned only if <code>return_n_iter</code> is
set to True.</p>
<h2 id="see-also_9">See also<a class="headerlink" href="#see-also_9" title="Permanent link">&para;</a></h2>
<p>dict_learning_online
DictionaryLearning
MiniBatchDictionaryLearning
SparsePCA
MiniBatchSparsePCA</p>
<div class="highlight"><pre><span></span><code><span class="k">val</span> <span class="n">dict_learning_online</span> <span class="o">:</span> <span class="o">?</span><span class="n">n_components</span><span class="o">:</span><span class="kt">int</span> <span class="o">-&gt;</span> <span class="o">?</span><span class="n">alpha</span><span class="o">:</span><span class="kt">float</span> <span class="o">-&gt;</span> <span class="o">?</span><span class="n">n_iter</span><span class="o">:</span><span class="kt">int</span> <span class="o">-&gt;</span> <span class="o">?</span><span class="n">return_code</span><span class="o">:</span><span class="kt">bool</span> <span class="o">-&gt;</span> <span class="o">?</span><span class="n">dict_init</span><span class="o">:[&gt;`</span><span class="nc">ArrayLike</span><span class="o">]</span> <span class="nn">Np</span><span class="p">.</span><span class="nn">Obj</span><span class="p">.</span><span class="n">t</span> <span class="o">-&gt;</span> <span class="o">?</span><span class="n">callback</span><span class="o">:</span><span class="nn">Py</span><span class="p">.</span><span class="nn">Object</span><span class="p">.</span><span class="n">t</span> <span class="o">-&gt;</span> <span class="o">?</span><span class="n">batch_size</span><span class="o">:</span><span class="kt">int</span> <span class="o">-&gt;</span> <span class="o">?</span><span class="n">verbose</span><span class="o">:</span><span class="kt">int</span> <span class="o">-&gt;</span> <span class="o">?</span><span class="n">shuffle</span><span class="o">:</span><span class="kt">bool</span> <span class="o">-&gt;</span> <span class="o">?</span><span class="n">n_jobs</span><span class="o">:</span><span class="kt">int</span> <span class="o">-&gt;</span> <span class="o">?</span><span class="n">method_</span><span class="o">:[`</span><span class="nc">Lars</span> <span class="o">|</span> <span class="o">`</span><span class="nc">Cd</span><span class="o">]</span> <span class="o">-&gt;</span> <span class="o">?</span><span class="n">iter_offset</span><span class="o">:</span><span class="kt">int</span> <span class="o">-&gt;</span> <span class="o">?</span><span class="n">random_state</span><span class="o">:</span><span class="kt">int</span> <span class="o">-&gt;</span> <span class="o">?</span><span class="n">return_inner_stats</span><span class="o">:</span><span class="kt">bool</span> <span class="o">-&gt;</span> <span class="o">?</span><span class="n">inner_stats</span><span class="o">:([&gt;`</span><span class="nc">ArrayLike</span><span class="o">]</span> <span class="nn">Np</span><span class="p">.</span><span class="nn">Obj</span><span class="p">.</span><span class="n">t</span> <span class="o">*</span> <span class="o">[&gt;`</span><span class="nc">ArrayLike</span><span class="o">]</span> <span class="nn">Np</span><span class="p">.</span><span class="nn">Obj</span><span class="p">.</span><span class="n">t</span><span class="o">)</span> <span class="o">-&gt;</span> <span class="o">?</span><span class="n">return_n_iter</span><span class="o">:</span><span class="kt">bool</span> <span class="o">-&gt;</span> <span class="o">?</span><span class="n">positive_dict</span><span class="o">:</span><span class="kt">bool</span> <span class="o">-&gt;</span> <span class="o">?</span><span class="n">positive_code</span><span class="o">:</span><span class="kt">bool</span> <span class="o">-&gt;</span> <span class="o">?</span><span class="n">method_max_iter</span><span class="o">:</span><span class="kt">int</span> <span class="o">-&gt;</span> <span class="n">x</span><span class="o">:[&gt;`</span><span class="nc">ArrayLike</span><span class="o">]</span> <span class="nn">Np</span><span class="p">.</span><span class="nn">Obj</span><span class="p">.</span><span class="n">t</span> <span class="o">-&gt;</span> <span class="kt">unit</span> <span class="o">-&gt;</span> <span class="o">([&gt;`</span><span class="nc">ArrayLike</span><span class="o">]</span> <span class="nn">Np</span><span class="p">.</span><span class="nn">Obj</span><span class="p">.</span><span class="n">t</span> <span class="o">*</span> <span class="o">[&gt;`</span><span class="nc">ArrayLike</span><span class="o">]</span> <span class="nn">Np</span><span class="p">.</span><span class="nn">Obj</span><span class="p">.</span><span class="n">t</span> <span class="o">*</span> <span class="kt">int</span><span class="o">)</span>
</code></pre></div>

<p>Solves a dictionary learning matrix factorization problem online.</p>
<p>Finds the best dictionary and the corresponding sparse code for
approximating the data matrix X by solving::</p>
<p>(U^<em>, V^</em> ) = argmin 0.5 || X - U V ||_2^2 + alpha * || U ||_1
(U,V)
with || V_k ||_2 = 1 for all  0 &lt;= k &lt; n_components</p>
<p>where V is the dictionary and U is the sparse code. This is
accomplished by repeatedly iterating over mini-batches by slicing
the input data.</p>
<p>Read more in the :ref:<code>User Guide &lt;DictionaryLearning&gt;</code>.</p>
<h2 id="parameters_94">Parameters<a class="headerlink" href="#parameters_94" title="Permanent link">&para;</a></h2>
<p>X : array of shape (n_samples, n_features)
Data matrix.</p>
<p>n_components : int,
Number of dictionary atoms to extract.</p>
<p>alpha : float,
Sparsity controlling parameter.</p>
<p>n_iter : int,
Number of mini-batch iterations to perform.</p>
<p>return_code : boolean,
Whether to also return the code U or just the dictionary V.</p>
<p>dict_init : array of shape (n_components, n_features),
Initial value for the dictionary for warm restart scenarios.</p>
<p>callback : callable or None, optional (default: None)
callable that gets invoked every five iterations</p>
<p>batch_size : int,
The number of samples to take in each batch.</p>
<p>verbose : bool, optional (default: False)
To control the verbosity of the procedure.</p>
<p>shuffle : boolean,
Whether to shuffle the data before splitting it in batches.</p>
<p>n_jobs : int or None, optional (default=None)
Number of parallel jobs to run.
<code>None</code> means 1 unless in a :obj:<code>joblib.parallel_backend</code> context.
<code>-1</code> means using all processors. See :term:<code>Glossary &lt;n_jobs&gt;</code>
for more details.</p>
<p>method : {'lars', 'cd'}
lars: uses the least angle regression method to solve the lasso problem
(linear_model.lars_path)
cd: uses the coordinate descent method to compute the
Lasso solution (linear_model.Lasso). Lars will be faster if
the estimated components are sparse.</p>
<p>iter_offset : int, default 0
Number of previous iterations completed on the dictionary used for
initialization.</p>
<p>random_state : int, RandomState instance or None, optional (default=None)
If int, random_state is the seed used by the random number generator;
If RandomState instance, random_state is the random number generator;
If None, the random number generator is the RandomState instance used
by <code>np.random</code>.</p>
<p>return_inner_stats : boolean, optional
Return the inner statistics A (dictionary covariance) and B
(data approximation). Useful to restart the algorithm in an
online setting. If return_inner_stats is True, return_code is
ignored</p>
<p>inner_stats : tuple of (A, B) ndarrays
Inner sufficient statistics that are kept by the algorithm.
Passing them at initialization is useful in online settings, to
avoid losing the history of the evolution.
A (n_components, n_components) is the dictionary covariance matrix.
B (n_features, n_components) is the data approximation matrix</p>
<p>return_n_iter : bool
Whether or not to return the number of iterations.</p>
<p>positive_dict : bool
Whether to enforce positivity when finding the dictionary.</p>
<p>.. versionadded:: 0.20</p>
<p>positive_code : bool
Whether to enforce positivity when finding the code.</p>
<p>.. versionadded:: 0.20</p>
<p>method_max_iter : int, optional (default=1000)
Maximum number of iterations to perform when solving the lasso problem.</p>
<p>.. versionadded:: 0.22</p>
<h2 id="returns_87">Returns<a class="headerlink" href="#returns_87" title="Permanent link">&para;</a></h2>
<p>code : array of shape (n_samples, n_components),
the sparse code (only returned if <code>return_code=True</code>)</p>
<p>dictionary : array of shape (n_components, n_features),
the solutions to the dictionary learning problem</p>
<p>n_iter : int
Number of iterations run. Returned only if <code>return_n_iter</code> is
set to <code>True</code>.</p>
<h2 id="see-also_10">See also<a class="headerlink" href="#see-also_10" title="Permanent link">&para;</a></h2>
<p>dict_learning
DictionaryLearning
MiniBatchDictionaryLearning
SparsePCA
MiniBatchSparsePCA</p>
<div class="highlight"><pre><span></span><code><span class="k">val</span> <span class="n">fastica</span> <span class="o">:</span> <span class="o">?</span><span class="n">n_components</span><span class="o">:</span><span class="kt">int</span> <span class="o">-&gt;</span> <span class="o">?</span><span class="n">algorithm</span><span class="o">:[`</span><span class="nc">Parallel</span> <span class="o">|</span> <span class="o">`</span><span class="nc">Deflation</span><span class="o">]</span> <span class="o">-&gt;</span> <span class="o">?</span><span class="n">whiten</span><span class="o">:</span><span class="kt">bool</span> <span class="o">-&gt;</span> <span class="o">?</span><span class="n">fun_</span><span class="o">:[`</span><span class="nc">Callable</span> <span class="k">of</span> <span class="nn">Py</span><span class="p">.</span><span class="nn">Object</span><span class="p">.</span><span class="n">t</span> <span class="o">|</span> <span class="o">`</span><span class="nc">S</span> <span class="k">of</span> <span class="kt">string</span><span class="o">]</span> <span class="o">-&gt;</span> <span class="o">?</span><span class="n">fun_args</span><span class="o">:</span><span class="nn">Dict</span><span class="p">.</span><span class="n">t</span> <span class="o">-&gt;</span> <span class="o">?</span><span class="n">max_iter</span><span class="o">:</span><span class="kt">int</span> <span class="o">-&gt;</span> <span class="o">?</span><span class="n">tol</span><span class="o">:</span><span class="kt">float</span> <span class="o">-&gt;</span> <span class="o">?</span><span class="n">w_init</span><span class="o">:[&gt;`</span><span class="nc">ArrayLike</span><span class="o">]</span> <span class="nn">Np</span><span class="p">.</span><span class="nn">Obj</span><span class="p">.</span><span class="n">t</span> <span class="o">-&gt;</span> <span class="o">?</span><span class="n">random_state</span><span class="o">:</span><span class="kt">int</span> <span class="o">-&gt;</span> <span class="o">?</span><span class="n">return_X_mean</span><span class="o">:</span><span class="kt">bool</span> <span class="o">-&gt;</span> <span class="o">?</span><span class="n">compute_sources</span><span class="o">:</span><span class="kt">bool</span> <span class="o">-&gt;</span> <span class="o">?</span><span class="n">return_n_iter</span><span class="o">:</span><span class="kt">bool</span> <span class="o">-&gt;</span> <span class="n">x</span><span class="o">:[&gt;`</span><span class="nc">ArrayLike</span><span class="o">]</span> <span class="nn">Np</span><span class="p">.</span><span class="nn">Obj</span><span class="p">.</span><span class="n">t</span> <span class="o">-&gt;</span> <span class="kt">unit</span> <span class="o">-&gt;</span> <span class="o">([&gt;`</span><span class="nc">ArrayLike</span><span class="o">]</span> <span class="nn">Np</span><span class="p">.</span><span class="nn">Obj</span><span class="p">.</span><span class="n">t</span> <span class="n">option</span> <span class="o">*</span> <span class="o">[&gt;`</span><span class="nc">ArrayLike</span><span class="o">]</span> <span class="nn">Np</span><span class="p">.</span><span class="nn">Obj</span><span class="p">.</span><span class="n">t</span> <span class="o">*</span> <span class="o">[&gt;`</span><span class="nc">ArrayLike</span><span class="o">]</span> <span class="nn">Np</span><span class="p">.</span><span class="nn">Obj</span><span class="p">.</span><span class="n">t</span> <span class="n">option</span> <span class="o">*</span> <span class="o">[&gt;`</span><span class="nc">ArrayLike</span><span class="o">]</span> <span class="nn">Np</span><span class="p">.</span><span class="nn">Obj</span><span class="p">.</span><span class="n">t</span> <span class="o">*</span> <span class="kt">int</span><span class="o">)</span>
</code></pre></div>

<p>Perform Fast Independent Component Analysis.</p>
<p>Read more in the :ref:<code>User Guide &lt;ICA&gt;</code>.</p>
<h2 id="parameters_95">Parameters<a class="headerlink" href="#parameters_95" title="Permanent link">&para;</a></h2>
<p>X : array-like, shape (n_samples, n_features)
Training vector, where n_samples is the number of samples and
n_features is the number of features.</p>
<p>n_components : int, optional
Number of components to extract. If None no dimension reduction
is performed.</p>
<p>algorithm : {'parallel', 'deflation'}, optional
Apply a parallel or deflational FASTICA algorithm.</p>
<p>whiten : boolean, optional
If True perform an initial whitening of the data.
If False, the data is assumed to have already been
preprocessed: it should be centered, normed and white.
Otherwise you will get incorrect results.
In this case the parameter n_components will be ignored.</p>
<p>fun : string or function, optional. Default: 'logcosh'
The functional form of the G function used in the
approximation to neg-entropy. Could be either 'logcosh', 'exp',
or 'cube'.
You can also provide your own function. It should return a tuple
containing the value of the function, and of its derivative, in the
point. The derivative should be averaged along its last dimension.
Example:</p>
<p>def my_g(x):
return x <strong> 3, np.mean(3 * x </strong> 2, axis=-1)</p>
<p>fun_args : dictionary, optional
Arguments to send to the functional form.
If empty or None and if fun='logcosh', fun_args will take value
{'alpha' : 1.0}</p>
<p>max_iter : int, optional
Maximum number of iterations to perform.</p>
<p>tol : float, optional
A positive scalar giving the tolerance at which the
un-mixing matrix is considered to have converged.</p>
<p>w_init : (n_components, n_components) array, optional
Initial un-mixing array of dimension (n.comp,n.comp).
If None (default) then an array of normal r.v.'s is used.</p>
<p>random_state : int, RandomState instance or None, optional (default=None)
If int, random_state is the seed used by the random number generator;
If RandomState instance, random_state is the random number generator;
If None, the random number generator is the RandomState instance used
by <code>np.random</code>.</p>
<p>return_X_mean : bool, optional
If True, X_mean is returned too.</p>
<p>compute_sources : bool, optional
If False, sources are not computed, but only the rotation matrix.
This can save memory when working with big data. Defaults to True.</p>
<p>return_n_iter : bool, optional
Whether or not to return the number of iterations.</p>
<h2 id="returns_88">Returns<a class="headerlink" href="#returns_88" title="Permanent link">&para;</a></h2>
<p>K : array, shape (n_components, n_features) | None.
If whiten is 'True', K is the pre-whitening matrix that projects data
onto the first n_components principal components. If whiten is 'False',
K is 'None'.</p>
<p>W : array, shape (n_components, n_components)
The square matrix that unmixes the data after whitening.
The mixing matrix is the pseudo-inverse of matrix <code>W K</code>
if K is not None, else it is the inverse of W.</p>
<p>S : array, shape (n_samples, n_components) | None
Estimated source matrix</p>
<p>X_mean : array, shape (n_features, )
The mean over features. Returned only if return_X_mean is True.</p>
<p>n_iter : int
If the algorithm is 'deflation', n_iter is the
maximum number of iterations run across all components. Else
they are just the number of iterations taken to converge. This is
returned only when return_n_iter is set to <code>True</code>.</p>
<h2 id="notes_8">Notes<a class="headerlink" href="#notes_8" title="Permanent link">&para;</a></h2>
<p>The data matrix X is considered to be a linear combination of
non-Gaussian (independent) components i.e. X = AS where columns of S
contain the independent components and A is a linear mixing
matrix. In short ICA attempts to `un-mix' the data by estimating an
un-mixing matrix W where <code>S = W K X.</code>
While FastICA was proposed to estimate as many sources
as features, it is possible to estimate less by setting
n_components &lt; n_features. It this case K is not a square matrix
and the estimated A is the pseudo-inverse of <code>W K</code>.</p>
<p>This implementation was originally made for data of shape
[n_features, n_samples]. Now the input is transposed
before the algorithm is applied. This makes it slightly
faster for Fortran-ordered input.</p>
<p>Implemented using FastICA:
<em>A. Hyvarinen and E. Oja, Independent Component Analysis:
Algorithms and Applications, Neural Networks, 13(4-5), 2000,
pp. 411-430</em></p>
<div class="highlight"><pre><span></span><code><span class="k">val</span> <span class="n">non_negative_factorization</span> <span class="o">:</span> <span class="o">?</span><span class="n">w</span><span class="o">:[&gt;`</span><span class="nc">ArrayLike</span><span class="o">]</span> <span class="nn">Np</span><span class="p">.</span><span class="nn">Obj</span><span class="p">.</span><span class="n">t</span> <span class="o">-&gt;</span> <span class="o">?</span><span class="n">h</span><span class="o">:[&gt;`</span><span class="nc">ArrayLike</span><span class="o">]</span> <span class="nn">Np</span><span class="p">.</span><span class="nn">Obj</span><span class="p">.</span><span class="n">t</span> <span class="o">-&gt;</span> <span class="o">?</span><span class="n">n_components</span><span class="o">:</span><span class="kt">int</span> <span class="o">-&gt;</span> <span class="o">?</span><span class="n">init</span><span class="o">:[`</span><span class="nc">Custom</span> <span class="o">|</span> <span class="o">`</span><span class="nc">Random</span> <span class="o">|</span> <span class="o">`</span><span class="nc">Nndsvda</span> <span class="o">|</span> <span class="o">`</span><span class="nc">Nndsvd</span> <span class="o">|</span> <span class="o">`</span><span class="nc">Nndsvdar</span> <span class="o">|</span> <span class="o">`</span><span class="nc">None</span><span class="o">]</span> <span class="o">-&gt;</span> <span class="o">?</span><span class="n">update_H</span><span class="o">:</span><span class="kt">bool</span> <span class="o">-&gt;</span> <span class="o">?</span><span class="n">solver</span><span class="o">:[`</span><span class="nc">Cd</span> <span class="o">|</span> <span class="o">`</span><span class="nc">Mu</span><span class="o">]</span> <span class="o">-&gt;</span> <span class="o">?</span><span class="n">beta_loss</span><span class="o">:[`</span><span class="nc">F</span> <span class="k">of</span> <span class="kt">float</span> <span class="o">|</span> <span class="o">`</span><span class="nc">S</span> <span class="k">of</span> <span class="kt">string</span><span class="o">]</span> <span class="o">-&gt;</span> <span class="o">?</span><span class="n">tol</span><span class="o">:</span><span class="kt">float</span> <span class="o">-&gt;</span> <span class="o">?</span><span class="n">max_iter</span><span class="o">:</span><span class="kt">int</span> <span class="o">-&gt;</span> <span class="o">?</span><span class="n">alpha</span><span class="o">:</span><span class="kt">float</span> <span class="o">-&gt;</span> <span class="o">?</span><span class="n">l1_ratio</span><span class="o">:</span><span class="kt">float</span> <span class="o">-&gt;</span> <span class="o">?</span><span class="n">regularization</span><span class="o">:[`</span><span class="nc">Transformation</span> <span class="o">|</span> <span class="o">`</span><span class="nc">Both</span> <span class="o">|</span> <span class="o">`</span><span class="nc">Components</span><span class="o">]</span> <span class="o">-&gt;</span> <span class="o">?</span><span class="n">random_state</span><span class="o">:</span><span class="kt">int</span> <span class="o">-&gt;</span> <span class="o">?</span><span class="n">verbose</span><span class="o">:</span><span class="kt">int</span> <span class="o">-&gt;</span> <span class="o">?</span><span class="n">shuffle</span><span class="o">:</span><span class="kt">bool</span> <span class="o">-&gt;</span> <span class="n">x</span><span class="o">:[&gt;`</span><span class="nc">ArrayLike</span><span class="o">]</span> <span class="nn">Np</span><span class="p">.</span><span class="nn">Obj</span><span class="p">.</span><span class="n">t</span> <span class="o">-&gt;</span> <span class="kt">unit</span> <span class="o">-&gt;</span> <span class="o">([&gt;`</span><span class="nc">ArrayLike</span><span class="o">]</span> <span class="nn">Np</span><span class="p">.</span><span class="nn">Obj</span><span class="p">.</span><span class="n">t</span> <span class="o">*</span> <span class="o">[&gt;`</span><span class="nc">ArrayLike</span><span class="o">]</span> <span class="nn">Np</span><span class="p">.</span><span class="nn">Obj</span><span class="p">.</span><span class="n">t</span> <span class="o">*</span> <span class="kt">int</span><span class="o">)</span>
</code></pre></div>

<p>Compute Non-negative Matrix Factorization (NMF)</p>
<p>Find two non-negative matrices (W, H) whose product approximates the non-
negative matrix X. This factorization can be used for example for
dimensionality reduction, source separation or topic extraction.</p>
<p>The objective function is::</p>
<p>0.5 * ||X - WH||_Fro^2
+ alpha * l1_ratio * ||vec(W)||_1
+ alpha * l1_ratio * ||vec(H)||_1
+ 0.5 * alpha * (1 - l1_ratio) * ||W||_Fro^2
+ 0.5 * alpha * (1 - l1_ratio) * ||H||_Fro^2</p>
<p>Where::</p>
<p>||A||<em>Fro^2 = \sum</em>{i,j} A_{ij}^2 (Frobenius norm)
||vec(A)||<em>1 = \sum</em>{i,j} abs(A_{ij}) (Elementwise L1 norm)</p>
<p>For multiplicative-update ('mu') solver, the Frobenius norm
(0.5 * ||X - WH||_Fro^2) can be changed into another beta-divergence loss,
by changing the beta_loss parameter.</p>
<p>The objective function is minimized with an alternating minimization of W
and H. If H is given and update_H=False, it solves for W only.</p>
<h2 id="parameters_96">Parameters<a class="headerlink" href="#parameters_96" title="Permanent link">&para;</a></h2>
<p>X : array-like, shape (n_samples, n_features)
Constant matrix.</p>
<p>W : array-like, shape (n_samples, n_components)
If init='custom', it is used as initial guess for the solution.</p>
<p>H : array-like, shape (n_components, n_features)
If init='custom', it is used as initial guess for the solution.
If update_H=False, it is used as a constant, to solve for W only.</p>
<p>n_components : integer
Number of components, if n_components is not set all features
are kept.</p>
<p>init : None | 'random' | 'nndsvd' | 'nndsvda' | 'nndsvdar' | 'custom'
Method used to initialize the procedure.
Default: 'random'.</p>
<p>The default value will change from 'random' to None in version 0.23
to make it consistent with decomposition.NMF.</p>
<p>Valid options:</p>
<ul>
<li>
<p>None: 'nndsvd' if n_components &lt; n_features, otherwise 'random'.</p>
</li>
<li>
<p>'random': non-negative random matrices, scaled with:
sqrt(X.mean() / n_components)</p>
</li>
<li>
<p>'nndsvd': Nonnegative Double Singular Value Decomposition (NNDSVD)
initialization (better for sparseness)</p>
</li>
<li>
<p>'nndsvda': NNDSVD with zeros filled with the average of X
(better when sparsity is not desired)</p>
</li>
<li>
<p>'nndsvdar': NNDSVD with zeros filled with small random values
(generally faster, less accurate alternative to NNDSVDa
for when sparsity is not desired)</p>
</li>
<li>
<p>'custom': use custom matrices W and H</p>
</li>
</ul>
<p>update_H : boolean, default: True
Set to True, both W and H will be estimated from initial guesses.
Set to False, only W will be estimated.</p>
<p>solver : 'cd' | 'mu'
Numerical solver to use:</p>
<ul>
<li>
<p>'cd' is a Coordinate Descent solver that uses Fast Hierarchical
Alternating Least Squares (Fast HALS).</p>
</li>
<li>
<p>'mu' is a Multiplicative Update solver.</p>
</li>
</ul>
<p>.. versionadded:: 0.17
Coordinate Descent solver.</p>
<p>.. versionadded:: 0.19
Multiplicative Update solver.</p>
<p>beta_loss : float or string, default 'frobenius'
String must be in {'frobenius', 'kullback-leibler', 'itakura-saito'}.
Beta divergence to be minimized, measuring the distance between X
and the dot product WH. Note that values different from 'frobenius'
(or 2) and 'kullback-leibler' (or 1) lead to significantly slower
fits. Note that for beta_loss &lt;= 0 (or 'itakura-saito'), the input
matrix X cannot contain zeros. Used only in 'mu' solver.</p>
<p>.. versionadded:: 0.19</p>
<p>tol : float, default: 1e-4
Tolerance of the stopping condition.</p>
<p>max_iter : integer, default: 200
Maximum number of iterations before timing out.</p>
<p>alpha : double, default: 0.
Constant that multiplies the regularization terms.</p>
<p>l1_ratio : double, default: 0.
The regularization mixing parameter, with 0 &lt;= l1_ratio &lt;= 1.
For l1_ratio = 0 the penalty is an elementwise L2 penalty
(aka Frobenius Norm).
For l1_ratio = 1 it is an elementwise L1 penalty.
For 0 &lt; l1_ratio &lt; 1, the penalty is a combination of L1 and L2.</p>
<p>regularization : 'both' | 'components' | 'transformation' | None
Select whether the regularization affects the components (H), the
transformation (W), both or none of them.</p>
<p>random_state : int, RandomState instance or None, optional, default: None
If int, random_state is the seed used by the random number generator;
If RandomState instance, random_state is the random number generator;
If None, the random number generator is the RandomState instance used
by <code>np.random</code>.</p>
<p>verbose : integer, default: 0
The verbosity level.</p>
<p>shuffle : boolean, default: False
If true, randomize the order of coordinates in the CD solver.</p>
<h2 id="returns_89">Returns<a class="headerlink" href="#returns_89" title="Permanent link">&para;</a></h2>
<p>W : array-like, shape (n_samples, n_components)
Solution to the non-negative least squares problem.</p>
<p>H : array-like, shape (n_components, n_features)
Solution to the non-negative least squares problem.</p>
<p>n_iter : int
Actual number of iterations.</p>
<h2 id="examples_12">Examples<a class="headerlink" href="#examples_12" title="Permanent link">&para;</a></h2>
<blockquote>
<blockquote>
<blockquote>
<p>import numpy as np
X = np.array([[1,1], [2, 1], [3, 1.2], [4, 1], [5, 0.8], [6, 1]])
from sklearn.decomposition import non_negative_factorization
W, H, n_iter = non_negative_factorization(X, n_components=2,
... init='random', random_state=0)</p>
</blockquote>
</blockquote>
</blockquote>
<h2 id="references_8">References<a class="headerlink" href="#references_8" title="Permanent link">&para;</a></h2>
<p>Cichocki, Andrzej, and P. H. A. N. Anh-Huy. 'Fast local algorithms for
large scale nonnegative matrix and tensor factorizations.'
IEICE transactions on fundamentals of electronics, communications and
computer sciences 92.3: 708-721, 2009.</p>
<p>Fevotte, C., &amp; Idier, J. (2011). Algorithms for nonnegative matrix
factorization with the beta-divergence. Neural Computation, 23(9).</p>
<div class="highlight"><pre><span></span><code><span class="k">val</span> <span class="n">randomized_svd</span> <span class="o">:</span> <span class="o">?</span><span class="n">n_oversamples</span><span class="o">:</span><span class="nn">Py</span><span class="p">.</span><span class="nn">Object</span><span class="p">.</span><span class="n">t</span> <span class="o">-&gt;</span> <span class="o">?</span><span class="n">n_iter</span><span class="o">:</span><span class="nn">Py</span><span class="p">.</span><span class="nn">Object</span><span class="p">.</span><span class="n">t</span> <span class="o">-&gt;</span> <span class="o">?</span><span class="n">power_iteration_normalizer</span><span class="o">:[`</span><span class="nc">Auto</span> <span class="o">|</span> <span class="o">`</span><span class="nc">QR</span> <span class="o">|</span> <span class="o">`</span><span class="nc">LU</span> <span class="o">|</span> <span class="o">`</span><span class="nc">None</span><span class="o">]</span> <span class="o">-&gt;</span> <span class="o">?</span><span class="n">transpose</span><span class="o">:[`</span><span class="nc">Auto</span> <span class="o">|</span> <span class="o">`</span><span class="nc">Bool</span> <span class="k">of</span> <span class="kt">bool</span><span class="o">]</span> <span class="o">-&gt;</span> <span class="o">?</span><span class="n">flip_sign</span><span class="o">:</span><span class="kt">bool</span> <span class="o">-&gt;</span> <span class="o">?</span><span class="n">random_state</span><span class="o">:</span><span class="kt">int</span> <span class="o">-&gt;</span> <span class="n">m</span><span class="o">:[&gt;`</span><span class="nc">ArrayLike</span><span class="o">]</span> <span class="nn">Np</span><span class="p">.</span><span class="nn">Obj</span><span class="p">.</span><span class="n">t</span> <span class="o">-&gt;</span> <span class="n">n_components</span><span class="o">:</span><span class="kt">int</span> <span class="o">-&gt;</span> <span class="kt">unit</span> <span class="o">-&gt;</span> <span class="nn">Py</span><span class="p">.</span><span class="nn">Object</span><span class="p">.</span><span class="n">t</span>
</code></pre></div>

<p>Computes a truncated randomized SVD</p>
<h2 id="parameters_97">Parameters<a class="headerlink" href="#parameters_97" title="Permanent link">&para;</a></h2>
<p>M : ndarray or sparse matrix
Matrix to decompose</p>
<p>n_components : int
Number of singular values and vectors to extract.</p>
<p>n_oversamples : int (default is 10)
Additional number of random vectors to sample the range of M so as
to ensure proper conditioning. The total number of random vectors
used to find the range of M is n_components + n_oversamples. Smaller
number can improve speed but can negatively impact the quality of
approximation of singular vectors and singular values.</p>
<p>n_iter : int or 'auto' (default is 'auto')
Number of power iterations. It can be used to deal with very noisy
problems. When 'auto', it is set to 4, unless <code>n_components</code> is small
(&lt; .1 * min(X.shape)) <code>n_iter</code> in which case is set to 7.
This improves precision with few components.</p>
<p>.. versionchanged:: 0.18</p>
<p>power_iteration_normalizer : 'auto' (default), 'QR', 'LU', 'none'
Whether the power iterations are normalized with step-by-step
QR factorization (the slowest but most accurate), 'none'
(the fastest but numerically unstable when <code>n_iter</code> is large, e.g.
typically 5 or larger), or 'LU' factorization (numerically stable
but can lose slightly in accuracy). The 'auto' mode applies no
normalization if <code>n_iter</code> &lt;= 2 and switches to LU otherwise.</p>
<p>.. versionadded:: 0.18</p>
<p>transpose : True, False or 'auto' (default)
Whether the algorithm should be applied to M.T instead of M. The
result should approximately be the same. The 'auto' mode will
trigger the transposition if M.shape[1] &gt; M.shape[0] since this
implementation of randomized SVD tend to be a little faster in that
case.</p>
<p>.. versionchanged:: 0.18</p>
<p>flip_sign : boolean, (True by default)
The output of a singular value decomposition is only unique up to a
permutation of the signs of the singular vectors. If <code>flip_sign</code> is
set to <code>True</code>, the sign ambiguity is resolved by making the largest
loadings for each component in the left singular vectors positive.</p>
<p>random_state : int, RandomState instance or None, optional (default=None)
The seed of the pseudo random number generator to use when shuffling
the data.  If int, random_state is the seed used by the random number
generator; If RandomState instance, random_state is the random number
generator; If None, the random number generator is the RandomState
instance used by <code>np.random</code>.</p>
<h2 id="notes_9">Notes<a class="headerlink" href="#notes_9" title="Permanent link">&para;</a></h2>
<p>This algorithm finds a (usually very good) approximate truncated
singular value decomposition using randomization to speed up the
computations. It is particularly fast on large matrices on which
you wish to extract only a small number of components. In order to
obtain further speed up, <code>n_iter</code> can be set &lt;=2 (at the cost of
loss of precision).</p>
<h2 id="references_9">References<a class="headerlink" href="#references_9" title="Permanent link">&para;</a></h2>
<ul>
<li>
<p>Finding structure with randomness: Stochastic algorithms for constructing
approximate matrix decompositions
Halko, et al., 2009 https://arxiv.org/abs/0909.4061</p>
</li>
<li>
<p>A randomized algorithm for the decomposition of matrices
Per-Gunnar Martinsson, Vladimir Rokhlin and Mark Tygert</p>
</li>
<li>
<p>An implementation of a randomized algorithm for principal component
analysis
A. Szlam et al. 2014</p>
</li>
</ul>
<div class="highlight"><pre><span></span><code><span class="k">val</span> <span class="n">sparse_encode</span> <span class="o">:</span> <span class="o">?</span><span class="n">gram</span><span class="o">:[&gt;`</span><span class="nc">ArrayLike</span><span class="o">]</span> <span class="nn">Np</span><span class="p">.</span><span class="nn">Obj</span><span class="p">.</span><span class="n">t</span> <span class="o">-&gt;</span> <span class="o">?</span><span class="n">cov</span><span class="o">:[&gt;`</span><span class="nc">ArrayLike</span><span class="o">]</span> <span class="nn">Np</span><span class="p">.</span><span class="nn">Obj</span><span class="p">.</span><span class="n">t</span> <span class="o">-&gt;</span> <span class="o">?</span><span class="n">algorithm</span><span class="o">:[`</span><span class="nc">Lasso_lars</span> <span class="o">|</span> <span class="o">`</span><span class="nc">Lasso_cd</span> <span class="o">|</span> <span class="o">`</span><span class="nc">Lars</span> <span class="o">|</span> <span class="o">`</span><span class="nc">Omp</span> <span class="o">|</span> <span class="o">`</span><span class="nc">Threshold</span><span class="o">]</span> <span class="o">-&gt;</span> <span class="o">?</span><span class="n">n_nonzero_coefs</span><span class="o">:[`</span><span class="nc">T0_1_</span> <span class="k">of</span> <span class="nn">Py</span><span class="p">.</span><span class="nn">Object</span><span class="p">.</span><span class="n">t</span> <span class="o">|</span> <span class="o">`</span><span class="nc">I</span> <span class="k">of</span> <span class="kt">int</span><span class="o">]</span> <span class="o">-&gt;</span> <span class="o">?</span><span class="n">alpha</span><span class="o">:</span><span class="kt">float</span> <span class="o">-&gt;</span> <span class="o">?</span><span class="n">copy_cov</span><span class="o">:</span><span class="kt">bool</span> <span class="o">-&gt;</span> <span class="o">?</span><span class="n">init</span><span class="o">:[&gt;`</span><span class="nc">ArrayLike</span><span class="o">]</span> <span class="nn">Np</span><span class="p">.</span><span class="nn">Obj</span><span class="p">.</span><span class="n">t</span> <span class="o">-&gt;</span> <span class="o">?</span><span class="n">max_iter</span><span class="o">:</span><span class="kt">int</span> <span class="o">-&gt;</span> <span class="o">?</span><span class="n">n_jobs</span><span class="o">:</span><span class="kt">int</span> <span class="o">-&gt;</span> <span class="o">?</span><span class="n">check_input</span><span class="o">:</span><span class="kt">bool</span> <span class="o">-&gt;</span> <span class="o">?</span><span class="n">verbose</span><span class="o">:</span><span class="kt">int</span> <span class="o">-&gt;</span> <span class="o">?</span><span class="n">positive</span><span class="o">:</span><span class="kt">bool</span> <span class="o">-&gt;</span> <span class="n">x</span><span class="o">:[&gt;`</span><span class="nc">ArrayLike</span><span class="o">]</span> <span class="nn">Np</span><span class="p">.</span><span class="nn">Obj</span><span class="p">.</span><span class="n">t</span> <span class="o">-&gt;</span> <span class="n">dictionary</span><span class="o">:[&gt;`</span><span class="nc">ArrayLike</span><span class="o">]</span> <span class="nn">Np</span><span class="p">.</span><span class="nn">Obj</span><span class="p">.</span><span class="n">t</span> <span class="o">-&gt;</span> <span class="kt">unit</span> <span class="o">-&gt;</span> <span class="o">[&gt;`</span><span class="nc">ArrayLike</span><span class="o">]</span> <span class="nn">Np</span><span class="p">.</span><span class="nn">Obj</span><span class="p">.</span><span class="n">t</span>
</code></pre></div>

<p>Sparse coding</p>
<p>Each row of the result is the solution to a sparse coding problem.
The goal is to find a sparse array <code>code</code> such that::</p>
<p>X ~= code * dictionary</p>
<p>Read more in the :ref:<code>User Guide &lt;SparseCoder&gt;</code>.</p>
<h2 id="parameters_98">Parameters<a class="headerlink" href="#parameters_98" title="Permanent link">&para;</a></h2>
<p>X : array of shape (n_samples, n_features)
Data matrix</p>
<p>dictionary : array of shape (n_components, n_features)
The dictionary matrix against which to solve the sparse coding of
the data. Some of the algorithms assume normalized rows for meaningful
output.</p>
<p>gram : array, shape=(n_components, n_components)
Precomputed Gram matrix, dictionary * dictionary'</p>
<p>cov : array, shape=(n_components, n_samples)
Precomputed covariance, dictionary' * X</p>
<p>algorithm : {'lasso_lars', 'lasso_cd', 'lars', 'omp', 'threshold'}
lars: uses the least angle regression method (linear_model.lars_path)
lasso_lars: uses Lars to compute the Lasso solution
lasso_cd: uses the coordinate descent method to compute the
Lasso solution (linear_model.Lasso). lasso_lars will be faster if
the estimated components are sparse.
omp: uses orthogonal matching pursuit to estimate the sparse solution
threshold: squashes to zero all coefficients less than alpha from
the projection dictionary * X'</p>
<p>n_nonzero_coefs : int, 0.1 * n_features by default
Number of nonzero coefficients to target in each column of the
solution. This is only used by <code>algorithm='lars'</code> and <code>algorithm='omp'</code>
and is overridden by <code>alpha</code> in the <code>omp</code> case.</p>
<p>alpha : float, 1. by default
If <code>algorithm='lasso_lars'</code> or <code>algorithm='lasso_cd'</code>, <code>alpha</code> is the
penalty applied to the L1 norm.
If <code>algorithm='threshold'</code>, <code>alpha</code> is the absolute value of the
threshold below which coefficients will be squashed to zero.
If <code>algorithm='omp'</code>, <code>alpha</code> is the tolerance parameter: the value of
the reconstruction error targeted. In this case, it overrides
<code>n_nonzero_coefs</code>.</p>
<p>copy_cov : boolean, optional
Whether to copy the precomputed covariance matrix; if False, it may be
overwritten.</p>
<p>init : array of shape (n_samples, n_components)
Initialization value of the sparse codes. Only used if
<code>algorithm='lasso_cd'</code>.</p>
<p>max_iter : int, 1000 by default
Maximum number of iterations to perform if <code>algorithm='lasso_cd'</code> or
<code>lasso_lars</code>.</p>
<p>n_jobs : int or None, optional (default=None)
Number of parallel jobs to run.
<code>None</code> means 1 unless in a :obj:<code>joblib.parallel_backend</code> context.
<code>-1</code> means using all processors. See :term:<code>Glossary &lt;n_jobs&gt;</code>
for more details.</p>
<p>check_input : boolean, optional
If False, the input arrays X and dictionary will not be checked.</p>
<p>verbose : int, optional
Controls the verbosity; the higher, the more messages. Defaults to 0.</p>
<p>positive : boolean, optional
Whether to enforce positivity when finding the encoding.</p>
<p>.. versionadded:: 0.20</p>
<h2 id="returns_90">Returns<a class="headerlink" href="#returns_90" title="Permanent link">&para;</a></h2>
<p>code : array of shape (n_samples, n_components)
The sparse codes</p>
<h2 id="see-also_11">See also<a class="headerlink" href="#see-also_11" title="Permanent link">&para;</a></h2>
<p>sklearn.linear_model.lars_path
sklearn.linear_model.orthogonal_mp
sklearn.linear_model.Lasso
SparseCoder</p>
                
              
              
                


              
            </article>
          </div>
        </div>
      </main>
      
        
<footer class="md-footer">
  
    <div class="md-footer-nav">
      <nav class="md-footer-nav__inner md-grid" aria-label="Footer">
        
          <a href="../Datasets/" title="Datasets" class="md-footer-nav__link md-footer-nav__link--prev" rel="prev">
            <div class="md-footer-nav__button md-icon">
              <svg xmlns="http://www.w3.org/2000/svg" viewBox="0 0 24 24"><path d="M20 11v2H8l5.5 5.5-1.42 1.42L4.16 12l7.92-7.92L13.5 5.5 8 11h12z"/></svg>
            </div>
            <div class="md-footer-nav__title">
              <div class="md-ellipsis">
                <span class="md-footer-nav__direction">
                  Previous
                </span>
                Datasets
              </div>
            </div>
          </a>
        
        
          <a href="../Discriminant_analysis/" title="Discriminant analysis" class="md-footer-nav__link md-footer-nav__link--next" rel="next">
            <div class="md-footer-nav__title">
              <div class="md-ellipsis">
                <span class="md-footer-nav__direction">
                  Next
                </span>
                Discriminant analysis
              </div>
            </div>
            <div class="md-footer-nav__button md-icon">
              <svg xmlns="http://www.w3.org/2000/svg" viewBox="0 0 24 24"><path d="M4 11v2h12l-5.5 5.5 1.42 1.42L19.84 12l-7.92-7.92L10.5 5.5 16 11H4z"/></svg>
            </div>
          </a>
        
      </nav>
    </div>
  
  <div class="md-footer-meta md-typeset">
    <div class="md-footer-meta__inner md-grid">
      <div class="md-footer-copyright">
        
        Made with
        <a href="https://squidfunk.github.io/mkdocs-material/" target="_blank" rel="noopener">
          Material for MkDocs
        </a>
      </div>
      
    </div>
  </div>
</footer>
      
    </div>
    
      <script src="../../assets/javascripts/vendor.d710d30a.min.js"></script>
      <script src="../../assets/javascripts/bundle.a45f732b.min.js"></script><script id="__lang" type="application/json">{"clipboard.copy": "Copy to clipboard", "clipboard.copied": "Copied to clipboard", "search.config.lang": "en", "search.config.pipeline": "trimmer, stopWordFilter", "search.config.separator": "[\\s\\-]+", "search.result.placeholder": "Type to start searching", "search.result.none": "No matching documents", "search.result.one": "1 matching document", "search.result.other": "# matching documents"}</script>
      
      <script>
        app = initialize({
          base: "../..",
          features: ["instant", "tabs"],
          search: Object.assign({
            worker: "../../assets/javascripts/worker/search.c03f0417.min.js"
          }, typeof search !== "undefined" && search)
        })
      </script>
      
        <script src="https://cdnjs.cloudflare.com/ajax/libs/mathjax/2.7.0/MathJax.js?config=TeX-MML-AM_CHTML"></script>
      
    
  </body>
</html>