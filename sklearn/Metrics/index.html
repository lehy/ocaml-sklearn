
<!doctype html>
<html lang="en" class="no-js">
  <head>
    
      <meta charset="utf-8">
      <meta name="viewport" content="width=device-width,initial-scale=1">
      
      
      
      
      <link rel="shortcut icon" href="../../assets/images/favicon.png">
      <meta name="generator" content="mkdocs-1.1.2, mkdocs-material-6.1.7">
    
    
      
        <title>Metrics - OCaml scikit-learn interface</title>
      
    
    
      <link rel="stylesheet" href="../../assets/stylesheets/main.19753c6b.min.css">
      
        
        <link rel="stylesheet" href="../../assets/stylesheets/palette.196e0c26.min.css">
        
          
          
          <meta name="theme-color" content="#4051b5">
        
      
    
    
    
      
        
        <link href="https://fonts.gstatic.com" rel="preconnect" crossorigin>
        <link rel="stylesheet" href="https://fonts.googleapis.com/css?family=Roboto:300,400,400i,700%7CRoboto+Mono&display=fallback">
        <style>body,input{font-family:"Roboto",-apple-system,BlinkMacSystemFont,Helvetica,Arial,sans-serif}code,kbd,pre{font-family:"Roboto Mono",SFMono-Regular,Consolas,Menlo,monospace}</style>
      
    
    
    
    
      
    
    
  </head>
  
  
    
    
    
    
    
    <body dir="ltr" data-md-color-scheme="" data-md-color-primary="indigo" data-md-color-accent="indigo">
      
  
    <input class="md-toggle" data-md-toggle="drawer" type="checkbox" id="__drawer" autocomplete="off">
    <input class="md-toggle" data-md-toggle="search" type="checkbox" id="__search" autocomplete="off">
    <label class="md-overlay" for="__drawer"></label>
    <div data-md-component="skip">
      
        
        <a href="#confusionmatrixdisplay" class="md-skip">
          Skip to content
        </a>
      
    </div>
    <div data-md-component="announce">
      
    </div>
    
      

<header class="md-header" data-md-component="header">
  <nav class="md-header-nav md-grid" aria-label="Header">
    <a href="../.." title="OCaml scikit-learn interface" class="md-header-nav__button md-logo" aria-label="OCaml scikit-learn interface">
      
  
  <svg xmlns="http://www.w3.org/2000/svg" viewBox="0 0 24 24"><path d="M12 8a3 3 0 003-3 3 3 0 00-3-3 3 3 0 00-3 3 3 3 0 003 3m0 3.54C9.64 9.35 6.5 8 3 8v11c3.5 0 6.64 1.35 9 3.54 2.36-2.19 5.5-3.54 9-3.54V8c-3.5 0-6.64 1.35-9 3.54z"/></svg>

    </a>
    <label class="md-header-nav__button md-icon" for="__drawer">
      <svg xmlns="http://www.w3.org/2000/svg" viewBox="0 0 24 24"><path d="M3 6h18v2H3V6m0 5h18v2H3v-2m0 5h18v2H3v-2z"/></svg>
    </label>
    <div class="md-header-nav__title" data-md-component="header-title">
      
        <div class="md-header-nav__ellipsis">
          <span class="md-header-nav__topic md-ellipsis">
            OCaml scikit-learn interface
          </span>
          <span class="md-header-nav__topic md-ellipsis">
            
              Metrics
            
          </span>
        </div>
      
    </div>
    
      <label class="md-header-nav__button md-icon" for="__search">
        <svg xmlns="http://www.w3.org/2000/svg" viewBox="0 0 24 24"><path d="M9.5 3A6.5 6.5 0 0116 9.5c0 1.61-.59 3.09-1.56 4.23l.27.27h.79l5 5-1.5 1.5-5-5v-.79l-.27-.27A6.516 6.516 0 019.5 16 6.5 6.5 0 013 9.5 6.5 6.5 0 019.5 3m0 2C7 5 5 7 5 9.5S7 14 9.5 14 14 12 14 9.5 12 5 9.5 5z"/></svg>
      </label>
      
<div class="md-search" data-md-component="search" role="dialog">
  <label class="md-search__overlay" for="__search"></label>
  <div class="md-search__inner" role="search">
    <form class="md-search__form" name="search">
      <input type="text" class="md-search__input" name="query" aria-label="Search" placeholder="Search" autocapitalize="off" autocorrect="off" autocomplete="off" spellcheck="false" data-md-component="search-query" data-md-state="active" required>
      <label class="md-search__icon md-icon" for="__search">
        <svg xmlns="http://www.w3.org/2000/svg" viewBox="0 0 24 24"><path d="M9.5 3A6.5 6.5 0 0116 9.5c0 1.61-.59 3.09-1.56 4.23l.27.27h.79l5 5-1.5 1.5-5-5v-.79l-.27-.27A6.516 6.516 0 019.5 16 6.5 6.5 0 013 9.5 6.5 6.5 0 019.5 3m0 2C7 5 5 7 5 9.5S7 14 9.5 14 14 12 14 9.5 12 5 9.5 5z"/></svg>
        <svg xmlns="http://www.w3.org/2000/svg" viewBox="0 0 24 24"><path d="M20 11v2H8l5.5 5.5-1.42 1.42L4.16 12l7.92-7.92L13.5 5.5 8 11h12z"/></svg>
      </label>
      <button type="reset" class="md-search__icon md-icon" aria-label="Clear" data-md-component="search-reset" tabindex="-1">
        <svg xmlns="http://www.w3.org/2000/svg" viewBox="0 0 24 24"><path d="M19 6.41L17.59 5 12 10.59 6.41 5 5 6.41 10.59 12 5 17.59 6.41 19 12 13.41 17.59 19 19 17.59 13.41 12 19 6.41z"/></svg>
      </button>
    </form>
    <div class="md-search__output">
      <div class="md-search__scrollwrap" data-md-scrollfix>
        <div class="md-search-result" data-md-component="search-result">
          <div class="md-search-result__meta">
            Initializing search
          </div>
          <ol class="md-search-result__list"></ol>
        </div>
      </div>
    </div>
  </div>
</div>
    
    
      <div class="md-header-nav__source">
        
<a href="https://github.com/lehy/ocaml-sklearn/" title="Go to repository" class="md-source">
  <div class="md-source__icon md-icon">
    
    <svg xmlns="http://www.w3.org/2000/svg" viewBox="0 0 448 512"><path d="M439.55 236.05L244 40.45a28.87 28.87 0 00-40.81 0l-40.66 40.63 51.52 51.52c27.06-9.14 52.68 16.77 43.39 43.68l49.66 49.66c34.23-11.8 61.18 31 35.47 56.69-26.49 26.49-70.21-2.87-56-37.34L240.22 199v121.85c25.3 12.54 22.26 41.85 9.08 55a34.34 34.34 0 01-48.55 0c-17.57-17.6-11.07-46.91 11.25-56v-123c-20.8-8.51-24.6-30.74-18.64-45L142.57 101 8.45 235.14a28.86 28.86 0 000 40.81l195.61 195.6a28.86 28.86 0 0040.8 0l194.69-194.69a28.86 28.86 0 000-40.81z"/></svg>
  </div>
  <div class="md-source__repository">
    lehy/ocaml-sklearn
  </div>
</a>
      </div>
    
  </nav>
</header>
    
    <div class="md-container" data-md-component="container">
      
      
        
      
      <main class="md-main" data-md-component="main">
        <div class="md-main__inner md-grid">
          
            
              <div class="md-sidebar md-sidebar--primary" data-md-component="navigation">
                <div class="md-sidebar__scrollwrap">
                  <div class="md-sidebar__inner">
                    

<nav class="md-nav md-nav--primary" aria-label="Navigation" data-md-level="0">
  <label class="md-nav__title" for="__drawer">
    <a href="../.." title="OCaml scikit-learn interface" class="md-nav__button md-logo" aria-label="OCaml scikit-learn interface">
      
  
  <svg xmlns="http://www.w3.org/2000/svg" viewBox="0 0 24 24"><path d="M12 8a3 3 0 003-3 3 3 0 00-3-3 3 3 0 00-3 3 3 3 0 003 3m0 3.54C9.64 9.35 6.5 8 3 8v11c3.5 0 6.64 1.35 9 3.54 2.36-2.19 5.5-3.54 9-3.54V8c-3.5 0-6.64 1.35-9 3.54z"/></svg>

    </a>
    OCaml scikit-learn interface
  </label>
  
    <div class="md-nav__source">
      
<a href="https://github.com/lehy/ocaml-sklearn/" title="Go to repository" class="md-source">
  <div class="md-source__icon md-icon">
    
    <svg xmlns="http://www.w3.org/2000/svg" viewBox="0 0 448 512"><path d="M439.55 236.05L244 40.45a28.87 28.87 0 00-40.81 0l-40.66 40.63 51.52 51.52c27.06-9.14 52.68 16.77 43.39 43.68l49.66 49.66c34.23-11.8 61.18 31 35.47 56.69-26.49 26.49-70.21-2.87-56-37.34L240.22 199v121.85c25.3 12.54 22.26 41.85 9.08 55a34.34 34.34 0 01-48.55 0c-17.57-17.6-11.07-46.91 11.25-56v-123c-20.8-8.51-24.6-30.74-18.64-45L142.57 101 8.45 235.14a28.86 28.86 0 000 40.81l195.61 195.6a28.86 28.86 0 0040.8 0l194.69-194.69a28.86 28.86 0 000-40.81z"/></svg>
  </div>
  <div class="md-source__repository">
    lehy/ocaml-sklearn
  </div>
</a>
    </div>
  
  <ul class="md-nav__list" data-md-scrollfix>
    
      
      
      


  <li class="md-nav__item">
    <a href="../.." class="md-nav__link">
      Home
    </a>
  </li>

    
      
      
      


  <li class="md-nav__item md-nav__item--nested">
    
    <input class="md-nav__toggle md-toggle" data-md-toggle="nav-2" type="checkbox" id="nav-2" >
    <label class="md-nav__link" for="nav-2">
      Np
      <span class="md-nav__icon md-icon"></span>
    </label>
    <nav class="md-nav" aria-label="Np" data-md-level="1">
      <label class="md-nav__title" for="nav-2">
        <span class="md-nav__icon md-icon"></span>
        Np
      </label>
      <ul class="md-nav__list" data-md-scrollfix>
        
        
          
          
          


  <li class="md-nav__item">
    <a href="../../np/" class="md-nav__link">
      Numpy for OCaml
    </a>
  </li>

        
          
          
          


  <li class="md-nav__item">
    <a href="../../np/Numpy/" class="md-nav__link">
      Numpy
    </a>
  </li>

        
          
          
          


  <li class="md-nav__item">
    <a href="../../np/NumpyRaw/" class="md-nav__link">
      NumpyRaw
    </a>
  </li>

        
          
          
          


  <li class="md-nav__item">
    <a href="../../np/PyList/" class="md-nav__link">
      PyList
    </a>
  </li>

        
          
          
          


  <li class="md-nav__item">
    <a href="../../np/dtype/" class="md-nav__link">
      Dtype
    </a>
  </li>

        
          
          
          


  <li class="md-nav__item">
    <a href="../../np/obj/" class="md-nav__link">
      Obj
    </a>
  </li>

        
      </ul>
    </nav>
  </li>

    
      
      
      


  <li class="md-nav__item md-nav__item--nested">
    
    <input class="md-nav__toggle md-toggle" data-md-toggle="nav-3" type="checkbox" id="nav-3" >
    <label class="md-nav__link" for="nav-3">
      Scipy
      <span class="md-nav__icon md-icon"></span>
    </label>
    <nav class="md-nav" aria-label="Scipy" data-md-level="1">
      <label class="md-nav__title" for="nav-3">
        <span class="md-nav__icon md-icon"></span>
        Scipy
      </label>
      <ul class="md-nav__list" data-md-scrollfix>
        
        
          
          
          


  <li class="md-nav__item">
    <a href="../../scipy/" class="md-nav__link">
      SciPy library for OCaml
    </a>
  </li>

        
          
          
          


  <li class="md-nav__item">
    <a href="../../scipy/Cluster/" class="md-nav__link">
      Cluster
    </a>
  </li>

        
          
          
          


  <li class="md-nav__item">
    <a href="../../scipy/Conftest/" class="md-nav__link">
      Conftest
    </a>
  </li>

        
          
          
          


  <li class="md-nav__item">
    <a href="../../scipy/Constants/" class="md-nav__link">
      Constants
    </a>
  </li>

        
          
          
          


  <li class="md-nav__item">
    <a href="../../scipy/Fft/" class="md-nav__link">
      Fft
    </a>
  </li>

        
          
          
          


  <li class="md-nav__item">
    <a href="../../scipy/Fftpack/" class="md-nav__link">
      Fftpack
    </a>
  </li>

        
          
          
          


  <li class="md-nav__item">
    <a href="../../scipy/Integrate/" class="md-nav__link">
      Integrate
    </a>
  </li>

        
          
          
          


  <li class="md-nav__item">
    <a href="../../scipy/Interpolate/" class="md-nav__link">
      Interpolate
    </a>
  </li>

        
          
          
          


  <li class="md-nav__item">
    <a href="../../scipy/Io/" class="md-nav__link">
      Io
    </a>
  </li>

        
          
          
          


  <li class="md-nav__item">
    <a href="../../scipy/Linalg/" class="md-nav__link">
      Linalg
    </a>
  </li>

        
          
          
          


  <li class="md-nav__item">
    <a href="../../scipy/Misc/" class="md-nav__link">
      Misc
    </a>
  </li>

        
          
          
          


  <li class="md-nav__item">
    <a href="../../scipy/Ndimage/" class="md-nav__link">
      Ndimage
    </a>
  </li>

        
          
          
          


  <li class="md-nav__item">
    <a href="../../scipy/Odr/" class="md-nav__link">
      Odr
    </a>
  </li>

        
          
          
          


  <li class="md-nav__item">
    <a href="../../scipy/Optimize/" class="md-nav__link">
      Optimize
    </a>
  </li>

        
          
          
          


  <li class="md-nav__item">
    <a href="../../scipy/Setup/" class="md-nav__link">
      Setup
    </a>
  </li>

        
          
          
          


  <li class="md-nav__item">
    <a href="../../scipy/Signal/" class="md-nav__link">
      Signal
    </a>
  </li>

        
          
          
          


  <li class="md-nav__item">
    <a href="../../scipy/Sparse/" class="md-nav__link">
      Sparse
    </a>
  </li>

        
          
          
          


  <li class="md-nav__item">
    <a href="../../scipy/Spatial/" class="md-nav__link">
      Spatial
    </a>
  </li>

        
          
          
          


  <li class="md-nav__item">
    <a href="../../scipy/Special/" class="md-nav__link">
      Special
    </a>
  </li>

        
          
          
          


  <li class="md-nav__item">
    <a href="../../scipy/Stats/" class="md-nav__link">
      Stats
    </a>
  </li>

        
          
          
          


  <li class="md-nav__item">
    <a href="../../scipy/Version/" class="md-nav__link">
      Version
    </a>
  </li>

        
          
          
          


  <li class="md-nav__item">
    <a href="../../scipy/wrap_version/" class="md-nav__link">
      Wrap version
    </a>
  </li>

        
      </ul>
    </nav>
  </li>

    
      
      
      

  


  <li class="md-nav__item md-nav__item--active md-nav__item--nested">
    
    <input class="md-nav__toggle md-toggle" data-md-toggle="nav-4" type="checkbox" id="nav-4" checked>
    <label class="md-nav__link" for="nav-4">
      Sklearn
      <span class="md-nav__icon md-icon"></span>
    </label>
    <nav class="md-nav" aria-label="Sklearn" data-md-level="1">
      <label class="md-nav__title" for="nav-4">
        <span class="md-nav__icon md-icon"></span>
        Sklearn
      </label>
      <ul class="md-nav__list" data-md-scrollfix>
        
        
          
          
          


  <li class="md-nav__item">
    <a href="../Base/" class="md-nav__link">
      Base
    </a>
  </li>

        
          
          
          


  <li class="md-nav__item">
    <a href="../Calibration/" class="md-nav__link">
      Calibration
    </a>
  </li>

        
          
          
          


  <li class="md-nav__item">
    <a href="../Cluster/" class="md-nav__link">
      Cluster
    </a>
  </li>

        
          
          
          


  <li class="md-nav__item">
    <a href="../Compose/" class="md-nav__link">
      Compose
    </a>
  </li>

        
          
          
          


  <li class="md-nav__item">
    <a href="../Conftest/" class="md-nav__link">
      Conftest
    </a>
  </li>

        
          
          
          


  <li class="md-nav__item">
    <a href="../Covariance/" class="md-nav__link">
      Covariance
    </a>
  </li>

        
          
          
          


  <li class="md-nav__item">
    <a href="../Cross_decomposition/" class="md-nav__link">
      Cross decomposition
    </a>
  </li>

        
          
          
          


  <li class="md-nav__item">
    <a href="../Datasets/" class="md-nav__link">
      Datasets
    </a>
  </li>

        
          
          
          


  <li class="md-nav__item">
    <a href="../Decomposition/" class="md-nav__link">
      Decomposition
    </a>
  </li>

        
          
          
          


  <li class="md-nav__item">
    <a href="../Discriminant_analysis/" class="md-nav__link">
      Discriminant analysis
    </a>
  </li>

        
          
          
          


  <li class="md-nav__item">
    <a href="../Dummy/" class="md-nav__link">
      Dummy
    </a>
  </li>

        
          
          
          


  <li class="md-nav__item">
    <a href="../Ensemble/" class="md-nav__link">
      Ensemble
    </a>
  </li>

        
          
          
          


  <li class="md-nav__item">
    <a href="../Exceptions/" class="md-nav__link">
      Exceptions
    </a>
  </li>

        
          
          
          


  <li class="md-nav__item">
    <a href="../Experimental/" class="md-nav__link">
      Experimental
    </a>
  </li>

        
          
          
          


  <li class="md-nav__item">
    <a href="../Externals/" class="md-nav__link">
      Externals
    </a>
  </li>

        
          
          
          


  <li class="md-nav__item">
    <a href="../Feature_extraction/" class="md-nav__link">
      Feature extraction
    </a>
  </li>

        
          
          
          


  <li class="md-nav__item">
    <a href="../Feature_selection/" class="md-nav__link">
      Feature selection
    </a>
  </li>

        
          
          
          


  <li class="md-nav__item">
    <a href="../Gaussian_process/" class="md-nav__link">
      Gaussian process
    </a>
  </li>

        
          
          
          


  <li class="md-nav__item">
    <a href="../Impute/" class="md-nav__link">
      Impute
    </a>
  </li>

        
          
          
          


  <li class="md-nav__item">
    <a href="../Inspection/" class="md-nav__link">
      Inspection
    </a>
  </li>

        
          
          
          


  <li class="md-nav__item">
    <a href="../Isotonic/" class="md-nav__link">
      Isotonic
    </a>
  </li>

        
          
          
          


  <li class="md-nav__item">
    <a href="../Kernel_approximation/" class="md-nav__link">
      Kernel approximation
    </a>
  </li>

        
          
          
          


  <li class="md-nav__item">
    <a href="../Kernel_ridge/" class="md-nav__link">
      Kernel ridge
    </a>
  </li>

        
          
          
          


  <li class="md-nav__item">
    <a href="../Linear_model/" class="md-nav__link">
      Linear model
    </a>
  </li>

        
          
          
          


  <li class="md-nav__item">
    <a href="../Manifold/" class="md-nav__link">
      Manifold
    </a>
  </li>

        
          
          
          

  


  <li class="md-nav__item md-nav__item--active">
    
    <input class="md-nav__toggle md-toggle" data-md-toggle="toc" type="checkbox" id="__toc">
    
    
      <label class="md-nav__link md-nav__link--active" for="__toc">
        Metrics
        <span class="md-nav__icon md-icon"></span>
      </label>
    
    <a href="./" class="md-nav__link md-nav__link--active">
      Metrics
    </a>
    
      
<nav class="md-nav md-nav--secondary" aria-label="Table of contents">
  
  
  
    <label class="md-nav__title" for="__toc">
      <span class="md-nav__icon md-icon"></span>
      Table of contents
    </label>
    <ul class="md-nav__list" data-md-scrollfix>
      
        <li class="md-nav__item">
  <a href="#confusionmatrixdisplay" class="md-nav__link">
    ConfusionMatrixDisplay
  </a>
  
    <nav class="md-nav" aria-label="ConfusionMatrixDisplay">
      <ul class="md-nav__list">
        
          <li class="md-nav__item">
  <a href="#create" class="md-nav__link">
    create
  </a>
  
</li>
        
          <li class="md-nav__item">
  <a href="#plot" class="md-nav__link">
    plot
  </a>
  
</li>
        
          <li class="md-nav__item">
  <a href="#im_" class="md-nav__link">
    im_
  </a>
  
</li>
        
          <li class="md-nav__item">
  <a href="#text_" class="md-nav__link">
    text_
  </a>
  
</li>
        
          <li class="md-nav__item">
  <a href="#ax_" class="md-nav__link">
    ax_
  </a>
  
</li>
        
          <li class="md-nav__item">
  <a href="#figure_" class="md-nav__link">
    figure_
  </a>
  
</li>
        
          <li class="md-nav__item">
  <a href="#to_string" class="md-nav__link">
    to_string
  </a>
  
</li>
        
          <li class="md-nav__item">
  <a href="#show" class="md-nav__link">
    show
  </a>
  
</li>
        
          <li class="md-nav__item">
  <a href="#pp" class="md-nav__link">
    pp
  </a>
  
</li>
        
      </ul>
    </nav>
  
</li>
      
        <li class="md-nav__item">
  <a href="#precisionrecalldisplay" class="md-nav__link">
    PrecisionRecallDisplay
  </a>
  
    <nav class="md-nav" aria-label="PrecisionRecallDisplay">
      <ul class="md-nav__list">
        
          <li class="md-nav__item">
  <a href="#create_1" class="md-nav__link">
    create
  </a>
  
</li>
        
          <li class="md-nav__item">
  <a href="#plot_1" class="md-nav__link">
    plot
  </a>
  
</li>
        
          <li class="md-nav__item">
  <a href="#line_" class="md-nav__link">
    line_
  </a>
  
</li>
        
          <li class="md-nav__item">
  <a href="#ax__1" class="md-nav__link">
    ax_
  </a>
  
</li>
        
          <li class="md-nav__item">
  <a href="#figure__1" class="md-nav__link">
    figure_
  </a>
  
</li>
        
          <li class="md-nav__item">
  <a href="#to_string_1" class="md-nav__link">
    to_string
  </a>
  
</li>
        
          <li class="md-nav__item">
  <a href="#show_1" class="md-nav__link">
    show
  </a>
  
</li>
        
          <li class="md-nav__item">
  <a href="#pp_1" class="md-nav__link">
    pp
  </a>
  
</li>
        
      </ul>
    </nav>
  
</li>
      
        <li class="md-nav__item">
  <a href="#roccurvedisplay" class="md-nav__link">
    RocCurveDisplay
  </a>
  
    <nav class="md-nav" aria-label="RocCurveDisplay">
      <ul class="md-nav__list">
        
          <li class="md-nav__item">
  <a href="#create_2" class="md-nav__link">
    create
  </a>
  
</li>
        
          <li class="md-nav__item">
  <a href="#plot_2" class="md-nav__link">
    plot
  </a>
  
</li>
        
          <li class="md-nav__item">
  <a href="#line__1" class="md-nav__link">
    line_
  </a>
  
</li>
        
          <li class="md-nav__item">
  <a href="#ax__2" class="md-nav__link">
    ax_
  </a>
  
</li>
        
          <li class="md-nav__item">
  <a href="#figure__2" class="md-nav__link">
    figure_
  </a>
  
</li>
        
          <li class="md-nav__item">
  <a href="#to_string_2" class="md-nav__link">
    to_string
  </a>
  
</li>
        
          <li class="md-nav__item">
  <a href="#show_2" class="md-nav__link">
    show
  </a>
  
</li>
        
          <li class="md-nav__item">
  <a href="#pp_2" class="md-nav__link">
    pp
  </a>
  
</li>
        
      </ul>
    </nav>
  
</li>
      
        <li class="md-nav__item">
  <a href="#cluster" class="md-nav__link">
    Cluster
  </a>
  
    <nav class="md-nav" aria-label="Cluster">
      <ul class="md-nav__list">
        
          <li class="md-nav__item">
  <a href="#adjusted_mutual_info_score" class="md-nav__link">
    adjusted_mutual_info_score
  </a>
  
</li>
        
          <li class="md-nav__item">
  <a href="#adjusted_rand_score" class="md-nav__link">
    adjusted_rand_score
  </a>
  
</li>
        
          <li class="md-nav__item">
  <a href="#calinski_harabasz_score" class="md-nav__link">
    calinski_harabasz_score
  </a>
  
</li>
        
          <li class="md-nav__item">
  <a href="#completeness_score" class="md-nav__link">
    completeness_score
  </a>
  
</li>
        
          <li class="md-nav__item">
  <a href="#consensus_score" class="md-nav__link">
    consensus_score
  </a>
  
</li>
        
          <li class="md-nav__item">
  <a href="#contingency_matrix" class="md-nav__link">
    contingency_matrix
  </a>
  
</li>
        
          <li class="md-nav__item">
  <a href="#davies_bouldin_score" class="md-nav__link">
    davies_bouldin_score
  </a>
  
</li>
        
          <li class="md-nav__item">
  <a href="#entropy" class="md-nav__link">
    entropy
  </a>
  
</li>
        
          <li class="md-nav__item">
  <a href="#fowlkes_mallows_score" class="md-nav__link">
    fowlkes_mallows_score
  </a>
  
</li>
        
          <li class="md-nav__item">
  <a href="#homogeneity_completeness_v_measure" class="md-nav__link">
    homogeneity_completeness_v_measure
  </a>
  
</li>
        
          <li class="md-nav__item">
  <a href="#homogeneity_score" class="md-nav__link">
    homogeneity_score
  </a>
  
</li>
        
          <li class="md-nav__item">
  <a href="#mutual_info_score" class="md-nav__link">
    mutual_info_score
  </a>
  
</li>
        
          <li class="md-nav__item">
  <a href="#normalized_mutual_info_score" class="md-nav__link">
    normalized_mutual_info_score
  </a>
  
</li>
        
          <li class="md-nav__item">
  <a href="#silhouette_samples" class="md-nav__link">
    silhouette_samples
  </a>
  
</li>
        
          <li class="md-nav__item">
  <a href="#silhouette_score" class="md-nav__link">
    silhouette_score
  </a>
  
</li>
        
          <li class="md-nav__item">
  <a href="#v_measure_score" class="md-nav__link">
    v_measure_score
  </a>
  
</li>
        
      </ul>
    </nav>
  
</li>
      
        <li class="md-nav__item">
  <a href="#pairwise" class="md-nav__link">
    Pairwise
  </a>
  
</li>
      
        <li class="md-nav__item">
  <a href="#csr_matrix" class="md-nav__link">
    Csr_matrix
  </a>
  
    <nav class="md-nav" aria-label="Csr_matrix">
      <ul class="md-nav__list">
        
          <li class="md-nav__item">
  <a href="#create_3" class="md-nav__link">
    create
  </a>
  
</li>
        
          <li class="md-nav__item">
  <a href="#get_item" class="md-nav__link">
    get_item
  </a>
  
</li>
        
          <li class="md-nav__item">
  <a href="#iter" class="md-nav__link">
    iter
  </a>
  
</li>
        
          <li class="md-nav__item">
  <a href="#setitem" class="md-nav__link">
    setitem
  </a>
  
</li>
        
          <li class="md-nav__item">
  <a href="#arcsin" class="md-nav__link">
    arcsin
  </a>
  
</li>
        
          <li class="md-nav__item">
  <a href="#arcsinh" class="md-nav__link">
    arcsinh
  </a>
  
</li>
        
          <li class="md-nav__item">
  <a href="#arctan" class="md-nav__link">
    arctan
  </a>
  
</li>
        
          <li class="md-nav__item">
  <a href="#arctanh" class="md-nav__link">
    arctanh
  </a>
  
</li>
        
          <li class="md-nav__item">
  <a href="#argmax" class="md-nav__link">
    argmax
  </a>
  
</li>
        
          <li class="md-nav__item">
  <a href="#argmin" class="md-nav__link">
    argmin
  </a>
  
</li>
        
          <li class="md-nav__item">
  <a href="#asformat" class="md-nav__link">
    asformat
  </a>
  
</li>
        
          <li class="md-nav__item">
  <a href="#asfptype" class="md-nav__link">
    asfptype
  </a>
  
</li>
        
          <li class="md-nav__item">
  <a href="#astype" class="md-nav__link">
    astype
  </a>
  
</li>
        
          <li class="md-nav__item">
  <a href="#ceil" class="md-nav__link">
    ceil
  </a>
  
</li>
        
          <li class="md-nav__item">
  <a href="#check_format" class="md-nav__link">
    check_format
  </a>
  
</li>
        
          <li class="md-nav__item">
  <a href="#conj" class="md-nav__link">
    conj
  </a>
  
</li>
        
          <li class="md-nav__item">
  <a href="#conjugate" class="md-nav__link">
    conjugate
  </a>
  
</li>
        
          <li class="md-nav__item">
  <a href="#copy" class="md-nav__link">
    copy
  </a>
  
</li>
        
          <li class="md-nav__item">
  <a href="#count_nonzero" class="md-nav__link">
    count_nonzero
  </a>
  
</li>
        
          <li class="md-nav__item">
  <a href="#deg2rad" class="md-nav__link">
    deg2rad
  </a>
  
</li>
        
          <li class="md-nav__item">
  <a href="#diagonal" class="md-nav__link">
    diagonal
  </a>
  
</li>
        
          <li class="md-nav__item">
  <a href="#dot" class="md-nav__link">
    dot
  </a>
  
</li>
        
          <li class="md-nav__item">
  <a href="#eliminate_zeros" class="md-nav__link">
    eliminate_zeros
  </a>
  
</li>
        
          <li class="md-nav__item">
  <a href="#expm1" class="md-nav__link">
    expm1
  </a>
  
</li>
        
          <li class="md-nav__item">
  <a href="#floor" class="md-nav__link">
    floor
  </a>
  
</li>
        
          <li class="md-nav__item">
  <a href="#geth" class="md-nav__link">
    getH
  </a>
  
</li>
        
          <li class="md-nav__item">
  <a href="#get_shape" class="md-nav__link">
    get_shape
  </a>
  
</li>
        
          <li class="md-nav__item">
  <a href="#getcol" class="md-nav__link">
    getcol
  </a>
  
</li>
        
          <li class="md-nav__item">
  <a href="#getformat" class="md-nav__link">
    getformat
  </a>
  
</li>
        
          <li class="md-nav__item">
  <a href="#getmaxprint" class="md-nav__link">
    getmaxprint
  </a>
  
</li>
        
          <li class="md-nav__item">
  <a href="#getnnz" class="md-nav__link">
    getnnz
  </a>
  
</li>
        
          <li class="md-nav__item">
  <a href="#getrow" class="md-nav__link">
    getrow
  </a>
  
</li>
        
          <li class="md-nav__item">
  <a href="#log1p" class="md-nav__link">
    log1p
  </a>
  
</li>
        
          <li class="md-nav__item">
  <a href="#max" class="md-nav__link">
    max
  </a>
  
</li>
        
          <li class="md-nav__item">
  <a href="#maximum" class="md-nav__link">
    maximum
  </a>
  
</li>
        
          <li class="md-nav__item">
  <a href="#mean" class="md-nav__link">
    mean
  </a>
  
</li>
        
          <li class="md-nav__item">
  <a href="#min" class="md-nav__link">
    min
  </a>
  
</li>
        
          <li class="md-nav__item">
  <a href="#minimum" class="md-nav__link">
    minimum
  </a>
  
</li>
        
          <li class="md-nav__item">
  <a href="#multiply" class="md-nav__link">
    multiply
  </a>
  
</li>
        
          <li class="md-nav__item">
  <a href="#nonzero" class="md-nav__link">
    nonzero
  </a>
  
</li>
        
          <li class="md-nav__item">
  <a href="#power" class="md-nav__link">
    power
  </a>
  
</li>
        
          <li class="md-nav__item">
  <a href="#prune" class="md-nav__link">
    prune
  </a>
  
</li>
        
          <li class="md-nav__item">
  <a href="#rad2deg" class="md-nav__link">
    rad2deg
  </a>
  
</li>
        
          <li class="md-nav__item">
  <a href="#reshape" class="md-nav__link">
    reshape
  </a>
  
</li>
        
          <li class="md-nav__item">
  <a href="#resize" class="md-nav__link">
    resize
  </a>
  
</li>
        
          <li class="md-nav__item">
  <a href="#rint" class="md-nav__link">
    rint
  </a>
  
</li>
        
          <li class="md-nav__item">
  <a href="#set_shape" class="md-nav__link">
    set_shape
  </a>
  
</li>
        
          <li class="md-nav__item">
  <a href="#setdiag" class="md-nav__link">
    setdiag
  </a>
  
</li>
        
          <li class="md-nav__item">
  <a href="#sign" class="md-nav__link">
    sign
  </a>
  
</li>
        
          <li class="md-nav__item">
  <a href="#sin" class="md-nav__link">
    sin
  </a>
  
</li>
        
          <li class="md-nav__item">
  <a href="#sinh" class="md-nav__link">
    sinh
  </a>
  
</li>
        
          <li class="md-nav__item">
  <a href="#sort_indices" class="md-nav__link">
    sort_indices
  </a>
  
</li>
        
          <li class="md-nav__item">
  <a href="#sorted_indices" class="md-nav__link">
    sorted_indices
  </a>
  
</li>
        
          <li class="md-nav__item">
  <a href="#sqrt" class="md-nav__link">
    sqrt
  </a>
  
</li>
        
          <li class="md-nav__item">
  <a href="#sum" class="md-nav__link">
    sum
  </a>
  
</li>
        
          <li class="md-nav__item">
  <a href="#sum_duplicates" class="md-nav__link">
    sum_duplicates
  </a>
  
</li>
        
          <li class="md-nav__item">
  <a href="#tan" class="md-nav__link">
    tan
  </a>
  
</li>
        
          <li class="md-nav__item">
  <a href="#tanh" class="md-nav__link">
    tanh
  </a>
  
</li>
        
          <li class="md-nav__item">
  <a href="#toarray" class="md-nav__link">
    toarray
  </a>
  
</li>
        
          <li class="md-nav__item">
  <a href="#tobsr" class="md-nav__link">
    tobsr
  </a>
  
</li>
        
          <li class="md-nav__item">
  <a href="#tocoo" class="md-nav__link">
    tocoo
  </a>
  
</li>
        
          <li class="md-nav__item">
  <a href="#tocsc" class="md-nav__link">
    tocsc
  </a>
  
</li>
        
          <li class="md-nav__item">
  <a href="#tocsr" class="md-nav__link">
    tocsr
  </a>
  
</li>
        
          <li class="md-nav__item">
  <a href="#todense" class="md-nav__link">
    todense
  </a>
  
</li>
        
          <li class="md-nav__item">
  <a href="#todia" class="md-nav__link">
    todia
  </a>
  
</li>
        
          <li class="md-nav__item">
  <a href="#todok" class="md-nav__link">
    todok
  </a>
  
</li>
        
          <li class="md-nav__item">
  <a href="#tolil" class="md-nav__link">
    tolil
  </a>
  
</li>
        
          <li class="md-nav__item">
  <a href="#transpose" class="md-nav__link">
    transpose
  </a>
  
</li>
        
          <li class="md-nav__item">
  <a href="#trunc" class="md-nav__link">
    trunc
  </a>
  
</li>
        
          <li class="md-nav__item">
  <a href="#dtype" class="md-nav__link">
    dtype
  </a>
  
</li>
        
          <li class="md-nav__item">
  <a href="#shape" class="md-nav__link">
    shape
  </a>
  
</li>
        
          <li class="md-nav__item">
  <a href="#ndim" class="md-nav__link">
    ndim
  </a>
  
</li>
        
          <li class="md-nav__item">
  <a href="#nnz" class="md-nav__link">
    nnz
  </a>
  
</li>
        
          <li class="md-nav__item">
  <a href="#data" class="md-nav__link">
    data
  </a>
  
</li>
        
          <li class="md-nav__item">
  <a href="#indices" class="md-nav__link">
    indices
  </a>
  
</li>
        
          <li class="md-nav__item">
  <a href="#indptr" class="md-nav__link">
    indptr
  </a>
  
</li>
        
          <li class="md-nav__item">
  <a href="#has_sorted_indices" class="md-nav__link">
    has_sorted_indices
  </a>
  
</li>
        
          <li class="md-nav__item">
  <a href="#to_string_3" class="md-nav__link">
    to_string
  </a>
  
</li>
        
          <li class="md-nav__item">
  <a href="#show_3" class="md-nav__link">
    show
  </a>
  
</li>
        
          <li class="md-nav__item">
  <a href="#pp_3" class="md-nav__link">
    pp
  </a>
  
</li>
        
      </ul>
    </nav>
  
</li>
      
        <li class="md-nav__item">
  <a href="#partial" class="md-nav__link">
    Partial
  </a>
  
    <nav class="md-nav" aria-label="Partial">
      <ul class="md-nav__list">
        
          <li class="md-nav__item">
  <a href="#create_4" class="md-nav__link">
    create
  </a>
  
</li>
        
          <li class="md-nav__item">
  <a href="#to_string_4" class="md-nav__link">
    to_string
  </a>
  
</li>
        
          <li class="md-nav__item">
  <a href="#show_4" class="md-nav__link">
    show
  </a>
  
</li>
        
          <li class="md-nav__item">
  <a href="#pp_4" class="md-nav__link">
    pp
  </a>
  
</li>
        
          <li class="md-nav__item">
  <a href="#additive_chi2_kernel" class="md-nav__link">
    additive_chi2_kernel
  </a>
  
</li>
        
          <li class="md-nav__item">
  <a href="#check_array" class="md-nav__link">
    check_array
  </a>
  
</li>
        
          <li class="md-nav__item">
  <a href="#check_non_negative" class="md-nav__link">
    check_non_negative
  </a>
  
</li>
        
          <li class="md-nav__item">
  <a href="#check_paired_arrays" class="md-nav__link">
    check_paired_arrays
  </a>
  
</li>
        
          <li class="md-nav__item">
  <a href="#check_pairwise_arrays" class="md-nav__link">
    check_pairwise_arrays
  </a>
  
</li>
        
          <li class="md-nav__item">
  <a href="#chi2_kernel" class="md-nav__link">
    chi2_kernel
  </a>
  
</li>
        
          <li class="md-nav__item">
  <a href="#cosine_distances" class="md-nav__link">
    cosine_distances
  </a>
  
</li>
        
          <li class="md-nav__item">
  <a href="#cosine_similarity" class="md-nav__link">
    cosine_similarity
  </a>
  
</li>
        
          <li class="md-nav__item">
  <a href="#delayed" class="md-nav__link">
    delayed
  </a>
  
</li>
        
          <li class="md-nav__item">
  <a href="#distance_metrics" class="md-nav__link">
    distance_metrics
  </a>
  
</li>
        
          <li class="md-nav__item">
  <a href="#effective_n_jobs" class="md-nav__link">
    effective_n_jobs
  </a>
  
</li>
        
          <li class="md-nav__item">
  <a href="#euclidean_distances" class="md-nav__link">
    euclidean_distances
  </a>
  
</li>
        
          <li class="md-nav__item">
  <a href="#gen_batches" class="md-nav__link">
    gen_batches
  </a>
  
</li>
        
          <li class="md-nav__item">
  <a href="#gen_even_slices" class="md-nav__link">
    gen_even_slices
  </a>
  
</li>
        
          <li class="md-nav__item">
  <a href="#get_chunk_n_rows" class="md-nav__link">
    get_chunk_n_rows
  </a>
  
</li>
        
          <li class="md-nav__item">
  <a href="#haversine_distances" class="md-nav__link">
    haversine_distances
  </a>
  
</li>
        
          <li class="md-nav__item">
  <a href="#is_scalar_nan" class="md-nav__link">
    is_scalar_nan
  </a>
  
</li>
        
          <li class="md-nav__item">
  <a href="#issparse" class="md-nav__link">
    issparse
  </a>
  
</li>
        
          <li class="md-nav__item">
  <a href="#kernel_metrics" class="md-nav__link">
    kernel_metrics
  </a>
  
</li>
        
          <li class="md-nav__item">
  <a href="#laplacian_kernel" class="md-nav__link">
    laplacian_kernel
  </a>
  
</li>
        
          <li class="md-nav__item">
  <a href="#linear_kernel" class="md-nav__link">
    linear_kernel
  </a>
  
</li>
        
          <li class="md-nav__item">
  <a href="#manhattan_distances" class="md-nav__link">
    manhattan_distances
  </a>
  
</li>
        
          <li class="md-nav__item">
  <a href="#nan_euclidean_distances" class="md-nav__link">
    nan_euclidean_distances
  </a>
  
</li>
        
          <li class="md-nav__item">
  <a href="#normalize" class="md-nav__link">
    normalize
  </a>
  
</li>
        
          <li class="md-nav__item">
  <a href="#paired_cosine_distances" class="md-nav__link">
    paired_cosine_distances
  </a>
  
</li>
        
          <li class="md-nav__item">
  <a href="#paired_distances" class="md-nav__link">
    paired_distances
  </a>
  
</li>
        
          <li class="md-nav__item">
  <a href="#paired_euclidean_distances" class="md-nav__link">
    paired_euclidean_distances
  </a>
  
</li>
        
          <li class="md-nav__item">
  <a href="#paired_manhattan_distances" class="md-nav__link">
    paired_manhattan_distances
  </a>
  
</li>
        
          <li class="md-nav__item">
  <a href="#pairwise_distances" class="md-nav__link">
    pairwise_distances
  </a>
  
</li>
        
          <li class="md-nav__item">
  <a href="#pairwise_distances_argmin" class="md-nav__link">
    pairwise_distances_argmin
  </a>
  
</li>
        
          <li class="md-nav__item">
  <a href="#pairwise_distances_argmin_min" class="md-nav__link">
    pairwise_distances_argmin_min
  </a>
  
</li>
        
          <li class="md-nav__item">
  <a href="#pairwise_distances_chunked" class="md-nav__link">
    pairwise_distances_chunked
  </a>
  
</li>
        
          <li class="md-nav__item">
  <a href="#pairwise_kernels" class="md-nav__link">
    pairwise_kernels
  </a>
  
</li>
        
          <li class="md-nav__item">
  <a href="#parse_version" class="md-nav__link">
    parse_version
  </a>
  
</li>
        
          <li class="md-nav__item">
  <a href="#polynomial_kernel" class="md-nav__link">
    polynomial_kernel
  </a>
  
</li>
        
          <li class="md-nav__item">
  <a href="#rbf_kernel" class="md-nav__link">
    rbf_kernel
  </a>
  
</li>
        
          <li class="md-nav__item">
  <a href="#row_norms" class="md-nav__link">
    row_norms
  </a>
  
</li>
        
          <li class="md-nav__item">
  <a href="#safe_sparse_dot" class="md-nav__link">
    safe_sparse_dot
  </a>
  
</li>
        
          <li class="md-nav__item">
  <a href="#sigmoid_kernel" class="md-nav__link">
    sigmoid_kernel
  </a>
  
</li>
        
          <li class="md-nav__item">
  <a href="#accuracy_score" class="md-nav__link">
    accuracy_score
  </a>
  
</li>
        
          <li class="md-nav__item">
  <a href="#adjusted_mutual_info_score_1" class="md-nav__link">
    adjusted_mutual_info_score
  </a>
  
</li>
        
          <li class="md-nav__item">
  <a href="#adjusted_rand_score_1" class="md-nav__link">
    adjusted_rand_score
  </a>
  
</li>
        
          <li class="md-nav__item">
  <a href="#auc" class="md-nav__link">
    auc
  </a>
  
</li>
        
          <li class="md-nav__item">
  <a href="#average_precision_score" class="md-nav__link">
    average_precision_score
  </a>
  
</li>
        
          <li class="md-nav__item">
  <a href="#balanced_accuracy_score" class="md-nav__link">
    balanced_accuracy_score
  </a>
  
</li>
        
          <li class="md-nav__item">
  <a href="#brier_score_loss" class="md-nav__link">
    brier_score_loss
  </a>
  
</li>
        
          <li class="md-nav__item">
  <a href="#calinski_harabasz_score_1" class="md-nav__link">
    calinski_harabasz_score
  </a>
  
</li>
        
          <li class="md-nav__item">
  <a href="#check_scoring" class="md-nav__link">
    check_scoring
  </a>
  
</li>
        
          <li class="md-nav__item">
  <a href="#classification_report" class="md-nav__link">
    classification_report
  </a>
  
</li>
        
          <li class="md-nav__item">
  <a href="#cohen_kappa_score" class="md-nav__link">
    cohen_kappa_score
  </a>
  
</li>
        
          <li class="md-nav__item">
  <a href="#completeness_score_1" class="md-nav__link">
    completeness_score
  </a>
  
</li>
        
          <li class="md-nav__item">
  <a href="#confusion_matrix" class="md-nav__link">
    confusion_matrix
  </a>
  
</li>
        
          <li class="md-nav__item">
  <a href="#consensus_score_1" class="md-nav__link">
    consensus_score
  </a>
  
</li>
        
          <li class="md-nav__item">
  <a href="#coverage_error" class="md-nav__link">
    coverage_error
  </a>
  
</li>
        
          <li class="md-nav__item">
  <a href="#davies_bouldin_score_1" class="md-nav__link">
    davies_bouldin_score
  </a>
  
</li>
        
          <li class="md-nav__item">
  <a href="#dcg_score" class="md-nav__link">
    dcg_score
  </a>
  
</li>
        
          <li class="md-nav__item">
  <a href="#euclidean_distances_1" class="md-nav__link">
    euclidean_distances
  </a>
  
</li>
        
          <li class="md-nav__item">
  <a href="#explained_variance_score" class="md-nav__link">
    explained_variance_score
  </a>
  
</li>
        
          <li class="md-nav__item">
  <a href="#f1_score" class="md-nav__link">
    f1_score
  </a>
  
</li>
        
          <li class="md-nav__item">
  <a href="#fbeta_score" class="md-nav__link">
    fbeta_score
  </a>
  
</li>
        
          <li class="md-nav__item">
  <a href="#fowlkes_mallows_score_1" class="md-nav__link">
    fowlkes_mallows_score
  </a>
  
</li>
        
          <li class="md-nav__item">
  <a href="#get_scorer" class="md-nav__link">
    get_scorer
  </a>
  
</li>
        
          <li class="md-nav__item">
  <a href="#hamming_loss" class="md-nav__link">
    hamming_loss
  </a>
  
</li>
        
          <li class="md-nav__item">
  <a href="#hinge_loss" class="md-nav__link">
    hinge_loss
  </a>
  
</li>
        
          <li class="md-nav__item">
  <a href="#homogeneity_completeness_v_measure_1" class="md-nav__link">
    homogeneity_completeness_v_measure
  </a>
  
</li>
        
          <li class="md-nav__item">
  <a href="#homogeneity_score_1" class="md-nav__link">
    homogeneity_score
  </a>
  
</li>
        
          <li class="md-nav__item">
  <a href="#jaccard_score" class="md-nav__link">
    jaccard_score
  </a>
  
</li>
        
          <li class="md-nav__item">
  <a href="#label_ranking_average_precision_score" class="md-nav__link">
    label_ranking_average_precision_score
  </a>
  
</li>
        
          <li class="md-nav__item">
  <a href="#label_ranking_loss" class="md-nav__link">
    label_ranking_loss
  </a>
  
</li>
        
          <li class="md-nav__item">
  <a href="#log_loss" class="md-nav__link">
    log_loss
  </a>
  
</li>
        
          <li class="md-nav__item">
  <a href="#make_scorer" class="md-nav__link">
    make_scorer
  </a>
  
</li>
        
          <li class="md-nav__item">
  <a href="#matthews_corrcoef" class="md-nav__link">
    matthews_corrcoef
  </a>
  
</li>
        
          <li class="md-nav__item">
  <a href="#max_error" class="md-nav__link">
    max_error
  </a>
  
</li>
        
          <li class="md-nav__item">
  <a href="#mean_absolute_error" class="md-nav__link">
    mean_absolute_error
  </a>
  
</li>
        
          <li class="md-nav__item">
  <a href="#mean_gamma_deviance" class="md-nav__link">
    mean_gamma_deviance
  </a>
  
</li>
        
          <li class="md-nav__item">
  <a href="#mean_poisson_deviance" class="md-nav__link">
    mean_poisson_deviance
  </a>
  
</li>
        
          <li class="md-nav__item">
  <a href="#mean_squared_error" class="md-nav__link">
    mean_squared_error
  </a>
  
</li>
        
          <li class="md-nav__item">
  <a href="#mean_squared_log_error" class="md-nav__link">
    mean_squared_log_error
  </a>
  
</li>
        
          <li class="md-nav__item">
  <a href="#mean_tweedie_deviance" class="md-nav__link">
    mean_tweedie_deviance
  </a>
  
</li>
        
          <li class="md-nav__item">
  <a href="#median_absolute_error" class="md-nav__link">
    median_absolute_error
  </a>
  
</li>
        
          <li class="md-nav__item">
  <a href="#multilabel_confusion_matrix" class="md-nav__link">
    multilabel_confusion_matrix
  </a>
  
</li>
        
          <li class="md-nav__item">
  <a href="#mutual_info_score_1" class="md-nav__link">
    mutual_info_score
  </a>
  
</li>
        
          <li class="md-nav__item">
  <a href="#nan_euclidean_distances_1" class="md-nav__link">
    nan_euclidean_distances
  </a>
  
</li>
        
          <li class="md-nav__item">
  <a href="#ndcg_score" class="md-nav__link">
    ndcg_score
  </a>
  
</li>
        
          <li class="md-nav__item">
  <a href="#normalized_mutual_info_score_1" class="md-nav__link">
    normalized_mutual_info_score
  </a>
  
</li>
        
          <li class="md-nav__item">
  <a href="#pairwise_distances_1" class="md-nav__link">
    pairwise_distances
  </a>
  
</li>
        
          <li class="md-nav__item">
  <a href="#pairwise_distances_argmin_1" class="md-nav__link">
    pairwise_distances_argmin
  </a>
  
</li>
        
          <li class="md-nav__item">
  <a href="#pairwise_distances_argmin_min_1" class="md-nav__link">
    pairwise_distances_argmin_min
  </a>
  
</li>
        
          <li class="md-nav__item">
  <a href="#pairwise_distances_chunked_1" class="md-nav__link">
    pairwise_distances_chunked
  </a>
  
</li>
        
          <li class="md-nav__item">
  <a href="#pairwise_kernels_1" class="md-nav__link">
    pairwise_kernels
  </a>
  
</li>
        
          <li class="md-nav__item">
  <a href="#plot_confusion_matrix" class="md-nav__link">
    plot_confusion_matrix
  </a>
  
</li>
        
          <li class="md-nav__item">
  <a href="#plot_precision_recall_curve" class="md-nav__link">
    plot_precision_recall_curve
  </a>
  
</li>
        
          <li class="md-nav__item">
  <a href="#plot_roc_curve" class="md-nav__link">
    plot_roc_curve
  </a>
  
</li>
        
          <li class="md-nav__item">
  <a href="#precision_recall_curve" class="md-nav__link">
    precision_recall_curve
  </a>
  
</li>
        
          <li class="md-nav__item">
  <a href="#precision_recall_fscore_support" class="md-nav__link">
    precision_recall_fscore_support
  </a>
  
</li>
        
          <li class="md-nav__item">
  <a href="#precision_score" class="md-nav__link">
    precision_score
  </a>
  
</li>
        
          <li class="md-nav__item">
  <a href="#r2_score" class="md-nav__link">
    r2_score
  </a>
  
</li>
        
          <li class="md-nav__item">
  <a href="#recall_score" class="md-nav__link">
    recall_score
  </a>
  
</li>
        
          <li class="md-nav__item">
  <a href="#roc_auc_score" class="md-nav__link">
    roc_auc_score
  </a>
  
</li>
        
          <li class="md-nav__item">
  <a href="#roc_curve" class="md-nav__link">
    roc_curve
  </a>
  
</li>
        
          <li class="md-nav__item">
  <a href="#silhouette_samples_1" class="md-nav__link">
    silhouette_samples
  </a>
  
</li>
        
          <li class="md-nav__item">
  <a href="#silhouette_score_1" class="md-nav__link">
    silhouette_score
  </a>
  
</li>
        
          <li class="md-nav__item">
  <a href="#v_measure_score_1" class="md-nav__link">
    v_measure_score
  </a>
  
</li>
        
          <li class="md-nav__item">
  <a href="#zero_one_loss" class="md-nav__link">
    zero_one_loss
  </a>
  
</li>
        
      </ul>
    </nav>
  
</li>
      
    </ul>
  
</nav>
    
  </li>

        
          
          
          


  <li class="md-nav__item">
    <a href="../Mixture/" class="md-nav__link">
      Mixture
    </a>
  </li>

        
          
          
          


  <li class="md-nav__item">
    <a href="../Model_selection/" class="md-nav__link">
      Model selection
    </a>
  </li>

        
          
          
          


  <li class="md-nav__item">
    <a href="../Multiclass/" class="md-nav__link">
      Multiclass
    </a>
  </li>

        
          
          
          


  <li class="md-nav__item">
    <a href="../Multioutput/" class="md-nav__link">
      Multioutput
    </a>
  </li>

        
          
          
          


  <li class="md-nav__item">
    <a href="../Naive_bayes/" class="md-nav__link">
      Naive bayes
    </a>
  </li>

        
          
          
          


  <li class="md-nav__item">
    <a href="../Neighbors/" class="md-nav__link">
      Neighbors
    </a>
  </li>

        
          
          
          


  <li class="md-nav__item">
    <a href="../Neural_network/" class="md-nav__link">
      Neural network
    </a>
  </li>

        
          
          
          


  <li class="md-nav__item">
    <a href="../Pipeline/" class="md-nav__link">
      Pipeline
    </a>
  </li>

        
          
          
          


  <li class="md-nav__item">
    <a href="../Preprocessing/" class="md-nav__link">
      Preprocessing
    </a>
  </li>

        
          
          
          


  <li class="md-nav__item">
    <a href="../Random_projection/" class="md-nav__link">
      Random projection
    </a>
  </li>

        
          
          
          


  <li class="md-nav__item">
    <a href="../Semi_supervised/" class="md-nav__link">
      Semi supervised
    </a>
  </li>

        
          
          
          


  <li class="md-nav__item">
    <a href="../Setup/" class="md-nav__link">
      Setup
    </a>
  </li>

        
          
          
          


  <li class="md-nav__item">
    <a href="../Svm/" class="md-nav__link">
      Svm
    </a>
  </li>

        
          
          
          


  <li class="md-nav__item">
    <a href="../Tests/" class="md-nav__link">
      Tests
    </a>
  </li>

        
          
          
          


  <li class="md-nav__item">
    <a href="../Tree/" class="md-nav__link">
      Tree
    </a>
  </li>

        
          
          
          


  <li class="md-nav__item">
    <a href="../Utils/" class="md-nav__link">
      Utils
    </a>
  </li>

        
          
          
          


  <li class="md-nav__item">
    <a href="../arr/" class="md-nav__link">
      Arr
    </a>
  </li>

        
          
          
          


  <li class="md-nav__item">
    <a href="../dict/" class="md-nav__link">
      Dict
    </a>
  </li>

        
          
          
          


  <li class="md-nav__item">
    <a href="../wrap_version/" class="md-nav__link">
      Wrap version
    </a>
  </li>

        
      </ul>
    </nav>
  </li>

    
  </ul>
</nav>
                  </div>
                </div>
              </div>
            
            
              <div class="md-sidebar md-sidebar--secondary" data-md-component="toc">
                <div class="md-sidebar__scrollwrap">
                  <div class="md-sidebar__inner">
                    
<nav class="md-nav md-nav--secondary" aria-label="Table of contents">
  
  
  
    <label class="md-nav__title" for="__toc">
      <span class="md-nav__icon md-icon"></span>
      Table of contents
    </label>
    <ul class="md-nav__list" data-md-scrollfix>
      
        <li class="md-nav__item">
  <a href="#confusionmatrixdisplay" class="md-nav__link">
    ConfusionMatrixDisplay
  </a>
  
    <nav class="md-nav" aria-label="ConfusionMatrixDisplay">
      <ul class="md-nav__list">
        
          <li class="md-nav__item">
  <a href="#create" class="md-nav__link">
    create
  </a>
  
</li>
        
          <li class="md-nav__item">
  <a href="#plot" class="md-nav__link">
    plot
  </a>
  
</li>
        
          <li class="md-nav__item">
  <a href="#im_" class="md-nav__link">
    im_
  </a>
  
</li>
        
          <li class="md-nav__item">
  <a href="#text_" class="md-nav__link">
    text_
  </a>
  
</li>
        
          <li class="md-nav__item">
  <a href="#ax_" class="md-nav__link">
    ax_
  </a>
  
</li>
        
          <li class="md-nav__item">
  <a href="#figure_" class="md-nav__link">
    figure_
  </a>
  
</li>
        
          <li class="md-nav__item">
  <a href="#to_string" class="md-nav__link">
    to_string
  </a>
  
</li>
        
          <li class="md-nav__item">
  <a href="#show" class="md-nav__link">
    show
  </a>
  
</li>
        
          <li class="md-nav__item">
  <a href="#pp" class="md-nav__link">
    pp
  </a>
  
</li>
        
      </ul>
    </nav>
  
</li>
      
        <li class="md-nav__item">
  <a href="#precisionrecalldisplay" class="md-nav__link">
    PrecisionRecallDisplay
  </a>
  
    <nav class="md-nav" aria-label="PrecisionRecallDisplay">
      <ul class="md-nav__list">
        
          <li class="md-nav__item">
  <a href="#create_1" class="md-nav__link">
    create
  </a>
  
</li>
        
          <li class="md-nav__item">
  <a href="#plot_1" class="md-nav__link">
    plot
  </a>
  
</li>
        
          <li class="md-nav__item">
  <a href="#line_" class="md-nav__link">
    line_
  </a>
  
</li>
        
          <li class="md-nav__item">
  <a href="#ax__1" class="md-nav__link">
    ax_
  </a>
  
</li>
        
          <li class="md-nav__item">
  <a href="#figure__1" class="md-nav__link">
    figure_
  </a>
  
</li>
        
          <li class="md-nav__item">
  <a href="#to_string_1" class="md-nav__link">
    to_string
  </a>
  
</li>
        
          <li class="md-nav__item">
  <a href="#show_1" class="md-nav__link">
    show
  </a>
  
</li>
        
          <li class="md-nav__item">
  <a href="#pp_1" class="md-nav__link">
    pp
  </a>
  
</li>
        
      </ul>
    </nav>
  
</li>
      
        <li class="md-nav__item">
  <a href="#roccurvedisplay" class="md-nav__link">
    RocCurveDisplay
  </a>
  
    <nav class="md-nav" aria-label="RocCurveDisplay">
      <ul class="md-nav__list">
        
          <li class="md-nav__item">
  <a href="#create_2" class="md-nav__link">
    create
  </a>
  
</li>
        
          <li class="md-nav__item">
  <a href="#plot_2" class="md-nav__link">
    plot
  </a>
  
</li>
        
          <li class="md-nav__item">
  <a href="#line__1" class="md-nav__link">
    line_
  </a>
  
</li>
        
          <li class="md-nav__item">
  <a href="#ax__2" class="md-nav__link">
    ax_
  </a>
  
</li>
        
          <li class="md-nav__item">
  <a href="#figure__2" class="md-nav__link">
    figure_
  </a>
  
</li>
        
          <li class="md-nav__item">
  <a href="#to_string_2" class="md-nav__link">
    to_string
  </a>
  
</li>
        
          <li class="md-nav__item">
  <a href="#show_2" class="md-nav__link">
    show
  </a>
  
</li>
        
          <li class="md-nav__item">
  <a href="#pp_2" class="md-nav__link">
    pp
  </a>
  
</li>
        
      </ul>
    </nav>
  
</li>
      
        <li class="md-nav__item">
  <a href="#cluster" class="md-nav__link">
    Cluster
  </a>
  
    <nav class="md-nav" aria-label="Cluster">
      <ul class="md-nav__list">
        
          <li class="md-nav__item">
  <a href="#adjusted_mutual_info_score" class="md-nav__link">
    adjusted_mutual_info_score
  </a>
  
</li>
        
          <li class="md-nav__item">
  <a href="#adjusted_rand_score" class="md-nav__link">
    adjusted_rand_score
  </a>
  
</li>
        
          <li class="md-nav__item">
  <a href="#calinski_harabasz_score" class="md-nav__link">
    calinski_harabasz_score
  </a>
  
</li>
        
          <li class="md-nav__item">
  <a href="#completeness_score" class="md-nav__link">
    completeness_score
  </a>
  
</li>
        
          <li class="md-nav__item">
  <a href="#consensus_score" class="md-nav__link">
    consensus_score
  </a>
  
</li>
        
          <li class="md-nav__item">
  <a href="#contingency_matrix" class="md-nav__link">
    contingency_matrix
  </a>
  
</li>
        
          <li class="md-nav__item">
  <a href="#davies_bouldin_score" class="md-nav__link">
    davies_bouldin_score
  </a>
  
</li>
        
          <li class="md-nav__item">
  <a href="#entropy" class="md-nav__link">
    entropy
  </a>
  
</li>
        
          <li class="md-nav__item">
  <a href="#fowlkes_mallows_score" class="md-nav__link">
    fowlkes_mallows_score
  </a>
  
</li>
        
          <li class="md-nav__item">
  <a href="#homogeneity_completeness_v_measure" class="md-nav__link">
    homogeneity_completeness_v_measure
  </a>
  
</li>
        
          <li class="md-nav__item">
  <a href="#homogeneity_score" class="md-nav__link">
    homogeneity_score
  </a>
  
</li>
        
          <li class="md-nav__item">
  <a href="#mutual_info_score" class="md-nav__link">
    mutual_info_score
  </a>
  
</li>
        
          <li class="md-nav__item">
  <a href="#normalized_mutual_info_score" class="md-nav__link">
    normalized_mutual_info_score
  </a>
  
</li>
        
          <li class="md-nav__item">
  <a href="#silhouette_samples" class="md-nav__link">
    silhouette_samples
  </a>
  
</li>
        
          <li class="md-nav__item">
  <a href="#silhouette_score" class="md-nav__link">
    silhouette_score
  </a>
  
</li>
        
          <li class="md-nav__item">
  <a href="#v_measure_score" class="md-nav__link">
    v_measure_score
  </a>
  
</li>
        
      </ul>
    </nav>
  
</li>
      
        <li class="md-nav__item">
  <a href="#pairwise" class="md-nav__link">
    Pairwise
  </a>
  
</li>
      
        <li class="md-nav__item">
  <a href="#csr_matrix" class="md-nav__link">
    Csr_matrix
  </a>
  
    <nav class="md-nav" aria-label="Csr_matrix">
      <ul class="md-nav__list">
        
          <li class="md-nav__item">
  <a href="#create_3" class="md-nav__link">
    create
  </a>
  
</li>
        
          <li class="md-nav__item">
  <a href="#get_item" class="md-nav__link">
    get_item
  </a>
  
</li>
        
          <li class="md-nav__item">
  <a href="#iter" class="md-nav__link">
    iter
  </a>
  
</li>
        
          <li class="md-nav__item">
  <a href="#setitem" class="md-nav__link">
    setitem
  </a>
  
</li>
        
          <li class="md-nav__item">
  <a href="#arcsin" class="md-nav__link">
    arcsin
  </a>
  
</li>
        
          <li class="md-nav__item">
  <a href="#arcsinh" class="md-nav__link">
    arcsinh
  </a>
  
</li>
        
          <li class="md-nav__item">
  <a href="#arctan" class="md-nav__link">
    arctan
  </a>
  
</li>
        
          <li class="md-nav__item">
  <a href="#arctanh" class="md-nav__link">
    arctanh
  </a>
  
</li>
        
          <li class="md-nav__item">
  <a href="#argmax" class="md-nav__link">
    argmax
  </a>
  
</li>
        
          <li class="md-nav__item">
  <a href="#argmin" class="md-nav__link">
    argmin
  </a>
  
</li>
        
          <li class="md-nav__item">
  <a href="#asformat" class="md-nav__link">
    asformat
  </a>
  
</li>
        
          <li class="md-nav__item">
  <a href="#asfptype" class="md-nav__link">
    asfptype
  </a>
  
</li>
        
          <li class="md-nav__item">
  <a href="#astype" class="md-nav__link">
    astype
  </a>
  
</li>
        
          <li class="md-nav__item">
  <a href="#ceil" class="md-nav__link">
    ceil
  </a>
  
</li>
        
          <li class="md-nav__item">
  <a href="#check_format" class="md-nav__link">
    check_format
  </a>
  
</li>
        
          <li class="md-nav__item">
  <a href="#conj" class="md-nav__link">
    conj
  </a>
  
</li>
        
          <li class="md-nav__item">
  <a href="#conjugate" class="md-nav__link">
    conjugate
  </a>
  
</li>
        
          <li class="md-nav__item">
  <a href="#copy" class="md-nav__link">
    copy
  </a>
  
</li>
        
          <li class="md-nav__item">
  <a href="#count_nonzero" class="md-nav__link">
    count_nonzero
  </a>
  
</li>
        
          <li class="md-nav__item">
  <a href="#deg2rad" class="md-nav__link">
    deg2rad
  </a>
  
</li>
        
          <li class="md-nav__item">
  <a href="#diagonal" class="md-nav__link">
    diagonal
  </a>
  
</li>
        
          <li class="md-nav__item">
  <a href="#dot" class="md-nav__link">
    dot
  </a>
  
</li>
        
          <li class="md-nav__item">
  <a href="#eliminate_zeros" class="md-nav__link">
    eliminate_zeros
  </a>
  
</li>
        
          <li class="md-nav__item">
  <a href="#expm1" class="md-nav__link">
    expm1
  </a>
  
</li>
        
          <li class="md-nav__item">
  <a href="#floor" class="md-nav__link">
    floor
  </a>
  
</li>
        
          <li class="md-nav__item">
  <a href="#geth" class="md-nav__link">
    getH
  </a>
  
</li>
        
          <li class="md-nav__item">
  <a href="#get_shape" class="md-nav__link">
    get_shape
  </a>
  
</li>
        
          <li class="md-nav__item">
  <a href="#getcol" class="md-nav__link">
    getcol
  </a>
  
</li>
        
          <li class="md-nav__item">
  <a href="#getformat" class="md-nav__link">
    getformat
  </a>
  
</li>
        
          <li class="md-nav__item">
  <a href="#getmaxprint" class="md-nav__link">
    getmaxprint
  </a>
  
</li>
        
          <li class="md-nav__item">
  <a href="#getnnz" class="md-nav__link">
    getnnz
  </a>
  
</li>
        
          <li class="md-nav__item">
  <a href="#getrow" class="md-nav__link">
    getrow
  </a>
  
</li>
        
          <li class="md-nav__item">
  <a href="#log1p" class="md-nav__link">
    log1p
  </a>
  
</li>
        
          <li class="md-nav__item">
  <a href="#max" class="md-nav__link">
    max
  </a>
  
</li>
        
          <li class="md-nav__item">
  <a href="#maximum" class="md-nav__link">
    maximum
  </a>
  
</li>
        
          <li class="md-nav__item">
  <a href="#mean" class="md-nav__link">
    mean
  </a>
  
</li>
        
          <li class="md-nav__item">
  <a href="#min" class="md-nav__link">
    min
  </a>
  
</li>
        
          <li class="md-nav__item">
  <a href="#minimum" class="md-nav__link">
    minimum
  </a>
  
</li>
        
          <li class="md-nav__item">
  <a href="#multiply" class="md-nav__link">
    multiply
  </a>
  
</li>
        
          <li class="md-nav__item">
  <a href="#nonzero" class="md-nav__link">
    nonzero
  </a>
  
</li>
        
          <li class="md-nav__item">
  <a href="#power" class="md-nav__link">
    power
  </a>
  
</li>
        
          <li class="md-nav__item">
  <a href="#prune" class="md-nav__link">
    prune
  </a>
  
</li>
        
          <li class="md-nav__item">
  <a href="#rad2deg" class="md-nav__link">
    rad2deg
  </a>
  
</li>
        
          <li class="md-nav__item">
  <a href="#reshape" class="md-nav__link">
    reshape
  </a>
  
</li>
        
          <li class="md-nav__item">
  <a href="#resize" class="md-nav__link">
    resize
  </a>
  
</li>
        
          <li class="md-nav__item">
  <a href="#rint" class="md-nav__link">
    rint
  </a>
  
</li>
        
          <li class="md-nav__item">
  <a href="#set_shape" class="md-nav__link">
    set_shape
  </a>
  
</li>
        
          <li class="md-nav__item">
  <a href="#setdiag" class="md-nav__link">
    setdiag
  </a>
  
</li>
        
          <li class="md-nav__item">
  <a href="#sign" class="md-nav__link">
    sign
  </a>
  
</li>
        
          <li class="md-nav__item">
  <a href="#sin" class="md-nav__link">
    sin
  </a>
  
</li>
        
          <li class="md-nav__item">
  <a href="#sinh" class="md-nav__link">
    sinh
  </a>
  
</li>
        
          <li class="md-nav__item">
  <a href="#sort_indices" class="md-nav__link">
    sort_indices
  </a>
  
</li>
        
          <li class="md-nav__item">
  <a href="#sorted_indices" class="md-nav__link">
    sorted_indices
  </a>
  
</li>
        
          <li class="md-nav__item">
  <a href="#sqrt" class="md-nav__link">
    sqrt
  </a>
  
</li>
        
          <li class="md-nav__item">
  <a href="#sum" class="md-nav__link">
    sum
  </a>
  
</li>
        
          <li class="md-nav__item">
  <a href="#sum_duplicates" class="md-nav__link">
    sum_duplicates
  </a>
  
</li>
        
          <li class="md-nav__item">
  <a href="#tan" class="md-nav__link">
    tan
  </a>
  
</li>
        
          <li class="md-nav__item">
  <a href="#tanh" class="md-nav__link">
    tanh
  </a>
  
</li>
        
          <li class="md-nav__item">
  <a href="#toarray" class="md-nav__link">
    toarray
  </a>
  
</li>
        
          <li class="md-nav__item">
  <a href="#tobsr" class="md-nav__link">
    tobsr
  </a>
  
</li>
        
          <li class="md-nav__item">
  <a href="#tocoo" class="md-nav__link">
    tocoo
  </a>
  
</li>
        
          <li class="md-nav__item">
  <a href="#tocsc" class="md-nav__link">
    tocsc
  </a>
  
</li>
        
          <li class="md-nav__item">
  <a href="#tocsr" class="md-nav__link">
    tocsr
  </a>
  
</li>
        
          <li class="md-nav__item">
  <a href="#todense" class="md-nav__link">
    todense
  </a>
  
</li>
        
          <li class="md-nav__item">
  <a href="#todia" class="md-nav__link">
    todia
  </a>
  
</li>
        
          <li class="md-nav__item">
  <a href="#todok" class="md-nav__link">
    todok
  </a>
  
</li>
        
          <li class="md-nav__item">
  <a href="#tolil" class="md-nav__link">
    tolil
  </a>
  
</li>
        
          <li class="md-nav__item">
  <a href="#transpose" class="md-nav__link">
    transpose
  </a>
  
</li>
        
          <li class="md-nav__item">
  <a href="#trunc" class="md-nav__link">
    trunc
  </a>
  
</li>
        
          <li class="md-nav__item">
  <a href="#dtype" class="md-nav__link">
    dtype
  </a>
  
</li>
        
          <li class="md-nav__item">
  <a href="#shape" class="md-nav__link">
    shape
  </a>
  
</li>
        
          <li class="md-nav__item">
  <a href="#ndim" class="md-nav__link">
    ndim
  </a>
  
</li>
        
          <li class="md-nav__item">
  <a href="#nnz" class="md-nav__link">
    nnz
  </a>
  
</li>
        
          <li class="md-nav__item">
  <a href="#data" class="md-nav__link">
    data
  </a>
  
</li>
        
          <li class="md-nav__item">
  <a href="#indices" class="md-nav__link">
    indices
  </a>
  
</li>
        
          <li class="md-nav__item">
  <a href="#indptr" class="md-nav__link">
    indptr
  </a>
  
</li>
        
          <li class="md-nav__item">
  <a href="#has_sorted_indices" class="md-nav__link">
    has_sorted_indices
  </a>
  
</li>
        
          <li class="md-nav__item">
  <a href="#to_string_3" class="md-nav__link">
    to_string
  </a>
  
</li>
        
          <li class="md-nav__item">
  <a href="#show_3" class="md-nav__link">
    show
  </a>
  
</li>
        
          <li class="md-nav__item">
  <a href="#pp_3" class="md-nav__link">
    pp
  </a>
  
</li>
        
      </ul>
    </nav>
  
</li>
      
        <li class="md-nav__item">
  <a href="#partial" class="md-nav__link">
    Partial
  </a>
  
    <nav class="md-nav" aria-label="Partial">
      <ul class="md-nav__list">
        
          <li class="md-nav__item">
  <a href="#create_4" class="md-nav__link">
    create
  </a>
  
</li>
        
          <li class="md-nav__item">
  <a href="#to_string_4" class="md-nav__link">
    to_string
  </a>
  
</li>
        
          <li class="md-nav__item">
  <a href="#show_4" class="md-nav__link">
    show
  </a>
  
</li>
        
          <li class="md-nav__item">
  <a href="#pp_4" class="md-nav__link">
    pp
  </a>
  
</li>
        
          <li class="md-nav__item">
  <a href="#additive_chi2_kernel" class="md-nav__link">
    additive_chi2_kernel
  </a>
  
</li>
        
          <li class="md-nav__item">
  <a href="#check_array" class="md-nav__link">
    check_array
  </a>
  
</li>
        
          <li class="md-nav__item">
  <a href="#check_non_negative" class="md-nav__link">
    check_non_negative
  </a>
  
</li>
        
          <li class="md-nav__item">
  <a href="#check_paired_arrays" class="md-nav__link">
    check_paired_arrays
  </a>
  
</li>
        
          <li class="md-nav__item">
  <a href="#check_pairwise_arrays" class="md-nav__link">
    check_pairwise_arrays
  </a>
  
</li>
        
          <li class="md-nav__item">
  <a href="#chi2_kernel" class="md-nav__link">
    chi2_kernel
  </a>
  
</li>
        
          <li class="md-nav__item">
  <a href="#cosine_distances" class="md-nav__link">
    cosine_distances
  </a>
  
</li>
        
          <li class="md-nav__item">
  <a href="#cosine_similarity" class="md-nav__link">
    cosine_similarity
  </a>
  
</li>
        
          <li class="md-nav__item">
  <a href="#delayed" class="md-nav__link">
    delayed
  </a>
  
</li>
        
          <li class="md-nav__item">
  <a href="#distance_metrics" class="md-nav__link">
    distance_metrics
  </a>
  
</li>
        
          <li class="md-nav__item">
  <a href="#effective_n_jobs" class="md-nav__link">
    effective_n_jobs
  </a>
  
</li>
        
          <li class="md-nav__item">
  <a href="#euclidean_distances" class="md-nav__link">
    euclidean_distances
  </a>
  
</li>
        
          <li class="md-nav__item">
  <a href="#gen_batches" class="md-nav__link">
    gen_batches
  </a>
  
</li>
        
          <li class="md-nav__item">
  <a href="#gen_even_slices" class="md-nav__link">
    gen_even_slices
  </a>
  
</li>
        
          <li class="md-nav__item">
  <a href="#get_chunk_n_rows" class="md-nav__link">
    get_chunk_n_rows
  </a>
  
</li>
        
          <li class="md-nav__item">
  <a href="#haversine_distances" class="md-nav__link">
    haversine_distances
  </a>
  
</li>
        
          <li class="md-nav__item">
  <a href="#is_scalar_nan" class="md-nav__link">
    is_scalar_nan
  </a>
  
</li>
        
          <li class="md-nav__item">
  <a href="#issparse" class="md-nav__link">
    issparse
  </a>
  
</li>
        
          <li class="md-nav__item">
  <a href="#kernel_metrics" class="md-nav__link">
    kernel_metrics
  </a>
  
</li>
        
          <li class="md-nav__item">
  <a href="#laplacian_kernel" class="md-nav__link">
    laplacian_kernel
  </a>
  
</li>
        
          <li class="md-nav__item">
  <a href="#linear_kernel" class="md-nav__link">
    linear_kernel
  </a>
  
</li>
        
          <li class="md-nav__item">
  <a href="#manhattan_distances" class="md-nav__link">
    manhattan_distances
  </a>
  
</li>
        
          <li class="md-nav__item">
  <a href="#nan_euclidean_distances" class="md-nav__link">
    nan_euclidean_distances
  </a>
  
</li>
        
          <li class="md-nav__item">
  <a href="#normalize" class="md-nav__link">
    normalize
  </a>
  
</li>
        
          <li class="md-nav__item">
  <a href="#paired_cosine_distances" class="md-nav__link">
    paired_cosine_distances
  </a>
  
</li>
        
          <li class="md-nav__item">
  <a href="#paired_distances" class="md-nav__link">
    paired_distances
  </a>
  
</li>
        
          <li class="md-nav__item">
  <a href="#paired_euclidean_distances" class="md-nav__link">
    paired_euclidean_distances
  </a>
  
</li>
        
          <li class="md-nav__item">
  <a href="#paired_manhattan_distances" class="md-nav__link">
    paired_manhattan_distances
  </a>
  
</li>
        
          <li class="md-nav__item">
  <a href="#pairwise_distances" class="md-nav__link">
    pairwise_distances
  </a>
  
</li>
        
          <li class="md-nav__item">
  <a href="#pairwise_distances_argmin" class="md-nav__link">
    pairwise_distances_argmin
  </a>
  
</li>
        
          <li class="md-nav__item">
  <a href="#pairwise_distances_argmin_min" class="md-nav__link">
    pairwise_distances_argmin_min
  </a>
  
</li>
        
          <li class="md-nav__item">
  <a href="#pairwise_distances_chunked" class="md-nav__link">
    pairwise_distances_chunked
  </a>
  
</li>
        
          <li class="md-nav__item">
  <a href="#pairwise_kernels" class="md-nav__link">
    pairwise_kernels
  </a>
  
</li>
        
          <li class="md-nav__item">
  <a href="#parse_version" class="md-nav__link">
    parse_version
  </a>
  
</li>
        
          <li class="md-nav__item">
  <a href="#polynomial_kernel" class="md-nav__link">
    polynomial_kernel
  </a>
  
</li>
        
          <li class="md-nav__item">
  <a href="#rbf_kernel" class="md-nav__link">
    rbf_kernel
  </a>
  
</li>
        
          <li class="md-nav__item">
  <a href="#row_norms" class="md-nav__link">
    row_norms
  </a>
  
</li>
        
          <li class="md-nav__item">
  <a href="#safe_sparse_dot" class="md-nav__link">
    safe_sparse_dot
  </a>
  
</li>
        
          <li class="md-nav__item">
  <a href="#sigmoid_kernel" class="md-nav__link">
    sigmoid_kernel
  </a>
  
</li>
        
          <li class="md-nav__item">
  <a href="#accuracy_score" class="md-nav__link">
    accuracy_score
  </a>
  
</li>
        
          <li class="md-nav__item">
  <a href="#adjusted_mutual_info_score_1" class="md-nav__link">
    adjusted_mutual_info_score
  </a>
  
</li>
        
          <li class="md-nav__item">
  <a href="#adjusted_rand_score_1" class="md-nav__link">
    adjusted_rand_score
  </a>
  
</li>
        
          <li class="md-nav__item">
  <a href="#auc" class="md-nav__link">
    auc
  </a>
  
</li>
        
          <li class="md-nav__item">
  <a href="#average_precision_score" class="md-nav__link">
    average_precision_score
  </a>
  
</li>
        
          <li class="md-nav__item">
  <a href="#balanced_accuracy_score" class="md-nav__link">
    balanced_accuracy_score
  </a>
  
</li>
        
          <li class="md-nav__item">
  <a href="#brier_score_loss" class="md-nav__link">
    brier_score_loss
  </a>
  
</li>
        
          <li class="md-nav__item">
  <a href="#calinski_harabasz_score_1" class="md-nav__link">
    calinski_harabasz_score
  </a>
  
</li>
        
          <li class="md-nav__item">
  <a href="#check_scoring" class="md-nav__link">
    check_scoring
  </a>
  
</li>
        
          <li class="md-nav__item">
  <a href="#classification_report" class="md-nav__link">
    classification_report
  </a>
  
</li>
        
          <li class="md-nav__item">
  <a href="#cohen_kappa_score" class="md-nav__link">
    cohen_kappa_score
  </a>
  
</li>
        
          <li class="md-nav__item">
  <a href="#completeness_score_1" class="md-nav__link">
    completeness_score
  </a>
  
</li>
        
          <li class="md-nav__item">
  <a href="#confusion_matrix" class="md-nav__link">
    confusion_matrix
  </a>
  
</li>
        
          <li class="md-nav__item">
  <a href="#consensus_score_1" class="md-nav__link">
    consensus_score
  </a>
  
</li>
        
          <li class="md-nav__item">
  <a href="#coverage_error" class="md-nav__link">
    coverage_error
  </a>
  
</li>
        
          <li class="md-nav__item">
  <a href="#davies_bouldin_score_1" class="md-nav__link">
    davies_bouldin_score
  </a>
  
</li>
        
          <li class="md-nav__item">
  <a href="#dcg_score" class="md-nav__link">
    dcg_score
  </a>
  
</li>
        
          <li class="md-nav__item">
  <a href="#euclidean_distances_1" class="md-nav__link">
    euclidean_distances
  </a>
  
</li>
        
          <li class="md-nav__item">
  <a href="#explained_variance_score" class="md-nav__link">
    explained_variance_score
  </a>
  
</li>
        
          <li class="md-nav__item">
  <a href="#f1_score" class="md-nav__link">
    f1_score
  </a>
  
</li>
        
          <li class="md-nav__item">
  <a href="#fbeta_score" class="md-nav__link">
    fbeta_score
  </a>
  
</li>
        
          <li class="md-nav__item">
  <a href="#fowlkes_mallows_score_1" class="md-nav__link">
    fowlkes_mallows_score
  </a>
  
</li>
        
          <li class="md-nav__item">
  <a href="#get_scorer" class="md-nav__link">
    get_scorer
  </a>
  
</li>
        
          <li class="md-nav__item">
  <a href="#hamming_loss" class="md-nav__link">
    hamming_loss
  </a>
  
</li>
        
          <li class="md-nav__item">
  <a href="#hinge_loss" class="md-nav__link">
    hinge_loss
  </a>
  
</li>
        
          <li class="md-nav__item">
  <a href="#homogeneity_completeness_v_measure_1" class="md-nav__link">
    homogeneity_completeness_v_measure
  </a>
  
</li>
        
          <li class="md-nav__item">
  <a href="#homogeneity_score_1" class="md-nav__link">
    homogeneity_score
  </a>
  
</li>
        
          <li class="md-nav__item">
  <a href="#jaccard_score" class="md-nav__link">
    jaccard_score
  </a>
  
</li>
        
          <li class="md-nav__item">
  <a href="#label_ranking_average_precision_score" class="md-nav__link">
    label_ranking_average_precision_score
  </a>
  
</li>
        
          <li class="md-nav__item">
  <a href="#label_ranking_loss" class="md-nav__link">
    label_ranking_loss
  </a>
  
</li>
        
          <li class="md-nav__item">
  <a href="#log_loss" class="md-nav__link">
    log_loss
  </a>
  
</li>
        
          <li class="md-nav__item">
  <a href="#make_scorer" class="md-nav__link">
    make_scorer
  </a>
  
</li>
        
          <li class="md-nav__item">
  <a href="#matthews_corrcoef" class="md-nav__link">
    matthews_corrcoef
  </a>
  
</li>
        
          <li class="md-nav__item">
  <a href="#max_error" class="md-nav__link">
    max_error
  </a>
  
</li>
        
          <li class="md-nav__item">
  <a href="#mean_absolute_error" class="md-nav__link">
    mean_absolute_error
  </a>
  
</li>
        
          <li class="md-nav__item">
  <a href="#mean_gamma_deviance" class="md-nav__link">
    mean_gamma_deviance
  </a>
  
</li>
        
          <li class="md-nav__item">
  <a href="#mean_poisson_deviance" class="md-nav__link">
    mean_poisson_deviance
  </a>
  
</li>
        
          <li class="md-nav__item">
  <a href="#mean_squared_error" class="md-nav__link">
    mean_squared_error
  </a>
  
</li>
        
          <li class="md-nav__item">
  <a href="#mean_squared_log_error" class="md-nav__link">
    mean_squared_log_error
  </a>
  
</li>
        
          <li class="md-nav__item">
  <a href="#mean_tweedie_deviance" class="md-nav__link">
    mean_tweedie_deviance
  </a>
  
</li>
        
          <li class="md-nav__item">
  <a href="#median_absolute_error" class="md-nav__link">
    median_absolute_error
  </a>
  
</li>
        
          <li class="md-nav__item">
  <a href="#multilabel_confusion_matrix" class="md-nav__link">
    multilabel_confusion_matrix
  </a>
  
</li>
        
          <li class="md-nav__item">
  <a href="#mutual_info_score_1" class="md-nav__link">
    mutual_info_score
  </a>
  
</li>
        
          <li class="md-nav__item">
  <a href="#nan_euclidean_distances_1" class="md-nav__link">
    nan_euclidean_distances
  </a>
  
</li>
        
          <li class="md-nav__item">
  <a href="#ndcg_score" class="md-nav__link">
    ndcg_score
  </a>
  
</li>
        
          <li class="md-nav__item">
  <a href="#normalized_mutual_info_score_1" class="md-nav__link">
    normalized_mutual_info_score
  </a>
  
</li>
        
          <li class="md-nav__item">
  <a href="#pairwise_distances_1" class="md-nav__link">
    pairwise_distances
  </a>
  
</li>
        
          <li class="md-nav__item">
  <a href="#pairwise_distances_argmin_1" class="md-nav__link">
    pairwise_distances_argmin
  </a>
  
</li>
        
          <li class="md-nav__item">
  <a href="#pairwise_distances_argmin_min_1" class="md-nav__link">
    pairwise_distances_argmin_min
  </a>
  
</li>
        
          <li class="md-nav__item">
  <a href="#pairwise_distances_chunked_1" class="md-nav__link">
    pairwise_distances_chunked
  </a>
  
</li>
        
          <li class="md-nav__item">
  <a href="#pairwise_kernels_1" class="md-nav__link">
    pairwise_kernels
  </a>
  
</li>
        
          <li class="md-nav__item">
  <a href="#plot_confusion_matrix" class="md-nav__link">
    plot_confusion_matrix
  </a>
  
</li>
        
          <li class="md-nav__item">
  <a href="#plot_precision_recall_curve" class="md-nav__link">
    plot_precision_recall_curve
  </a>
  
</li>
        
          <li class="md-nav__item">
  <a href="#plot_roc_curve" class="md-nav__link">
    plot_roc_curve
  </a>
  
</li>
        
          <li class="md-nav__item">
  <a href="#precision_recall_curve" class="md-nav__link">
    precision_recall_curve
  </a>
  
</li>
        
          <li class="md-nav__item">
  <a href="#precision_recall_fscore_support" class="md-nav__link">
    precision_recall_fscore_support
  </a>
  
</li>
        
          <li class="md-nav__item">
  <a href="#precision_score" class="md-nav__link">
    precision_score
  </a>
  
</li>
        
          <li class="md-nav__item">
  <a href="#r2_score" class="md-nav__link">
    r2_score
  </a>
  
</li>
        
          <li class="md-nav__item">
  <a href="#recall_score" class="md-nav__link">
    recall_score
  </a>
  
</li>
        
          <li class="md-nav__item">
  <a href="#roc_auc_score" class="md-nav__link">
    roc_auc_score
  </a>
  
</li>
        
          <li class="md-nav__item">
  <a href="#roc_curve" class="md-nav__link">
    roc_curve
  </a>
  
</li>
        
          <li class="md-nav__item">
  <a href="#silhouette_samples_1" class="md-nav__link">
    silhouette_samples
  </a>
  
</li>
        
          <li class="md-nav__item">
  <a href="#silhouette_score_1" class="md-nav__link">
    silhouette_score
  </a>
  
</li>
        
          <li class="md-nav__item">
  <a href="#v_measure_score_1" class="md-nav__link">
    v_measure_score
  </a>
  
</li>
        
          <li class="md-nav__item">
  <a href="#zero_one_loss" class="md-nav__link">
    zero_one_loss
  </a>
  
</li>
        
      </ul>
    </nav>
  
</li>
      
    </ul>
  
</nav>
                  </div>
                </div>
              </div>
            
          
          <div class="md-content">
            <article class="md-content__inner md-typeset">
              
                
                  <a href="https://github.com/lehy/ocaml-sklearn/edit/master/docs/sklearn/Metrics.md" title="Edit this page" class="md-content__button md-icon">
                    <svg xmlns="http://www.w3.org/2000/svg" viewBox="0 0 24 24"><path d="M20.71 7.04c.39-.39.39-1.04 0-1.41l-2.34-2.34c-.37-.39-1.02-.39-1.41 0l-1.84 1.83 3.75 3.75M3 17.25V21h3.75L17.81 9.93l-3.75-3.75L3 17.25z"/></svg>
                  </a>
                
                
                  <h1>Metrics</h1>
                
                <h2 id="confusionmatrixdisplay">ConfusionMatrixDisplay<a class="headerlink" href="#confusionmatrixdisplay" title="Permanent link">&para;</a></h2>
<p>Module <code>Sklearn.Metrics.ConfusionMatrixDisplay</code> wraps Python class <a href="https://scikit-learn.org/stable/modules/generated/sklearn.metrics.ConfusionMatrixDisplay.html"><code>sklearn.metrics.ConfusionMatrixDisplay</code></a>.</p>
<div class="highlight"><pre><span></span><code><span class="k">type</span> <span class="n">t</span>
</code></pre></div>

<h3 id="create">create<a class="headerlink" href="#create" title="Permanent link">&para;</a></h3>
<details class="note" open="open"><summary>constructor and attributes create</summary><div class="highlight"><pre><span></span><code><span class="k">val</span> <span class="n">create</span> <span class="o">:</span>
  <span class="o">?</span><span class="n">display_labels</span><span class="o">:[&gt;`</span><span class="nc">ArrayLike</span><span class="o">]</span> <span class="nn">Np</span><span class="p">.</span><span class="nn">Obj</span><span class="p">.</span><span class="n">t</span> <span class="o">-&gt;</span>
  <span class="n">confusion_matrix</span><span class="o">:[&gt;`</span><span class="nc">ArrayLike</span><span class="o">]</span> <span class="nn">Np</span><span class="p">.</span><span class="nn">Obj</span><span class="p">.</span><span class="n">t</span> <span class="o">-&gt;</span>
  <span class="kt">unit</span> <span class="o">-&gt;</span>
  <span class="n">t</span>
</code></pre></div>

<p>Confusion Matrix visualization.</p>
<p>It is recommend to use :func:<code>~sklearn.metrics.plot_confusion_matrix</code> to
create a :class:<code>ConfusionMatrixDisplay</code>. All parameters are stored as
attributes.</p>
<p>Read more in the :ref:<code>User Guide &lt;visualizations&gt;</code>.</p>
<h4>Parameters</h4>
<ul>
<li>
<p><strong>confusion_matrix : ndarray of shape (n_classes, n_classes)</strong>
    Confusion matrix.</p>
</li>
<li>
<p><strong>display_labels : ndarray of shape (n_classes,), default=None</strong>
    Display labels for plot. If None, display labels are set from 0 to
    <code>n_classes - 1</code>.</p>
</li>
</ul>
<h4>Attributes</h4>
<ul>
<li>
<p><strong>im_ : matplotlib AxesImage</strong>
    Image representing the confusion matrix.</p>
</li>
<li>
<p><strong>text_ : ndarray of shape (n_classes, n_classes), dtype=matplotlib Text,             or None</strong>
    Array of matplotlib axes. <code>None</code> if <code>include_values</code> is false.</p>
</li>
<li>
<p><strong>ax_ : matplotlib Axes</strong>
    Axes with confusion matrix.</p>
</li>
<li>
<p><strong>figure_ : matplotlib Figure</strong>
    Figure containing the confusion matrix.</p>
</li>
</ul>
</details>
<h3 id="plot">plot<a class="headerlink" href="#plot" title="Permanent link">&para;</a></h3>
<details class="note" open="open"><summary>method plot</summary><div class="highlight"><pre><span></span><code><span class="k">val</span> <span class="n">plot</span> <span class="o">:</span>
  <span class="o">?</span><span class="n">include_values</span><span class="o">:</span><span class="kt">bool</span> <span class="o">-&gt;</span>
  <span class="o">?</span><span class="n">cmap</span><span class="o">:[`</span><span class="nc">S</span> <span class="k">of</span> <span class="kt">string</span> <span class="o">|</span> <span class="o">`</span><span class="nc">Matplotlib_Colormap</span> <span class="k">of</span> <span class="nn">Py</span><span class="p">.</span><span class="nn">Object</span><span class="p">.</span><span class="n">t</span><span class="o">]</span> <span class="o">-&gt;</span>
  <span class="o">?</span><span class="n">xticks_rotation</span><span class="o">:[`</span><span class="nc">Horizontal</span> <span class="o">|</span> <span class="o">`</span><span class="nc">F</span> <span class="k">of</span> <span class="kt">float</span> <span class="o">|</span> <span class="o">`</span><span class="nc">Vertical</span><span class="o">]</span> <span class="o">-&gt;</span>
  <span class="o">?</span><span class="n">values_format</span><span class="o">:</span><span class="kt">string</span> <span class="o">-&gt;</span>
  <span class="o">?</span><span class="n">ax</span><span class="o">:</span><span class="nn">Py</span><span class="p">.</span><span class="nn">Object</span><span class="p">.</span><span class="n">t</span> <span class="o">-&gt;</span>
  <span class="o">[&gt;</span> <span class="n">tag</span><span class="o">]</span> <span class="nn">Obj</span><span class="p">.</span><span class="n">t</span> <span class="o">-&gt;</span>
  <span class="nn">Py</span><span class="p">.</span><span class="nn">Object</span><span class="p">.</span><span class="n">t</span>
</code></pre></div>

<p>Plot visualization.</p>
<h4>Parameters</h4>
<ul>
<li>
<p><strong>include_values : bool, default=True</strong>
    Includes values in confusion matrix.</p>
</li>
<li>
<p><strong>cmap : str or matplotlib Colormap, default='viridis'</strong>
    Colormap recognized by matplotlib.</p>
</li>
<li>
<p><strong>xticks_rotation : {'vertical', 'horizontal'} or float,                          default='horizontal'</strong>
    Rotation of xtick labels.</p>
</li>
<li>
<p><strong>values_format : str, default=None</strong>
    Format specification for values in confusion matrix. If <code>None</code>,
    the format specification is 'd' or '.2g' whichever is shorter.</p>
</li>
<li>
<p><strong>ax : matplotlib axes, default=None</strong>
    Axes object to plot on. If <code>None</code>, a new figure and axes is
    created.</p>
</li>
</ul>
<h4>Returns</h4>
<ul>
<li><strong>display : :class:<code>~sklearn.metrics.ConfusionMatrixDisplay</code></strong></li>
</ul>
</details>
<h3 id="im_">im_<a class="headerlink" href="#im_" title="Permanent link">&para;</a></h3>
<details class="note" open="open"><summary>attribute im_</summary><div class="highlight"><pre><span></span><code><span class="k">val</span> <span class="n">im_</span> <span class="o">:</span> <span class="n">t</span> <span class="o">-&gt;</span> <span class="nn">Py</span><span class="p">.</span><span class="nn">Object</span><span class="p">.</span><span class="n">t</span>
<span class="k">val</span> <span class="n">im_opt</span> <span class="o">:</span> <span class="n">t</span> <span class="o">-&gt;</span> <span class="o">(</span><span class="nn">Py</span><span class="p">.</span><span class="nn">Object</span><span class="p">.</span><span class="n">t</span><span class="o">)</span> <span class="n">option</span>
</code></pre></div>

<p>This attribute is documented in <code>create</code> above. The first version raises Not_found
if the attribute is None. The _opt version returns an option.</p>
</details>
<h3 id="text_">text_<a class="headerlink" href="#text_" title="Permanent link">&para;</a></h3>
<details class="note" open="open"><summary>attribute text_</summary><div class="highlight"><pre><span></span><code><span class="k">val</span> <span class="n">text_</span> <span class="o">:</span> <span class="n">t</span> <span class="o">-&gt;</span> <span class="nn">Py</span><span class="p">.</span><span class="nn">Object</span><span class="p">.</span><span class="n">t</span>
<span class="k">val</span> <span class="n">text_opt</span> <span class="o">:</span> <span class="n">t</span> <span class="o">-&gt;</span> <span class="o">(</span><span class="nn">Py</span><span class="p">.</span><span class="nn">Object</span><span class="p">.</span><span class="n">t</span><span class="o">)</span> <span class="n">option</span>
</code></pre></div>

<p>This attribute is documented in <code>create</code> above. The first version raises Not_found
if the attribute is None. The _opt version returns an option.</p>
</details>
<h3 id="ax_">ax_<a class="headerlink" href="#ax_" title="Permanent link">&para;</a></h3>
<details class="note" open="open"><summary>attribute ax_</summary><div class="highlight"><pre><span></span><code><span class="k">val</span> <span class="n">ax_</span> <span class="o">:</span> <span class="n">t</span> <span class="o">-&gt;</span> <span class="nn">Py</span><span class="p">.</span><span class="nn">Object</span><span class="p">.</span><span class="n">t</span>
<span class="k">val</span> <span class="n">ax_opt</span> <span class="o">:</span> <span class="n">t</span> <span class="o">-&gt;</span> <span class="o">(</span><span class="nn">Py</span><span class="p">.</span><span class="nn">Object</span><span class="p">.</span><span class="n">t</span><span class="o">)</span> <span class="n">option</span>
</code></pre></div>

<p>This attribute is documented in <code>create</code> above. The first version raises Not_found
if the attribute is None. The _opt version returns an option.</p>
</details>
<h3 id="figure_">figure_<a class="headerlink" href="#figure_" title="Permanent link">&para;</a></h3>
<details class="note" open="open"><summary>attribute figure_</summary><div class="highlight"><pre><span></span><code><span class="k">val</span> <span class="n">figure_</span> <span class="o">:</span> <span class="n">t</span> <span class="o">-&gt;</span> <span class="nn">Py</span><span class="p">.</span><span class="nn">Object</span><span class="p">.</span><span class="n">t</span>
<span class="k">val</span> <span class="n">figure_opt</span> <span class="o">:</span> <span class="n">t</span> <span class="o">-&gt;</span> <span class="o">(</span><span class="nn">Py</span><span class="p">.</span><span class="nn">Object</span><span class="p">.</span><span class="n">t</span><span class="o">)</span> <span class="n">option</span>
</code></pre></div>

<p>This attribute is documented in <code>create</code> above. The first version raises Not_found
if the attribute is None. The _opt version returns an option.</p>
</details>
<h3 id="to_string">to_string<a class="headerlink" href="#to_string" title="Permanent link">&para;</a></h3>
<details class="note" open="open"><summary>method to_string</summary><div class="highlight"><pre><span></span><code><span class="k">val</span> <span class="n">to_string</span><span class="o">:</span> <span class="n">t</span> <span class="o">-&gt;</span> <span class="kt">string</span>
</code></pre></div>

<p>Print the object to a human-readable representation.</p>
</details>
<h3 id="show">show<a class="headerlink" href="#show" title="Permanent link">&para;</a></h3>
<details class="note" open="open"><summary>method show</summary><div class="highlight"><pre><span></span><code><span class="k">val</span> <span class="n">show</span><span class="o">:</span> <span class="n">t</span> <span class="o">-&gt;</span> <span class="kt">string</span>
</code></pre></div>

<p>Print the object to a human-readable representation.</p>
</details>
<h3 id="pp">pp<a class="headerlink" href="#pp" title="Permanent link">&para;</a></h3>
<details class="note" open="open"><summary>method pp</summary><div class="highlight"><pre><span></span><code><span class="k">val</span> <span class="n">pp</span><span class="o">:</span> <span class="nn">Format</span><span class="p">.</span><span class="n">formatter</span> <span class="o">-&gt;</span> <span class="n">t</span> <span class="o">-&gt;</span> <span class="kt">unit</span>
</code></pre></div>

<p>Pretty-print the object to a formatter.</p>
</details>
<h2 id="precisionrecalldisplay">PrecisionRecallDisplay<a class="headerlink" href="#precisionrecalldisplay" title="Permanent link">&para;</a></h2>
<p>Module <code>Sklearn.Metrics.PrecisionRecallDisplay</code> wraps Python class <a href="https://scikit-learn.org/stable/modules/generated/sklearn.metrics.PrecisionRecallDisplay.html"><code>sklearn.metrics.PrecisionRecallDisplay</code></a>.</p>
<div class="highlight"><pre><span></span><code><span class="k">type</span> <span class="n">t</span>
</code></pre></div>

<h3 id="create_1">create<a class="headerlink" href="#create_1" title="Permanent link">&para;</a></h3>
<details class="note" open="open"><summary>constructor and attributes create</summary><div class="highlight"><pre><span></span><code><span class="k">val</span> <span class="n">create</span> <span class="o">:</span>
  <span class="o">?</span><span class="n">average_precision</span><span class="o">:</span><span class="kt">float</span> <span class="o">-&gt;</span>
  <span class="o">?</span><span class="n">estimator_name</span><span class="o">:</span><span class="kt">string</span> <span class="o">-&gt;</span>
  <span class="n">precision</span><span class="o">:[&gt;`</span><span class="nc">ArrayLike</span><span class="o">]</span> <span class="nn">Np</span><span class="p">.</span><span class="nn">Obj</span><span class="p">.</span><span class="n">t</span> <span class="o">-&gt;</span>
  <span class="n">recall</span><span class="o">:[&gt;`</span><span class="nc">ArrayLike</span><span class="o">]</span> <span class="nn">Np</span><span class="p">.</span><span class="nn">Obj</span><span class="p">.</span><span class="n">t</span> <span class="o">-&gt;</span>
  <span class="kt">unit</span> <span class="o">-&gt;</span>
  <span class="n">t</span>
</code></pre></div>

<p>Precision Recall visualization.</p>
<p>It is recommend to use :func:<code>~sklearn.metrics.plot_precision_recall_curve</code>
to create a visualizer. All parameters are stored as attributes.</p>
<p>Read more in the :ref:<code>User Guide &lt;visualizations&gt;</code>.</p>
<h4>Parameters</h4>
<ul>
<li>
<p><strong>precision : ndarray</strong>
    Precision values.</p>
</li>
<li>
<p><strong>recall : ndarray</strong>
    Recall values.</p>
</li>
<li>
<p><strong>average_precision : float, default=None</strong>
    Average precision. If None, the average precision is not shown.</p>
</li>
<li>
<p><strong>estimator_name : str, default=None</strong>
    Name of estimator. If None, then the estimator name is not shown.</p>
</li>
</ul>
<h4>Attributes</h4>
<ul>
<li>
<p><strong>line_ : matplotlib Artist</strong>
    Precision recall curve.</p>
</li>
<li>
<p><strong>ax_ : matplotlib Axes</strong>
    Axes with precision recall curve.</p>
</li>
<li>
<p><strong>figure_ : matplotlib Figure</strong>
    Figure containing the curve.</p>
</li>
</ul>
</details>
<h3 id="plot_1">plot<a class="headerlink" href="#plot_1" title="Permanent link">&para;</a></h3>
<details class="note" open="open"><summary>method plot</summary><div class="highlight"><pre><span></span><code><span class="k">val</span> <span class="n">plot</span> <span class="o">:</span>
  <span class="o">?</span><span class="n">ax</span><span class="o">:</span><span class="nn">Py</span><span class="p">.</span><span class="nn">Object</span><span class="p">.</span><span class="n">t</span> <span class="o">-&gt;</span>
  <span class="o">?</span><span class="n">name</span><span class="o">:</span><span class="kt">string</span> <span class="o">-&gt;</span>
  <span class="o">?</span><span class="n">kwargs</span><span class="o">:(</span><span class="kt">string</span> <span class="o">*</span> <span class="nn">Py</span><span class="p">.</span><span class="nn">Object</span><span class="p">.</span><span class="n">t</span><span class="o">)</span> <span class="kt">list</span> <span class="o">-&gt;</span>
  <span class="o">[&gt;</span> <span class="n">tag</span><span class="o">]</span> <span class="nn">Obj</span><span class="p">.</span><span class="n">t</span> <span class="o">-&gt;</span>
  <span class="nn">Py</span><span class="p">.</span><span class="nn">Object</span><span class="p">.</span><span class="n">t</span>
</code></pre></div>

<p>Plot visualization.</p>
<p>Extra keyword arguments will be passed to matplotlib's <code>plot</code>.</p>
<h4>Parameters</h4>
<ul>
<li>
<p><strong>ax : Matplotlib Axes, default=None</strong>
    Axes object to plot on. If <code>None</code>, a new figure and axes is
    created.</p>
</li>
<li>
<p><strong>name : str, default=None</strong>
    Name of precision recall curve for labeling. If <code>None</code>, use the
    name of the estimator.</p>
</li>
<li>
<p><strong>**kwargs : dict</strong>
    Keyword arguments to be passed to matplotlib's <code>plot</code>.</p>
</li>
</ul>
<h4>Returns</h4>
<ul>
<li><strong>display : :class:<code>~sklearn.metrics.PrecisionRecallDisplay</code></strong>
    Object that stores computed values.</li>
</ul>
</details>
<h3 id="line_">line_<a class="headerlink" href="#line_" title="Permanent link">&para;</a></h3>
<details class="note" open="open"><summary>attribute line_</summary><div class="highlight"><pre><span></span><code><span class="k">val</span> <span class="n">line_</span> <span class="o">:</span> <span class="n">t</span> <span class="o">-&gt;</span> <span class="nn">Py</span><span class="p">.</span><span class="nn">Object</span><span class="p">.</span><span class="n">t</span>
<span class="k">val</span> <span class="n">line_opt</span> <span class="o">:</span> <span class="n">t</span> <span class="o">-&gt;</span> <span class="o">(</span><span class="nn">Py</span><span class="p">.</span><span class="nn">Object</span><span class="p">.</span><span class="n">t</span><span class="o">)</span> <span class="n">option</span>
</code></pre></div>

<p>This attribute is documented in <code>create</code> above. The first version raises Not_found
if the attribute is None. The _opt version returns an option.</p>
</details>
<h3 id="ax__1">ax_<a class="headerlink" href="#ax__1" title="Permanent link">&para;</a></h3>
<details class="note" open="open"><summary>attribute ax_</summary><div class="highlight"><pre><span></span><code><span class="k">val</span> <span class="n">ax_</span> <span class="o">:</span> <span class="n">t</span> <span class="o">-&gt;</span> <span class="nn">Py</span><span class="p">.</span><span class="nn">Object</span><span class="p">.</span><span class="n">t</span>
<span class="k">val</span> <span class="n">ax_opt</span> <span class="o">:</span> <span class="n">t</span> <span class="o">-&gt;</span> <span class="o">(</span><span class="nn">Py</span><span class="p">.</span><span class="nn">Object</span><span class="p">.</span><span class="n">t</span><span class="o">)</span> <span class="n">option</span>
</code></pre></div>

<p>This attribute is documented in <code>create</code> above. The first version raises Not_found
if the attribute is None. The _opt version returns an option.</p>
</details>
<h3 id="figure__1">figure_<a class="headerlink" href="#figure__1" title="Permanent link">&para;</a></h3>
<details class="note" open="open"><summary>attribute figure_</summary><div class="highlight"><pre><span></span><code><span class="k">val</span> <span class="n">figure_</span> <span class="o">:</span> <span class="n">t</span> <span class="o">-&gt;</span> <span class="nn">Py</span><span class="p">.</span><span class="nn">Object</span><span class="p">.</span><span class="n">t</span>
<span class="k">val</span> <span class="n">figure_opt</span> <span class="o">:</span> <span class="n">t</span> <span class="o">-&gt;</span> <span class="o">(</span><span class="nn">Py</span><span class="p">.</span><span class="nn">Object</span><span class="p">.</span><span class="n">t</span><span class="o">)</span> <span class="n">option</span>
</code></pre></div>

<p>This attribute is documented in <code>create</code> above. The first version raises Not_found
if the attribute is None. The _opt version returns an option.</p>
</details>
<h3 id="to_string_1">to_string<a class="headerlink" href="#to_string_1" title="Permanent link">&para;</a></h3>
<details class="note" open="open"><summary>method to_string</summary><div class="highlight"><pre><span></span><code><span class="k">val</span> <span class="n">to_string</span><span class="o">:</span> <span class="n">t</span> <span class="o">-&gt;</span> <span class="kt">string</span>
</code></pre></div>

<p>Print the object to a human-readable representation.</p>
</details>
<h3 id="show_1">show<a class="headerlink" href="#show_1" title="Permanent link">&para;</a></h3>
<details class="note" open="open"><summary>method show</summary><div class="highlight"><pre><span></span><code><span class="k">val</span> <span class="n">show</span><span class="o">:</span> <span class="n">t</span> <span class="o">-&gt;</span> <span class="kt">string</span>
</code></pre></div>

<p>Print the object to a human-readable representation.</p>
</details>
<h3 id="pp_1">pp<a class="headerlink" href="#pp_1" title="Permanent link">&para;</a></h3>
<details class="note" open="open"><summary>method pp</summary><div class="highlight"><pre><span></span><code><span class="k">val</span> <span class="n">pp</span><span class="o">:</span> <span class="nn">Format</span><span class="p">.</span><span class="n">formatter</span> <span class="o">-&gt;</span> <span class="n">t</span> <span class="o">-&gt;</span> <span class="kt">unit</span>
</code></pre></div>

<p>Pretty-print the object to a formatter.</p>
</details>
<h2 id="roccurvedisplay">RocCurveDisplay<a class="headerlink" href="#roccurvedisplay" title="Permanent link">&para;</a></h2>
<p>Module <code>Sklearn.Metrics.RocCurveDisplay</code> wraps Python class <a href="https://scikit-learn.org/stable/modules/generated/sklearn.metrics.RocCurveDisplay.html"><code>sklearn.metrics.RocCurveDisplay</code></a>.</p>
<div class="highlight"><pre><span></span><code><span class="k">type</span> <span class="n">t</span>
</code></pre></div>

<h3 id="create_2">create<a class="headerlink" href="#create_2" title="Permanent link">&para;</a></h3>
<details class="note" open="open"><summary>constructor and attributes create</summary><div class="highlight"><pre><span></span><code><span class="k">val</span> <span class="n">create</span> <span class="o">:</span>
  <span class="o">?</span><span class="n">roc_auc</span><span class="o">:</span><span class="kt">float</span> <span class="o">-&gt;</span>
  <span class="o">?</span><span class="n">estimator_name</span><span class="o">:</span><span class="kt">string</span> <span class="o">-&gt;</span>
  <span class="n">fpr</span><span class="o">:[&gt;`</span><span class="nc">ArrayLike</span><span class="o">]</span> <span class="nn">Np</span><span class="p">.</span><span class="nn">Obj</span><span class="p">.</span><span class="n">t</span> <span class="o">-&gt;</span>
  <span class="n">tpr</span><span class="o">:[&gt;`</span><span class="nc">ArrayLike</span><span class="o">]</span> <span class="nn">Np</span><span class="p">.</span><span class="nn">Obj</span><span class="p">.</span><span class="n">t</span> <span class="o">-&gt;</span>
  <span class="kt">unit</span> <span class="o">-&gt;</span>
  <span class="n">t</span>
</code></pre></div>

<p>ROC Curve visualization.</p>
<p>It is recommend to use :func:<code>~sklearn.metrics.plot_roc_curve</code> to create a
visualizer. All parameters are stored as attributes.</p>
<p>Read more in the :ref:<code>User Guide &lt;visualizations&gt;</code>.</p>
<h4>Parameters</h4>
<ul>
<li>
<p><strong>fpr : ndarray</strong>
    False positive rate.</p>
</li>
<li>
<p><strong>tpr : ndarray</strong>
    True positive rate.</p>
</li>
<li>
<p><strong>roc_auc : float, default=None</strong>
    Area under ROC curve. If None, the roc_auc score is not shown.</p>
</li>
<li>
<p><strong>estimator_name : str, default=None</strong>
    Name of estimator. If None, the estimator name is not shown.</p>
</li>
</ul>
<h4>Attributes</h4>
<ul>
<li>
<p><strong>line_ : matplotlib Artist</strong>
    ROC Curve.</p>
</li>
<li>
<p><strong>ax_ : matplotlib Axes</strong>
    Axes with ROC Curve.</p>
</li>
<li>
<p><strong>figure_ : matplotlib Figure</strong>
    Figure containing the curve.</p>
</li>
</ul>
<h4>Examples</h4>
<div class="highlight"><pre><span></span><code><span class="o">&gt;&gt;&gt;</span> <span class="kn">import</span> <span class="nn">matplotlib.pyplot</span> <span class="k">as</span> <span class="nn">plt</span>  <span class="c1"># doctest: +SKIP</span>
<span class="o">&gt;&gt;&gt;</span> <span class="kn">import</span> <span class="nn">numpy</span> <span class="k">as</span> <span class="nn">np</span>
<span class="o">&gt;&gt;&gt;</span> <span class="kn">from</span> <span class="nn">sklearn</span> <span class="kn">import</span> <span class="n">metrics</span>
<span class="o">&gt;&gt;&gt;</span> <span class="n">y</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">array</span><span class="p">([</span><span class="mi">0</span><span class="p">,</span> <span class="mi">0</span><span class="p">,</span> <span class="mi">1</span><span class="p">,</span> <span class="mi">1</span><span class="p">])</span>
<span class="o">&gt;&gt;&gt;</span> <span class="n">pred</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">array</span><span class="p">([</span><span class="mf">0.1</span><span class="p">,</span> <span class="mf">0.4</span><span class="p">,</span> <span class="mf">0.35</span><span class="p">,</span> <span class="mf">0.8</span><span class="p">])</span>
<span class="o">&gt;&gt;&gt;</span> <span class="n">fpr</span><span class="p">,</span> <span class="n">tpr</span><span class="p">,</span> <span class="n">thresholds</span> <span class="o">=</span> <span class="n">metrics</span><span class="o">.</span><span class="n">roc_curve</span><span class="p">(</span><span class="n">y</span><span class="p">,</span> <span class="n">pred</span><span class="p">)</span>
<span class="o">&gt;&gt;&gt;</span> <span class="n">roc_auc</span> <span class="o">=</span> <span class="n">metrics</span><span class="o">.</span><span class="n">auc</span><span class="p">(</span><span class="n">fpr</span><span class="p">,</span> <span class="n">tpr</span><span class="p">)</span>
<span class="o">&gt;&gt;&gt;</span> <span class="n">display</span> <span class="o">=</span> <span class="n">metrics</span><span class="o">.</span><span class="n">RocCurveDisplay</span><span class="p">(</span><span class="n">fpr</span><span class="o">=</span><span class="n">fpr</span><span class="p">,</span> <span class="n">tpr</span><span class="o">=</span><span class="n">tpr</span><span class="p">,</span> <span class="n">roc_auc</span><span class="o">=</span><span class="n">roc_auc</span><span class="p">,</span>                                          <span class="n">estimator_name</span><span class="o">=</span><span class="s1">&#39;example estimator&#39;</span><span class="p">)</span>
<span class="o">&gt;&gt;&gt;</span> <span class="n">display</span><span class="o">.</span><span class="n">plot</span><span class="p">()</span>  <span class="c1"># doctest: +SKIP</span>
<span class="o">&gt;&gt;&gt;</span> <span class="n">plt</span><span class="o">.</span><span class="n">show</span><span class="p">()</span>      <span class="c1"># doctest: +SKIP</span>
</code></pre></div>

</details>
<h3 id="plot_2">plot<a class="headerlink" href="#plot_2" title="Permanent link">&para;</a></h3>
<details class="note" open="open"><summary>method plot</summary><div class="highlight"><pre><span></span><code><span class="k">val</span> <span class="n">plot</span> <span class="o">:</span>
  <span class="o">?</span><span class="n">ax</span><span class="o">:</span><span class="nn">Py</span><span class="p">.</span><span class="nn">Object</span><span class="p">.</span><span class="n">t</span> <span class="o">-&gt;</span>
  <span class="o">?</span><span class="n">name</span><span class="o">:</span><span class="kt">string</span> <span class="o">-&gt;</span>
  <span class="o">?</span><span class="n">kwargs</span><span class="o">:(</span><span class="kt">string</span> <span class="o">*</span> <span class="nn">Py</span><span class="p">.</span><span class="nn">Object</span><span class="p">.</span><span class="n">t</span><span class="o">)</span> <span class="kt">list</span> <span class="o">-&gt;</span>
  <span class="o">[&gt;</span> <span class="n">tag</span><span class="o">]</span> <span class="nn">Obj</span><span class="p">.</span><span class="n">t</span> <span class="o">-&gt;</span>
  <span class="nn">Py</span><span class="p">.</span><span class="nn">Object</span><span class="p">.</span><span class="n">t</span>
</code></pre></div>

<p>Plot visualization</p>
<p>Extra keyword arguments will be passed to matplotlib's <code>plot</code>.</p>
<h4>Parameters</h4>
<ul>
<li>
<p><strong>ax : matplotlib axes, default=None</strong>
    Axes object to plot on. If <code>None</code>, a new figure and axes is
    created.</p>
</li>
<li>
<p><strong>name : str, default=None</strong>
    Name of ROC Curve for labeling. If <code>None</code>, use the name of the
    estimator.</p>
</li>
</ul>
<h4>Returns</h4>
<ul>
<li><strong>display : :class:<code>~sklearn.metrics.plot.RocCurveDisplay</code></strong>
    Object that stores computed values.</li>
</ul>
</details>
<h3 id="line__1">line_<a class="headerlink" href="#line__1" title="Permanent link">&para;</a></h3>
<details class="note" open="open"><summary>attribute line_</summary><div class="highlight"><pre><span></span><code><span class="k">val</span> <span class="n">line_</span> <span class="o">:</span> <span class="n">t</span> <span class="o">-&gt;</span> <span class="nn">Py</span><span class="p">.</span><span class="nn">Object</span><span class="p">.</span><span class="n">t</span>
<span class="k">val</span> <span class="n">line_opt</span> <span class="o">:</span> <span class="n">t</span> <span class="o">-&gt;</span> <span class="o">(</span><span class="nn">Py</span><span class="p">.</span><span class="nn">Object</span><span class="p">.</span><span class="n">t</span><span class="o">)</span> <span class="n">option</span>
</code></pre></div>

<p>This attribute is documented in <code>create</code> above. The first version raises Not_found
if the attribute is None. The _opt version returns an option.</p>
</details>
<h3 id="ax__2">ax_<a class="headerlink" href="#ax__2" title="Permanent link">&para;</a></h3>
<details class="note" open="open"><summary>attribute ax_</summary><div class="highlight"><pre><span></span><code><span class="k">val</span> <span class="n">ax_</span> <span class="o">:</span> <span class="n">t</span> <span class="o">-&gt;</span> <span class="nn">Py</span><span class="p">.</span><span class="nn">Object</span><span class="p">.</span><span class="n">t</span>
<span class="k">val</span> <span class="n">ax_opt</span> <span class="o">:</span> <span class="n">t</span> <span class="o">-&gt;</span> <span class="o">(</span><span class="nn">Py</span><span class="p">.</span><span class="nn">Object</span><span class="p">.</span><span class="n">t</span><span class="o">)</span> <span class="n">option</span>
</code></pre></div>

<p>This attribute is documented in <code>create</code> above. The first version raises Not_found
if the attribute is None. The _opt version returns an option.</p>
</details>
<h3 id="figure__2">figure_<a class="headerlink" href="#figure__2" title="Permanent link">&para;</a></h3>
<details class="note" open="open"><summary>attribute figure_</summary><div class="highlight"><pre><span></span><code><span class="k">val</span> <span class="n">figure_</span> <span class="o">:</span> <span class="n">t</span> <span class="o">-&gt;</span> <span class="nn">Py</span><span class="p">.</span><span class="nn">Object</span><span class="p">.</span><span class="n">t</span>
<span class="k">val</span> <span class="n">figure_opt</span> <span class="o">:</span> <span class="n">t</span> <span class="o">-&gt;</span> <span class="o">(</span><span class="nn">Py</span><span class="p">.</span><span class="nn">Object</span><span class="p">.</span><span class="n">t</span><span class="o">)</span> <span class="n">option</span>
</code></pre></div>

<p>This attribute is documented in <code>create</code> above. The first version raises Not_found
if the attribute is None. The _opt version returns an option.</p>
</details>
<h3 id="to_string_2">to_string<a class="headerlink" href="#to_string_2" title="Permanent link">&para;</a></h3>
<details class="note" open="open"><summary>method to_string</summary><div class="highlight"><pre><span></span><code><span class="k">val</span> <span class="n">to_string</span><span class="o">:</span> <span class="n">t</span> <span class="o">-&gt;</span> <span class="kt">string</span>
</code></pre></div>

<p>Print the object to a human-readable representation.</p>
</details>
<h3 id="show_2">show<a class="headerlink" href="#show_2" title="Permanent link">&para;</a></h3>
<details class="note" open="open"><summary>method show</summary><div class="highlight"><pre><span></span><code><span class="k">val</span> <span class="n">show</span><span class="o">:</span> <span class="n">t</span> <span class="o">-&gt;</span> <span class="kt">string</span>
</code></pre></div>

<p>Print the object to a human-readable representation.</p>
</details>
<h3 id="pp_2">pp<a class="headerlink" href="#pp_2" title="Permanent link">&para;</a></h3>
<details class="note" open="open"><summary>method pp</summary><div class="highlight"><pre><span></span><code><span class="k">val</span> <span class="n">pp</span><span class="o">:</span> <span class="nn">Format</span><span class="p">.</span><span class="n">formatter</span> <span class="o">-&gt;</span> <span class="n">t</span> <span class="o">-&gt;</span> <span class="kt">unit</span>
</code></pre></div>

<p>Pretty-print the object to a formatter.</p>
</details>
<h2 id="cluster">Cluster<a class="headerlink" href="#cluster" title="Permanent link">&para;</a></h2>
<p>Module <code>Sklearn.Metrics.Cluster</code> wraps Python module <code>sklearn.metrics.cluster</code>.</p>
<h3 id="adjusted_mutual_info_score">adjusted_mutual_info_score<a class="headerlink" href="#adjusted_mutual_info_score" title="Permanent link">&para;</a></h3>
<details class="note" open="open"><summary>function adjusted_mutual_info_score</summary><div class="highlight"><pre><span></span><code><span class="k">val</span> <span class="n">adjusted_mutual_info_score</span> <span class="o">:</span>
  <span class="o">?</span><span class="n">average_method</span><span class="o">:</span><span class="kt">string</span> <span class="o">-&gt;</span>
  <span class="n">labels_true</span><span class="o">:[&gt;`</span><span class="nc">ArrayLike</span><span class="o">]</span> <span class="nn">Np</span><span class="p">.</span><span class="nn">Obj</span><span class="p">.</span><span class="n">t</span> <span class="o">-&gt;</span>
  <span class="n">labels_pred</span><span class="o">:[&gt;`</span><span class="nc">ArrayLike</span><span class="o">]</span> <span class="nn">Np</span><span class="p">.</span><span class="nn">Obj</span><span class="p">.</span><span class="n">t</span> <span class="o">-&gt;</span>
  <span class="kt">unit</span> <span class="o">-&gt;</span>
  <span class="kt">float</span>
</code></pre></div>

<p>Adjusted Mutual Information between two clusterings.</p>
<p>Adjusted Mutual Information (AMI) is an adjustment of the Mutual
Information (MI) score to account for chance. It accounts for the fact that
the MI is generally higher for two clusterings with a larger number of
clusters, regardless of whether there is actually more information shared.
For two clusterings :math:<code>U</code> and :math:<code>V</code>, the AMI is given as::</p>
<div class="codehilite"><pre><span></span><code>AMI(U, V) = [MI(U, V) - E(MI(U, V))] / [avg(H(U), H(V)) - E(MI(U, V))]
</code></pre></div>


<p>This metric is independent of the absolute values of the labels:
a permutation of the class or cluster label values won't change the
score value in any way.</p>
<p>This metric is furthermore symmetric: switching <code>label_true</code> with
<code>label_pred</code> will return the same score value. This can be useful to
measure the agreement of two independent label assignments strategies
on the same dataset when the real ground truth is not known.</p>
<p>Be mindful that this function is an order of magnitude slower than other
metrics, such as the Adjusted Rand Index.</p>
<p>Read more in the :ref:<code>User Guide &lt;mutual_info_score&gt;</code>.</p>
<h4>Parameters</h4>
<ul>
<li>
<p><strong>labels_true : int array, shape = [n_samples]</strong>
    A clustering of the data into disjoint subsets.</p>
</li>
<li>
<p><strong>labels_pred : int array-like of shape (n_samples,)</strong>
    A clustering of the data into disjoint subsets.</p>
</li>
<li>
<p><strong>average_method : string, optional (default: 'arithmetic')</strong>
    How to compute the normalizer in the denominator. Possible options
    are 'min', 'geometric', 'arithmetic', and 'max'.</p>
<p>.. versionadded:: 0.20</p>
<p>.. versionchanged:: 0.22
   The default value of <code>average_method</code> changed from 'max' to
   'arithmetic'.</p>
</li>
</ul>
<h4>Returns</h4>
<ul>
<li><strong>ami: float (upperlimited by 1.0)</strong>
   The AMI returns a value of 1 when the two partitions are identical
   (ie perfectly matched). Random partitions (independent labellings) have
   an expected AMI around 0 on average hence can be negative.</li>
</ul>
<h4>See also</h4>
<ul>
<li>
<p><strong>adjusted_rand_score: Adjusted Rand Index</strong></p>
</li>
<li>
<p><strong>mutual_info_score: Mutual Information (not adjusted for chance)</strong></p>
</li>
</ul>
<h4>Examples</h4>
<p>Perfect labelings are both homogeneous and complete, hence have
score 1.0::</p>
<blockquote>
<blockquote>
<blockquote>
<p>from sklearn.metrics.cluster import adjusted_mutual_info_score
adjusted_mutual_info_score([0, 0, 1, 1], [0, 0, 1, 1])
  ... # doctest: +SKIP
  1.0
adjusted_mutual_info_score([0, 0, 1, 1], [1, 1, 0, 0])
  ... # doctest: +SKIP
  1.0</p>
</blockquote>
</blockquote>
</blockquote>
<p>If classes members are completely split across different clusters,
the assignment is totally in-complete, hence the AMI is null::</p>
<blockquote>
<blockquote>
<blockquote>
<p>adjusted_mutual_info_score([0, 0, 0, 0], [0, 1, 2, 3])
  ... # doctest: +SKIP
  0.0</p>
</blockquote>
</blockquote>
</blockquote>
<h4>References</h4>
<p>.. [1] <code>Vinh, Epps, and Bailey, (2010). Information Theoretic Measures for
   Clusterings Comparison: Variants, Properties, Normalization and
   Correction for Chance, JMLR
   &lt;http://jmlr.csail.mit.edu/papers/volume11/vinh10a/vinh10a.pdf&gt;</code>_</p>
<p>.. [2] <code>Wikipedia entry for the Adjusted Mutual Information
   &lt;https://en.wikipedia.org/wiki/Adjusted_Mutual_Information&gt;</code>_</p>
</details>
<h3 id="adjusted_rand_score">adjusted_rand_score<a class="headerlink" href="#adjusted_rand_score" title="Permanent link">&para;</a></h3>
<details class="note" open="open"><summary>function adjusted_rand_score</summary><div class="highlight"><pre><span></span><code><span class="k">val</span> <span class="n">adjusted_rand_score</span> <span class="o">:</span>
  <span class="n">labels_true</span><span class="o">:[&gt;`</span><span class="nc">ArrayLike</span><span class="o">]</span> <span class="nn">Np</span><span class="p">.</span><span class="nn">Obj</span><span class="p">.</span><span class="n">t</span> <span class="o">-&gt;</span>
  <span class="n">labels_pred</span><span class="o">:[&gt;`</span><span class="nc">ArrayLike</span><span class="o">]</span> <span class="nn">Np</span><span class="p">.</span><span class="nn">Obj</span><span class="p">.</span><span class="n">t</span> <span class="o">-&gt;</span>
  <span class="kt">unit</span> <span class="o">-&gt;</span>
  <span class="kt">float</span>
</code></pre></div>

<p>Rand index adjusted for chance.</p>
<p>The Rand Index computes a similarity measure between two clusterings
by considering all pairs of samples and counting pairs that are
assigned in the same or different clusters in the predicted and
true clusterings.</p>
<p>The raw RI score is then 'adjusted for chance' into the ARI score
using the following scheme::</p>
<div class="codehilite"><pre><span></span><code>ARI = (RI - Expected_RI) / (max(RI) - Expected_RI)
</code></pre></div>


<p>The adjusted Rand index is thus ensured to have a value close to
0.0 for random labeling independently of the number of clusters and
samples and exactly 1.0 when the clusterings are identical (up to
a permutation).</p>
<p>ARI is a symmetric measure::</p>
<div class="codehilite"><pre><span></span><code>adjusted_rand_score(a, b) == adjusted_rand_score(b, a)
</code></pre></div>


<p>Read more in the :ref:<code>User Guide &lt;adjusted_rand_score&gt;</code>.</p>
<h4>Parameters</h4>
<ul>
<li>
<p><strong>labels_true : int array, shape = [n_samples]</strong>
    Ground truth class labels to be used as a reference</p>
</li>
<li>
<p><strong>labels_pred : array-like of shape (n_samples,)</strong>
    Cluster labels to evaluate</p>
</li>
</ul>
<h4>Returns</h4>
<ul>
<li><strong>ari : float</strong>
   Similarity score between -1.0 and 1.0. Random labelings have an ARI
   close to 0.0. 1.0 stands for perfect match.</li>
</ul>
<h4>Examples</h4>
<p>Perfectly matching labelings have a score of 1 even</p>
<blockquote>
<blockquote>
<blockquote>
<p>from sklearn.metrics.cluster import adjusted_rand_score
adjusted_rand_score([0, 0, 1, 1], [0, 0, 1, 1])
  1.0
adjusted_rand_score([0, 0, 1, 1], [1, 1, 0, 0])
  1.0</p>
</blockquote>
</blockquote>
</blockquote>
<p>Labelings that assign all classes members to the same clusters
are complete be not always pure, hence penalized::</p>
<blockquote>
<blockquote>
<blockquote>
<p>adjusted_rand_score([0, 0, 1, 2], [0, 0, 1, 1])
  0.57...</p>
</blockquote>
</blockquote>
</blockquote>
<p>ARI is symmetric, so labelings that have pure clusters with members
coming from the same classes but unnecessary splits are penalized::</p>
<blockquote>
<blockquote>
<blockquote>
<p>adjusted_rand_score([0, 0, 1, 1], [0, 0, 1, 2])
  0.57...</p>
</blockquote>
</blockquote>
</blockquote>
<p>If classes members are completely split across different clusters, the
assignment is totally incomplete, hence the ARI is very low::</p>
<blockquote>
<blockquote>
<blockquote>
<p>adjusted_rand_score([0, 0, 0, 0], [0, 1, 2, 3])
  0.0</p>
</blockquote>
</blockquote>
</blockquote>
<h4>References</h4>
<p>.. [Hubert1985] L. Hubert and P. Arabie, Comparing Partitions,
  Journal of Classification 1985</p>
<ul>
<li><strong>https://link.springer.com/article/10.1007%2FBF01908075</strong></li>
</ul>
<p>.. [wk] https://en.wikipedia.org/wiki/Rand_index#Adjusted_Rand_index</p>
<h4>See also</h4>
<ul>
<li><strong>adjusted_mutual_info_score: Adjusted Mutual Information</strong></li>
</ul>
</details>
<h3 id="calinski_harabasz_score">calinski_harabasz_score<a class="headerlink" href="#calinski_harabasz_score" title="Permanent link">&para;</a></h3>
<details class="note" open="open"><summary>function calinski_harabasz_score</summary><div class="highlight"><pre><span></span><code><span class="k">val</span> <span class="n">calinski_harabasz_score</span> <span class="o">:</span>
  <span class="n">x</span><span class="o">:[&gt;`</span><span class="nc">ArrayLike</span><span class="o">]</span> <span class="nn">Np</span><span class="p">.</span><span class="nn">Obj</span><span class="p">.</span><span class="n">t</span> <span class="o">-&gt;</span>
  <span class="n">labels</span><span class="o">:[&gt;`</span><span class="nc">ArrayLike</span><span class="o">]</span> <span class="nn">Np</span><span class="p">.</span><span class="nn">Obj</span><span class="p">.</span><span class="n">t</span> <span class="o">-&gt;</span>
  <span class="kt">unit</span> <span class="o">-&gt;</span>
  <span class="kt">float</span>
</code></pre></div>

<p>Compute the Calinski and Harabasz score.</p>
<p>It is also known as the Variance Ratio Criterion.</p>
<p>The score is defined as ratio between the within-cluster dispersion and
the between-cluster dispersion.</p>
<p>Read more in the :ref:<code>User Guide &lt;calinski_harabasz_index&gt;</code>.</p>
<h4>Parameters</h4>
<ul>
<li>
<p><strong>X : array-like, shape (<code>n_samples</code>, <code>n_features</code>)</strong>
    List of <code>n_features</code>-dimensional data points. Each row corresponds
    to a single data point.</p>
</li>
<li>
<p><strong>labels : array-like, shape (<code>n_samples</code>,)</strong>
    Predicted labels for each sample.</p>
</li>
</ul>
<h4>Returns</h4>
<ul>
<li><strong>score : float</strong>
    The resulting Calinski-Harabasz score.</li>
</ul>
<h4>References</h4>
<p>.. [1] <code>T. Calinski and J. Harabasz, 1974. 'A dendrite method for cluster
   analysis'. Communications in Statistics
   &lt;https://www.tandfonline.com/doi/abs/10.1080/03610927408827101&gt;</code>_</p>
</details>
<h3 id="completeness_score">completeness_score<a class="headerlink" href="#completeness_score" title="Permanent link">&para;</a></h3>
<details class="note" open="open"><summary>function completeness_score</summary><div class="highlight"><pre><span></span><code><span class="k">val</span> <span class="n">completeness_score</span> <span class="o">:</span>
  <span class="n">labels_true</span><span class="o">:[&gt;`</span><span class="nc">ArrayLike</span><span class="o">]</span> <span class="nn">Np</span><span class="p">.</span><span class="nn">Obj</span><span class="p">.</span><span class="n">t</span> <span class="o">-&gt;</span>
  <span class="n">labels_pred</span><span class="o">:[&gt;`</span><span class="nc">ArrayLike</span><span class="o">]</span> <span class="nn">Np</span><span class="p">.</span><span class="nn">Obj</span><span class="p">.</span><span class="n">t</span> <span class="o">-&gt;</span>
  <span class="kt">unit</span> <span class="o">-&gt;</span>
  <span class="kt">float</span>
</code></pre></div>

<p>Completeness metric of a cluster labeling given a ground truth.</p>
<p>A clustering result satisfies completeness if all the data points
that are members of a given class are elements of the same cluster.</p>
<p>This metric is independent of the absolute values of the labels:
a permutation of the class or cluster label values won't change the
score value in any way.</p>
<p>This metric is not symmetric: switching <code>label_true</code> with <code>label_pred</code>
will return the :func:<code>homogeneity_score</code> which will be different in
general.</p>
<p>Read more in the :ref:<code>User Guide &lt;homogeneity_completeness&gt;</code>.</p>
<h4>Parameters</h4>
<ul>
<li>
<p><strong>labels_true : int array, shape = [n_samples]</strong>
    ground truth class labels to be used as a reference</p>
</li>
<li>
<p><strong>labels_pred : array-like of shape (n_samples,)</strong>
    cluster labels to evaluate</p>
</li>
</ul>
<h4>Returns</h4>
<ul>
<li><strong>completeness : float</strong>
   score between 0.0 and 1.0. 1.0 stands for perfectly complete labeling</li>
</ul>
<h4>References</h4>
<p>.. [1] <code>Andrew Rosenberg and Julia Hirschberg, 2007. V-Measure: A
   conditional entropy-based external cluster evaluation measure
   &lt;https://aclweb.org/anthology/D/D07/D07-1043.pdf&gt;</code>_</p>
<h4>See also</h4>
<p>homogeneity_score
v_measure_score</p>
<h4>Examples</h4>
<p>Perfect labelings are complete::</p>
<blockquote>
<blockquote>
<blockquote>
<p>from sklearn.metrics.cluster import completeness_score
completeness_score([0, 0, 1, 1], [1, 1, 0, 0])
  1.0</p>
</blockquote>
</blockquote>
</blockquote>
<p>Non-perfect labelings that assign all classes members to the same clusters
are still complete::</p>
<blockquote>
<blockquote>
<blockquote>
<p>print(completeness_score([0, 0, 1, 1], [0, 0, 0, 0]))
  1.0
print(completeness_score([0, 1, 2, 3], [0, 0, 1, 1]))
  0.999...</p>
</blockquote>
</blockquote>
</blockquote>
<p>If classes members are split across different clusters, the
assignment cannot be complete::</p>
<blockquote>
<blockquote>
<blockquote>
<p>print(completeness_score([0, 0, 1, 1], [0, 1, 0, 1]))
  0.0
print(completeness_score([0, 0, 0, 0], [0, 1, 2, 3]))
  0.0</p>
</blockquote>
</blockquote>
</blockquote>
</details>
<h3 id="consensus_score">consensus_score<a class="headerlink" href="#consensus_score" title="Permanent link">&para;</a></h3>
<details class="note" open="open"><summary>function consensus_score</summary><div class="highlight"><pre><span></span><code><span class="k">val</span> <span class="n">consensus_score</span> <span class="o">:</span>
  <span class="o">?</span><span class="n">similarity</span><span class="o">:[`</span><span class="nc">S</span> <span class="k">of</span> <span class="kt">string</span> <span class="o">|</span> <span class="o">`</span><span class="nc">Callable</span> <span class="k">of</span> <span class="nn">Py</span><span class="p">.</span><span class="nn">Object</span><span class="p">.</span><span class="n">t</span><span class="o">]</span> <span class="o">-&gt;</span>
  <span class="n">a</span><span class="o">:</span><span class="nn">Py</span><span class="p">.</span><span class="nn">Object</span><span class="p">.</span><span class="n">t</span> <span class="o">-&gt;</span>
  <span class="n">b</span><span class="o">:</span><span class="nn">Py</span><span class="p">.</span><span class="nn">Object</span><span class="p">.</span><span class="n">t</span> <span class="o">-&gt;</span>
  <span class="kt">unit</span> <span class="o">-&gt;</span>
  <span class="nn">Py</span><span class="p">.</span><span class="nn">Object</span><span class="p">.</span><span class="n">t</span>
</code></pre></div>

<p>The similarity of two sets of biclusters.</p>
<p>Similarity between individual biclusters is computed. Then the
best matching between sets is found using the Hungarian algorithm.
The final score is the sum of similarities divided by the size of
the larger set.</p>
<p>Read more in the :ref:<code>User Guide &lt;biclustering&gt;</code>.</p>
<h4>Parameters</h4>
<ul>
<li>
<p><strong>a : (rows, columns)</strong>
    Tuple of row and column indicators for a set of biclusters.</p>
</li>
<li>
<p><strong>b : (rows, columns)</strong>
    Another set of biclusters like <code>a</code>.</p>
</li>
<li>
<p><strong>similarity : string or function, optional, default: 'jaccard'</strong>
    May be the string 'jaccard' to use the Jaccard coefficient, or
    any function that takes four arguments, each of which is a 1d
    indicator vector: (a_rows, a_columns, b_rows, b_columns).</p>
</li>
</ul>
<h4>References</h4>
<ul>
<li>Hochreiter, Bodenhofer, et. al., 2010. <code>FABIA: factor analysis
  for bicluster acquisition
  &lt;https://www.ncbi.nlm.nih.gov/pmc/articles/PMC2881408/&gt;</code>__.</li>
</ul>
</details>
<h3 id="contingency_matrix">contingency_matrix<a class="headerlink" href="#contingency_matrix" title="Permanent link">&para;</a></h3>
<details class="note" open="open"><summary>function contingency_matrix</summary><div class="highlight"><pre><span></span><code><span class="k">val</span> <span class="n">contingency_matrix</span> <span class="o">:</span>
  <span class="o">?</span><span class="n">eps</span><span class="o">:</span><span class="kt">float</span> <span class="o">-&gt;</span>
  <span class="o">?</span><span class="n">sparse</span><span class="o">:</span><span class="kt">bool</span> <span class="o">-&gt;</span>
  <span class="n">labels_true</span><span class="o">:[&gt;`</span><span class="nc">ArrayLike</span><span class="o">]</span> <span class="nn">Np</span><span class="p">.</span><span class="nn">Obj</span><span class="p">.</span><span class="n">t</span> <span class="o">-&gt;</span>
  <span class="n">labels_pred</span><span class="o">:[&gt;`</span><span class="nc">ArrayLike</span><span class="o">]</span> <span class="nn">Np</span><span class="p">.</span><span class="nn">Obj</span><span class="p">.</span><span class="n">t</span> <span class="o">-&gt;</span>
  <span class="kt">unit</span> <span class="o">-&gt;</span>
  <span class="nn">Py</span><span class="p">.</span><span class="nn">Object</span><span class="p">.</span><span class="n">t</span>
</code></pre></div>

<p>Build a contingency matrix describing the relationship between labels.</p>
<h4>Parameters</h4>
<ul>
<li>
<p><strong>labels_true : int array, shape = [n_samples]</strong>
    Ground truth class labels to be used as a reference</p>
</li>
<li>
<p><strong>labels_pred : array-like of shape (n_samples,)</strong>
    Cluster labels to evaluate</p>
</li>
<li>
<p><strong>eps : None or float, optional.</strong>
    If a float, that value is added to all values in the contingency
    matrix. This helps to stop NaN propagation.
    If <code>None</code>, nothing is adjusted.</p>
</li>
<li>
<p><strong>sparse : boolean, optional.</strong>
    If True, return a sparse CSR continency matrix. If <code>eps is not None</code>,
    and <code>sparse is True</code>, will throw ValueError.</p>
<p>.. versionadded:: 0.18</p>
</li>
</ul>
<h4>Returns</h4>
<ul>
<li>
<p><strong>contingency : {array-like, sparse}, shape=[n_classes_true, n_classes_pred]</strong></p>
</li>
<li>
<p><strong>Matrix :math:<code>C</code> such that :math:<code>C_{i, j}</code> is the number of samples in</strong>
    true class :math:<code>i</code> and in predicted class :math:<code>j</code>. If
    <code>eps is None</code>, the dtype of this array will be integer. If <code>eps</code> is
    given, the dtype will be float.
    Will be a <code>scipy.sparse.csr_matrix</code> if <code>sparse=True</code>.</p>
</li>
</ul>
</details>
<h3 id="davies_bouldin_score">davies_bouldin_score<a class="headerlink" href="#davies_bouldin_score" title="Permanent link">&para;</a></h3>
<details class="note" open="open"><summary>function davies_bouldin_score</summary><div class="highlight"><pre><span></span><code><span class="k">val</span> <span class="n">davies_bouldin_score</span> <span class="o">:</span>
  <span class="n">x</span><span class="o">:[&gt;`</span><span class="nc">ArrayLike</span><span class="o">]</span> <span class="nn">Np</span><span class="p">.</span><span class="nn">Obj</span><span class="p">.</span><span class="n">t</span> <span class="o">-&gt;</span>
  <span class="n">labels</span><span class="o">:[&gt;`</span><span class="nc">ArrayLike</span><span class="o">]</span> <span class="nn">Np</span><span class="p">.</span><span class="nn">Obj</span><span class="p">.</span><span class="n">t</span> <span class="o">-&gt;</span>
  <span class="kt">unit</span> <span class="o">-&gt;</span>
  <span class="kt">float</span>
</code></pre></div>

<p>Computes the Davies-Bouldin score.</p>
<p>The score is defined as the average similarity measure of each cluster with
its most similar cluster, where similarity is the ratio of within-cluster
distances to between-cluster distances. Thus, clusters which are farther
apart and less dispersed will result in a better score.</p>
<p>The minimum score is zero, with lower values indicating better clustering.</p>
<p>Read more in the :ref:<code>User Guide &lt;davies-bouldin_index&gt;</code>.</p>
<p>.. versionadded:: 0.20</p>
<h4>Parameters</h4>
<ul>
<li>
<p><strong>X : array-like, shape (<code>n_samples</code>, <code>n_features</code>)</strong>
    List of <code>n_features</code>-dimensional data points. Each row corresponds
    to a single data point.</p>
</li>
<li>
<p><strong>labels : array-like, shape (<code>n_samples</code>,)</strong>
    Predicted labels for each sample.</p>
</li>
</ul>
<h4>Returns</h4>
<ul>
<li><strong>score: float</strong>
    The resulting Davies-Bouldin score.</li>
</ul>
<h4>References</h4>
<p>.. [1] Davies, David L.; Bouldin, Donald W. (1979).
   <code>'A Cluster Separation Measure'
   &lt;https://ieeexplore.ieee.org/document/4766909&gt;</code>__.
   IEEE Transactions on Pattern Analysis and Machine Intelligence.
   PAMI-1 (2): 224-227</p>
</details>
<h3 id="entropy">entropy<a class="headerlink" href="#entropy" title="Permanent link">&para;</a></h3>
<details class="note" open="open"><summary>function entropy</summary><div class="highlight"><pre><span></span><code><span class="k">val</span> <span class="n">entropy</span> <span class="o">:</span>
  <span class="o">[&gt;`</span><span class="nc">ArrayLike</span><span class="o">]</span> <span class="nn">Np</span><span class="p">.</span><span class="nn">Obj</span><span class="p">.</span><span class="n">t</span> <span class="o">-&gt;</span>
  <span class="nn">Py</span><span class="p">.</span><span class="nn">Object</span><span class="p">.</span><span class="n">t</span>
</code></pre></div>

<p>Calculates the entropy for a labeling.</p>
<h4>Parameters</h4>
<ul>
<li><strong>labels : int array, shape = [n_samples]</strong>
    The labels</li>
</ul>
<h4>Notes</h4>
<p>The logarithm used is the natural logarithm (base-e).</p>
</details>
<h3 id="fowlkes_mallows_score">fowlkes_mallows_score<a class="headerlink" href="#fowlkes_mallows_score" title="Permanent link">&para;</a></h3>
<details class="note" open="open"><summary>function fowlkes_mallows_score</summary><div class="highlight"><pre><span></span><code><span class="k">val</span> <span class="n">fowlkes_mallows_score</span> <span class="o">:</span>
  <span class="o">?</span><span class="n">sparse</span><span class="o">:</span><span class="kt">bool</span> <span class="o">-&gt;</span>
  <span class="n">labels_true</span><span class="o">:[&gt;`</span><span class="nc">ArrayLike</span><span class="o">]</span> <span class="nn">Np</span><span class="p">.</span><span class="nn">Obj</span><span class="p">.</span><span class="n">t</span> <span class="o">-&gt;</span>
  <span class="n">labels_pred</span><span class="o">:[&gt;`</span><span class="nc">ArrayLike</span><span class="o">]</span> <span class="nn">Np</span><span class="p">.</span><span class="nn">Obj</span><span class="p">.</span><span class="n">t</span> <span class="o">-&gt;</span>
  <span class="kt">unit</span> <span class="o">-&gt;</span>
  <span class="kt">float</span>
</code></pre></div>

<p>Measure the similarity of two clusterings of a set of points.</p>
<p>.. versionadded:: 0.18</p>
<p>The Fowlkes-Mallows index (FMI) is defined as the geometric mean between of
the precision and recall::</p>
<div class="codehilite"><pre><span></span><code>FMI = TP / sqrt((TP + FP) * (TP + FN))
</code></pre></div>


<p>Where <code>TP</code> is the number of <strong>True Positive</strong> (i.e. the number of pair of
points that belongs in the same clusters in both <code>labels_true</code> and
<code>labels_pred</code>), <code>FP</code> is the number of <strong>False Positive</strong> (i.e. the
number of pair of points that belongs in the same clusters in
<code>labels_true</code> and not in <code>labels_pred</code>) and <code>FN</code> is the number of
<strong>False Negative</strong> (i.e the number of pair of points that belongs in the
same clusters in <code>labels_pred</code> and not in <code>labels_True</code>).</p>
<p>The score ranges from 0 to 1. A high value indicates a good similarity
between two clusters.</p>
<p>Read more in the :ref:<code>User Guide &lt;fowlkes_mallows_scores&gt;</code>.</p>
<h4>Parameters</h4>
<ul>
<li>
<p><strong>labels_true : int array, shape = (<code>n_samples</code>,)</strong>
    A clustering of the data into disjoint subsets.</p>
</li>
<li>
<p><strong>labels_pred : array, shape = (<code>n_samples</code>, )</strong>
    A clustering of the data into disjoint subsets.</p>
</li>
<li>
<p><strong>sparse : bool</strong>
    Compute contingency matrix internally with sparse matrix.</p>
</li>
</ul>
<h4>Returns</h4>
<ul>
<li><strong>score : float</strong>
   The resulting Fowlkes-Mallows score.</li>
</ul>
<h4>Examples</h4>
<p>Perfect labelings are both homogeneous and complete, hence have
score 1.0::</p>
<blockquote>
<blockquote>
<blockquote>
<p>from sklearn.metrics.cluster import fowlkes_mallows_score
fowlkes_mallows_score([0, 0, 1, 1], [0, 0, 1, 1])
  1.0
fowlkes_mallows_score([0, 0, 1, 1], [1, 1, 0, 0])
  1.0</p>
</blockquote>
</blockquote>
</blockquote>
<p>If classes members are completely split across different clusters,
the assignment is totally random, hence the FMI is null::</p>
<blockquote>
<blockquote>
<blockquote>
<p>fowlkes_mallows_score([0, 0, 0, 0], [0, 1, 2, 3])
  0.0</p>
</blockquote>
</blockquote>
</blockquote>
<h4>References</h4>
<p>.. [1] <code>E. B. Fowkles and C. L. Mallows, 1983. 'A method for comparing two
   hierarchical clusterings'. Journal of the American Statistical
   Association
   &lt;http://wildfire.stat.ucla.edu/pdflibrary/fowlkes.pdf&gt;</code>_</p>
<p>.. [2] <code>Wikipedia entry for the Fowlkes-Mallows Index
       &lt;https://en.wikipedia.org/wiki/Fowlkes-Mallows_index&gt;</code>_</p>
</details>
<h3 id="homogeneity_completeness_v_measure">homogeneity_completeness_v_measure<a class="headerlink" href="#homogeneity_completeness_v_measure" title="Permanent link">&para;</a></h3>
<details class="note" open="open"><summary>function homogeneity_completeness_v_measure</summary><div class="highlight"><pre><span></span><code><span class="k">val</span> <span class="n">homogeneity_completeness_v_measure</span> <span class="o">:</span>
  <span class="o">?</span><span class="n">beta</span><span class="o">:</span><span class="kt">float</span> <span class="o">-&gt;</span>
  <span class="n">labels_true</span><span class="o">:[&gt;`</span><span class="nc">ArrayLike</span><span class="o">]</span> <span class="nn">Np</span><span class="p">.</span><span class="nn">Obj</span><span class="p">.</span><span class="n">t</span> <span class="o">-&gt;</span>
  <span class="n">labels_pred</span><span class="o">:[&gt;`</span><span class="nc">ArrayLike</span><span class="o">]</span> <span class="nn">Np</span><span class="p">.</span><span class="nn">Obj</span><span class="p">.</span><span class="n">t</span> <span class="o">-&gt;</span>
  <span class="kt">unit</span> <span class="o">-&gt;</span>
  <span class="o">(</span><span class="kt">float</span> <span class="o">*</span> <span class="kt">float</span> <span class="o">*</span> <span class="kt">float</span><span class="o">)</span>
</code></pre></div>

<p>Compute the homogeneity and completeness and V-Measure scores at once.</p>
<p>Those metrics are based on normalized conditional entropy measures of
the clustering labeling to evaluate given the knowledge of a Ground
Truth class labels of the same samples.</p>
<p>A clustering result satisfies homogeneity if all of its clusters
contain only data points which are members of a single class.</p>
<p>A clustering result satisfies completeness if all the data points
that are members of a given class are elements of the same cluster.</p>
<p>Both scores have positive values between 0.0 and 1.0, larger values
being desirable.</p>
<p>Those 3 metrics are independent of the absolute values of the labels:
a permutation of the class or cluster label values won't change the
score values in any way.</p>
<p>V-Measure is furthermore symmetric: swapping <code>labels_true</code> and
<code>label_pred</code> will give the same score. This does not hold for
homogeneity and completeness. V-Measure is identical to
:func:<code>normalized_mutual_info_score</code> with the arithmetic averaging
method.</p>
<p>Read more in the :ref:<code>User Guide &lt;homogeneity_completeness&gt;</code>.</p>
<h4>Parameters</h4>
<ul>
<li>
<p><strong>labels_true : int array, shape = [n_samples]</strong>
    ground truth class labels to be used as a reference</p>
</li>
<li>
<p><strong>labels_pred : array-like of shape (n_samples,)</strong>
    cluster labels to evaluate</p>
</li>
<li>
<p><strong>beta : float</strong>
    Ratio of weight attributed to <code>homogeneity</code> vs <code>completeness</code>.
    If <code>beta</code> is greater than 1, <code>completeness</code> is weighted more
    strongly in the calculation. If <code>beta</code> is less than 1,
    <code>homogeneity</code> is weighted more strongly.</p>
</li>
</ul>
<h4>Returns</h4>
<ul>
<li>
<p><strong>homogeneity : float</strong>
   score between 0.0 and 1.0. 1.0 stands for perfectly homogeneous labeling</p>
</li>
<li>
<p><strong>completeness : float</strong>
   score between 0.0 and 1.0. 1.0 stands for perfectly complete labeling</p>
</li>
<li>
<p><strong>v_measure : float</strong>
    harmonic mean of the first two</p>
</li>
</ul>
<h4>See also</h4>
<p>homogeneity_score
completeness_score
v_measure_score</p>
</details>
<h3 id="homogeneity_score">homogeneity_score<a class="headerlink" href="#homogeneity_score" title="Permanent link">&para;</a></h3>
<details class="note" open="open"><summary>function homogeneity_score</summary><div class="highlight"><pre><span></span><code><span class="k">val</span> <span class="n">homogeneity_score</span> <span class="o">:</span>
  <span class="n">labels_true</span><span class="o">:[&gt;`</span><span class="nc">ArrayLike</span><span class="o">]</span> <span class="nn">Np</span><span class="p">.</span><span class="nn">Obj</span><span class="p">.</span><span class="n">t</span> <span class="o">-&gt;</span>
  <span class="n">labels_pred</span><span class="o">:[&gt;`</span><span class="nc">ArrayLike</span><span class="o">]</span> <span class="nn">Np</span><span class="p">.</span><span class="nn">Obj</span><span class="p">.</span><span class="n">t</span> <span class="o">-&gt;</span>
  <span class="kt">unit</span> <span class="o">-&gt;</span>
  <span class="kt">float</span>
</code></pre></div>

<p>Homogeneity metric of a cluster labeling given a ground truth.</p>
<p>A clustering result satisfies homogeneity if all of its clusters
contain only data points which are members of a single class.</p>
<p>This metric is independent of the absolute values of the labels:
a permutation of the class or cluster label values won't change the
score value in any way.</p>
<p>This metric is not symmetric: switching <code>label_true</code> with <code>label_pred</code>
will return the :func:<code>completeness_score</code> which will be different in
general.</p>
<p>Read more in the :ref:<code>User Guide &lt;homogeneity_completeness&gt;</code>.</p>
<h4>Parameters</h4>
<ul>
<li>
<p><strong>labels_true : int array, shape = [n_samples]</strong>
    ground truth class labels to be used as a reference</p>
</li>
<li>
<p><strong>labels_pred : array-like of shape (n_samples,)</strong>
    cluster labels to evaluate</p>
</li>
</ul>
<h4>Returns</h4>
<ul>
<li><strong>homogeneity : float</strong>
   score between 0.0 and 1.0. 1.0 stands for perfectly homogeneous labeling</li>
</ul>
<h4>References</h4>
<p>.. [1] <code>Andrew Rosenberg and Julia Hirschberg, 2007. V-Measure: A
   conditional entropy-based external cluster evaluation measure
   &lt;https://aclweb.org/anthology/D/D07/D07-1043.pdf&gt;</code>_</p>
<h4>See also</h4>
<p>completeness_score
v_measure_score</p>
<h4>Examples</h4>
<p>Perfect labelings are homogeneous::</p>
<blockquote>
<blockquote>
<blockquote>
<p>from sklearn.metrics.cluster import homogeneity_score
homogeneity_score([0, 0, 1, 1], [1, 1, 0, 0])
  1.0</p>
</blockquote>
</blockquote>
</blockquote>
<p>Non-perfect labelings that further split classes into more clusters can be
perfectly homogeneous::</p>
<blockquote>
<blockquote>
<blockquote>
<p>print('%.6f' % homogeneity_score([0, 0, 1, 1], [0, 0, 1, 2]))
  1.000000
print('%.6f' % homogeneity_score([0, 0, 1, 1], [0, 1, 2, 3]))
  1.000000</p>
</blockquote>
</blockquote>
</blockquote>
<p>Clusters that include samples from different classes do not make for an
homogeneous labeling::</p>
<blockquote>
<blockquote>
<blockquote>
<p>print('%.6f' % homogeneity_score([0, 0, 1, 1], [0, 1, 0, 1]))
  0.0...
print('%.6f' % homogeneity_score([0, 0, 1, 1], [0, 0, 0, 0]))
  0.0...</p>
</blockquote>
</blockquote>
</blockquote>
</details>
<h3 id="mutual_info_score">mutual_info_score<a class="headerlink" href="#mutual_info_score" title="Permanent link">&para;</a></h3>
<details class="note" open="open"><summary>function mutual_info_score</summary><div class="highlight"><pre><span></span><code><span class="k">val</span> <span class="n">mutual_info_score</span> <span class="o">:</span>
  <span class="o">?</span><span class="n">contingency</span><span class="o">:[&gt;`</span><span class="nc">ArrayLike</span><span class="o">]</span> <span class="nn">Np</span><span class="p">.</span><span class="nn">Obj</span><span class="p">.</span><span class="n">t</span> <span class="o">-&gt;</span>
  <span class="n">labels_true</span><span class="o">:[&gt;`</span><span class="nc">ArrayLike</span><span class="o">]</span> <span class="nn">Np</span><span class="p">.</span><span class="nn">Obj</span><span class="p">.</span><span class="n">t</span> <span class="o">-&gt;</span>
  <span class="n">labels_pred</span><span class="o">:[&gt;`</span><span class="nc">ArrayLike</span><span class="o">]</span> <span class="nn">Np</span><span class="p">.</span><span class="nn">Obj</span><span class="p">.</span><span class="n">t</span> <span class="o">-&gt;</span>
  <span class="kt">unit</span> <span class="o">-&gt;</span>
  <span class="kt">float</span>
</code></pre></div>

<p>Mutual Information between two clusterings.</p>
<p>The Mutual Information is a measure of the similarity between two labels of
the same data. Where :math:<code>|U_i|</code> is the number of the samples
in cluster :math:<code>U_i</code> and :math:<code>|V_j|</code> is the number of the
samples in cluster :math:<code>V_j</code>, the Mutual Information
between clusterings :math:<code>U</code> and :math:<code>V</code> is given as:</p>
<div>
<div class="MathJax_Preview">
    MI(U,V)=\sum_{i=1}^{ |U| } \sum_{j=1}^{ |V| } \frac{ |U_i\cap V_j| }{N}
    \log\frac{N|U_i \cap V_j| }{ |U_i||V_j| }
</div>
<script type="math/tex; mode=display">
    MI(U,V)=\sum_{i=1}^{ |U| } \sum_{j=1}^{ |V| } \frac{ |U_i\cap V_j| }{N}
    \log\frac{N|U_i \cap V_j| }{ |U_i||V_j| }
</script>
</div>
<p>This metric is independent of the absolute values of the labels:
a permutation of the class or cluster label values won't change the
score value in any way.</p>
<p>This metric is furthermore symmetric: switching <code>label_true</code> with
<code>label_pred</code> will return the same score value. This can be useful to
measure the agreement of two independent label assignments strategies
on the same dataset when the real ground truth is not known.</p>
<p>Read more in the :ref:<code>User Guide &lt;mutual_info_score&gt;</code>.</p>
<h4>Parameters</h4>
<ul>
<li>
<p><strong>labels_true : int array, shape = [n_samples]</strong>
    A clustering of the data into disjoint subsets.</p>
</li>
<li>
<p><strong>labels_pred : int array-like of shape (n_samples,)</strong>
    A clustering of the data into disjoint subsets.</p>
</li>
<li>
<p><strong>contingency : {None, array, sparse matrix},                   shape = [n_classes_true, n_classes_pred]</strong>
    A contingency matrix given by the :func:<code>contingency_matrix</code> function.
    If value is <code>None</code>, it will be computed, otherwise the given value is
    used, with <code>labels_true</code> and <code>labels_pred</code> ignored.</p>
</li>
</ul>
<h4>Returns</h4>
<ul>
<li><strong>mi : float</strong>
   Mutual information, a non-negative value</li>
</ul>
<h4>Notes</h4>
<p>The logarithm used is the natural logarithm (base-e).</p>
<h4>See also</h4>
<ul>
<li>
<p><strong>adjusted_mutual_info_score: Adjusted against chance Mutual Information</strong></p>
</li>
<li>
<p><strong>normalized_mutual_info_score: Normalized Mutual Information</strong></p>
</li>
</ul>
</details>
<h3 id="normalized_mutual_info_score">normalized_mutual_info_score<a class="headerlink" href="#normalized_mutual_info_score" title="Permanent link">&para;</a></h3>
<details class="note" open="open"><summary>function normalized_mutual_info_score</summary><div class="highlight"><pre><span></span><code><span class="k">val</span> <span class="n">normalized_mutual_info_score</span> <span class="o">:</span>
  <span class="o">?</span><span class="n">average_method</span><span class="o">:</span><span class="kt">string</span> <span class="o">-&gt;</span>
  <span class="n">labels_true</span><span class="o">:[&gt;`</span><span class="nc">ArrayLike</span><span class="o">]</span> <span class="nn">Np</span><span class="p">.</span><span class="nn">Obj</span><span class="p">.</span><span class="n">t</span> <span class="o">-&gt;</span>
  <span class="n">labels_pred</span><span class="o">:[&gt;`</span><span class="nc">ArrayLike</span><span class="o">]</span> <span class="nn">Np</span><span class="p">.</span><span class="nn">Obj</span><span class="p">.</span><span class="n">t</span> <span class="o">-&gt;</span>
  <span class="kt">unit</span> <span class="o">-&gt;</span>
  <span class="kt">float</span>
</code></pre></div>

<p>Normalized Mutual Information between two clusterings.</p>
<p>Normalized Mutual Information (NMI) is a normalization of the Mutual
Information (MI) score to scale the results between 0 (no mutual
information) and 1 (perfect correlation). In this function, mutual
information is normalized by some generalized mean of <code>H(labels_true)</code>
and <code>H(labels_pred))</code>, defined by the <code>average_method</code>.</p>
<p>This measure is not adjusted for chance. Therefore
:func:<code>adjusted_mutual_info_score</code> might be preferred.</p>
<p>This metric is independent of the absolute values of the labels:
a permutation of the class or cluster label values won't change the
score value in any way.</p>
<p>This metric is furthermore symmetric: switching <code>label_true</code> with
<code>label_pred</code> will return the same score value. This can be useful to
measure the agreement of two independent label assignments strategies
on the same dataset when the real ground truth is not known.</p>
<p>Read more in the :ref:<code>User Guide &lt;mutual_info_score&gt;</code>.</p>
<h4>Parameters</h4>
<ul>
<li>
<p><strong>labels_true : int array, shape = [n_samples]</strong>
    A clustering of the data into disjoint subsets.</p>
</li>
<li>
<p><strong>labels_pred : int array-like of shape (n_samples,)</strong>
    A clustering of the data into disjoint subsets.</p>
</li>
<li>
<p><strong>average_method : string, optional (default: 'arithmetic')</strong>
    How to compute the normalizer in the denominator. Possible options
    are 'min', 'geometric', 'arithmetic', and 'max'.</p>
<p>.. versionadded:: 0.20</p>
<p>.. versionchanged:: 0.22
   The default value of <code>average_method</code> changed from 'geometric' to
   'arithmetic'.</p>
</li>
</ul>
<h4>Returns</h4>
<ul>
<li><strong>nmi : float</strong>
   score between 0.0 and 1.0. 1.0 stands for perfectly complete labeling</li>
</ul>
<h4>See also</h4>
<ul>
<li>
<p><strong>v_measure_score: V-Measure (NMI with arithmetic mean option.)</strong></p>
</li>
<li>
<p><strong>adjusted_rand_score: Adjusted Rand Index</strong></p>
</li>
<li>
<p><strong>adjusted_mutual_info_score: Adjusted Mutual Information (adjusted</strong>
    against chance)</p>
</li>
</ul>
<h4>Examples</h4>
<p>Perfect labelings are both homogeneous and complete, hence have
score 1.0::</p>
<blockquote>
<blockquote>
<blockquote>
<p>from sklearn.metrics.cluster import normalized_mutual_info_score
normalized_mutual_info_score([0, 0, 1, 1], [0, 0, 1, 1])
  ... # doctest: +SKIP
  1.0
normalized_mutual_info_score([0, 0, 1, 1], [1, 1, 0, 0])
  ... # doctest: +SKIP
  1.0</p>
</blockquote>
</blockquote>
</blockquote>
<p>If classes members are completely split across different clusters,
the assignment is totally in-complete, hence the NMI is null::</p>
<blockquote>
<blockquote>
<blockquote>
<p>normalized_mutual_info_score([0, 0, 0, 0], [0, 1, 2, 3])
  ... # doctest: +SKIP
  0.0</p>
</blockquote>
</blockquote>
</blockquote>
</details>
<h3 id="silhouette_samples">silhouette_samples<a class="headerlink" href="#silhouette_samples" title="Permanent link">&para;</a></h3>
<details class="note" open="open"><summary>function silhouette_samples</summary><div class="highlight"><pre><span></span><code><span class="k">val</span> <span class="n">silhouette_samples</span> <span class="o">:</span>
  <span class="o">?</span><span class="n">metric</span><span class="o">:[`</span><span class="nc">S</span> <span class="k">of</span> <span class="kt">string</span> <span class="o">|</span> <span class="o">`</span><span class="nc">Callable</span> <span class="k">of</span> <span class="nn">Py</span><span class="p">.</span><span class="nn">Object</span><span class="p">.</span><span class="n">t</span><span class="o">]</span> <span class="o">-&gt;</span>
  <span class="o">?</span><span class="n">kwds</span><span class="o">:(</span><span class="kt">string</span> <span class="o">*</span> <span class="nn">Py</span><span class="p">.</span><span class="nn">Object</span><span class="p">.</span><span class="n">t</span><span class="o">)</span> <span class="kt">list</span> <span class="o">-&gt;</span>
  <span class="n">x</span><span class="o">:[`</span><span class="nc">Arr</span> <span class="k">of</span> <span class="o">[&gt;`</span><span class="nc">ArrayLike</span><span class="o">]</span> <span class="nn">Np</span><span class="p">.</span><span class="nn">Obj</span><span class="p">.</span><span class="n">t</span> <span class="o">|</span> <span class="o">`</span><span class="nc">Otherwise</span> <span class="k">of</span> <span class="nn">Py</span><span class="p">.</span><span class="nn">Object</span><span class="p">.</span><span class="n">t</span><span class="o">]</span> <span class="o">-&gt;</span>
  <span class="n">labels</span><span class="o">:[&gt;`</span><span class="nc">ArrayLike</span><span class="o">]</span> <span class="nn">Np</span><span class="p">.</span><span class="nn">Obj</span><span class="p">.</span><span class="n">t</span> <span class="o">-&gt;</span>
  <span class="kt">unit</span> <span class="o">-&gt;</span>
  <span class="o">[&gt;`</span><span class="nc">ArrayLike</span><span class="o">]</span> <span class="nn">Np</span><span class="p">.</span><span class="nn">Obj</span><span class="p">.</span><span class="n">t</span>
</code></pre></div>

<p>Compute the Silhouette Coefficient for each sample.</p>
<p>The Silhouette Coefficient is a measure of how well samples are clustered
with samples that are similar to themselves. Clustering models with a high
Silhouette Coefficient are said to be dense, where samples in the same
cluster are similar to each other, and well separated, where samples in
different clusters are not very similar to each other.</p>
<p>The Silhouette Coefficient is calculated using the mean intra-cluster
distance (<code>a</code>) and the mean nearest-cluster distance (<code>b</code>) for each
sample.  The Silhouette Coefficient for a sample is <code>(b - a) / max(a,
b)</code>.
Note that Silhouette Coefficient is only defined if number of labels
is 2 &lt;= n_labels &lt;= n_samples - 1.</p>
<p>This function returns the Silhouette Coefficient for each sample.</p>
<p>The best value is 1 and the worst value is -1. Values near 0 indicate
overlapping clusters.</p>
<p>Read more in the :ref:<code>User Guide &lt;silhouette_coefficient&gt;</code>.</p>
<h4>Parameters</h4>
<ul>
<li>
<p><strong>X : array [n_samples_a, n_samples_a] if metric == 'precomputed', or,              [n_samples_a, n_features] otherwise</strong>
    Array of pairwise distances between samples, or a feature array.</p>
</li>
<li>
<p><strong>labels : array, shape = [n_samples]</strong>
         label values for each sample</p>
</li>
<li>
<p><strong>metric : string, or callable</strong>
    The metric to use when calculating distance between instances in a
    feature array. If metric is a string, it must be one of the options
    allowed by :func:<code>sklearn.metrics.pairwise.pairwise_distances</code>. If X is
    the distance array itself, use 'precomputed' as the metric. Precomputed
    distance matrices must have 0 along the diagonal.</p>
</li>
</ul>
<p><code>**kwds</code> : optional keyword parameters
    Any further parameters are passed directly to the distance function.
    If using a <code>scipy.spatial.distance</code> metric, the parameters are still
    metric dependent. See the scipy docs for usage examples.</p>
<h4>Returns</h4>
<ul>
<li><strong>silhouette : array, shape = [n_samples]</strong>
    Silhouette Coefficient for each samples.</li>
</ul>
<h4>References</h4>
<p>.. [1] <code>Peter J. Rousseeuw (1987). 'Silhouettes: a Graphical Aid to the
   Interpretation and Validation of Cluster Analysis'. Computational
   and Applied Mathematics 20: 53-65.
   &lt;https://www.sciencedirect.com/science/article/pii/0377042787901257&gt;</code>_</p>
<p>.. [2] <code>Wikipedia entry on the Silhouette Coefficient
   &lt;https://en.wikipedia.org/wiki/Silhouette_(clustering)&gt;</code>_</p>
</details>
<h3 id="silhouette_score">silhouette_score<a class="headerlink" href="#silhouette_score" title="Permanent link">&para;</a></h3>
<details class="note" open="open"><summary>function silhouette_score</summary><div class="highlight"><pre><span></span><code><span class="k">val</span> <span class="n">silhouette_score</span> <span class="o">:</span>
  <span class="o">?</span><span class="n">metric</span><span class="o">:[`</span><span class="nc">S</span> <span class="k">of</span> <span class="kt">string</span> <span class="o">|</span> <span class="o">`</span><span class="nc">Callable</span> <span class="k">of</span> <span class="nn">Py</span><span class="p">.</span><span class="nn">Object</span><span class="p">.</span><span class="n">t</span><span class="o">]</span> <span class="o">-&gt;</span>
  <span class="o">?</span><span class="n">sample_size</span><span class="o">:</span><span class="kt">int</span> <span class="o">-&gt;</span>
  <span class="o">?</span><span class="n">random_state</span><span class="o">:</span><span class="kt">int</span> <span class="o">-&gt;</span>
  <span class="o">?</span><span class="n">kwds</span><span class="o">:(</span><span class="kt">string</span> <span class="o">*</span> <span class="nn">Py</span><span class="p">.</span><span class="nn">Object</span><span class="p">.</span><span class="n">t</span><span class="o">)</span> <span class="kt">list</span> <span class="o">-&gt;</span>
  <span class="n">x</span><span class="o">:[`</span><span class="nc">Arr</span> <span class="k">of</span> <span class="o">[&gt;`</span><span class="nc">ArrayLike</span><span class="o">]</span> <span class="nn">Np</span><span class="p">.</span><span class="nn">Obj</span><span class="p">.</span><span class="n">t</span> <span class="o">|</span> <span class="o">`</span><span class="nc">Otherwise</span> <span class="k">of</span> <span class="nn">Py</span><span class="p">.</span><span class="nn">Object</span><span class="p">.</span><span class="n">t</span><span class="o">]</span> <span class="o">-&gt;</span>
  <span class="n">labels</span><span class="o">:[&gt;`</span><span class="nc">ArrayLike</span><span class="o">]</span> <span class="nn">Np</span><span class="p">.</span><span class="nn">Obj</span><span class="p">.</span><span class="n">t</span> <span class="o">-&gt;</span>
  <span class="kt">unit</span> <span class="o">-&gt;</span>
  <span class="kt">float</span>
</code></pre></div>

<p>Compute the mean Silhouette Coefficient of all samples.</p>
<p>The Silhouette Coefficient is calculated using the mean intra-cluster
distance (<code>a</code>) and the mean nearest-cluster distance (<code>b</code>) for each
sample.  The Silhouette Coefficient for a sample is <code>(b - a) / max(a,
b)</code>.  To clarify, <code>b</code> is the distance between a sample and the nearest
cluster that the sample is not a part of.
Note that Silhouette Coefficient is only defined if number of labels
is 2 &lt;= n_labels &lt;= n_samples - 1.</p>
<p>This function returns the mean Silhouette Coefficient over all samples.
To obtain the values for each sample, use :func:<code>silhouette_samples</code>.</p>
<p>The best value is 1 and the worst value is -1. Values near 0 indicate
overlapping clusters. Negative values generally indicate that a sample has
been assigned to the wrong cluster, as a different cluster is more similar.</p>
<p>Read more in the :ref:<code>User Guide &lt;silhouette_coefficient&gt;</code>.</p>
<h4>Parameters</h4>
<ul>
<li>
<p><strong>X : array [n_samples_a, n_samples_a] if metric == 'precomputed', or,              [n_samples_a, n_features] otherwise</strong>
    Array of pairwise distances between samples, or a feature array.</p>
</li>
<li>
<p><strong>labels : array, shape = [n_samples]</strong>
     Predicted labels for each sample.</p>
</li>
<li>
<p><strong>metric : string, or callable</strong>
    The metric to use when calculating distance between instances in a
    feature array. If metric is a string, it must be one of the options
    allowed by :func:<code>metrics.pairwise.pairwise_distances
    &lt;sklearn.metrics.pairwise.pairwise_distances&gt;</code>. If X is the distance
    array itself, use <code>metric='precomputed'</code>.</p>
</li>
<li>
<p><strong>sample_size : int or None</strong>
    The size of the sample to use when computing the Silhouette Coefficient
    on a random subset of the data.
    If <code>sample_size is None</code>, no sampling is used.</p>
</li>
<li>
<p><strong>random_state : int, RandomState instance or None, optional (default=None)</strong>
    Determines random number generation for selecting a subset of samples.
    Used when <code>sample_size is not None</code>.
    Pass an int for reproducible results across multiple function calls.</p>
</li>
<li>
<p><strong>See :term:<code>Glossary &lt;random_state&gt;</code>.</strong></p>
</li>
<li>
<p><strong>**kwds : optional keyword parameters</strong>
    Any further parameters are passed directly to the distance function.
    If using a scipy.spatial.distance metric, the parameters are still
    metric dependent. See the scipy docs for usage examples.</p>
</li>
</ul>
<h4>Returns</h4>
<ul>
<li><strong>silhouette : float</strong>
    Mean Silhouette Coefficient for all samples.</li>
</ul>
<h4>References</h4>
<p>.. [1] <code>Peter J. Rousseeuw (1987). 'Silhouettes: a Graphical Aid to the
   Interpretation and Validation of Cluster Analysis'. Computational
   and Applied Mathematics 20: 53-65.
   &lt;https://www.sciencedirect.com/science/article/pii/0377042787901257&gt;</code>_</p>
<p>.. [2] <code>Wikipedia entry on the Silhouette Coefficient
       &lt;https://en.wikipedia.org/wiki/Silhouette_(clustering)&gt;</code>_</p>
</details>
<h3 id="v_measure_score">v_measure_score<a class="headerlink" href="#v_measure_score" title="Permanent link">&para;</a></h3>
<details class="note" open="open"><summary>function v_measure_score</summary><div class="highlight"><pre><span></span><code><span class="k">val</span> <span class="n">v_measure_score</span> <span class="o">:</span>
  <span class="o">?</span><span class="n">beta</span><span class="o">:</span><span class="kt">float</span> <span class="o">-&gt;</span>
  <span class="n">labels_true</span><span class="o">:[&gt;`</span><span class="nc">ArrayLike</span><span class="o">]</span> <span class="nn">Np</span><span class="p">.</span><span class="nn">Obj</span><span class="p">.</span><span class="n">t</span> <span class="o">-&gt;</span>
  <span class="n">labels_pred</span><span class="o">:[&gt;`</span><span class="nc">ArrayLike</span><span class="o">]</span> <span class="nn">Np</span><span class="p">.</span><span class="nn">Obj</span><span class="p">.</span><span class="n">t</span> <span class="o">-&gt;</span>
  <span class="kt">unit</span> <span class="o">-&gt;</span>
  <span class="kt">float</span>
</code></pre></div>

<p>V-measure cluster labeling given a ground truth.</p>
<p>This score is identical to :func:<code>normalized_mutual_info_score</code> with
the <code>'arithmetic'</code> option for averaging.</p>
<p>The V-measure is the harmonic mean between homogeneity and completeness::</p>
<div class="codehilite"><pre><span></span><code>v = (1 + beta) * homogeneity * completeness
     / (beta * homogeneity + completeness)
</code></pre></div>


<p>This metric is independent of the absolute values of the labels:
a permutation of the class or cluster label values won't change the
score value in any way.</p>
<p>This metric is furthermore symmetric: switching <code>label_true</code> with
<code>label_pred</code> will return the same score value. This can be useful to
measure the agreement of two independent label assignments strategies
on the same dataset when the real ground truth is not known.</p>
<p>Read more in the :ref:<code>User Guide &lt;homogeneity_completeness&gt;</code>.</p>
<h4>Parameters</h4>
<ul>
<li>
<p><strong>labels_true : int array, shape = [n_samples]</strong>
    ground truth class labels to be used as a reference</p>
</li>
<li>
<p><strong>labels_pred : array-like of shape (n_samples,)</strong>
    cluster labels to evaluate</p>
</li>
<li>
<p><strong>beta : float</strong>
    Ratio of weight attributed to <code>homogeneity</code> vs <code>completeness</code>.
    If <code>beta</code> is greater than 1, <code>completeness</code> is weighted more
    strongly in the calculation. If <code>beta</code> is less than 1,
    <code>homogeneity</code> is weighted more strongly.</p>
</li>
</ul>
<h4>Returns</h4>
<ul>
<li><strong>v_measure : float</strong>
   score between 0.0 and 1.0. 1.0 stands for perfectly complete labeling</li>
</ul>
<h4>References</h4>
<p>.. [1] <code>Andrew Rosenberg and Julia Hirschberg, 2007. V-Measure: A
   conditional entropy-based external cluster evaluation measure
   &lt;https://aclweb.org/anthology/D/D07/D07-1043.pdf&gt;</code>_</p>
<h4>See also</h4>
<p>homogeneity_score
completeness_score
normalized_mutual_info_score</p>
<h4>Examples</h4>
<p>Perfect labelings are both homogeneous and complete, hence have score 1.0::</p>
<blockquote>
<blockquote>
<blockquote>
<p>from sklearn.metrics.cluster import v_measure_score
v_measure_score([0, 0, 1, 1], [0, 0, 1, 1])
  1.0
v_measure_score([0, 0, 1, 1], [1, 1, 0, 0])
  1.0</p>
</blockquote>
</blockquote>
</blockquote>
<p>Labelings that assign all classes members to the same clusters
are complete be not homogeneous, hence penalized::</p>
<blockquote>
<blockquote>
<blockquote>
<p>print('%.6f' % v_measure_score([0, 0, 1, 2], [0, 0, 1, 1]))
  0.8...
print('%.6f' % v_measure_score([0, 1, 2, 3], [0, 0, 1, 1]))
  0.66...</p>
</blockquote>
</blockquote>
</blockquote>
<p>Labelings that have pure clusters with members coming from the same
classes are homogeneous but un-necessary splits harms completeness
and thus penalize V-measure as well::</p>
<blockquote>
<blockquote>
<blockquote>
<p>print('%.6f' % v_measure_score([0, 0, 1, 1], [0, 0, 1, 2]))
  0.8...
print('%.6f' % v_measure_score([0, 0, 1, 1], [0, 1, 2, 3]))
  0.66...</p>
</blockquote>
</blockquote>
</blockquote>
<p>If classes members are completely split across different clusters,
the assignment is totally incomplete, hence the V-Measure is null::</p>
<blockquote>
<blockquote>
<blockquote>
<p>print('%.6f' % v_measure_score([0, 0, 0, 0], [0, 1, 2, 3]))
  0.0...</p>
</blockquote>
</blockquote>
</blockquote>
<p>Clusters that include samples from totally different classes totally
destroy the homogeneity of the labeling, hence::</p>
<blockquote>
<blockquote>
<blockquote>
<p>print('%.6f' % v_measure_score([0, 0, 1, 1], [0, 0, 0, 0]))
  0.0...</p>
</blockquote>
</blockquote>
</blockquote>
</details>
<h2 id="pairwise">Pairwise<a class="headerlink" href="#pairwise" title="Permanent link">&para;</a></h2>
<p>Module <code>Sklearn.Metrics.Pairwise</code> wraps Python module <code>sklearn.metrics.pairwise</code>.</p>
<h2 id="csr_matrix">Csr_matrix<a class="headerlink" href="#csr_matrix" title="Permanent link">&para;</a></h2>
<p>Module <code>Sklearn.Metrics.Pairwise.Csr_matrix</code> wraps Python class <a href="https://scikit-learn.org/stable/modules/generated/sklearn.metrics.pairwise.csr_matrix.html"><code>sklearn.metrics.pairwise.csr_matrix</code></a>.</p>
<div class="highlight"><pre><span></span><code><span class="k">type</span> <span class="n">t</span>
</code></pre></div>

<h3 id="create_3">create<a class="headerlink" href="#create_3" title="Permanent link">&para;</a></h3>
<details class="note" open="open"><summary>constructor and attributes create</summary><div class="highlight"><pre><span></span><code><span class="k">val</span> <span class="n">create</span> <span class="o">:</span>
  <span class="o">?</span><span class="n">shape</span><span class="o">:</span><span class="kt">int</span> <span class="kt">list</span> <span class="o">-&gt;</span>
  <span class="o">?</span><span class="n">dtype</span><span class="o">:</span><span class="nn">Py</span><span class="p">.</span><span class="nn">Object</span><span class="p">.</span><span class="n">t</span> <span class="o">-&gt;</span>
  <span class="o">?</span><span class="n">copy</span><span class="o">:</span><span class="nn">Py</span><span class="p">.</span><span class="nn">Object</span><span class="p">.</span><span class="n">t</span> <span class="o">-&gt;</span>
  <span class="n">arg1</span><span class="o">:</span><span class="nn">Py</span><span class="p">.</span><span class="nn">Object</span><span class="p">.</span><span class="n">t</span> <span class="o">-&gt;</span>
  <span class="kt">unit</span> <span class="o">-&gt;</span>
  <span class="n">t</span>
</code></pre></div>

<p>Compressed Sparse Row matrix</p>
<p>This can be instantiated in several ways:
    csr_matrix(D)
        with a dense matrix or rank-2 ndarray D</p>
<div class="codehilite"><pre><span></span><code>csr_matrix(S)
    with another sparse matrix S (equivalent to S.tocsr())

csr_matrix((M, N), [dtype])
    to construct an empty matrix with shape (M, N)
    dtype is optional, defaulting to dtype=&#39;d&#39;.

csr_matrix((data, (row_ind, col_ind)), [shape=(M, N)])
    where ``data``, ``row_ind`` and ``col_ind`` satisfy the
    relationship ``a[row_ind[k], col_ind[k]] = data[k]``.

csr_matrix((data, indices, indptr), [shape=(M, N)])
    is the standard CSR representation where the column indices for
    row i are stored in ``indices[indptr[i]:indptr[i+1]]`` and their
    corresponding values are stored in ``data[indptr[i]:indptr[i+1]]``.
    If the shape parameter is not supplied, the matrix dimensions
    are inferred from the index arrays.
</code></pre></div>


<h4>Attributes</h4>
<ul>
<li>
<p><strong>dtype : dtype</strong>
    Data type of the matrix</p>
</li>
<li>
<p><strong>shape : 2-tuple</strong>
    Shape of the matrix</p>
</li>
<li>
<p><strong>ndim : int</strong>
    Number of dimensions (this is always 2)
nnz
    Number of stored values, including explicit zeros
data
    CSR format data array of the matrix
indices
    CSR format index array of the matrix
indptr
    CSR format index pointer array of the matrix
has_sorted_indices
    Whether indices are sorted</p>
</li>
</ul>
<h4>Notes</h4>
<p>Sparse matrices can be used in arithmetic operations: they support
addition, subtraction, multiplication, division, and matrix power.</p>
<p>Advantages of the CSR format
  - efficient arithmetic operations CSR + CSR, CSR * CSR, etc.
  - efficient row slicing
  - fast matrix vector products</p>
<p>Disadvantages of the CSR format
  - slow column slicing operations (consider CSC)
  - changes to the sparsity structure are expensive (consider LIL or DOK)</p>
<h4>Examples</h4>
<div class="highlight"><pre><span></span><code><span class="o">&gt;&gt;&gt;</span> <span class="kn">import</span> <span class="nn">numpy</span> <span class="k">as</span> <span class="nn">np</span>
<span class="o">&gt;&gt;&gt;</span> <span class="kn">from</span> <span class="nn">scipy.sparse</span> <span class="kn">import</span> <span class="n">csr_matrix</span>
<span class="o">&gt;&gt;&gt;</span> <span class="n">csr_matrix</span><span class="p">((</span><span class="mi">3</span><span class="p">,</span> <span class="mi">4</span><span class="p">),</span> <span class="n">dtype</span><span class="o">=</span><span class="n">np</span><span class="o">.</span><span class="n">int8</span><span class="p">)</span><span class="o">.</span><span class="n">toarray</span><span class="p">()</span>
<span class="n">array</span><span class="p">([[</span><span class="mi">0</span><span class="p">,</span> <span class="mi">0</span><span class="p">,</span> <span class="mi">0</span><span class="p">,</span> <span class="mi">0</span><span class="p">],</span>
       <span class="p">[</span><span class="mi">0</span><span class="p">,</span> <span class="mi">0</span><span class="p">,</span> <span class="mi">0</span><span class="p">,</span> <span class="mi">0</span><span class="p">],</span>
       <span class="p">[</span><span class="mi">0</span><span class="p">,</span> <span class="mi">0</span><span class="p">,</span> <span class="mi">0</span><span class="p">,</span> <span class="mi">0</span><span class="p">]],</span> <span class="n">dtype</span><span class="o">=</span><span class="n">int8</span><span class="p">)</span>
</code></pre></div>

<div class="highlight"><pre><span></span><code><span class="o">&gt;&gt;&gt;</span> <span class="n">row</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">array</span><span class="p">([</span><span class="mi">0</span><span class="p">,</span> <span class="mi">0</span><span class="p">,</span> <span class="mi">1</span><span class="p">,</span> <span class="mi">2</span><span class="p">,</span> <span class="mi">2</span><span class="p">,</span> <span class="mi">2</span><span class="p">])</span>
<span class="o">&gt;&gt;&gt;</span> <span class="n">col</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">array</span><span class="p">([</span><span class="mi">0</span><span class="p">,</span> <span class="mi">2</span><span class="p">,</span> <span class="mi">2</span><span class="p">,</span> <span class="mi">0</span><span class="p">,</span> <span class="mi">1</span><span class="p">,</span> <span class="mi">2</span><span class="p">])</span>
<span class="o">&gt;&gt;&gt;</span> <span class="n">data</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">array</span><span class="p">([</span><span class="mi">1</span><span class="p">,</span> <span class="mi">2</span><span class="p">,</span> <span class="mi">3</span><span class="p">,</span> <span class="mi">4</span><span class="p">,</span> <span class="mi">5</span><span class="p">,</span> <span class="mi">6</span><span class="p">])</span>
<span class="o">&gt;&gt;&gt;</span> <span class="n">csr_matrix</span><span class="p">((</span><span class="n">data</span><span class="p">,</span> <span class="p">(</span><span class="n">row</span><span class="p">,</span> <span class="n">col</span><span class="p">)),</span> <span class="n">shape</span><span class="o">=</span><span class="p">(</span><span class="mi">3</span><span class="p">,</span> <span class="mi">3</span><span class="p">))</span><span class="o">.</span><span class="n">toarray</span><span class="p">()</span>
<span class="n">array</span><span class="p">([[</span><span class="mi">1</span><span class="p">,</span> <span class="mi">0</span><span class="p">,</span> <span class="mi">2</span><span class="p">],</span>
       <span class="p">[</span><span class="mi">0</span><span class="p">,</span> <span class="mi">0</span><span class="p">,</span> <span class="mi">3</span><span class="p">],</span>
       <span class="p">[</span><span class="mi">4</span><span class="p">,</span> <span class="mi">5</span><span class="p">,</span> <span class="mi">6</span><span class="p">]])</span>
</code></pre></div>

<div class="highlight"><pre><span></span><code><span class="o">&gt;&gt;&gt;</span> <span class="n">indptr</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">array</span><span class="p">([</span><span class="mi">0</span><span class="p">,</span> <span class="mi">2</span><span class="p">,</span> <span class="mi">3</span><span class="p">,</span> <span class="mi">6</span><span class="p">])</span>
<span class="o">&gt;&gt;&gt;</span> <span class="n">indices</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">array</span><span class="p">([</span><span class="mi">0</span><span class="p">,</span> <span class="mi">2</span><span class="p">,</span> <span class="mi">2</span><span class="p">,</span> <span class="mi">0</span><span class="p">,</span> <span class="mi">1</span><span class="p">,</span> <span class="mi">2</span><span class="p">])</span>
<span class="o">&gt;&gt;&gt;</span> <span class="n">data</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">array</span><span class="p">([</span><span class="mi">1</span><span class="p">,</span> <span class="mi">2</span><span class="p">,</span> <span class="mi">3</span><span class="p">,</span> <span class="mi">4</span><span class="p">,</span> <span class="mi">5</span><span class="p">,</span> <span class="mi">6</span><span class="p">])</span>
<span class="o">&gt;&gt;&gt;</span> <span class="n">csr_matrix</span><span class="p">((</span><span class="n">data</span><span class="p">,</span> <span class="n">indices</span><span class="p">,</span> <span class="n">indptr</span><span class="p">),</span> <span class="n">shape</span><span class="o">=</span><span class="p">(</span><span class="mi">3</span><span class="p">,</span> <span class="mi">3</span><span class="p">))</span><span class="o">.</span><span class="n">toarray</span><span class="p">()</span>
<span class="n">array</span><span class="p">([[</span><span class="mi">1</span><span class="p">,</span> <span class="mi">0</span><span class="p">,</span> <span class="mi">2</span><span class="p">],</span>
       <span class="p">[</span><span class="mi">0</span><span class="p">,</span> <span class="mi">0</span><span class="p">,</span> <span class="mi">3</span><span class="p">],</span>
       <span class="p">[</span><span class="mi">4</span><span class="p">,</span> <span class="mi">5</span><span class="p">,</span> <span class="mi">6</span><span class="p">]])</span>
</code></pre></div>

<p>Duplicate entries are summed together:</p>
<div class="highlight"><pre><span></span><code><span class="o">&gt;&gt;&gt;</span> <span class="n">row</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">array</span><span class="p">([</span><span class="mi">0</span><span class="p">,</span> <span class="mi">1</span><span class="p">,</span> <span class="mi">2</span><span class="p">,</span> <span class="mi">0</span><span class="p">])</span>
<span class="o">&gt;&gt;&gt;</span> <span class="n">col</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">array</span><span class="p">([</span><span class="mi">0</span><span class="p">,</span> <span class="mi">1</span><span class="p">,</span> <span class="mi">1</span><span class="p">,</span> <span class="mi">0</span><span class="p">])</span>
<span class="o">&gt;&gt;&gt;</span> <span class="n">data</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">array</span><span class="p">([</span><span class="mi">1</span><span class="p">,</span> <span class="mi">2</span><span class="p">,</span> <span class="mi">4</span><span class="p">,</span> <span class="mi">8</span><span class="p">])</span>
<span class="o">&gt;&gt;&gt;</span> <span class="n">csr_matrix</span><span class="p">((</span><span class="n">data</span><span class="p">,</span> <span class="p">(</span><span class="n">row</span><span class="p">,</span> <span class="n">col</span><span class="p">)),</span> <span class="n">shape</span><span class="o">=</span><span class="p">(</span><span class="mi">3</span><span class="p">,</span> <span class="mi">3</span><span class="p">))</span><span class="o">.</span><span class="n">toarray</span><span class="p">()</span>
<span class="n">array</span><span class="p">([[</span><span class="mi">9</span><span class="p">,</span> <span class="mi">0</span><span class="p">,</span> <span class="mi">0</span><span class="p">],</span>
       <span class="p">[</span><span class="mi">0</span><span class="p">,</span> <span class="mi">2</span><span class="p">,</span> <span class="mi">0</span><span class="p">],</span>
       <span class="p">[</span><span class="mi">0</span><span class="p">,</span> <span class="mi">4</span><span class="p">,</span> <span class="mi">0</span><span class="p">]])</span>
</code></pre></div>

<p>As an example of how to construct a CSR matrix incrementally,
the following snippet builds a term-document matrix from texts:</p>
<div class="highlight"><pre><span></span><code><span class="o">&gt;&gt;&gt;</span> <span class="n">docs</span> <span class="o">=</span> <span class="p">[[</span><span class="s1">&#39;hello&#39;</span><span class="p">,</span> <span class="s1">&#39;world&#39;</span><span class="p">,</span> <span class="s1">&#39;hello&#39;</span><span class="p">],</span> <span class="p">[</span><span class="s1">&#39;goodbye&#39;</span><span class="p">,</span> <span class="s1">&#39;cruel&#39;</span><span class="p">,</span> <span class="s1">&#39;world&#39;</span><span class="p">]]</span>
<span class="o">&gt;&gt;&gt;</span> <span class="n">indptr</span> <span class="o">=</span> <span class="p">[</span><span class="mi">0</span><span class="p">]</span>
<span class="o">&gt;&gt;&gt;</span> <span class="n">indices</span> <span class="o">=</span> <span class="p">[]</span>
<span class="o">&gt;&gt;&gt;</span> <span class="n">data</span> <span class="o">=</span> <span class="p">[]</span>
<span class="o">&gt;&gt;&gt;</span> <span class="n">vocabulary</span> <span class="o">=</span> <span class="p">{}</span>
<span class="o">&gt;&gt;&gt;</span> <span class="k">for</span> <span class="n">d</span> <span class="ow">in</span> <span class="n">docs</span><span class="p">:</span>
<span class="o">...</span>     <span class="k">for</span> <span class="n">term</span> <span class="ow">in</span> <span class="n">d</span><span class="p">:</span>
<span class="o">...</span>         <span class="n">index</span> <span class="o">=</span> <span class="n">vocabulary</span><span class="o">.</span><span class="n">setdefault</span><span class="p">(</span><span class="n">term</span><span class="p">,</span> <span class="nb">len</span><span class="p">(</span><span class="n">vocabulary</span><span class="p">))</span>
<span class="o">...</span>         <span class="n">indices</span><span class="o">.</span><span class="n">append</span><span class="p">(</span><span class="n">index</span><span class="p">)</span>
<span class="o">...</span>         <span class="n">data</span><span class="o">.</span><span class="n">append</span><span class="p">(</span><span class="mi">1</span><span class="p">)</span>
<span class="o">...</span>     <span class="n">indptr</span><span class="o">.</span><span class="n">append</span><span class="p">(</span><span class="nb">len</span><span class="p">(</span><span class="n">indices</span><span class="p">))</span>
<span class="o">...</span>
<span class="o">&gt;&gt;&gt;</span> <span class="n">csr_matrix</span><span class="p">((</span><span class="n">data</span><span class="p">,</span> <span class="n">indices</span><span class="p">,</span> <span class="n">indptr</span><span class="p">),</span> <span class="n">dtype</span><span class="o">=</span><span class="nb">int</span><span class="p">)</span><span class="o">.</span><span class="n">toarray</span><span class="p">()</span>
<span class="n">array</span><span class="p">([[</span><span class="mi">2</span><span class="p">,</span> <span class="mi">1</span><span class="p">,</span> <span class="mi">0</span><span class="p">,</span> <span class="mi">0</span><span class="p">],</span>
       <span class="p">[</span><span class="mi">0</span><span class="p">,</span> <span class="mi">1</span><span class="p">,</span> <span class="mi">1</span><span class="p">,</span> <span class="mi">1</span><span class="p">]])</span>
</code></pre></div>

</details>
<h3 id="get_item">get_item<a class="headerlink" href="#get_item" title="Permanent link">&para;</a></h3>
<details class="note" open="open"><summary>method get_item</summary><div class="highlight"><pre><span></span><code><span class="k">val</span> <span class="n">get_item</span> <span class="o">:</span>
  <span class="n">key</span><span class="o">:</span><span class="nn">Py</span><span class="p">.</span><span class="nn">Object</span><span class="p">.</span><span class="n">t</span> <span class="o">-&gt;</span>
  <span class="o">[&gt;</span> <span class="n">tag</span><span class="o">]</span> <span class="nn">Obj</span><span class="p">.</span><span class="n">t</span> <span class="o">-&gt;</span>
  <span class="nn">Py</span><span class="p">.</span><span class="nn">Object</span><span class="p">.</span><span class="n">t</span>
</code></pre></div>

</details>
<h3 id="iter">iter<a class="headerlink" href="#iter" title="Permanent link">&para;</a></h3>
<details class="note" open="open"><summary>method iter</summary><div class="highlight"><pre><span></span><code><span class="k">val</span> <span class="n">iter</span> <span class="o">:</span>
  <span class="o">[&gt;</span> <span class="n">tag</span><span class="o">]</span> <span class="nn">Obj</span><span class="p">.</span><span class="n">t</span> <span class="o">-&gt;</span>
  <span class="nn">Dict</span><span class="p">.</span><span class="n">t</span> <span class="nn">Seq</span><span class="p">.</span><span class="n">t</span>
</code></pre></div>

</details>
<h3 id="setitem"><strong>setitem</strong><a class="headerlink" href="#setitem" title="Permanent link">&para;</a></h3>
<details class="note" open="open"><summary>method <strong>setitem</strong></summary><div class="highlight"><pre><span></span><code><span class="k">val</span> <span class="o">__</span><span class="n">setitem__</span> <span class="o">:</span>
  <span class="n">key</span><span class="o">:</span><span class="nn">Py</span><span class="p">.</span><span class="nn">Object</span><span class="p">.</span><span class="n">t</span> <span class="o">-&gt;</span>
  <span class="n">x</span><span class="o">:</span><span class="nn">Py</span><span class="p">.</span><span class="nn">Object</span><span class="p">.</span><span class="n">t</span> <span class="o">-&gt;</span>
  <span class="o">[&gt;</span> <span class="n">tag</span><span class="o">]</span> <span class="nn">Obj</span><span class="p">.</span><span class="n">t</span> <span class="o">-&gt;</span>
  <span class="nn">Py</span><span class="p">.</span><span class="nn">Object</span><span class="p">.</span><span class="n">t</span>
</code></pre></div>

</details>
<h3 id="arcsin">arcsin<a class="headerlink" href="#arcsin" title="Permanent link">&para;</a></h3>
<details class="note" open="open"><summary>method arcsin</summary><div class="highlight"><pre><span></span><code><span class="k">val</span> <span class="n">arcsin</span> <span class="o">:</span>
  <span class="o">[&gt;</span> <span class="n">tag</span><span class="o">]</span> <span class="nn">Obj</span><span class="p">.</span><span class="n">t</span> <span class="o">-&gt;</span>
  <span class="nn">Py</span><span class="p">.</span><span class="nn">Object</span><span class="p">.</span><span class="n">t</span>
</code></pre></div>

<p>Element-wise arcsin.</p>
<p>See <code>numpy.arcsin</code> for more information.</p>
</details>
<h3 id="arcsinh">arcsinh<a class="headerlink" href="#arcsinh" title="Permanent link">&para;</a></h3>
<details class="note" open="open"><summary>method arcsinh</summary><div class="highlight"><pre><span></span><code><span class="k">val</span> <span class="n">arcsinh</span> <span class="o">:</span>
  <span class="o">[&gt;</span> <span class="n">tag</span><span class="o">]</span> <span class="nn">Obj</span><span class="p">.</span><span class="n">t</span> <span class="o">-&gt;</span>
  <span class="nn">Py</span><span class="p">.</span><span class="nn">Object</span><span class="p">.</span><span class="n">t</span>
</code></pre></div>

<p>Element-wise arcsinh.</p>
<p>See <code>numpy.arcsinh</code> for more information.</p>
</details>
<h3 id="arctan">arctan<a class="headerlink" href="#arctan" title="Permanent link">&para;</a></h3>
<details class="note" open="open"><summary>method arctan</summary><div class="highlight"><pre><span></span><code><span class="k">val</span> <span class="n">arctan</span> <span class="o">:</span>
  <span class="o">[&gt;</span> <span class="n">tag</span><span class="o">]</span> <span class="nn">Obj</span><span class="p">.</span><span class="n">t</span> <span class="o">-&gt;</span>
  <span class="nn">Py</span><span class="p">.</span><span class="nn">Object</span><span class="p">.</span><span class="n">t</span>
</code></pre></div>

<p>Element-wise arctan.</p>
<p>See <code>numpy.arctan</code> for more information.</p>
</details>
<h3 id="arctanh">arctanh<a class="headerlink" href="#arctanh" title="Permanent link">&para;</a></h3>
<details class="note" open="open"><summary>method arctanh</summary><div class="highlight"><pre><span></span><code><span class="k">val</span> <span class="n">arctanh</span> <span class="o">:</span>
  <span class="o">[&gt;</span> <span class="n">tag</span><span class="o">]</span> <span class="nn">Obj</span><span class="p">.</span><span class="n">t</span> <span class="o">-&gt;</span>
  <span class="nn">Py</span><span class="p">.</span><span class="nn">Object</span><span class="p">.</span><span class="n">t</span>
</code></pre></div>

<p>Element-wise arctanh.</p>
<p>See <code>numpy.arctanh</code> for more information.</p>
</details>
<h3 id="argmax">argmax<a class="headerlink" href="#argmax" title="Permanent link">&para;</a></h3>
<details class="note" open="open"><summary>method argmax</summary><div class="highlight"><pre><span></span><code><span class="k">val</span> <span class="n">argmax</span> <span class="o">:</span>
  <span class="o">?</span><span class="n">axis</span><span class="o">:[`</span><span class="nc">One</span> <span class="o">|</span> <span class="o">`</span><span class="nc">Zero</span> <span class="o">|</span> <span class="o">`</span><span class="nc">PyObject</span> <span class="k">of</span> <span class="nn">Py</span><span class="p">.</span><span class="nn">Object</span><span class="p">.</span><span class="n">t</span><span class="o">]</span> <span class="o">-&gt;</span>
  <span class="o">?</span><span class="n">out</span><span class="o">:</span><span class="nn">Py</span><span class="p">.</span><span class="nn">Object</span><span class="p">.</span><span class="n">t</span> <span class="o">-&gt;</span>
  <span class="o">[&gt;</span> <span class="n">tag</span><span class="o">]</span> <span class="nn">Obj</span><span class="p">.</span><span class="n">t</span> <span class="o">-&gt;</span>
  <span class="nn">Py</span><span class="p">.</span><span class="nn">Object</span><span class="p">.</span><span class="n">t</span>
</code></pre></div>

<p>Return indices of maximum elements along an axis.</p>
<p>Implicit zero elements are also taken into account. If there are
several maximum values, the index of the first occurrence is returned.</p>
<h4>Parameters</h4>
<ul>
<li>
<p><strong>axis : {-2, -1, 0, 1, None}, optional</strong>
    Axis along which the argmax is computed. If None (default), index
    of the maximum element in the flatten data is returned.</p>
</li>
<li>
<p><strong>out : None, optional</strong>
    This argument is in the signature <em>solely</em> for NumPy
    compatibility reasons. Do not pass in anything except for
    the default value, as this argument is not used.</p>
</li>
</ul>
<h4>Returns</h4>
<ul>
<li><strong>ind : numpy.matrix or int</strong>
    Indices of maximum elements. If matrix, its size along <code>axis</code> is 1.</li>
</ul>
</details>
<h3 id="argmin">argmin<a class="headerlink" href="#argmin" title="Permanent link">&para;</a></h3>
<details class="note" open="open"><summary>method argmin</summary><div class="highlight"><pre><span></span><code><span class="k">val</span> <span class="n">argmin</span> <span class="o">:</span>
  <span class="o">?</span><span class="n">axis</span><span class="o">:[`</span><span class="nc">One</span> <span class="o">|</span> <span class="o">`</span><span class="nc">Zero</span> <span class="o">|</span> <span class="o">`</span><span class="nc">PyObject</span> <span class="k">of</span> <span class="nn">Py</span><span class="p">.</span><span class="nn">Object</span><span class="p">.</span><span class="n">t</span><span class="o">]</span> <span class="o">-&gt;</span>
  <span class="o">?</span><span class="n">out</span><span class="o">:</span><span class="nn">Py</span><span class="p">.</span><span class="nn">Object</span><span class="p">.</span><span class="n">t</span> <span class="o">-&gt;</span>
  <span class="o">[&gt;</span> <span class="n">tag</span><span class="o">]</span> <span class="nn">Obj</span><span class="p">.</span><span class="n">t</span> <span class="o">-&gt;</span>
  <span class="nn">Py</span><span class="p">.</span><span class="nn">Object</span><span class="p">.</span><span class="n">t</span>
</code></pre></div>

<p>Return indices of minimum elements along an axis.</p>
<p>Implicit zero elements are also taken into account. If there are
several minimum values, the index of the first occurrence is returned.</p>
<h4>Parameters</h4>
<ul>
<li>
<p><strong>axis : {-2, -1, 0, 1, None}, optional</strong>
    Axis along which the argmin is computed. If None (default), index
    of the minimum element in the flatten data is returned.</p>
</li>
<li>
<p><strong>out : None, optional</strong>
    This argument is in the signature <em>solely</em> for NumPy
    compatibility reasons. Do not pass in anything except for
    the default value, as this argument is not used.</p>
</li>
</ul>
<h4>Returns</h4>
<ul>
<li><strong>ind : numpy.matrix or int</strong>
    Indices of minimum elements. If matrix, its size along <code>axis</code> is 1.</li>
</ul>
</details>
<h3 id="asformat">asformat<a class="headerlink" href="#asformat" title="Permanent link">&para;</a></h3>
<details class="note" open="open"><summary>method asformat</summary><div class="highlight"><pre><span></span><code><span class="k">val</span> <span class="n">asformat</span> <span class="o">:</span>
  <span class="o">?</span><span class="n">copy</span><span class="o">:</span><span class="kt">bool</span> <span class="o">-&gt;</span>
  <span class="n">format</span><span class="o">:[`</span><span class="nc">S</span> <span class="k">of</span> <span class="kt">string</span> <span class="o">|</span> <span class="o">`</span><span class="nc">None</span><span class="o">]</span> <span class="o">-&gt;</span>
  <span class="o">[&gt;</span> <span class="n">tag</span><span class="o">]</span> <span class="nn">Obj</span><span class="p">.</span><span class="n">t</span> <span class="o">-&gt;</span>
  <span class="nn">Py</span><span class="p">.</span><span class="nn">Object</span><span class="p">.</span><span class="n">t</span>
</code></pre></div>

<p>Return this matrix in the passed format.</p>
<h4>Parameters</h4>
<ul>
<li>
<p><strong>format : {str, None}</strong>
    The desired matrix format ('csr', 'csc', 'lil', 'dok', 'array', ...)
    or None for no conversion.</p>
</li>
<li>
<p><strong>copy : bool, optional</strong>
    If True, the result is guaranteed to not share data with self.</p>
</li>
</ul>
<h4>Returns</h4>
<ul>
<li><strong>A : This matrix in the passed format.</strong></li>
</ul>
</details>
<h3 id="asfptype">asfptype<a class="headerlink" href="#asfptype" title="Permanent link">&para;</a></h3>
<details class="note" open="open"><summary>method asfptype</summary><div class="highlight"><pre><span></span><code><span class="k">val</span> <span class="n">asfptype</span> <span class="o">:</span>
  <span class="o">[&gt;</span> <span class="n">tag</span><span class="o">]</span> <span class="nn">Obj</span><span class="p">.</span><span class="n">t</span> <span class="o">-&gt;</span>
  <span class="nn">Py</span><span class="p">.</span><span class="nn">Object</span><span class="p">.</span><span class="n">t</span>
</code></pre></div>

<p>Upcast matrix to a floating point format (if necessary)</p>
</details>
<h3 id="astype">astype<a class="headerlink" href="#astype" title="Permanent link">&para;</a></h3>
<details class="note" open="open"><summary>method astype</summary><div class="highlight"><pre><span></span><code><span class="k">val</span> <span class="n">astype</span> <span class="o">:</span>
  <span class="o">?</span><span class="n">casting</span><span class="o">:[`</span><span class="nc">No</span> <span class="o">|</span> <span class="o">`</span><span class="nc">Equiv</span> <span class="o">|</span> <span class="o">`</span><span class="nc">Safe</span> <span class="o">|</span> <span class="o">`</span><span class="nc">Same_kind</span> <span class="o">|</span> <span class="o">`</span><span class="nc">Unsafe</span><span class="o">]</span> <span class="o">-&gt;</span>
  <span class="o">?</span><span class="n">copy</span><span class="o">:</span><span class="kt">bool</span> <span class="o">-&gt;</span>
  <span class="n">dtype</span><span class="o">:[`</span><span class="nc">S</span> <span class="k">of</span> <span class="kt">string</span> <span class="o">|</span> <span class="o">`</span><span class="nc">Dtype</span> <span class="k">of</span> <span class="nn">Np</span><span class="p">.</span><span class="nn">Dtype</span><span class="p">.</span><span class="n">t</span><span class="o">]</span> <span class="o">-&gt;</span>
  <span class="o">[&gt;</span> <span class="n">tag</span><span class="o">]</span> <span class="nn">Obj</span><span class="p">.</span><span class="n">t</span> <span class="o">-&gt;</span>
  <span class="nn">Py</span><span class="p">.</span><span class="nn">Object</span><span class="p">.</span><span class="n">t</span>
</code></pre></div>

<p>Cast the matrix elements to a specified type.</p>
<h4>Parameters</h4>
<ul>
<li>
<p><strong>dtype : string or numpy dtype</strong>
    Typecode or data-type to which to cast the data.</p>
</li>
<li>
<p><strong>casting : {'no', 'equiv', 'safe', 'same_kind', 'unsafe'}, optional</strong>
    Controls what kind of data casting may occur.
    Defaults to 'unsafe' for backwards compatibility.
    'no' means the data types should not be cast at all.
    'equiv' means only byte-order changes are allowed.
    'safe' means only casts which can preserve values are allowed.
    'same_kind' means only safe casts or casts within a kind,
    like float64 to float32, are allowed.
    'unsafe' means any data conversions may be done.</p>
</li>
<li>
<p><strong>copy : bool, optional</strong>
    If <code>copy</code> is <code>False</code>, the result might share some memory with this
    matrix. If <code>copy</code> is <code>True</code>, it is guaranteed that the result and
    this matrix do not share any memory.</p>
</li>
</ul>
</details>
<h3 id="ceil">ceil<a class="headerlink" href="#ceil" title="Permanent link">&para;</a></h3>
<details class="note" open="open"><summary>method ceil</summary><div class="highlight"><pre><span></span><code><span class="k">val</span> <span class="n">ceil</span> <span class="o">:</span>
  <span class="o">[&gt;</span> <span class="n">tag</span><span class="o">]</span> <span class="nn">Obj</span><span class="p">.</span><span class="n">t</span> <span class="o">-&gt;</span>
  <span class="nn">Py</span><span class="p">.</span><span class="nn">Object</span><span class="p">.</span><span class="n">t</span>
</code></pre></div>

<p>Element-wise ceil.</p>
<p>See <code>numpy.ceil</code> for more information.</p>
</details>
<h3 id="check_format">check_format<a class="headerlink" href="#check_format" title="Permanent link">&para;</a></h3>
<details class="note" open="open"><summary>method check_format</summary><div class="highlight"><pre><span></span><code><span class="k">val</span> <span class="n">check_format</span> <span class="o">:</span>
  <span class="o">?</span><span class="n">full_check</span><span class="o">:</span><span class="kt">bool</span> <span class="o">-&gt;</span>
  <span class="o">[&gt;</span> <span class="n">tag</span><span class="o">]</span> <span class="nn">Obj</span><span class="p">.</span><span class="n">t</span> <span class="o">-&gt;</span>
  <span class="nn">Py</span><span class="p">.</span><span class="nn">Object</span><span class="p">.</span><span class="n">t</span>
</code></pre></div>

<p>check whether the matrix format is valid</p>
<h4>Parameters</h4>
<ul>
<li><strong>full_check : bool, optional</strong>
    If <code>True</code>, rigorous check, O(N) operations. Otherwise
    basic check, O(1) operations (default True).</li>
</ul>
</details>
<h3 id="conj">conj<a class="headerlink" href="#conj" title="Permanent link">&para;</a></h3>
<details class="note" open="open"><summary>method conj</summary><div class="highlight"><pre><span></span><code><span class="k">val</span> <span class="n">conj</span> <span class="o">:</span>
  <span class="o">?</span><span class="n">copy</span><span class="o">:</span><span class="kt">bool</span> <span class="o">-&gt;</span>
  <span class="o">[&gt;</span> <span class="n">tag</span><span class="o">]</span> <span class="nn">Obj</span><span class="p">.</span><span class="n">t</span> <span class="o">-&gt;</span>
  <span class="nn">Py</span><span class="p">.</span><span class="nn">Object</span><span class="p">.</span><span class="n">t</span>
</code></pre></div>

<p>Element-wise complex conjugation.</p>
<p>If the matrix is of non-complex data type and <code>copy</code> is False,
this method does nothing and the data is not copied.</p>
<h4>Parameters</h4>
<ul>
<li><strong>copy : bool, optional</strong>
    If True, the result is guaranteed to not share data with self.</li>
</ul>
<h4>Returns</h4>
<ul>
<li><strong>A : The element-wise complex conjugate.</strong></li>
</ul>
</details>
<h3 id="conjugate">conjugate<a class="headerlink" href="#conjugate" title="Permanent link">&para;</a></h3>
<details class="note" open="open"><summary>method conjugate</summary><div class="highlight"><pre><span></span><code><span class="k">val</span> <span class="n">conjugate</span> <span class="o">:</span>
  <span class="o">?</span><span class="n">copy</span><span class="o">:</span><span class="kt">bool</span> <span class="o">-&gt;</span>
  <span class="o">[&gt;</span> <span class="n">tag</span><span class="o">]</span> <span class="nn">Obj</span><span class="p">.</span><span class="n">t</span> <span class="o">-&gt;</span>
  <span class="nn">Py</span><span class="p">.</span><span class="nn">Object</span><span class="p">.</span><span class="n">t</span>
</code></pre></div>

<p>Element-wise complex conjugation.</p>
<p>If the matrix is of non-complex data type and <code>copy</code> is False,
this method does nothing and the data is not copied.</p>
<h4>Parameters</h4>
<ul>
<li><strong>copy : bool, optional</strong>
    If True, the result is guaranteed to not share data with self.</li>
</ul>
<h4>Returns</h4>
<ul>
<li><strong>A : The element-wise complex conjugate.</strong></li>
</ul>
</details>
<h3 id="copy">copy<a class="headerlink" href="#copy" title="Permanent link">&para;</a></h3>
<details class="note" open="open"><summary>method copy</summary><div class="highlight"><pre><span></span><code><span class="k">val</span> <span class="n">copy</span> <span class="o">:</span>
  <span class="o">[&gt;</span> <span class="n">tag</span><span class="o">]</span> <span class="nn">Obj</span><span class="p">.</span><span class="n">t</span> <span class="o">-&gt;</span>
  <span class="nn">Py</span><span class="p">.</span><span class="nn">Object</span><span class="p">.</span><span class="n">t</span>
</code></pre></div>

<p>Returns a copy of this matrix.</p>
<p>No data/indices will be shared between the returned value and current
matrix.</p>
</details>
<h3 id="count_nonzero">count_nonzero<a class="headerlink" href="#count_nonzero" title="Permanent link">&para;</a></h3>
<details class="note" open="open"><summary>method count_nonzero</summary><div class="highlight"><pre><span></span><code><span class="k">val</span> <span class="n">count_nonzero</span> <span class="o">:</span>
  <span class="o">[&gt;</span> <span class="n">tag</span><span class="o">]</span> <span class="nn">Obj</span><span class="p">.</span><span class="n">t</span> <span class="o">-&gt;</span>
  <span class="nn">Py</span><span class="p">.</span><span class="nn">Object</span><span class="p">.</span><span class="n">t</span>
</code></pre></div>

<p>Number of non-zero entries, equivalent to</p>
<p>np.count_nonzero(a.toarray())</p>
<p>Unlike getnnz() and the nnz property, which return the number of stored
entries (the length of the data attribute), this method counts the
actual number of non-zero entries in data.</p>
</details>
<h3 id="deg2rad">deg2rad<a class="headerlink" href="#deg2rad" title="Permanent link">&para;</a></h3>
<details class="note" open="open"><summary>method deg2rad</summary><div class="highlight"><pre><span></span><code><span class="k">val</span> <span class="n">deg2rad</span> <span class="o">:</span>
  <span class="o">[&gt;</span> <span class="n">tag</span><span class="o">]</span> <span class="nn">Obj</span><span class="p">.</span><span class="n">t</span> <span class="o">-&gt;</span>
  <span class="nn">Py</span><span class="p">.</span><span class="nn">Object</span><span class="p">.</span><span class="n">t</span>
</code></pre></div>

<p>Element-wise deg2rad.</p>
<p>See <code>numpy.deg2rad</code> for more information.</p>
</details>
<h3 id="diagonal">diagonal<a class="headerlink" href="#diagonal" title="Permanent link">&para;</a></h3>
<details class="note" open="open"><summary>method diagonal</summary><div class="highlight"><pre><span></span><code><span class="k">val</span> <span class="n">diagonal</span> <span class="o">:</span>
  <span class="o">?</span><span class="n">k</span><span class="o">:</span><span class="kt">int</span> <span class="o">-&gt;</span>
  <span class="o">[&gt;</span> <span class="n">tag</span><span class="o">]</span> <span class="nn">Obj</span><span class="p">.</span><span class="n">t</span> <span class="o">-&gt;</span>
  <span class="nn">Py</span><span class="p">.</span><span class="nn">Object</span><span class="p">.</span><span class="n">t</span>
</code></pre></div>

<p>Returns the kth diagonal of the matrix.</p>
<h4>Parameters</h4>
<ul>
<li>
<p><strong>k : int, optional</strong>
    Which diagonal to get, corresponding to elements a[i, i+k].</p>
</li>
<li>
<p><strong>Default: 0 (the main diagonal).</strong></p>
<p>.. versionadded:: 1.0</p>
</li>
</ul>
<h4>See also</h4>
<ul>
<li><strong>numpy.diagonal : Equivalent numpy function.</strong></li>
</ul>
<h4>Examples</h4>
<div class="highlight"><pre><span></span><code><span class="o">&gt;&gt;&gt;</span> <span class="kn">from</span> <span class="nn">scipy.sparse</span> <span class="kn">import</span> <span class="n">csr_matrix</span>
<span class="o">&gt;&gt;&gt;</span> <span class="n">A</span> <span class="o">=</span> <span class="n">csr_matrix</span><span class="p">([[</span><span class="mi">1</span><span class="p">,</span> <span class="mi">2</span><span class="p">,</span> <span class="mi">0</span><span class="p">],</span> <span class="p">[</span><span class="mi">0</span><span class="p">,</span> <span class="mi">0</span><span class="p">,</span> <span class="mi">3</span><span class="p">],</span> <span class="p">[</span><span class="mi">4</span><span class="p">,</span> <span class="mi">0</span><span class="p">,</span> <span class="mi">5</span><span class="p">]])</span>
<span class="o">&gt;&gt;&gt;</span> <span class="n">A</span><span class="o">.</span><span class="n">diagonal</span><span class="p">()</span>
<span class="n">array</span><span class="p">([</span><span class="mi">1</span><span class="p">,</span> <span class="mi">0</span><span class="p">,</span> <span class="mi">5</span><span class="p">])</span>
<span class="o">&gt;&gt;&gt;</span> <span class="n">A</span><span class="o">.</span><span class="n">diagonal</span><span class="p">(</span><span class="n">k</span><span class="o">=</span><span class="mi">1</span><span class="p">)</span>
<span class="n">array</span><span class="p">([</span><span class="mi">2</span><span class="p">,</span> <span class="mi">3</span><span class="p">])</span>
</code></pre></div>

</details>
<h3 id="dot">dot<a class="headerlink" href="#dot" title="Permanent link">&para;</a></h3>
<details class="note" open="open"><summary>method dot</summary><div class="highlight"><pre><span></span><code><span class="k">val</span> <span class="n">dot</span> <span class="o">:</span>
  <span class="n">other</span><span class="o">:</span><span class="nn">Py</span><span class="p">.</span><span class="nn">Object</span><span class="p">.</span><span class="n">t</span> <span class="o">-&gt;</span>
  <span class="o">[&gt;</span> <span class="n">tag</span><span class="o">]</span> <span class="nn">Obj</span><span class="p">.</span><span class="n">t</span> <span class="o">-&gt;</span>
  <span class="nn">Py</span><span class="p">.</span><span class="nn">Object</span><span class="p">.</span><span class="n">t</span>
</code></pre></div>

<p>Ordinary dot product</p>
<h4>Examples</h4>
<div class="highlight"><pre><span></span><code><span class="o">&gt;&gt;&gt;</span> <span class="kn">import</span> <span class="nn">numpy</span> <span class="k">as</span> <span class="nn">np</span>
<span class="o">&gt;&gt;&gt;</span> <span class="kn">from</span> <span class="nn">scipy.sparse</span> <span class="kn">import</span> <span class="n">csr_matrix</span>
<span class="o">&gt;&gt;&gt;</span> <span class="n">A</span> <span class="o">=</span> <span class="n">csr_matrix</span><span class="p">([[</span><span class="mi">1</span><span class="p">,</span> <span class="mi">2</span><span class="p">,</span> <span class="mi">0</span><span class="p">],</span> <span class="p">[</span><span class="mi">0</span><span class="p">,</span> <span class="mi">0</span><span class="p">,</span> <span class="mi">3</span><span class="p">],</span> <span class="p">[</span><span class="mi">4</span><span class="p">,</span> <span class="mi">0</span><span class="p">,</span> <span class="mi">5</span><span class="p">]])</span>
<span class="o">&gt;&gt;&gt;</span> <span class="n">v</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">array</span><span class="p">([</span><span class="mi">1</span><span class="p">,</span> <span class="mi">0</span><span class="p">,</span> <span class="o">-</span><span class="mi">1</span><span class="p">])</span>
<span class="o">&gt;&gt;&gt;</span> <span class="n">A</span><span class="o">.</span><span class="n">dot</span><span class="p">(</span><span class="n">v</span><span class="p">)</span>
<span class="n">array</span><span class="p">([</span> <span class="mi">1</span><span class="p">,</span> <span class="o">-</span><span class="mi">3</span><span class="p">,</span> <span class="o">-</span><span class="mi">1</span><span class="p">],</span> <span class="n">dtype</span><span class="o">=</span><span class="n">int64</span><span class="p">)</span>
</code></pre></div>

</details>
<h3 id="eliminate_zeros">eliminate_zeros<a class="headerlink" href="#eliminate_zeros" title="Permanent link">&para;</a></h3>
<details class="note" open="open"><summary>method eliminate_zeros</summary><div class="highlight"><pre><span></span><code><span class="k">val</span> <span class="n">eliminate_zeros</span> <span class="o">:</span>
  <span class="o">[&gt;</span> <span class="n">tag</span><span class="o">]</span> <span class="nn">Obj</span><span class="p">.</span><span class="n">t</span> <span class="o">-&gt;</span>
  <span class="nn">Py</span><span class="p">.</span><span class="nn">Object</span><span class="p">.</span><span class="n">t</span>
</code></pre></div>

<p>Remove zero entries from the matrix</p>
<p>This is an <em>in place</em> operation</p>
</details>
<h3 id="expm1">expm1<a class="headerlink" href="#expm1" title="Permanent link">&para;</a></h3>
<details class="note" open="open"><summary>method expm1</summary><div class="highlight"><pre><span></span><code><span class="k">val</span> <span class="n">expm1</span> <span class="o">:</span>
  <span class="o">[&gt;</span> <span class="n">tag</span><span class="o">]</span> <span class="nn">Obj</span><span class="p">.</span><span class="n">t</span> <span class="o">-&gt;</span>
  <span class="nn">Py</span><span class="p">.</span><span class="nn">Object</span><span class="p">.</span><span class="n">t</span>
</code></pre></div>

<p>Element-wise expm1.</p>
<p>See <code>numpy.expm1</code> for more information.</p>
</details>
<h3 id="floor">floor<a class="headerlink" href="#floor" title="Permanent link">&para;</a></h3>
<details class="note" open="open"><summary>method floor</summary><div class="highlight"><pre><span></span><code><span class="k">val</span> <span class="n">floor</span> <span class="o">:</span>
  <span class="o">[&gt;</span> <span class="n">tag</span><span class="o">]</span> <span class="nn">Obj</span><span class="p">.</span><span class="n">t</span> <span class="o">-&gt;</span>
  <span class="nn">Py</span><span class="p">.</span><span class="nn">Object</span><span class="p">.</span><span class="n">t</span>
</code></pre></div>

<p>Element-wise floor.</p>
<p>See <code>numpy.floor</code> for more information.</p>
</details>
<h3 id="geth">getH<a class="headerlink" href="#geth" title="Permanent link">&para;</a></h3>
<details class="note" open="open"><summary>method getH</summary><div class="highlight"><pre><span></span><code><span class="k">val</span> <span class="n">getH</span> <span class="o">:</span>
  <span class="o">[&gt;</span> <span class="n">tag</span><span class="o">]</span> <span class="nn">Obj</span><span class="p">.</span><span class="n">t</span> <span class="o">-&gt;</span>
  <span class="nn">Py</span><span class="p">.</span><span class="nn">Object</span><span class="p">.</span><span class="n">t</span>
</code></pre></div>

<p>Return the Hermitian transpose of this matrix.</p>
<h4>See Also</h4>
<ul>
<li><strong>numpy.matrix.getH : NumPy's implementation of <code>getH</code> for matrices</strong></li>
</ul>
</details>
<h3 id="get_shape">get_shape<a class="headerlink" href="#get_shape" title="Permanent link">&para;</a></h3>
<details class="note" open="open"><summary>method get_shape</summary><div class="highlight"><pre><span></span><code><span class="k">val</span> <span class="n">get_shape</span> <span class="o">:</span>
  <span class="o">[&gt;</span> <span class="n">tag</span><span class="o">]</span> <span class="nn">Obj</span><span class="p">.</span><span class="n">t</span> <span class="o">-&gt;</span>
  <span class="nn">Py</span><span class="p">.</span><span class="nn">Object</span><span class="p">.</span><span class="n">t</span>
</code></pre></div>

<p>Get shape of a matrix.</p>
</details>
<h3 id="getcol">getcol<a class="headerlink" href="#getcol" title="Permanent link">&para;</a></h3>
<details class="note" open="open"><summary>method getcol</summary><div class="highlight"><pre><span></span><code><span class="k">val</span> <span class="n">getcol</span> <span class="o">:</span>
  <span class="n">i</span><span class="o">:</span><span class="nn">Py</span><span class="p">.</span><span class="nn">Object</span><span class="p">.</span><span class="n">t</span> <span class="o">-&gt;</span>
  <span class="o">[&gt;</span> <span class="n">tag</span><span class="o">]</span> <span class="nn">Obj</span><span class="p">.</span><span class="n">t</span> <span class="o">-&gt;</span>
  <span class="nn">Py</span><span class="p">.</span><span class="nn">Object</span><span class="p">.</span><span class="n">t</span>
</code></pre></div>

<p>Returns a copy of column i of the matrix, as a (m x 1)
CSR matrix (column vector).</p>
</details>
<h3 id="getformat">getformat<a class="headerlink" href="#getformat" title="Permanent link">&para;</a></h3>
<details class="note" open="open"><summary>method getformat</summary><div class="highlight"><pre><span></span><code><span class="k">val</span> <span class="n">getformat</span> <span class="o">:</span>
  <span class="o">[&gt;</span> <span class="n">tag</span><span class="o">]</span> <span class="nn">Obj</span><span class="p">.</span><span class="n">t</span> <span class="o">-&gt;</span>
  <span class="nn">Py</span><span class="p">.</span><span class="nn">Object</span><span class="p">.</span><span class="n">t</span>
</code></pre></div>

<p>Format of a matrix representation as a string.</p>
</details>
<h3 id="getmaxprint">getmaxprint<a class="headerlink" href="#getmaxprint" title="Permanent link">&para;</a></h3>
<details class="note" open="open"><summary>method getmaxprint</summary><div class="highlight"><pre><span></span><code><span class="k">val</span> <span class="n">getmaxprint</span> <span class="o">:</span>
  <span class="o">[&gt;</span> <span class="n">tag</span><span class="o">]</span> <span class="nn">Obj</span><span class="p">.</span><span class="n">t</span> <span class="o">-&gt;</span>
  <span class="nn">Py</span><span class="p">.</span><span class="nn">Object</span><span class="p">.</span><span class="n">t</span>
</code></pre></div>

<p>Maximum number of elements to display when printed.</p>
</details>
<h3 id="getnnz">getnnz<a class="headerlink" href="#getnnz" title="Permanent link">&para;</a></h3>
<details class="note" open="open"><summary>method getnnz</summary><div class="highlight"><pre><span></span><code><span class="k">val</span> <span class="n">getnnz</span> <span class="o">:</span>
  <span class="o">?</span><span class="n">axis</span><span class="o">:[`</span><span class="nc">Zero</span> <span class="o">|</span> <span class="o">`</span><span class="nc">One</span><span class="o">]</span> <span class="o">-&gt;</span>
  <span class="o">[&gt;</span> <span class="n">tag</span><span class="o">]</span> <span class="nn">Obj</span><span class="p">.</span><span class="n">t</span> <span class="o">-&gt;</span>
  <span class="nn">Py</span><span class="p">.</span><span class="nn">Object</span><span class="p">.</span><span class="n">t</span>
</code></pre></div>

<p>Number of stored values, including explicit zeros.</p>
<h4>Parameters</h4>
<ul>
<li><strong>axis : None, 0, or 1</strong>
    Select between the number of values across the whole matrix, in
    each column, or in each row.</li>
</ul>
<h4>See also</h4>
<ul>
<li><strong>count_nonzero : Number of non-zero entries</strong></li>
</ul>
</details>
<h3 id="getrow">getrow<a class="headerlink" href="#getrow" title="Permanent link">&para;</a></h3>
<details class="note" open="open"><summary>method getrow</summary><div class="highlight"><pre><span></span><code><span class="k">val</span> <span class="n">getrow</span> <span class="o">:</span>
  <span class="n">i</span><span class="o">:</span><span class="nn">Py</span><span class="p">.</span><span class="nn">Object</span><span class="p">.</span><span class="n">t</span> <span class="o">-&gt;</span>
  <span class="o">[&gt;</span> <span class="n">tag</span><span class="o">]</span> <span class="nn">Obj</span><span class="p">.</span><span class="n">t</span> <span class="o">-&gt;</span>
  <span class="nn">Py</span><span class="p">.</span><span class="nn">Object</span><span class="p">.</span><span class="n">t</span>
</code></pre></div>

<p>Returns a copy of row i of the matrix, as a (1 x n)
CSR matrix (row vector).</p>
</details>
<h3 id="log1p">log1p<a class="headerlink" href="#log1p" title="Permanent link">&para;</a></h3>
<details class="note" open="open"><summary>method log1p</summary><div class="highlight"><pre><span></span><code><span class="k">val</span> <span class="n">log1p</span> <span class="o">:</span>
  <span class="o">[&gt;</span> <span class="n">tag</span><span class="o">]</span> <span class="nn">Obj</span><span class="p">.</span><span class="n">t</span> <span class="o">-&gt;</span>
  <span class="nn">Py</span><span class="p">.</span><span class="nn">Object</span><span class="p">.</span><span class="n">t</span>
</code></pre></div>

<p>Element-wise log1p.</p>
<p>See <code>numpy.log1p</code> for more information.</p>
</details>
<h3 id="max">max<a class="headerlink" href="#max" title="Permanent link">&para;</a></h3>
<details class="note" open="open"><summary>method max</summary><div class="highlight"><pre><span></span><code><span class="k">val</span> <span class="n">max</span> <span class="o">:</span>
  <span class="o">?</span><span class="n">axis</span><span class="o">:[`</span><span class="nc">One</span> <span class="o">|</span> <span class="o">`</span><span class="nc">Zero</span> <span class="o">|</span> <span class="o">`</span><span class="nc">PyObject</span> <span class="k">of</span> <span class="nn">Py</span><span class="p">.</span><span class="nn">Object</span><span class="p">.</span><span class="n">t</span><span class="o">]</span> <span class="o">-&gt;</span>
  <span class="o">?</span><span class="n">out</span><span class="o">:</span><span class="nn">Py</span><span class="p">.</span><span class="nn">Object</span><span class="p">.</span><span class="n">t</span> <span class="o">-&gt;</span>
  <span class="o">[&gt;</span> <span class="n">tag</span><span class="o">]</span> <span class="nn">Obj</span><span class="p">.</span><span class="n">t</span> <span class="o">-&gt;</span>
  <span class="nn">Py</span><span class="p">.</span><span class="nn">Object</span><span class="p">.</span><span class="n">t</span>
</code></pre></div>

<p>Return the maximum of the matrix or maximum along an axis.
This takes all elements into account, not just the non-zero ones.</p>
<h4>Parameters</h4>
<ul>
<li>
<p><strong>axis : {-2, -1, 0, 1, None} optional</strong>
    Axis along which the sum is computed. The default is to
    compute the maximum over all the matrix elements, returning
    a scalar (i.e., <code>axis</code> = <code>None</code>).</p>
</li>
<li>
<p><strong>out : None, optional</strong>
    This argument is in the signature <em>solely</em> for NumPy
    compatibility reasons. Do not pass in anything except
    for the default value, as this argument is not used.</p>
</li>
</ul>
<h4>Returns</h4>
<ul>
<li><strong>amax : coo_matrix or scalar</strong>
    Maximum of <code>a</code>. If <code>axis</code> is None, the result is a scalar value.
    If <code>axis</code> is given, the result is a sparse.coo_matrix of dimension
    <code>a.ndim - 1</code>.</li>
</ul>
<h4>See Also</h4>
<ul>
<li>
<p><strong>min : The minimum value of a sparse matrix along a given axis.</strong></p>
</li>
<li>
<p><strong>numpy.matrix.max : NumPy's implementation of 'max' for matrices</strong></p>
</li>
</ul>
</details>
<h3 id="maximum">maximum<a class="headerlink" href="#maximum" title="Permanent link">&para;</a></h3>
<details class="note" open="open"><summary>method maximum</summary><div class="highlight"><pre><span></span><code><span class="k">val</span> <span class="n">maximum</span> <span class="o">:</span>
  <span class="n">other</span><span class="o">:</span><span class="nn">Py</span><span class="p">.</span><span class="nn">Object</span><span class="p">.</span><span class="n">t</span> <span class="o">-&gt;</span>
  <span class="o">[&gt;</span> <span class="n">tag</span><span class="o">]</span> <span class="nn">Obj</span><span class="p">.</span><span class="n">t</span> <span class="o">-&gt;</span>
  <span class="nn">Py</span><span class="p">.</span><span class="nn">Object</span><span class="p">.</span><span class="n">t</span>
</code></pre></div>

<p>Element-wise maximum between this and another matrix.</p>
</details>
<h3 id="mean">mean<a class="headerlink" href="#mean" title="Permanent link">&para;</a></h3>
<details class="note" open="open"><summary>method mean</summary><div class="highlight"><pre><span></span><code><span class="k">val</span> <span class="n">mean</span> <span class="o">:</span>
  <span class="o">?</span><span class="n">axis</span><span class="o">:[`</span><span class="nc">One</span> <span class="o">|</span> <span class="o">`</span><span class="nc">Zero</span> <span class="o">|</span> <span class="o">`</span><span class="nc">PyObject</span> <span class="k">of</span> <span class="nn">Py</span><span class="p">.</span><span class="nn">Object</span><span class="p">.</span><span class="n">t</span><span class="o">]</span> <span class="o">-&gt;</span>
  <span class="o">?</span><span class="n">dtype</span><span class="o">:</span><span class="nn">Np</span><span class="p">.</span><span class="nn">Dtype</span><span class="p">.</span><span class="n">t</span> <span class="o">-&gt;</span>
  <span class="o">?</span><span class="n">out</span><span class="o">:[&gt;`</span><span class="nc">ArrayLike</span><span class="o">]</span> <span class="nn">Np</span><span class="p">.</span><span class="nn">Obj</span><span class="p">.</span><span class="n">t</span> <span class="o">-&gt;</span>
  <span class="o">[&gt;</span> <span class="n">tag</span><span class="o">]</span> <span class="nn">Obj</span><span class="p">.</span><span class="n">t</span> <span class="o">-&gt;</span>
  <span class="o">[&gt;`</span><span class="nc">ArrayLike</span><span class="o">]</span> <span class="nn">Np</span><span class="p">.</span><span class="nn">Obj</span><span class="p">.</span><span class="n">t</span>
</code></pre></div>

<p>Compute the arithmetic mean along the specified axis.</p>
<p>Returns the average of the matrix elements. The average is taken
over all elements in the matrix by default, otherwise over the
specified axis. <code>float64</code> intermediate and return values are used
for integer inputs.</p>
<h4>Parameters</h4>
<ul>
<li>
<p><strong>axis : {-2, -1, 0, 1, None} optional</strong>
    Axis along which the mean is computed. The default is to compute
    the mean of all elements in the matrix (i.e., <code>axis</code> = <code>None</code>).</p>
</li>
<li>
<p><strong>dtype : data-type, optional</strong>
    Type to use in computing the mean. For integer inputs, the default
    is <code>float64</code>; for floating point inputs, it is the same as the
    input dtype.</p>
<p>.. versionadded:: 0.18.0</p>
</li>
<li>
<p><strong>out : np.matrix, optional</strong>
    Alternative output matrix in which to place the result. It must
    have the same shape as the expected output, but the type of the
    output values will be cast if necessary.</p>
<p>.. versionadded:: 0.18.0</p>
</li>
</ul>
<h4>Returns</h4>
<ul>
<li><strong>m : np.matrix</strong></li>
</ul>
<h4>See Also</h4>
<ul>
<li><strong>numpy.matrix.mean : NumPy's implementation of 'mean' for matrices</strong></li>
</ul>
</details>
<h3 id="min">min<a class="headerlink" href="#min" title="Permanent link">&para;</a></h3>
<details class="note" open="open"><summary>method min</summary><div class="highlight"><pre><span></span><code><span class="k">val</span> <span class="n">min</span> <span class="o">:</span>
  <span class="o">?</span><span class="n">axis</span><span class="o">:[`</span><span class="nc">One</span> <span class="o">|</span> <span class="o">`</span><span class="nc">Zero</span> <span class="o">|</span> <span class="o">`</span><span class="nc">PyObject</span> <span class="k">of</span> <span class="nn">Py</span><span class="p">.</span><span class="nn">Object</span><span class="p">.</span><span class="n">t</span><span class="o">]</span> <span class="o">-&gt;</span>
  <span class="o">?</span><span class="n">out</span><span class="o">:</span><span class="nn">Py</span><span class="p">.</span><span class="nn">Object</span><span class="p">.</span><span class="n">t</span> <span class="o">-&gt;</span>
  <span class="o">[&gt;</span> <span class="n">tag</span><span class="o">]</span> <span class="nn">Obj</span><span class="p">.</span><span class="n">t</span> <span class="o">-&gt;</span>
  <span class="nn">Py</span><span class="p">.</span><span class="nn">Object</span><span class="p">.</span><span class="n">t</span>
</code></pre></div>

<p>Return the minimum of the matrix or maximum along an axis.
This takes all elements into account, not just the non-zero ones.</p>
<h4>Parameters</h4>
<ul>
<li>
<p><strong>axis : {-2, -1, 0, 1, None} optional</strong>
    Axis along which the sum is computed. The default is to
    compute the minimum over all the matrix elements, returning
    a scalar (i.e., <code>axis</code> = <code>None</code>).</p>
</li>
<li>
<p><strong>out : None, optional</strong>
    This argument is in the signature <em>solely</em> for NumPy
    compatibility reasons. Do not pass in anything except for
    the default value, as this argument is not used.</p>
</li>
</ul>
<h4>Returns</h4>
<ul>
<li><strong>amin : coo_matrix or scalar</strong>
    Minimum of <code>a</code>. If <code>axis</code> is None, the result is a scalar value.
    If <code>axis</code> is given, the result is a sparse.coo_matrix of dimension
    <code>a.ndim - 1</code>.</li>
</ul>
<h4>See Also</h4>
<ul>
<li>
<p><strong>max : The maximum value of a sparse matrix along a given axis.</strong></p>
</li>
<li>
<p><strong>numpy.matrix.min : NumPy's implementation of 'min' for matrices</strong></p>
</li>
</ul>
</details>
<h3 id="minimum">minimum<a class="headerlink" href="#minimum" title="Permanent link">&para;</a></h3>
<details class="note" open="open"><summary>method minimum</summary><div class="highlight"><pre><span></span><code><span class="k">val</span> <span class="n">minimum</span> <span class="o">:</span>
  <span class="n">other</span><span class="o">:</span><span class="nn">Py</span><span class="p">.</span><span class="nn">Object</span><span class="p">.</span><span class="n">t</span> <span class="o">-&gt;</span>
  <span class="o">[&gt;</span> <span class="n">tag</span><span class="o">]</span> <span class="nn">Obj</span><span class="p">.</span><span class="n">t</span> <span class="o">-&gt;</span>
  <span class="nn">Py</span><span class="p">.</span><span class="nn">Object</span><span class="p">.</span><span class="n">t</span>
</code></pre></div>

<p>Element-wise minimum between this and another matrix.</p>
</details>
<h3 id="multiply">multiply<a class="headerlink" href="#multiply" title="Permanent link">&para;</a></h3>
<details class="note" open="open"><summary>method multiply</summary><div class="highlight"><pre><span></span><code><span class="k">val</span> <span class="n">multiply</span> <span class="o">:</span>
  <span class="n">other</span><span class="o">:</span><span class="nn">Py</span><span class="p">.</span><span class="nn">Object</span><span class="p">.</span><span class="n">t</span> <span class="o">-&gt;</span>
  <span class="o">[&gt;</span> <span class="n">tag</span><span class="o">]</span> <span class="nn">Obj</span><span class="p">.</span><span class="n">t</span> <span class="o">-&gt;</span>
  <span class="nn">Py</span><span class="p">.</span><span class="nn">Object</span><span class="p">.</span><span class="n">t</span>
</code></pre></div>

<p>Point-wise multiplication by another matrix, vector, or
scalar.</p>
</details>
<h3 id="nonzero">nonzero<a class="headerlink" href="#nonzero" title="Permanent link">&para;</a></h3>
<details class="note" open="open"><summary>method nonzero</summary><div class="highlight"><pre><span></span><code><span class="k">val</span> <span class="n">nonzero</span> <span class="o">:</span>
  <span class="o">[&gt;</span> <span class="n">tag</span><span class="o">]</span> <span class="nn">Obj</span><span class="p">.</span><span class="n">t</span> <span class="o">-&gt;</span>
  <span class="nn">Py</span><span class="p">.</span><span class="nn">Object</span><span class="p">.</span><span class="n">t</span>
</code></pre></div>

<p>nonzero indices</p>
<p>Returns a tuple of arrays (row,col) containing the indices
of the non-zero elements of the matrix.</p>
<h4>Examples</h4>
<div class="highlight"><pre><span></span><code><span class="o">&gt;&gt;&gt;</span> <span class="kn">from</span> <span class="nn">scipy.sparse</span> <span class="kn">import</span> <span class="n">csr_matrix</span>
<span class="o">&gt;&gt;&gt;</span> <span class="n">A</span> <span class="o">=</span> <span class="n">csr_matrix</span><span class="p">([[</span><span class="mi">1</span><span class="p">,</span><span class="mi">2</span><span class="p">,</span><span class="mi">0</span><span class="p">],[</span><span class="mi">0</span><span class="p">,</span><span class="mi">0</span><span class="p">,</span><span class="mi">3</span><span class="p">],[</span><span class="mi">4</span><span class="p">,</span><span class="mi">0</span><span class="p">,</span><span class="mi">5</span><span class="p">]])</span>
<span class="o">&gt;&gt;&gt;</span> <span class="n">A</span><span class="o">.</span><span class="n">nonzero</span><span class="p">()</span>
<span class="p">(</span><span class="n">array</span><span class="p">([</span><span class="mi">0</span><span class="p">,</span> <span class="mi">0</span><span class="p">,</span> <span class="mi">1</span><span class="p">,</span> <span class="mi">2</span><span class="p">,</span> <span class="mi">2</span><span class="p">]),</span> <span class="n">array</span><span class="p">([</span><span class="mi">0</span><span class="p">,</span> <span class="mi">1</span><span class="p">,</span> <span class="mi">2</span><span class="p">,</span> <span class="mi">0</span><span class="p">,</span> <span class="mi">2</span><span class="p">]))</span>
</code></pre></div>

</details>
<h3 id="power">power<a class="headerlink" href="#power" title="Permanent link">&para;</a></h3>
<details class="note" open="open"><summary>method power</summary><div class="highlight"><pre><span></span><code><span class="k">val</span> <span class="n">power</span> <span class="o">:</span>
  <span class="o">?</span><span class="n">dtype</span><span class="o">:</span><span class="nn">Py</span><span class="p">.</span><span class="nn">Object</span><span class="p">.</span><span class="n">t</span> <span class="o">-&gt;</span>
  <span class="n">n</span><span class="o">:</span><span class="nn">Py</span><span class="p">.</span><span class="nn">Object</span><span class="p">.</span><span class="n">t</span> <span class="o">-&gt;</span>
  <span class="o">[&gt;</span> <span class="n">tag</span><span class="o">]</span> <span class="nn">Obj</span><span class="p">.</span><span class="n">t</span> <span class="o">-&gt;</span>
  <span class="nn">Py</span><span class="p">.</span><span class="nn">Object</span><span class="p">.</span><span class="n">t</span>
</code></pre></div>

<p>This function performs element-wise power.</p>
<h4>Parameters</h4>
<ul>
<li>
<p><strong>n : n is a scalar</strong></p>
</li>
<li>
<p><strong>dtype : If dtype is not specified, the current dtype will be preserved.</strong></p>
</li>
</ul>
</details>
<h3 id="prune">prune<a class="headerlink" href="#prune" title="Permanent link">&para;</a></h3>
<details class="note" open="open"><summary>method prune</summary><div class="highlight"><pre><span></span><code><span class="k">val</span> <span class="n">prune</span> <span class="o">:</span>
  <span class="o">[&gt;</span> <span class="n">tag</span><span class="o">]</span> <span class="nn">Obj</span><span class="p">.</span><span class="n">t</span> <span class="o">-&gt;</span>
  <span class="nn">Py</span><span class="p">.</span><span class="nn">Object</span><span class="p">.</span><span class="n">t</span>
</code></pre></div>

<p>Remove empty space after all non-zero elements.</p>
</details>
<h3 id="rad2deg">rad2deg<a class="headerlink" href="#rad2deg" title="Permanent link">&para;</a></h3>
<details class="note" open="open"><summary>method rad2deg</summary><div class="highlight"><pre><span></span><code><span class="k">val</span> <span class="n">rad2deg</span> <span class="o">:</span>
  <span class="o">[&gt;</span> <span class="n">tag</span><span class="o">]</span> <span class="nn">Obj</span><span class="p">.</span><span class="n">t</span> <span class="o">-&gt;</span>
  <span class="nn">Py</span><span class="p">.</span><span class="nn">Object</span><span class="p">.</span><span class="n">t</span>
</code></pre></div>

<p>Element-wise rad2deg.</p>
<p>See <code>numpy.rad2deg</code> for more information.</p>
</details>
<h3 id="reshape">reshape<a class="headerlink" href="#reshape" title="Permanent link">&para;</a></h3>
<details class="note" open="open"><summary>method reshape</summary><div class="highlight"><pre><span></span><code><span class="k">val</span> <span class="n">reshape</span> <span class="o">:</span>
  <span class="o">?</span><span class="n">kwargs</span><span class="o">:(</span><span class="kt">string</span> <span class="o">*</span> <span class="nn">Py</span><span class="p">.</span><span class="nn">Object</span><span class="p">.</span><span class="n">t</span><span class="o">)</span> <span class="kt">list</span> <span class="o">-&gt;</span>
  <span class="nn">Py</span><span class="p">.</span><span class="nn">Object</span><span class="p">.</span><span class="n">t</span> <span class="kt">list</span> <span class="o">-&gt;</span>
  <span class="o">[&gt;</span> <span class="n">tag</span><span class="o">]</span> <span class="nn">Obj</span><span class="p">.</span><span class="n">t</span> <span class="o">-&gt;</span>
  <span class="o">[`</span><span class="nc">ArrayLike</span><span class="o">|`</span><span class="nc">Object</span><span class="o">|`</span><span class="nc">Spmatrix</span><span class="o">]</span> <span class="nn">Np</span><span class="p">.</span><span class="nn">Obj</span><span class="p">.</span><span class="n">t</span>
</code></pre></div>

<p>reshape(self, shape, order='C', copy=False)</p>
<p>Gives a new shape to a sparse matrix without changing its data.</p>
<h4>Parameters</h4>
<ul>
<li>
<p><strong>shape : length-2 tuple of ints</strong>
    The new shape should be compatible with the original shape.</p>
</li>
<li>
<p><strong>order : {'C', 'F'}, optional</strong>
    Read the elements using this index order. 'C' means to read and
    write the elements using C-like index order; e.g., read entire first
    row, then second row, etc. 'F' means to read and write the elements
    using Fortran-like index order; e.g., read entire first column, then
    second column, etc.</p>
</li>
<li>
<p><strong>copy : bool, optional</strong>
    Indicates whether or not attributes of self should be copied
    whenever possible. The degree to which attributes are copied varies
    depending on the type of sparse matrix being used.</p>
</li>
</ul>
<h4>Returns</h4>
<ul>
<li><strong>reshaped_matrix : sparse matrix</strong>
    A sparse matrix with the given <code>shape</code>, not necessarily of the same
    format as the current object.</li>
</ul>
<h4>See Also</h4>
<ul>
<li><strong>numpy.matrix.reshape : NumPy's implementation of 'reshape' for</strong>
                       matrices</li>
</ul>
</details>
<h3 id="resize">resize<a class="headerlink" href="#resize" title="Permanent link">&para;</a></h3>
<details class="note" open="open"><summary>method resize</summary><div class="highlight"><pre><span></span><code><span class="k">val</span> <span class="n">resize</span> <span class="o">:</span>
  <span class="kt">int</span> <span class="kt">list</span> <span class="o">-&gt;</span>
  <span class="o">[&gt;</span> <span class="n">tag</span><span class="o">]</span> <span class="nn">Obj</span><span class="p">.</span><span class="n">t</span> <span class="o">-&gt;</span>
  <span class="nn">Py</span><span class="p">.</span><span class="nn">Object</span><span class="p">.</span><span class="n">t</span>
</code></pre></div>

<p>Resize the matrix in-place to dimensions given by <code>shape</code></p>
<p>Any elements that lie within the new shape will remain at the same
indices, while non-zero elements lying outside the new shape are
removed.</p>
<h4>Parameters</h4>
<ul>
<li><strong>shape : (int, int)</strong>
    number of rows and columns in the new matrix</li>
</ul>
<h4>Notes</h4>
<p>The semantics are not identical to <code>numpy.ndarray.resize</code> or
<code>numpy.resize</code>. Here, the same data will be maintained at each index
before and after reshape, if that index is within the new bounds. In
numpy, resizing maintains contiguity of the array, moving elements
around in the logical matrix but not within a flattened representation.</p>
<p>We give no guarantees about whether the underlying data attributes
(arrays, etc.) will be modified in place or replaced with new objects.</p>
</details>
<h3 id="rint">rint<a class="headerlink" href="#rint" title="Permanent link">&para;</a></h3>
<details class="note" open="open"><summary>method rint</summary><div class="highlight"><pre><span></span><code><span class="k">val</span> <span class="n">rint</span> <span class="o">:</span>
  <span class="o">[&gt;</span> <span class="n">tag</span><span class="o">]</span> <span class="nn">Obj</span><span class="p">.</span><span class="n">t</span> <span class="o">-&gt;</span>
  <span class="nn">Py</span><span class="p">.</span><span class="nn">Object</span><span class="p">.</span><span class="n">t</span>
</code></pre></div>

<p>Element-wise rint.</p>
<p>See <code>numpy.rint</code> for more information.</p>
</details>
<h3 id="set_shape">set_shape<a class="headerlink" href="#set_shape" title="Permanent link">&para;</a></h3>
<details class="note" open="open"><summary>method set_shape</summary><div class="highlight"><pre><span></span><code><span class="k">val</span> <span class="n">set_shape</span> <span class="o">:</span>
  <span class="n">shape</span><span class="o">:</span><span class="kt">int</span> <span class="kt">list</span> <span class="o">-&gt;</span>
  <span class="o">[&gt;</span> <span class="n">tag</span><span class="o">]</span> <span class="nn">Obj</span><span class="p">.</span><span class="n">t</span> <span class="o">-&gt;</span>
  <span class="nn">Py</span><span class="p">.</span><span class="nn">Object</span><span class="p">.</span><span class="n">t</span>
</code></pre></div>

<p>See <code>reshape</code>.</p>
</details>
<h3 id="setdiag">setdiag<a class="headerlink" href="#setdiag" title="Permanent link">&para;</a></h3>
<details class="note" open="open"><summary>method setdiag</summary><div class="highlight"><pre><span></span><code><span class="k">val</span> <span class="n">setdiag</span> <span class="o">:</span>
  <span class="o">?</span><span class="n">k</span><span class="o">:</span><span class="kt">int</span> <span class="o">-&gt;</span>
  <span class="n">values</span><span class="o">:[&gt;`</span><span class="nc">ArrayLike</span><span class="o">]</span> <span class="nn">Np</span><span class="p">.</span><span class="nn">Obj</span><span class="p">.</span><span class="n">t</span> <span class="o">-&gt;</span>
  <span class="o">[&gt;</span> <span class="n">tag</span><span class="o">]</span> <span class="nn">Obj</span><span class="p">.</span><span class="n">t</span> <span class="o">-&gt;</span>
  <span class="nn">Py</span><span class="p">.</span><span class="nn">Object</span><span class="p">.</span><span class="n">t</span>
</code></pre></div>

<p>Set diagonal or off-diagonal elements of the array.</p>
<h4>Parameters</h4>
<ul>
<li>
<p><strong>values : array_like</strong>
    New values of the diagonal elements.</p>
<p>Values may have any length. If the diagonal is longer than values,
then the remaining diagonal entries will not be set. If values if
longer than the diagonal, then the remaining values are ignored.</p>
<p>If a scalar value is given, all of the diagonal is set to it.</p>
</li>
<li>
<p><strong>k : int, optional</strong>
    Which off-diagonal to set, corresponding to elements a[i,i+k].</p>
</li>
<li>
<p><strong>Default: 0 (the main diagonal).</strong></p>
</li>
</ul>
</details>
<h3 id="sign">sign<a class="headerlink" href="#sign" title="Permanent link">&para;</a></h3>
<details class="note" open="open"><summary>method sign</summary><div class="highlight"><pre><span></span><code><span class="k">val</span> <span class="n">sign</span> <span class="o">:</span>
  <span class="o">[&gt;</span> <span class="n">tag</span><span class="o">]</span> <span class="nn">Obj</span><span class="p">.</span><span class="n">t</span> <span class="o">-&gt;</span>
  <span class="nn">Py</span><span class="p">.</span><span class="nn">Object</span><span class="p">.</span><span class="n">t</span>
</code></pre></div>

<p>Element-wise sign.</p>
<p>See <code>numpy.sign</code> for more information.</p>
</details>
<h3 id="sin">sin<a class="headerlink" href="#sin" title="Permanent link">&para;</a></h3>
<details class="note" open="open"><summary>method sin</summary><div class="highlight"><pre><span></span><code><span class="k">val</span> <span class="n">sin</span> <span class="o">:</span>
  <span class="o">[&gt;</span> <span class="n">tag</span><span class="o">]</span> <span class="nn">Obj</span><span class="p">.</span><span class="n">t</span> <span class="o">-&gt;</span>
  <span class="nn">Py</span><span class="p">.</span><span class="nn">Object</span><span class="p">.</span><span class="n">t</span>
</code></pre></div>

<p>Element-wise sin.</p>
<p>See <code>numpy.sin</code> for more information.</p>
</details>
<h3 id="sinh">sinh<a class="headerlink" href="#sinh" title="Permanent link">&para;</a></h3>
<details class="note" open="open"><summary>method sinh</summary><div class="highlight"><pre><span></span><code><span class="k">val</span> <span class="n">sinh</span> <span class="o">:</span>
  <span class="o">[&gt;</span> <span class="n">tag</span><span class="o">]</span> <span class="nn">Obj</span><span class="p">.</span><span class="n">t</span> <span class="o">-&gt;</span>
  <span class="nn">Py</span><span class="p">.</span><span class="nn">Object</span><span class="p">.</span><span class="n">t</span>
</code></pre></div>

<p>Element-wise sinh.</p>
<p>See <code>numpy.sinh</code> for more information.</p>
</details>
<h3 id="sort_indices">sort_indices<a class="headerlink" href="#sort_indices" title="Permanent link">&para;</a></h3>
<details class="note" open="open"><summary>method sort_indices</summary><div class="highlight"><pre><span></span><code><span class="k">val</span> <span class="n">sort_indices</span> <span class="o">:</span>
  <span class="o">[&gt;</span> <span class="n">tag</span><span class="o">]</span> <span class="nn">Obj</span><span class="p">.</span><span class="n">t</span> <span class="o">-&gt;</span>
  <span class="nn">Py</span><span class="p">.</span><span class="nn">Object</span><span class="p">.</span><span class="n">t</span>
</code></pre></div>

<p>Sort the indices of this matrix <em>in place</em></p>
</details>
<h3 id="sorted_indices">sorted_indices<a class="headerlink" href="#sorted_indices" title="Permanent link">&para;</a></h3>
<details class="note" open="open"><summary>method sorted_indices</summary><div class="highlight"><pre><span></span><code><span class="k">val</span> <span class="n">sorted_indices</span> <span class="o">:</span>
  <span class="o">[&gt;</span> <span class="n">tag</span><span class="o">]</span> <span class="nn">Obj</span><span class="p">.</span><span class="n">t</span> <span class="o">-&gt;</span>
  <span class="nn">Py</span><span class="p">.</span><span class="nn">Object</span><span class="p">.</span><span class="n">t</span>
</code></pre></div>

<p>Return a copy of this matrix with sorted indices</p>
</details>
<h3 id="sqrt">sqrt<a class="headerlink" href="#sqrt" title="Permanent link">&para;</a></h3>
<details class="note" open="open"><summary>method sqrt</summary><div class="highlight"><pre><span></span><code><span class="k">val</span> <span class="n">sqrt</span> <span class="o">:</span>
  <span class="o">[&gt;</span> <span class="n">tag</span><span class="o">]</span> <span class="nn">Obj</span><span class="p">.</span><span class="n">t</span> <span class="o">-&gt;</span>
  <span class="nn">Py</span><span class="p">.</span><span class="nn">Object</span><span class="p">.</span><span class="n">t</span>
</code></pre></div>

<p>Element-wise sqrt.</p>
<p>See <code>numpy.sqrt</code> for more information.</p>
</details>
<h3 id="sum">sum<a class="headerlink" href="#sum" title="Permanent link">&para;</a></h3>
<details class="note" open="open"><summary>method sum</summary><div class="highlight"><pre><span></span><code><span class="k">val</span> <span class="n">sum</span> <span class="o">:</span>
  <span class="o">?</span><span class="n">axis</span><span class="o">:[`</span><span class="nc">One</span> <span class="o">|</span> <span class="o">`</span><span class="nc">Zero</span> <span class="o">|</span> <span class="o">`</span><span class="nc">PyObject</span> <span class="k">of</span> <span class="nn">Py</span><span class="p">.</span><span class="nn">Object</span><span class="p">.</span><span class="n">t</span><span class="o">]</span> <span class="o">-&gt;</span>
  <span class="o">?</span><span class="n">dtype</span><span class="o">:</span><span class="nn">Np</span><span class="p">.</span><span class="nn">Dtype</span><span class="p">.</span><span class="n">t</span> <span class="o">-&gt;</span>
  <span class="o">?</span><span class="n">out</span><span class="o">:[&gt;`</span><span class="nc">ArrayLike</span><span class="o">]</span> <span class="nn">Np</span><span class="p">.</span><span class="nn">Obj</span><span class="p">.</span><span class="n">t</span> <span class="o">-&gt;</span>
  <span class="o">[&gt;</span> <span class="n">tag</span><span class="o">]</span> <span class="nn">Obj</span><span class="p">.</span><span class="n">t</span> <span class="o">-&gt;</span>
  <span class="o">[&gt;`</span><span class="nc">ArrayLike</span><span class="o">]</span> <span class="nn">Np</span><span class="p">.</span><span class="nn">Obj</span><span class="p">.</span><span class="n">t</span>
</code></pre></div>

<p>Sum the matrix elements over a given axis.</p>
<h4>Parameters</h4>
<ul>
<li>
<p><strong>axis : {-2, -1, 0, 1, None} optional</strong>
    Axis along which the sum is computed. The default is to
    compute the sum of all the matrix elements, returning a scalar
    (i.e., <code>axis</code> = <code>None</code>).</p>
</li>
<li>
<p><strong>dtype : dtype, optional</strong>
    The type of the returned matrix and of the accumulator in which
    the elements are summed.  The dtype of <code>a</code> is used by default
    unless <code>a</code> has an integer dtype of less precision than the default
    platform integer.  In that case, if <code>a</code> is signed then the platform
    integer is used while if <code>a</code> is unsigned then an unsigned integer
    of the same precision as the platform integer is used.</p>
<p>.. versionadded:: 0.18.0</p>
</li>
<li>
<p><strong>out : np.matrix, optional</strong>
    Alternative output matrix in which to place the result. It must
    have the same shape as the expected output, but the type of the
    output values will be cast if necessary.</p>
<p>.. versionadded:: 0.18.0</p>
</li>
</ul>
<h4>Returns</h4>
<ul>
<li><strong>sum_along_axis : np.matrix</strong>
    A matrix with the same shape as <code>self</code>, with the specified
    axis removed.</li>
</ul>
<h4>See Also</h4>
<ul>
<li><strong>numpy.matrix.sum : NumPy's implementation of 'sum' for matrices</strong></li>
</ul>
</details>
<h3 id="sum_duplicates">sum_duplicates<a class="headerlink" href="#sum_duplicates" title="Permanent link">&para;</a></h3>
<details class="note" open="open"><summary>method sum_duplicates</summary><div class="highlight"><pre><span></span><code><span class="k">val</span> <span class="n">sum_duplicates</span> <span class="o">:</span>
  <span class="o">[&gt;</span> <span class="n">tag</span><span class="o">]</span> <span class="nn">Obj</span><span class="p">.</span><span class="n">t</span> <span class="o">-&gt;</span>
  <span class="nn">Py</span><span class="p">.</span><span class="nn">Object</span><span class="p">.</span><span class="n">t</span>
</code></pre></div>

<p>Eliminate duplicate matrix entries by adding them together</p>
<p>The is an <em>in place</em> operation</p>
</details>
<h3 id="tan">tan<a class="headerlink" href="#tan" title="Permanent link">&para;</a></h3>
<details class="note" open="open"><summary>method tan</summary><div class="highlight"><pre><span></span><code><span class="k">val</span> <span class="n">tan</span> <span class="o">:</span>
  <span class="o">[&gt;</span> <span class="n">tag</span><span class="o">]</span> <span class="nn">Obj</span><span class="p">.</span><span class="n">t</span> <span class="o">-&gt;</span>
  <span class="nn">Py</span><span class="p">.</span><span class="nn">Object</span><span class="p">.</span><span class="n">t</span>
</code></pre></div>

<p>Element-wise tan.</p>
<p>See <code>numpy.tan</code> for more information.</p>
</details>
<h3 id="tanh">tanh<a class="headerlink" href="#tanh" title="Permanent link">&para;</a></h3>
<details class="note" open="open"><summary>method tanh</summary><div class="highlight"><pre><span></span><code><span class="k">val</span> <span class="n">tanh</span> <span class="o">:</span>
  <span class="o">[&gt;</span> <span class="n">tag</span><span class="o">]</span> <span class="nn">Obj</span><span class="p">.</span><span class="n">t</span> <span class="o">-&gt;</span>
  <span class="nn">Py</span><span class="p">.</span><span class="nn">Object</span><span class="p">.</span><span class="n">t</span>
</code></pre></div>

<p>Element-wise tanh.</p>
<p>See <code>numpy.tanh</code> for more information.</p>
</details>
<h3 id="toarray">toarray<a class="headerlink" href="#toarray" title="Permanent link">&para;</a></h3>
<details class="note" open="open"><summary>method toarray</summary><div class="highlight"><pre><span></span><code><span class="k">val</span> <span class="n">toarray</span> <span class="o">:</span>
  <span class="o">?</span><span class="n">order</span><span class="o">:[`</span><span class="nc">F</span> <span class="o">|</span> <span class="o">`</span><span class="nc">C</span><span class="o">]</span> <span class="o">-&gt;</span>
  <span class="o">?</span><span class="n">out</span><span class="o">:[`</span><span class="nc">Arr</span> <span class="k">of</span> <span class="o">[&gt;`</span><span class="nc">ArrayLike</span><span class="o">]</span> <span class="nn">Np</span><span class="p">.</span><span class="nn">Obj</span><span class="p">.</span><span class="n">t</span> <span class="o">|</span> <span class="o">`</span><span class="nc">T2_D</span> <span class="k">of</span> <span class="nn">Py</span><span class="p">.</span><span class="nn">Object</span><span class="p">.</span><span class="n">t</span><span class="o">]</span> <span class="o">-&gt;</span>
  <span class="o">[&gt;</span> <span class="n">tag</span><span class="o">]</span> <span class="nn">Obj</span><span class="p">.</span><span class="n">t</span> <span class="o">-&gt;</span>
  <span class="nn">Py</span><span class="p">.</span><span class="nn">Object</span><span class="p">.</span><span class="n">t</span>
</code></pre></div>

<p>Return a dense ndarray representation of this matrix.</p>
<h4>Parameters</h4>
<ul>
<li>
<p><strong>order : {'C', 'F'}, optional</strong>
    Whether to store multidimensional data in C (row-major)
    or Fortran (column-major) order in memory. The default
    is 'None', indicating the NumPy default of C-ordered.
    Cannot be specified in conjunction with the <code>out</code>
    argument.</p>
</li>
<li>
<p><strong>out : ndarray, 2-D, optional</strong>
    If specified, uses this array as the output buffer
    instead of allocating a new array to return. The provided
    array must have the same shape and dtype as the sparse
    matrix on which you are calling the method. For most
    sparse types, <code>out</code> is required to be memory contiguous
    (either C or Fortran ordered).</p>
</li>
</ul>
<h4>Returns</h4>
<ul>
<li><strong>arr : ndarray, 2-D</strong>
    An array with the same shape and containing the same
    data represented by the sparse matrix, with the requested
    memory order. If <code>out</code> was passed, the same object is
    returned after being modified in-place to contain the
    appropriate values.</li>
</ul>
</details>
<h3 id="tobsr">tobsr<a class="headerlink" href="#tobsr" title="Permanent link">&para;</a></h3>
<details class="note" open="open"><summary>method tobsr</summary><div class="highlight"><pre><span></span><code><span class="k">val</span> <span class="n">tobsr</span> <span class="o">:</span>
  <span class="o">?</span><span class="n">blocksize</span><span class="o">:</span><span class="nn">Py</span><span class="p">.</span><span class="nn">Object</span><span class="p">.</span><span class="n">t</span> <span class="o">-&gt;</span>
  <span class="o">?</span><span class="n">copy</span><span class="o">:</span><span class="nn">Py</span><span class="p">.</span><span class="nn">Object</span><span class="p">.</span><span class="n">t</span> <span class="o">-&gt;</span>
  <span class="o">[&gt;</span> <span class="n">tag</span><span class="o">]</span> <span class="nn">Obj</span><span class="p">.</span><span class="n">t</span> <span class="o">-&gt;</span>
  <span class="nn">Py</span><span class="p">.</span><span class="nn">Object</span><span class="p">.</span><span class="n">t</span>
</code></pre></div>

<p>Convert this matrix to Block Sparse Row format.</p>
<p>With copy=False, the data/indices may be shared between this matrix and
the resultant bsr_matrix.</p>
<p>When blocksize=(R, C) is provided, it will be used for construction of
the bsr_matrix.</p>
</details>
<h3 id="tocoo">tocoo<a class="headerlink" href="#tocoo" title="Permanent link">&para;</a></h3>
<details class="note" open="open"><summary>method tocoo</summary><div class="highlight"><pre><span></span><code><span class="k">val</span> <span class="n">tocoo</span> <span class="o">:</span>
  <span class="o">?</span><span class="n">copy</span><span class="o">:</span><span class="nn">Py</span><span class="p">.</span><span class="nn">Object</span><span class="p">.</span><span class="n">t</span> <span class="o">-&gt;</span>
  <span class="o">[&gt;</span> <span class="n">tag</span><span class="o">]</span> <span class="nn">Obj</span><span class="p">.</span><span class="n">t</span> <span class="o">-&gt;</span>
  <span class="nn">Py</span><span class="p">.</span><span class="nn">Object</span><span class="p">.</span><span class="n">t</span>
</code></pre></div>

<p>Convert this matrix to COOrdinate format.</p>
<p>With copy=False, the data/indices may be shared between this matrix and
the resultant coo_matrix.</p>
</details>
<h3 id="tocsc">tocsc<a class="headerlink" href="#tocsc" title="Permanent link">&para;</a></h3>
<details class="note" open="open"><summary>method tocsc</summary><div class="highlight"><pre><span></span><code><span class="k">val</span> <span class="n">tocsc</span> <span class="o">:</span>
  <span class="o">?</span><span class="n">copy</span><span class="o">:</span><span class="nn">Py</span><span class="p">.</span><span class="nn">Object</span><span class="p">.</span><span class="n">t</span> <span class="o">-&gt;</span>
  <span class="o">[&gt;</span> <span class="n">tag</span><span class="o">]</span> <span class="nn">Obj</span><span class="p">.</span><span class="n">t</span> <span class="o">-&gt;</span>
  <span class="nn">Py</span><span class="p">.</span><span class="nn">Object</span><span class="p">.</span><span class="n">t</span>
</code></pre></div>

<p>Convert this matrix to Compressed Sparse Column format.</p>
<p>With copy=False, the data/indices may be shared between this matrix and
the resultant csc_matrix.</p>
</details>
<h3 id="tocsr">tocsr<a class="headerlink" href="#tocsr" title="Permanent link">&para;</a></h3>
<details class="note" open="open"><summary>method tocsr</summary><div class="highlight"><pre><span></span><code><span class="k">val</span> <span class="n">tocsr</span> <span class="o">:</span>
  <span class="o">?</span><span class="n">copy</span><span class="o">:</span><span class="nn">Py</span><span class="p">.</span><span class="nn">Object</span><span class="p">.</span><span class="n">t</span> <span class="o">-&gt;</span>
  <span class="o">[&gt;</span> <span class="n">tag</span><span class="o">]</span> <span class="nn">Obj</span><span class="p">.</span><span class="n">t</span> <span class="o">-&gt;</span>
  <span class="nn">Py</span><span class="p">.</span><span class="nn">Object</span><span class="p">.</span><span class="n">t</span>
</code></pre></div>

<p>Convert this matrix to Compressed Sparse Row format.</p>
<p>With copy=False, the data/indices may be shared between this matrix and
the resultant csr_matrix.</p>
</details>
<h3 id="todense">todense<a class="headerlink" href="#todense" title="Permanent link">&para;</a></h3>
<details class="note" open="open"><summary>method todense</summary><div class="highlight"><pre><span></span><code><span class="k">val</span> <span class="n">todense</span> <span class="o">:</span>
  <span class="o">?</span><span class="n">order</span><span class="o">:[`</span><span class="nc">F</span> <span class="o">|</span> <span class="o">`</span><span class="nc">C</span><span class="o">]</span> <span class="o">-&gt;</span>
  <span class="o">?</span><span class="n">out</span><span class="o">:[`</span><span class="nc">Arr</span> <span class="k">of</span> <span class="o">[&gt;`</span><span class="nc">ArrayLike</span><span class="o">]</span> <span class="nn">Np</span><span class="p">.</span><span class="nn">Obj</span><span class="p">.</span><span class="n">t</span> <span class="o">|</span> <span class="o">`</span><span class="nc">T2_D</span> <span class="k">of</span> <span class="nn">Py</span><span class="p">.</span><span class="nn">Object</span><span class="p">.</span><span class="n">t</span><span class="o">]</span> <span class="o">-&gt;</span>
  <span class="o">[&gt;</span> <span class="n">tag</span><span class="o">]</span> <span class="nn">Obj</span><span class="p">.</span><span class="n">t</span> <span class="o">-&gt;</span>
  <span class="nn">Py</span><span class="p">.</span><span class="nn">Object</span><span class="p">.</span><span class="n">t</span>
</code></pre></div>

<p>Return a dense matrix representation of this matrix.</p>
<h4>Parameters</h4>
<ul>
<li>
<p><strong>order : {'C', 'F'}, optional</strong>
    Whether to store multi-dimensional data in C (row-major)
    or Fortran (column-major) order in memory. The default
    is 'None', indicating the NumPy default of C-ordered.
    Cannot be specified in conjunction with the <code>out</code>
    argument.</p>
</li>
<li>
<p><strong>out : ndarray, 2-D, optional</strong>
    If specified, uses this array (or <code>numpy.matrix</code>) as the
    output buffer instead of allocating a new array to
    return. The provided array must have the same shape and
    dtype as the sparse matrix on which you are calling the
    method.</p>
</li>
</ul>
<h4>Returns</h4>
<ul>
<li><strong>arr : numpy.matrix, 2-D</strong>
    A NumPy matrix object with the same shape and containing
    the same data represented by the sparse matrix, with the
    requested memory order. If <code>out</code> was passed and was an
    array (rather than a <code>numpy.matrix</code>), it will be filled
    with the appropriate values and returned wrapped in a
    <code>numpy.matrix</code> object that shares the same memory.</li>
</ul>
</details>
<h3 id="todia">todia<a class="headerlink" href="#todia" title="Permanent link">&para;</a></h3>
<details class="note" open="open"><summary>method todia</summary><div class="highlight"><pre><span></span><code><span class="k">val</span> <span class="n">todia</span> <span class="o">:</span>
  <span class="o">?</span><span class="n">copy</span><span class="o">:</span><span class="nn">Py</span><span class="p">.</span><span class="nn">Object</span><span class="p">.</span><span class="n">t</span> <span class="o">-&gt;</span>
  <span class="o">[&gt;</span> <span class="n">tag</span><span class="o">]</span> <span class="nn">Obj</span><span class="p">.</span><span class="n">t</span> <span class="o">-&gt;</span>
  <span class="nn">Py</span><span class="p">.</span><span class="nn">Object</span><span class="p">.</span><span class="n">t</span>
</code></pre></div>

<p>Convert this matrix to sparse DIAgonal format.</p>
<p>With copy=False, the data/indices may be shared between this matrix and
the resultant dia_matrix.</p>
</details>
<h3 id="todok">todok<a class="headerlink" href="#todok" title="Permanent link">&para;</a></h3>
<details class="note" open="open"><summary>method todok</summary><div class="highlight"><pre><span></span><code><span class="k">val</span> <span class="n">todok</span> <span class="o">:</span>
  <span class="o">?</span><span class="n">copy</span><span class="o">:</span><span class="nn">Py</span><span class="p">.</span><span class="nn">Object</span><span class="p">.</span><span class="n">t</span> <span class="o">-&gt;</span>
  <span class="o">[&gt;</span> <span class="n">tag</span><span class="o">]</span> <span class="nn">Obj</span><span class="p">.</span><span class="n">t</span> <span class="o">-&gt;</span>
  <span class="nn">Py</span><span class="p">.</span><span class="nn">Object</span><span class="p">.</span><span class="n">t</span>
</code></pre></div>

<p>Convert this matrix to Dictionary Of Keys format.</p>
<p>With copy=False, the data/indices may be shared between this matrix and
the resultant dok_matrix.</p>
</details>
<h3 id="tolil">tolil<a class="headerlink" href="#tolil" title="Permanent link">&para;</a></h3>
<details class="note" open="open"><summary>method tolil</summary><div class="highlight"><pre><span></span><code><span class="k">val</span> <span class="n">tolil</span> <span class="o">:</span>
  <span class="o">?</span><span class="n">copy</span><span class="o">:</span><span class="nn">Py</span><span class="p">.</span><span class="nn">Object</span><span class="p">.</span><span class="n">t</span> <span class="o">-&gt;</span>
  <span class="o">[&gt;</span> <span class="n">tag</span><span class="o">]</span> <span class="nn">Obj</span><span class="p">.</span><span class="n">t</span> <span class="o">-&gt;</span>
  <span class="nn">Py</span><span class="p">.</span><span class="nn">Object</span><span class="p">.</span><span class="n">t</span>
</code></pre></div>

<p>Convert this matrix to List of Lists format.</p>
<p>With copy=False, the data/indices may be shared between this matrix and
the resultant lil_matrix.</p>
</details>
<h3 id="transpose">transpose<a class="headerlink" href="#transpose" title="Permanent link">&para;</a></h3>
<details class="note" open="open"><summary>method transpose</summary><div class="highlight"><pre><span></span><code><span class="k">val</span> <span class="n">transpose</span> <span class="o">:</span>
  <span class="o">?</span><span class="n">axes</span><span class="o">:</span><span class="nn">Py</span><span class="p">.</span><span class="nn">Object</span><span class="p">.</span><span class="n">t</span> <span class="o">-&gt;</span>
  <span class="o">?</span><span class="n">copy</span><span class="o">:</span><span class="kt">bool</span> <span class="o">-&gt;</span>
  <span class="o">[&gt;</span> <span class="n">tag</span><span class="o">]</span> <span class="nn">Obj</span><span class="p">.</span><span class="n">t</span> <span class="o">-&gt;</span>
  <span class="nn">Py</span><span class="p">.</span><span class="nn">Object</span><span class="p">.</span><span class="n">t</span>
</code></pre></div>

<p>Reverses the dimensions of the sparse matrix.</p>
<h4>Parameters</h4>
<ul>
<li>
<p><strong>axes : None, optional</strong>
    This argument is in the signature <em>solely</em> for NumPy
    compatibility reasons. Do not pass in anything except
    for the default value.</p>
</li>
<li>
<p><strong>copy : bool, optional</strong>
    Indicates whether or not attributes of <code>self</code> should be
    copied whenever possible. The degree to which attributes
    are copied varies depending on the type of sparse matrix
    being used.</p>
</li>
</ul>
<h4>Returns</h4>
<ul>
<li><strong>p : <code>self</code> with the dimensions reversed.</strong></li>
</ul>
<h4>See Also</h4>
<ul>
<li><strong>numpy.matrix.transpose : NumPy's implementation of 'transpose'</strong>
                         for matrices</li>
</ul>
</details>
<h3 id="trunc">trunc<a class="headerlink" href="#trunc" title="Permanent link">&para;</a></h3>
<details class="note" open="open"><summary>method trunc</summary><div class="highlight"><pre><span></span><code><span class="k">val</span> <span class="n">trunc</span> <span class="o">:</span>
  <span class="o">[&gt;</span> <span class="n">tag</span><span class="o">]</span> <span class="nn">Obj</span><span class="p">.</span><span class="n">t</span> <span class="o">-&gt;</span>
  <span class="nn">Py</span><span class="p">.</span><span class="nn">Object</span><span class="p">.</span><span class="n">t</span>
</code></pre></div>

<p>Element-wise trunc.</p>
<p>See <code>numpy.trunc</code> for more information.</p>
</details>
<h3 id="dtype">dtype<a class="headerlink" href="#dtype" title="Permanent link">&para;</a></h3>
<details class="note" open="open"><summary>attribute dtype</summary><div class="highlight"><pre><span></span><code><span class="k">val</span> <span class="n">dtype</span> <span class="o">:</span> <span class="n">t</span> <span class="o">-&gt;</span> <span class="nn">Np</span><span class="p">.</span><span class="nn">Dtype</span><span class="p">.</span><span class="n">t</span>
<span class="k">val</span> <span class="n">dtype_opt</span> <span class="o">:</span> <span class="n">t</span> <span class="o">-&gt;</span> <span class="o">(</span><span class="nn">Np</span><span class="p">.</span><span class="nn">Dtype</span><span class="p">.</span><span class="n">t</span><span class="o">)</span> <span class="n">option</span>
</code></pre></div>

<p>This attribute is documented in <code>create</code> above. The first version raises Not_found
if the attribute is None. The _opt version returns an option.</p>
</details>
<h3 id="shape">shape<a class="headerlink" href="#shape" title="Permanent link">&para;</a></h3>
<details class="note" open="open"><summary>attribute shape</summary><div class="highlight"><pre><span></span><code><span class="k">val</span> <span class="n">shape</span> <span class="o">:</span> <span class="n">t</span> <span class="o">-&gt;</span> <span class="kt">int</span> <span class="kt">list</span>
<span class="k">val</span> <span class="n">shape_opt</span> <span class="o">:</span> <span class="n">t</span> <span class="o">-&gt;</span> <span class="o">(</span><span class="kt">int</span> <span class="kt">list</span><span class="o">)</span> <span class="n">option</span>
</code></pre></div>

<p>This attribute is documented in <code>create</code> above. The first version raises Not_found
if the attribute is None. The _opt version returns an option.</p>
</details>
<h3 id="ndim">ndim<a class="headerlink" href="#ndim" title="Permanent link">&para;</a></h3>
<details class="note" open="open"><summary>attribute ndim</summary><div class="highlight"><pre><span></span><code><span class="k">val</span> <span class="n">ndim</span> <span class="o">:</span> <span class="n">t</span> <span class="o">-&gt;</span> <span class="kt">int</span>
<span class="k">val</span> <span class="n">ndim_opt</span> <span class="o">:</span> <span class="n">t</span> <span class="o">-&gt;</span> <span class="o">(</span><span class="kt">int</span><span class="o">)</span> <span class="n">option</span>
</code></pre></div>

<p>This attribute is documented in <code>create</code> above. The first version raises Not_found
if the attribute is None. The _opt version returns an option.</p>
</details>
<h3 id="nnz">nnz<a class="headerlink" href="#nnz" title="Permanent link">&para;</a></h3>
<details class="note" open="open"><summary>attribute nnz</summary><div class="highlight"><pre><span></span><code><span class="k">val</span> <span class="n">nnz</span> <span class="o">:</span> <span class="n">t</span> <span class="o">-&gt;</span> <span class="nn">Py</span><span class="p">.</span><span class="nn">Object</span><span class="p">.</span><span class="n">t</span>
<span class="k">val</span> <span class="n">nnz_opt</span> <span class="o">:</span> <span class="n">t</span> <span class="o">-&gt;</span> <span class="o">(</span><span class="nn">Py</span><span class="p">.</span><span class="nn">Object</span><span class="p">.</span><span class="n">t</span><span class="o">)</span> <span class="n">option</span>
</code></pre></div>

<p>This attribute is documented in <code>create</code> above. The first version raises Not_found
if the attribute is None. The _opt version returns an option.</p>
</details>
<h3 id="data">data<a class="headerlink" href="#data" title="Permanent link">&para;</a></h3>
<details class="note" open="open"><summary>attribute data</summary><div class="highlight"><pre><span></span><code><span class="k">val</span> <span class="n">data</span> <span class="o">:</span> <span class="n">t</span> <span class="o">-&gt;</span> <span class="nn">Py</span><span class="p">.</span><span class="nn">Object</span><span class="p">.</span><span class="n">t</span>
<span class="k">val</span> <span class="n">data_opt</span> <span class="o">:</span> <span class="n">t</span> <span class="o">-&gt;</span> <span class="o">(</span><span class="nn">Py</span><span class="p">.</span><span class="nn">Object</span><span class="p">.</span><span class="n">t</span><span class="o">)</span> <span class="n">option</span>
</code></pre></div>

<p>This attribute is documented in <code>create</code> above. The first version raises Not_found
if the attribute is None. The _opt version returns an option.</p>
</details>
<h3 id="indices">indices<a class="headerlink" href="#indices" title="Permanent link">&para;</a></h3>
<details class="note" open="open"><summary>attribute indices</summary><div class="highlight"><pre><span></span><code><span class="k">val</span> <span class="n">indices</span> <span class="o">:</span> <span class="n">t</span> <span class="o">-&gt;</span> <span class="nn">Py</span><span class="p">.</span><span class="nn">Object</span><span class="p">.</span><span class="n">t</span>
<span class="k">val</span> <span class="n">indices_opt</span> <span class="o">:</span> <span class="n">t</span> <span class="o">-&gt;</span> <span class="o">(</span><span class="nn">Py</span><span class="p">.</span><span class="nn">Object</span><span class="p">.</span><span class="n">t</span><span class="o">)</span> <span class="n">option</span>
</code></pre></div>

<p>This attribute is documented in <code>create</code> above. The first version raises Not_found
if the attribute is None. The _opt version returns an option.</p>
</details>
<h3 id="indptr">indptr<a class="headerlink" href="#indptr" title="Permanent link">&para;</a></h3>
<details class="note" open="open"><summary>attribute indptr</summary><div class="highlight"><pre><span></span><code><span class="k">val</span> <span class="n">indptr</span> <span class="o">:</span> <span class="n">t</span> <span class="o">-&gt;</span> <span class="nn">Py</span><span class="p">.</span><span class="nn">Object</span><span class="p">.</span><span class="n">t</span>
<span class="k">val</span> <span class="n">indptr_opt</span> <span class="o">:</span> <span class="n">t</span> <span class="o">-&gt;</span> <span class="o">(</span><span class="nn">Py</span><span class="p">.</span><span class="nn">Object</span><span class="p">.</span><span class="n">t</span><span class="o">)</span> <span class="n">option</span>
</code></pre></div>

<p>This attribute is documented in <code>create</code> above. The first version raises Not_found
if the attribute is None. The _opt version returns an option.</p>
</details>
<h3 id="has_sorted_indices">has_sorted_indices<a class="headerlink" href="#has_sorted_indices" title="Permanent link">&para;</a></h3>
<details class="note" open="open"><summary>attribute has_sorted_indices</summary><div class="highlight"><pre><span></span><code><span class="k">val</span> <span class="n">has_sorted_indices</span> <span class="o">:</span> <span class="n">t</span> <span class="o">-&gt;</span> <span class="nn">Py</span><span class="p">.</span><span class="nn">Object</span><span class="p">.</span><span class="n">t</span>
<span class="k">val</span> <span class="n">has_sorted_indices_opt</span> <span class="o">:</span> <span class="n">t</span> <span class="o">-&gt;</span> <span class="o">(</span><span class="nn">Py</span><span class="p">.</span><span class="nn">Object</span><span class="p">.</span><span class="n">t</span><span class="o">)</span> <span class="n">option</span>
</code></pre></div>

<p>This attribute is documented in <code>create</code> above. The first version raises Not_found
if the attribute is None. The _opt version returns an option.</p>
</details>
<h3 id="to_string_3">to_string<a class="headerlink" href="#to_string_3" title="Permanent link">&para;</a></h3>
<details class="note" open="open"><summary>method to_string</summary><div class="highlight"><pre><span></span><code><span class="k">val</span> <span class="n">to_string</span><span class="o">:</span> <span class="n">t</span> <span class="o">-&gt;</span> <span class="kt">string</span>
</code></pre></div>

<p>Print the object to a human-readable representation.</p>
</details>
<h3 id="show_3">show<a class="headerlink" href="#show_3" title="Permanent link">&para;</a></h3>
<details class="note" open="open"><summary>method show</summary><div class="highlight"><pre><span></span><code><span class="k">val</span> <span class="n">show</span><span class="o">:</span> <span class="n">t</span> <span class="o">-&gt;</span> <span class="kt">string</span>
</code></pre></div>

<p>Print the object to a human-readable representation.</p>
</details>
<h3 id="pp_3">pp<a class="headerlink" href="#pp_3" title="Permanent link">&para;</a></h3>
<details class="note" open="open"><summary>method pp</summary><div class="highlight"><pre><span></span><code><span class="k">val</span> <span class="n">pp</span><span class="o">:</span> <span class="nn">Format</span><span class="p">.</span><span class="n">formatter</span> <span class="o">-&gt;</span> <span class="n">t</span> <span class="o">-&gt;</span> <span class="kt">unit</span>
</code></pre></div>

<p>Pretty-print the object to a formatter.</p>
</details>
<h2 id="partial">Partial<a class="headerlink" href="#partial" title="Permanent link">&para;</a></h2>
<p>Module <code>Sklearn.Metrics.Pairwise.Partial</code> wraps Python class <a href="https://scikit-learn.org/stable/modules/generated/sklearn.metrics.pairwise.partial.html"><code>sklearn.metrics.pairwise.partial</code></a>.</p>
<div class="highlight"><pre><span></span><code><span class="k">type</span> <span class="n">t</span>
</code></pre></div>

<h3 id="create_4">create<a class="headerlink" href="#create_4" title="Permanent link">&para;</a></h3>
<details class="note" open="open"><summary>constructor and attributes create</summary><div class="highlight"><pre><span></span><code><span class="k">val</span> <span class="n">create</span> <span class="o">:</span>
  <span class="o">?</span><span class="n">keywords</span><span class="o">:(</span><span class="kt">string</span> <span class="o">*</span> <span class="nn">Py</span><span class="p">.</span><span class="nn">Object</span><span class="p">.</span><span class="n">t</span><span class="o">)</span> <span class="kt">list</span> <span class="o">-&gt;</span>
  <span class="n">func</span><span class="o">:</span><span class="nn">Py</span><span class="p">.</span><span class="nn">Object</span><span class="p">.</span><span class="n">t</span> <span class="o">-&gt;</span>
  <span class="nn">Py</span><span class="p">.</span><span class="nn">Object</span><span class="p">.</span><span class="n">t</span> <span class="kt">list</span> <span class="o">-&gt;</span>
  <span class="n">t</span>
</code></pre></div>

<p>partial(func, <em>args, </em>*keywords) - new function with partial application
of the given arguments and keywords.</p>
</details>
<h3 id="to_string_4">to_string<a class="headerlink" href="#to_string_4" title="Permanent link">&para;</a></h3>
<details class="note" open="open"><summary>method to_string</summary><div class="highlight"><pre><span></span><code><span class="k">val</span> <span class="n">to_string</span><span class="o">:</span> <span class="n">t</span> <span class="o">-&gt;</span> <span class="kt">string</span>
</code></pre></div>

<p>Print the object to a human-readable representation.</p>
</details>
<h3 id="show_4">show<a class="headerlink" href="#show_4" title="Permanent link">&para;</a></h3>
<details class="note" open="open"><summary>method show</summary><div class="highlight"><pre><span></span><code><span class="k">val</span> <span class="n">show</span><span class="o">:</span> <span class="n">t</span> <span class="o">-&gt;</span> <span class="kt">string</span>
</code></pre></div>

<p>Print the object to a human-readable representation.</p>
</details>
<h3 id="pp_4">pp<a class="headerlink" href="#pp_4" title="Permanent link">&para;</a></h3>
<details class="note" open="open"><summary>method pp</summary><div class="highlight"><pre><span></span><code><span class="k">val</span> <span class="n">pp</span><span class="o">:</span> <span class="nn">Format</span><span class="p">.</span><span class="n">formatter</span> <span class="o">-&gt;</span> <span class="n">t</span> <span class="o">-&gt;</span> <span class="kt">unit</span>
</code></pre></div>

<p>Pretty-print the object to a formatter.</p>
</details>
<h3 id="additive_chi2_kernel">additive_chi2_kernel<a class="headerlink" href="#additive_chi2_kernel" title="Permanent link">&para;</a></h3>
<details class="note" open="open"><summary>function additive_chi2_kernel</summary><div class="highlight"><pre><span></span><code><span class="k">val</span> <span class="n">additive_chi2_kernel</span> <span class="o">:</span>
  <span class="o">?</span><span class="n">y</span><span class="o">:[&gt;`</span><span class="nc">ArrayLike</span><span class="o">]</span> <span class="nn">Np</span><span class="p">.</span><span class="nn">Obj</span><span class="p">.</span><span class="n">t</span> <span class="o">-&gt;</span>
  <span class="n">x</span><span class="o">:[&gt;`</span><span class="nc">ArrayLike</span><span class="o">]</span> <span class="nn">Np</span><span class="p">.</span><span class="nn">Obj</span><span class="p">.</span><span class="n">t</span> <span class="o">-&gt;</span>
  <span class="kt">unit</span> <span class="o">-&gt;</span>
  <span class="o">[&gt;`</span><span class="nc">ArrayLike</span><span class="o">]</span> <span class="nn">Np</span><span class="p">.</span><span class="nn">Obj</span><span class="p">.</span><span class="n">t</span>
</code></pre></div>

<p>Computes the additive chi-squared kernel between observations in X and Y</p>
<p>The chi-squared kernel is computed between each pair of rows in X and Y.  X
and Y have to be non-negative. This kernel is most commonly applied to
histograms.</p>
<p>The chi-squared kernel is given by::</p>
<div class="codehilite"><pre><span></span><code>k(x, y) = -Sum [(x - y)^2 / (x + y)]
</code></pre></div>


<p>It can be interpreted as a weighted difference per entry.</p>
<p>Read more in the :ref:<code>User Guide &lt;chi2_kernel&gt;</code>.</p>
<h4>Notes</h4>
<p>As the negative of a distance, this kernel is only conditionally positive
definite.</p>
<h4>Parameters</h4>
<ul>
<li>
<p><strong>X : array-like of shape (n_samples_X, n_features)</strong></p>
</li>
<li>
<p><strong>Y : array of shape (n_samples_Y, n_features)</strong></p>
</li>
</ul>
<h4>Returns</h4>
<ul>
<li><strong>kernel_matrix : array of shape (n_samples_X, n_samples_Y)</strong></li>
</ul>
<h4>References</h4>
<ul>
<li>
<p>Zhang, J. and Marszalek, M. and Lazebnik, S. and Schmid, C.
  Local features and kernels for classification of texture and object</p>
</li>
<li>
<p><strong>categories: A comprehensive study</strong>
  International Journal of Computer Vision 2007</p>
</li>
<li>
<p><strong>https://research.microsoft.com/en-us/um/people/manik/projects/trade-off/papers/ZhangIJCV06.pdf</strong></p>
</li>
</ul>
<h4>See also</h4>
<ul>
<li>
<p><strong>chi2_kernel : The exponentiated version of the kernel, which is usually</strong>
    preferable.</p>
</li>
<li>
<p><strong>sklearn.kernel_approximation.AdditiveChi2Sampler : A Fourier approximation</strong>
    to this kernel.</p>
</li>
</ul>
</details>
<h3 id="check_array">check_array<a class="headerlink" href="#check_array" title="Permanent link">&para;</a></h3>
<details class="note" open="open"><summary>function check_array</summary><div class="highlight"><pre><span></span><code><span class="k">val</span> <span class="n">check_array</span> <span class="o">:</span>
  <span class="o">?</span><span class="n">accept_sparse</span><span class="o">:[`</span><span class="nc">S</span> <span class="k">of</span> <span class="kt">string</span> <span class="o">|</span> <span class="o">`</span><span class="nc">StringList</span> <span class="k">of</span> <span class="kt">string</span> <span class="kt">list</span> <span class="o">|</span> <span class="o">`</span><span class="nc">Bool</span> <span class="k">of</span> <span class="kt">bool</span><span class="o">]</span> <span class="o">-&gt;</span>
  <span class="o">?</span><span class="n">accept_large_sparse</span><span class="o">:</span><span class="kt">bool</span> <span class="o">-&gt;</span>
  <span class="o">?</span><span class="n">dtype</span><span class="o">:[`</span><span class="nc">Dtypes</span> <span class="k">of</span> <span class="nn">Np</span><span class="p">.</span><span class="nn">Dtype</span><span class="p">.</span><span class="n">t</span> <span class="kt">list</span> <span class="o">|</span> <span class="o">`</span><span class="nc">S</span> <span class="k">of</span> <span class="kt">string</span> <span class="o">|</span> <span class="o">`</span><span class="nc">Dtype</span> <span class="k">of</span> <span class="nn">Np</span><span class="p">.</span><span class="nn">Dtype</span><span class="p">.</span><span class="n">t</span> <span class="o">|</span> <span class="o">`</span><span class="nc">None</span><span class="o">]</span> <span class="o">-&gt;</span>
  <span class="o">?</span><span class="n">order</span><span class="o">:[`</span><span class="nc">F</span> <span class="o">|</span> <span class="o">`</span><span class="nc">C</span><span class="o">]</span> <span class="o">-&gt;</span>
  <span class="o">?</span><span class="n">copy</span><span class="o">:</span><span class="kt">bool</span> <span class="o">-&gt;</span>
  <span class="o">?</span><span class="n">force_all_finite</span><span class="o">:[`</span><span class="nc">Allow_nan</span> <span class="o">|</span> <span class="o">`</span><span class="nc">Bool</span> <span class="k">of</span> <span class="kt">bool</span><span class="o">]</span> <span class="o">-&gt;</span>
  <span class="o">?</span><span class="n">ensure_2d</span><span class="o">:</span><span class="kt">bool</span> <span class="o">-&gt;</span>
  <span class="o">?</span><span class="n">allow_nd</span><span class="o">:</span><span class="kt">bool</span> <span class="o">-&gt;</span>
  <span class="o">?</span><span class="n">ensure_min_samples</span><span class="o">:</span><span class="kt">int</span> <span class="o">-&gt;</span>
  <span class="o">?</span><span class="n">ensure_min_features</span><span class="o">:</span><span class="kt">int</span> <span class="o">-&gt;</span>
  <span class="o">?</span><span class="n">estimator</span><span class="o">:[&gt;`</span><span class="nc">BaseEstimator</span><span class="o">]</span> <span class="nn">Np</span><span class="p">.</span><span class="nn">Obj</span><span class="p">.</span><span class="n">t</span> <span class="o">-&gt;</span>
  <span class="kt">array</span><span class="o">:</span><span class="nn">Py</span><span class="p">.</span><span class="nn">Object</span><span class="p">.</span><span class="n">t</span> <span class="o">-&gt;</span>
  <span class="kt">unit</span> <span class="o">-&gt;</span>
  <span class="nn">Py</span><span class="p">.</span><span class="nn">Object</span><span class="p">.</span><span class="n">t</span>
</code></pre></div>

<p>Input validation on an array, list, sparse matrix or similar.</p>
<p>By default, the input is checked to be a non-empty 2D array containing
only finite values. If the dtype of the array is object, attempt
converting to float, raising on failure.</p>
<h4>Parameters</h4>
<ul>
<li>
<p><strong>array : object</strong>
    Input object to check / convert.</p>
</li>
<li>
<p><strong>accept_sparse : string, boolean or list/tuple of strings (default=False)</strong>
    String[s] representing allowed sparse matrix formats, such as 'csc',
    'csr', etc. If the input is sparse but not in the allowed format,
    it will be converted to the first listed format. True allows the input
    to be any format. False means that a sparse matrix input will
    raise an error.</p>
</li>
<li>
<p><strong>accept_large_sparse : bool (default=True)</strong>
    If a CSR, CSC, COO or BSR sparse matrix is supplied and accepted by
    accept_sparse, accept_large_sparse=False will cause it to be accepted
    only if its indices are stored with a 32-bit dtype.</p>
<p>.. versionadded:: 0.20</p>
</li>
<li>
<p><strong>dtype : string, type, list of types or None (default='numeric')</strong>
    Data type of result. If None, the dtype of the input is preserved.
    If 'numeric', dtype is preserved unless array.dtype is object.
    If dtype is a list of types, conversion on the first type is only
    performed if the dtype of the input is not in the list.</p>
</li>
<li>
<p><strong>order : 'F', 'C' or None (default=None)</strong>
    Whether an array will be forced to be fortran or c-style.
    When order is None (default), then if copy=False, nothing is ensured
    about the memory layout of the output array; otherwise (copy=True)
    the memory layout of the returned array is kept as close as possible
    to the original array.</p>
</li>
<li>
<p><strong>copy : boolean (default=False)</strong>
    Whether a forced copy will be triggered. If copy=False, a copy might
    be triggered by a conversion.</p>
</li>
<li>
<p><strong>force_all_finite : boolean or 'allow-nan', (default=True)</strong>
    Whether to raise an error on np.inf, np.nan, pd.NA in array. The
    possibilities are:</p>
<ul>
<li>True: Force all values of array to be finite.</li>
<li>False: accepts np.inf, np.nan, pd.NA in array.</li>
<li>'allow-nan': accepts only np.nan and pd.NA values in array. Values
  cannot be infinite.</li>
</ul>
<p>.. versionadded:: 0.20
   <code>force_all_finite</code> accepts the string <code>'allow-nan'</code>.</p>
<p>.. versionchanged:: 0.23
   Accepts <code>pd.NA</code> and converts it into <code>np.nan</code></p>
</li>
<li>
<p><strong>ensure_2d : boolean (default=True)</strong>
    Whether to raise a value error if array is not 2D.</p>
</li>
<li>
<p><strong>allow_nd : boolean (default=False)</strong>
    Whether to allow array.ndim &gt; 2.</p>
</li>
<li>
<p><strong>ensure_min_samples : int (default=1)</strong>
    Make sure that the array has a minimum number of samples in its first
    axis (rows for a 2D array). Setting to 0 disables this check.</p>
</li>
<li>
<p><strong>ensure_min_features : int (default=1)</strong>
    Make sure that the 2D array has some minimum number of features
    (columns). The default value of 1 rejects empty datasets.
    This check is only enforced when the input data has effectively 2
    dimensions or is originally 1D and <code>ensure_2d</code> is True. Setting to 0
    disables this check.</p>
</li>
<li>
<p><strong>estimator : str or estimator instance (default=None)</strong>
    If passed, include the name of the estimator in warning messages.</p>
</li>
</ul>
<h4>Returns</h4>
<ul>
<li><strong>array_converted : object</strong>
    The converted and validated array.</li>
</ul>
</details>
<h3 id="check_non_negative">check_non_negative<a class="headerlink" href="#check_non_negative" title="Permanent link">&para;</a></h3>
<details class="note" open="open"><summary>function check_non_negative</summary><div class="highlight"><pre><span></span><code><span class="k">val</span> <span class="n">check_non_negative</span> <span class="o">:</span>
  <span class="n">x</span><span class="o">:[&gt;`</span><span class="nc">ArrayLike</span><span class="o">]</span> <span class="nn">Np</span><span class="p">.</span><span class="nn">Obj</span><span class="p">.</span><span class="n">t</span> <span class="o">-&gt;</span>
  <span class="n">whom</span><span class="o">:</span><span class="kt">string</span> <span class="o">-&gt;</span>
  <span class="kt">unit</span> <span class="o">-&gt;</span>
  <span class="nn">Py</span><span class="p">.</span><span class="nn">Object</span><span class="p">.</span><span class="n">t</span>
</code></pre></div>

<p>Check if there is any negative value in an array.</p>
<h4>Parameters</h4>
<ul>
<li>
<p><strong>X : array-like or sparse matrix</strong>
    Input data.</p>
</li>
<li>
<p><strong>whom : string</strong>
    Who passed X to this function.</p>
</li>
</ul>
</details>
<h3 id="check_paired_arrays">check_paired_arrays<a class="headerlink" href="#check_paired_arrays" title="Permanent link">&para;</a></h3>
<details class="note" open="open"><summary>function check_paired_arrays</summary><div class="highlight"><pre><span></span><code><span class="k">val</span> <span class="n">check_paired_arrays</span> <span class="o">:</span>
  <span class="n">x</span><span class="o">:[&gt;`</span><span class="nc">ArrayLike</span><span class="o">]</span> <span class="nn">Np</span><span class="p">.</span><span class="nn">Obj</span><span class="p">.</span><span class="n">t</span> <span class="o">-&gt;</span>
  <span class="n">y</span><span class="o">:[&gt;`</span><span class="nc">ArrayLike</span><span class="o">]</span> <span class="nn">Np</span><span class="p">.</span><span class="nn">Obj</span><span class="p">.</span><span class="n">t</span> <span class="o">-&gt;</span>
  <span class="kt">unit</span> <span class="o">-&gt;</span>
  <span class="o">([&gt;`</span><span class="nc">ArrayLike</span><span class="o">]</span> <span class="nn">Np</span><span class="p">.</span><span class="nn">Obj</span><span class="p">.</span><span class="n">t</span> <span class="o">*</span> <span class="o">[&gt;`</span><span class="nc">ArrayLike</span><span class="o">]</span> <span class="nn">Np</span><span class="p">.</span><span class="nn">Obj</span><span class="p">.</span><span class="n">t</span><span class="o">)</span>
</code></pre></div>

<p>Set X and Y appropriately and checks inputs for paired distances</p>
<p>All paired distance metrics should use this function first to assert that
the given parameters are correct and safe to use.</p>
<p>Specifically, this function first ensures that both X and Y are arrays,
then checks that they are at least two dimensional while ensuring that
their elements are floats. Finally, the function checks that the size
of the dimensions of the two arrays are equal.</p>
<h4>Parameters</h4>
<ul>
<li>
<p><strong>X : {array-like, sparse matrix}, shape (n_samples_a, n_features)</strong></p>
</li>
<li>
<p><strong>Y : {array-like, sparse matrix}, shape (n_samples_b, n_features)</strong></p>
</li>
</ul>
<h4>Returns</h4>
<ul>
<li>
<p><strong>safe_X : {array-like, sparse matrix}, shape (n_samples_a, n_features)</strong>
    An array equal to X, guaranteed to be a numpy array.</p>
</li>
<li>
<p><strong>safe_Y : {array-like, sparse matrix}, shape (n_samples_b, n_features)</strong>
    An array equal to Y if Y was not None, guaranteed to be a numpy array.
    If Y was None, safe_Y will be a pointer to X.</p>
</li>
</ul>
</details>
<h3 id="check_pairwise_arrays">check_pairwise_arrays<a class="headerlink" href="#check_pairwise_arrays" title="Permanent link">&para;</a></h3>
<details class="note" open="open"><summary>function check_pairwise_arrays</summary><div class="highlight"><pre><span></span><code><span class="k">val</span> <span class="n">check_pairwise_arrays</span> <span class="o">:</span>
  <span class="o">?</span><span class="n">precomputed</span><span class="o">:</span><span class="kt">bool</span> <span class="o">-&gt;</span>
  <span class="o">?</span><span class="n">dtype</span><span class="o">:[`</span><span class="nc">Dtypes</span> <span class="k">of</span> <span class="nn">Np</span><span class="p">.</span><span class="nn">Dtype</span><span class="p">.</span><span class="n">t</span> <span class="kt">list</span> <span class="o">|</span> <span class="o">`</span><span class="nc">S</span> <span class="k">of</span> <span class="kt">string</span> <span class="o">|</span> <span class="o">`</span><span class="nc">Dtype</span> <span class="k">of</span> <span class="nn">Np</span><span class="p">.</span><span class="nn">Dtype</span><span class="p">.</span><span class="n">t</span><span class="o">]</span> <span class="o">-&gt;</span>
  <span class="o">?</span><span class="n">accept_sparse</span><span class="o">:[`</span><span class="nc">S</span> <span class="k">of</span> <span class="kt">string</span> <span class="o">|</span> <span class="o">`</span><span class="nc">StringList</span> <span class="k">of</span> <span class="kt">string</span> <span class="kt">list</span> <span class="o">|</span> <span class="o">`</span><span class="nc">Bool</span> <span class="k">of</span> <span class="kt">bool</span><span class="o">]</span> <span class="o">-&gt;</span>
  <span class="o">?</span><span class="n">force_all_finite</span><span class="o">:[`</span><span class="nc">Allow_nan</span> <span class="o">|</span> <span class="o">`</span><span class="nc">Bool</span> <span class="k">of</span> <span class="kt">bool</span><span class="o">]</span> <span class="o">-&gt;</span>
  <span class="o">?</span><span class="n">copy</span><span class="o">:</span><span class="kt">bool</span> <span class="o">-&gt;</span>
  <span class="n">x</span><span class="o">:[&gt;`</span><span class="nc">ArrayLike</span><span class="o">]</span> <span class="nn">Np</span><span class="p">.</span><span class="nn">Obj</span><span class="p">.</span><span class="n">t</span> <span class="o">-&gt;</span>
  <span class="n">y</span><span class="o">:[&gt;`</span><span class="nc">ArrayLike</span><span class="o">]</span> <span class="nn">Np</span><span class="p">.</span><span class="nn">Obj</span><span class="p">.</span><span class="n">t</span> <span class="o">-&gt;</span>
  <span class="kt">unit</span> <span class="o">-&gt;</span>
  <span class="o">([&gt;`</span><span class="nc">ArrayLike</span><span class="o">]</span> <span class="nn">Np</span><span class="p">.</span><span class="nn">Obj</span><span class="p">.</span><span class="n">t</span> <span class="o">*</span> <span class="o">[&gt;`</span><span class="nc">ArrayLike</span><span class="o">]</span> <span class="nn">Np</span><span class="p">.</span><span class="nn">Obj</span><span class="p">.</span><span class="n">t</span><span class="o">)</span>
</code></pre></div>

<p>Set X and Y appropriately and checks inputs</p>
<p>If Y is None, it is set as a pointer to X (i.e. not a copy).
If Y is given, this does not happen.
All distance metrics should use this function first to assert that the
given parameters are correct and safe to use.</p>
<p>Specifically, this function first ensures that both X and Y are arrays,
then checks that they are at least two dimensional while ensuring that
their elements are floats (or dtype if provided). Finally, the function
checks that the size of the second dimension of the two arrays is equal, or
the equivalent check for a precomputed distance matrix.</p>
<h4>Parameters</h4>
<ul>
<li>
<p><strong>X : {array-like, sparse matrix}, shape (n_samples_a, n_features)</strong></p>
</li>
<li>
<p><strong>Y : {array-like, sparse matrix}, shape (n_samples_b, n_features)</strong></p>
</li>
<li>
<p><strong>precomputed : bool</strong>
    True if X is to be treated as precomputed distances to the samples in
    Y.</p>
</li>
<li>
<p><strong>dtype : string, type, list of types or None (default=None)</strong>
    Data type required for X and Y. If None, the dtype will be an
    appropriate float type selected by _return_float_dtype.</p>
<p>.. versionadded:: 0.18</p>
</li>
<li>
<p><strong>accept_sparse : string, boolean or list/tuple of strings</strong>
    String[s] representing allowed sparse matrix formats, such as 'csc',
    'csr', etc. If the input is sparse but not in the allowed format,
    it will be converted to the first listed format. True allows the input
    to be any format. False means that a sparse matrix input will
    raise an error.</p>
</li>
<li>
<p><strong>force_all_finite : boolean or 'allow-nan', (default=True)</strong>
    Whether to raise an error on np.inf, np.nan, pd.NA in array. The
    possibilities are:</p>
<ul>
<li>True: Force all values of array to be finite.</li>
<li>False: accepts np.inf, np.nan, pd.NA in array.</li>
<li>'allow-nan': accepts only np.nan and pd.NA values in array. Values
  cannot be infinite.</li>
</ul>
<p>.. versionadded:: 0.22
   <code>force_all_finite</code> accepts the string <code>'allow-nan'</code>.</p>
<p>.. versionchanged:: 0.23
   Accepts <code>pd.NA</code> and converts it into <code>np.nan</code></p>
</li>
<li>
<p><strong>copy : bool</strong>
    Whether a forced copy will be triggered. If copy=False, a copy might
    be triggered by a conversion.</p>
<p>.. versionadded:: 0.22</p>
</li>
</ul>
<h4>Returns</h4>
<ul>
<li>
<p><strong>safe_X : {array-like, sparse matrix}, shape (n_samples_a, n_features)</strong>
    An array equal to X, guaranteed to be a numpy array.</p>
</li>
<li>
<p><strong>safe_Y : {array-like, sparse matrix}, shape (n_samples_b, n_features)</strong>
    An array equal to Y if Y was not None, guaranteed to be a numpy array.
    If Y was None, safe_Y will be a pointer to X.</p>
</li>
</ul>
</details>
<h3 id="chi2_kernel">chi2_kernel<a class="headerlink" href="#chi2_kernel" title="Permanent link">&para;</a></h3>
<details class="note" open="open"><summary>function chi2_kernel</summary><div class="highlight"><pre><span></span><code><span class="k">val</span> <span class="n">chi2_kernel</span> <span class="o">:</span>
  <span class="o">?</span><span class="n">y</span><span class="o">:[&gt;`</span><span class="nc">ArrayLike</span><span class="o">]</span> <span class="nn">Np</span><span class="p">.</span><span class="nn">Obj</span><span class="p">.</span><span class="n">t</span> <span class="o">-&gt;</span>
  <span class="o">?</span><span class="n">gamma</span><span class="o">:</span><span class="kt">float</span> <span class="o">-&gt;</span>
  <span class="n">x</span><span class="o">:[&gt;`</span><span class="nc">ArrayLike</span><span class="o">]</span> <span class="nn">Np</span><span class="p">.</span><span class="nn">Obj</span><span class="p">.</span><span class="n">t</span> <span class="o">-&gt;</span>
  <span class="kt">unit</span> <span class="o">-&gt;</span>
  <span class="o">[&gt;`</span><span class="nc">ArrayLike</span><span class="o">]</span> <span class="nn">Np</span><span class="p">.</span><span class="nn">Obj</span><span class="p">.</span><span class="n">t</span>
</code></pre></div>

<p>Computes the exponential chi-squared kernel X and Y.</p>
<p>The chi-squared kernel is computed between each pair of rows in X and Y.  X
and Y have to be non-negative. This kernel is most commonly applied to
histograms.</p>
<p>The chi-squared kernel is given by::</p>
<div class="codehilite"><pre><span></span><code>k(x, y) = exp(-gamma Sum [(x - y)^2 / (x + y)])
</code></pre></div>


<p>It can be interpreted as a weighted difference per entry.</p>
<p>Read more in the :ref:<code>User Guide &lt;chi2_kernel&gt;</code>.</p>
<h4>Parameters</h4>
<ul>
<li>
<p><strong>X : array-like of shape (n_samples_X, n_features)</strong></p>
</li>
<li>
<p><strong>Y : array of shape (n_samples_Y, n_features)</strong></p>
</li>
<li>
<p><strong>gamma : float, default=1.</strong>
    Scaling parameter of the chi2 kernel.</p>
</li>
</ul>
<h4>Returns</h4>
<ul>
<li><strong>kernel_matrix : array of shape (n_samples_X, n_samples_Y)</strong></li>
</ul>
<h4>References</h4>
<ul>
<li>
<p>Zhang, J. and Marszalek, M. and Lazebnik, S. and Schmid, C.
  Local features and kernels for classification of texture and object</p>
</li>
<li>
<p><strong>categories: A comprehensive study</strong>
  International Journal of Computer Vision 2007</p>
</li>
<li>
<p><strong>https://research.microsoft.com/en-us/um/people/manik/projects/trade-off/papers/ZhangIJCV06.pdf</strong></p>
</li>
</ul>
<h4>See also</h4>
<ul>
<li>
<p><strong>additive_chi2_kernel : The additive version of this kernel</strong></p>
</li>
<li>
<p><strong>sklearn.kernel_approximation.AdditiveChi2Sampler : A Fourier approximation</strong>
    to the additive version of this kernel.</p>
</li>
</ul>
</details>
<h3 id="cosine_distances">cosine_distances<a class="headerlink" href="#cosine_distances" title="Permanent link">&para;</a></h3>
<details class="note" open="open"><summary>function cosine_distances</summary><div class="highlight"><pre><span></span><code><span class="k">val</span> <span class="n">cosine_distances</span> <span class="o">:</span>
  <span class="o">?</span><span class="n">y</span><span class="o">:[&gt;`</span><span class="nc">ArrayLike</span><span class="o">]</span> <span class="nn">Np</span><span class="p">.</span><span class="nn">Obj</span><span class="p">.</span><span class="n">t</span> <span class="o">-&gt;</span>
  <span class="n">x</span><span class="o">:[&gt;`</span><span class="nc">ArrayLike</span><span class="o">]</span> <span class="nn">Np</span><span class="p">.</span><span class="nn">Obj</span><span class="p">.</span><span class="n">t</span> <span class="o">-&gt;</span>
  <span class="kt">unit</span> <span class="o">-&gt;</span>
  <span class="nn">Py</span><span class="p">.</span><span class="nn">Object</span><span class="p">.</span><span class="n">t</span>
</code></pre></div>

<p>Compute cosine distance between samples in X and Y.</p>
<p>Cosine distance is defined as 1.0 minus the cosine similarity.</p>
<p>Read more in the :ref:<code>User Guide &lt;metrics&gt;</code>.</p>
<h4>Parameters</h4>
<ul>
<li>
<p><strong>X : array_like, sparse matrix</strong>
    with shape (n_samples_X, n_features).</p>
</li>
<li>
<p><strong>Y : array_like, sparse matrix (optional)</strong>
    with shape (n_samples_Y, n_features).</p>
</li>
</ul>
<h4>Returns</h4>
<p>distance matrix : array
    An array with shape (n_samples_X, n_samples_Y).</p>
<h4>See also</h4>
<p>sklearn.metrics.pairwise.cosine_similarity</p>
<ul>
<li><strong>scipy.spatial.distance.cosine : dense matrices only</strong></li>
</ul>
</details>
<h3 id="cosine_similarity">cosine_similarity<a class="headerlink" href="#cosine_similarity" title="Permanent link">&para;</a></h3>
<details class="note" open="open"><summary>function cosine_similarity</summary><div class="highlight"><pre><span></span><code><span class="k">val</span> <span class="n">cosine_similarity</span> <span class="o">:</span>
  <span class="o">?</span><span class="n">y</span><span class="o">:[&gt;`</span><span class="nc">ArrayLike</span><span class="o">]</span> <span class="nn">Np</span><span class="p">.</span><span class="nn">Obj</span><span class="p">.</span><span class="n">t</span> <span class="o">-&gt;</span>
  <span class="o">?</span><span class="n">dense_output</span><span class="o">:</span><span class="kt">bool</span> <span class="o">-&gt;</span>
  <span class="n">x</span><span class="o">:[&gt;`</span><span class="nc">ArrayLike</span><span class="o">]</span> <span class="nn">Np</span><span class="p">.</span><span class="nn">Obj</span><span class="p">.</span><span class="n">t</span> <span class="o">-&gt;</span>
  <span class="kt">unit</span> <span class="o">-&gt;</span>
  <span class="nn">Py</span><span class="p">.</span><span class="nn">Object</span><span class="p">.</span><span class="n">t</span>
</code></pre></div>

<p>Compute cosine similarity between samples in X and Y.</p>
<p>Cosine similarity, or the cosine kernel, computes similarity as the
normalized dot product of X and Y:</p>
<div class="codehilite"><pre><span></span><code>K(X, Y) = &lt;X, Y&gt; / (||X||*||Y||)
</code></pre></div>


<p>On L2-normalized data, this function is equivalent to linear_kernel.</p>
<p>Read more in the :ref:<code>User Guide &lt;cosine_similarity&gt;</code>.</p>
<h4>Parameters</h4>
<ul>
<li>
<p><strong>X : ndarray or sparse array, shape: (n_samples_X, n_features)</strong>
    Input data.</p>
</li>
<li>
<p><strong>Y : ndarray or sparse array, shape: (n_samples_Y, n_features)</strong>
    Input data. If <code>None</code>, the output will be the pairwise
    similarities between all samples in <code>X</code>.</p>
</li>
<li>
<p><strong>dense_output : boolean (optional), default True</strong>
    Whether to return dense output even when the input is sparse. If
    <code>False</code>, the output is sparse if both input arrays are sparse.</p>
<p>.. versionadded:: 0.17
   parameter <code>dense_output</code> for dense output.</p>
</li>
</ul>
<h4>Returns</h4>
<p>kernel matrix : array
    An array with shape (n_samples_X, n_samples_Y).</p>
</details>
<h3 id="delayed">delayed<a class="headerlink" href="#delayed" title="Permanent link">&para;</a></h3>
<details class="note" open="open"><summary>function delayed</summary><div class="highlight"><pre><span></span><code><span class="k">val</span> <span class="n">delayed</span> <span class="o">:</span>
  <span class="o">?</span><span class="n">check_pickle</span><span class="o">:</span><span class="nn">Py</span><span class="p">.</span><span class="nn">Object</span><span class="p">.</span><span class="n">t</span> <span class="o">-&gt;</span>
  <span class="n">function_</span><span class="o">:</span><span class="nn">Py</span><span class="p">.</span><span class="nn">Object</span><span class="p">.</span><span class="n">t</span> <span class="o">-&gt;</span>
  <span class="kt">unit</span> <span class="o">-&gt;</span>
  <span class="nn">Py</span><span class="p">.</span><span class="nn">Object</span><span class="p">.</span><span class="n">t</span>
</code></pre></div>

<p>Decorator used to capture the arguments of a function.</p>
</details>
<h3 id="distance_metrics">distance_metrics<a class="headerlink" href="#distance_metrics" title="Permanent link">&para;</a></h3>
<details class="note" open="open"><summary>function distance_metrics</summary><div class="highlight"><pre><span></span><code><span class="k">val</span> <span class="n">distance_metrics</span> <span class="o">:</span>
  <span class="kt">unit</span> <span class="o">-&gt;</span>
  <span class="nn">Py</span><span class="p">.</span><span class="nn">Object</span><span class="p">.</span><span class="n">t</span>
</code></pre></div>

<p>Valid metrics for pairwise_distances.</p>
<p>This function simply returns the valid pairwise distance metrics.
It exists to allow for a description of the mapping for
each of the valid strings.</p>
<p>The valid distance metrics, and the function they map to, are:</p>
<p>=============== ========================================
metric          Function
=============== ========================================
'cityblock'     metrics.pairwise.manhattan_distances
'cosine'        metrics.pairwise.cosine_distances
'euclidean'     metrics.pairwise.euclidean_distances
'haversine'     metrics.pairwise.haversine_distances
'l1'            metrics.pairwise.manhattan_distances
'l2'            metrics.pairwise.euclidean_distances
'manhattan'     metrics.pairwise.manhattan_distances
'nan_euclidean' metrics.pairwise.nan_euclidean_distances
=============== ========================================</p>
<p>Read more in the :ref:<code>User Guide &lt;metrics&gt;</code>.</p>
</details>
<h3 id="effective_n_jobs">effective_n_jobs<a class="headerlink" href="#effective_n_jobs" title="Permanent link">&para;</a></h3>
<details class="note" open="open"><summary>function effective_n_jobs</summary><div class="highlight"><pre><span></span><code><span class="k">val</span> <span class="n">effective_n_jobs</span> <span class="o">:</span>
  <span class="o">?</span><span class="n">n_jobs</span><span class="o">:</span><span class="nn">Py</span><span class="p">.</span><span class="nn">Object</span><span class="p">.</span><span class="n">t</span> <span class="o">-&gt;</span>
  <span class="kt">unit</span> <span class="o">-&gt;</span>
  <span class="nn">Py</span><span class="p">.</span><span class="nn">Object</span><span class="p">.</span><span class="n">t</span>
</code></pre></div>

<p>Determine the number of jobs that can actually run in parallel</p>
<p>n_jobs is the number of workers requested by the callers. Passing n_jobs=-1
means requesting all available workers for instance matching the number of
CPU cores on the worker host(s).</p>
<p>This method should return a guesstimate of the number of workers that can
actually perform work concurrently with the currently enabled default
backend. The primary use case is to make it possible for the caller to know
in how many chunks to slice the work.</p>
<p>In general working on larger data chunks is more efficient (less scheduling
overhead and better use of CPU cache prefetching heuristics) as long as all
the workers have enough work to do.</p>
<ul>
<li><strong>Warning: this function is experimental and subject to change in a future</strong>
version of joblib.</li>
</ul>
<p>.. versionadded:: 0.10</p>
</details>
<h3 id="euclidean_distances">euclidean_distances<a class="headerlink" href="#euclidean_distances" title="Permanent link">&para;</a></h3>
<details class="note" open="open"><summary>function euclidean_distances</summary><div class="highlight"><pre><span></span><code><span class="k">val</span> <span class="n">euclidean_distances</span> <span class="o">:</span>
  <span class="o">?</span><span class="n">y</span><span class="o">:[&gt;`</span><span class="nc">ArrayLike</span><span class="o">]</span> <span class="nn">Np</span><span class="p">.</span><span class="nn">Obj</span><span class="p">.</span><span class="n">t</span> <span class="o">-&gt;</span>
  <span class="o">?</span><span class="n">y_norm_squared</span><span class="o">:[&gt;`</span><span class="nc">ArrayLike</span><span class="o">]</span> <span class="nn">Np</span><span class="p">.</span><span class="nn">Obj</span><span class="p">.</span><span class="n">t</span> <span class="o">-&gt;</span>
  <span class="o">?</span><span class="n">squared</span><span class="o">:</span><span class="kt">bool</span> <span class="o">-&gt;</span>
  <span class="o">?</span><span class="n">x_norm_squared</span><span class="o">:[&gt;`</span><span class="nc">ArrayLike</span><span class="o">]</span> <span class="nn">Np</span><span class="p">.</span><span class="nn">Obj</span><span class="p">.</span><span class="n">t</span> <span class="o">-&gt;</span>
  <span class="n">x</span><span class="o">:[&gt;`</span><span class="nc">ArrayLike</span><span class="o">]</span> <span class="nn">Np</span><span class="p">.</span><span class="nn">Obj</span><span class="p">.</span><span class="n">t</span> <span class="o">-&gt;</span>
  <span class="kt">unit</span> <span class="o">-&gt;</span>
  <span class="o">[&gt;`</span><span class="nc">ArrayLike</span><span class="o">]</span> <span class="nn">Np</span><span class="p">.</span><span class="nn">Obj</span><span class="p">.</span><span class="n">t</span>
</code></pre></div>

<p>Considering the rows of X (and Y=X) as vectors, compute the
distance matrix between each pair of vectors.</p>
<p>For efficiency reasons, the euclidean distance between a pair of row
vector x and y is computed as::</p>
<div class="codehilite"><pre><span></span><code>dist(x, y) = sqrt(dot(x, x) - 2 * dot(x, y) + dot(y, y))
</code></pre></div>


<p>This formulation has two advantages over other ways of computing distances.
First, it is computationally efficient when dealing with sparse data.
Second, if one argument varies but the other remains unchanged, then
<code>dot(x, x)</code> and/or <code>dot(y, y)</code> can be pre-computed.</p>
<p>However, this is not the most precise way of doing this computation, and
the distance matrix returned by this function may not be exactly
symmetric as required by, e.g., <code>scipy.spatial.distance</code> functions.</p>
<p>Read more in the :ref:<code>User Guide &lt;metrics&gt;</code>.</p>
<h4>Parameters</h4>
<ul>
<li>
<p><strong>X : {array-like, sparse matrix}, shape (n_samples_1, n_features)</strong></p>
</li>
<li>
<p><strong>Y : {array-like, sparse matrix}, shape (n_samples_2, n_features)</strong></p>
</li>
<li>
<p><strong>Y_norm_squared : array-like, shape (n_samples_2, ), optional</strong>
    Pre-computed dot-products of vectors in Y (e.g.,
    <code>(Y**2).sum(axis=1)</code>)
    May be ignored in some cases, see the note below.</p>
</li>
<li>
<p><strong>squared : boolean, optional</strong>
    Return squared Euclidean distances.</p>
</li>
<li>
<p><strong>X_norm_squared : array-like of shape (n_samples,), optional</strong>
    Pre-computed dot-products of vectors in X (e.g.,
    <code>(X**2).sum(axis=1)</code>)
    May be ignored in some cases, see the note below.</p>
</li>
</ul>
<h4>Notes</h4>
<p>To achieve better accuracy, <code>X_norm_squared</code>and <code>Y_norm_squared</code> may be
unused if they are passed as <code>float32</code>.</p>
<h4>Returns</h4>
<ul>
<li><strong>distances : array, shape (n_samples_1, n_samples_2)</strong></li>
</ul>
<h4>Examples</h4>
<div class="highlight"><pre><span></span><code><span class="o">&gt;&gt;&gt;</span> <span class="kn">from</span> <span class="nn">sklearn.metrics.pairwise</span> <span class="kn">import</span> <span class="n">euclidean_distances</span>
<span class="o">&gt;&gt;&gt;</span> <span class="n">X</span> <span class="o">=</span> <span class="p">[[</span><span class="mi">0</span><span class="p">,</span> <span class="mi">1</span><span class="p">],</span> <span class="p">[</span><span class="mi">1</span><span class="p">,</span> <span class="mi">1</span><span class="p">]]</span>
<span class="o">&gt;&gt;&gt;</span> <span class="c1"># distance between rows of X</span>
<span class="o">&gt;&gt;&gt;</span> <span class="n">euclidean_distances</span><span class="p">(</span><span class="n">X</span><span class="p">,</span> <span class="n">X</span><span class="p">)</span>
<span class="n">array</span><span class="p">([[</span><span class="mf">0.</span><span class="p">,</span> <span class="mf">1.</span><span class="p">],</span>
       <span class="p">[</span><span class="mf">1.</span><span class="p">,</span> <span class="mf">0.</span><span class="p">]])</span>
<span class="o">&gt;&gt;&gt;</span> <span class="c1"># get distance to origin</span>
<span class="o">&gt;&gt;&gt;</span> <span class="n">euclidean_distances</span><span class="p">(</span><span class="n">X</span><span class="p">,</span> <span class="p">[[</span><span class="mi">0</span><span class="p">,</span> <span class="mi">0</span><span class="p">]])</span>
<span class="n">array</span><span class="p">([[</span><span class="mf">1.</span>        <span class="p">],</span>
       <span class="p">[</span><span class="mf">1.41421356</span><span class="p">]])</span>
</code></pre></div>

<h4>See also</h4>
<ul>
<li><strong>paired_distances : distances betweens pairs of elements of X and Y.</strong></li>
</ul>
</details>
<h3 id="gen_batches">gen_batches<a class="headerlink" href="#gen_batches" title="Permanent link">&para;</a></h3>
<details class="note" open="open"><summary>function gen_batches</summary><div class="highlight"><pre><span></span><code><span class="k">val</span> <span class="n">gen_batches</span> <span class="o">:</span>
  <span class="o">?</span><span class="n">min_batch_size</span><span class="o">:</span><span class="kt">int</span> <span class="o">-&gt;</span>
  <span class="n">n</span><span class="o">:</span><span class="kt">int</span> <span class="o">-&gt;</span>
  <span class="n">batch_size</span><span class="o">:</span><span class="nn">Py</span><span class="p">.</span><span class="nn">Object</span><span class="p">.</span><span class="n">t</span> <span class="o">-&gt;</span>
  <span class="kt">unit</span> <span class="o">-&gt;</span>
  <span class="nn">Py</span><span class="p">.</span><span class="nn">Object</span><span class="p">.</span><span class="n">t</span>
</code></pre></div>

<p>Generator to create slices containing batch_size elements, from 0 to n.</p>
<p>The last slice may contain less than batch_size elements, when batch_size
does not divide n.</p>
<h4>Parameters</h4>
<ul>
<li>
<p><strong>n : int</strong></p>
</li>
<li>
<p><strong>batch_size : int</strong>
    Number of element in each batch</p>
</li>
<li>
<p><strong>min_batch_size : int, default=0</strong>
    Minimum batch size to produce.</p>
</li>
</ul>
<h4>Yields</h4>
<p>slice of batch_size elements</p>
<h4>Examples</h4>
<div class="highlight"><pre><span></span><code><span class="o">&gt;&gt;&gt;</span> <span class="kn">from</span> <span class="nn">sklearn.utils</span> <span class="kn">import</span> <span class="n">gen_batches</span>
<span class="o">&gt;&gt;&gt;</span> <span class="nb">list</span><span class="p">(</span><span class="n">gen_batches</span><span class="p">(</span><span class="mi">7</span><span class="p">,</span> <span class="mi">3</span><span class="p">))</span>
<span class="p">[</span><span class="nb">slice</span><span class="p">(</span><span class="mi">0</span><span class="p">,</span> <span class="mi">3</span><span class="p">,</span> <span class="kc">None</span><span class="p">),</span> <span class="nb">slice</span><span class="p">(</span><span class="mi">3</span><span class="p">,</span> <span class="mi">6</span><span class="p">,</span> <span class="kc">None</span><span class="p">),</span> <span class="nb">slice</span><span class="p">(</span><span class="mi">6</span><span class="p">,</span> <span class="mi">7</span><span class="p">,</span> <span class="kc">None</span><span class="p">)]</span>
<span class="o">&gt;&gt;&gt;</span> <span class="nb">list</span><span class="p">(</span><span class="n">gen_batches</span><span class="p">(</span><span class="mi">6</span><span class="p">,</span> <span class="mi">3</span><span class="p">))</span>
<span class="p">[</span><span class="nb">slice</span><span class="p">(</span><span class="mi">0</span><span class="p">,</span> <span class="mi">3</span><span class="p">,</span> <span class="kc">None</span><span class="p">),</span> <span class="nb">slice</span><span class="p">(</span><span class="mi">3</span><span class="p">,</span> <span class="mi">6</span><span class="p">,</span> <span class="kc">None</span><span class="p">)]</span>
<span class="o">&gt;&gt;&gt;</span> <span class="nb">list</span><span class="p">(</span><span class="n">gen_batches</span><span class="p">(</span><span class="mi">2</span><span class="p">,</span> <span class="mi">3</span><span class="p">))</span>
<span class="p">[</span><span class="nb">slice</span><span class="p">(</span><span class="mi">0</span><span class="p">,</span> <span class="mi">2</span><span class="p">,</span> <span class="kc">None</span><span class="p">)]</span>
<span class="o">&gt;&gt;&gt;</span> <span class="nb">list</span><span class="p">(</span><span class="n">gen_batches</span><span class="p">(</span><span class="mi">7</span><span class="p">,</span> <span class="mi">3</span><span class="p">,</span> <span class="n">min_batch_size</span><span class="o">=</span><span class="mi">0</span><span class="p">))</span>
<span class="p">[</span><span class="nb">slice</span><span class="p">(</span><span class="mi">0</span><span class="p">,</span> <span class="mi">3</span><span class="p">,</span> <span class="kc">None</span><span class="p">),</span> <span class="nb">slice</span><span class="p">(</span><span class="mi">3</span><span class="p">,</span> <span class="mi">6</span><span class="p">,</span> <span class="kc">None</span><span class="p">),</span> <span class="nb">slice</span><span class="p">(</span><span class="mi">6</span><span class="p">,</span> <span class="mi">7</span><span class="p">,</span> <span class="kc">None</span><span class="p">)]</span>
<span class="o">&gt;&gt;&gt;</span> <span class="nb">list</span><span class="p">(</span><span class="n">gen_batches</span><span class="p">(</span><span class="mi">7</span><span class="p">,</span> <span class="mi">3</span><span class="p">,</span> <span class="n">min_batch_size</span><span class="o">=</span><span class="mi">2</span><span class="p">))</span>
<span class="p">[</span><span class="nb">slice</span><span class="p">(</span><span class="mi">0</span><span class="p">,</span> <span class="mi">3</span><span class="p">,</span> <span class="kc">None</span><span class="p">),</span> <span class="nb">slice</span><span class="p">(</span><span class="mi">3</span><span class="p">,</span> <span class="mi">7</span><span class="p">,</span> <span class="kc">None</span><span class="p">)]</span>
</code></pre></div>

</details>
<h3 id="gen_even_slices">gen_even_slices<a class="headerlink" href="#gen_even_slices" title="Permanent link">&para;</a></h3>
<details class="note" open="open"><summary>function gen_even_slices</summary><div class="highlight"><pre><span></span><code><span class="k">val</span> <span class="n">gen_even_slices</span> <span class="o">:</span>
  <span class="o">?</span><span class="n">n_samples</span><span class="o">:</span><span class="kt">int</span> <span class="o">-&gt;</span>
  <span class="n">n</span><span class="o">:</span><span class="kt">int</span> <span class="o">-&gt;</span>
  <span class="n">n_packs</span><span class="o">:</span><span class="nn">Py</span><span class="p">.</span><span class="nn">Object</span><span class="p">.</span><span class="n">t</span> <span class="o">-&gt;</span>
  <span class="kt">unit</span> <span class="o">-&gt;</span>
  <span class="nn">Py</span><span class="p">.</span><span class="nn">Object</span><span class="p">.</span><span class="n">t</span>
</code></pre></div>

<p>Generator to create n_packs slices going up to n.</p>
<h4>Parameters</h4>
<ul>
<li>
<p><strong>n : int</strong></p>
</li>
<li>
<p><strong>n_packs : int</strong>
    Number of slices to generate.</p>
</li>
<li>
<p><strong>n_samples : int or None (default = None)</strong>
    Number of samples. Pass n_samples when the slices are to be used for
    sparse matrix indexing; slicing off-the-end raises an exception, while
    it works for NumPy arrays.</p>
</li>
</ul>
<h4>Yields</h4>
<p>slice</p>
<h4>Examples</h4>
<div class="highlight"><pre><span></span><code><span class="o">&gt;&gt;&gt;</span> <span class="kn">from</span> <span class="nn">sklearn.utils</span> <span class="kn">import</span> <span class="n">gen_even_slices</span>
<span class="o">&gt;&gt;&gt;</span> <span class="nb">list</span><span class="p">(</span><span class="n">gen_even_slices</span><span class="p">(</span><span class="mi">10</span><span class="p">,</span> <span class="mi">1</span><span class="p">))</span>
<span class="p">[</span><span class="nb">slice</span><span class="p">(</span><span class="mi">0</span><span class="p">,</span> <span class="mi">10</span><span class="p">,</span> <span class="kc">None</span><span class="p">)]</span>
<span class="o">&gt;&gt;&gt;</span> <span class="nb">list</span><span class="p">(</span><span class="n">gen_even_slices</span><span class="p">(</span><span class="mi">10</span><span class="p">,</span> <span class="mi">10</span><span class="p">))</span>
<span class="p">[</span><span class="nb">slice</span><span class="p">(</span><span class="mi">0</span><span class="p">,</span> <span class="mi">1</span><span class="p">,</span> <span class="kc">None</span><span class="p">),</span> <span class="nb">slice</span><span class="p">(</span><span class="mi">1</span><span class="p">,</span> <span class="mi">2</span><span class="p">,</span> <span class="kc">None</span><span class="p">),</span> <span class="o">...</span><span class="p">,</span> <span class="nb">slice</span><span class="p">(</span><span class="mi">9</span><span class="p">,</span> <span class="mi">10</span><span class="p">,</span> <span class="kc">None</span><span class="p">)]</span>
<span class="o">&gt;&gt;&gt;</span> <span class="nb">list</span><span class="p">(</span><span class="n">gen_even_slices</span><span class="p">(</span><span class="mi">10</span><span class="p">,</span> <span class="mi">5</span><span class="p">))</span>
<span class="p">[</span><span class="nb">slice</span><span class="p">(</span><span class="mi">0</span><span class="p">,</span> <span class="mi">2</span><span class="p">,</span> <span class="kc">None</span><span class="p">),</span> <span class="nb">slice</span><span class="p">(</span><span class="mi">2</span><span class="p">,</span> <span class="mi">4</span><span class="p">,</span> <span class="kc">None</span><span class="p">),</span> <span class="o">...</span><span class="p">,</span> <span class="nb">slice</span><span class="p">(</span><span class="mi">8</span><span class="p">,</span> <span class="mi">10</span><span class="p">,</span> <span class="kc">None</span><span class="p">)]</span>
<span class="o">&gt;&gt;&gt;</span> <span class="nb">list</span><span class="p">(</span><span class="n">gen_even_slices</span><span class="p">(</span><span class="mi">10</span><span class="p">,</span> <span class="mi">3</span><span class="p">))</span>
<span class="p">[</span><span class="nb">slice</span><span class="p">(</span><span class="mi">0</span><span class="p">,</span> <span class="mi">4</span><span class="p">,</span> <span class="kc">None</span><span class="p">),</span> <span class="nb">slice</span><span class="p">(</span><span class="mi">4</span><span class="p">,</span> <span class="mi">7</span><span class="p">,</span> <span class="kc">None</span><span class="p">),</span> <span class="nb">slice</span><span class="p">(</span><span class="mi">7</span><span class="p">,</span> <span class="mi">10</span><span class="p">,</span> <span class="kc">None</span><span class="p">)]</span>
</code></pre></div>

</details>
<h3 id="get_chunk_n_rows">get_chunk_n_rows<a class="headerlink" href="#get_chunk_n_rows" title="Permanent link">&para;</a></h3>
<details class="note" open="open"><summary>function get_chunk_n_rows</summary><div class="highlight"><pre><span></span><code><span class="k">val</span> <span class="n">get_chunk_n_rows</span> <span class="o">:</span>
  <span class="o">?</span><span class="n">max_n_rows</span><span class="o">:</span><span class="kt">int</span> <span class="o">-&gt;</span>
  <span class="o">?</span><span class="n">working_memory</span><span class="o">:[`</span><span class="nc">F</span> <span class="k">of</span> <span class="kt">float</span> <span class="o">|</span> <span class="o">`</span><span class="nc">I</span> <span class="k">of</span> <span class="kt">int</span><span class="o">]</span> <span class="o">-&gt;</span>
  <span class="n">row_bytes</span><span class="o">:</span><span class="kt">int</span> <span class="o">-&gt;</span>
  <span class="kt">unit</span> <span class="o">-&gt;</span>
  <span class="nn">Py</span><span class="p">.</span><span class="nn">Object</span><span class="p">.</span><span class="n">t</span>
</code></pre></div>

<p>Calculates how many rows can be processed within working_memory</p>
<h4>Parameters</h4>
<ul>
<li>
<p><strong>row_bytes : int</strong>
    The expected number of bytes of memory that will be consumed
    during the processing of each row.</p>
</li>
<li>
<p><strong>max_n_rows : int, optional</strong>
    The maximum return value.</p>
</li>
<li>
<p><strong>working_memory : int or float, optional</strong>
    The number of rows to fit inside this number of MiB will be returned.
    When None (default), the value of
    <code>sklearn.get_config()['working_memory']</code> is used.</p>
</li>
</ul>
<h4>Returns</h4>
<p>int or the value of n_samples</p>
<h4>Warns</h4>
<p>Issues a UserWarning if <code>row_bytes</code> exceeds <code>working_memory</code> MiB.</p>
</details>
<h3 id="haversine_distances">haversine_distances<a class="headerlink" href="#haversine_distances" title="Permanent link">&para;</a></h3>
<details class="note" open="open"><summary>function haversine_distances</summary><div class="highlight"><pre><span></span><code><span class="k">val</span> <span class="n">haversine_distances</span> <span class="o">:</span>
  <span class="o">?</span><span class="n">y</span><span class="o">:[&gt;`</span><span class="nc">ArrayLike</span><span class="o">]</span> <span class="nn">Np</span><span class="p">.</span><span class="nn">Obj</span><span class="p">.</span><span class="n">t</span> <span class="o">-&gt;</span>
  <span class="n">x</span><span class="o">:[&gt;`</span><span class="nc">ArrayLike</span><span class="o">]</span> <span class="nn">Np</span><span class="p">.</span><span class="nn">Obj</span><span class="p">.</span><span class="n">t</span> <span class="o">-&gt;</span>
  <span class="kt">unit</span> <span class="o">-&gt;</span>
  <span class="o">[&gt;`</span><span class="nc">ArrayLike</span><span class="o">]</span> <span class="nn">Np</span><span class="p">.</span><span class="nn">Obj</span><span class="p">.</span><span class="n">t</span>
</code></pre></div>

<p>Compute the Haversine distance between samples in X and Y</p>
<p>The Haversine (or great circle) distance is the angular distance between
two points on the surface of a sphere. The first distance of each point is
assumed to be the latitude, the second is the longitude, given in radians.
The dimension of the data must be 2.</p>
<div>
<div class="MathJax_Preview">   D(x, y) = 2\arcsin[\sqrt{\sin^2((x1 - y1) / 2)
                            + \cos(x1)\cos(y1)\sin^2((x2 - y2) / 2)}]
</div>
<script type="math/tex; mode=display">   D(x, y) = 2\arcsin[\sqrt{\sin^2((x1 - y1) / 2)
                            + \cos(x1)\cos(y1)\sin^2((x2 - y2) / 2)}]
</script>
</div>
<h4>Parameters</h4>
<ul>
<li>
<p><strong>X : array_like, shape (n_samples_1, 2)</strong></p>
</li>
<li>
<p><strong>Y : array_like, shape (n_samples_2, 2), optional</strong></p>
</li>
</ul>
<h4>Returns</h4>
<ul>
<li><strong>distance : {array}, shape (n_samples_1, n_samples_2)</strong></li>
</ul>
<h4>Notes</h4>
<p>As the Earth is nearly spherical, the haversine formula provides a good
approximation of the distance between two points of the Earth surface, with
a less than 1% error on average.</p>
<h4>Examples</h4>
<p>We want to calculate the distance between the Ezeiza Airport
(Buenos Aires, Argentina) and the Charles de Gaulle Airport (Paris, France)</p>
<div class="highlight"><pre><span></span><code><span class="o">&gt;&gt;&gt;</span> <span class="kn">from</span> <span class="nn">sklearn.metrics.pairwise</span> <span class="kn">import</span> <span class="n">haversine_distances</span>
<span class="o">&gt;&gt;&gt;</span> <span class="kn">from</span> <span class="nn">math</span> <span class="kn">import</span> <span class="n">radians</span>
<span class="o">&gt;&gt;&gt;</span> <span class="n">bsas</span> <span class="o">=</span> <span class="p">[</span><span class="o">-</span><span class="mf">34.83333</span><span class="p">,</span> <span class="o">-</span><span class="mf">58.5166646</span><span class="p">]</span>
<span class="o">&gt;&gt;&gt;</span> <span class="n">paris</span> <span class="o">=</span> <span class="p">[</span><span class="mf">49.0083899664</span><span class="p">,</span> <span class="mf">2.53844117956</span><span class="p">]</span>
<span class="o">&gt;&gt;&gt;</span> <span class="n">bsas_in_radians</span> <span class="o">=</span> <span class="p">[</span><span class="n">radians</span><span class="p">(</span><span class="n">_</span><span class="p">)</span> <span class="k">for</span> <span class="n">_</span> <span class="ow">in</span> <span class="n">bsas</span><span class="p">]</span>
<span class="o">&gt;&gt;&gt;</span> <span class="n">paris_in_radians</span> <span class="o">=</span> <span class="p">[</span><span class="n">radians</span><span class="p">(</span><span class="n">_</span><span class="p">)</span> <span class="k">for</span> <span class="n">_</span> <span class="ow">in</span> <span class="n">paris</span><span class="p">]</span>
<span class="o">&gt;&gt;&gt;</span> <span class="n">result</span> <span class="o">=</span> <span class="n">haversine_distances</span><span class="p">([</span><span class="n">bsas_in_radians</span><span class="p">,</span> <span class="n">paris_in_radians</span><span class="p">])</span>
<span class="o">&gt;&gt;&gt;</span> <span class="n">result</span> <span class="o">*</span> <span class="mi">6371000</span><span class="o">/</span><span class="mi">1000</span>  <span class="c1"># multiply by Earth radius to get kilometers</span>
<span class="n">array</span><span class="p">([[</span>    <span class="mf">0.</span>        <span class="p">,</span> <span class="mf">11099.54035582</span><span class="p">],</span>
       <span class="p">[</span><span class="mf">11099.54035582</span><span class="p">,</span>     <span class="mf">0.</span>        <span class="p">]])</span>
</code></pre></div>

</details>
<h3 id="is_scalar_nan">is_scalar_nan<a class="headerlink" href="#is_scalar_nan" title="Permanent link">&para;</a></h3>
<details class="note" open="open"><summary>function is_scalar_nan</summary><div class="highlight"><pre><span></span><code><span class="k">val</span> <span class="n">is_scalar_nan</span> <span class="o">:</span>
  <span class="nn">Py</span><span class="p">.</span><span class="nn">Object</span><span class="p">.</span><span class="n">t</span> <span class="o">-&gt;</span>
  <span class="nn">Py</span><span class="p">.</span><span class="nn">Object</span><span class="p">.</span><span class="n">t</span>
</code></pre></div>

<p>Tests if x is NaN</p>
<p>This function is meant to overcome the issue that np.isnan does not allow
non-numerical types as input, and that np.nan is not np.float('nan').</p>
<h4>Parameters</h4>
<ul>
<li><strong>x : any type</strong></li>
</ul>
<h4>Returns</h4>
<p>boolean</p>
<h4>Examples</h4>
<div class="highlight"><pre><span></span><code><span class="o">&gt;&gt;&gt;</span> <span class="n">is_scalar_nan</span><span class="p">(</span><span class="n">np</span><span class="o">.</span><span class="n">nan</span><span class="p">)</span>
<span class="kc">True</span>
<span class="o">&gt;&gt;&gt;</span> <span class="n">is_scalar_nan</span><span class="p">(</span><span class="nb">float</span><span class="p">(</span><span class="s1">&#39;nan&#39;</span><span class="p">))</span>
<span class="kc">True</span>
<span class="o">&gt;&gt;&gt;</span> <span class="n">is_scalar_nan</span><span class="p">(</span><span class="kc">None</span><span class="p">)</span>
<span class="kc">False</span>
<span class="o">&gt;&gt;&gt;</span> <span class="n">is_scalar_nan</span><span class="p">(</span><span class="s1">&#39;&#39;</span><span class="p">)</span>
<span class="kc">False</span>
<span class="o">&gt;&gt;&gt;</span> <span class="n">is_scalar_nan</span><span class="p">([</span><span class="n">np</span><span class="o">.</span><span class="n">nan</span><span class="p">])</span>
<span class="kc">False</span>
</code></pre></div>

</details>
<h3 id="issparse">issparse<a class="headerlink" href="#issparse" title="Permanent link">&para;</a></h3>
<details class="note" open="open"><summary>function issparse</summary><div class="highlight"><pre><span></span><code><span class="k">val</span> <span class="n">issparse</span> <span class="o">:</span>
  <span class="nn">Py</span><span class="p">.</span><span class="nn">Object</span><span class="p">.</span><span class="n">t</span> <span class="o">-&gt;</span>
  <span class="nn">Py</span><span class="p">.</span><span class="nn">Object</span><span class="p">.</span><span class="n">t</span>
</code></pre></div>

<p>Is x of a sparse matrix type?</p>
<h4>Parameters</h4>
<p>x
    object to check for being a sparse matrix</p>
<h4>Returns</h4>
<p>bool
    True if x is a sparse matrix, False otherwise</p>
<h4>Notes</h4>
<p>issparse and isspmatrix are aliases for the same function.</p>
<h4>Examples</h4>
<div class="highlight"><pre><span></span><code><span class="o">&gt;&gt;&gt;</span> <span class="kn">from</span> <span class="nn">scipy.sparse</span> <span class="kn">import</span> <span class="n">csr_matrix</span><span class="p">,</span> <span class="n">isspmatrix</span>
<span class="o">&gt;&gt;&gt;</span> <span class="n">isspmatrix</span><span class="p">(</span><span class="n">csr_matrix</span><span class="p">([[</span><span class="mi">5</span><span class="p">]]))</span>
<span class="kc">True</span>
</code></pre></div>

<div class="highlight"><pre><span></span><code><span class="o">&gt;&gt;&gt;</span> <span class="kn">from</span> <span class="nn">scipy.sparse</span> <span class="kn">import</span> <span class="n">isspmatrix</span>
<span class="o">&gt;&gt;&gt;</span> <span class="n">isspmatrix</span><span class="p">(</span><span class="mi">5</span><span class="p">)</span>
<span class="kc">False</span>
</code></pre></div>

</details>
<h3 id="kernel_metrics">kernel_metrics<a class="headerlink" href="#kernel_metrics" title="Permanent link">&para;</a></h3>
<details class="note" open="open"><summary>function kernel_metrics</summary><div class="highlight"><pre><span></span><code><span class="k">val</span> <span class="n">kernel_metrics</span> <span class="o">:</span>
  <span class="kt">unit</span> <span class="o">-&gt;</span>
  <span class="nn">Py</span><span class="p">.</span><span class="nn">Object</span><span class="p">.</span><span class="n">t</span>
</code></pre></div>

<p>Valid metrics for pairwise_kernels</p>
<p>This function simply returns the valid pairwise distance metrics.
It exists, however, to allow for a verbose description of the mapping for
each of the valid strings.</p>
<p>The valid distance metrics, and the function they map to, are:
  ===============   ========================================
  metric            Function
  ===============   ========================================
  'additive_chi2'   sklearn.pairwise.additive_chi2_kernel
  'chi2'            sklearn.pairwise.chi2_kernel
  'linear'          sklearn.pairwise.linear_kernel
  'poly'            sklearn.pairwise.polynomial_kernel
  'polynomial'      sklearn.pairwise.polynomial_kernel
  'rbf'             sklearn.pairwise.rbf_kernel
  'laplacian'       sklearn.pairwise.laplacian_kernel
  'sigmoid'         sklearn.pairwise.sigmoid_kernel
  'cosine'          sklearn.pairwise.cosine_similarity
  ===============   ========================================</p>
<p>Read more in the :ref:<code>User Guide &lt;metrics&gt;</code>.</p>
</details>
<h3 id="laplacian_kernel">laplacian_kernel<a class="headerlink" href="#laplacian_kernel" title="Permanent link">&para;</a></h3>
<details class="note" open="open"><summary>function laplacian_kernel</summary><div class="highlight"><pre><span></span><code><span class="k">val</span> <span class="n">laplacian_kernel</span> <span class="o">:</span>
  <span class="o">?</span><span class="n">y</span><span class="o">:[&gt;`</span><span class="nc">ArrayLike</span><span class="o">]</span> <span class="nn">Np</span><span class="p">.</span><span class="nn">Obj</span><span class="p">.</span><span class="n">t</span> <span class="o">-&gt;</span>
  <span class="o">?</span><span class="n">gamma</span><span class="o">:</span><span class="kt">float</span> <span class="o">-&gt;</span>
  <span class="n">x</span><span class="o">:[&gt;`</span><span class="nc">ArrayLike</span><span class="o">]</span> <span class="nn">Np</span><span class="p">.</span><span class="nn">Obj</span><span class="p">.</span><span class="n">t</span> <span class="o">-&gt;</span>
  <span class="kt">unit</span> <span class="o">-&gt;</span>
  <span class="o">[&gt;`</span><span class="nc">ArrayLike</span><span class="o">]</span> <span class="nn">Np</span><span class="p">.</span><span class="nn">Obj</span><span class="p">.</span><span class="n">t</span>
</code></pre></div>

<p>Compute the laplacian kernel between X and Y.</p>
<p>The laplacian kernel is defined as::</p>
<div class="codehilite"><pre><span></span><code>K(x, y) = exp(-gamma ||x-y||_1)
</code></pre></div>


<p>for each pair of rows x in X and y in Y.
Read more in the :ref:<code>User Guide &lt;laplacian_kernel&gt;</code>.</p>
<p>.. versionadded:: 0.17</p>
<h4>Parameters</h4>
<ul>
<li>
<p><strong>X : array of shape (n_samples_X, n_features)</strong></p>
</li>
<li>
<p><strong>Y : array of shape (n_samples_Y, n_features)</strong></p>
</li>
<li>
<p><strong>gamma : float, default None</strong>
    If None, defaults to 1.0 / n_features</p>
</li>
</ul>
<h4>Returns</h4>
<ul>
<li><strong>kernel_matrix : array of shape (n_samples_X, n_samples_Y)</strong></li>
</ul>
</details>
<h3 id="linear_kernel">linear_kernel<a class="headerlink" href="#linear_kernel" title="Permanent link">&para;</a></h3>
<details class="note" open="open"><summary>function linear_kernel</summary><div class="highlight"><pre><span></span><code><span class="k">val</span> <span class="n">linear_kernel</span> <span class="o">:</span>
  <span class="o">?</span><span class="n">y</span><span class="o">:[&gt;`</span><span class="nc">ArrayLike</span><span class="o">]</span> <span class="nn">Np</span><span class="p">.</span><span class="nn">Obj</span><span class="p">.</span><span class="n">t</span> <span class="o">-&gt;</span>
  <span class="o">?</span><span class="n">dense_output</span><span class="o">:</span><span class="kt">bool</span> <span class="o">-&gt;</span>
  <span class="n">x</span><span class="o">:[&gt;`</span><span class="nc">ArrayLike</span><span class="o">]</span> <span class="nn">Np</span><span class="p">.</span><span class="nn">Obj</span><span class="p">.</span><span class="n">t</span> <span class="o">-&gt;</span>
  <span class="kt">unit</span> <span class="o">-&gt;</span>
  <span class="nn">Py</span><span class="p">.</span><span class="nn">Object</span><span class="p">.</span><span class="n">t</span>
</code></pre></div>

<p>Compute the linear kernel between X and Y.</p>
<p>Read more in the :ref:<code>User Guide &lt;linear_kernel&gt;</code>.</p>
<h4>Parameters</h4>
<ul>
<li>
<p><strong>X : array of shape (n_samples_1, n_features)</strong></p>
</li>
<li>
<p><strong>Y : array of shape (n_samples_2, n_features)</strong></p>
</li>
<li>
<p><strong>dense_output : boolean (optional), default True</strong>
    Whether to return dense output even when the input is sparse. If
    <code>False</code>, the output is sparse if both input arrays are sparse.</p>
<p>.. versionadded:: 0.20</p>
</li>
</ul>
<h4>Returns</h4>
<p>Gram matrix : array of shape (n_samples_1, n_samples_2)</p>
</details>
<h3 id="manhattan_distances">manhattan_distances<a class="headerlink" href="#manhattan_distances" title="Permanent link">&para;</a></h3>
<details class="note" open="open"><summary>function manhattan_distances</summary><div class="highlight"><pre><span></span><code><span class="k">val</span> <span class="n">manhattan_distances</span> <span class="o">:</span>
  <span class="o">?</span><span class="n">y</span><span class="o">:[&gt;`</span><span class="nc">ArrayLike</span><span class="o">]</span> <span class="nn">Np</span><span class="p">.</span><span class="nn">Obj</span><span class="p">.</span><span class="n">t</span> <span class="o">-&gt;</span>
  <span class="o">?</span><span class="n">sum_over_features</span><span class="o">:</span><span class="kt">bool</span> <span class="o">-&gt;</span>
  <span class="n">x</span><span class="o">:[&gt;`</span><span class="nc">ArrayLike</span><span class="o">]</span> <span class="nn">Np</span><span class="p">.</span><span class="nn">Obj</span><span class="p">.</span><span class="n">t</span> <span class="o">-&gt;</span>
  <span class="kt">unit</span> <span class="o">-&gt;</span>
  <span class="o">[&gt;`</span><span class="nc">ArrayLike</span><span class="o">]</span> <span class="nn">Np</span><span class="p">.</span><span class="nn">Obj</span><span class="p">.</span><span class="n">t</span>
</code></pre></div>

<p>Compute the L1 distances between the vectors in X and Y.</p>
<p>With sum_over_features equal to False it returns the componentwise
distances.</p>
<p>Read more in the :ref:<code>User Guide &lt;metrics&gt;</code>.</p>
<h4>Parameters</h4>
<ul>
<li>
<p><strong>X : array_like</strong>
    An array with shape (n_samples_X, n_features).</p>
</li>
<li>
<p><strong>Y : array_like, optional</strong>
    An array with shape (n_samples_Y, n_features).</p>
</li>
<li>
<p><strong>sum_over_features : bool, default=True</strong>
    If True the function returns the pairwise distance matrix
    else it returns the componentwise L1 pairwise-distances.
    Not supported for sparse matrix inputs.</p>
</li>
</ul>
<h4>Returns</h4>
<ul>
<li><strong>D : array</strong>
    If sum_over_features is False shape is
    (n_samples_X * n_samples_Y, n_features) and D contains the
    componentwise L1 pairwise-distances (ie. absolute difference),
    else shape is (n_samples_X, n_samples_Y) and D contains
    the pairwise L1 distances.</li>
</ul>
<h4>Notes</h4>
<p>When X and/or Y are CSR sparse matrices and they are not already
in canonical format, this function modifies them in-place to
make them canonical.</p>
<h4>Examples</h4>
<div class="highlight"><pre><span></span><code><span class="o">&gt;&gt;&gt;</span> <span class="kn">from</span> <span class="nn">sklearn.metrics.pairwise</span> <span class="kn">import</span> <span class="n">manhattan_distances</span>
<span class="o">&gt;&gt;&gt;</span> <span class="n">manhattan_distances</span><span class="p">([[</span><span class="mi">3</span><span class="p">]],</span> <span class="p">[[</span><span class="mi">3</span><span class="p">]])</span>
<span class="n">array</span><span class="p">([[</span><span class="mf">0.</span><span class="p">]])</span>
<span class="o">&gt;&gt;&gt;</span> <span class="n">manhattan_distances</span><span class="p">([[</span><span class="mi">3</span><span class="p">]],</span> <span class="p">[[</span><span class="mi">2</span><span class="p">]])</span>
<span class="n">array</span><span class="p">([[</span><span class="mf">1.</span><span class="p">]])</span>
<span class="o">&gt;&gt;&gt;</span> <span class="n">manhattan_distances</span><span class="p">([[</span><span class="mi">2</span><span class="p">]],</span> <span class="p">[[</span><span class="mi">3</span><span class="p">]])</span>
<span class="n">array</span><span class="p">([[</span><span class="mf">1.</span><span class="p">]])</span>
<span class="o">&gt;&gt;&gt;</span> <span class="n">manhattan_distances</span><span class="p">([[</span><span class="mi">1</span><span class="p">,</span> <span class="mi">2</span><span class="p">],</span> <span class="p">[</span><span class="mi">3</span><span class="p">,</span> <span class="mi">4</span><span class="p">]],</span>         <span class="p">[[</span><span class="mi">1</span><span class="p">,</span> <span class="mi">2</span><span class="p">],</span> <span class="p">[</span><span class="mi">0</span><span class="p">,</span> <span class="mi">3</span><span class="p">]])</span>
<span class="n">array</span><span class="p">([[</span><span class="mf">0.</span><span class="p">,</span> <span class="mf">2.</span><span class="p">],</span>
       <span class="p">[</span><span class="mf">4.</span><span class="p">,</span> <span class="mf">4.</span><span class="p">]])</span>
<span class="o">&gt;&gt;&gt;</span> <span class="kn">import</span> <span class="nn">numpy</span> <span class="k">as</span> <span class="nn">np</span>
<span class="o">&gt;&gt;&gt;</span> <span class="n">X</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">ones</span><span class="p">((</span><span class="mi">1</span><span class="p">,</span> <span class="mi">2</span><span class="p">))</span>
<span class="o">&gt;&gt;&gt;</span> <span class="n">y</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">full</span><span class="p">((</span><span class="mi">2</span><span class="p">,</span> <span class="mi">2</span><span class="p">),</span> <span class="mf">2.</span><span class="p">)</span>
<span class="o">&gt;&gt;&gt;</span> <span class="n">manhattan_distances</span><span class="p">(</span><span class="n">X</span><span class="p">,</span> <span class="n">y</span><span class="p">,</span> <span class="n">sum_over_features</span><span class="o">=</span><span class="kc">False</span><span class="p">)</span>
<span class="n">array</span><span class="p">([[</span><span class="mf">1.</span><span class="p">,</span> <span class="mf">1.</span><span class="p">],</span>
       <span class="p">[</span><span class="mf">1.</span><span class="p">,</span> <span class="mf">1.</span><span class="p">]])</span>
</code></pre></div>

</details>
<h3 id="nan_euclidean_distances">nan_euclidean_distances<a class="headerlink" href="#nan_euclidean_distances" title="Permanent link">&para;</a></h3>
<details class="note" open="open"><summary>function nan_euclidean_distances</summary><div class="highlight"><pre><span></span><code><span class="k">val</span> <span class="n">nan_euclidean_distances</span> <span class="o">:</span>
  <span class="o">?</span><span class="n">y</span><span class="o">:[&gt;`</span><span class="nc">ArrayLike</span><span class="o">]</span> <span class="nn">Np</span><span class="p">.</span><span class="nn">Obj</span><span class="p">.</span><span class="n">t</span> <span class="o">-&gt;</span>
  <span class="o">?</span><span class="n">squared</span><span class="o">:</span><span class="kt">bool</span> <span class="o">-&gt;</span>
  <span class="o">?</span><span class="n">missing_values</span><span class="o">:[`</span><span class="nc">Np_nan</span> <span class="k">of</span> <span class="nn">Py</span><span class="p">.</span><span class="nn">Object</span><span class="p">.</span><span class="n">t</span> <span class="o">|</span> <span class="o">`</span><span class="nc">I</span> <span class="k">of</span> <span class="kt">int</span><span class="o">]</span> <span class="o">-&gt;</span>
  <span class="o">?</span><span class="n">copy</span><span class="o">:</span><span class="kt">bool</span> <span class="o">-&gt;</span>
  <span class="n">x</span><span class="o">:[&gt;`</span><span class="nc">ArrayLike</span><span class="o">]</span> <span class="nn">Np</span><span class="p">.</span><span class="nn">Obj</span><span class="p">.</span><span class="n">t</span> <span class="o">-&gt;</span>
  <span class="kt">unit</span> <span class="o">-&gt;</span>
  <span class="o">[&gt;`</span><span class="nc">ArrayLike</span><span class="o">]</span> <span class="nn">Np</span><span class="p">.</span><span class="nn">Obj</span><span class="p">.</span><span class="n">t</span>
</code></pre></div>

<p>Calculate the euclidean distances in the presence of missing values.</p>
<p>Compute the euclidean distance between each pair of samples in X and Y,
where Y=X is assumed if Y=None. When calculating the distance between a
pair of samples, this formulation ignores feature coordinates with a
missing value in either sample and scales up the weight of the remaining
coordinates:</p>
<div class="codehilite"><pre><span></span><code>dist(x,y) = sqrt(weight * sq. distance from present coordinates)
where,
weight = Total # of coordinates / # of present coordinates
</code></pre></div>


<p>For example, the distance between <code>[3, na, na, 6]</code> and <code>[1, na, 4, 5]</code>
is:</p>
<div class="codehilite"><pre><span></span><code>.. math::
    \sqrt{\frac{4}{2}((3-1)^2 + (6-5)^2)}
</code></pre></div>


<p>If all the coordinates are missing or if there are no common present
coordinates then NaN is returned for that pair.</p>
<p>Read more in the :ref:<code>User Guide &lt;metrics&gt;</code>.</p>
<p>.. versionadded:: 0.22</p>
<h4>Parameters</h4>
<ul>
<li>
<p><strong>X : array-like, shape=(n_samples_1, n_features)</strong></p>
</li>
<li>
<p><strong>Y : array-like, shape=(n_samples_2, n_features)</strong></p>
</li>
<li>
<p><strong>squared : bool, default=False</strong>
    Return squared Euclidean distances.</p>
</li>
<li>
<p><strong>missing_values : np.nan or int, default=np.nan</strong>
    Representation of missing value</p>
</li>
<li>
<p><strong>copy : boolean, default=True</strong>
    Make and use a deep copy of X and Y (if Y exists)</p>
</li>
</ul>
<h4>Returns</h4>
<ul>
<li><strong>distances : array, shape (n_samples_1, n_samples_2)</strong></li>
</ul>
<h4>Examples</h4>
<div class="highlight"><pre><span></span><code><span class="o">&gt;&gt;&gt;</span> <span class="kn">from</span> <span class="nn">sklearn.metrics.pairwise</span> <span class="kn">import</span> <span class="n">nan_euclidean_distances</span>
<span class="o">&gt;&gt;&gt;</span> <span class="n">nan</span> <span class="o">=</span> <span class="nb">float</span><span class="p">(</span><span class="s1">&#39;NaN&#39;</span><span class="p">)</span>
<span class="o">&gt;&gt;&gt;</span> <span class="n">X</span> <span class="o">=</span> <span class="p">[[</span><span class="mi">0</span><span class="p">,</span> <span class="mi">1</span><span class="p">],</span> <span class="p">[</span><span class="mi">1</span><span class="p">,</span> <span class="n">nan</span><span class="p">]]</span>
<span class="o">&gt;&gt;&gt;</span> <span class="n">nan_euclidean_distances</span><span class="p">(</span><span class="n">X</span><span class="p">,</span> <span class="n">X</span><span class="p">)</span> <span class="c1"># distance between rows of X</span>
<span class="n">array</span><span class="p">([[</span><span class="mf">0.</span>        <span class="p">,</span> <span class="mf">1.41421356</span><span class="p">],</span>
       <span class="p">[</span><span class="mf">1.41421356</span><span class="p">,</span> <span class="mf">0.</span>        <span class="p">]])</span>
</code></pre></div>

<div class="highlight"><pre><span></span><code><span class="o">&gt;&gt;&gt;</span> <span class="c1"># get distance to origin</span>
<span class="o">&gt;&gt;&gt;</span> <span class="n">nan_euclidean_distances</span><span class="p">(</span><span class="n">X</span><span class="p">,</span> <span class="p">[[</span><span class="mi">0</span><span class="p">,</span> <span class="mi">0</span><span class="p">]])</span>
<span class="n">array</span><span class="p">([[</span><span class="mf">1.</span>        <span class="p">],</span>
       <span class="p">[</span><span class="mf">1.41421356</span><span class="p">]])</span>
</code></pre></div>

<h4>References</h4>
<ul>
<li>
<p>John K. Dixon, 'Pattern Recognition with Partly Missing Data',
  IEEE Transactions on Systems, Man, and Cybernetics, Volume: 9, Issue:
  10, pp. 617 - 621, Oct. 1979.</p>
</li>
<li>
<p><strong>http://ieeexplore.ieee.org/abstract/document/4310090/</strong></p>
</li>
</ul>
<h4>See also</h4>
<ul>
<li><strong>paired_distances : distances between pairs of elements of X and Y.</strong></li>
</ul>
</details>
<h3 id="normalize">normalize<a class="headerlink" href="#normalize" title="Permanent link">&para;</a></h3>
<details class="note" open="open"><summary>function normalize</summary><div class="highlight"><pre><span></span><code><span class="k">val</span> <span class="n">normalize</span> <span class="o">:</span>
  <span class="o">?</span><span class="n">norm</span><span class="o">:[`</span><span class="nc">L1</span> <span class="o">|</span> <span class="o">`</span><span class="nc">L2</span> <span class="o">|</span> <span class="o">`</span><span class="nc">Max</span><span class="o">]</span> <span class="o">-&gt;</span>
  <span class="o">?</span><span class="n">axis</span><span class="o">:[`</span><span class="nc">Zero</span> <span class="o">|</span> <span class="o">`</span><span class="nc">One</span><span class="o">]</span> <span class="o">-&gt;</span>
  <span class="o">?</span><span class="n">copy</span><span class="o">:</span><span class="kt">bool</span> <span class="o">-&gt;</span>
  <span class="o">?</span><span class="n">return_norm</span><span class="o">:</span><span class="kt">bool</span> <span class="o">-&gt;</span>
  <span class="n">x</span><span class="o">:[&gt;`</span><span class="nc">ArrayLike</span><span class="o">]</span> <span class="nn">Np</span><span class="p">.</span><span class="nn">Obj</span><span class="p">.</span><span class="n">t</span> <span class="o">-&gt;</span>
  <span class="kt">unit</span> <span class="o">-&gt;</span>
  <span class="o">([&gt;`</span><span class="nc">ArrayLike</span><span class="o">]</span> <span class="nn">Np</span><span class="p">.</span><span class="nn">Obj</span><span class="p">.</span><span class="n">t</span> <span class="o">*</span> <span class="o">[&gt;`</span><span class="nc">ArrayLike</span><span class="o">]</span> <span class="nn">Np</span><span class="p">.</span><span class="nn">Obj</span><span class="p">.</span><span class="n">t</span><span class="o">)</span>
</code></pre></div>

<p>Scale input vectors individually to unit norm (vector length).</p>
<p>Read more in the :ref:<code>User Guide &lt;preprocessing_normalization&gt;</code>.</p>
<h4>Parameters</h4>
<ul>
<li>
<p><strong>X : {array-like, sparse matrix}, shape [n_samples, n_features]</strong>
    The data to normalize, element by element.
    scipy.sparse matrices should be in CSR format to avoid an
    un-necessary copy.</p>
</li>
<li>
<p><strong>norm : 'l1', 'l2', or 'max', optional ('l2' by default)</strong>
    The norm to use to normalize each non zero sample (or each non-zero
    feature if axis is 0).</p>
</li>
<li>
<p><strong>axis : 0 or 1, optional (1 by default)</strong>
    axis used to normalize the data along. If 1, independently normalize
    each sample, otherwise (if 0) normalize each feature.</p>
</li>
<li>
<p><strong>copy : boolean, optional, default True</strong>
    set to False to perform inplace row normalization and avoid a
    copy (if the input is already a numpy array or a scipy.sparse
    CSR matrix and if axis is 1).</p>
</li>
<li>
<p><strong>return_norm : boolean, default False</strong>
    whether to return the computed norms</p>
</li>
</ul>
<h4>Returns</h4>
<ul>
<li>
<p><strong>X : {array-like, sparse matrix}, shape [n_samples, n_features]</strong>
    Normalized input X.</p>
</li>
<li>
<p><strong>norms : array, shape [n_samples] if axis=1 else [n_features]</strong>
    An array of norms along given axis for X.
    When X is sparse, a NotImplementedError will be raised
    for norm 'l1' or 'l2'.</p>
</li>
</ul>
<h4>See also</h4>
<ul>
<li><strong>Normalizer: Performs normalization using the <code>Transformer</code> API</strong>
    (e.g. as part of a preprocessing :class:<code>sklearn.pipeline.Pipeline</code>).</li>
</ul>
<h4>Notes</h4>
<p>For a comparison of the different scalers, transformers, and normalizers,</p>
<ul>
<li>**see :ref:<code>examples/preprocessing/plot_all_scaling.py**
&lt;sphx_glr_auto_examples_preprocessing_plot_all_scaling.py&gt;</code>.</li>
</ul>
</details>
<h3 id="paired_cosine_distances">paired_cosine_distances<a class="headerlink" href="#paired_cosine_distances" title="Permanent link">&para;</a></h3>
<details class="note" open="open"><summary>function paired_cosine_distances</summary><div class="highlight"><pre><span></span><code><span class="k">val</span> <span class="n">paired_cosine_distances</span> <span class="o">:</span>
  <span class="n">x</span><span class="o">:[&gt;`</span><span class="nc">ArrayLike</span><span class="o">]</span> <span class="nn">Np</span><span class="p">.</span><span class="nn">Obj</span><span class="p">.</span><span class="n">t</span> <span class="o">-&gt;</span>
  <span class="n">y</span><span class="o">:[&gt;`</span><span class="nc">ArrayLike</span><span class="o">]</span> <span class="nn">Np</span><span class="p">.</span><span class="nn">Obj</span><span class="p">.</span><span class="n">t</span> <span class="o">-&gt;</span>
  <span class="kt">unit</span> <span class="o">-&gt;</span>
  <span class="o">[&gt;`</span><span class="nc">ArrayLike</span><span class="o">]</span> <span class="nn">Np</span><span class="p">.</span><span class="nn">Obj</span><span class="p">.</span><span class="n">t</span>
</code></pre></div>

<p>Computes the paired cosine distances between X and Y</p>
<p>Read more in the :ref:<code>User Guide &lt;metrics&gt;</code>.</p>
<h4>Parameters</h4>
<ul>
<li>
<p><strong>X : array-like, shape (n_samples, n_features)</strong></p>
</li>
<li>
<p><strong>Y : array-like, shape (n_samples, n_features)</strong></p>
</li>
</ul>
<h4>Returns</h4>
<ul>
<li><strong>distances : ndarray, shape (n_samples, )</strong></li>
</ul>
<h4>Notes</h4>
<p>The cosine distance is equivalent to the half the squared
euclidean distance if each sample is normalized to unit norm</p>
</details>
<h3 id="paired_distances">paired_distances<a class="headerlink" href="#paired_distances" title="Permanent link">&para;</a></h3>
<details class="note" open="open"><summary>function paired_distances</summary><div class="highlight"><pre><span></span><code><span class="k">val</span> <span class="n">paired_distances</span> <span class="o">:</span>
  <span class="o">?</span><span class="n">metric</span><span class="o">:[`</span><span class="nc">S</span> <span class="k">of</span> <span class="kt">string</span> <span class="o">|</span> <span class="o">`</span><span class="nc">Callable</span> <span class="k">of</span> <span class="nn">Py</span><span class="p">.</span><span class="nn">Object</span><span class="p">.</span><span class="n">t</span><span class="o">]</span> <span class="o">-&gt;</span>
  <span class="o">?</span><span class="n">kwds</span><span class="o">:(</span><span class="kt">string</span> <span class="o">*</span> <span class="nn">Py</span><span class="p">.</span><span class="nn">Object</span><span class="p">.</span><span class="n">t</span><span class="o">)</span> <span class="kt">list</span> <span class="o">-&gt;</span>
  <span class="n">x</span><span class="o">:[&gt;`</span><span class="nc">ArrayLike</span><span class="o">]</span> <span class="nn">Np</span><span class="p">.</span><span class="nn">Obj</span><span class="p">.</span><span class="n">t</span> <span class="o">-&gt;</span>
  <span class="n">y</span><span class="o">:[&gt;`</span><span class="nc">ArrayLike</span><span class="o">]</span> <span class="nn">Np</span><span class="p">.</span><span class="nn">Obj</span><span class="p">.</span><span class="n">t</span> <span class="o">-&gt;</span>
  <span class="kt">unit</span> <span class="o">-&gt;</span>
  <span class="o">[&gt;`</span><span class="nc">ArrayLike</span><span class="o">]</span> <span class="nn">Np</span><span class="p">.</span><span class="nn">Obj</span><span class="p">.</span><span class="n">t</span>
</code></pre></div>

<p>Computes the paired distances between X and Y.</p>
<p>Computes the distances between (X[0], Y[0]), (X[1], Y[1]), etc...</p>
<p>Read more in the :ref:<code>User Guide &lt;metrics&gt;</code>.</p>
<h4>Parameters</h4>
<ul>
<li>
<p><strong>X : ndarray (n_samples, n_features)</strong>
    Array 1 for distance computation.</p>
</li>
<li>
<p><strong>Y : ndarray (n_samples, n_features)</strong>
    Array 2 for distance computation.</p>
</li>
<li>
<p><strong>metric : string or callable</strong>
    The metric to use when calculating distance between instances in a
    feature array. If metric is a string, it must be one of the options
    specified in PAIRED_DISTANCES, including 'euclidean',
    'manhattan', or 'cosine'.
    Alternatively, if metric is a callable function, it is called on each
    pair of instances (rows) and the resulting value recorded. The callable
    should take two arrays from X as input and return a value indicating
    the distance between them.</p>
</li>
</ul>
<h4>Returns</h4>
<ul>
<li><strong>distances : ndarray (n_samples, )</strong></li>
</ul>
<h4>Examples</h4>
<div class="highlight"><pre><span></span><code><span class="o">&gt;&gt;&gt;</span> <span class="kn">from</span> <span class="nn">sklearn.metrics.pairwise</span> <span class="kn">import</span> <span class="n">paired_distances</span>
<span class="o">&gt;&gt;&gt;</span> <span class="n">X</span> <span class="o">=</span> <span class="p">[[</span><span class="mi">0</span><span class="p">,</span> <span class="mi">1</span><span class="p">],</span> <span class="p">[</span><span class="mi">1</span><span class="p">,</span> <span class="mi">1</span><span class="p">]]</span>
<span class="o">&gt;&gt;&gt;</span> <span class="n">Y</span> <span class="o">=</span> <span class="p">[[</span><span class="mi">0</span><span class="p">,</span> <span class="mi">1</span><span class="p">],</span> <span class="p">[</span><span class="mi">2</span><span class="p">,</span> <span class="mi">1</span><span class="p">]]</span>
<span class="o">&gt;&gt;&gt;</span> <span class="n">paired_distances</span><span class="p">(</span><span class="n">X</span><span class="p">,</span> <span class="n">Y</span><span class="p">)</span>
<span class="n">array</span><span class="p">([</span><span class="mf">0.</span><span class="p">,</span> <span class="mf">1.</span><span class="p">])</span>
</code></pre></div>

<h4>See also</h4>
<ul>
<li><strong>pairwise_distances : Computes the distance between every pair of samples</strong></li>
</ul>
</details>
<h3 id="paired_euclidean_distances">paired_euclidean_distances<a class="headerlink" href="#paired_euclidean_distances" title="Permanent link">&para;</a></h3>
<details class="note" open="open"><summary>function paired_euclidean_distances</summary><div class="highlight"><pre><span></span><code><span class="k">val</span> <span class="n">paired_euclidean_distances</span> <span class="o">:</span>
  <span class="n">x</span><span class="o">:[&gt;`</span><span class="nc">ArrayLike</span><span class="o">]</span> <span class="nn">Np</span><span class="p">.</span><span class="nn">Obj</span><span class="p">.</span><span class="n">t</span> <span class="o">-&gt;</span>
  <span class="n">y</span><span class="o">:[&gt;`</span><span class="nc">ArrayLike</span><span class="o">]</span> <span class="nn">Np</span><span class="p">.</span><span class="nn">Obj</span><span class="p">.</span><span class="n">t</span> <span class="o">-&gt;</span>
  <span class="kt">unit</span> <span class="o">-&gt;</span>
  <span class="o">[&gt;`</span><span class="nc">ArrayLike</span><span class="o">]</span> <span class="nn">Np</span><span class="p">.</span><span class="nn">Obj</span><span class="p">.</span><span class="n">t</span>
</code></pre></div>

<p>Computes the paired euclidean distances between X and Y</p>
<p>Read more in the :ref:<code>User Guide &lt;metrics&gt;</code>.</p>
<h4>Parameters</h4>
<ul>
<li>
<p><strong>X : array-like, shape (n_samples, n_features)</strong></p>
</li>
<li>
<p><strong>Y : array-like, shape (n_samples, n_features)</strong></p>
</li>
</ul>
<h4>Returns</h4>
<ul>
<li><strong>distances : ndarray (n_samples, )</strong></li>
</ul>
</details>
<h3 id="paired_manhattan_distances">paired_manhattan_distances<a class="headerlink" href="#paired_manhattan_distances" title="Permanent link">&para;</a></h3>
<details class="note" open="open"><summary>function paired_manhattan_distances</summary><div class="highlight"><pre><span></span><code><span class="k">val</span> <span class="n">paired_manhattan_distances</span> <span class="o">:</span>
  <span class="n">x</span><span class="o">:[&gt;`</span><span class="nc">ArrayLike</span><span class="o">]</span> <span class="nn">Np</span><span class="p">.</span><span class="nn">Obj</span><span class="p">.</span><span class="n">t</span> <span class="o">-&gt;</span>
  <span class="n">y</span><span class="o">:[&gt;`</span><span class="nc">ArrayLike</span><span class="o">]</span> <span class="nn">Np</span><span class="p">.</span><span class="nn">Obj</span><span class="p">.</span><span class="n">t</span> <span class="o">-&gt;</span>
  <span class="kt">unit</span> <span class="o">-&gt;</span>
  <span class="o">[&gt;`</span><span class="nc">ArrayLike</span><span class="o">]</span> <span class="nn">Np</span><span class="p">.</span><span class="nn">Obj</span><span class="p">.</span><span class="n">t</span>
</code></pre></div>

<p>Compute the L1 distances between the vectors in X and Y.</p>
<p>Read more in the :ref:<code>User Guide &lt;metrics&gt;</code>.</p>
<h4>Parameters</h4>
<ul>
<li>
<p><strong>X : array-like, shape (n_samples, n_features)</strong></p>
</li>
<li>
<p><strong>Y : array-like, shape (n_samples, n_features)</strong></p>
</li>
</ul>
<h4>Returns</h4>
<ul>
<li><strong>distances : ndarray (n_samples, )</strong></li>
</ul>
</details>
<h3 id="pairwise_distances">pairwise_distances<a class="headerlink" href="#pairwise_distances" title="Permanent link">&para;</a></h3>
<details class="note" open="open"><summary>function pairwise_distances</summary><div class="highlight"><pre><span></span><code><span class="k">val</span> <span class="n">pairwise_distances</span> <span class="o">:</span>
  <span class="o">?</span><span class="n">y</span><span class="o">:[&gt;`</span><span class="nc">ArrayLike</span><span class="o">]</span> <span class="nn">Np</span><span class="p">.</span><span class="nn">Obj</span><span class="p">.</span><span class="n">t</span> <span class="o">-&gt;</span>
  <span class="o">?</span><span class="n">metric</span><span class="o">:[`</span><span class="nc">S</span> <span class="k">of</span> <span class="kt">string</span> <span class="o">|</span> <span class="o">`</span><span class="nc">Callable</span> <span class="k">of</span> <span class="nn">Py</span><span class="p">.</span><span class="nn">Object</span><span class="p">.</span><span class="n">t</span><span class="o">]</span> <span class="o">-&gt;</span>
  <span class="o">?</span><span class="n">n_jobs</span><span class="o">:</span><span class="kt">int</span> <span class="o">-&gt;</span>
  <span class="o">?</span><span class="n">force_all_finite</span><span class="o">:[`</span><span class="nc">Allow_nan</span> <span class="o">|</span> <span class="o">`</span><span class="nc">Bool</span> <span class="k">of</span> <span class="kt">bool</span><span class="o">]</span> <span class="o">-&gt;</span>
  <span class="o">?</span><span class="n">kwds</span><span class="o">:(</span><span class="kt">string</span> <span class="o">*</span> <span class="nn">Py</span><span class="p">.</span><span class="nn">Object</span><span class="p">.</span><span class="n">t</span><span class="o">)</span> <span class="kt">list</span> <span class="o">-&gt;</span>
  <span class="n">x</span><span class="o">:[`</span><span class="nc">Arr</span> <span class="k">of</span> <span class="o">[&gt;`</span><span class="nc">ArrayLike</span><span class="o">]</span> <span class="nn">Np</span><span class="p">.</span><span class="nn">Obj</span><span class="p">.</span><span class="n">t</span> <span class="o">|</span> <span class="o">`</span><span class="nc">Otherwise</span> <span class="k">of</span> <span class="nn">Py</span><span class="p">.</span><span class="nn">Object</span><span class="p">.</span><span class="n">t</span><span class="o">]</span> <span class="o">-&gt;</span>
  <span class="kt">unit</span> <span class="o">-&gt;</span>
  <span class="o">[&gt;`</span><span class="nc">ArrayLike</span><span class="o">]</span> <span class="nn">Np</span><span class="p">.</span><span class="nn">Obj</span><span class="p">.</span><span class="n">t</span>
</code></pre></div>

<p>Compute the distance matrix from a vector array X and optional Y.</p>
<p>This method takes either a vector array or a distance matrix, and returns
a distance matrix. If the input is a vector array, the distances are
computed. If the input is a distances matrix, it is returned instead.</p>
<p>This method provides a safe way to take a distance matrix as input, while
preserving compatibility with many other algorithms that take a vector
array.</p>
<p>If Y is given (default is None), then the returned matrix is the pairwise
distance between the arrays from both X and Y.</p>
<p>Valid values for metric are:</p>
<ul>
<li>
<p>From scikit-learn: ['cityblock', 'cosine', 'euclidean', 'l1', 'l2',
  'manhattan']. These metrics support sparse matrix
  inputs.
  ['nan_euclidean'] but it does not yet support sparse matrices.</p>
</li>
<li>
<p>From scipy.spatial.distance: ['braycurtis', 'canberra', 'chebyshev',
  'correlation', 'dice', 'hamming', 'jaccard', 'kulsinski', 'mahalanobis',
  'minkowski', 'rogerstanimoto', 'russellrao', 'seuclidean',
  'sokalmichener', 'sokalsneath', 'sqeuclidean', 'yule']
  See the documentation for scipy.spatial.distance for details on these
  metrics. These metrics do not support sparse matrix inputs.</p>
</li>
</ul>
<p>Note that in the case of 'cityblock', 'cosine' and 'euclidean' (which are
valid scipy.spatial.distance metrics), the scikit-learn implementation
will be used, which is faster and has support for sparse matrices (except
for 'cityblock'). For a verbose description of the metrics from
scikit-learn, see the <strong>doc</strong> of the sklearn.pairwise.distance_metrics
function.</p>
<p>Read more in the :ref:<code>User Guide &lt;metrics&gt;</code>.</p>
<h4>Parameters</h4>
<ul>
<li>
<p><strong>X : array [n_samples_a, n_samples_a] if metric == 'precomputed', or,              [n_samples_a, n_features] otherwise</strong>
    Array of pairwise distances between samples, or a feature array.</p>
</li>
<li>
<p><strong>Y : array [n_samples_b, n_features], optional</strong>
    An optional second feature array. Only allowed if
    metric != 'precomputed'.</p>
</li>
<li>
<p><strong>metric : string, or callable</strong>
    The metric to use when calculating distance between instances in a
    feature array. If metric is a string, it must be one of the options
    allowed by scipy.spatial.distance.pdist for its metric parameter, or
    a metric listed in pairwise.PAIRWISE_DISTANCE_FUNCTIONS.
    If metric is 'precomputed', X is assumed to be a distance matrix.
    Alternatively, if metric is a callable function, it is called on each
    pair of instances (rows) and the resulting value recorded. The callable
    should take two arrays from X as input and return a value indicating
    the distance between them.</p>
</li>
<li>
<p><strong>n_jobs : int or None, optional (default=None)</strong>
    The number of jobs to use for the computation. This works by breaking
    down the pairwise matrix into n_jobs even slices and computing them in
    parallel.</p>
<p><code>None</code> means 1 unless in a :obj:<code>joblib.parallel_backend</code> context.
<code>-1</code> means using all processors. See :term:<code>Glossary &lt;n_jobs&gt;</code>
for more details.</p>
</li>
<li>
<p><strong>force_all_finite : boolean or 'allow-nan', (default=True)</strong>
    Whether to raise an error on np.inf, np.nan, pd.NA in array. The
    possibilities are:</p>
<ul>
<li>True: Force all values of array to be finite.</li>
<li>False: accepts np.inf, np.nan, pd.NA in array.</li>
<li>'allow-nan': accepts only np.nan and pd.NA values in array. Values
  cannot be infinite.</li>
</ul>
<p>.. versionadded:: 0.22
   <code>force_all_finite</code> accepts the string <code>'allow-nan'</code>.</p>
<p>.. versionchanged:: 0.23
   Accepts <code>pd.NA</code> and converts it into <code>np.nan</code></p>
</li>
<li>
<p><strong>**kwds : optional keyword parameters</strong>
    Any further parameters are passed directly to the distance function.
    If using a scipy.spatial.distance metric, the parameters are still
    metric dependent. See the scipy docs for usage examples.</p>
</li>
</ul>
<h4>Returns</h4>
<ul>
<li><strong>D : array [n_samples_a, n_samples_a] or [n_samples_a, n_samples_b]</strong>
    A distance matrix D such that D_{i, j} is the distance between the
    ith and jth vectors of the given matrix X, if Y is None.
    If Y is not None, then D_{i, j} is the distance between the ith array
    from X and the jth array from Y.</li>
</ul>
<h4>See also</h4>
<ul>
<li>
<p><strong>pairwise_distances_chunked : performs the same calculation as this</strong>
    function, but returns a generator of chunks of the distance matrix, in
    order to limit memory usage.</p>
</li>
<li>
<p><strong>paired_distances : Computes the distances between corresponding</strong>
                   elements of two arrays</p>
</li>
</ul>
</details>
<h3 id="pairwise_distances_argmin">pairwise_distances_argmin<a class="headerlink" href="#pairwise_distances_argmin" title="Permanent link">&para;</a></h3>
<details class="note" open="open"><summary>function pairwise_distances_argmin</summary><div class="highlight"><pre><span></span><code><span class="k">val</span> <span class="n">pairwise_distances_argmin</span> <span class="o">:</span>
  <span class="o">?</span><span class="n">axis</span><span class="o">:</span><span class="kt">int</span> <span class="o">-&gt;</span>
  <span class="o">?</span><span class="n">metric</span><span class="o">:[`</span><span class="nc">S</span> <span class="k">of</span> <span class="kt">string</span> <span class="o">|</span> <span class="o">`</span><span class="nc">Callable</span> <span class="k">of</span> <span class="nn">Py</span><span class="p">.</span><span class="nn">Object</span><span class="p">.</span><span class="n">t</span><span class="o">]</span> <span class="o">-&gt;</span>
  <span class="o">?</span><span class="n">metric_kwargs</span><span class="o">:</span><span class="nn">Dict</span><span class="p">.</span><span class="n">t</span> <span class="o">-&gt;</span>
  <span class="n">x</span><span class="o">:[&gt;`</span><span class="nc">ArrayLike</span><span class="o">]</span> <span class="nn">Np</span><span class="p">.</span><span class="nn">Obj</span><span class="p">.</span><span class="n">t</span> <span class="o">-&gt;</span>
  <span class="n">y</span><span class="o">:[&gt;`</span><span class="nc">ArrayLike</span><span class="o">]</span> <span class="nn">Np</span><span class="p">.</span><span class="nn">Obj</span><span class="p">.</span><span class="n">t</span> <span class="o">-&gt;</span>
  <span class="kt">unit</span> <span class="o">-&gt;</span>
  <span class="o">[&gt;`</span><span class="nc">ArrayLike</span><span class="o">]</span> <span class="nn">Np</span><span class="p">.</span><span class="nn">Obj</span><span class="p">.</span><span class="n">t</span>
</code></pre></div>

<p>Compute minimum distances between one point and a set of points.</p>
<p>This function computes for each row in X, the index of the row of Y which
is closest (according to the specified distance).</p>
<p>This is mostly equivalent to calling:</p>
<div class="codehilite"><pre><span></span><code>pairwise_distances(X, Y=Y, metric=metric).argmin(axis=axis)
</code></pre></div>


<p>but uses much less memory, and is faster for large arrays.</p>
<p>This function works with dense 2D arrays only.</p>
<h4>Parameters</h4>
<ul>
<li>
<p><strong>X : array-like</strong>
    Arrays containing points. Respective shapes (n_samples1, n_features)
    and (n_samples2, n_features)</p>
</li>
<li>
<p><strong>Y : array-like</strong>
    Arrays containing points. Respective shapes (n_samples1, n_features)
    and (n_samples2, n_features)</p>
</li>
<li>
<p><strong>axis : int, optional, default 1</strong>
    Axis along which the argmin and distances are to be computed.</p>
</li>
<li>
<p><strong>metric : string or callable</strong>
    metric to use for distance computation. Any metric from scikit-learn
    or scipy.spatial.distance can be used.</p>
<p>If metric is a callable function, it is called on each
pair of instances (rows) and the resulting value recorded. The callable
should take two arrays as input and return one value indicating the
distance between them. This works for Scipy's metrics, but is less
efficient than passing the metric name as a string.</p>
<p>Distance matrices are not supported.</p>
<p>Valid values for metric are:</p>
<ul>
<li>
<p>from scikit-learn: ['cityblock', 'cosine', 'euclidean', 'l1', 'l2',
  'manhattan']</p>
</li>
<li>
<p>from scipy.spatial.distance: ['braycurtis', 'canberra', 'chebyshev',
  'correlation', 'dice', 'hamming', 'jaccard', 'kulsinski',
  'mahalanobis', 'minkowski', 'rogerstanimoto', 'russellrao',
  'seuclidean', 'sokalmichener', 'sokalsneath', 'sqeuclidean',
  'yule']</p>
</li>
</ul>
<p>See the documentation for scipy.spatial.distance for details on these
metrics.</p>
</li>
<li>
<p><strong>metric_kwargs : dict</strong>
    keyword arguments to pass to specified metric function.</p>
</li>
</ul>
<h4>Returns</h4>
<ul>
<li>
<p><strong>argmin : numpy.ndarray</strong></p>
</li>
<li>
<p><strong>Y[argmin[i], :] is the row in Y that is closest to X[i, :].</strong></p>
</li>
</ul>
<h4>See also</h4>
<p>sklearn.metrics.pairwise_distances
sklearn.metrics.pairwise_distances_argmin_min</p>
</details>
<h3 id="pairwise_distances_argmin_min">pairwise_distances_argmin_min<a class="headerlink" href="#pairwise_distances_argmin_min" title="Permanent link">&para;</a></h3>
<details class="note" open="open"><summary>function pairwise_distances_argmin_min</summary><div class="highlight"><pre><span></span><code><span class="k">val</span> <span class="n">pairwise_distances_argmin_min</span> <span class="o">:</span>
  <span class="o">?</span><span class="n">axis</span><span class="o">:</span><span class="kt">int</span> <span class="o">-&gt;</span>
  <span class="o">?</span><span class="n">metric</span><span class="o">:[`</span><span class="nc">S</span> <span class="k">of</span> <span class="kt">string</span> <span class="o">|</span> <span class="o">`</span><span class="nc">Callable</span> <span class="k">of</span> <span class="nn">Py</span><span class="p">.</span><span class="nn">Object</span><span class="p">.</span><span class="n">t</span><span class="o">]</span> <span class="o">-&gt;</span>
  <span class="o">?</span><span class="n">metric_kwargs</span><span class="o">:</span><span class="nn">Dict</span><span class="p">.</span><span class="n">t</span> <span class="o">-&gt;</span>
  <span class="n">x</span><span class="o">:[&gt;`</span><span class="nc">ArrayLike</span><span class="o">]</span> <span class="nn">Np</span><span class="p">.</span><span class="nn">Obj</span><span class="p">.</span><span class="n">t</span> <span class="o">-&gt;</span>
  <span class="n">y</span><span class="o">:[&gt;`</span><span class="nc">ArrayLike</span><span class="o">]</span> <span class="nn">Np</span><span class="p">.</span><span class="nn">Obj</span><span class="p">.</span><span class="n">t</span> <span class="o">-&gt;</span>
  <span class="kt">unit</span> <span class="o">-&gt;</span>
  <span class="o">([&gt;`</span><span class="nc">ArrayLike</span><span class="o">]</span> <span class="nn">Np</span><span class="p">.</span><span class="nn">Obj</span><span class="p">.</span><span class="n">t</span> <span class="o">*</span> <span class="o">[&gt;`</span><span class="nc">ArrayLike</span><span class="o">]</span> <span class="nn">Np</span><span class="p">.</span><span class="nn">Obj</span><span class="p">.</span><span class="n">t</span><span class="o">)</span>
</code></pre></div>

<p>Compute minimum distances between one point and a set of points.</p>
<p>This function computes for each row in X, the index of the row of Y which
is closest (according to the specified distance). The minimal distances are
also returned.</p>
<p>This is mostly equivalent to calling:</p>
<div class="codehilite"><pre><span></span><code>(pairwise_distances(X, Y=Y, metric=metric).argmin(axis=axis),
 pairwise_distances(X, Y=Y, metric=metric).min(axis=axis))
</code></pre></div>


<p>but uses much less memory, and is faster for large arrays.</p>
<h4>Parameters</h4>
<ul>
<li>
<p><strong>X : {array-like, sparse matrix}, shape (n_samples1, n_features)</strong>
    Array containing points.</p>
</li>
<li>
<p><strong>Y : {array-like, sparse matrix}, shape (n_samples2, n_features)</strong>
    Arrays containing points.</p>
</li>
<li>
<p><strong>axis : int, optional, default 1</strong>
    Axis along which the argmin and distances are to be computed.</p>
</li>
<li>
<p><strong>metric : string or callable, default 'euclidean'</strong>
    metric to use for distance computation. Any metric from scikit-learn
    or scipy.spatial.distance can be used.</p>
<p>If metric is a callable function, it is called on each
pair of instances (rows) and the resulting value recorded. The callable
should take two arrays as input and return one value indicating the
distance between them. This works for Scipy's metrics, but is less
efficient than passing the metric name as a string.</p>
<p>Distance matrices are not supported.</p>
<p>Valid values for metric are:</p>
<ul>
<li>
<p>from scikit-learn: ['cityblock', 'cosine', 'euclidean', 'l1', 'l2',
  'manhattan']</p>
</li>
<li>
<p>from scipy.spatial.distance: ['braycurtis', 'canberra', 'chebyshev',
  'correlation', 'dice', 'hamming', 'jaccard', 'kulsinski',
  'mahalanobis', 'minkowski', 'rogerstanimoto', 'russellrao',
  'seuclidean', 'sokalmichener', 'sokalsneath', 'sqeuclidean',
  'yule']</p>
</li>
</ul>
<p>See the documentation for scipy.spatial.distance for details on these
metrics.</p>
</li>
<li>
<p><strong>metric_kwargs : dict, optional</strong>
    Keyword arguments to pass to specified metric function.</p>
</li>
</ul>
<h4>Returns</h4>
<ul>
<li>
<p><strong>argmin : numpy.ndarray</strong></p>
</li>
<li>
<p><strong>Y[argmin[i], :] is the row in Y that is closest to X[i, :].</strong></p>
</li>
<li>
<p><strong>distances : numpy.ndarray</strong>
    distances[i] is the distance between the i-th row in X and the
    argmin[i]-th row in Y.</p>
</li>
</ul>
<h4>See also</h4>
<p>sklearn.metrics.pairwise_distances
sklearn.metrics.pairwise_distances_argmin</p>
</details>
<h3 id="pairwise_distances_chunked">pairwise_distances_chunked<a class="headerlink" href="#pairwise_distances_chunked" title="Permanent link">&para;</a></h3>
<details class="note" open="open"><summary>function pairwise_distances_chunked</summary><div class="highlight"><pre><span></span><code><span class="k">val</span> <span class="n">pairwise_distances_chunked</span> <span class="o">:</span>
  <span class="o">?</span><span class="n">y</span><span class="o">:[&gt;`</span><span class="nc">ArrayLike</span><span class="o">]</span> <span class="nn">Np</span><span class="p">.</span><span class="nn">Obj</span><span class="p">.</span><span class="n">t</span> <span class="o">-&gt;</span>
  <span class="o">?</span><span class="n">reduce_func</span><span class="o">:</span><span class="nn">Py</span><span class="p">.</span><span class="nn">Object</span><span class="p">.</span><span class="n">t</span> <span class="o">-&gt;</span>
  <span class="o">?</span><span class="n">metric</span><span class="o">:[`</span><span class="nc">S</span> <span class="k">of</span> <span class="kt">string</span> <span class="o">|</span> <span class="o">`</span><span class="nc">Callable</span> <span class="k">of</span> <span class="nn">Py</span><span class="p">.</span><span class="nn">Object</span><span class="p">.</span><span class="n">t</span><span class="o">]</span> <span class="o">-&gt;</span>
  <span class="o">?</span><span class="n">n_jobs</span><span class="o">:</span><span class="kt">int</span> <span class="o">-&gt;</span>
  <span class="o">?</span><span class="n">working_memory</span><span class="o">:</span><span class="kt">int</span> <span class="o">-&gt;</span>
  <span class="o">?</span><span class="n">kwds</span><span class="o">:(</span><span class="kt">string</span> <span class="o">*</span> <span class="nn">Py</span><span class="p">.</span><span class="nn">Object</span><span class="p">.</span><span class="n">t</span><span class="o">)</span> <span class="kt">list</span> <span class="o">-&gt;</span>
  <span class="n">x</span><span class="o">:[&gt;`</span><span class="nc">ArrayLike</span><span class="o">]</span> <span class="nn">Np</span><span class="p">.</span><span class="nn">Obj</span><span class="p">.</span><span class="n">t</span> <span class="o">-&gt;</span>
  <span class="kt">unit</span> <span class="o">-&gt;</span>
  <span class="o">[&gt;`</span><span class="nc">ArrayLike</span><span class="o">]</span> <span class="nn">Np</span><span class="p">.</span><span class="nn">Obj</span><span class="p">.</span><span class="n">t</span> <span class="nn">Seq</span><span class="p">.</span><span class="n">t</span>
</code></pre></div>

<p>Generate a distance matrix chunk by chunk with optional reduction</p>
<p>In cases where not all of a pairwise distance matrix needs to be stored at
once, this is used to calculate pairwise distances in
<code>working_memory</code>-sized chunks.  If <code>reduce_func</code> is given, it is run
on each chunk and its return values are concatenated into lists, arrays
or sparse matrices.</p>
<h4>Parameters</h4>
<ul>
<li>
<p><strong>X : array [n_samples_a, n_samples_a] if metric == 'precomputed', or,</strong>
    [n_samples_a, n_features] otherwise
    Array of pairwise distances between samples, or a feature array.</p>
</li>
<li>
<p><strong>Y : array [n_samples_b, n_features], optional</strong>
    An optional second feature array. Only allowed if
    metric != 'precomputed'.</p>
</li>
<li>
<p><strong>reduce_func : callable, optional</strong>
    The function which is applied on each chunk of the distance matrix,
    reducing it to needed values.  <code>reduce_func(D_chunk, start)</code>
    is called repeatedly, where <code>D_chunk</code> is a contiguous vertical
    slice of the pairwise distance matrix, starting at row <code>start</code>.
    It should return one of: None; an array, a list, or a sparse matrix
    of length <code>D_chunk.shape[0]</code>; or a tuple of such objects. Returning
    None is useful for in-place operations, rather than reductions.</p>
<p>If None, pairwise_distances_chunked returns a generator of vertical
chunks of the distance matrix.</p>
</li>
<li>
<p><strong>metric : string, or callable</strong>
    The metric to use when calculating distance between instances in a
    feature array. If metric is a string, it must be one of the options
    allowed by scipy.spatial.distance.pdist for its metric parameter, or
    a metric listed in pairwise.PAIRWISE_DISTANCE_FUNCTIONS.
    If metric is 'precomputed', X is assumed to be a distance matrix.
    Alternatively, if metric is a callable function, it is called on each
    pair of instances (rows) and the resulting value recorded. The callable
    should take two arrays from X as input and return a value indicating
    the distance between them.</p>
</li>
<li>
<p><strong>n_jobs : int or None, optional (default=None)</strong>
    The number of jobs to use for the computation. This works by breaking
    down the pairwise matrix into n_jobs even slices and computing them in
    parallel.</p>
<p><code>None</code> means 1 unless in a :obj:<code>joblib.parallel_backend</code> context.
<code>-1</code> means using all processors. See :term:<code>Glossary &lt;n_jobs&gt;</code>
for more details.</p>
</li>
<li>
<p><strong>working_memory : int, optional</strong>
    The sought maximum memory for temporary distance matrix chunks.
    When None (default), the value of
    <code>sklearn.get_config()['working_memory']</code> is used.</p>
</li>
</ul>
<p><code>**kwds</code> : optional keyword parameters
    Any further parameters are passed directly to the distance function.
    If using a scipy.spatial.distance metric, the parameters are still
    metric dependent. See the scipy docs for usage examples.</p>
<h4>Yields</h4>
<ul>
<li><strong>D_chunk : array or sparse matrix</strong>
    A contiguous slice of distance matrix, optionally processed by
    <code>reduce_func</code>.</li>
</ul>
<h4>Examples</h4>
<p>Without reduce_func:</p>
<div class="highlight"><pre><span></span><code><span class="o">&gt;&gt;&gt;</span> <span class="kn">import</span> <span class="nn">numpy</span> <span class="k">as</span> <span class="nn">np</span>
<span class="o">&gt;&gt;&gt;</span> <span class="kn">from</span> <span class="nn">sklearn.metrics</span> <span class="kn">import</span> <span class="n">pairwise_distances_chunked</span>
<span class="o">&gt;&gt;&gt;</span> <span class="n">X</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">random</span><span class="o">.</span><span class="n">RandomState</span><span class="p">(</span><span class="mi">0</span><span class="p">)</span><span class="o">.</span><span class="n">rand</span><span class="p">(</span><span class="mi">5</span><span class="p">,</span> <span class="mi">3</span><span class="p">)</span>
<span class="o">&gt;&gt;&gt;</span> <span class="n">D_chunk</span> <span class="o">=</span> <span class="nb">next</span><span class="p">(</span><span class="n">pairwise_distances_chunked</span><span class="p">(</span><span class="n">X</span><span class="p">))</span>
<span class="o">&gt;&gt;&gt;</span> <span class="n">D_chunk</span>
<span class="n">array</span><span class="p">([[</span><span class="mf">0.</span>  <span class="o">...</span><span class="p">,</span> <span class="mf">0.29</span><span class="o">...</span><span class="p">,</span> <span class="mf">0.41</span><span class="o">...</span><span class="p">,</span> <span class="mf">0.19</span><span class="o">...</span><span class="p">,</span> <span class="mf">0.57</span><span class="o">...</span><span class="p">],</span>
       <span class="p">[</span><span class="mf">0.29</span><span class="o">...</span><span class="p">,</span> <span class="mf">0.</span>  <span class="o">...</span><span class="p">,</span> <span class="mf">0.57</span><span class="o">...</span><span class="p">,</span> <span class="mf">0.41</span><span class="o">...</span><span class="p">,</span> <span class="mf">0.76</span><span class="o">...</span><span class="p">],</span>
       <span class="p">[</span><span class="mf">0.41</span><span class="o">...</span><span class="p">,</span> <span class="mf">0.57</span><span class="o">...</span><span class="p">,</span> <span class="mf">0.</span>  <span class="o">...</span><span class="p">,</span> <span class="mf">0.44</span><span class="o">...</span><span class="p">,</span> <span class="mf">0.90</span><span class="o">...</span><span class="p">],</span>
       <span class="p">[</span><span class="mf">0.19</span><span class="o">...</span><span class="p">,</span> <span class="mf">0.41</span><span class="o">...</span><span class="p">,</span> <span class="mf">0.44</span><span class="o">...</span><span class="p">,</span> <span class="mf">0.</span>  <span class="o">...</span><span class="p">,</span> <span class="mf">0.51</span><span class="o">...</span><span class="p">],</span>
       <span class="p">[</span><span class="mf">0.57</span><span class="o">...</span><span class="p">,</span> <span class="mf">0.76</span><span class="o">...</span><span class="p">,</span> <span class="mf">0.90</span><span class="o">...</span><span class="p">,</span> <span class="mf">0.51</span><span class="o">...</span><span class="p">,</span> <span class="mf">0.</span>  <span class="o">...</span><span class="p">]])</span>
</code></pre></div>

<p>Retrieve all neighbors and average distance within radius r:</p>
<div class="highlight"><pre><span></span><code><span class="o">&gt;&gt;&gt;</span> <span class="n">r</span> <span class="o">=</span> <span class="o">.</span><span class="mi">2</span>
<span class="o">&gt;&gt;&gt;</span> <span class="k">def</span> <span class="nf">reduce_func</span><span class="p">(</span><span class="n">D_chunk</span><span class="p">,</span> <span class="n">start</span><span class="p">):</span>
<span class="o">...</span>     <span class="n">neigh</span> <span class="o">=</span> <span class="p">[</span><span class="n">np</span><span class="o">.</span><span class="n">flatnonzero</span><span class="p">(</span><span class="n">d</span> <span class="o">&lt;</span> <span class="n">r</span><span class="p">)</span> <span class="k">for</span> <span class="n">d</span> <span class="ow">in</span> <span class="n">D_chunk</span><span class="p">]</span>
<span class="o">...</span>     <span class="n">avg_dist</span> <span class="o">=</span> <span class="p">(</span><span class="n">D_chunk</span> <span class="o">*</span> <span class="p">(</span><span class="n">D_chunk</span> <span class="o">&lt;</span> <span class="n">r</span><span class="p">))</span><span class="o">.</span><span class="n">mean</span><span class="p">(</span><span class="n">axis</span><span class="o">=</span><span class="mi">1</span><span class="p">)</span>
<span class="o">...</span>     <span class="k">return</span> <span class="n">neigh</span><span class="p">,</span> <span class="n">avg_dist</span>
<span class="o">&gt;&gt;&gt;</span> <span class="n">gen</span> <span class="o">=</span> <span class="n">pairwise_distances_chunked</span><span class="p">(</span><span class="n">X</span><span class="p">,</span> <span class="n">reduce_func</span><span class="o">=</span><span class="n">reduce_func</span><span class="p">)</span>
<span class="o">&gt;&gt;&gt;</span> <span class="n">neigh</span><span class="p">,</span> <span class="n">avg_dist</span> <span class="o">=</span> <span class="nb">next</span><span class="p">(</span><span class="n">gen</span><span class="p">)</span>
<span class="o">&gt;&gt;&gt;</span> <span class="n">neigh</span>
<span class="p">[</span><span class="n">array</span><span class="p">([</span><span class="mi">0</span><span class="p">,</span> <span class="mi">3</span><span class="p">]),</span> <span class="n">array</span><span class="p">([</span><span class="mi">1</span><span class="p">]),</span> <span class="n">array</span><span class="p">([</span><span class="mi">2</span><span class="p">]),</span> <span class="n">array</span><span class="p">([</span><span class="mi">0</span><span class="p">,</span> <span class="mi">3</span><span class="p">]),</span> <span class="n">array</span><span class="p">([</span><span class="mi">4</span><span class="p">])]</span>
<span class="o">&gt;&gt;&gt;</span> <span class="n">avg_dist</span>
<span class="n">array</span><span class="p">([</span><span class="mf">0.039</span><span class="o">...</span><span class="p">,</span> <span class="mf">0.</span>        <span class="p">,</span> <span class="mf">0.</span>        <span class="p">,</span> <span class="mf">0.039</span><span class="o">...</span><span class="p">,</span> <span class="mf">0.</span>        <span class="p">])</span>
</code></pre></div>

<p>Where r is defined per sample, we need to make use of <code>start</code>:</p>
<div class="highlight"><pre><span></span><code><span class="o">&gt;&gt;&gt;</span> <span class="n">r</span> <span class="o">=</span> <span class="p">[</span><span class="o">.</span><span class="mi">2</span><span class="p">,</span> <span class="o">.</span><span class="mi">4</span><span class="p">,</span> <span class="o">.</span><span class="mi">4</span><span class="p">,</span> <span class="o">.</span><span class="mi">3</span><span class="p">,</span> <span class="o">.</span><span class="mi">1</span><span class="p">]</span>
<span class="o">&gt;&gt;&gt;</span> <span class="k">def</span> <span class="nf">reduce_func</span><span class="p">(</span><span class="n">D_chunk</span><span class="p">,</span> <span class="n">start</span><span class="p">):</span>
<span class="o">...</span>     <span class="n">neigh</span> <span class="o">=</span> <span class="p">[</span><span class="n">np</span><span class="o">.</span><span class="n">flatnonzero</span><span class="p">(</span><span class="n">d</span> <span class="o">&lt;</span> <span class="n">r</span><span class="p">[</span><span class="n">i</span><span class="p">])</span>
<span class="o">...</span>              <span class="k">for</span> <span class="n">i</span><span class="p">,</span> <span class="n">d</span> <span class="ow">in</span> <span class="nb">enumerate</span><span class="p">(</span><span class="n">D_chunk</span><span class="p">,</span> <span class="n">start</span><span class="p">)]</span>
<span class="o">...</span>     <span class="k">return</span> <span class="n">neigh</span>
<span class="o">&gt;&gt;&gt;</span> <span class="n">neigh</span> <span class="o">=</span> <span class="nb">next</span><span class="p">(</span><span class="n">pairwise_distances_chunked</span><span class="p">(</span><span class="n">X</span><span class="p">,</span> <span class="n">reduce_func</span><span class="o">=</span><span class="n">reduce_func</span><span class="p">))</span>
<span class="o">&gt;&gt;&gt;</span> <span class="n">neigh</span>
<span class="p">[</span><span class="n">array</span><span class="p">([</span><span class="mi">0</span><span class="p">,</span> <span class="mi">3</span><span class="p">]),</span> <span class="n">array</span><span class="p">([</span><span class="mi">0</span><span class="p">,</span> <span class="mi">1</span><span class="p">]),</span> <span class="n">array</span><span class="p">([</span><span class="mi">2</span><span class="p">]),</span> <span class="n">array</span><span class="p">([</span><span class="mi">0</span><span class="p">,</span> <span class="mi">3</span><span class="p">]),</span> <span class="n">array</span><span class="p">([</span><span class="mi">4</span><span class="p">])]</span>
</code></pre></div>

<p>Force row-by-row generation by reducing <code>working_memory</code>:</p>
<div class="highlight"><pre><span></span><code><span class="o">&gt;&gt;&gt;</span> <span class="n">gen</span> <span class="o">=</span> <span class="n">pairwise_distances_chunked</span><span class="p">(</span><span class="n">X</span><span class="p">,</span> <span class="n">reduce_func</span><span class="o">=</span><span class="n">reduce_func</span><span class="p">,</span>
<span class="o">...</span>                                  <span class="n">working_memory</span><span class="o">=</span><span class="mi">0</span><span class="p">)</span>
<span class="o">&gt;&gt;&gt;</span> <span class="nb">next</span><span class="p">(</span><span class="n">gen</span><span class="p">)</span>
<span class="p">[</span><span class="n">array</span><span class="p">([</span><span class="mi">0</span><span class="p">,</span> <span class="mi">3</span><span class="p">])]</span>
<span class="o">&gt;&gt;&gt;</span> <span class="nb">next</span><span class="p">(</span><span class="n">gen</span><span class="p">)</span>
<span class="p">[</span><span class="n">array</span><span class="p">([</span><span class="mi">0</span><span class="p">,</span> <span class="mi">1</span><span class="p">])]</span>
</code></pre></div>

</details>
<h3 id="pairwise_kernels">pairwise_kernels<a class="headerlink" href="#pairwise_kernels" title="Permanent link">&para;</a></h3>
<details class="note" open="open"><summary>function pairwise_kernels</summary><div class="highlight"><pre><span></span><code><span class="k">val</span> <span class="n">pairwise_kernels</span> <span class="o">:</span>
  <span class="o">?</span><span class="n">y</span><span class="o">:[&gt;`</span><span class="nc">ArrayLike</span><span class="o">]</span> <span class="nn">Np</span><span class="p">.</span><span class="nn">Obj</span><span class="p">.</span><span class="n">t</span> <span class="o">-&gt;</span>
  <span class="o">?</span><span class="n">metric</span><span class="o">:[`</span><span class="nc">S</span> <span class="k">of</span> <span class="kt">string</span> <span class="o">|</span> <span class="o">`</span><span class="nc">Callable</span> <span class="k">of</span> <span class="nn">Py</span><span class="p">.</span><span class="nn">Object</span><span class="p">.</span><span class="n">t</span><span class="o">]</span> <span class="o">-&gt;</span>
  <span class="o">?</span><span class="n">filter_params</span><span class="o">:</span><span class="kt">bool</span> <span class="o">-&gt;</span>
  <span class="o">?</span><span class="n">n_jobs</span><span class="o">:</span><span class="kt">int</span> <span class="o">-&gt;</span>
  <span class="o">?</span><span class="n">kwds</span><span class="o">:(</span><span class="kt">string</span> <span class="o">*</span> <span class="nn">Py</span><span class="p">.</span><span class="nn">Object</span><span class="p">.</span><span class="n">t</span><span class="o">)</span> <span class="kt">list</span> <span class="o">-&gt;</span>
  <span class="n">x</span><span class="o">:[`</span><span class="nc">Arr</span> <span class="k">of</span> <span class="o">[&gt;`</span><span class="nc">ArrayLike</span><span class="o">]</span> <span class="nn">Np</span><span class="p">.</span><span class="nn">Obj</span><span class="p">.</span><span class="n">t</span> <span class="o">|</span> <span class="o">`</span><span class="nc">Otherwise</span> <span class="k">of</span> <span class="nn">Py</span><span class="p">.</span><span class="nn">Object</span><span class="p">.</span><span class="n">t</span><span class="o">]</span> <span class="o">-&gt;</span>
  <span class="kt">unit</span> <span class="o">-&gt;</span>
  <span class="o">[&gt;`</span><span class="nc">ArrayLike</span><span class="o">]</span> <span class="nn">Np</span><span class="p">.</span><span class="nn">Obj</span><span class="p">.</span><span class="n">t</span>
</code></pre></div>

<p>Compute the kernel between arrays X and optional array Y.</p>
<p>This method takes either a vector array or a kernel matrix, and returns
a kernel matrix. If the input is a vector array, the kernels are
computed. If the input is a kernel matrix, it is returned instead.</p>
<p>This method provides a safe way to take a kernel matrix as input, while
preserving compatibility with many other algorithms that take a vector
array.</p>
<p>If Y is given (default is None), then the returned matrix is the pairwise
kernel between the arrays from both X and Y.</p>
<p>Valid values for metric are:
    ['additive_chi2', 'chi2', 'linear', 'poly', 'polynomial', 'rbf',
    'laplacian', 'sigmoid', 'cosine']</p>
<p>Read more in the :ref:<code>User Guide &lt;metrics&gt;</code>.</p>
<h4>Parameters</h4>
<ul>
<li>
<p><strong>X : array [n_samples_a, n_samples_a] if metric == 'precomputed', or,              [n_samples_a, n_features] otherwise</strong>
    Array of pairwise kernels between samples, or a feature array.</p>
</li>
<li>
<p><strong>Y : array [n_samples_b, n_features]</strong>
    A second feature array only if X has shape [n_samples_a, n_features].</p>
</li>
<li>
<p><strong>metric : string, or callable</strong>
    The metric to use when calculating kernel between instances in a
    feature array. If metric is a string, it must be one of the metrics
    in pairwise.PAIRWISE_KERNEL_FUNCTIONS.
    If metric is 'precomputed', X is assumed to be a kernel matrix.
    Alternatively, if metric is a callable function, it is called on each
    pair of instances (rows) and the resulting value recorded. The callable
    should take two rows from X as input and return the corresponding
    kernel value as a single number. This means that callables from
    :mod:<code>sklearn.metrics.pairwise</code> are not allowed, as they operate on
    matrices, not single samples. Use the string identifying the kernel
    instead.</p>
</li>
<li>
<p><strong>filter_params : boolean</strong>
    Whether to filter invalid parameters or not.</p>
</li>
<li>
<p><strong>n_jobs : int or None, optional (default=None)</strong>
    The number of jobs to use for the computation. This works by breaking
    down the pairwise matrix into n_jobs even slices and computing them in
    parallel.</p>
<p><code>None</code> means 1 unless in a :obj:<code>joblib.parallel_backend</code> context.
<code>-1</code> means using all processors. See :term:<code>Glossary &lt;n_jobs&gt;</code>
for more details.</p>
</li>
<li>
<p><strong>**kwds : optional keyword parameters</strong>
    Any further parameters are passed directly to the kernel function.</p>
</li>
</ul>
<h4>Returns</h4>
<ul>
<li><strong>K : array [n_samples_a, n_samples_a] or [n_samples_a, n_samples_b]</strong>
    A kernel matrix K such that K_{i, j} is the kernel between the
    ith and jth vectors of the given matrix X, if Y is None.
    If Y is not None, then K_{i, j} is the kernel between the ith array
    from X and the jth array from Y.</li>
</ul>
<h4>Notes</h4>
<p>If metric is 'precomputed', Y is ignored and X is returned.</p>
</details>
<h3 id="parse_version">parse_version<a class="headerlink" href="#parse_version" title="Permanent link">&para;</a></h3>
<details class="note" open="open"><summary>function parse_version</summary><div class="highlight"><pre><span></span><code><span class="k">val</span> <span class="n">parse_version</span> <span class="o">:</span>
  <span class="nn">Py</span><span class="p">.</span><span class="nn">Object</span><span class="p">.</span><span class="n">t</span> <span class="o">-&gt;</span>
  <span class="nn">Py</span><span class="p">.</span><span class="nn">Object</span><span class="p">.</span><span class="n">t</span>
</code></pre></div>

</details>
<h3 id="polynomial_kernel">polynomial_kernel<a class="headerlink" href="#polynomial_kernel" title="Permanent link">&para;</a></h3>
<details class="note" open="open"><summary>function polynomial_kernel</summary><div class="highlight"><pre><span></span><code><span class="k">val</span> <span class="n">polynomial_kernel</span> <span class="o">:</span>
  <span class="o">?</span><span class="n">y</span><span class="o">:[&gt;`</span><span class="nc">ArrayLike</span><span class="o">]</span> <span class="nn">Np</span><span class="p">.</span><span class="nn">Obj</span><span class="p">.</span><span class="n">t</span> <span class="o">-&gt;</span>
  <span class="o">?</span><span class="n">degree</span><span class="o">:</span><span class="kt">int</span> <span class="o">-&gt;</span>
  <span class="o">?</span><span class="n">gamma</span><span class="o">:</span><span class="kt">float</span> <span class="o">-&gt;</span>
  <span class="o">?</span><span class="n">coef0</span><span class="o">:</span><span class="kt">float</span> <span class="o">-&gt;</span>
  <span class="n">x</span><span class="o">:[&gt;`</span><span class="nc">ArrayLike</span><span class="o">]</span> <span class="nn">Np</span><span class="p">.</span><span class="nn">Obj</span><span class="p">.</span><span class="n">t</span> <span class="o">-&gt;</span>
  <span class="kt">unit</span> <span class="o">-&gt;</span>
  <span class="nn">Py</span><span class="p">.</span><span class="nn">Object</span><span class="p">.</span><span class="n">t</span>
</code></pre></div>

<p>Compute the polynomial kernel between X and Y::</p>
<div class="codehilite"><pre><span></span><code>K(X, Y) = (gamma &lt;X, Y&gt; + coef0)^degree
</code></pre></div>


<p>Read more in the :ref:<code>User Guide &lt;polynomial_kernel&gt;</code>.</p>
<h4>Parameters</h4>
<ul>
<li>
<p><strong>X : ndarray of shape (n_samples_1, n_features)</strong></p>
</li>
<li>
<p><strong>Y : ndarray of shape (n_samples_2, n_features)</strong></p>
</li>
<li>
<p><strong>degree : int, default 3</strong></p>
</li>
<li>
<p><strong>gamma : float, default None</strong>
    if None, defaults to 1.0 / n_features</p>
</li>
<li>
<p><strong>coef0 : float, default 1</strong></p>
</li>
</ul>
<h4>Returns</h4>
<p>Gram matrix : array of shape (n_samples_1, n_samples_2)</p>
</details>
<h3 id="rbf_kernel">rbf_kernel<a class="headerlink" href="#rbf_kernel" title="Permanent link">&para;</a></h3>
<details class="note" open="open"><summary>function rbf_kernel</summary><div class="highlight"><pre><span></span><code><span class="k">val</span> <span class="n">rbf_kernel</span> <span class="o">:</span>
  <span class="o">?</span><span class="n">y</span><span class="o">:[&gt;`</span><span class="nc">ArrayLike</span><span class="o">]</span> <span class="nn">Np</span><span class="p">.</span><span class="nn">Obj</span><span class="p">.</span><span class="n">t</span> <span class="o">-&gt;</span>
  <span class="o">?</span><span class="n">gamma</span><span class="o">:</span><span class="kt">float</span> <span class="o">-&gt;</span>
  <span class="n">x</span><span class="o">:[&gt;`</span><span class="nc">ArrayLike</span><span class="o">]</span> <span class="nn">Np</span><span class="p">.</span><span class="nn">Obj</span><span class="p">.</span><span class="n">t</span> <span class="o">-&gt;</span>
  <span class="kt">unit</span> <span class="o">-&gt;</span>
  <span class="o">[&gt;`</span><span class="nc">ArrayLike</span><span class="o">]</span> <span class="nn">Np</span><span class="p">.</span><span class="nn">Obj</span><span class="p">.</span><span class="n">t</span>
</code></pre></div>

<p>Compute the rbf (gaussian) kernel between X and Y::</p>
<div class="codehilite"><pre><span></span><code>K(x, y) = exp(-gamma ||x-y||^2)
</code></pre></div>


<p>for each pair of rows x in X and y in Y.</p>
<p>Read more in the :ref:<code>User Guide &lt;rbf_kernel&gt;</code>.</p>
<h4>Parameters</h4>
<ul>
<li>
<p><strong>X : array of shape (n_samples_X, n_features)</strong></p>
</li>
<li>
<p><strong>Y : array of shape (n_samples_Y, n_features)</strong></p>
</li>
<li>
<p><strong>gamma : float, default None</strong>
    If None, defaults to 1.0 / n_features</p>
</li>
</ul>
<h4>Returns</h4>
<ul>
<li><strong>kernel_matrix : array of shape (n_samples_X, n_samples_Y)</strong></li>
</ul>
</details>
<h3 id="row_norms">row_norms<a class="headerlink" href="#row_norms" title="Permanent link">&para;</a></h3>
<details class="note" open="open"><summary>function row_norms</summary><div class="highlight"><pre><span></span><code><span class="k">val</span> <span class="n">row_norms</span> <span class="o">:</span>
  <span class="o">?</span><span class="n">squared</span><span class="o">:</span><span class="kt">bool</span> <span class="o">-&gt;</span>
  <span class="n">x</span><span class="o">:[&gt;`</span><span class="nc">ArrayLike</span><span class="o">]</span> <span class="nn">Np</span><span class="p">.</span><span class="nn">Obj</span><span class="p">.</span><span class="n">t</span> <span class="o">-&gt;</span>
  <span class="kt">unit</span> <span class="o">-&gt;</span>
  <span class="nn">Py</span><span class="p">.</span><span class="nn">Object</span><span class="p">.</span><span class="n">t</span>
</code></pre></div>

<p>Row-wise (squared) Euclidean norm of X.</p>
<p>Equivalent to np.sqrt((X * X).sum(axis=1)), but also supports sparse
matrices and does not create an X.shape-sized temporary.</p>
<p>Performs no input validation.</p>
<h4>Parameters</h4>
<ul>
<li>
<p><strong>X : array_like</strong>
    The input array</p>
</li>
<li>
<p><strong>squared : bool, optional (default = False)</strong>
    If True, return squared norms.</p>
</li>
</ul>
<h4>Returns</h4>
<p>array_like
    The row-wise (squared) Euclidean norm of X.</p>
</details>
<h3 id="safe_sparse_dot">safe_sparse_dot<a class="headerlink" href="#safe_sparse_dot" title="Permanent link">&para;</a></h3>
<details class="note" open="open"><summary>function safe_sparse_dot</summary><div class="highlight"><pre><span></span><code><span class="k">val</span> <span class="n">safe_sparse_dot</span> <span class="o">:</span>
  <span class="o">?</span><span class="n">dense_output</span><span class="o">:</span><span class="nn">Py</span><span class="p">.</span><span class="nn">Object</span><span class="p">.</span><span class="n">t</span> <span class="o">-&gt;</span>
  <span class="n">a</span><span class="o">:[&gt;`</span><span class="nc">ArrayLike</span><span class="o">]</span> <span class="nn">Np</span><span class="p">.</span><span class="nn">Obj</span><span class="p">.</span><span class="n">t</span> <span class="o">-&gt;</span>
  <span class="n">b</span><span class="o">:</span><span class="nn">Py</span><span class="p">.</span><span class="nn">Object</span><span class="p">.</span><span class="n">t</span> <span class="o">-&gt;</span>
  <span class="kt">unit</span> <span class="o">-&gt;</span>
  <span class="o">[&gt;`</span><span class="nc">ArrayLike</span><span class="o">]</span> <span class="nn">Np</span><span class="p">.</span><span class="nn">Obj</span><span class="p">.</span><span class="n">t</span>
</code></pre></div>

<p>Dot product that handle the sparse matrix case correctly</p>
<h4>Parameters</h4>
<ul>
<li>
<p><strong>a : array or sparse matrix</strong></p>
</li>
<li>
<p><strong>b : array or sparse matrix</strong></p>
</li>
<li>
<p><strong>dense_output : boolean, (default=False)</strong>
    When False, <code>a</code> and <code>b</code> both being sparse will yield sparse output.
    When True, output will always be a dense array.</p>
</li>
</ul>
<h4>Returns</h4>
<ul>
<li><strong>dot_product : array or sparse matrix</strong>
    sparse if <code>a</code> and <code>b</code> are sparse and <code>dense_output=False</code>.</li>
</ul>
</details>
<h3 id="sigmoid_kernel">sigmoid_kernel<a class="headerlink" href="#sigmoid_kernel" title="Permanent link">&para;</a></h3>
<details class="note" open="open"><summary>function sigmoid_kernel</summary><div class="highlight"><pre><span></span><code><span class="k">val</span> <span class="n">sigmoid_kernel</span> <span class="o">:</span>
  <span class="o">?</span><span class="n">y</span><span class="o">:[&gt;`</span><span class="nc">ArrayLike</span><span class="o">]</span> <span class="nn">Np</span><span class="p">.</span><span class="nn">Obj</span><span class="p">.</span><span class="n">t</span> <span class="o">-&gt;</span>
  <span class="o">?</span><span class="n">gamma</span><span class="o">:</span><span class="kt">float</span> <span class="o">-&gt;</span>
  <span class="o">?</span><span class="n">coef0</span><span class="o">:</span><span class="kt">float</span> <span class="o">-&gt;</span>
  <span class="n">x</span><span class="o">:[&gt;`</span><span class="nc">ArrayLike</span><span class="o">]</span> <span class="nn">Np</span><span class="p">.</span><span class="nn">Obj</span><span class="p">.</span><span class="n">t</span> <span class="o">-&gt;</span>
  <span class="kt">unit</span> <span class="o">-&gt;</span>
  <span class="nn">Py</span><span class="p">.</span><span class="nn">Object</span><span class="p">.</span><span class="n">t</span>
</code></pre></div>

<p>Compute the sigmoid kernel between X and Y::</p>
<div class="codehilite"><pre><span></span><code>K(X, Y) = tanh(gamma &lt;X, Y&gt; + coef0)
</code></pre></div>


<p>Read more in the :ref:<code>User Guide &lt;sigmoid_kernel&gt;</code>.</p>
<h4>Parameters</h4>
<ul>
<li>
<p><strong>X : ndarray of shape (n_samples_1, n_features)</strong></p>
</li>
<li>
<p><strong>Y : ndarray of shape (n_samples_2, n_features)</strong></p>
</li>
<li>
<p><strong>gamma : float, default None</strong>
    If None, defaults to 1.0 / n_features</p>
</li>
<li>
<p><strong>coef0 : float, default 1</strong></p>
</li>
</ul>
<h4>Returns</h4>
<p>Gram matrix : array of shape (n_samples_1, n_samples_2)</p>
</details>
<h3 id="accuracy_score">accuracy_score<a class="headerlink" href="#accuracy_score" title="Permanent link">&para;</a></h3>
<details class="note" open="open"><summary>function accuracy_score</summary><div class="highlight"><pre><span></span><code><span class="k">val</span> <span class="n">accuracy_score</span> <span class="o">:</span>
  <span class="o">?</span><span class="n">normalize</span><span class="o">:</span><span class="kt">bool</span> <span class="o">-&gt;</span>
  <span class="o">?</span><span class="n">sample_weight</span><span class="o">:[&gt;`</span><span class="nc">ArrayLike</span><span class="o">]</span> <span class="nn">Np</span><span class="p">.</span><span class="nn">Obj</span><span class="p">.</span><span class="n">t</span> <span class="o">-&gt;</span>
  <span class="n">y_true</span><span class="o">:[&gt;`</span><span class="nc">ArrayLike</span><span class="o">]</span> <span class="nn">Np</span><span class="p">.</span><span class="nn">Obj</span><span class="p">.</span><span class="n">t</span> <span class="o">-&gt;</span>
  <span class="n">y_pred</span><span class="o">:[&gt;`</span><span class="nc">ArrayLike</span><span class="o">]</span> <span class="nn">Np</span><span class="p">.</span><span class="nn">Obj</span><span class="p">.</span><span class="n">t</span> <span class="o">-&gt;</span>
  <span class="kt">unit</span> <span class="o">-&gt;</span>
  <span class="kt">float</span>
</code></pre></div>

<p>Accuracy classification score.</p>
<p>In multilabel classification, this function computes subset accuracy:
the set of labels predicted for a sample must <em>exactly</em> match the
corresponding set of labels in y_true.</p>
<p>Read more in the :ref:<code>User Guide &lt;accuracy_score&gt;</code>.</p>
<h4>Parameters</h4>
<ul>
<li>
<p><strong>y_true : 1d array-like, or label indicator array / sparse matrix</strong>
    Ground truth (correct) labels.</p>
</li>
<li>
<p><strong>y_pred : 1d array-like, or label indicator array / sparse matrix</strong>
    Predicted labels, as returned by a classifier.</p>
</li>
<li>
<p><strong>normalize : bool, optional (default=True)</strong>
    If <code>False</code>, return the number of correctly classified samples.
    Otherwise, return the fraction of correctly classified samples.</p>
</li>
<li>
<p><strong>sample_weight : array-like of shape (n_samples,), default=None</strong>
    Sample weights.</p>
</li>
</ul>
<h4>Returns</h4>
<ul>
<li>
<p><strong>score : float</strong>
    If <code>normalize == True</code>, return the fraction of correctly
    classified samples (float), else returns the number of correctly
    classified samples (int).</p>
<p>The best performance is 1 with <code>normalize == True</code> and the number
of samples with <code>normalize == False</code>.</p>
</li>
</ul>
<h4>See also</h4>
<p>jaccard_score, hamming_loss, zero_one_loss</p>
<h4>Notes</h4>
<p>In binary and multiclass classification, this function is equal
to the <code>jaccard_score</code> function.</p>
<h4>Examples</h4>
<div class="highlight"><pre><span></span><code><span class="o">&gt;&gt;&gt;</span> <span class="kn">from</span> <span class="nn">sklearn.metrics</span> <span class="kn">import</span> <span class="n">accuracy_score</span>
<span class="o">&gt;&gt;&gt;</span> <span class="n">y_pred</span> <span class="o">=</span> <span class="p">[</span><span class="mi">0</span><span class="p">,</span> <span class="mi">2</span><span class="p">,</span> <span class="mi">1</span><span class="p">,</span> <span class="mi">3</span><span class="p">]</span>
<span class="o">&gt;&gt;&gt;</span> <span class="n">y_true</span> <span class="o">=</span> <span class="p">[</span><span class="mi">0</span><span class="p">,</span> <span class="mi">1</span><span class="p">,</span> <span class="mi">2</span><span class="p">,</span> <span class="mi">3</span><span class="p">]</span>
<span class="o">&gt;&gt;&gt;</span> <span class="n">accuracy_score</span><span class="p">(</span><span class="n">y_true</span><span class="p">,</span> <span class="n">y_pred</span><span class="p">)</span>
<span class="mf">0.5</span>
<span class="o">&gt;&gt;&gt;</span> <span class="n">accuracy_score</span><span class="p">(</span><span class="n">y_true</span><span class="p">,</span> <span class="n">y_pred</span><span class="p">,</span> <span class="n">normalize</span><span class="o">=</span><span class="kc">False</span><span class="p">)</span>
<span class="mi">2</span>
</code></pre></div>

<p>In the multilabel case with binary label indicators:</p>
<div class="highlight"><pre><span></span><code><span class="o">&gt;&gt;&gt;</span> <span class="kn">import</span> <span class="nn">numpy</span> <span class="k">as</span> <span class="nn">np</span>
<span class="o">&gt;&gt;&gt;</span> <span class="n">accuracy_score</span><span class="p">(</span><span class="n">np</span><span class="o">.</span><span class="n">array</span><span class="p">([[</span><span class="mi">0</span><span class="p">,</span> <span class="mi">1</span><span class="p">],</span> <span class="p">[</span><span class="mi">1</span><span class="p">,</span> <span class="mi">1</span><span class="p">]]),</span> <span class="n">np</span><span class="o">.</span><span class="n">ones</span><span class="p">((</span><span class="mi">2</span><span class="p">,</span> <span class="mi">2</span><span class="p">)))</span>
<span class="mf">0.5</span>
</code></pre></div>

</details>
<h3 id="adjusted_mutual_info_score_1">adjusted_mutual_info_score<a class="headerlink" href="#adjusted_mutual_info_score_1" title="Permanent link">&para;</a></h3>
<details class="note" open="open"><summary>function adjusted_mutual_info_score</summary><div class="highlight"><pre><span></span><code><span class="k">val</span> <span class="n">adjusted_mutual_info_score</span> <span class="o">:</span>
  <span class="o">?</span><span class="n">average_method</span><span class="o">:</span><span class="kt">string</span> <span class="o">-&gt;</span>
  <span class="n">labels_true</span><span class="o">:[&gt;`</span><span class="nc">ArrayLike</span><span class="o">]</span> <span class="nn">Np</span><span class="p">.</span><span class="nn">Obj</span><span class="p">.</span><span class="n">t</span> <span class="o">-&gt;</span>
  <span class="n">labels_pred</span><span class="o">:[&gt;`</span><span class="nc">ArrayLike</span><span class="o">]</span> <span class="nn">Np</span><span class="p">.</span><span class="nn">Obj</span><span class="p">.</span><span class="n">t</span> <span class="o">-&gt;</span>
  <span class="kt">unit</span> <span class="o">-&gt;</span>
  <span class="kt">float</span>
</code></pre></div>

<p>Adjusted Mutual Information between two clusterings.</p>
<p>Adjusted Mutual Information (AMI) is an adjustment of the Mutual
Information (MI) score to account for chance. It accounts for the fact that
the MI is generally higher for two clusterings with a larger number of
clusters, regardless of whether there is actually more information shared.
For two clusterings :math:<code>U</code> and :math:<code>V</code>, the AMI is given as::</p>
<div class="codehilite"><pre><span></span><code>AMI(U, V) = [MI(U, V) - E(MI(U, V))] / [avg(H(U), H(V)) - E(MI(U, V))]
</code></pre></div>


<p>This metric is independent of the absolute values of the labels:
a permutation of the class or cluster label values won't change the
score value in any way.</p>
<p>This metric is furthermore symmetric: switching <code>label_true</code> with
<code>label_pred</code> will return the same score value. This can be useful to
measure the agreement of two independent label assignments strategies
on the same dataset when the real ground truth is not known.</p>
<p>Be mindful that this function is an order of magnitude slower than other
metrics, such as the Adjusted Rand Index.</p>
<p>Read more in the :ref:<code>User Guide &lt;mutual_info_score&gt;</code>.</p>
<h4>Parameters</h4>
<ul>
<li>
<p><strong>labels_true : int array, shape = [n_samples]</strong>
    A clustering of the data into disjoint subsets.</p>
</li>
<li>
<p><strong>labels_pred : int array-like of shape (n_samples,)</strong>
    A clustering of the data into disjoint subsets.</p>
</li>
<li>
<p><strong>average_method : string, optional (default: 'arithmetic')</strong>
    How to compute the normalizer in the denominator. Possible options
    are 'min', 'geometric', 'arithmetic', and 'max'.</p>
<p>.. versionadded:: 0.20</p>
<p>.. versionchanged:: 0.22
   The default value of <code>average_method</code> changed from 'max' to
   'arithmetic'.</p>
</li>
</ul>
<h4>Returns</h4>
<ul>
<li><strong>ami: float (upperlimited by 1.0)</strong>
   The AMI returns a value of 1 when the two partitions are identical
   (ie perfectly matched). Random partitions (independent labellings) have
   an expected AMI around 0 on average hence can be negative.</li>
</ul>
<h4>See also</h4>
<ul>
<li>
<p><strong>adjusted_rand_score: Adjusted Rand Index</strong></p>
</li>
<li>
<p><strong>mutual_info_score: Mutual Information (not adjusted for chance)</strong></p>
</li>
</ul>
<h4>Examples</h4>
<p>Perfect labelings are both homogeneous and complete, hence have
score 1.0::</p>
<blockquote>
<blockquote>
<blockquote>
<p>from sklearn.metrics.cluster import adjusted_mutual_info_score
adjusted_mutual_info_score([0, 0, 1, 1], [0, 0, 1, 1])
  ... # doctest: +SKIP
  1.0
adjusted_mutual_info_score([0, 0, 1, 1], [1, 1, 0, 0])
  ... # doctest: +SKIP
  1.0</p>
</blockquote>
</blockquote>
</blockquote>
<p>If classes members are completely split across different clusters,
the assignment is totally in-complete, hence the AMI is null::</p>
<blockquote>
<blockquote>
<blockquote>
<p>adjusted_mutual_info_score([0, 0, 0, 0], [0, 1, 2, 3])
  ... # doctest: +SKIP
  0.0</p>
</blockquote>
</blockquote>
</blockquote>
<h4>References</h4>
<p>.. [1] <code>Vinh, Epps, and Bailey, (2010). Information Theoretic Measures for
   Clusterings Comparison: Variants, Properties, Normalization and
   Correction for Chance, JMLR
   &lt;http://jmlr.csail.mit.edu/papers/volume11/vinh10a/vinh10a.pdf&gt;</code>_</p>
<p>.. [2] <code>Wikipedia entry for the Adjusted Mutual Information
   &lt;https://en.wikipedia.org/wiki/Adjusted_Mutual_Information&gt;</code>_</p>
</details>
<h3 id="adjusted_rand_score_1">adjusted_rand_score<a class="headerlink" href="#adjusted_rand_score_1" title="Permanent link">&para;</a></h3>
<details class="note" open="open"><summary>function adjusted_rand_score</summary><div class="highlight"><pre><span></span><code><span class="k">val</span> <span class="n">adjusted_rand_score</span> <span class="o">:</span>
  <span class="n">labels_true</span><span class="o">:[&gt;`</span><span class="nc">ArrayLike</span><span class="o">]</span> <span class="nn">Np</span><span class="p">.</span><span class="nn">Obj</span><span class="p">.</span><span class="n">t</span> <span class="o">-&gt;</span>
  <span class="n">labels_pred</span><span class="o">:[&gt;`</span><span class="nc">ArrayLike</span><span class="o">]</span> <span class="nn">Np</span><span class="p">.</span><span class="nn">Obj</span><span class="p">.</span><span class="n">t</span> <span class="o">-&gt;</span>
  <span class="kt">unit</span> <span class="o">-&gt;</span>
  <span class="kt">float</span>
</code></pre></div>

<p>Rand index adjusted for chance.</p>
<p>The Rand Index computes a similarity measure between two clusterings
by considering all pairs of samples and counting pairs that are
assigned in the same or different clusters in the predicted and
true clusterings.</p>
<p>The raw RI score is then 'adjusted for chance' into the ARI score
using the following scheme::</p>
<div class="codehilite"><pre><span></span><code>ARI = (RI - Expected_RI) / (max(RI) - Expected_RI)
</code></pre></div>


<p>The adjusted Rand index is thus ensured to have a value close to
0.0 for random labeling independently of the number of clusters and
samples and exactly 1.0 when the clusterings are identical (up to
a permutation).</p>
<p>ARI is a symmetric measure::</p>
<div class="codehilite"><pre><span></span><code>adjusted_rand_score(a, b) == adjusted_rand_score(b, a)
</code></pre></div>


<p>Read more in the :ref:<code>User Guide &lt;adjusted_rand_score&gt;</code>.</p>
<h4>Parameters</h4>
<ul>
<li>
<p><strong>labels_true : int array, shape = [n_samples]</strong>
    Ground truth class labels to be used as a reference</p>
</li>
<li>
<p><strong>labels_pred : array-like of shape (n_samples,)</strong>
    Cluster labels to evaluate</p>
</li>
</ul>
<h4>Returns</h4>
<ul>
<li><strong>ari : float</strong>
   Similarity score between -1.0 and 1.0. Random labelings have an ARI
   close to 0.0. 1.0 stands for perfect match.</li>
</ul>
<h4>Examples</h4>
<p>Perfectly matching labelings have a score of 1 even</p>
<blockquote>
<blockquote>
<blockquote>
<p>from sklearn.metrics.cluster import adjusted_rand_score
adjusted_rand_score([0, 0, 1, 1], [0, 0, 1, 1])
  1.0
adjusted_rand_score([0, 0, 1, 1], [1, 1, 0, 0])
  1.0</p>
</blockquote>
</blockquote>
</blockquote>
<p>Labelings that assign all classes members to the same clusters
are complete be not always pure, hence penalized::</p>
<blockquote>
<blockquote>
<blockquote>
<p>adjusted_rand_score([0, 0, 1, 2], [0, 0, 1, 1])
  0.57...</p>
</blockquote>
</blockquote>
</blockquote>
<p>ARI is symmetric, so labelings that have pure clusters with members
coming from the same classes but unnecessary splits are penalized::</p>
<blockquote>
<blockquote>
<blockquote>
<p>adjusted_rand_score([0, 0, 1, 1], [0, 0, 1, 2])
  0.57...</p>
</blockquote>
</blockquote>
</blockquote>
<p>If classes members are completely split across different clusters, the
assignment is totally incomplete, hence the ARI is very low::</p>
<blockquote>
<blockquote>
<blockquote>
<p>adjusted_rand_score([0, 0, 0, 0], [0, 1, 2, 3])
  0.0</p>
</blockquote>
</blockquote>
</blockquote>
<h4>References</h4>
<p>.. [Hubert1985] L. Hubert and P. Arabie, Comparing Partitions,
  Journal of Classification 1985</p>
<ul>
<li><strong>https://link.springer.com/article/10.1007%2FBF01908075</strong></li>
</ul>
<p>.. [wk] https://en.wikipedia.org/wiki/Rand_index#Adjusted_Rand_index</p>
<h4>See also</h4>
<ul>
<li><strong>adjusted_mutual_info_score: Adjusted Mutual Information</strong></li>
</ul>
</details>
<h3 id="auc">auc<a class="headerlink" href="#auc" title="Permanent link">&para;</a></h3>
<details class="note" open="open"><summary>function auc</summary><div class="highlight"><pre><span></span><code><span class="k">val</span> <span class="n">auc</span> <span class="o">:</span>
  <span class="n">x</span><span class="o">:[&gt;`</span><span class="nc">ArrayLike</span><span class="o">]</span> <span class="nn">Np</span><span class="p">.</span><span class="nn">Obj</span><span class="p">.</span><span class="n">t</span> <span class="o">-&gt;</span>
  <span class="n">y</span><span class="o">:[&gt;`</span><span class="nc">ArrayLike</span><span class="o">]</span> <span class="nn">Np</span><span class="p">.</span><span class="nn">Obj</span><span class="p">.</span><span class="n">t</span> <span class="o">-&gt;</span>
  <span class="kt">unit</span> <span class="o">-&gt;</span>
  <span class="kt">float</span>
</code></pre></div>

<p>Compute Area Under the Curve (AUC) using the trapezoidal rule</p>
<p>This is a general function, given points on a curve.  For computing the
area under the ROC-curve, see :func:<code>roc_auc_score</code>.  For an alternative
way to summarize a precision-recall curve, see
:func:<code>average_precision_score</code>.</p>
<h4>Parameters</h4>
<ul>
<li>
<p><strong>x : array, shape = [n]</strong>
    x coordinates. These must be either monotonic increasing or monotonic
    decreasing.</p>
</li>
<li>
<p><strong>y : array, shape = [n]</strong>
    y coordinates.</p>
</li>
</ul>
<h4>Returns</h4>
<ul>
<li><strong>auc : float</strong></li>
</ul>
<h4>Examples</h4>
<div class="highlight"><pre><span></span><code><span class="o">&gt;&gt;&gt;</span> <span class="kn">import</span> <span class="nn">numpy</span> <span class="k">as</span> <span class="nn">np</span>
<span class="o">&gt;&gt;&gt;</span> <span class="kn">from</span> <span class="nn">sklearn</span> <span class="kn">import</span> <span class="n">metrics</span>
<span class="o">&gt;&gt;&gt;</span> <span class="n">y</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">array</span><span class="p">([</span><span class="mi">1</span><span class="p">,</span> <span class="mi">1</span><span class="p">,</span> <span class="mi">2</span><span class="p">,</span> <span class="mi">2</span><span class="p">])</span>
<span class="o">&gt;&gt;&gt;</span> <span class="n">pred</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">array</span><span class="p">([</span><span class="mf">0.1</span><span class="p">,</span> <span class="mf">0.4</span><span class="p">,</span> <span class="mf">0.35</span><span class="p">,</span> <span class="mf">0.8</span><span class="p">])</span>
<span class="o">&gt;&gt;&gt;</span> <span class="n">fpr</span><span class="p">,</span> <span class="n">tpr</span><span class="p">,</span> <span class="n">thresholds</span> <span class="o">=</span> <span class="n">metrics</span><span class="o">.</span><span class="n">roc_curve</span><span class="p">(</span><span class="n">y</span><span class="p">,</span> <span class="n">pred</span><span class="p">,</span> <span class="n">pos_label</span><span class="o">=</span><span class="mi">2</span><span class="p">)</span>
<span class="o">&gt;&gt;&gt;</span> <span class="n">metrics</span><span class="o">.</span><span class="n">auc</span><span class="p">(</span><span class="n">fpr</span><span class="p">,</span> <span class="n">tpr</span><span class="p">)</span>
<span class="mf">0.75</span>
</code></pre></div>

<h4>See also</h4>
<ul>
<li>
<p><strong>roc_auc_score : Compute the area under the ROC curve</strong></p>
</li>
<li>
<p><strong>average_precision_score : Compute average precision from prediction scores</strong>
precision_recall_curve :
    Compute precision-recall pairs for different probability thresholds</p>
</li>
</ul>
</details>
<h3 id="average_precision_score">average_precision_score<a class="headerlink" href="#average_precision_score" title="Permanent link">&para;</a></h3>
<details class="note" open="open"><summary>function average_precision_score</summary><div class="highlight"><pre><span></span><code><span class="k">val</span> <span class="n">average_precision_score</span> <span class="o">:</span>
  <span class="o">?</span><span class="n">average</span><span class="o">:[`</span><span class="nc">Macro</span> <span class="o">|</span> <span class="o">`</span><span class="nc">Micro</span> <span class="o">|</span> <span class="o">`</span><span class="nc">Weighted</span> <span class="o">|</span> <span class="o">`</span><span class="nc">Samples</span> <span class="o">|</span> <span class="o">`</span><span class="nc">None</span><span class="o">]</span> <span class="o">-&gt;</span>
  <span class="o">?</span><span class="n">pos_label</span><span class="o">:[`</span><span class="nc">S</span> <span class="k">of</span> <span class="kt">string</span> <span class="o">|</span> <span class="o">`</span><span class="nc">I</span> <span class="k">of</span> <span class="kt">int</span><span class="o">]</span> <span class="o">-&gt;</span>
  <span class="o">?</span><span class="n">sample_weight</span><span class="o">:[&gt;`</span><span class="nc">ArrayLike</span><span class="o">]</span> <span class="nn">Np</span><span class="p">.</span><span class="nn">Obj</span><span class="p">.</span><span class="n">t</span> <span class="o">-&gt;</span>
  <span class="n">y_true</span><span class="o">:[&gt;`</span><span class="nc">ArrayLike</span><span class="o">]</span> <span class="nn">Np</span><span class="p">.</span><span class="nn">Obj</span><span class="p">.</span><span class="n">t</span> <span class="o">-&gt;</span>
  <span class="n">y_score</span><span class="o">:[&gt;`</span><span class="nc">ArrayLike</span><span class="o">]</span> <span class="nn">Np</span><span class="p">.</span><span class="nn">Obj</span><span class="p">.</span><span class="n">t</span> <span class="o">-&gt;</span>
  <span class="kt">unit</span> <span class="o">-&gt;</span>
  <span class="kt">float</span>
</code></pre></div>

<p>Compute average precision (AP) from prediction scores</p>
<p>AP summarizes a precision-recall curve as the weighted mean of precisions
achieved at each threshold, with the increase in recall from the previous
threshold used as the weight:</p>
<div>
<div class="MathJax_Preview">    \text{AP} = \sum_n (R_n - R_{n-1}) P_n
</div>
<script type="math/tex; mode=display">    \text{AP} = \sum_n (R_n - R_{n-1}) P_n
</script>
</div>
<ul>
<li>
<p><strong>where :math:<code>P_n</code> and :math:<code>R_n</code> are the precision and recall at the nth</strong>
threshold [1]_. This implementation is not interpolated and is different
from computing the area under the precision-recall curve with the
trapezoidal rule, which uses linear interpolation and can be too
optimistic.</p>
</li>
<li>
<p><strong>Note: this implementation is restricted to the binary classification task</strong>
or multilabel classification task.</p>
</li>
</ul>
<p>Read more in the :ref:<code>User Guide &lt;precision_recall_f_measure_metrics&gt;</code>.</p>
<h4>Parameters</h4>
<ul>
<li>
<p><strong>y_true : array, shape = [n_samples] or [n_samples, n_classes]</strong>
    True binary labels or binary label indicators.</p>
</li>
<li>
<p><strong>y_score : array, shape = [n_samples] or [n_samples, n_classes]</strong>
    Target scores, can either be probability estimates of the positive
    class, confidence values, or non-thresholded measure of decisions
    (as returned by 'decision_function' on some classifiers).</p>
</li>
<li>
<p><strong>average : string, [None, 'micro', 'macro' (default), 'samples', 'weighted']</strong>
    If <code>None</code>, the scores for each class are returned. Otherwise,
    this determines the type of averaging performed on the data:</p>
<p><code>'micro'</code>:
    Calculate metrics globally by considering each element of the label
    indicator matrix as a label.
<code>'macro'</code>:
    Calculate metrics for each label, and find their unweighted
    mean.  This does not take label imbalance into account.
<code>'weighted'</code>:
    Calculate metrics for each label, and find their average, weighted
    by support (the number of true instances for each label).
<code>'samples'</code>:
    Calculate metrics for each instance, and find their average.</p>
<p>Will be ignored when <code>y_true</code> is binary.</p>
</li>
<li>
<p><strong>pos_label : int or str (default=1)</strong>
    The label of the positive class. Only applied to binary <code>y_true</code>.
    For multilabel-indicator <code>y_true</code>, <code>pos_label</code> is fixed to 1.</p>
</li>
<li>
<p><strong>sample_weight : array-like of shape (n_samples,), default=None</strong>
    Sample weights.</p>
</li>
</ul>
<h4>Returns</h4>
<ul>
<li><strong>average_precision : float</strong></li>
</ul>
<h4>References</h4>
<p>.. [1] <code>Wikipedia entry for the Average precision
       &lt;https://en.wikipedia.org/w/index.php?title=Information_retrieval&amp;
       oldid=793358396#Average_precision&gt;</code>_</p>
<h4>See also</h4>
<ul>
<li><strong>roc_auc_score : Compute the area under the ROC curve</strong></li>
</ul>
<p>precision_recall_curve :
    Compute precision-recall pairs for different probability thresholds</p>
<h4>Examples</h4>
<div class="highlight"><pre><span></span><code><span class="o">&gt;&gt;&gt;</span> <span class="kn">import</span> <span class="nn">numpy</span> <span class="k">as</span> <span class="nn">np</span>
<span class="o">&gt;&gt;&gt;</span> <span class="kn">from</span> <span class="nn">sklearn.metrics</span> <span class="kn">import</span> <span class="n">average_precision_score</span>
<span class="o">&gt;&gt;&gt;</span> <span class="n">y_true</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">array</span><span class="p">([</span><span class="mi">0</span><span class="p">,</span> <span class="mi">0</span><span class="p">,</span> <span class="mi">1</span><span class="p">,</span> <span class="mi">1</span><span class="p">])</span>
<span class="o">&gt;&gt;&gt;</span> <span class="n">y_scores</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">array</span><span class="p">([</span><span class="mf">0.1</span><span class="p">,</span> <span class="mf">0.4</span><span class="p">,</span> <span class="mf">0.35</span><span class="p">,</span> <span class="mf">0.8</span><span class="p">])</span>
<span class="o">&gt;&gt;&gt;</span> <span class="n">average_precision_score</span><span class="p">(</span><span class="n">y_true</span><span class="p">,</span> <span class="n">y_scores</span><span class="p">)</span>
<span class="mf">0.83</span><span class="o">...</span>
</code></pre></div>

<h4>Notes</h4>
<p>.. versionchanged:: 0.19
  Instead of linearly interpolating between operating points, precisions
  are weighted by the change in recall since the last operating point.</p>
</details>
<h3 id="balanced_accuracy_score">balanced_accuracy_score<a class="headerlink" href="#balanced_accuracy_score" title="Permanent link">&para;</a></h3>
<details class="note" open="open"><summary>function balanced_accuracy_score</summary><div class="highlight"><pre><span></span><code><span class="k">val</span> <span class="n">balanced_accuracy_score</span> <span class="o">:</span>
  <span class="o">?</span><span class="n">sample_weight</span><span class="o">:[&gt;`</span><span class="nc">ArrayLike</span><span class="o">]</span> <span class="nn">Np</span><span class="p">.</span><span class="nn">Obj</span><span class="p">.</span><span class="n">t</span> <span class="o">-&gt;</span>
  <span class="o">?</span><span class="n">adjusted</span><span class="o">:</span><span class="kt">bool</span> <span class="o">-&gt;</span>
  <span class="n">y_true</span><span class="o">:[&gt;`</span><span class="nc">ArrayLike</span><span class="o">]</span> <span class="nn">Np</span><span class="p">.</span><span class="nn">Obj</span><span class="p">.</span><span class="n">t</span> <span class="o">-&gt;</span>
  <span class="n">y_pred</span><span class="o">:[&gt;`</span><span class="nc">ArrayLike</span><span class="o">]</span> <span class="nn">Np</span><span class="p">.</span><span class="nn">Obj</span><span class="p">.</span><span class="n">t</span> <span class="o">-&gt;</span>
  <span class="kt">unit</span> <span class="o">-&gt;</span>
  <span class="kt">float</span>
</code></pre></div>

<p>Compute the balanced accuracy</p>
<p>The balanced accuracy in binary and multiclass classification problems to
deal with imbalanced datasets. It is defined as the average of recall
obtained on each class.</p>
<p>The best value is 1 and the worst value is 0 when <code>adjusted=False</code>.</p>
<p>Read more in the :ref:<code>User Guide &lt;balanced_accuracy_score&gt;</code>.</p>
<p>.. versionadded:: 0.20</p>
<h4>Parameters</h4>
<ul>
<li>
<p><strong>y_true : 1d array-like</strong>
    Ground truth (correct) target values.</p>
</li>
<li>
<p><strong>y_pred : 1d array-like</strong>
    Estimated targets as returned by a classifier.</p>
</li>
<li>
<p><strong>sample_weight : array-like of shape (n_samples,), default=None</strong>
    Sample weights.</p>
</li>
<li>
<p><strong>adjusted : bool, default=False</strong>
    When true, the result is adjusted for chance, so that random
    performance would score 0, and perfect performance scores 1.</p>
</li>
</ul>
<h4>Returns</h4>
<ul>
<li><strong>balanced_accuracy : float</strong></li>
</ul>
<h4>See also</h4>
<p>recall_score, roc_auc_score</p>
<h4>Notes</h4>
<p>Some literature promotes alternative definitions of balanced accuracy. Our
definition is equivalent to :func:<code>accuracy_score</code> with class-balanced
sample weights, and shares desirable properties with the binary case.
See the :ref:<code>User Guide &lt;balanced_accuracy_score&gt;</code>.</p>
<h4>References</h4>
<p>.. [1] Brodersen, K.H.; Ong, C.S.; Stephan, K.E.; Buhmann, J.M. (2010).
       The balanced accuracy and its posterior distribution.
       Proceedings of the 20th International Conference on Pattern
       Recognition, 3121-24.
.. [2] John. D. Kelleher, Brian Mac Namee, Aoife D'Arcy, (2015).
       <code>Fundamentals of Machine Learning for Predictive Data Analytics:
       Algorithms, Worked Examples, and Case Studies
       &lt;https://mitpress.mit.edu/books/fundamentals-machine-learning-predictive-data-analytics&gt;</code>_.</p>
<h4>Examples</h4>
<div class="highlight"><pre><span></span><code><span class="o">&gt;&gt;&gt;</span> <span class="kn">from</span> <span class="nn">sklearn.metrics</span> <span class="kn">import</span> <span class="n">balanced_accuracy_score</span>
<span class="o">&gt;&gt;&gt;</span> <span class="n">y_true</span> <span class="o">=</span> <span class="p">[</span><span class="mi">0</span><span class="p">,</span> <span class="mi">1</span><span class="p">,</span> <span class="mi">0</span><span class="p">,</span> <span class="mi">0</span><span class="p">,</span> <span class="mi">1</span><span class="p">,</span> <span class="mi">0</span><span class="p">]</span>
<span class="o">&gt;&gt;&gt;</span> <span class="n">y_pred</span> <span class="o">=</span> <span class="p">[</span><span class="mi">0</span><span class="p">,</span> <span class="mi">1</span><span class="p">,</span> <span class="mi">0</span><span class="p">,</span> <span class="mi">0</span><span class="p">,</span> <span class="mi">0</span><span class="p">,</span> <span class="mi">1</span><span class="p">]</span>
<span class="o">&gt;&gt;&gt;</span> <span class="n">balanced_accuracy_score</span><span class="p">(</span><span class="n">y_true</span><span class="p">,</span> <span class="n">y_pred</span><span class="p">)</span>
<span class="mf">0.625</span>
</code></pre></div>

</details>
<h3 id="brier_score_loss">brier_score_loss<a class="headerlink" href="#brier_score_loss" title="Permanent link">&para;</a></h3>
<details class="note" open="open"><summary>function brier_score_loss</summary><div class="highlight"><pre><span></span><code><span class="k">val</span> <span class="n">brier_score_loss</span> <span class="o">:</span>
  <span class="o">?</span><span class="n">sample_weight</span><span class="o">:[&gt;`</span><span class="nc">ArrayLike</span><span class="o">]</span> <span class="nn">Np</span><span class="p">.</span><span class="nn">Obj</span><span class="p">.</span><span class="n">t</span> <span class="o">-&gt;</span>
  <span class="o">?</span><span class="n">pos_label</span><span class="o">:[`</span><span class="nc">S</span> <span class="k">of</span> <span class="kt">string</span> <span class="o">|</span> <span class="o">`</span><span class="nc">I</span> <span class="k">of</span> <span class="kt">int</span><span class="o">]</span> <span class="o">-&gt;</span>
  <span class="n">y_true</span><span class="o">:[&gt;`</span><span class="nc">ArrayLike</span><span class="o">]</span> <span class="nn">Np</span><span class="p">.</span><span class="nn">Obj</span><span class="p">.</span><span class="n">t</span> <span class="o">-&gt;</span>
  <span class="n">y_prob</span><span class="o">:[&gt;`</span><span class="nc">ArrayLike</span><span class="o">]</span> <span class="nn">Np</span><span class="p">.</span><span class="nn">Obj</span><span class="p">.</span><span class="n">t</span> <span class="o">-&gt;</span>
  <span class="kt">unit</span> <span class="o">-&gt;</span>
  <span class="kt">float</span>
</code></pre></div>

<p>Compute the Brier score.</p>
<p>The smaller the Brier score, the better, hence the naming with 'loss'.
Across all items in a set N predictions, the Brier score measures the
mean squared difference between (1) the predicted probability assigned
to the possible outcomes for item i, and (2) the actual outcome.
Therefore, the lower the Brier score is for a set of predictions, the
better the predictions are calibrated. Note that the Brier score always
takes on a value between zero and one, since this is the largest
possible difference between a predicted probability (which must be
between zero and one) and the actual outcome (which can take on values
of only 0 and 1). The Brier loss is composed of refinement loss and
calibration loss.
The Brier score is appropriate for binary and categorical outcomes that
can be structured as true or false, but is inappropriate for ordinal
variables which can take on three or more values (this is because the
Brier score assumes that all possible outcomes are equivalently
'distant' from one another). Which label is considered to be the positive
label is controlled via the parameter pos_label, which defaults to 1.
Read more in the :ref:<code>User Guide &lt;calibration&gt;</code>.</p>
<h4>Parameters</h4>
<ul>
<li>
<p><strong>y_true : array, shape (n_samples,)</strong>
    True targets.</p>
</li>
<li>
<p><strong>y_prob : array, shape (n_samples,)</strong>
    Probabilities of the positive class.</p>
</li>
<li>
<p><strong>sample_weight : array-like of shape (n_samples,), default=None</strong>
    Sample weights.</p>
</li>
<li>
<p><strong>pos_label : int or str, default=None</strong>
    Label of the positive class.
    Defaults to the greater label unless y_true is all 0 or all -1
    in which case pos_label defaults to 1.</p>
</li>
</ul>
<h4>Returns</h4>
<ul>
<li><strong>score : float</strong>
    Brier score</li>
</ul>
<h4>Examples</h4>
<div class="highlight"><pre><span></span><code><span class="o">&gt;&gt;&gt;</span> <span class="kn">import</span> <span class="nn">numpy</span> <span class="k">as</span> <span class="nn">np</span>
<span class="o">&gt;&gt;&gt;</span> <span class="kn">from</span> <span class="nn">sklearn.metrics</span> <span class="kn">import</span> <span class="n">brier_score_loss</span>
<span class="o">&gt;&gt;&gt;</span> <span class="n">y_true</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">array</span><span class="p">([</span><span class="mi">0</span><span class="p">,</span> <span class="mi">1</span><span class="p">,</span> <span class="mi">1</span><span class="p">,</span> <span class="mi">0</span><span class="p">])</span>
<span class="o">&gt;&gt;&gt;</span> <span class="n">y_true_categorical</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">array</span><span class="p">([</span><span class="s1">&#39;spam&#39;</span><span class="p">,</span> <span class="s1">&#39;ham&#39;</span><span class="p">,</span> <span class="s1">&#39;ham&#39;</span><span class="p">,</span> <span class="s1">&#39;spam&#39;</span><span class="p">])</span>
<span class="o">&gt;&gt;&gt;</span> <span class="n">y_prob</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">array</span><span class="p">([</span><span class="mf">0.1</span><span class="p">,</span> <span class="mf">0.9</span><span class="p">,</span> <span class="mf">0.8</span><span class="p">,</span> <span class="mf">0.3</span><span class="p">])</span>
<span class="o">&gt;&gt;&gt;</span> <span class="n">brier_score_loss</span><span class="p">(</span><span class="n">y_true</span><span class="p">,</span> <span class="n">y_prob</span><span class="p">)</span>
<span class="mf">0.037</span><span class="o">...</span>
<span class="o">&gt;&gt;&gt;</span> <span class="n">brier_score_loss</span><span class="p">(</span><span class="n">y_true</span><span class="p">,</span> <span class="mi">1</span><span class="o">-</span><span class="n">y_prob</span><span class="p">,</span> <span class="n">pos_label</span><span class="o">=</span><span class="mi">0</span><span class="p">)</span>
<span class="mf">0.037</span><span class="o">...</span>
<span class="o">&gt;&gt;&gt;</span> <span class="n">brier_score_loss</span><span class="p">(</span><span class="n">y_true_categorical</span><span class="p">,</span> <span class="n">y_prob</span><span class="p">,</span> <span class="n">pos_label</span><span class="o">=</span><span class="s1">&#39;ham&#39;</span><span class="p">)</span>
<span class="mf">0.037</span><span class="o">...</span>
<span class="o">&gt;&gt;&gt;</span> <span class="n">brier_score_loss</span><span class="p">(</span><span class="n">y_true</span><span class="p">,</span> <span class="n">np</span><span class="o">.</span><span class="n">array</span><span class="p">(</span><span class="n">y_prob</span><span class="p">)</span> <span class="o">&gt;</span> <span class="mf">0.5</span><span class="p">)</span>
<span class="mf">0.0</span>
</code></pre></div>

<h4>References</h4>
<p>.. [1] <code>Wikipedia entry for the Brier score.
        &lt;https://en.wikipedia.org/wiki/Brier_score&gt;</code>_</p>
</details>
<h3 id="calinski_harabasz_score_1">calinski_harabasz_score<a class="headerlink" href="#calinski_harabasz_score_1" title="Permanent link">&para;</a></h3>
<details class="note" open="open"><summary>function calinski_harabasz_score</summary><div class="highlight"><pre><span></span><code><span class="k">val</span> <span class="n">calinski_harabasz_score</span> <span class="o">:</span>
  <span class="n">x</span><span class="o">:[&gt;`</span><span class="nc">ArrayLike</span><span class="o">]</span> <span class="nn">Np</span><span class="p">.</span><span class="nn">Obj</span><span class="p">.</span><span class="n">t</span> <span class="o">-&gt;</span>
  <span class="n">labels</span><span class="o">:[&gt;`</span><span class="nc">ArrayLike</span><span class="o">]</span> <span class="nn">Np</span><span class="p">.</span><span class="nn">Obj</span><span class="p">.</span><span class="n">t</span> <span class="o">-&gt;</span>
  <span class="kt">unit</span> <span class="o">-&gt;</span>
  <span class="kt">float</span>
</code></pre></div>

<p>Compute the Calinski and Harabasz score.</p>
<p>It is also known as the Variance Ratio Criterion.</p>
<p>The score is defined as ratio between the within-cluster dispersion and
the between-cluster dispersion.</p>
<p>Read more in the :ref:<code>User Guide &lt;calinski_harabasz_index&gt;</code>.</p>
<h4>Parameters</h4>
<ul>
<li>
<p><strong>X : array-like, shape (<code>n_samples</code>, <code>n_features</code>)</strong>
    List of <code>n_features</code>-dimensional data points. Each row corresponds
    to a single data point.</p>
</li>
<li>
<p><strong>labels : array-like, shape (<code>n_samples</code>,)</strong>
    Predicted labels for each sample.</p>
</li>
</ul>
<h4>Returns</h4>
<ul>
<li><strong>score : float</strong>
    The resulting Calinski-Harabasz score.</li>
</ul>
<h4>References</h4>
<p>.. [1] <code>T. Calinski and J. Harabasz, 1974. 'A dendrite method for cluster
   analysis'. Communications in Statistics
   &lt;https://www.tandfonline.com/doi/abs/10.1080/03610927408827101&gt;</code>_</p>
</details>
<h3 id="check_scoring">check_scoring<a class="headerlink" href="#check_scoring" title="Permanent link">&para;</a></h3>
<details class="note" open="open"><summary>function check_scoring</summary><div class="highlight"><pre><span></span><code><span class="k">val</span> <span class="n">check_scoring</span> <span class="o">:</span>
  <span class="o">?</span><span class="n">scoring</span><span class="o">:[`</span><span class="nc">Score</span> <span class="k">of</span> <span class="o">[`</span><span class="nc">Explained_variance</span> <span class="o">|</span> <span class="o">`</span><span class="nc">R2</span> <span class="o">|</span> <span class="o">`</span><span class="nc">Max_error</span> <span class="o">|</span> <span class="o">`</span><span class="nc">Neg_median_absolute_error</span> <span class="o">|</span> <span class="o">`</span><span class="nc">Neg_mean_absolute_error</span> <span class="o">|</span> <span class="o">`</span><span class="nc">Neg_mean_squared_error</span> <span class="o">|</span> <span class="o">`</span><span class="nc">Neg_mean_squared_log_error</span> <span class="o">|</span> <span class="o">`</span><span class="nc">Neg_root_mean_squared_error</span> <span class="o">|</span> <span class="o">`</span><span class="nc">Neg_mean_poisson_deviance</span> <span class="o">|</span> <span class="o">`</span><span class="nc">Neg_mean_gamma_deviance</span> <span class="o">|</span> <span class="o">`</span><span class="nc">Accuracy</span> <span class="o">|</span> <span class="o">`</span><span class="nc">Roc_auc</span> <span class="o">|</span> <span class="o">`</span><span class="nc">Roc_auc_ovr</span> <span class="o">|</span> <span class="o">`</span><span class="nc">Roc_auc_ovo</span> <span class="o">|</span> <span class="o">`</span><span class="nc">Roc_auc_ovr_weighted</span> <span class="o">|</span> <span class="o">`</span><span class="nc">Roc_auc_ovo_weighted</span> <span class="o">|</span> <span class="o">`</span><span class="nc">Balanced_accuracy</span> <span class="o">|</span> <span class="o">`</span><span class="nc">Average_precision</span> <span class="o">|</span> <span class="o">`</span><span class="nc">Neg_log_loss</span> <span class="o">|</span> <span class="o">`</span><span class="nc">Neg_brier_score</span> <span class="o">|</span> <span class="o">`</span><span class="nc">Adjusted_rand_score</span> <span class="o">|</span> <span class="o">`</span><span class="nc">Homogeneity_score</span> <span class="o">|</span> <span class="o">`</span><span class="nc">Completeness_score</span> <span class="o">|</span> <span class="o">`</span><span class="nc">V_measure_score</span> <span class="o">|</span> <span class="o">`</span><span class="nc">Mutual_info_score</span> <span class="o">|</span> <span class="o">`</span><span class="nc">Adjusted_mutual_info_score</span> <span class="o">|</span> <span class="o">`</span><span class="nc">Normalized_mutual_info_score</span> <span class="o">|</span> <span class="o">`</span><span class="nc">Fowlkes_mallows_score</span> <span class="o">|</span> <span class="o">`</span><span class="nc">Precision</span> <span class="o">|</span> <span class="o">`</span><span class="nc">Precision_macro</span> <span class="o">|</span> <span class="o">`</span><span class="nc">Precision_micro</span> <span class="o">|</span> <span class="o">`</span><span class="nc">Precision_samples</span> <span class="o">|</span> <span class="o">`</span><span class="nc">Precision_weighted</span> <span class="o">|</span> <span class="o">`</span><span class="nc">Recall</span> <span class="o">|</span> <span class="o">`</span><span class="nc">Recall_macro</span> <span class="o">|</span> <span class="o">`</span><span class="nc">Recall_micro</span> <span class="o">|</span> <span class="o">`</span><span class="nc">Recall_samples</span> <span class="o">|</span> <span class="o">`</span><span class="nc">Recall_weighted</span> <span class="o">|</span> <span class="o">`</span><span class="nc">F1</span> <span class="o">|</span> <span class="o">`</span><span class="nc">F1_macro</span> <span class="o">|</span> <span class="o">`</span><span class="nc">F1_micro</span> <span class="o">|</span> <span class="o">`</span><span class="nc">F1_samples</span> <span class="o">|</span> <span class="o">`</span><span class="nc">F1_weighted</span> <span class="o">|</span> <span class="o">`</span><span class="nc">Jaccard</span> <span class="o">|</span> <span class="o">`</span><span class="nc">Jaccard_macro</span> <span class="o">|</span> <span class="o">`</span><span class="nc">Jaccard_micro</span> <span class="o">|</span> <span class="o">`</span><span class="nc">Jaccard_samples</span> <span class="o">|</span> <span class="o">`</span><span class="nc">Jaccard_weighted</span><span class="o">]</span> <span class="o">|</span> <span class="o">`</span><span class="nc">Callable</span> <span class="k">of</span> <span class="nn">Py</span><span class="p">.</span><span class="nn">Object</span><span class="p">.</span><span class="n">t</span><span class="o">]</span> <span class="o">-&gt;</span>
  <span class="o">?</span><span class="n">allow_none</span><span class="o">:</span><span class="kt">bool</span> <span class="o">-&gt;</span>
  <span class="n">estimator</span><span class="o">:[&gt;`</span><span class="nc">BaseEstimator</span><span class="o">]</span> <span class="nn">Np</span><span class="p">.</span><span class="nn">Obj</span><span class="p">.</span><span class="n">t</span> <span class="o">-&gt;</span>
  <span class="kt">unit</span> <span class="o">-&gt;</span>
  <span class="nn">Py</span><span class="p">.</span><span class="nn">Object</span><span class="p">.</span><span class="n">t</span>
</code></pre></div>

<p>Determine scorer from user options.</p>
<p>A TypeError will be thrown if the estimator cannot be scored.</p>
<h4>Parameters</h4>
<ul>
<li>
<p><strong>estimator : estimator object implementing 'fit'</strong>
    The object to use to fit the data.</p>
</li>
<li>
<p><strong>scoring : string, callable or None, optional, default: None</strong>
    A string (see model evaluation documentation) or
    a scorer callable object / function with signature
    <code>scorer(estimator, X, y)</code>.</p>
</li>
<li>
<p><strong>allow_none : boolean, optional, default: False</strong>
    If no scoring is specified and the estimator has no score function, we
    can either return None or raise an exception.</p>
</li>
</ul>
<h4>Returns</h4>
<ul>
<li><strong>scoring : callable</strong>
    A scorer callable object / function with signature
    <code>scorer(estimator, X, y)</code>.</li>
</ul>
</details>
<h3 id="classification_report">classification_report<a class="headerlink" href="#classification_report" title="Permanent link">&para;</a></h3>
<details class="note" open="open"><summary>function classification_report</summary><div class="highlight"><pre><span></span><code><span class="k">val</span> <span class="n">classification_report</span> <span class="o">:</span>
  <span class="o">?</span><span class="n">labels</span><span class="o">:[&gt;`</span><span class="nc">ArrayLike</span><span class="o">]</span> <span class="nn">Np</span><span class="p">.</span><span class="nn">Obj</span><span class="p">.</span><span class="n">t</span> <span class="o">-&gt;</span>
  <span class="o">?</span><span class="n">target_names</span><span class="o">:[&gt;`</span><span class="nc">ArrayLike</span><span class="o">]</span> <span class="nn">Np</span><span class="p">.</span><span class="nn">Obj</span><span class="p">.</span><span class="n">t</span> <span class="o">-&gt;</span>
  <span class="o">?</span><span class="n">sample_weight</span><span class="o">:[&gt;`</span><span class="nc">ArrayLike</span><span class="o">]</span> <span class="nn">Np</span><span class="p">.</span><span class="nn">Obj</span><span class="p">.</span><span class="n">t</span> <span class="o">-&gt;</span>
  <span class="o">?</span><span class="n">digits</span><span class="o">:</span><span class="kt">int</span> <span class="o">-&gt;</span>
  <span class="o">?</span><span class="n">output_dict</span><span class="o">:</span><span class="kt">bool</span> <span class="o">-&gt;</span>
  <span class="o">?</span><span class="n">zero_division</span><span class="o">:[`</span><span class="nc">Warn</span> <span class="o">|</span> <span class="o">`</span><span class="nc">Zero</span> <span class="o">|</span> <span class="o">`</span><span class="nc">One</span><span class="o">]</span> <span class="o">-&gt;</span>
  <span class="n">y_true</span><span class="o">:[&gt;`</span><span class="nc">ArrayLike</span><span class="o">]</span> <span class="nn">Np</span><span class="p">.</span><span class="nn">Obj</span><span class="p">.</span><span class="n">t</span> <span class="o">-&gt;</span>
  <span class="n">y_pred</span><span class="o">:[&gt;`</span><span class="nc">ArrayLike</span><span class="o">]</span> <span class="nn">Np</span><span class="p">.</span><span class="nn">Obj</span><span class="p">.</span><span class="n">t</span> <span class="o">-&gt;</span>
  <span class="kt">unit</span> <span class="o">-&gt;</span>
  <span class="o">[`</span><span class="nc">S</span> <span class="k">of</span> <span class="kt">string</span> <span class="o">|</span> <span class="o">`</span><span class="nc">Dict</span> <span class="k">of</span> <span class="o">(</span><span class="kt">string</span> <span class="o">*</span> <span class="o">&lt;</span><span class="n">precision</span><span class="o">:</span><span class="kt">float</span><span class="o">;</span> <span class="n">recall</span><span class="o">:</span><span class="kt">float</span><span class="o">;</span> <span class="n">f1_score</span><span class="o">:</span><span class="kt">float</span><span class="o">;</span> <span class="n">support</span><span class="o">:</span><span class="kt">float</span><span class="o">&gt;)</span> <span class="kt">list</span><span class="o">]</span>
</code></pre></div>

<p>Build a text report showing the main classification metrics.</p>
<p>Read more in the :ref:<code>User Guide &lt;classification_report&gt;</code>.</p>
<h4>Parameters</h4>
<ul>
<li>
<p><strong>y_true : 1d array-like, or label indicator array / sparse matrix</strong>
    Ground truth (correct) target values.</p>
</li>
<li>
<p><strong>y_pred : 1d array-like, or label indicator array / sparse matrix</strong>
    Estimated targets as returned by a classifier.</p>
</li>
<li>
<p><strong>labels : array, shape = [n_labels]</strong>
    Optional list of label indices to include in the report.</p>
</li>
<li>
<p><strong>target_names : list of strings</strong>
    Optional display names matching the labels (same order).</p>
</li>
<li>
<p><strong>sample_weight : array-like of shape (n_samples,), default=None</strong>
    Sample weights.</p>
</li>
<li>
<p><strong>digits : int</strong>
    Number of digits for formatting output floating point values.
    When <code>output_dict</code> is <code>True</code>, this will be ignored and the
    returned values will not be rounded.</p>
</li>
<li>
<p><strong>output_dict : bool (default = False)</strong>
    If True, return output as dict</p>
<p>.. versionadded:: 0.20</p>
</li>
<li>
<p><strong>zero_division : 'warn', 0 or 1, default='warn'</strong>
    Sets the value to return when there is a zero division. If set to
    'warn', this acts as 0, but warnings are also raised.</p>
</li>
</ul>
<h4>Returns</h4>
<ul>
<li>
<p><strong>report : string / dict</strong>
    Text summary of the precision, recall, F1 score for each class.
    Dictionary returned if output_dict is True. Dictionary has the
    following structure::</p>
<div class="codehilite"><pre><span></span><code>{&#39;label 1&#39;: {&#39;precision&#39;:0.5,
             &#39;recall&#39;:1.0,
             &#39;f1-score&#39;:0.67,
             &#39;support&#39;:1},
 &#39;label 2&#39;: { ... },
  ...
}
</code></pre></div>


<p>The reported averages include macro average (averaging the unweighted
mean per label), weighted average (averaging the support-weighted mean
per label), and sample average (only for multilabel classification).
Micro average (averaging the total true positives, false negatives and
false positives) is only shown for multi-label or multi-class
with a subset of classes, because it corresponds to accuracy otherwise.
See also :func:<code>precision_recall_fscore_support</code> for more details
on averages.</p>
<p>Note that in binary classification, recall of the positive class
is also known as 'sensitivity'; recall of the negative class is
'specificity'.</p>
</li>
</ul>
<h4>See also</h4>
<p>precision_recall_fscore_support, confusion_matrix,
multilabel_confusion_matrix</p>
<h4>Examples</h4>
<div class="highlight"><pre><span></span><code><span class="o">&gt;&gt;&gt;</span> <span class="kn">from</span> <span class="nn">sklearn.metrics</span> <span class="kn">import</span> <span class="n">classification_report</span>
<span class="o">&gt;&gt;&gt;</span> <span class="n">y_true</span> <span class="o">=</span> <span class="p">[</span><span class="mi">0</span><span class="p">,</span> <span class="mi">1</span><span class="p">,</span> <span class="mi">2</span><span class="p">,</span> <span class="mi">2</span><span class="p">,</span> <span class="mi">2</span><span class="p">]</span>
<span class="o">&gt;&gt;&gt;</span> <span class="n">y_pred</span> <span class="o">=</span> <span class="p">[</span><span class="mi">0</span><span class="p">,</span> <span class="mi">0</span><span class="p">,</span> <span class="mi">2</span><span class="p">,</span> <span class="mi">2</span><span class="p">,</span> <span class="mi">1</span><span class="p">]</span>
<span class="o">&gt;&gt;&gt;</span> <span class="n">target_names</span> <span class="o">=</span> <span class="p">[</span><span class="s1">&#39;class 0&#39;</span><span class="p">,</span> <span class="s1">&#39;class 1&#39;</span><span class="p">,</span> <span class="s1">&#39;class 2&#39;</span><span class="p">]</span>
<span class="o">&gt;&gt;&gt;</span> <span class="nb">print</span><span class="p">(</span><span class="n">classification_report</span><span class="p">(</span><span class="n">y_true</span><span class="p">,</span> <span class="n">y_pred</span><span class="p">,</span> <span class="n">target_names</span><span class="o">=</span><span class="n">target_names</span><span class="p">))</span>
              <span class="n">precision</span>    <span class="n">recall</span>  <span class="n">f1</span><span class="o">-</span><span class="n">score</span>   <span class="n">support</span>
<span class="o">&lt;</span><span class="n">BLANKLINE</span><span class="o">&gt;</span>
     <span class="k">class</span> <span class="err">0       0.50      1.00      0.67         1</span>
     <span class="k">class</span> <span class="err">1       0.00      0.00      0.00         1</span>
     <span class="k">class</span> <span class="err">2       1.00      0.67      0.80         3</span>
<span class="o">&lt;</span><span class="n">BLANKLINE</span><span class="o">&gt;</span>
    <span class="n">accuracy</span>                           <span class="mf">0.60</span>         <span class="mi">5</span>
   <span class="n">macro</span> <span class="n">avg</span>       <span class="mf">0.50</span>      <span class="mf">0.56</span>      <span class="mf">0.49</span>         <span class="mi">5</span>
<span class="n">weighted</span> <span class="n">avg</span>       <span class="mf">0.70</span>      <span class="mf">0.60</span>      <span class="mf">0.61</span>         <span class="mi">5</span>
<span class="o">&lt;</span><span class="n">BLANKLINE</span><span class="o">&gt;</span>
<span class="o">&gt;&gt;&gt;</span> <span class="n">y_pred</span> <span class="o">=</span> <span class="p">[</span><span class="mi">1</span><span class="p">,</span> <span class="mi">1</span><span class="p">,</span> <span class="mi">0</span><span class="p">]</span>
<span class="o">&gt;&gt;&gt;</span> <span class="n">y_true</span> <span class="o">=</span> <span class="p">[</span><span class="mi">1</span><span class="p">,</span> <span class="mi">1</span><span class="p">,</span> <span class="mi">1</span><span class="p">]</span>
<span class="o">&gt;&gt;&gt;</span> <span class="nb">print</span><span class="p">(</span><span class="n">classification_report</span><span class="p">(</span><span class="n">y_true</span><span class="p">,</span> <span class="n">y_pred</span><span class="p">,</span> <span class="n">labels</span><span class="o">=</span><span class="p">[</span><span class="mi">1</span><span class="p">,</span> <span class="mi">2</span><span class="p">,</span> <span class="mi">3</span><span class="p">]))</span>
              <span class="n">precision</span>    <span class="n">recall</span>  <span class="n">f1</span><span class="o">-</span><span class="n">score</span>   <span class="n">support</span>
<span class="o">&lt;</span><span class="n">BLANKLINE</span><span class="o">&gt;</span>
           <span class="mi">1</span>       <span class="mf">1.00</span>      <span class="mf">0.67</span>      <span class="mf">0.80</span>         <span class="mi">3</span>
           <span class="mi">2</span>       <span class="mf">0.00</span>      <span class="mf">0.00</span>      <span class="mf">0.00</span>         <span class="mi">0</span>
           <span class="mi">3</span>       <span class="mf">0.00</span>      <span class="mf">0.00</span>      <span class="mf">0.00</span>         <span class="mi">0</span>
<span class="o">&lt;</span><span class="n">BLANKLINE</span><span class="o">&gt;</span>
   <span class="n">micro</span> <span class="n">avg</span>       <span class="mf">1.00</span>      <span class="mf">0.67</span>      <span class="mf">0.80</span>         <span class="mi">3</span>
   <span class="n">macro</span> <span class="n">avg</span>       <span class="mf">0.33</span>      <span class="mf">0.22</span>      <span class="mf">0.27</span>         <span class="mi">3</span>
<span class="n">weighted</span> <span class="n">avg</span>       <span class="mf">1.00</span>      <span class="mf">0.67</span>      <span class="mf">0.80</span>         <span class="mi">3</span>
<span class="o">&lt;</span><span class="n">BLANKLINE</span><span class="o">&gt;</span>
</code></pre></div>

</details>
<h3 id="cohen_kappa_score">cohen_kappa_score<a class="headerlink" href="#cohen_kappa_score" title="Permanent link">&para;</a></h3>
<details class="note" open="open"><summary>function cohen_kappa_score</summary><div class="highlight"><pre><span></span><code><span class="k">val</span> <span class="n">cohen_kappa_score</span> <span class="o">:</span>
  <span class="o">?</span><span class="n">labels</span><span class="o">:[&gt;`</span><span class="nc">ArrayLike</span><span class="o">]</span> <span class="nn">Np</span><span class="p">.</span><span class="nn">Obj</span><span class="p">.</span><span class="n">t</span> <span class="o">-&gt;</span>
  <span class="o">?</span><span class="n">weights</span><span class="o">:</span><span class="kt">string</span> <span class="o">-&gt;</span>
  <span class="o">?</span><span class="n">sample_weight</span><span class="o">:[&gt;`</span><span class="nc">ArrayLike</span><span class="o">]</span> <span class="nn">Np</span><span class="p">.</span><span class="nn">Obj</span><span class="p">.</span><span class="n">t</span> <span class="o">-&gt;</span>
  <span class="n">y1</span><span class="o">:[&gt;`</span><span class="nc">ArrayLike</span><span class="o">]</span> <span class="nn">Np</span><span class="p">.</span><span class="nn">Obj</span><span class="p">.</span><span class="n">t</span> <span class="o">-&gt;</span>
  <span class="n">y2</span><span class="o">:[&gt;`</span><span class="nc">ArrayLike</span><span class="o">]</span> <span class="nn">Np</span><span class="p">.</span><span class="nn">Obj</span><span class="p">.</span><span class="n">t</span> <span class="o">-&gt;</span>
  <span class="kt">unit</span> <span class="o">-&gt;</span>
  <span class="kt">float</span>
</code></pre></div>

<p>Cohen's kappa: a statistic that measures inter-annotator agreement.</p>
<p>This function computes Cohen's kappa [1]_, a score that expresses the level
of agreement between two annotators on a classification problem. It is
defined as</p>
<div>
<div class="MathJax_Preview">    \kappa = (p_o - p_e) / (1 - p_e)
</div>
<script type="math/tex; mode=display">    \kappa = (p_o - p_e) / (1 - p_e)
</script>
</div>
<ul>
<li><strong>where :math:<code>p_o</code> is the empirical probability of agreement on the label</strong>
assigned to any sample (the observed agreement ratio), and :math:<code>p_e</code> is
the expected agreement when both annotators assign labels randomly.
:math:<code>p_e</code> is estimated using a per-annotator empirical prior over the
class labels [2]_.</li>
</ul>
<p>Read more in the :ref:<code>User Guide &lt;cohen_kappa&gt;</code>.</p>
<h4>Parameters</h4>
<ul>
<li>
<p><strong>y1 : array, shape = [n_samples]</strong>
    Labels assigned by the first annotator.</p>
</li>
<li>
<p><strong>y2 : array, shape = [n_samples]</strong>
    Labels assigned by the second annotator. The kappa statistic is
    symmetric, so swapping <code>y1</code> and <code>y2</code> doesn't change the value.</p>
</li>
<li>
<p><strong>labels : array, shape = [n_classes], optional</strong>
    List of labels to index the matrix. This may be used to select a
    subset of labels. If None, all labels that appear at least once in
    <code>y1</code> or <code>y2</code> are used.</p>
</li>
<li>
<p><strong>weights : str, optional</strong>
    Weighting type to calculate the score. None means no weighted;
    'linear' means linear weighted; 'quadratic' means quadratic weighted.</p>
</li>
<li>
<p><strong>sample_weight : array-like of shape (n_samples,), default=None</strong>
    Sample weights.</p>
</li>
</ul>
<h4>Returns</h4>
<ul>
<li><strong>kappa : float</strong>
    The kappa statistic, which is a number between -1 and 1. The maximum
    value means complete agreement; zero or lower means chance agreement.</li>
</ul>
<h4>References</h4>
<p>.. [1] J. Cohen (1960). 'A coefficient of agreement for nominal scales'.
       Educational and Psychological Measurement 20(1):37-46.</p>
<ul>
<li><strong>doi:10.1177/001316446002000104.</strong>
.. [2] <code>R. Artstein and M. Poesio (2008). 'Inter-coder agreement for
       computational linguistics'. Computational Linguistics 34(4):555-596.
       &lt;https://www.mitpressjournals.org/doi/pdf/10.1162/coli.07-034-R2&gt;</code><em>
.. [3] <code>Wikipedia entry for the Cohen's kappa.
        &lt;https://en.wikipedia.org/wiki/Cohen%27s_kappa&gt;</code></em></li>
</ul>
</details>
<h3 id="completeness_score_1">completeness_score<a class="headerlink" href="#completeness_score_1" title="Permanent link">&para;</a></h3>
<details class="note" open="open"><summary>function completeness_score</summary><div class="highlight"><pre><span></span><code><span class="k">val</span> <span class="n">completeness_score</span> <span class="o">:</span>
  <span class="n">labels_true</span><span class="o">:[&gt;`</span><span class="nc">ArrayLike</span><span class="o">]</span> <span class="nn">Np</span><span class="p">.</span><span class="nn">Obj</span><span class="p">.</span><span class="n">t</span> <span class="o">-&gt;</span>
  <span class="n">labels_pred</span><span class="o">:[&gt;`</span><span class="nc">ArrayLike</span><span class="o">]</span> <span class="nn">Np</span><span class="p">.</span><span class="nn">Obj</span><span class="p">.</span><span class="n">t</span> <span class="o">-&gt;</span>
  <span class="kt">unit</span> <span class="o">-&gt;</span>
  <span class="kt">float</span>
</code></pre></div>

<p>Completeness metric of a cluster labeling given a ground truth.</p>
<p>A clustering result satisfies completeness if all the data points
that are members of a given class are elements of the same cluster.</p>
<p>This metric is independent of the absolute values of the labels:
a permutation of the class or cluster label values won't change the
score value in any way.</p>
<p>This metric is not symmetric: switching <code>label_true</code> with <code>label_pred</code>
will return the :func:<code>homogeneity_score</code> which will be different in
general.</p>
<p>Read more in the :ref:<code>User Guide &lt;homogeneity_completeness&gt;</code>.</p>
<h4>Parameters</h4>
<ul>
<li>
<p><strong>labels_true : int array, shape = [n_samples]</strong>
    ground truth class labels to be used as a reference</p>
</li>
<li>
<p><strong>labels_pred : array-like of shape (n_samples,)</strong>
    cluster labels to evaluate</p>
</li>
</ul>
<h4>Returns</h4>
<ul>
<li><strong>completeness : float</strong>
   score between 0.0 and 1.0. 1.0 stands for perfectly complete labeling</li>
</ul>
<h4>References</h4>
<p>.. [1] <code>Andrew Rosenberg and Julia Hirschberg, 2007. V-Measure: A
   conditional entropy-based external cluster evaluation measure
   &lt;https://aclweb.org/anthology/D/D07/D07-1043.pdf&gt;</code>_</p>
<h4>See also</h4>
<p>homogeneity_score
v_measure_score</p>
<h4>Examples</h4>
<p>Perfect labelings are complete::</p>
<blockquote>
<blockquote>
<blockquote>
<p>from sklearn.metrics.cluster import completeness_score
completeness_score([0, 0, 1, 1], [1, 1, 0, 0])
  1.0</p>
</blockquote>
</blockquote>
</blockquote>
<p>Non-perfect labelings that assign all classes members to the same clusters
are still complete::</p>
<blockquote>
<blockquote>
<blockquote>
<p>print(completeness_score([0, 0, 1, 1], [0, 0, 0, 0]))
  1.0
print(completeness_score([0, 1, 2, 3], [0, 0, 1, 1]))
  0.999...</p>
</blockquote>
</blockquote>
</blockquote>
<p>If classes members are split across different clusters, the
assignment cannot be complete::</p>
<blockquote>
<blockquote>
<blockquote>
<p>print(completeness_score([0, 0, 1, 1], [0, 1, 0, 1]))
  0.0
print(completeness_score([0, 0, 0, 0], [0, 1, 2, 3]))
  0.0</p>
</blockquote>
</blockquote>
</blockquote>
</details>
<h3 id="confusion_matrix">confusion_matrix<a class="headerlink" href="#confusion_matrix" title="Permanent link">&para;</a></h3>
<details class="note" open="open"><summary>function confusion_matrix</summary><div class="highlight"><pre><span></span><code><span class="k">val</span> <span class="n">confusion_matrix</span> <span class="o">:</span>
  <span class="o">?</span><span class="n">labels</span><span class="o">:[&gt;`</span><span class="nc">ArrayLike</span><span class="o">]</span> <span class="nn">Np</span><span class="p">.</span><span class="nn">Obj</span><span class="p">.</span><span class="n">t</span> <span class="o">-&gt;</span>
  <span class="o">?</span><span class="n">sample_weight</span><span class="o">:[&gt;`</span><span class="nc">ArrayLike</span><span class="o">]</span> <span class="nn">Np</span><span class="p">.</span><span class="nn">Obj</span><span class="p">.</span><span class="n">t</span> <span class="o">-&gt;</span>
  <span class="o">?</span><span class="n">normalize</span><span class="o">:[`</span><span class="nc">All</span> <span class="o">|</span> <span class="o">`</span><span class="nc">Pred</span> <span class="o">|</span> <span class="o">`</span><span class="nc">True</span><span class="o">]</span> <span class="o">-&gt;</span>
  <span class="n">y_true</span><span class="o">:[&gt;`</span><span class="nc">ArrayLike</span><span class="o">]</span> <span class="nn">Np</span><span class="p">.</span><span class="nn">Obj</span><span class="p">.</span><span class="n">t</span> <span class="o">-&gt;</span>
  <span class="n">y_pred</span><span class="o">:[&gt;`</span><span class="nc">ArrayLike</span><span class="o">]</span> <span class="nn">Np</span><span class="p">.</span><span class="nn">Obj</span><span class="p">.</span><span class="n">t</span> <span class="o">-&gt;</span>
  <span class="kt">unit</span> <span class="o">-&gt;</span>
  <span class="o">[&gt;`</span><span class="nc">ArrayLike</span><span class="o">]</span> <span class="nn">Np</span><span class="p">.</span><span class="nn">Obj</span><span class="p">.</span><span class="n">t</span>
</code></pre></div>

<p>Compute confusion matrix to evaluate the accuracy of a classification.</p>
<p>By definition a confusion matrix :math:<code>C</code> is such that :math:<code>C_{i, j}</code>
is equal to the number of observations known to be in group :math:<code>i</code> and
predicted to be in group :math:<code>j</code>.</p>
<p>Thus in binary classification, the count of true negatives is
:math:<code>C_{0,0}</code>, false negatives is :math:<code>C_{1,0}</code>, true positives is
:math:<code>C_{1,1}</code> and false positives is :math:<code>C_{0,1}</code>.</p>
<p>Read more in the :ref:<code>User Guide &lt;confusion_matrix&gt;</code>.</p>
<h4>Parameters</h4>
<ul>
<li>
<p><strong>y_true : array-like of shape (n_samples,)</strong>
    Ground truth (correct) target values.</p>
</li>
<li>
<p><strong>y_pred : array-like of shape (n_samples,)</strong>
    Estimated targets as returned by a classifier.</p>
</li>
<li>
<p><strong>labels : array-like of shape (n_classes), default=None</strong>
    List of labels to index the matrix. This may be used to reorder
    or select a subset of labels.
    If <code>None</code> is given, those that appear at least once
    in <code>y_true</code> or <code>y_pred</code> are used in sorted order.</p>
</li>
<li>
<p><strong>sample_weight : array-like of shape (n_samples,), default=None</strong>
    Sample weights.</p>
<p>.. versionadded:: 0.18</p>
</li>
<li>
<p><strong>normalize : {'true', 'pred', 'all'}, default=None</strong>
    Normalizes confusion matrix over the true (rows), predicted (columns)
    conditions or all the population. If None, confusion matrix will not be
    normalized.</p>
</li>
</ul>
<h4>Returns</h4>
<ul>
<li><strong>C : ndarray of shape (n_classes, n_classes)</strong>
    Confusion matrix whose i-th row and j-th
    column entry indicates the number of
    samples with true label being i-th class
    and prediced label being j-th class.</li>
</ul>
<h4>References</h4>
<p>.. [1] <code>Wikipedia entry for the Confusion matrix
       &lt;https://en.wikipedia.org/wiki/Confusion_matrix&gt;</code>_
       (Wikipedia and other references may use a different
       convention for axes)</p>
<h4>Examples</h4>
<div class="highlight"><pre><span></span><code><span class="o">&gt;&gt;&gt;</span> <span class="kn">from</span> <span class="nn">sklearn.metrics</span> <span class="kn">import</span> <span class="n">confusion_matrix</span>
<span class="o">&gt;&gt;&gt;</span> <span class="n">y_true</span> <span class="o">=</span> <span class="p">[</span><span class="mi">2</span><span class="p">,</span> <span class="mi">0</span><span class="p">,</span> <span class="mi">2</span><span class="p">,</span> <span class="mi">2</span><span class="p">,</span> <span class="mi">0</span><span class="p">,</span> <span class="mi">1</span><span class="p">]</span>
<span class="o">&gt;&gt;&gt;</span> <span class="n">y_pred</span> <span class="o">=</span> <span class="p">[</span><span class="mi">0</span><span class="p">,</span> <span class="mi">0</span><span class="p">,</span> <span class="mi">2</span><span class="p">,</span> <span class="mi">2</span><span class="p">,</span> <span class="mi">0</span><span class="p">,</span> <span class="mi">2</span><span class="p">]</span>
<span class="o">&gt;&gt;&gt;</span> <span class="n">confusion_matrix</span><span class="p">(</span><span class="n">y_true</span><span class="p">,</span> <span class="n">y_pred</span><span class="p">)</span>
<span class="n">array</span><span class="p">([[</span><span class="mi">2</span><span class="p">,</span> <span class="mi">0</span><span class="p">,</span> <span class="mi">0</span><span class="p">],</span>
       <span class="p">[</span><span class="mi">0</span><span class="p">,</span> <span class="mi">0</span><span class="p">,</span> <span class="mi">1</span><span class="p">],</span>
       <span class="p">[</span><span class="mi">1</span><span class="p">,</span> <span class="mi">0</span><span class="p">,</span> <span class="mi">2</span><span class="p">]])</span>
</code></pre></div>

<div class="highlight"><pre><span></span><code><span class="o">&gt;&gt;&gt;</span> <span class="n">y_true</span> <span class="o">=</span> <span class="p">[</span><span class="s1">&#39;cat&#39;</span><span class="p">,</span> <span class="s1">&#39;ant&#39;</span><span class="p">,</span> <span class="s1">&#39;cat&#39;</span><span class="p">,</span> <span class="s1">&#39;cat&#39;</span><span class="p">,</span> <span class="s1">&#39;ant&#39;</span><span class="p">,</span> <span class="s1">&#39;bird&#39;</span><span class="p">]</span>
<span class="o">&gt;&gt;&gt;</span> <span class="n">y_pred</span> <span class="o">=</span> <span class="p">[</span><span class="s1">&#39;ant&#39;</span><span class="p">,</span> <span class="s1">&#39;ant&#39;</span><span class="p">,</span> <span class="s1">&#39;cat&#39;</span><span class="p">,</span> <span class="s1">&#39;cat&#39;</span><span class="p">,</span> <span class="s1">&#39;ant&#39;</span><span class="p">,</span> <span class="s1">&#39;cat&#39;</span><span class="p">]</span>
<span class="o">&gt;&gt;&gt;</span> <span class="n">confusion_matrix</span><span class="p">(</span><span class="n">y_true</span><span class="p">,</span> <span class="n">y_pred</span><span class="p">,</span> <span class="n">labels</span><span class="o">=</span><span class="p">[</span><span class="s1">&#39;ant&#39;</span><span class="p">,</span> <span class="s1">&#39;bird&#39;</span><span class="p">,</span> <span class="s1">&#39;cat&#39;</span><span class="p">])</span>
<span class="n">array</span><span class="p">([[</span><span class="mi">2</span><span class="p">,</span> <span class="mi">0</span><span class="p">,</span> <span class="mi">0</span><span class="p">],</span>
       <span class="p">[</span><span class="mi">0</span><span class="p">,</span> <span class="mi">0</span><span class="p">,</span> <span class="mi">1</span><span class="p">],</span>
       <span class="p">[</span><span class="mi">1</span><span class="p">,</span> <span class="mi">0</span><span class="p">,</span> <span class="mi">2</span><span class="p">]])</span>
</code></pre></div>

<p>In the binary case, we can extract true positives, etc as follows:</p>
<div class="highlight"><pre><span></span><code><span class="o">&gt;&gt;&gt;</span> <span class="n">tn</span><span class="p">,</span> <span class="n">fp</span><span class="p">,</span> <span class="n">fn</span><span class="p">,</span> <span class="n">tp</span> <span class="o">=</span> <span class="n">confusion_matrix</span><span class="p">([</span><span class="mi">0</span><span class="p">,</span> <span class="mi">1</span><span class="p">,</span> <span class="mi">0</span><span class="p">,</span> <span class="mi">1</span><span class="p">],</span> <span class="p">[</span><span class="mi">1</span><span class="p">,</span> <span class="mi">1</span><span class="p">,</span> <span class="mi">1</span><span class="p">,</span> <span class="mi">0</span><span class="p">])</span><span class="o">.</span><span class="n">ravel</span><span class="p">()</span>
<span class="o">&gt;&gt;&gt;</span> <span class="p">(</span><span class="n">tn</span><span class="p">,</span> <span class="n">fp</span><span class="p">,</span> <span class="n">fn</span><span class="p">,</span> <span class="n">tp</span><span class="p">)</span>
<span class="p">(</span><span class="mi">0</span><span class="p">,</span> <span class="mi">2</span><span class="p">,</span> <span class="mi">1</span><span class="p">,</span> <span class="mi">1</span><span class="p">)</span>
</code></pre></div>

</details>
<h3 id="consensus_score_1">consensus_score<a class="headerlink" href="#consensus_score_1" title="Permanent link">&para;</a></h3>
<details class="note" open="open"><summary>function consensus_score</summary><div class="highlight"><pre><span></span><code><span class="k">val</span> <span class="n">consensus_score</span> <span class="o">:</span>
  <span class="o">?</span><span class="n">similarity</span><span class="o">:[`</span><span class="nc">S</span> <span class="k">of</span> <span class="kt">string</span> <span class="o">|</span> <span class="o">`</span><span class="nc">Callable</span> <span class="k">of</span> <span class="nn">Py</span><span class="p">.</span><span class="nn">Object</span><span class="p">.</span><span class="n">t</span><span class="o">]</span> <span class="o">-&gt;</span>
  <span class="n">a</span><span class="o">:</span><span class="nn">Py</span><span class="p">.</span><span class="nn">Object</span><span class="p">.</span><span class="n">t</span> <span class="o">-&gt;</span>
  <span class="n">b</span><span class="o">:</span><span class="nn">Py</span><span class="p">.</span><span class="nn">Object</span><span class="p">.</span><span class="n">t</span> <span class="o">-&gt;</span>
  <span class="kt">unit</span> <span class="o">-&gt;</span>
  <span class="nn">Py</span><span class="p">.</span><span class="nn">Object</span><span class="p">.</span><span class="n">t</span>
</code></pre></div>

<p>The similarity of two sets of biclusters.</p>
<p>Similarity between individual biclusters is computed. Then the
best matching between sets is found using the Hungarian algorithm.
The final score is the sum of similarities divided by the size of
the larger set.</p>
<p>Read more in the :ref:<code>User Guide &lt;biclustering&gt;</code>.</p>
<h4>Parameters</h4>
<ul>
<li>
<p><strong>a : (rows, columns)</strong>
    Tuple of row and column indicators for a set of biclusters.</p>
</li>
<li>
<p><strong>b : (rows, columns)</strong>
    Another set of biclusters like <code>a</code>.</p>
</li>
<li>
<p><strong>similarity : string or function, optional, default: 'jaccard'</strong>
    May be the string 'jaccard' to use the Jaccard coefficient, or
    any function that takes four arguments, each of which is a 1d
    indicator vector: (a_rows, a_columns, b_rows, b_columns).</p>
</li>
</ul>
<h4>References</h4>
<ul>
<li>Hochreiter, Bodenhofer, et. al., 2010. <code>FABIA: factor analysis
  for bicluster acquisition
  &lt;https://www.ncbi.nlm.nih.gov/pmc/articles/PMC2881408/&gt;</code>__.</li>
</ul>
</details>
<h3 id="coverage_error">coverage_error<a class="headerlink" href="#coverage_error" title="Permanent link">&para;</a></h3>
<details class="note" open="open"><summary>function coverage_error</summary><div class="highlight"><pre><span></span><code><span class="k">val</span> <span class="n">coverage_error</span> <span class="o">:</span>
  <span class="o">?</span><span class="n">sample_weight</span><span class="o">:[&gt;`</span><span class="nc">ArrayLike</span><span class="o">]</span> <span class="nn">Np</span><span class="p">.</span><span class="nn">Obj</span><span class="p">.</span><span class="n">t</span> <span class="o">-&gt;</span>
  <span class="n">y_true</span><span class="o">:[&gt;`</span><span class="nc">ArrayLike</span><span class="o">]</span> <span class="nn">Np</span><span class="p">.</span><span class="nn">Obj</span><span class="p">.</span><span class="n">t</span> <span class="o">-&gt;</span>
  <span class="n">y_score</span><span class="o">:[&gt;`</span><span class="nc">ArrayLike</span><span class="o">]</span> <span class="nn">Np</span><span class="p">.</span><span class="nn">Obj</span><span class="p">.</span><span class="n">t</span> <span class="o">-&gt;</span>
  <span class="kt">unit</span> <span class="o">-&gt;</span>
  <span class="kt">float</span>
</code></pre></div>

<p>Coverage error measure</p>
<p>Compute how far we need to go through the ranked scores to cover all
true labels. The best value is equal to the average number
of labels in <code>y_true</code> per sample.</p>
<p>Ties in <code>y_scores</code> are broken by giving maximal rank that would have
been assigned to all tied values.</p>
<ul>
<li><strong>Note: Our implementation's score is 1 greater than the one given in</strong>
Tsoumakas et al., 2010. This extends it to handle the degenerate case
in which an instance has 0 true labels.</li>
</ul>
<p>Read more in the :ref:<code>User Guide &lt;coverage_error&gt;</code>.</p>
<h4>Parameters</h4>
<ul>
<li>
<p><strong>y_true : array, shape = [n_samples, n_labels]</strong>
    True binary labels in binary indicator format.</p>
</li>
<li>
<p><strong>y_score : array, shape = [n_samples, n_labels]</strong>
    Target scores, can either be probability estimates of the positive
    class, confidence values, or non-thresholded measure of decisions
    (as returned by 'decision_function' on some classifiers).</p>
</li>
<li>
<p><strong>sample_weight : array-like of shape (n_samples,), default=None</strong>
    Sample weights.</p>
</li>
</ul>
<h4>Returns</h4>
<ul>
<li><strong>coverage_error : float</strong></li>
</ul>
<h4>References</h4>
<p>.. [1] Tsoumakas, G., Katakis, I., &amp; Vlahavas, I. (2010).
       Mining multi-label data. In Data mining and knowledge discovery
       handbook (pp. 667-685). Springer US.</p>
</details>
<h3 id="davies_bouldin_score_1">davies_bouldin_score<a class="headerlink" href="#davies_bouldin_score_1" title="Permanent link">&para;</a></h3>
<details class="note" open="open"><summary>function davies_bouldin_score</summary><div class="highlight"><pre><span></span><code><span class="k">val</span> <span class="n">davies_bouldin_score</span> <span class="o">:</span>
  <span class="n">x</span><span class="o">:[&gt;`</span><span class="nc">ArrayLike</span><span class="o">]</span> <span class="nn">Np</span><span class="p">.</span><span class="nn">Obj</span><span class="p">.</span><span class="n">t</span> <span class="o">-&gt;</span>
  <span class="n">labels</span><span class="o">:[&gt;`</span><span class="nc">ArrayLike</span><span class="o">]</span> <span class="nn">Np</span><span class="p">.</span><span class="nn">Obj</span><span class="p">.</span><span class="n">t</span> <span class="o">-&gt;</span>
  <span class="kt">unit</span> <span class="o">-&gt;</span>
  <span class="kt">float</span>
</code></pre></div>

<p>Computes the Davies-Bouldin score.</p>
<p>The score is defined as the average similarity measure of each cluster with
its most similar cluster, where similarity is the ratio of within-cluster
distances to between-cluster distances. Thus, clusters which are farther
apart and less dispersed will result in a better score.</p>
<p>The minimum score is zero, with lower values indicating better clustering.</p>
<p>Read more in the :ref:<code>User Guide &lt;davies-bouldin_index&gt;</code>.</p>
<p>.. versionadded:: 0.20</p>
<h4>Parameters</h4>
<ul>
<li>
<p><strong>X : array-like, shape (<code>n_samples</code>, <code>n_features</code>)</strong>
    List of <code>n_features</code>-dimensional data points. Each row corresponds
    to a single data point.</p>
</li>
<li>
<p><strong>labels : array-like, shape (<code>n_samples</code>,)</strong>
    Predicted labels for each sample.</p>
</li>
</ul>
<h4>Returns</h4>
<ul>
<li><strong>score: float</strong>
    The resulting Davies-Bouldin score.</li>
</ul>
<h4>References</h4>
<p>.. [1] Davies, David L.; Bouldin, Donald W. (1979).
   <code>'A Cluster Separation Measure'
   &lt;https://ieeexplore.ieee.org/document/4766909&gt;</code>__.
   IEEE Transactions on Pattern Analysis and Machine Intelligence.
   PAMI-1 (2): 224-227</p>
</details>
<h3 id="dcg_score">dcg_score<a class="headerlink" href="#dcg_score" title="Permanent link">&para;</a></h3>
<details class="note" open="open"><summary>function dcg_score</summary><div class="highlight"><pre><span></span><code><span class="k">val</span> <span class="n">dcg_score</span> <span class="o">:</span>
  <span class="o">?</span><span class="n">k</span><span class="o">:</span><span class="kt">int</span> <span class="o">-&gt;</span>
  <span class="o">?</span><span class="n">log_base</span><span class="o">:</span><span class="kt">float</span> <span class="o">-&gt;</span>
  <span class="o">?</span><span class="n">sample_weight</span><span class="o">:[&gt;`</span><span class="nc">ArrayLike</span><span class="o">]</span> <span class="nn">Np</span><span class="p">.</span><span class="nn">Obj</span><span class="p">.</span><span class="n">t</span> <span class="o">-&gt;</span>
  <span class="o">?</span><span class="n">ignore_ties</span><span class="o">:</span><span class="kt">bool</span> <span class="o">-&gt;</span>
  <span class="n">y_true</span><span class="o">:[&gt;`</span><span class="nc">ArrayLike</span><span class="o">]</span> <span class="nn">Np</span><span class="p">.</span><span class="nn">Obj</span><span class="p">.</span><span class="n">t</span> <span class="o">-&gt;</span>
  <span class="n">y_score</span><span class="o">:[&gt;`</span><span class="nc">ArrayLike</span><span class="o">]</span> <span class="nn">Np</span><span class="p">.</span><span class="nn">Obj</span><span class="p">.</span><span class="n">t</span> <span class="o">-&gt;</span>
  <span class="kt">unit</span> <span class="o">-&gt;</span>
  <span class="kt">float</span>
</code></pre></div>

<p>Compute Discounted Cumulative Gain.</p>
<p>Sum the true scores ranked in the order induced by the predicted scores,
after applying a logarithmic discount.</p>
<p>This ranking metric yields a high value if true labels are ranked high by
<code>y_score</code>.</p>
<p>Usually the Normalized Discounted Cumulative Gain (NDCG, computed by
ndcg_score) is preferred.</p>
<h4>Parameters</h4>
<ul>
<li>
<p><strong>y_true : ndarray, shape (n_samples, n_labels)</strong>
    True targets of multilabel classification, or true scores of entities
    to be ranked.</p>
</li>
<li>
<p><strong>y_score : ndarray, shape (n_samples, n_labels)</strong>
    Target scores, can either be probability estimates, confidence values,
    or non-thresholded measure of decisions (as returned by
    'decision_function' on some classifiers).</p>
</li>
<li>
<p><strong>k : int, optional (default=None)</strong>
    Only consider the highest k scores in the ranking. If None, use all
    outputs.</p>
</li>
<li>
<p><strong>log_base : float, optional (default=2)</strong>
    Base of the logarithm used for the discount. A low value means a
    sharper discount (top results are more important).</p>
</li>
<li>
<p><strong>sample_weight : ndarray, shape (n_samples,), optional (default=None)</strong>
    Sample weights. If None, all samples are given the same weight.</p>
</li>
<li>
<p><strong>ignore_ties : bool, optional (default=False)</strong>
    Assume that there are no ties in y_score (which is likely to be the
    case if y_score is continuous) for efficiency gains.</p>
</li>
</ul>
<h4>Returns</h4>
<ul>
<li><strong>discounted_cumulative_gain : float</strong>
    The averaged sample DCG scores.</li>
</ul>
<h4>See also</h4>
<p>ndcg_score :
    The Discounted Cumulative Gain divided by the Ideal Discounted
    Cumulative Gain (the DCG obtained for a perfect ranking), in order to
    have a score between 0 and 1.</p>
<h4>References</h4>
<p><code>Wikipedia entry for Discounted Cumulative Gain
&lt;https://en.wikipedia.org/wiki/Discounted_cumulative_gain&gt;</code>_</p>
<p>Jarvelin, K., &amp; Kekalainen, J. (2002).
Cumulated gain-based evaluation of IR techniques. ACM Transactions on
Information Systems (TOIS), 20(4), 422-446.</p>
<p>Wang, Y., Wang, L., Li, Y., He, D., Chen, W., &amp; Liu, T. Y. (2013, May).
A theoretical analysis of NDCG ranking measures. In Proceedings of the 26th
Annual Conference on Learning Theory (COLT 2013)</p>
<p>McSherry, F., &amp; Najork, M. (2008, March). Computing information retrieval
performance measures efficiently in the presence of tied scores. In
European conference on information retrieval (pp. 414-421). Springer,
Berlin, Heidelberg.</p>
<h4>Examples</h4>
<div class="highlight"><pre><span></span><code><span class="o">&gt;&gt;&gt;</span> <span class="kn">from</span> <span class="nn">sklearn.metrics</span> <span class="kn">import</span> <span class="n">dcg_score</span>
<span class="o">&gt;&gt;&gt;</span> <span class="c1"># we have groud-truth relevance of some answers to a query:</span>
<span class="o">&gt;&gt;&gt;</span> <span class="n">true_relevance</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">asarray</span><span class="p">([[</span><span class="mi">10</span><span class="p">,</span> <span class="mi">0</span><span class="p">,</span> <span class="mi">0</span><span class="p">,</span> <span class="mi">1</span><span class="p">,</span> <span class="mi">5</span><span class="p">]])</span>
<span class="o">&gt;&gt;&gt;</span> <span class="c1"># we predict scores for the answers</span>
<span class="o">&gt;&gt;&gt;</span> <span class="n">scores</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">asarray</span><span class="p">([[</span><span class="o">.</span><span class="mi">1</span><span class="p">,</span> <span class="o">.</span><span class="mi">2</span><span class="p">,</span> <span class="o">.</span><span class="mi">3</span><span class="p">,</span> <span class="mi">4</span><span class="p">,</span> <span class="mi">70</span><span class="p">]])</span>
<span class="o">&gt;&gt;&gt;</span> <span class="n">dcg_score</span><span class="p">(</span><span class="n">true_relevance</span><span class="p">,</span> <span class="n">scores</span><span class="p">)</span>
<span class="mf">9.49</span><span class="o">...</span>
<span class="o">&gt;&gt;&gt;</span> <span class="c1"># we can set k to truncate the sum; only top k answers contribute</span>
<span class="o">&gt;&gt;&gt;</span> <span class="n">dcg_score</span><span class="p">(</span><span class="n">true_relevance</span><span class="p">,</span> <span class="n">scores</span><span class="p">,</span> <span class="n">k</span><span class="o">=</span><span class="mi">2</span><span class="p">)</span>
<span class="mf">5.63</span><span class="o">...</span>
<span class="o">&gt;&gt;&gt;</span> <span class="c1"># now we have some ties in our prediction</span>
<span class="o">&gt;&gt;&gt;</span> <span class="n">scores</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">asarray</span><span class="p">([[</span><span class="mi">1</span><span class="p">,</span> <span class="mi">0</span><span class="p">,</span> <span class="mi">0</span><span class="p">,</span> <span class="mi">0</span><span class="p">,</span> <span class="mi">1</span><span class="p">]])</span>
<span class="o">&gt;&gt;&gt;</span> <span class="c1"># by default ties are averaged, so here we get the average true</span>
<span class="o">&gt;&gt;&gt;</span> <span class="c1"># relevance of our top predictions: (10 + 5) / 2 = 7.5</span>
<span class="o">&gt;&gt;&gt;</span> <span class="n">dcg_score</span><span class="p">(</span><span class="n">true_relevance</span><span class="p">,</span> <span class="n">scores</span><span class="p">,</span> <span class="n">k</span><span class="o">=</span><span class="mi">1</span><span class="p">)</span>
<span class="mf">7.5</span>
<span class="o">&gt;&gt;&gt;</span> <span class="c1"># we can choose to ignore ties for faster results, but only</span>
<span class="o">&gt;&gt;&gt;</span> <span class="c1"># if we know there aren&#39;t ties in our scores, otherwise we get</span>
<span class="o">&gt;&gt;&gt;</span> <span class="c1"># wrong results:</span>
<span class="o">&gt;&gt;&gt;</span> <span class="n">dcg_score</span><span class="p">(</span><span class="n">true_relevance</span><span class="p">,</span>
<span class="o">...</span>           <span class="n">scores</span><span class="p">,</span> <span class="n">k</span><span class="o">=</span><span class="mi">1</span><span class="p">,</span> <span class="n">ignore_ties</span><span class="o">=</span><span class="kc">True</span><span class="p">)</span>
<span class="mf">5.0</span>
</code></pre></div>

</details>
<h3 id="euclidean_distances_1">euclidean_distances<a class="headerlink" href="#euclidean_distances_1" title="Permanent link">&para;</a></h3>
<details class="note" open="open"><summary>function euclidean_distances</summary><div class="highlight"><pre><span></span><code><span class="k">val</span> <span class="n">euclidean_distances</span> <span class="o">:</span>
  <span class="o">?</span><span class="n">y</span><span class="o">:[&gt;`</span><span class="nc">ArrayLike</span><span class="o">]</span> <span class="nn">Np</span><span class="p">.</span><span class="nn">Obj</span><span class="p">.</span><span class="n">t</span> <span class="o">-&gt;</span>
  <span class="o">?</span><span class="n">y_norm_squared</span><span class="o">:[&gt;`</span><span class="nc">ArrayLike</span><span class="o">]</span> <span class="nn">Np</span><span class="p">.</span><span class="nn">Obj</span><span class="p">.</span><span class="n">t</span> <span class="o">-&gt;</span>
  <span class="o">?</span><span class="n">squared</span><span class="o">:</span><span class="kt">bool</span> <span class="o">-&gt;</span>
  <span class="o">?</span><span class="n">x_norm_squared</span><span class="o">:[&gt;`</span><span class="nc">ArrayLike</span><span class="o">]</span> <span class="nn">Np</span><span class="p">.</span><span class="nn">Obj</span><span class="p">.</span><span class="n">t</span> <span class="o">-&gt;</span>
  <span class="n">x</span><span class="o">:[&gt;`</span><span class="nc">ArrayLike</span><span class="o">]</span> <span class="nn">Np</span><span class="p">.</span><span class="nn">Obj</span><span class="p">.</span><span class="n">t</span> <span class="o">-&gt;</span>
  <span class="kt">unit</span> <span class="o">-&gt;</span>
  <span class="o">[&gt;`</span><span class="nc">ArrayLike</span><span class="o">]</span> <span class="nn">Np</span><span class="p">.</span><span class="nn">Obj</span><span class="p">.</span><span class="n">t</span>
</code></pre></div>

<p>Considering the rows of X (and Y=X) as vectors, compute the
distance matrix between each pair of vectors.</p>
<p>For efficiency reasons, the euclidean distance between a pair of row
vector x and y is computed as::</p>
<div class="codehilite"><pre><span></span><code>dist(x, y) = sqrt(dot(x, x) - 2 * dot(x, y) + dot(y, y))
</code></pre></div>


<p>This formulation has two advantages over other ways of computing distances.
First, it is computationally efficient when dealing with sparse data.
Second, if one argument varies but the other remains unchanged, then
<code>dot(x, x)</code> and/or <code>dot(y, y)</code> can be pre-computed.</p>
<p>However, this is not the most precise way of doing this computation, and
the distance matrix returned by this function may not be exactly
symmetric as required by, e.g., <code>scipy.spatial.distance</code> functions.</p>
<p>Read more in the :ref:<code>User Guide &lt;metrics&gt;</code>.</p>
<h4>Parameters</h4>
<ul>
<li>
<p><strong>X : {array-like, sparse matrix}, shape (n_samples_1, n_features)</strong></p>
</li>
<li>
<p><strong>Y : {array-like, sparse matrix}, shape (n_samples_2, n_features)</strong></p>
</li>
<li>
<p><strong>Y_norm_squared : array-like, shape (n_samples_2, ), optional</strong>
    Pre-computed dot-products of vectors in Y (e.g.,
    <code>(Y**2).sum(axis=1)</code>)
    May be ignored in some cases, see the note below.</p>
</li>
<li>
<p><strong>squared : boolean, optional</strong>
    Return squared Euclidean distances.</p>
</li>
<li>
<p><strong>X_norm_squared : array-like of shape (n_samples,), optional</strong>
    Pre-computed dot-products of vectors in X (e.g.,
    <code>(X**2).sum(axis=1)</code>)
    May be ignored in some cases, see the note below.</p>
</li>
</ul>
<h4>Notes</h4>
<p>To achieve better accuracy, <code>X_norm_squared</code>and <code>Y_norm_squared</code> may be
unused if they are passed as <code>float32</code>.</p>
<h4>Returns</h4>
<ul>
<li><strong>distances : array, shape (n_samples_1, n_samples_2)</strong></li>
</ul>
<h4>Examples</h4>
<div class="highlight"><pre><span></span><code><span class="o">&gt;&gt;&gt;</span> <span class="kn">from</span> <span class="nn">sklearn.metrics.pairwise</span> <span class="kn">import</span> <span class="n">euclidean_distances</span>
<span class="o">&gt;&gt;&gt;</span> <span class="n">X</span> <span class="o">=</span> <span class="p">[[</span><span class="mi">0</span><span class="p">,</span> <span class="mi">1</span><span class="p">],</span> <span class="p">[</span><span class="mi">1</span><span class="p">,</span> <span class="mi">1</span><span class="p">]]</span>
<span class="o">&gt;&gt;&gt;</span> <span class="c1"># distance between rows of X</span>
<span class="o">&gt;&gt;&gt;</span> <span class="n">euclidean_distances</span><span class="p">(</span><span class="n">X</span><span class="p">,</span> <span class="n">X</span><span class="p">)</span>
<span class="n">array</span><span class="p">([[</span><span class="mf">0.</span><span class="p">,</span> <span class="mf">1.</span><span class="p">],</span>
       <span class="p">[</span><span class="mf">1.</span><span class="p">,</span> <span class="mf">0.</span><span class="p">]])</span>
<span class="o">&gt;&gt;&gt;</span> <span class="c1"># get distance to origin</span>
<span class="o">&gt;&gt;&gt;</span> <span class="n">euclidean_distances</span><span class="p">(</span><span class="n">X</span><span class="p">,</span> <span class="p">[[</span><span class="mi">0</span><span class="p">,</span> <span class="mi">0</span><span class="p">]])</span>
<span class="n">array</span><span class="p">([[</span><span class="mf">1.</span>        <span class="p">],</span>
       <span class="p">[</span><span class="mf">1.41421356</span><span class="p">]])</span>
</code></pre></div>

<h4>See also</h4>
<ul>
<li><strong>paired_distances : distances betweens pairs of elements of X and Y.</strong></li>
</ul>
</details>
<h3 id="explained_variance_score">explained_variance_score<a class="headerlink" href="#explained_variance_score" title="Permanent link">&para;</a></h3>
<details class="note" open="open"><summary>function explained_variance_score</summary><div class="highlight"><pre><span></span><code><span class="k">val</span> <span class="n">explained_variance_score</span> <span class="o">:</span>
  <span class="o">?</span><span class="n">sample_weight</span><span class="o">:[&gt;`</span><span class="nc">ArrayLike</span><span class="o">]</span> <span class="nn">Np</span><span class="p">.</span><span class="nn">Obj</span><span class="p">.</span><span class="n">t</span> <span class="o">-&gt;</span>
  <span class="o">?</span><span class="n">multioutput</span><span class="o">:[`</span><span class="nc">Arr</span> <span class="k">of</span> <span class="o">[&gt;`</span><span class="nc">ArrayLike</span><span class="o">]</span> <span class="nn">Np</span><span class="p">.</span><span class="nn">Obj</span><span class="p">.</span><span class="n">t</span> <span class="o">|</span> <span class="o">`</span><span class="nc">Variance_weighted</span> <span class="o">|</span> <span class="o">`</span><span class="nc">Uniform_average</span> <span class="o">|</span> <span class="o">`</span><span class="nc">Raw_values</span><span class="o">]</span> <span class="o">-&gt;</span>
  <span class="n">y_true</span><span class="o">:[&gt;`</span><span class="nc">ArrayLike</span><span class="o">]</span> <span class="nn">Np</span><span class="p">.</span><span class="nn">Obj</span><span class="p">.</span><span class="n">t</span> <span class="o">-&gt;</span>
  <span class="n">y_pred</span><span class="o">:[&gt;`</span><span class="nc">ArrayLike</span><span class="o">]</span> <span class="nn">Np</span><span class="p">.</span><span class="nn">Obj</span><span class="p">.</span><span class="n">t</span> <span class="o">-&gt;</span>
  <span class="kt">unit</span> <span class="o">-&gt;</span>
  <span class="o">[&gt;`</span><span class="nc">ArrayLike</span><span class="o">]</span> <span class="nn">Np</span><span class="p">.</span><span class="nn">Obj</span><span class="p">.</span><span class="n">t</span>
</code></pre></div>

<p>Explained variance regression score function</p>
<p>Best possible score is 1.0, lower values are worse.</p>
<p>Read more in the :ref:<code>User Guide &lt;explained_variance_score&gt;</code>.</p>
<h4>Parameters</h4>
<ul>
<li>
<p><strong>y_true : array-like of shape (n_samples,) or (n_samples, n_outputs)</strong>
    Ground truth (correct) target values.</p>
</li>
<li>
<p><strong>y_pred : array-like of shape (n_samples,) or (n_samples, n_outputs)</strong>
    Estimated target values.</p>
</li>
<li>
<p><strong>sample_weight : array-like of shape (n_samples,), optional</strong>
    Sample weights.</p>
</li>
<li>
<p><strong>multioutput : string in ['raw_values', 'uniform_average',                 'variance_weighted'] or array-like of shape (n_outputs)</strong>
    Defines aggregating of multiple output scores.
    Array-like value defines weights used to average scores.</p>
<p>'raw_values' :
    Returns a full set of scores in case of multioutput input.</p>
<p>'uniform_average' :
    Scores of all outputs are averaged with uniform weight.</p>
<p>'variance_weighted' :
    Scores of all outputs are averaged, weighted by the variances
    of each individual output.</p>
</li>
</ul>
<h4>Returns</h4>
<ul>
<li><strong>score : float or ndarray of floats</strong>
    The explained variance or ndarray if 'multioutput' is 'raw_values'.</li>
</ul>
<h4>Notes</h4>
<p>This is not a symmetric function.</p>
<h4>Examples</h4>
<div class="highlight"><pre><span></span><code><span class="o">&gt;&gt;&gt;</span> <span class="kn">from</span> <span class="nn">sklearn.metrics</span> <span class="kn">import</span> <span class="n">explained_variance_score</span>
<span class="o">&gt;&gt;&gt;</span> <span class="n">y_true</span> <span class="o">=</span> <span class="p">[</span><span class="mi">3</span><span class="p">,</span> <span class="o">-</span><span class="mf">0.5</span><span class="p">,</span> <span class="mi">2</span><span class="p">,</span> <span class="mi">7</span><span class="p">]</span>
<span class="o">&gt;&gt;&gt;</span> <span class="n">y_pred</span> <span class="o">=</span> <span class="p">[</span><span class="mf">2.5</span><span class="p">,</span> <span class="mf">0.0</span><span class="p">,</span> <span class="mi">2</span><span class="p">,</span> <span class="mi">8</span><span class="p">]</span>
<span class="o">&gt;&gt;&gt;</span> <span class="n">explained_variance_score</span><span class="p">(</span><span class="n">y_true</span><span class="p">,</span> <span class="n">y_pred</span><span class="p">)</span>
<span class="mf">0.957</span><span class="o">...</span>
<span class="o">&gt;&gt;&gt;</span> <span class="n">y_true</span> <span class="o">=</span> <span class="p">[[</span><span class="mf">0.5</span><span class="p">,</span> <span class="mi">1</span><span class="p">],</span> <span class="p">[</span><span class="o">-</span><span class="mi">1</span><span class="p">,</span> <span class="mi">1</span><span class="p">],</span> <span class="p">[</span><span class="mi">7</span><span class="p">,</span> <span class="o">-</span><span class="mi">6</span><span class="p">]]</span>
<span class="o">&gt;&gt;&gt;</span> <span class="n">y_pred</span> <span class="o">=</span> <span class="p">[[</span><span class="mi">0</span><span class="p">,</span> <span class="mi">2</span><span class="p">],</span> <span class="p">[</span><span class="o">-</span><span class="mi">1</span><span class="p">,</span> <span class="mi">2</span><span class="p">],</span> <span class="p">[</span><span class="mi">8</span><span class="p">,</span> <span class="o">-</span><span class="mi">5</span><span class="p">]]</span>
<span class="o">&gt;&gt;&gt;</span> <span class="n">explained_variance_score</span><span class="p">(</span><span class="n">y_true</span><span class="p">,</span> <span class="n">y_pred</span><span class="p">,</span> <span class="n">multioutput</span><span class="o">=</span><span class="s1">&#39;uniform_average&#39;</span><span class="p">)</span>
<span class="mf">0.983</span><span class="o">...</span>
</code></pre></div>

</details>
<h3 id="f1_score">f1_score<a class="headerlink" href="#f1_score" title="Permanent link">&para;</a></h3>
<details class="note" open="open"><summary>function f1_score</summary><div class="highlight"><pre><span></span><code><span class="k">val</span> <span class="n">f1_score</span> <span class="o">:</span>
  <span class="o">?</span><span class="n">labels</span><span class="o">:[&gt;`</span><span class="nc">ArrayLike</span><span class="o">]</span> <span class="nn">Np</span><span class="p">.</span><span class="nn">Obj</span><span class="p">.</span><span class="n">t</span> <span class="o">-&gt;</span>
  <span class="o">?</span><span class="n">pos_label</span><span class="o">:[`</span><span class="nc">S</span> <span class="k">of</span> <span class="kt">string</span> <span class="o">|</span> <span class="o">`</span><span class="nc">I</span> <span class="k">of</span> <span class="kt">int</span><span class="o">]</span> <span class="o">-&gt;</span>
  <span class="o">?</span><span class="n">average</span><span class="o">:[`</span><span class="nc">Macro</span> <span class="o">|</span> <span class="o">`</span><span class="nc">Weighted</span> <span class="o">|</span> <span class="o">`</span><span class="nc">Samples</span> <span class="o">|</span> <span class="o">`</span><span class="nc">Micro</span> <span class="o">|</span> <span class="o">`</span><span class="nc">Binary</span> <span class="o">|</span> <span class="o">`</span><span class="nc">None</span><span class="o">]</span> <span class="o">-&gt;</span>
  <span class="o">?</span><span class="n">sample_weight</span><span class="o">:[&gt;`</span><span class="nc">ArrayLike</span><span class="o">]</span> <span class="nn">Np</span><span class="p">.</span><span class="nn">Obj</span><span class="p">.</span><span class="n">t</span> <span class="o">-&gt;</span>
  <span class="o">?</span><span class="n">zero_division</span><span class="o">:[`</span><span class="nc">Warn</span> <span class="o">|</span> <span class="o">`</span><span class="nc">Zero</span> <span class="o">|</span> <span class="o">`</span><span class="nc">One</span><span class="o">]</span> <span class="o">-&gt;</span>
  <span class="n">y_true</span><span class="o">:[&gt;`</span><span class="nc">ArrayLike</span><span class="o">]</span> <span class="nn">Np</span><span class="p">.</span><span class="nn">Obj</span><span class="p">.</span><span class="n">t</span> <span class="o">-&gt;</span>
  <span class="n">y_pred</span><span class="o">:[&gt;`</span><span class="nc">ArrayLike</span><span class="o">]</span> <span class="nn">Np</span><span class="p">.</span><span class="nn">Obj</span><span class="p">.</span><span class="n">t</span> <span class="o">-&gt;</span>
  <span class="kt">unit</span> <span class="o">-&gt;</span>
  <span class="o">[&gt;`</span><span class="nc">ArrayLike</span><span class="o">]</span> <span class="nn">Np</span><span class="p">.</span><span class="nn">Obj</span><span class="p">.</span><span class="n">t</span>
</code></pre></div>

<p>Compute the F1 score, also known as balanced F-score or F-measure</p>
<p>The F1 score can be interpreted as a weighted average of the precision and
recall, where an F1 score reaches its best value at 1 and worst score at 0.
The relative contribution of precision and recall to the F1 score are
equal. The formula for the F1 score is::</p>
<div class="codehilite"><pre><span></span><code>F1 = 2 * (precision * recall) / (precision + recall)
</code></pre></div>


<p>In the multi-class and multi-label case, this is the average of
the F1 score of each class with weighting depending on the <code>average</code>
parameter.</p>
<p>Read more in the :ref:<code>User Guide &lt;precision_recall_f_measure_metrics&gt;</code>.</p>
<h4>Parameters</h4>
<ul>
<li>
<p><strong>y_true : 1d array-like, or label indicator array / sparse matrix</strong>
    Ground truth (correct) target values.</p>
</li>
<li>
<p><strong>y_pred : 1d array-like, or label indicator array / sparse matrix</strong>
    Estimated targets as returned by a classifier.</p>
</li>
<li>
<p><strong>labels : list, optional</strong>
    The set of labels to include when <code>average != 'binary'</code>, and their
    order if <code>average is None</code>. Labels present in the data can be
    excluded, for example to calculate a multiclass average ignoring a
    majority negative class, while labels not present in the data will
    result in 0 components in a macro average. For multilabel targets,
    labels are column indices. By default, all labels in <code>y_true</code> and
    <code>y_pred</code> are used in sorted order.</p>
<p>.. versionchanged:: 0.17
   parameter <em>labels</em> improved for multiclass problem.</p>
</li>
<li>
<p><strong>pos_label : str or int, 1 by default</strong>
    The class to report if <code>average='binary'</code> and the data is binary.
    If the data are multiclass or multilabel, this will be ignored;
    setting <code>labels=[pos_label]</code> and <code>average != 'binary'</code> will report
    scores for that label only.</p>
</li>
<li>
<p><strong>average : string, [None, 'binary' (default), 'micro', 'macro', 'samples',                        'weighted']</strong>
    This parameter is required for multiclass/multilabel targets.
    If <code>None</code>, the scores for each class are returned. Otherwise, this
    determines the type of averaging performed on the data:</p>
<p><code>'binary'</code>:
    Only report results for the class specified by <code>pos_label</code>.
    This is applicable only if targets (<code>y_{true,pred}</code>) are binary.
<code>'micro'</code>:
    Calculate metrics globally by counting the total true positives,
    false negatives and false positives.
<code>'macro'</code>:
    Calculate metrics for each label, and find their unweighted
    mean.  This does not take label imbalance into account.
<code>'weighted'</code>:
    Calculate metrics for each label, and find their average weighted
    by support (the number of true instances for each label). This
    alters 'macro' to account for label imbalance; it can result in an
    F-score that is not between precision and recall.
<code>'samples'</code>:
    Calculate metrics for each instance, and find their average (only
    meaningful for multilabel classification where this differs from
    :func:<code>accuracy_score</code>).</p>
</li>
<li>
<p><strong>sample_weight : array-like of shape (n_samples,), default=None</strong>
    Sample weights.</p>
</li>
<li>
<p><strong>zero_division : 'warn', 0 or 1, default='warn'</strong>
    Sets the value to return when there is a zero division, i.e. when all
    predictions and labels are negative. If set to 'warn', this acts as 0,
    but warnings are also raised.</p>
</li>
</ul>
<h4>Returns</h4>
<ul>
<li><strong>f1_score : float or array of float, shape = [n_unique_labels]</strong>
    F1 score of the positive class in binary classification or weighted
    average of the F1 scores of each class for the multiclass task.</li>
</ul>
<h4>See also</h4>
<p>fbeta_score, precision_recall_fscore_support, jaccard_score,
multilabel_confusion_matrix</p>
<h4>References</h4>
<p>.. [1] <code>Wikipedia entry for the F1-score
       &lt;https://en.wikipedia.org/wiki/F1_score&gt;</code>_</p>
<h4>Examples</h4>
<div class="highlight"><pre><span></span><code><span class="o">&gt;&gt;&gt;</span> <span class="kn">from</span> <span class="nn">sklearn.metrics</span> <span class="kn">import</span> <span class="n">f1_score</span>
<span class="o">&gt;&gt;&gt;</span> <span class="n">y_true</span> <span class="o">=</span> <span class="p">[</span><span class="mi">0</span><span class="p">,</span> <span class="mi">1</span><span class="p">,</span> <span class="mi">2</span><span class="p">,</span> <span class="mi">0</span><span class="p">,</span> <span class="mi">1</span><span class="p">,</span> <span class="mi">2</span><span class="p">]</span>
<span class="o">&gt;&gt;&gt;</span> <span class="n">y_pred</span> <span class="o">=</span> <span class="p">[</span><span class="mi">0</span><span class="p">,</span> <span class="mi">2</span><span class="p">,</span> <span class="mi">1</span><span class="p">,</span> <span class="mi">0</span><span class="p">,</span> <span class="mi">0</span><span class="p">,</span> <span class="mi">1</span><span class="p">]</span>
<span class="o">&gt;&gt;&gt;</span> <span class="n">f1_score</span><span class="p">(</span><span class="n">y_true</span><span class="p">,</span> <span class="n">y_pred</span><span class="p">,</span> <span class="n">average</span><span class="o">=</span><span class="s1">&#39;macro&#39;</span><span class="p">)</span>
<span class="mf">0.26</span><span class="o">...</span>
<span class="o">&gt;&gt;&gt;</span> <span class="n">f1_score</span><span class="p">(</span><span class="n">y_true</span><span class="p">,</span> <span class="n">y_pred</span><span class="p">,</span> <span class="n">average</span><span class="o">=</span><span class="s1">&#39;micro&#39;</span><span class="p">)</span>
<span class="mf">0.33</span><span class="o">...</span>
<span class="o">&gt;&gt;&gt;</span> <span class="n">f1_score</span><span class="p">(</span><span class="n">y_true</span><span class="p">,</span> <span class="n">y_pred</span><span class="p">,</span> <span class="n">average</span><span class="o">=</span><span class="s1">&#39;weighted&#39;</span><span class="p">)</span>
<span class="mf">0.26</span><span class="o">...</span>
<span class="o">&gt;&gt;&gt;</span> <span class="n">f1_score</span><span class="p">(</span><span class="n">y_true</span><span class="p">,</span> <span class="n">y_pred</span><span class="p">,</span> <span class="n">average</span><span class="o">=</span><span class="kc">None</span><span class="p">)</span>
<span class="n">array</span><span class="p">([</span><span class="mf">0.8</span><span class="p">,</span> <span class="mf">0.</span> <span class="p">,</span> <span class="mf">0.</span> <span class="p">])</span>
<span class="o">&gt;&gt;&gt;</span> <span class="n">y_true</span> <span class="o">=</span> <span class="p">[</span><span class="mi">0</span><span class="p">,</span> <span class="mi">0</span><span class="p">,</span> <span class="mi">0</span><span class="p">,</span> <span class="mi">0</span><span class="p">,</span> <span class="mi">0</span><span class="p">,</span> <span class="mi">0</span><span class="p">]</span>
<span class="o">&gt;&gt;&gt;</span> <span class="n">y_pred</span> <span class="o">=</span> <span class="p">[</span><span class="mi">0</span><span class="p">,</span> <span class="mi">0</span><span class="p">,</span> <span class="mi">0</span><span class="p">,</span> <span class="mi">0</span><span class="p">,</span> <span class="mi">0</span><span class="p">,</span> <span class="mi">0</span><span class="p">]</span>
<span class="o">&gt;&gt;&gt;</span> <span class="n">f1_score</span><span class="p">(</span><span class="n">y_true</span><span class="p">,</span> <span class="n">y_pred</span><span class="p">,</span> <span class="n">zero_division</span><span class="o">=</span><span class="mi">1</span><span class="p">)</span>
<span class="mf">1.0</span><span class="o">...</span>
</code></pre></div>

<h4>Notes</h4>
<p>When <code>true positive + false positive == 0</code>, precision is undefined;
When <code>true positive + false negative == 0</code>, recall is undefined.
In such cases, by default the metric will be set to 0, as will f-score,
and <code>UndefinedMetricWarning</code> will be raised. This behavior can be
modified with <code>zero_division</code>.</p>
</details>
<h3 id="fbeta_score">fbeta_score<a class="headerlink" href="#fbeta_score" title="Permanent link">&para;</a></h3>
<details class="note" open="open"><summary>function fbeta_score</summary><div class="highlight"><pre><span></span><code><span class="k">val</span> <span class="n">fbeta_score</span> <span class="o">:</span>
  <span class="o">?</span><span class="n">labels</span><span class="o">:[&gt;`</span><span class="nc">ArrayLike</span><span class="o">]</span> <span class="nn">Np</span><span class="p">.</span><span class="nn">Obj</span><span class="p">.</span><span class="n">t</span> <span class="o">-&gt;</span>
  <span class="o">?</span><span class="n">pos_label</span><span class="o">:[`</span><span class="nc">S</span> <span class="k">of</span> <span class="kt">string</span> <span class="o">|</span> <span class="o">`</span><span class="nc">I</span> <span class="k">of</span> <span class="kt">int</span><span class="o">]</span> <span class="o">-&gt;</span>
  <span class="o">?</span><span class="n">average</span><span class="o">:[`</span><span class="nc">Macro</span> <span class="o">|</span> <span class="o">`</span><span class="nc">Weighted</span> <span class="o">|</span> <span class="o">`</span><span class="nc">Samples</span> <span class="o">|</span> <span class="o">`</span><span class="nc">Micro</span> <span class="o">|</span> <span class="o">`</span><span class="nc">Binary</span> <span class="o">|</span> <span class="o">`</span><span class="nc">None</span><span class="o">]</span> <span class="o">-&gt;</span>
  <span class="o">?</span><span class="n">sample_weight</span><span class="o">:[&gt;`</span><span class="nc">ArrayLike</span><span class="o">]</span> <span class="nn">Np</span><span class="p">.</span><span class="nn">Obj</span><span class="p">.</span><span class="n">t</span> <span class="o">-&gt;</span>
  <span class="o">?</span><span class="n">zero_division</span><span class="o">:[`</span><span class="nc">Warn</span> <span class="o">|</span> <span class="o">`</span><span class="nc">Zero</span> <span class="o">|</span> <span class="o">`</span><span class="nc">One</span><span class="o">]</span> <span class="o">-&gt;</span>
  <span class="n">y_true</span><span class="o">:[&gt;`</span><span class="nc">ArrayLike</span><span class="o">]</span> <span class="nn">Np</span><span class="p">.</span><span class="nn">Obj</span><span class="p">.</span><span class="n">t</span> <span class="o">-&gt;</span>
  <span class="n">y_pred</span><span class="o">:[&gt;`</span><span class="nc">ArrayLike</span><span class="o">]</span> <span class="nn">Np</span><span class="p">.</span><span class="nn">Obj</span><span class="p">.</span><span class="n">t</span> <span class="o">-&gt;</span>
  <span class="n">beta</span><span class="o">:</span><span class="kt">float</span> <span class="o">-&gt;</span>
  <span class="kt">unit</span> <span class="o">-&gt;</span>
  <span class="o">[&gt;`</span><span class="nc">ArrayLike</span><span class="o">]</span> <span class="nn">Np</span><span class="p">.</span><span class="nn">Obj</span><span class="p">.</span><span class="n">t</span>
</code></pre></div>

<p>Compute the F-beta score</p>
<p>The F-beta score is the weighted harmonic mean of precision and recall,
reaching its optimal value at 1 and its worst value at 0.</p>
<p>The <code>beta</code> parameter determines the weight of recall in the combined
score. <code>beta &lt; 1</code> lends more weight to precision, while <code>beta &gt; 1</code>
favors recall (<code>beta -&gt; 0</code> considers only precision, <code>beta -&gt; +inf</code>
only recall).</p>
<p>Read more in the :ref:<code>User Guide &lt;precision_recall_f_measure_metrics&gt;</code>.</p>
<h4>Parameters</h4>
<ul>
<li>
<p><strong>y_true : 1d array-like, or label indicator array / sparse matrix</strong>
    Ground truth (correct) target values.</p>
</li>
<li>
<p><strong>y_pred : 1d array-like, or label indicator array / sparse matrix</strong>
    Estimated targets as returned by a classifier.</p>
</li>
<li>
<p><strong>beta : float</strong>
    Determines the weight of recall in the combined score.</p>
</li>
<li>
<p><strong>labels : list, optional</strong>
    The set of labels to include when <code>average != 'binary'</code>, and their
    order if <code>average is None</code>. Labels present in the data can be
    excluded, for example to calculate a multiclass average ignoring a
    majority negative class, while labels not present in the data will
    result in 0 components in a macro average. For multilabel targets,
    labels are column indices. By default, all labels in <code>y_true</code> and
    <code>y_pred</code> are used in sorted order.</p>
<p>.. versionchanged:: 0.17
   parameter <em>labels</em> improved for multiclass problem.</p>
</li>
<li>
<p><strong>pos_label : str or int, 1 by default</strong>
    The class to report if <code>average='binary'</code> and the data is binary.
    If the data are multiclass or multilabel, this will be ignored;
    setting <code>labels=[pos_label]</code> and <code>average != 'binary'</code> will report
    scores for that label only.</p>
</li>
<li>
<p><strong>average : string, [None, 'binary' (default), 'micro', 'macro', 'samples',                        'weighted']</strong>
    This parameter is required for multiclass/multilabel targets.
    If <code>None</code>, the scores for each class are returned. Otherwise, this
    determines the type of averaging performed on the data:</p>
<p><code>'binary'</code>:
    Only report results for the class specified by <code>pos_label</code>.
    This is applicable only if targets (<code>y_{true,pred}</code>) are binary.
<code>'micro'</code>:
    Calculate metrics globally by counting the total true positives,
    false negatives and false positives.
<code>'macro'</code>:
    Calculate metrics for each label, and find their unweighted
    mean.  This does not take label imbalance into account.
<code>'weighted'</code>:
    Calculate metrics for each label, and find their average weighted
    by support (the number of true instances for each label). This
    alters 'macro' to account for label imbalance; it can result in an
    F-score that is not between precision and recall.
<code>'samples'</code>:
    Calculate metrics for each instance, and find their average (only
    meaningful for multilabel classification where this differs from
    :func:<code>accuracy_score</code>).</p>
</li>
<li>
<p><strong>sample_weight : array-like of shape (n_samples,), default=None</strong>
    Sample weights.</p>
</li>
<li>
<p><strong>zero_division : 'warn', 0 or 1, default='warn'</strong>
    Sets the value to return when there is a zero division, i.e. when all
    predictions and labels are negative. If set to 'warn', this acts as 0,
    but warnings are also raised.</p>
</li>
</ul>
<h4>Returns</h4>
<ul>
<li><strong>fbeta_score : float (if average is not None) or array of float, shape =        [n_unique_labels]</strong>
    F-beta score of the positive class in binary classification or weighted
    average of the F-beta score of each class for the multiclass task.</li>
</ul>
<h4>See also</h4>
<p>precision_recall_fscore_support, multilabel_confusion_matrix</p>
<h4>References</h4>
<p>.. [1] R. Baeza-Yates and B. Ribeiro-Neto (2011).
       Modern Information Retrieval. Addison Wesley, pp. 327-328.</p>
<p>.. [2] <code>Wikipedia entry for the F1-score
       &lt;https://en.wikipedia.org/wiki/F1_score&gt;</code>_</p>
<h4>Examples</h4>
<div class="highlight"><pre><span></span><code><span class="o">&gt;&gt;&gt;</span> <span class="kn">from</span> <span class="nn">sklearn.metrics</span> <span class="kn">import</span> <span class="n">fbeta_score</span>
<span class="o">&gt;&gt;&gt;</span> <span class="n">y_true</span> <span class="o">=</span> <span class="p">[</span><span class="mi">0</span><span class="p">,</span> <span class="mi">1</span><span class="p">,</span> <span class="mi">2</span><span class="p">,</span> <span class="mi">0</span><span class="p">,</span> <span class="mi">1</span><span class="p">,</span> <span class="mi">2</span><span class="p">]</span>
<span class="o">&gt;&gt;&gt;</span> <span class="n">y_pred</span> <span class="o">=</span> <span class="p">[</span><span class="mi">0</span><span class="p">,</span> <span class="mi">2</span><span class="p">,</span> <span class="mi">1</span><span class="p">,</span> <span class="mi">0</span><span class="p">,</span> <span class="mi">0</span><span class="p">,</span> <span class="mi">1</span><span class="p">]</span>
<span class="o">&gt;&gt;&gt;</span> <span class="n">fbeta_score</span><span class="p">(</span><span class="n">y_true</span><span class="p">,</span> <span class="n">y_pred</span><span class="p">,</span> <span class="n">average</span><span class="o">=</span><span class="s1">&#39;macro&#39;</span><span class="p">,</span> <span class="n">beta</span><span class="o">=</span><span class="mf">0.5</span><span class="p">)</span>
<span class="mf">0.23</span><span class="o">...</span>
<span class="o">&gt;&gt;&gt;</span> <span class="n">fbeta_score</span><span class="p">(</span><span class="n">y_true</span><span class="p">,</span> <span class="n">y_pred</span><span class="p">,</span> <span class="n">average</span><span class="o">=</span><span class="s1">&#39;micro&#39;</span><span class="p">,</span> <span class="n">beta</span><span class="o">=</span><span class="mf">0.5</span><span class="p">)</span>
<span class="mf">0.33</span><span class="o">...</span>
<span class="o">&gt;&gt;&gt;</span> <span class="n">fbeta_score</span><span class="p">(</span><span class="n">y_true</span><span class="p">,</span> <span class="n">y_pred</span><span class="p">,</span> <span class="n">average</span><span class="o">=</span><span class="s1">&#39;weighted&#39;</span><span class="p">,</span> <span class="n">beta</span><span class="o">=</span><span class="mf">0.5</span><span class="p">)</span>
<span class="mf">0.23</span><span class="o">...</span>
<span class="o">&gt;&gt;&gt;</span> <span class="n">fbeta_score</span><span class="p">(</span><span class="n">y_true</span><span class="p">,</span> <span class="n">y_pred</span><span class="p">,</span> <span class="n">average</span><span class="o">=</span><span class="kc">None</span><span class="p">,</span> <span class="n">beta</span><span class="o">=</span><span class="mf">0.5</span><span class="p">)</span>
<span class="n">array</span><span class="p">([</span><span class="mf">0.71</span><span class="o">...</span><span class="p">,</span> <span class="mf">0.</span>        <span class="p">,</span> <span class="mf">0.</span>        <span class="p">])</span>
</code></pre></div>

<h4>Notes</h4>
<p>When <code>true positive + false positive == 0</code> or
<code>true positive + false negative == 0</code>, f-score returns 0 and raises
<code>UndefinedMetricWarning</code>. This behavior can be
modified with <code>zero_division</code>.</p>
</details>
<h3 id="fowlkes_mallows_score_1">fowlkes_mallows_score<a class="headerlink" href="#fowlkes_mallows_score_1" title="Permanent link">&para;</a></h3>
<details class="note" open="open"><summary>function fowlkes_mallows_score</summary><div class="highlight"><pre><span></span><code><span class="k">val</span> <span class="n">fowlkes_mallows_score</span> <span class="o">:</span>
  <span class="o">?</span><span class="n">sparse</span><span class="o">:</span><span class="kt">bool</span> <span class="o">-&gt;</span>
  <span class="n">labels_true</span><span class="o">:[&gt;`</span><span class="nc">ArrayLike</span><span class="o">]</span> <span class="nn">Np</span><span class="p">.</span><span class="nn">Obj</span><span class="p">.</span><span class="n">t</span> <span class="o">-&gt;</span>
  <span class="n">labels_pred</span><span class="o">:[&gt;`</span><span class="nc">ArrayLike</span><span class="o">]</span> <span class="nn">Np</span><span class="p">.</span><span class="nn">Obj</span><span class="p">.</span><span class="n">t</span> <span class="o">-&gt;</span>
  <span class="kt">unit</span> <span class="o">-&gt;</span>
  <span class="kt">float</span>
</code></pre></div>

<p>Measure the similarity of two clusterings of a set of points.</p>
<p>.. versionadded:: 0.18</p>
<p>The Fowlkes-Mallows index (FMI) is defined as the geometric mean between of
the precision and recall::</p>
<div class="codehilite"><pre><span></span><code>FMI = TP / sqrt((TP + FP) * (TP + FN))
</code></pre></div>


<p>Where <code>TP</code> is the number of <strong>True Positive</strong> (i.e. the number of pair of
points that belongs in the same clusters in both <code>labels_true</code> and
<code>labels_pred</code>), <code>FP</code> is the number of <strong>False Positive</strong> (i.e. the
number of pair of points that belongs in the same clusters in
<code>labels_true</code> and not in <code>labels_pred</code>) and <code>FN</code> is the number of
<strong>False Negative</strong> (i.e the number of pair of points that belongs in the
same clusters in <code>labels_pred</code> and not in <code>labels_True</code>).</p>
<p>The score ranges from 0 to 1. A high value indicates a good similarity
between two clusters.</p>
<p>Read more in the :ref:<code>User Guide &lt;fowlkes_mallows_scores&gt;</code>.</p>
<h4>Parameters</h4>
<ul>
<li>
<p><strong>labels_true : int array, shape = (<code>n_samples</code>,)</strong>
    A clustering of the data into disjoint subsets.</p>
</li>
<li>
<p><strong>labels_pred : array, shape = (<code>n_samples</code>, )</strong>
    A clustering of the data into disjoint subsets.</p>
</li>
<li>
<p><strong>sparse : bool</strong>
    Compute contingency matrix internally with sparse matrix.</p>
</li>
</ul>
<h4>Returns</h4>
<ul>
<li><strong>score : float</strong>
   The resulting Fowlkes-Mallows score.</li>
</ul>
<h4>Examples</h4>
<p>Perfect labelings are both homogeneous and complete, hence have
score 1.0::</p>
<blockquote>
<blockquote>
<blockquote>
<p>from sklearn.metrics.cluster import fowlkes_mallows_score
fowlkes_mallows_score([0, 0, 1, 1], [0, 0, 1, 1])
  1.0
fowlkes_mallows_score([0, 0, 1, 1], [1, 1, 0, 0])
  1.0</p>
</blockquote>
</blockquote>
</blockquote>
<p>If classes members are completely split across different clusters,
the assignment is totally random, hence the FMI is null::</p>
<blockquote>
<blockquote>
<blockquote>
<p>fowlkes_mallows_score([0, 0, 0, 0], [0, 1, 2, 3])
  0.0</p>
</blockquote>
</blockquote>
</blockquote>
<h4>References</h4>
<p>.. [1] <code>E. B. Fowkles and C. L. Mallows, 1983. 'A method for comparing two
   hierarchical clusterings'. Journal of the American Statistical
   Association
   &lt;http://wildfire.stat.ucla.edu/pdflibrary/fowlkes.pdf&gt;</code>_</p>
<p>.. [2] <code>Wikipedia entry for the Fowlkes-Mallows Index
       &lt;https://en.wikipedia.org/wiki/Fowlkes-Mallows_index&gt;</code>_</p>
</details>
<h3 id="get_scorer">get_scorer<a class="headerlink" href="#get_scorer" title="Permanent link">&para;</a></h3>
<details class="note" open="open"><summary>function get_scorer</summary><div class="highlight"><pre><span></span><code><span class="k">val</span> <span class="n">get_scorer</span> <span class="o">:</span>
  <span class="o">[`</span><span class="nc">Score</span> <span class="k">of</span> <span class="o">[`</span><span class="nc">Explained_variance</span> <span class="o">|</span> <span class="o">`</span><span class="nc">R2</span> <span class="o">|</span> <span class="o">`</span><span class="nc">Max_error</span> <span class="o">|</span> <span class="o">`</span><span class="nc">Neg_median_absolute_error</span> <span class="o">|</span> <span class="o">`</span><span class="nc">Neg_mean_absolute_error</span> <span class="o">|</span> <span class="o">`</span><span class="nc">Neg_mean_squared_error</span> <span class="o">|</span> <span class="o">`</span><span class="nc">Neg_mean_squared_log_error</span> <span class="o">|</span> <span class="o">`</span><span class="nc">Neg_root_mean_squared_error</span> <span class="o">|</span> <span class="o">`</span><span class="nc">Neg_mean_poisson_deviance</span> <span class="o">|</span> <span class="o">`</span><span class="nc">Neg_mean_gamma_deviance</span> <span class="o">|</span> <span class="o">`</span><span class="nc">Accuracy</span> <span class="o">|</span> <span class="o">`</span><span class="nc">Roc_auc</span> <span class="o">|</span> <span class="o">`</span><span class="nc">Roc_auc_ovr</span> <span class="o">|</span> <span class="o">`</span><span class="nc">Roc_auc_ovo</span> <span class="o">|</span> <span class="o">`</span><span class="nc">Roc_auc_ovr_weighted</span> <span class="o">|</span> <span class="o">`</span><span class="nc">Roc_auc_ovo_weighted</span> <span class="o">|</span> <span class="o">`</span><span class="nc">Balanced_accuracy</span> <span class="o">|</span> <span class="o">`</span><span class="nc">Average_precision</span> <span class="o">|</span> <span class="o">`</span><span class="nc">Neg_log_loss</span> <span class="o">|</span> <span class="o">`</span><span class="nc">Neg_brier_score</span> <span class="o">|</span> <span class="o">`</span><span class="nc">Adjusted_rand_score</span> <span class="o">|</span> <span class="o">`</span><span class="nc">Homogeneity_score</span> <span class="o">|</span> <span class="o">`</span><span class="nc">Completeness_score</span> <span class="o">|</span> <span class="o">`</span><span class="nc">V_measure_score</span> <span class="o">|</span> <span class="o">`</span><span class="nc">Mutual_info_score</span> <span class="o">|</span> <span class="o">`</span><span class="nc">Adjusted_mutual_info_score</span> <span class="o">|</span> <span class="o">`</span><span class="nc">Normalized_mutual_info_score</span> <span class="o">|</span> <span class="o">`</span><span class="nc">Fowlkes_mallows_score</span> <span class="o">|</span> <span class="o">`</span><span class="nc">Precision</span> <span class="o">|</span> <span class="o">`</span><span class="nc">Precision_macro</span> <span class="o">|</span> <span class="o">`</span><span class="nc">Precision_micro</span> <span class="o">|</span> <span class="o">`</span><span class="nc">Precision_samples</span> <span class="o">|</span> <span class="o">`</span><span class="nc">Precision_weighted</span> <span class="o">|</span> <span class="o">`</span><span class="nc">Recall</span> <span class="o">|</span> <span class="o">`</span><span class="nc">Recall_macro</span> <span class="o">|</span> <span class="o">`</span><span class="nc">Recall_micro</span> <span class="o">|</span> <span class="o">`</span><span class="nc">Recall_samples</span> <span class="o">|</span> <span class="o">`</span><span class="nc">Recall_weighted</span> <span class="o">|</span> <span class="o">`</span><span class="nc">F1</span> <span class="o">|</span> <span class="o">`</span><span class="nc">F1_macro</span> <span class="o">|</span> <span class="o">`</span><span class="nc">F1_micro</span> <span class="o">|</span> <span class="o">`</span><span class="nc">F1_samples</span> <span class="o">|</span> <span class="o">`</span><span class="nc">F1_weighted</span> <span class="o">|</span> <span class="o">`</span><span class="nc">Jaccard</span> <span class="o">|</span> <span class="o">`</span><span class="nc">Jaccard_macro</span> <span class="o">|</span> <span class="o">`</span><span class="nc">Jaccard_micro</span> <span class="o">|</span> <span class="o">`</span><span class="nc">Jaccard_samples</span> <span class="o">|</span> <span class="o">`</span><span class="nc">Jaccard_weighted</span><span class="o">]</span> <span class="o">|</span> <span class="o">`</span><span class="nc">Callable</span> <span class="k">of</span> <span class="nn">Py</span><span class="p">.</span><span class="nn">Object</span><span class="p">.</span><span class="n">t</span><span class="o">]</span> <span class="o">-&gt;</span>
  <span class="nn">Py</span><span class="p">.</span><span class="nn">Object</span><span class="p">.</span><span class="n">t</span>
</code></pre></div>

<p>Get a scorer from string.</p>
<p>Read more in the :ref:<code>User Guide &lt;scoring_parameter&gt;</code>.</p>
<h4>Parameters</h4>
<ul>
<li><strong>scoring : str | callable</strong>
    scoring method as string. If callable it is returned as is.</li>
</ul>
<h4>Returns</h4>
<ul>
<li><strong>scorer : callable</strong>
    The scorer.</li>
</ul>
</details>
<h3 id="hamming_loss">hamming_loss<a class="headerlink" href="#hamming_loss" title="Permanent link">&para;</a></h3>
<details class="note" open="open"><summary>function hamming_loss</summary><div class="highlight"><pre><span></span><code><span class="k">val</span> <span class="n">hamming_loss</span> <span class="o">:</span>
  <span class="o">?</span><span class="n">sample_weight</span><span class="o">:[&gt;`</span><span class="nc">ArrayLike</span><span class="o">]</span> <span class="nn">Np</span><span class="p">.</span><span class="nn">Obj</span><span class="p">.</span><span class="n">t</span> <span class="o">-&gt;</span>
  <span class="n">y_true</span><span class="o">:[&gt;`</span><span class="nc">ArrayLike</span><span class="o">]</span> <span class="nn">Np</span><span class="p">.</span><span class="nn">Obj</span><span class="p">.</span><span class="n">t</span> <span class="o">-&gt;</span>
  <span class="n">y_pred</span><span class="o">:[&gt;`</span><span class="nc">ArrayLike</span><span class="o">]</span> <span class="nn">Np</span><span class="p">.</span><span class="nn">Obj</span><span class="p">.</span><span class="n">t</span> <span class="o">-&gt;</span>
  <span class="kt">unit</span> <span class="o">-&gt;</span>
  <span class="kt">float</span>
</code></pre></div>

<p>Compute the average Hamming loss.</p>
<p>The Hamming loss is the fraction of labels that are incorrectly predicted.</p>
<p>Read more in the :ref:<code>User Guide &lt;hamming_loss&gt;</code>.</p>
<h4>Parameters</h4>
<ul>
<li>
<p><strong>y_true : 1d array-like, or label indicator array / sparse matrix</strong>
    Ground truth (correct) labels.</p>
</li>
<li>
<p><strong>y_pred : 1d array-like, or label indicator array / sparse matrix</strong>
    Predicted labels, as returned by a classifier.</p>
</li>
<li>
<p><strong>sample_weight : array-like of shape (n_samples,), default=None</strong>
    Sample weights.</p>
<p>.. versionadded:: 0.18</p>
</li>
</ul>
<h4>Returns</h4>
<ul>
<li><strong>loss : float or int,</strong>
    Return the average Hamming loss between element of <code>y_true</code> and
    <code>y_pred</code>.</li>
</ul>
<h4>See Also</h4>
<p>accuracy_score, jaccard_score, zero_one_loss</p>
<h4>Notes</h4>
<p>In multiclass classification, the Hamming loss corresponds to the Hamming
distance between <code>y_true</code> and <code>y_pred</code> which is equivalent to the
subset <code>zero_one_loss</code> function, when <code>normalize</code> parameter is set to
True.</p>
<p>In multilabel classification, the Hamming loss is different from the
subset zero-one loss. The zero-one loss considers the entire set of labels
for a given sample incorrect if it does not entirely match the true set of
labels. Hamming loss is more forgiving in that it penalizes only the
individual labels.</p>
<p>The Hamming loss is upperbounded by the subset zero-one loss, when
<code>normalize</code> parameter is set to True. It is always between 0 and 1,
lower being better.</p>
<h4>References</h4>
<p>.. [1] Grigorios Tsoumakas, Ioannis Katakis. Multi-Label Classification:
       An Overview. International Journal of Data Warehousing &amp; Mining,
       3(3), 1-13, July-September 2007.</p>
<p>.. [2] <code>Wikipedia entry on the Hamming distance
       &lt;https://en.wikipedia.org/wiki/Hamming_distance&gt;</code>_</p>
<h4>Examples</h4>
<div class="highlight"><pre><span></span><code><span class="o">&gt;&gt;&gt;</span> <span class="kn">from</span> <span class="nn">sklearn.metrics</span> <span class="kn">import</span> <span class="n">hamming_loss</span>
<span class="o">&gt;&gt;&gt;</span> <span class="n">y_pred</span> <span class="o">=</span> <span class="p">[</span><span class="mi">1</span><span class="p">,</span> <span class="mi">2</span><span class="p">,</span> <span class="mi">3</span><span class="p">,</span> <span class="mi">4</span><span class="p">]</span>
<span class="o">&gt;&gt;&gt;</span> <span class="n">y_true</span> <span class="o">=</span> <span class="p">[</span><span class="mi">2</span><span class="p">,</span> <span class="mi">2</span><span class="p">,</span> <span class="mi">3</span><span class="p">,</span> <span class="mi">4</span><span class="p">]</span>
<span class="o">&gt;&gt;&gt;</span> <span class="n">hamming_loss</span><span class="p">(</span><span class="n">y_true</span><span class="p">,</span> <span class="n">y_pred</span><span class="p">)</span>
<span class="mf">0.25</span>
</code></pre></div>

<p>In the multilabel case with binary label indicators:</p>
<div class="highlight"><pre><span></span><code><span class="o">&gt;&gt;&gt;</span> <span class="kn">import</span> <span class="nn">numpy</span> <span class="k">as</span> <span class="nn">np</span>
<span class="o">&gt;&gt;&gt;</span> <span class="n">hamming_loss</span><span class="p">(</span><span class="n">np</span><span class="o">.</span><span class="n">array</span><span class="p">([[</span><span class="mi">0</span><span class="p">,</span> <span class="mi">1</span><span class="p">],</span> <span class="p">[</span><span class="mi">1</span><span class="p">,</span> <span class="mi">1</span><span class="p">]]),</span> <span class="n">np</span><span class="o">.</span><span class="n">zeros</span><span class="p">((</span><span class="mi">2</span><span class="p">,</span> <span class="mi">2</span><span class="p">)))</span>
<span class="mf">0.75</span>
</code></pre></div>

</details>
<h3 id="hinge_loss">hinge_loss<a class="headerlink" href="#hinge_loss" title="Permanent link">&para;</a></h3>
<details class="note" open="open"><summary>function hinge_loss</summary><div class="highlight"><pre><span></span><code><span class="k">val</span> <span class="n">hinge_loss</span> <span class="o">:</span>
  <span class="o">?</span><span class="n">labels</span><span class="o">:[&gt;`</span><span class="nc">ArrayLike</span><span class="o">]</span> <span class="nn">Np</span><span class="p">.</span><span class="nn">Obj</span><span class="p">.</span><span class="n">t</span> <span class="o">-&gt;</span>
  <span class="o">?</span><span class="n">sample_weight</span><span class="o">:[&gt;`</span><span class="nc">ArrayLike</span><span class="o">]</span> <span class="nn">Np</span><span class="p">.</span><span class="nn">Obj</span><span class="p">.</span><span class="n">t</span> <span class="o">-&gt;</span>
  <span class="n">y_true</span><span class="o">:[&gt;`</span><span class="nc">ArrayLike</span><span class="o">]</span> <span class="nn">Np</span><span class="p">.</span><span class="nn">Obj</span><span class="p">.</span><span class="n">t</span> <span class="o">-&gt;</span>
  <span class="n">pred_decision</span><span class="o">:[&gt;`</span><span class="nc">ArrayLike</span><span class="o">]</span> <span class="nn">Np</span><span class="p">.</span><span class="nn">Obj</span><span class="p">.</span><span class="n">t</span> <span class="o">-&gt;</span>
  <span class="kt">unit</span> <span class="o">-&gt;</span>
  <span class="kt">float</span>
</code></pre></div>

<p>Average hinge loss (non-regularized)</p>
<p>In binary class case, assuming labels in y_true are encoded with +1 and -1,
when a prediction mistake is made, <code>margin = y_true * pred_decision</code> is
always negative (since the signs disagree), implying <code>1 - margin</code> is
always greater than 1.  The cumulated hinge loss is therefore an upper
bound of the number of mistakes made by the classifier.</p>
<p>In multiclass case, the function expects that either all the labels are
included in y_true or an optional labels argument is provided which
contains all the labels. The multilabel margin is calculated according
to Crammer-Singer's method. As in the binary case, the cumulated hinge loss
is an upper bound of the number of mistakes made by the classifier.</p>
<p>Read more in the :ref:<code>User Guide &lt;hinge_loss&gt;</code>.</p>
<h4>Parameters</h4>
<ul>
<li>
<p><strong>y_true : array, shape = [n_samples]</strong>
    True target, consisting of integers of two values. The positive label
    must be greater than the negative label.</p>
</li>
<li>
<p><strong>pred_decision : array, shape = [n_samples] or [n_samples, n_classes]</strong>
    Predicted decisions, as output by decision_function (floats).</p>
</li>
<li>
<p><strong>labels : array, optional, default None</strong>
    Contains all the labels for the problem. Used in multiclass hinge loss.</p>
</li>
<li>
<p><strong>sample_weight : array-like of shape (n_samples,), default=None</strong>
    Sample weights.</p>
</li>
</ul>
<h4>Returns</h4>
<ul>
<li><strong>loss : float</strong></li>
</ul>
<h4>References</h4>
<p>.. [1] <code>Wikipedia entry on the Hinge loss
       &lt;https://en.wikipedia.org/wiki/Hinge_loss&gt;</code>_</p>
<p>.. [2] Koby Crammer, Yoram Singer. On the Algorithmic
       Implementation of Multiclass Kernel-based Vector
       Machines. Journal of Machine Learning Research 2,
       (2001), 265-292</p>
<p>.. [3] <code>L1 AND L2 Regularization for Multiclass Hinge Loss Models
       by Robert C. Moore, John DeNero.
       &lt;http://www.ttic.edu/sigml/symposium2011/papers/
       Moore+DeNero_Regularization.pdf&gt;</code>_</p>
<h4>Examples</h4>
<div class="highlight"><pre><span></span><code><span class="o">&gt;&gt;&gt;</span> <span class="kn">from</span> <span class="nn">sklearn</span> <span class="kn">import</span> <span class="n">svm</span>
<span class="o">&gt;&gt;&gt;</span> <span class="kn">from</span> <span class="nn">sklearn.metrics</span> <span class="kn">import</span> <span class="n">hinge_loss</span>
<span class="o">&gt;&gt;&gt;</span> <span class="n">X</span> <span class="o">=</span> <span class="p">[[</span><span class="mi">0</span><span class="p">],</span> <span class="p">[</span><span class="mi">1</span><span class="p">]]</span>
<span class="o">&gt;&gt;&gt;</span> <span class="n">y</span> <span class="o">=</span> <span class="p">[</span><span class="o">-</span><span class="mi">1</span><span class="p">,</span> <span class="mi">1</span><span class="p">]</span>
<span class="o">&gt;&gt;&gt;</span> <span class="n">est</span> <span class="o">=</span> <span class="n">svm</span><span class="o">.</span><span class="n">LinearSVC</span><span class="p">(</span><span class="n">random_state</span><span class="o">=</span><span class="mi">0</span><span class="p">)</span>
<span class="o">&gt;&gt;&gt;</span> <span class="n">est</span><span class="o">.</span><span class="n">fit</span><span class="p">(</span><span class="n">X</span><span class="p">,</span> <span class="n">y</span><span class="p">)</span>
<span class="n">LinearSVC</span><span class="p">(</span><span class="n">random_state</span><span class="o">=</span><span class="mi">0</span><span class="p">)</span>
<span class="o">&gt;&gt;&gt;</span> <span class="n">pred_decision</span> <span class="o">=</span> <span class="n">est</span><span class="o">.</span><span class="n">decision_function</span><span class="p">([[</span><span class="o">-</span><span class="mi">2</span><span class="p">],</span> <span class="p">[</span><span class="mi">3</span><span class="p">],</span> <span class="p">[</span><span class="mf">0.5</span><span class="p">]])</span>
<span class="o">&gt;&gt;&gt;</span> <span class="n">pred_decision</span>
<span class="n">array</span><span class="p">([</span><span class="o">-</span><span class="mf">2.18</span><span class="o">...</span><span class="p">,</span>  <span class="mf">2.36</span><span class="o">...</span><span class="p">,</span>  <span class="mf">0.09</span><span class="o">...</span><span class="p">])</span>
<span class="o">&gt;&gt;&gt;</span> <span class="n">hinge_loss</span><span class="p">([</span><span class="o">-</span><span class="mi">1</span><span class="p">,</span> <span class="mi">1</span><span class="p">,</span> <span class="mi">1</span><span class="p">],</span> <span class="n">pred_decision</span><span class="p">)</span>
<span class="mf">0.30</span><span class="o">...</span>
</code></pre></div>

<p>In the multiclass case:</p>
<div class="highlight"><pre><span></span><code><span class="o">&gt;&gt;&gt;</span> <span class="kn">import</span> <span class="nn">numpy</span> <span class="k">as</span> <span class="nn">np</span>
<span class="o">&gt;&gt;&gt;</span> <span class="n">X</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">array</span><span class="p">([[</span><span class="mi">0</span><span class="p">],</span> <span class="p">[</span><span class="mi">1</span><span class="p">],</span> <span class="p">[</span><span class="mi">2</span><span class="p">],</span> <span class="p">[</span><span class="mi">3</span><span class="p">]])</span>
<span class="o">&gt;&gt;&gt;</span> <span class="n">Y</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">array</span><span class="p">([</span><span class="mi">0</span><span class="p">,</span> <span class="mi">1</span><span class="p">,</span> <span class="mi">2</span><span class="p">,</span> <span class="mi">3</span><span class="p">])</span>
<span class="o">&gt;&gt;&gt;</span> <span class="n">labels</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">array</span><span class="p">([</span><span class="mi">0</span><span class="p">,</span> <span class="mi">1</span><span class="p">,</span> <span class="mi">2</span><span class="p">,</span> <span class="mi">3</span><span class="p">])</span>
<span class="o">&gt;&gt;&gt;</span> <span class="n">est</span> <span class="o">=</span> <span class="n">svm</span><span class="o">.</span><span class="n">LinearSVC</span><span class="p">()</span>
<span class="o">&gt;&gt;&gt;</span> <span class="n">est</span><span class="o">.</span><span class="n">fit</span><span class="p">(</span><span class="n">X</span><span class="p">,</span> <span class="n">Y</span><span class="p">)</span>
<span class="n">LinearSVC</span><span class="p">()</span>
<span class="o">&gt;&gt;&gt;</span> <span class="n">pred_decision</span> <span class="o">=</span> <span class="n">est</span><span class="o">.</span><span class="n">decision_function</span><span class="p">([[</span><span class="o">-</span><span class="mi">1</span><span class="p">],</span> <span class="p">[</span><span class="mi">2</span><span class="p">],</span> <span class="p">[</span><span class="mi">3</span><span class="p">]])</span>
<span class="o">&gt;&gt;&gt;</span> <span class="n">y_true</span> <span class="o">=</span> <span class="p">[</span><span class="mi">0</span><span class="p">,</span> <span class="mi">2</span><span class="p">,</span> <span class="mi">3</span><span class="p">]</span>
<span class="o">&gt;&gt;&gt;</span> <span class="n">hinge_loss</span><span class="p">(</span><span class="n">y_true</span><span class="p">,</span> <span class="n">pred_decision</span><span class="p">,</span> <span class="n">labels</span><span class="o">=</span><span class="n">labels</span><span class="p">)</span>
<span class="mf">0.56</span><span class="o">...</span>
</code></pre></div>

</details>
<h3 id="homogeneity_completeness_v_measure_1">homogeneity_completeness_v_measure<a class="headerlink" href="#homogeneity_completeness_v_measure_1" title="Permanent link">&para;</a></h3>
<details class="note" open="open"><summary>function homogeneity_completeness_v_measure</summary><div class="highlight"><pre><span></span><code><span class="k">val</span> <span class="n">homogeneity_completeness_v_measure</span> <span class="o">:</span>
  <span class="o">?</span><span class="n">beta</span><span class="o">:</span><span class="kt">float</span> <span class="o">-&gt;</span>
  <span class="n">labels_true</span><span class="o">:[&gt;`</span><span class="nc">ArrayLike</span><span class="o">]</span> <span class="nn">Np</span><span class="p">.</span><span class="nn">Obj</span><span class="p">.</span><span class="n">t</span> <span class="o">-&gt;</span>
  <span class="n">labels_pred</span><span class="o">:[&gt;`</span><span class="nc">ArrayLike</span><span class="o">]</span> <span class="nn">Np</span><span class="p">.</span><span class="nn">Obj</span><span class="p">.</span><span class="n">t</span> <span class="o">-&gt;</span>
  <span class="kt">unit</span> <span class="o">-&gt;</span>
  <span class="o">(</span><span class="kt">float</span> <span class="o">*</span> <span class="kt">float</span> <span class="o">*</span> <span class="kt">float</span><span class="o">)</span>
</code></pre></div>

<p>Compute the homogeneity and completeness and V-Measure scores at once.</p>
<p>Those metrics are based on normalized conditional entropy measures of
the clustering labeling to evaluate given the knowledge of a Ground
Truth class labels of the same samples.</p>
<p>A clustering result satisfies homogeneity if all of its clusters
contain only data points which are members of a single class.</p>
<p>A clustering result satisfies completeness if all the data points
that are members of a given class are elements of the same cluster.</p>
<p>Both scores have positive values between 0.0 and 1.0, larger values
being desirable.</p>
<p>Those 3 metrics are independent of the absolute values of the labels:
a permutation of the class or cluster label values won't change the
score values in any way.</p>
<p>V-Measure is furthermore symmetric: swapping <code>labels_true</code> and
<code>label_pred</code> will give the same score. This does not hold for
homogeneity and completeness. V-Measure is identical to
:func:<code>normalized_mutual_info_score</code> with the arithmetic averaging
method.</p>
<p>Read more in the :ref:<code>User Guide &lt;homogeneity_completeness&gt;</code>.</p>
<h4>Parameters</h4>
<ul>
<li>
<p><strong>labels_true : int array, shape = [n_samples]</strong>
    ground truth class labels to be used as a reference</p>
</li>
<li>
<p><strong>labels_pred : array-like of shape (n_samples,)</strong>
    cluster labels to evaluate</p>
</li>
<li>
<p><strong>beta : float</strong>
    Ratio of weight attributed to <code>homogeneity</code> vs <code>completeness</code>.
    If <code>beta</code> is greater than 1, <code>completeness</code> is weighted more
    strongly in the calculation. If <code>beta</code> is less than 1,
    <code>homogeneity</code> is weighted more strongly.</p>
</li>
</ul>
<h4>Returns</h4>
<ul>
<li>
<p><strong>homogeneity : float</strong>
   score between 0.0 and 1.0. 1.0 stands for perfectly homogeneous labeling</p>
</li>
<li>
<p><strong>completeness : float</strong>
   score between 0.0 and 1.0. 1.0 stands for perfectly complete labeling</p>
</li>
<li>
<p><strong>v_measure : float</strong>
    harmonic mean of the first two</p>
</li>
</ul>
<h4>See also</h4>
<p>homogeneity_score
completeness_score
v_measure_score</p>
</details>
<h3 id="homogeneity_score_1">homogeneity_score<a class="headerlink" href="#homogeneity_score_1" title="Permanent link">&para;</a></h3>
<details class="note" open="open"><summary>function homogeneity_score</summary><div class="highlight"><pre><span></span><code><span class="k">val</span> <span class="n">homogeneity_score</span> <span class="o">:</span>
  <span class="n">labels_true</span><span class="o">:[&gt;`</span><span class="nc">ArrayLike</span><span class="o">]</span> <span class="nn">Np</span><span class="p">.</span><span class="nn">Obj</span><span class="p">.</span><span class="n">t</span> <span class="o">-&gt;</span>
  <span class="n">labels_pred</span><span class="o">:[&gt;`</span><span class="nc">ArrayLike</span><span class="o">]</span> <span class="nn">Np</span><span class="p">.</span><span class="nn">Obj</span><span class="p">.</span><span class="n">t</span> <span class="o">-&gt;</span>
  <span class="kt">unit</span> <span class="o">-&gt;</span>
  <span class="kt">float</span>
</code></pre></div>

<p>Homogeneity metric of a cluster labeling given a ground truth.</p>
<p>A clustering result satisfies homogeneity if all of its clusters
contain only data points which are members of a single class.</p>
<p>This metric is independent of the absolute values of the labels:
a permutation of the class or cluster label values won't change the
score value in any way.</p>
<p>This metric is not symmetric: switching <code>label_true</code> with <code>label_pred</code>
will return the :func:<code>completeness_score</code> which will be different in
general.</p>
<p>Read more in the :ref:<code>User Guide &lt;homogeneity_completeness&gt;</code>.</p>
<h4>Parameters</h4>
<ul>
<li>
<p><strong>labels_true : int array, shape = [n_samples]</strong>
    ground truth class labels to be used as a reference</p>
</li>
<li>
<p><strong>labels_pred : array-like of shape (n_samples,)</strong>
    cluster labels to evaluate</p>
</li>
</ul>
<h4>Returns</h4>
<ul>
<li><strong>homogeneity : float</strong>
   score between 0.0 and 1.0. 1.0 stands for perfectly homogeneous labeling</li>
</ul>
<h4>References</h4>
<p>.. [1] <code>Andrew Rosenberg and Julia Hirschberg, 2007. V-Measure: A
   conditional entropy-based external cluster evaluation measure
   &lt;https://aclweb.org/anthology/D/D07/D07-1043.pdf&gt;</code>_</p>
<h4>See also</h4>
<p>completeness_score
v_measure_score</p>
<h4>Examples</h4>
<p>Perfect labelings are homogeneous::</p>
<blockquote>
<blockquote>
<blockquote>
<p>from sklearn.metrics.cluster import homogeneity_score
homogeneity_score([0, 0, 1, 1], [1, 1, 0, 0])
  1.0</p>
</blockquote>
</blockquote>
</blockquote>
<p>Non-perfect labelings that further split classes into more clusters can be
perfectly homogeneous::</p>
<blockquote>
<blockquote>
<blockquote>
<p>print('%.6f' % homogeneity_score([0, 0, 1, 1], [0, 0, 1, 2]))
  1.000000
print('%.6f' % homogeneity_score([0, 0, 1, 1], [0, 1, 2, 3]))
  1.000000</p>
</blockquote>
</blockquote>
</blockquote>
<p>Clusters that include samples from different classes do not make for an
homogeneous labeling::</p>
<blockquote>
<blockquote>
<blockquote>
<p>print('%.6f' % homogeneity_score([0, 0, 1, 1], [0, 1, 0, 1]))
  0.0...
print('%.6f' % homogeneity_score([0, 0, 1, 1], [0, 0, 0, 0]))
  0.0...</p>
</blockquote>
</blockquote>
</blockquote>
</details>
<h3 id="jaccard_score">jaccard_score<a class="headerlink" href="#jaccard_score" title="Permanent link">&para;</a></h3>
<details class="note" open="open"><summary>function jaccard_score</summary><div class="highlight"><pre><span></span><code><span class="k">val</span> <span class="n">jaccard_score</span> <span class="o">:</span>
  <span class="o">?</span><span class="n">labels</span><span class="o">:[&gt;`</span><span class="nc">ArrayLike</span><span class="o">]</span> <span class="nn">Np</span><span class="p">.</span><span class="nn">Obj</span><span class="p">.</span><span class="n">t</span> <span class="o">-&gt;</span>
  <span class="o">?</span><span class="n">pos_label</span><span class="o">:[`</span><span class="nc">S</span> <span class="k">of</span> <span class="kt">string</span> <span class="o">|</span> <span class="o">`</span><span class="nc">I</span> <span class="k">of</span> <span class="kt">int</span><span class="o">]</span> <span class="o">-&gt;</span>
  <span class="o">?</span><span class="n">average</span><span class="o">:[`</span><span class="nc">Macro</span> <span class="o">|</span> <span class="o">`</span><span class="nc">Weighted</span> <span class="o">|</span> <span class="o">`</span><span class="nc">Samples</span> <span class="o">|</span> <span class="o">`</span><span class="nc">Micro</span> <span class="o">|</span> <span class="o">`</span><span class="nc">Binary</span> <span class="o">|</span> <span class="o">`</span><span class="nc">None</span><span class="o">]</span> <span class="o">-&gt;</span>
  <span class="o">?</span><span class="n">sample_weight</span><span class="o">:[&gt;`</span><span class="nc">ArrayLike</span><span class="o">]</span> <span class="nn">Np</span><span class="p">.</span><span class="nn">Obj</span><span class="p">.</span><span class="n">t</span> <span class="o">-&gt;</span>
  <span class="n">y_true</span><span class="o">:[&gt;`</span><span class="nc">ArrayLike</span><span class="o">]</span> <span class="nn">Np</span><span class="p">.</span><span class="nn">Obj</span><span class="p">.</span><span class="n">t</span> <span class="o">-&gt;</span>
  <span class="n">y_pred</span><span class="o">:[&gt;`</span><span class="nc">ArrayLike</span><span class="o">]</span> <span class="nn">Np</span><span class="p">.</span><span class="nn">Obj</span><span class="p">.</span><span class="n">t</span> <span class="o">-&gt;</span>
  <span class="kt">unit</span> <span class="o">-&gt;</span>
  <span class="o">[&gt;`</span><span class="nc">ArrayLike</span><span class="o">]</span> <span class="nn">Np</span><span class="p">.</span><span class="nn">Obj</span><span class="p">.</span><span class="n">t</span>
</code></pre></div>

<p>Jaccard similarity coefficient score</p>
<p>The Jaccard index [1], or Jaccard similarity coefficient, defined as
the size of the intersection divided by the size of the union of two label
sets, is used to compare set of predicted labels for a sample to the
corresponding set of labels in <code>y_true</code>.</p>
<p>Read more in the :ref:<code>User Guide &lt;jaccard_similarity_score&gt;</code>.</p>
<h4>Parameters</h4>
<ul>
<li>
<p><strong>y_true : 1d array-like, or label indicator array / sparse matrix</strong>
    Ground truth (correct) labels.</p>
</li>
<li>
<p><strong>y_pred : 1d array-like, or label indicator array / sparse matrix</strong>
    Predicted labels, as returned by a classifier.</p>
</li>
<li>
<p><strong>labels : list, optional</strong>
    The set of labels to include when <code>average != 'binary'</code>, and their
    order if <code>average is None</code>. Labels present in the data can be
    excluded, for example to calculate a multiclass average ignoring a
    majority negative class, while labels not present in the data will
    result in 0 components in a macro average. For multilabel targets,
    labels are column indices. By default, all labels in <code>y_true</code> and
    <code>y_pred</code> are used in sorted order.</p>
</li>
<li>
<p><strong>pos_label : str or int, 1 by default</strong>
    The class to report if <code>average='binary'</code> and the data is binary.
    If the data are multiclass or multilabel, this will be ignored;
    setting <code>labels=[pos_label]</code> and <code>average != 'binary'</code> will report
    scores for that label only.</p>
</li>
<li>
<p><strong>average : string, [None, 'binary' (default), 'micro', 'macro', 'samples',                        'weighted']</strong>
    If <code>None</code>, the scores for each class are returned. Otherwise, this
    determines the type of averaging performed on the data:</p>
<p><code>'binary'</code>:
    Only report results for the class specified by <code>pos_label</code>.
    This is applicable only if targets (<code>y_{true,pred}</code>) are binary.
<code>'micro'</code>:
    Calculate metrics globally by counting the total true positives,
    false negatives and false positives.
<code>'macro'</code>:
    Calculate metrics for each label, and find their unweighted
    mean.  This does not take label imbalance into account.
<code>'weighted'</code>:
    Calculate metrics for each label, and find their average, weighted
    by support (the number of true instances for each label). This
    alters 'macro' to account for label imbalance.
<code>'samples'</code>:
    Calculate metrics for each instance, and find their average (only
    meaningful for multilabel classification).</p>
</li>
<li>
<p><strong>sample_weight : array-like of shape (n_samples,), default=None</strong>
    Sample weights.</p>
</li>
</ul>
<h4>Returns</h4>
<ul>
<li><strong>score : float (if average is not None) or array of floats, shape =            [n_unique_labels]</strong></li>
</ul>
<h4>See also</h4>
<p>accuracy_score, f_score, multilabel_confusion_matrix</p>
<h4>Notes</h4>
<p>:func:<code>jaccard_score</code> may be a poor metric if there are no
positives for some samples or classes. Jaccard is undefined if there are
no true or predicted labels, and our implementation will return a score
of 0 with a warning.</p>
<h4>References</h4>
<p>.. [1] <code>Wikipedia entry for the Jaccard index
       &lt;https://en.wikipedia.org/wiki/Jaccard_index&gt;</code>_</p>
<h4>Examples</h4>
<div class="highlight"><pre><span></span><code><span class="o">&gt;&gt;&gt;</span> <span class="kn">import</span> <span class="nn">numpy</span> <span class="k">as</span> <span class="nn">np</span>
<span class="o">&gt;&gt;&gt;</span> <span class="kn">from</span> <span class="nn">sklearn.metrics</span> <span class="kn">import</span> <span class="n">jaccard_score</span>
<span class="o">&gt;&gt;&gt;</span> <span class="n">y_true</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">array</span><span class="p">([[</span><span class="mi">0</span><span class="p">,</span> <span class="mi">1</span><span class="p">,</span> <span class="mi">1</span><span class="p">],</span>
<span class="o">...</span>                    <span class="p">[</span><span class="mi">1</span><span class="p">,</span> <span class="mi">1</span><span class="p">,</span> <span class="mi">0</span><span class="p">]])</span>
<span class="o">&gt;&gt;&gt;</span> <span class="n">y_pred</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">array</span><span class="p">([[</span><span class="mi">1</span><span class="p">,</span> <span class="mi">1</span><span class="p">,</span> <span class="mi">1</span><span class="p">],</span>
<span class="o">...</span>                    <span class="p">[</span><span class="mi">1</span><span class="p">,</span> <span class="mi">0</span><span class="p">,</span> <span class="mi">0</span><span class="p">]])</span>
</code></pre></div>

<p>In the binary case:</p>
<div class="highlight"><pre><span></span><code><span class="o">&gt;&gt;&gt;</span> <span class="n">jaccard_score</span><span class="p">(</span><span class="n">y_true</span><span class="p">[</span><span class="mi">0</span><span class="p">],</span> <span class="n">y_pred</span><span class="p">[</span><span class="mi">0</span><span class="p">])</span>
<span class="mf">0.6666</span><span class="o">...</span>
</code></pre></div>

<p>In the multilabel case:</p>
<div class="highlight"><pre><span></span><code><span class="o">&gt;&gt;&gt;</span> <span class="n">jaccard_score</span><span class="p">(</span><span class="n">y_true</span><span class="p">,</span> <span class="n">y_pred</span><span class="p">,</span> <span class="n">average</span><span class="o">=</span><span class="s1">&#39;samples&#39;</span><span class="p">)</span>
<span class="mf">0.5833</span><span class="o">...</span>
<span class="o">&gt;&gt;&gt;</span> <span class="n">jaccard_score</span><span class="p">(</span><span class="n">y_true</span><span class="p">,</span> <span class="n">y_pred</span><span class="p">,</span> <span class="n">average</span><span class="o">=</span><span class="s1">&#39;macro&#39;</span><span class="p">)</span>
<span class="mf">0.6666</span><span class="o">...</span>
<span class="o">&gt;&gt;&gt;</span> <span class="n">jaccard_score</span><span class="p">(</span><span class="n">y_true</span><span class="p">,</span> <span class="n">y_pred</span><span class="p">,</span> <span class="n">average</span><span class="o">=</span><span class="kc">None</span><span class="p">)</span>
<span class="n">array</span><span class="p">([</span><span class="mf">0.5</span><span class="p">,</span> <span class="mf">0.5</span><span class="p">,</span> <span class="mf">1.</span> <span class="p">])</span>
</code></pre></div>

<p>In the multiclass case:</p>
<div class="highlight"><pre><span></span><code><span class="o">&gt;&gt;&gt;</span> <span class="n">y_pred</span> <span class="o">=</span> <span class="p">[</span><span class="mi">0</span><span class="p">,</span> <span class="mi">2</span><span class="p">,</span> <span class="mi">1</span><span class="p">,</span> <span class="mi">2</span><span class="p">]</span>
<span class="o">&gt;&gt;&gt;</span> <span class="n">y_true</span> <span class="o">=</span> <span class="p">[</span><span class="mi">0</span><span class="p">,</span> <span class="mi">1</span><span class="p">,</span> <span class="mi">2</span><span class="p">,</span> <span class="mi">2</span><span class="p">]</span>
<span class="o">&gt;&gt;&gt;</span> <span class="n">jaccard_score</span><span class="p">(</span><span class="n">y_true</span><span class="p">,</span> <span class="n">y_pred</span><span class="p">,</span> <span class="n">average</span><span class="o">=</span><span class="kc">None</span><span class="p">)</span>
<span class="n">array</span><span class="p">([</span><span class="mf">1.</span> <span class="p">,</span> <span class="mf">0.</span> <span class="p">,</span> <span class="mf">0.33</span><span class="o">...</span><span class="p">])</span>
</code></pre></div>

</details>
<h3 id="label_ranking_average_precision_score">label_ranking_average_precision_score<a class="headerlink" href="#label_ranking_average_precision_score" title="Permanent link">&para;</a></h3>
<details class="note" open="open"><summary>function label_ranking_average_precision_score</summary><div class="highlight"><pre><span></span><code><span class="k">val</span> <span class="n">label_ranking_average_precision_score</span> <span class="o">:</span>
  <span class="o">?</span><span class="n">sample_weight</span><span class="o">:[&gt;`</span><span class="nc">ArrayLike</span><span class="o">]</span> <span class="nn">Np</span><span class="p">.</span><span class="nn">Obj</span><span class="p">.</span><span class="n">t</span> <span class="o">-&gt;</span>
  <span class="n">y_true</span><span class="o">:[&gt;`</span><span class="nc">ArrayLike</span><span class="o">]</span> <span class="nn">Np</span><span class="p">.</span><span class="nn">Obj</span><span class="p">.</span><span class="n">t</span> <span class="o">-&gt;</span>
  <span class="n">y_score</span><span class="o">:[&gt;`</span><span class="nc">ArrayLike</span><span class="o">]</span> <span class="nn">Np</span><span class="p">.</span><span class="nn">Obj</span><span class="p">.</span><span class="n">t</span> <span class="o">-&gt;</span>
  <span class="kt">unit</span> <span class="o">-&gt;</span>
  <span class="kt">float</span>
</code></pre></div>

<p>Compute ranking-based average precision</p>
<p>Label ranking average precision (LRAP) is the average over each ground
truth label assigned to each sample, of the ratio of true vs. total
labels with lower score.</p>
<p>This metric is used in multilabel ranking problem, where the goal
is to give better rank to the labels associated to each sample.</p>
<p>The obtained score is always strictly greater than 0 and
the best value is 1.</p>
<p>Read more in the :ref:<code>User Guide &lt;label_ranking_average_precision&gt;</code>.</p>
<h4>Parameters</h4>
<ul>
<li>
<p><strong>y_true : array or sparse matrix, shape = [n_samples, n_labels]</strong>
    True binary labels in binary indicator format.</p>
</li>
<li>
<p><strong>y_score : array, shape = [n_samples, n_labels]</strong>
    Target scores, can either be probability estimates of the positive
    class, confidence values, or non-thresholded measure of decisions
    (as returned by 'decision_function' on some classifiers).</p>
</li>
<li>
<p><strong>sample_weight : array-like of shape (n_samples,), default=None</strong>
    Sample weights.</p>
<p>.. versionadded:: 0.20</p>
</li>
</ul>
<h4>Returns</h4>
<ul>
<li><strong>score : float</strong></li>
</ul>
<h4>Examples</h4>
<div class="highlight"><pre><span></span><code><span class="o">&gt;&gt;&gt;</span> <span class="kn">import</span> <span class="nn">numpy</span> <span class="k">as</span> <span class="nn">np</span>
<span class="o">&gt;&gt;&gt;</span> <span class="kn">from</span> <span class="nn">sklearn.metrics</span> <span class="kn">import</span> <span class="n">label_ranking_average_precision_score</span>
<span class="o">&gt;&gt;&gt;</span> <span class="n">y_true</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">array</span><span class="p">([[</span><span class="mi">1</span><span class="p">,</span> <span class="mi">0</span><span class="p">,</span> <span class="mi">0</span><span class="p">],</span> <span class="p">[</span><span class="mi">0</span><span class="p">,</span> <span class="mi">0</span><span class="p">,</span> <span class="mi">1</span><span class="p">]])</span>
<span class="o">&gt;&gt;&gt;</span> <span class="n">y_score</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">array</span><span class="p">([[</span><span class="mf">0.75</span><span class="p">,</span> <span class="mf">0.5</span><span class="p">,</span> <span class="mi">1</span><span class="p">],</span> <span class="p">[</span><span class="mi">1</span><span class="p">,</span> <span class="mf">0.2</span><span class="p">,</span> <span class="mf">0.1</span><span class="p">]])</span>
<span class="o">&gt;&gt;&gt;</span> <span class="n">label_ranking_average_precision_score</span><span class="p">(</span><span class="n">y_true</span><span class="p">,</span> <span class="n">y_score</span><span class="p">)</span>
<span class="mf">0.416</span><span class="o">...</span>
</code></pre></div>

</details>
<h3 id="label_ranking_loss">label_ranking_loss<a class="headerlink" href="#label_ranking_loss" title="Permanent link">&para;</a></h3>
<details class="note" open="open"><summary>function label_ranking_loss</summary><div class="highlight"><pre><span></span><code><span class="k">val</span> <span class="n">label_ranking_loss</span> <span class="o">:</span>
  <span class="o">?</span><span class="n">sample_weight</span><span class="o">:[&gt;`</span><span class="nc">ArrayLike</span><span class="o">]</span> <span class="nn">Np</span><span class="p">.</span><span class="nn">Obj</span><span class="p">.</span><span class="n">t</span> <span class="o">-&gt;</span>
  <span class="n">y_true</span><span class="o">:[&gt;`</span><span class="nc">ArrayLike</span><span class="o">]</span> <span class="nn">Np</span><span class="p">.</span><span class="nn">Obj</span><span class="p">.</span><span class="n">t</span> <span class="o">-&gt;</span>
  <span class="n">y_score</span><span class="o">:[&gt;`</span><span class="nc">ArrayLike</span><span class="o">]</span> <span class="nn">Np</span><span class="p">.</span><span class="nn">Obj</span><span class="p">.</span><span class="n">t</span> <span class="o">-&gt;</span>
  <span class="kt">unit</span> <span class="o">-&gt;</span>
  <span class="kt">float</span>
</code></pre></div>

<p>Compute Ranking loss measure</p>
<p>Compute the average number of label pairs that are incorrectly ordered
given y_score weighted by the size of the label set and the number of
labels not in the label set.</p>
<p>This is similar to the error set size, but weighted by the number of
relevant and irrelevant labels. The best performance is achieved with
a ranking loss of zero.</p>
<p>Read more in the :ref:<code>User Guide &lt;label_ranking_loss&gt;</code>.</p>
<p>.. versionadded:: 0.17
   A function <em>label_ranking_loss</em></p>
<h4>Parameters</h4>
<ul>
<li>
<p><strong>y_true : array or sparse matrix, shape = [n_samples, n_labels]</strong>
    True binary labels in binary indicator format.</p>
</li>
<li>
<p><strong>y_score : array, shape = [n_samples, n_labels]</strong>
    Target scores, can either be probability estimates of the positive
    class, confidence values, or non-thresholded measure of decisions
    (as returned by 'decision_function' on some classifiers).</p>
</li>
<li>
<p><strong>sample_weight : array-like of shape (n_samples,), default=None</strong>
    Sample weights.</p>
</li>
</ul>
<h4>Returns</h4>
<ul>
<li><strong>loss : float</strong></li>
</ul>
<h4>References</h4>
<p>.. [1] Tsoumakas, G., Katakis, I., &amp; Vlahavas, I. (2010).
       Mining multi-label data. In Data mining and knowledge discovery
       handbook (pp. 667-685). Springer US.</p>
</details>
<h3 id="log_loss">log_loss<a class="headerlink" href="#log_loss" title="Permanent link">&para;</a></h3>
<details class="note" open="open"><summary>function log_loss</summary><div class="highlight"><pre><span></span><code><span class="k">val</span> <span class="n">log_loss</span> <span class="o">:</span>
  <span class="o">?</span><span class="n">eps</span><span class="o">:</span><span class="kt">float</span> <span class="o">-&gt;</span>
  <span class="o">?</span><span class="n">normalize</span><span class="o">:</span><span class="kt">bool</span> <span class="o">-&gt;</span>
  <span class="o">?</span><span class="n">sample_weight</span><span class="o">:[&gt;`</span><span class="nc">ArrayLike</span><span class="o">]</span> <span class="nn">Np</span><span class="p">.</span><span class="nn">Obj</span><span class="p">.</span><span class="n">t</span> <span class="o">-&gt;</span>
  <span class="o">?</span><span class="n">labels</span><span class="o">:[&gt;`</span><span class="nc">ArrayLike</span><span class="o">]</span> <span class="nn">Np</span><span class="p">.</span><span class="nn">Obj</span><span class="p">.</span><span class="n">t</span> <span class="o">-&gt;</span>
  <span class="n">y_true</span><span class="o">:[&gt;`</span><span class="nc">ArrayLike</span><span class="o">]</span> <span class="nn">Np</span><span class="p">.</span><span class="nn">Obj</span><span class="p">.</span><span class="n">t</span> <span class="o">-&gt;</span>
  <span class="n">y_pred</span><span class="o">:[&gt;`</span><span class="nc">ArrayLike</span><span class="o">]</span> <span class="nn">Np</span><span class="p">.</span><span class="nn">Obj</span><span class="p">.</span><span class="n">t</span> <span class="o">-&gt;</span>
  <span class="kt">unit</span> <span class="o">-&gt;</span>
  <span class="kt">float</span>
</code></pre></div>

<p>Log loss, aka logistic loss or cross-entropy loss.</p>
<p>This is the loss function used in (multinomial) logistic regression
and extensions of it such as neural networks, defined as the negative
log-likelihood of a logistic model that returns <code>y_pred</code> probabilities
for its training data <code>y_true</code>.
The log loss is only defined for two or more labels.
For a single sample with true label yt in {0,1} and
estimated probability yp that yt = 1, the log loss is</p>
<div class="codehilite"><pre><span></span><code>-log P(yt|yp) = -(yt log(yp) + (1 - yt) log(1 - yp))
</code></pre></div>


<p>Read more in the :ref:<code>User Guide &lt;log_loss&gt;</code>.</p>
<h4>Parameters</h4>
<ul>
<li>
<p><strong>y_true : array-like or label indicator matrix</strong>
    Ground truth (correct) labels for n_samples samples.</p>
</li>
<li>
<p><strong>y_pred : array-like of float, shape = (n_samples, n_classes) or (n_samples,)</strong>
    Predicted probabilities, as returned by a classifier's
    predict_proba method. If <code>y_pred.shape = (n_samples,)</code>
    the probabilities provided are assumed to be that of the
    positive class. The labels in <code>y_pred</code> are assumed to be
    ordered alphabetically, as done by
    :class:<code>preprocessing.LabelBinarizer</code>.</p>
</li>
<li>
<p><strong>eps : float</strong>
    Log loss is undefined for p=0 or p=1, so probabilities are
    clipped to max(eps, min(1 - eps, p)).</p>
</li>
<li>
<p><strong>normalize : bool, optional (default=True)</strong>
    If true, return the mean loss per sample.
    Otherwise, return the sum of the per-sample losses.</p>
</li>
<li>
<p><strong>sample_weight : array-like of shape (n_samples,), default=None</strong>
    Sample weights.</p>
</li>
<li>
<p><strong>labels : array-like, optional (default=None)</strong>
    If not provided, labels will be inferred from y_true. If <code>labels</code>
    is <code>None</code> and <code>y_pred</code> has shape (n_samples,) the labels are
    assumed to be binary and are inferred from <code>y_true</code>.</p>
<p>.. versionadded:: 0.18</p>
</li>
</ul>
<h4>Returns</h4>
<ul>
<li><strong>loss : float</strong></li>
</ul>
<h4>Examples</h4>
<div class="highlight"><pre><span></span><code><span class="o">&gt;&gt;&gt;</span> <span class="kn">from</span> <span class="nn">sklearn.metrics</span> <span class="kn">import</span> <span class="n">log_loss</span>
<span class="o">&gt;&gt;&gt;</span> <span class="n">log_loss</span><span class="p">([</span><span class="s1">&#39;spam&#39;</span><span class="p">,</span> <span class="s1">&#39;ham&#39;</span><span class="p">,</span> <span class="s1">&#39;ham&#39;</span><span class="p">,</span> <span class="s1">&#39;spam&#39;</span><span class="p">],</span>
<span class="o">...</span>          <span class="p">[[</span><span class="o">.</span><span class="mi">1</span><span class="p">,</span> <span class="o">.</span><span class="mi">9</span><span class="p">],</span> <span class="p">[</span><span class="o">.</span><span class="mi">9</span><span class="p">,</span> <span class="o">.</span><span class="mi">1</span><span class="p">],</span> <span class="p">[</span><span class="o">.</span><span class="mi">8</span><span class="p">,</span> <span class="o">.</span><span class="mi">2</span><span class="p">],</span> <span class="p">[</span><span class="o">.</span><span class="mi">35</span><span class="p">,</span> <span class="o">.</span><span class="mi">65</span><span class="p">]])</span>
<span class="mf">0.21616</span><span class="o">...</span>
</code></pre></div>

<h4>References</h4>
<p>C.M. Bishop (2006). Pattern Recognition and Machine Learning. Springer,
p. 209.</p>
<h4>Notes</h4>
<p>The logarithm used is the natural logarithm (base-e).</p>
</details>
<h3 id="make_scorer">make_scorer<a class="headerlink" href="#make_scorer" title="Permanent link">&para;</a></h3>
<details class="note" open="open"><summary>function make_scorer</summary><div class="highlight"><pre><span></span><code><span class="k">val</span> <span class="n">make_scorer</span> <span class="o">:</span>
  <span class="o">?</span><span class="n">greater_is_better</span><span class="o">:</span><span class="kt">bool</span> <span class="o">-&gt;</span>
  <span class="o">?</span><span class="n">needs_proba</span><span class="o">:</span><span class="kt">bool</span> <span class="o">-&gt;</span>
  <span class="o">?</span><span class="n">needs_threshold</span><span class="o">:</span><span class="kt">bool</span> <span class="o">-&gt;</span>
  <span class="o">?</span><span class="n">kwargs</span><span class="o">:(</span><span class="kt">string</span> <span class="o">*</span> <span class="nn">Py</span><span class="p">.</span><span class="nn">Object</span><span class="p">.</span><span class="n">t</span><span class="o">)</span> <span class="kt">list</span> <span class="o">-&gt;</span>
  <span class="n">score_func</span><span class="o">:</span><span class="nn">Py</span><span class="p">.</span><span class="nn">Object</span><span class="p">.</span><span class="n">t</span> <span class="o">-&gt;</span>
  <span class="kt">unit</span> <span class="o">-&gt;</span>
  <span class="nn">Py</span><span class="p">.</span><span class="nn">Object</span><span class="p">.</span><span class="n">t</span>
</code></pre></div>

<p>Make a scorer from a performance metric or loss function.</p>
<p>This factory function wraps scoring functions for use in GridSearchCV
and cross_val_score. It takes a score function, such as <code>accuracy_score</code>,
<code>mean_squared_error</code>, <code>adjusted_rand_index</code> or <code>average_precision</code>
and returns a callable that scores an estimator's output.</p>
<p>Read more in the :ref:<code>User Guide &lt;scoring&gt;</code>.</p>
<h4>Parameters</h4>
<ul>
<li>
<p><strong>score_func : callable,</strong>
    Score function (or loss function) with signature
    <code>score_func(y, y_pred, **kwargs)</code>.</p>
</li>
<li>
<p><strong>greater_is_better : boolean, default=True</strong>
    Whether score_func is a score function (default), meaning high is good,
    or a loss function, meaning low is good. In the latter case, the
    scorer object will sign-flip the outcome of the score_func.</p>
</li>
<li>
<p><strong>needs_proba : boolean, default=False</strong>
    Whether score_func requires predict_proba to get probability estimates
    out of a classifier.</p>
<p>If True, for binary <code>y_true</code>, the score function is supposed to accept
a 1D <code>y_pred</code> (i.e., probability of the positive class, shape
<code>(n_samples,)</code>).</p>
</li>
<li>
<p><strong>needs_threshold : boolean, default=False</strong>
    Whether score_func takes a continuous decision certainty.
    This only works for binary classification using estimators that
    have either a decision_function or predict_proba method.</p>
<p>If True, for binary <code>y_true</code>, the score function is supposed to accept
a 1D <code>y_pred</code> (i.e., probability of the positive class or the decision
function, shape <code>(n_samples,)</code>).</p>
<p>For example <code>average_precision</code> or the area under the roc curve
can not be computed using discrete predictions alone.</p>
</li>
<li>
<p><strong>**kwargs : additional arguments</strong>
    Additional parameters to be passed to score_func.</p>
</li>
</ul>
<h4>Returns</h4>
<ul>
<li><strong>scorer : callable</strong>
    Callable object that returns a scalar score; greater is better.</li>
</ul>
<h4>Examples</h4>
<div class="highlight"><pre><span></span><code><span class="o">&gt;&gt;&gt;</span> <span class="kn">from</span> <span class="nn">sklearn.metrics</span> <span class="kn">import</span> <span class="n">fbeta_score</span><span class="p">,</span> <span class="n">make_scorer</span>
<span class="o">&gt;&gt;&gt;</span> <span class="n">ftwo_scorer</span> <span class="o">=</span> <span class="n">make_scorer</span><span class="p">(</span><span class="n">fbeta_score</span><span class="p">,</span> <span class="n">beta</span><span class="o">=</span><span class="mi">2</span><span class="p">)</span>
<span class="o">&gt;&gt;&gt;</span> <span class="n">ftwo_scorer</span>
<span class="n">make_scorer</span><span class="p">(</span><span class="n">fbeta_score</span><span class="p">,</span> <span class="n">beta</span><span class="o">=</span><span class="mi">2</span><span class="p">)</span>
<span class="o">&gt;&gt;&gt;</span> <span class="kn">from</span> <span class="nn">sklearn.model_selection</span> <span class="kn">import</span> <span class="n">GridSearchCV</span>
<span class="o">&gt;&gt;&gt;</span> <span class="kn">from</span> <span class="nn">sklearn.svm</span> <span class="kn">import</span> <span class="n">LinearSVC</span>
<span class="o">&gt;&gt;&gt;</span> <span class="n">grid</span> <span class="o">=</span> <span class="n">GridSearchCV</span><span class="p">(</span><span class="n">LinearSVC</span><span class="p">(),</span> <span class="n">param_grid</span><span class="o">=</span><span class="p">{</span><span class="s1">&#39;C&#39;</span><span class="p">:</span> <span class="p">[</span><span class="mi">1</span><span class="p">,</span> <span class="mi">10</span><span class="p">]},</span>
<span class="o">...</span>                     <span class="n">scoring</span><span class="o">=</span><span class="n">ftwo_scorer</span><span class="p">)</span>
</code></pre></div>

<h4>Notes</h4>
<p>If <code>needs_proba=False</code> and <code>needs_threshold=False</code>, the score
function is supposed to accept the output of :term:<code>predict</code>. If
<code>needs_proba=True</code>, the score function is supposed to accept the
output of :term:<code>predict_proba</code> (For binary <code>y_true</code>, the score function is
supposed to accept probability of the positive class). If
<code>needs_threshold=True</code>, the score function is supposed to accept the
output of :term:<code>decision_function</code>.</p>
</details>
<h3 id="matthews_corrcoef">matthews_corrcoef<a class="headerlink" href="#matthews_corrcoef" title="Permanent link">&para;</a></h3>
<details class="note" open="open"><summary>function matthews_corrcoef</summary><div class="highlight"><pre><span></span><code><span class="k">val</span> <span class="n">matthews_corrcoef</span> <span class="o">:</span>
  <span class="o">?</span><span class="n">sample_weight</span><span class="o">:[&gt;`</span><span class="nc">ArrayLike</span><span class="o">]</span> <span class="nn">Np</span><span class="p">.</span><span class="nn">Obj</span><span class="p">.</span><span class="n">t</span> <span class="o">-&gt;</span>
  <span class="n">y_true</span><span class="o">:[&gt;`</span><span class="nc">ArrayLike</span><span class="o">]</span> <span class="nn">Np</span><span class="p">.</span><span class="nn">Obj</span><span class="p">.</span><span class="n">t</span> <span class="o">-&gt;</span>
  <span class="n">y_pred</span><span class="o">:[&gt;`</span><span class="nc">ArrayLike</span><span class="o">]</span> <span class="nn">Np</span><span class="p">.</span><span class="nn">Obj</span><span class="p">.</span><span class="n">t</span> <span class="o">-&gt;</span>
  <span class="kt">unit</span> <span class="o">-&gt;</span>
  <span class="kt">float</span>
</code></pre></div>

<p>Compute the Matthews correlation coefficient (MCC)</p>
<p>The Matthews correlation coefficient is used in machine learning as a
measure of the quality of binary and multiclass classifications. It takes
into account true and false positives and negatives and is generally
regarded as a balanced measure which can be used even if the classes are of
very different sizes. The MCC is in essence a correlation coefficient value
between -1 and +1. A coefficient of +1 represents a perfect prediction, 0
an average random prediction and -1 an inverse prediction.  The statistic
is also known as the phi coefficient. [source: Wikipedia]</p>
<p>Binary and multiclass labels are supported.  Only in the binary case does
this relate to information about true and false positives and negatives.
See references below.</p>
<p>Read more in the :ref:<code>User Guide &lt;matthews_corrcoef&gt;</code>.</p>
<h4>Parameters</h4>
<ul>
<li>
<p><strong>y_true : array, shape = [n_samples]</strong>
    Ground truth (correct) target values.</p>
</li>
<li>
<p><strong>y_pred : array, shape = [n_samples]</strong>
    Estimated targets as returned by a classifier.</p>
</li>
<li>
<p><strong>sample_weight : array-like of shape (n_samples,), default=None</strong>
    Sample weights.</p>
<p>.. versionadded:: 0.18</p>
</li>
</ul>
<h4>Returns</h4>
<ul>
<li><strong>mcc : float</strong>
    The Matthews correlation coefficient (+1 represents a perfect
    prediction, 0 an average random prediction and -1 and inverse
    prediction).</li>
</ul>
<h4>References</h4>
<p>.. [1] <code>Baldi, Brunak, Chauvin, Andersen and Nielsen, (2000). Assessing the
   accuracy of prediction algorithms for classification: an overview
   &lt;https://doi.org/10.1093/bioinformatics/16.5.412&gt;</code>_</p>
<p>.. [2] <code>Wikipedia entry for the Matthews Correlation Coefficient
   &lt;https://en.wikipedia.org/wiki/Matthews_correlation_coefficient&gt;</code>_</p>
<p>.. [3] <code>Gorodkin, (2004). Comparing two K-category assignments by a
    K-category correlation coefficient
    &lt;https://www.sciencedirect.com/science/article/pii/S1476927104000799&gt;</code>_</p>
<p>.. [4] <code>Jurman, Riccadonna, Furlanello, (2012). A Comparison of MCC and CEN
    Error Measures in MultiClass Prediction
    &lt;https://journals.plos.org/plosone/article?id=10.1371/journal.pone.0041882&gt;</code>_</p>
<h4>Examples</h4>
<div class="highlight"><pre><span></span><code><span class="o">&gt;&gt;&gt;</span> <span class="kn">from</span> <span class="nn">sklearn.metrics</span> <span class="kn">import</span> <span class="n">matthews_corrcoef</span>
<span class="o">&gt;&gt;&gt;</span> <span class="n">y_true</span> <span class="o">=</span> <span class="p">[</span><span class="o">+</span><span class="mi">1</span><span class="p">,</span> <span class="o">+</span><span class="mi">1</span><span class="p">,</span> <span class="o">+</span><span class="mi">1</span><span class="p">,</span> <span class="o">-</span><span class="mi">1</span><span class="p">]</span>
<span class="o">&gt;&gt;&gt;</span> <span class="n">y_pred</span> <span class="o">=</span> <span class="p">[</span><span class="o">+</span><span class="mi">1</span><span class="p">,</span> <span class="o">-</span><span class="mi">1</span><span class="p">,</span> <span class="o">+</span><span class="mi">1</span><span class="p">,</span> <span class="o">+</span><span class="mi">1</span><span class="p">]</span>
<span class="o">&gt;&gt;&gt;</span> <span class="n">matthews_corrcoef</span><span class="p">(</span><span class="n">y_true</span><span class="p">,</span> <span class="n">y_pred</span><span class="p">)</span>
<span class="o">-</span><span class="mf">0.33</span><span class="o">...</span>
</code></pre></div>

</details>
<h3 id="max_error">max_error<a class="headerlink" href="#max_error" title="Permanent link">&para;</a></h3>
<details class="note" open="open"><summary>function max_error</summary><div class="highlight"><pre><span></span><code><span class="k">val</span> <span class="n">max_error</span> <span class="o">:</span>
  <span class="n">y_true</span><span class="o">:[&gt;`</span><span class="nc">ArrayLike</span><span class="o">]</span> <span class="nn">Np</span><span class="p">.</span><span class="nn">Obj</span><span class="p">.</span><span class="n">t</span> <span class="o">-&gt;</span>
  <span class="n">y_pred</span><span class="o">:[&gt;`</span><span class="nc">ArrayLike</span><span class="o">]</span> <span class="nn">Np</span><span class="p">.</span><span class="nn">Obj</span><span class="p">.</span><span class="n">t</span> <span class="o">-&gt;</span>
  <span class="kt">unit</span> <span class="o">-&gt;</span>
  <span class="kt">float</span>
</code></pre></div>

<p>max_error metric calculates the maximum residual error.</p>
<p>Read more in the :ref:<code>User Guide &lt;max_error&gt;</code>.</p>
<h4>Parameters</h4>
<ul>
<li>
<p><strong>y_true : array-like of shape (n_samples,)</strong>
    Ground truth (correct) target values.</p>
</li>
<li>
<p><strong>y_pred : array-like of shape (n_samples,)</strong>
    Estimated target values.</p>
</li>
</ul>
<h4>Returns</h4>
<ul>
<li><strong>max_error : float</strong>
    A positive floating point value (the best value is 0.0).</li>
</ul>
<h4>Examples</h4>
<div class="highlight"><pre><span></span><code><span class="o">&gt;&gt;&gt;</span> <span class="kn">from</span> <span class="nn">sklearn.metrics</span> <span class="kn">import</span> <span class="n">max_error</span>
<span class="o">&gt;&gt;&gt;</span> <span class="n">y_true</span> <span class="o">=</span> <span class="p">[</span><span class="mi">3</span><span class="p">,</span> <span class="mi">2</span><span class="p">,</span> <span class="mi">7</span><span class="p">,</span> <span class="mi">1</span><span class="p">]</span>
<span class="o">&gt;&gt;&gt;</span> <span class="n">y_pred</span> <span class="o">=</span> <span class="p">[</span><span class="mi">4</span><span class="p">,</span> <span class="mi">2</span><span class="p">,</span> <span class="mi">7</span><span class="p">,</span> <span class="mi">1</span><span class="p">]</span>
<span class="o">&gt;&gt;&gt;</span> <span class="n">max_error</span><span class="p">(</span><span class="n">y_true</span><span class="p">,</span> <span class="n">y_pred</span><span class="p">)</span>
<span class="mi">1</span>
</code></pre></div>

</details>
<h3 id="mean_absolute_error">mean_absolute_error<a class="headerlink" href="#mean_absolute_error" title="Permanent link">&para;</a></h3>
<details class="note" open="open"><summary>function mean_absolute_error</summary><div class="highlight"><pre><span></span><code><span class="k">val</span> <span class="n">mean_absolute_error</span> <span class="o">:</span>
  <span class="o">?</span><span class="n">sample_weight</span><span class="o">:[&gt;`</span><span class="nc">ArrayLike</span><span class="o">]</span> <span class="nn">Np</span><span class="p">.</span><span class="nn">Obj</span><span class="p">.</span><span class="n">t</span> <span class="o">-&gt;</span>
  <span class="o">?</span><span class="n">multioutput</span><span class="o">:[`</span><span class="nc">Raw_values</span> <span class="o">|</span> <span class="o">`</span><span class="nc">Uniform_average</span> <span class="o">|</span> <span class="o">`</span><span class="nc">Arr</span> <span class="k">of</span> <span class="o">[&gt;`</span><span class="nc">ArrayLike</span><span class="o">]</span> <span class="nn">Np</span><span class="p">.</span><span class="nn">Obj</span><span class="p">.</span><span class="n">t</span><span class="o">]</span> <span class="o">-&gt;</span>
  <span class="n">y_true</span><span class="o">:[&gt;`</span><span class="nc">ArrayLike</span><span class="o">]</span> <span class="nn">Np</span><span class="p">.</span><span class="nn">Obj</span><span class="p">.</span><span class="n">t</span> <span class="o">-&gt;</span>
  <span class="n">y_pred</span><span class="o">:[&gt;`</span><span class="nc">ArrayLike</span><span class="o">]</span> <span class="nn">Np</span><span class="p">.</span><span class="nn">Obj</span><span class="p">.</span><span class="n">t</span> <span class="o">-&gt;</span>
  <span class="kt">unit</span> <span class="o">-&gt;</span>
  <span class="o">[&gt;`</span><span class="nc">ArrayLike</span><span class="o">]</span> <span class="nn">Np</span><span class="p">.</span><span class="nn">Obj</span><span class="p">.</span><span class="n">t</span>
</code></pre></div>

<p>Mean absolute error regression loss</p>
<p>Read more in the :ref:<code>User Guide &lt;mean_absolute_error&gt;</code>.</p>
<h4>Parameters</h4>
<ul>
<li>
<p><strong>y_true : array-like of shape (n_samples,) or (n_samples, n_outputs)</strong>
    Ground truth (correct) target values.</p>
</li>
<li>
<p><strong>y_pred : array-like of shape (n_samples,) or (n_samples, n_outputs)</strong>
    Estimated target values.</p>
</li>
<li>
<p><strong>sample_weight : array-like of shape (n_samples,), optional</strong>
    Sample weights.</p>
</li>
<li>
<p><strong>multioutput : string in ['raw_values', 'uniform_average']                 or array-like of shape (n_outputs)</strong>
    Defines aggregating of multiple output values.
    Array-like value defines weights used to average errors.</p>
<p>'raw_values' :
    Returns a full set of errors in case of multioutput input.</p>
<p>'uniform_average' :
    Errors of all outputs are averaged with uniform weight.</p>
</li>
</ul>
<h4>Returns</h4>
<ul>
<li>
<p><strong>loss : float or ndarray of floats</strong>
    If multioutput is 'raw_values', then mean absolute error is returned
    for each output separately.
    If multioutput is 'uniform_average' or an ndarray of weights, then the
    weighted average of all output errors is returned.</p>
<p>MAE output is non-negative floating point. The best value is 0.0.</p>
</li>
</ul>
<h4>Examples</h4>
<div class="highlight"><pre><span></span><code><span class="o">&gt;&gt;&gt;</span> <span class="kn">from</span> <span class="nn">sklearn.metrics</span> <span class="kn">import</span> <span class="n">mean_absolute_error</span>
<span class="o">&gt;&gt;&gt;</span> <span class="n">y_true</span> <span class="o">=</span> <span class="p">[</span><span class="mi">3</span><span class="p">,</span> <span class="o">-</span><span class="mf">0.5</span><span class="p">,</span> <span class="mi">2</span><span class="p">,</span> <span class="mi">7</span><span class="p">]</span>
<span class="o">&gt;&gt;&gt;</span> <span class="n">y_pred</span> <span class="o">=</span> <span class="p">[</span><span class="mf">2.5</span><span class="p">,</span> <span class="mf">0.0</span><span class="p">,</span> <span class="mi">2</span><span class="p">,</span> <span class="mi">8</span><span class="p">]</span>
<span class="o">&gt;&gt;&gt;</span> <span class="n">mean_absolute_error</span><span class="p">(</span><span class="n">y_true</span><span class="p">,</span> <span class="n">y_pred</span><span class="p">)</span>
<span class="mf">0.5</span>
<span class="o">&gt;&gt;&gt;</span> <span class="n">y_true</span> <span class="o">=</span> <span class="p">[[</span><span class="mf">0.5</span><span class="p">,</span> <span class="mi">1</span><span class="p">],</span> <span class="p">[</span><span class="o">-</span><span class="mi">1</span><span class="p">,</span> <span class="mi">1</span><span class="p">],</span> <span class="p">[</span><span class="mi">7</span><span class="p">,</span> <span class="o">-</span><span class="mi">6</span><span class="p">]]</span>
<span class="o">&gt;&gt;&gt;</span> <span class="n">y_pred</span> <span class="o">=</span> <span class="p">[[</span><span class="mi">0</span><span class="p">,</span> <span class="mi">2</span><span class="p">],</span> <span class="p">[</span><span class="o">-</span><span class="mi">1</span><span class="p">,</span> <span class="mi">2</span><span class="p">],</span> <span class="p">[</span><span class="mi">8</span><span class="p">,</span> <span class="o">-</span><span class="mi">5</span><span class="p">]]</span>
<span class="o">&gt;&gt;&gt;</span> <span class="n">mean_absolute_error</span><span class="p">(</span><span class="n">y_true</span><span class="p">,</span> <span class="n">y_pred</span><span class="p">)</span>
<span class="mf">0.75</span>
<span class="o">&gt;&gt;&gt;</span> <span class="n">mean_absolute_error</span><span class="p">(</span><span class="n">y_true</span><span class="p">,</span> <span class="n">y_pred</span><span class="p">,</span> <span class="n">multioutput</span><span class="o">=</span><span class="s1">&#39;raw_values&#39;</span><span class="p">)</span>
<span class="n">array</span><span class="p">([</span><span class="mf">0.5</span><span class="p">,</span> <span class="mf">1.</span> <span class="p">])</span>
<span class="o">&gt;&gt;&gt;</span> <span class="n">mean_absolute_error</span><span class="p">(</span><span class="n">y_true</span><span class="p">,</span> <span class="n">y_pred</span><span class="p">,</span> <span class="n">multioutput</span><span class="o">=</span><span class="p">[</span><span class="mf">0.3</span><span class="p">,</span> <span class="mf">0.7</span><span class="p">])</span>
<span class="mf">0.85</span><span class="o">...</span>
</code></pre></div>

</details>
<h3 id="mean_gamma_deviance">mean_gamma_deviance<a class="headerlink" href="#mean_gamma_deviance" title="Permanent link">&para;</a></h3>
<details class="note" open="open"><summary>function mean_gamma_deviance</summary><div class="highlight"><pre><span></span><code><span class="k">val</span> <span class="n">mean_gamma_deviance</span> <span class="o">:</span>
  <span class="o">?</span><span class="n">sample_weight</span><span class="o">:[&gt;`</span><span class="nc">ArrayLike</span><span class="o">]</span> <span class="nn">Np</span><span class="p">.</span><span class="nn">Obj</span><span class="p">.</span><span class="n">t</span> <span class="o">-&gt;</span>
  <span class="n">y_true</span><span class="o">:[&gt;`</span><span class="nc">ArrayLike</span><span class="o">]</span> <span class="nn">Np</span><span class="p">.</span><span class="nn">Obj</span><span class="p">.</span><span class="n">t</span> <span class="o">-&gt;</span>
  <span class="n">y_pred</span><span class="o">:[&gt;`</span><span class="nc">ArrayLike</span><span class="o">]</span> <span class="nn">Np</span><span class="p">.</span><span class="nn">Obj</span><span class="p">.</span><span class="n">t</span> <span class="o">-&gt;</span>
  <span class="kt">unit</span> <span class="o">-&gt;</span>
  <span class="kt">float</span>
</code></pre></div>

<p>Mean Gamma deviance regression loss.</p>
<p>Gamma deviance is equivalent to the Tweedie deviance with
the power parameter <code>power=2</code>. It is invariant to scaling of
the target variable, and measures relative errors.</p>
<p>Read more in the :ref:<code>User Guide &lt;mean_tweedie_deviance&gt;</code>.</p>
<h4>Parameters</h4>
<ul>
<li>
<p><strong>y_true : array-like of shape (n_samples,)</strong>
    Ground truth (correct) target values. Requires y_true &gt; 0.</p>
</li>
<li>
<p><strong>y_pred : array-like of shape (n_samples,)</strong>
    Estimated target values. Requires y_pred &gt; 0.</p>
</li>
<li>
<p><strong>sample_weight : array-like of shape (n_samples,), default=None</strong>
    Sample weights.</p>
</li>
</ul>
<h4>Returns</h4>
<ul>
<li><strong>loss : float</strong>
    A non-negative floating point value (the best value is 0.0).</li>
</ul>
<h4>Examples</h4>
<div class="highlight"><pre><span></span><code><span class="o">&gt;&gt;&gt;</span> <span class="kn">from</span> <span class="nn">sklearn.metrics</span> <span class="kn">import</span> <span class="n">mean_gamma_deviance</span>
<span class="o">&gt;&gt;&gt;</span> <span class="n">y_true</span> <span class="o">=</span> <span class="p">[</span><span class="mi">2</span><span class="p">,</span> <span class="mf">0.5</span><span class="p">,</span> <span class="mi">1</span><span class="p">,</span> <span class="mi">4</span><span class="p">]</span>
<span class="o">&gt;&gt;&gt;</span> <span class="n">y_pred</span> <span class="o">=</span> <span class="p">[</span><span class="mf">0.5</span><span class="p">,</span> <span class="mf">0.5</span><span class="p">,</span> <span class="mf">2.</span><span class="p">,</span> <span class="mf">2.</span><span class="p">]</span>
<span class="o">&gt;&gt;&gt;</span> <span class="n">mean_gamma_deviance</span><span class="p">(</span><span class="n">y_true</span><span class="p">,</span> <span class="n">y_pred</span><span class="p">)</span>
<span class="mf">1.0568</span><span class="o">...</span>
</code></pre></div>

</details>
<h3 id="mean_poisson_deviance">mean_poisson_deviance<a class="headerlink" href="#mean_poisson_deviance" title="Permanent link">&para;</a></h3>
<details class="note" open="open"><summary>function mean_poisson_deviance</summary><div class="highlight"><pre><span></span><code><span class="k">val</span> <span class="n">mean_poisson_deviance</span> <span class="o">:</span>
  <span class="o">?</span><span class="n">sample_weight</span><span class="o">:[&gt;`</span><span class="nc">ArrayLike</span><span class="o">]</span> <span class="nn">Np</span><span class="p">.</span><span class="nn">Obj</span><span class="p">.</span><span class="n">t</span> <span class="o">-&gt;</span>
  <span class="n">y_true</span><span class="o">:[&gt;`</span><span class="nc">ArrayLike</span><span class="o">]</span> <span class="nn">Np</span><span class="p">.</span><span class="nn">Obj</span><span class="p">.</span><span class="n">t</span> <span class="o">-&gt;</span>
  <span class="n">y_pred</span><span class="o">:[&gt;`</span><span class="nc">ArrayLike</span><span class="o">]</span> <span class="nn">Np</span><span class="p">.</span><span class="nn">Obj</span><span class="p">.</span><span class="n">t</span> <span class="o">-&gt;</span>
  <span class="kt">unit</span> <span class="o">-&gt;</span>
  <span class="kt">float</span>
</code></pre></div>

<p>Mean Poisson deviance regression loss.</p>
<p>Poisson deviance is equivalent to the Tweedie deviance with
the power parameter <code>power=1</code>.</p>
<p>Read more in the :ref:<code>User Guide &lt;mean_tweedie_deviance&gt;</code>.</p>
<h4>Parameters</h4>
<ul>
<li>
<p><strong>y_true : array-like of shape (n_samples,)</strong>
    Ground truth (correct) target values. Requires y_true &gt;= 0.</p>
</li>
<li>
<p><strong>y_pred : array-like of shape (n_samples,)</strong>
    Estimated target values. Requires y_pred &gt; 0.</p>
</li>
<li>
<p><strong>sample_weight : array-like of shape (n_samples,), default=None</strong>
    Sample weights.</p>
</li>
</ul>
<h4>Returns</h4>
<ul>
<li><strong>loss : float</strong>
    A non-negative floating point value (the best value is 0.0).</li>
</ul>
<h4>Examples</h4>
<div class="highlight"><pre><span></span><code><span class="o">&gt;&gt;&gt;</span> <span class="kn">from</span> <span class="nn">sklearn.metrics</span> <span class="kn">import</span> <span class="n">mean_poisson_deviance</span>
<span class="o">&gt;&gt;&gt;</span> <span class="n">y_true</span> <span class="o">=</span> <span class="p">[</span><span class="mi">2</span><span class="p">,</span> <span class="mi">0</span><span class="p">,</span> <span class="mi">1</span><span class="p">,</span> <span class="mi">4</span><span class="p">]</span>
<span class="o">&gt;&gt;&gt;</span> <span class="n">y_pred</span> <span class="o">=</span> <span class="p">[</span><span class="mf">0.5</span><span class="p">,</span> <span class="mf">0.5</span><span class="p">,</span> <span class="mf">2.</span><span class="p">,</span> <span class="mf">2.</span><span class="p">]</span>
<span class="o">&gt;&gt;&gt;</span> <span class="n">mean_poisson_deviance</span><span class="p">(</span><span class="n">y_true</span><span class="p">,</span> <span class="n">y_pred</span><span class="p">)</span>
<span class="mf">1.4260</span><span class="o">...</span>
</code></pre></div>

</details>
<h3 id="mean_squared_error">mean_squared_error<a class="headerlink" href="#mean_squared_error" title="Permanent link">&para;</a></h3>
<details class="note" open="open"><summary>function mean_squared_error</summary><div class="highlight"><pre><span></span><code><span class="k">val</span> <span class="n">mean_squared_error</span> <span class="o">:</span>
  <span class="o">?</span><span class="n">sample_weight</span><span class="o">:[&gt;`</span><span class="nc">ArrayLike</span><span class="o">]</span> <span class="nn">Np</span><span class="p">.</span><span class="nn">Obj</span><span class="p">.</span><span class="n">t</span> <span class="o">-&gt;</span>
  <span class="o">?</span><span class="n">multioutput</span><span class="o">:[`</span><span class="nc">Raw_values</span> <span class="o">|</span> <span class="o">`</span><span class="nc">Uniform_average</span> <span class="o">|</span> <span class="o">`</span><span class="nc">Arr</span> <span class="k">of</span> <span class="o">[&gt;`</span><span class="nc">ArrayLike</span><span class="o">]</span> <span class="nn">Np</span><span class="p">.</span><span class="nn">Obj</span><span class="p">.</span><span class="n">t</span><span class="o">]</span> <span class="o">-&gt;</span>
  <span class="o">?</span><span class="n">squared</span><span class="o">:</span><span class="kt">bool</span> <span class="o">-&gt;</span>
  <span class="n">y_true</span><span class="o">:[&gt;`</span><span class="nc">ArrayLike</span><span class="o">]</span> <span class="nn">Np</span><span class="p">.</span><span class="nn">Obj</span><span class="p">.</span><span class="n">t</span> <span class="o">-&gt;</span>
  <span class="n">y_pred</span><span class="o">:[&gt;`</span><span class="nc">ArrayLike</span><span class="o">]</span> <span class="nn">Np</span><span class="p">.</span><span class="nn">Obj</span><span class="p">.</span><span class="n">t</span> <span class="o">-&gt;</span>
  <span class="kt">unit</span> <span class="o">-&gt;</span>
  <span class="o">[&gt;`</span><span class="nc">ArrayLike</span><span class="o">]</span> <span class="nn">Np</span><span class="p">.</span><span class="nn">Obj</span><span class="p">.</span><span class="n">t</span>
</code></pre></div>

<p>Mean squared error regression loss</p>
<p>Read more in the :ref:<code>User Guide &lt;mean_squared_error&gt;</code>.</p>
<h4>Parameters</h4>
<ul>
<li>
<p><strong>y_true : array-like of shape (n_samples,) or (n_samples, n_outputs)</strong>
    Ground truth (correct) target values.</p>
</li>
<li>
<p><strong>y_pred : array-like of shape (n_samples,) or (n_samples, n_outputs)</strong>
    Estimated target values.</p>
</li>
<li>
<p><strong>sample_weight : array-like of shape (n_samples,), optional</strong>
    Sample weights.</p>
</li>
<li>
<p><strong>multioutput : string in ['raw_values', 'uniform_average']                 or array-like of shape (n_outputs)</strong>
    Defines aggregating of multiple output values.
    Array-like value defines weights used to average errors.</p>
<p>'raw_values' :
    Returns a full set of errors in case of multioutput input.</p>
<p>'uniform_average' :
    Errors of all outputs are averaged with uniform weight.</p>
</li>
<li>
<p><strong>squared : boolean value, optional (default = True)</strong>
    If True returns MSE value, if False returns RMSE value.</p>
</li>
</ul>
<h4>Returns</h4>
<ul>
<li><strong>loss : float or ndarray of floats</strong>
    A non-negative floating point value (the best value is 0.0), or an
    array of floating point values, one for each individual target.</li>
</ul>
<h4>Examples</h4>
<div class="highlight"><pre><span></span><code><span class="o">&gt;&gt;&gt;</span> <span class="kn">from</span> <span class="nn">sklearn.metrics</span> <span class="kn">import</span> <span class="n">mean_squared_error</span>
<span class="o">&gt;&gt;&gt;</span> <span class="n">y_true</span> <span class="o">=</span> <span class="p">[</span><span class="mi">3</span><span class="p">,</span> <span class="o">-</span><span class="mf">0.5</span><span class="p">,</span> <span class="mi">2</span><span class="p">,</span> <span class="mi">7</span><span class="p">]</span>
<span class="o">&gt;&gt;&gt;</span> <span class="n">y_pred</span> <span class="o">=</span> <span class="p">[</span><span class="mf">2.5</span><span class="p">,</span> <span class="mf">0.0</span><span class="p">,</span> <span class="mi">2</span><span class="p">,</span> <span class="mi">8</span><span class="p">]</span>
<span class="o">&gt;&gt;&gt;</span> <span class="n">mean_squared_error</span><span class="p">(</span><span class="n">y_true</span><span class="p">,</span> <span class="n">y_pred</span><span class="p">)</span>
<span class="mf">0.375</span>
<span class="o">&gt;&gt;&gt;</span> <span class="n">y_true</span> <span class="o">=</span> <span class="p">[</span><span class="mi">3</span><span class="p">,</span> <span class="o">-</span><span class="mf">0.5</span><span class="p">,</span> <span class="mi">2</span><span class="p">,</span> <span class="mi">7</span><span class="p">]</span>
<span class="o">&gt;&gt;&gt;</span> <span class="n">y_pred</span> <span class="o">=</span> <span class="p">[</span><span class="mf">2.5</span><span class="p">,</span> <span class="mf">0.0</span><span class="p">,</span> <span class="mi">2</span><span class="p">,</span> <span class="mi">8</span><span class="p">]</span>
<span class="o">&gt;&gt;&gt;</span> <span class="n">mean_squared_error</span><span class="p">(</span><span class="n">y_true</span><span class="p">,</span> <span class="n">y_pred</span><span class="p">,</span> <span class="n">squared</span><span class="o">=</span><span class="kc">False</span><span class="p">)</span>
<span class="mf">0.612</span><span class="o">...</span>
<span class="o">&gt;&gt;&gt;</span> <span class="n">y_true</span> <span class="o">=</span> <span class="p">[[</span><span class="mf">0.5</span><span class="p">,</span> <span class="mi">1</span><span class="p">],[</span><span class="o">-</span><span class="mi">1</span><span class="p">,</span> <span class="mi">1</span><span class="p">],[</span><span class="mi">7</span><span class="p">,</span> <span class="o">-</span><span class="mi">6</span><span class="p">]]</span>
<span class="o">&gt;&gt;&gt;</span> <span class="n">y_pred</span> <span class="o">=</span> <span class="p">[[</span><span class="mi">0</span><span class="p">,</span> <span class="mi">2</span><span class="p">],[</span><span class="o">-</span><span class="mi">1</span><span class="p">,</span> <span class="mi">2</span><span class="p">],[</span><span class="mi">8</span><span class="p">,</span> <span class="o">-</span><span class="mi">5</span><span class="p">]]</span>
<span class="o">&gt;&gt;&gt;</span> <span class="n">mean_squared_error</span><span class="p">(</span><span class="n">y_true</span><span class="p">,</span> <span class="n">y_pred</span><span class="p">)</span>
<span class="mf">0.708</span><span class="o">...</span>
<span class="o">&gt;&gt;&gt;</span> <span class="n">mean_squared_error</span><span class="p">(</span><span class="n">y_true</span><span class="p">,</span> <span class="n">y_pred</span><span class="p">,</span> <span class="n">squared</span><span class="o">=</span><span class="kc">False</span><span class="p">)</span>
<span class="mf">0.822</span><span class="o">...</span>
<span class="o">&gt;&gt;&gt;</span> <span class="n">mean_squared_error</span><span class="p">(</span><span class="n">y_true</span><span class="p">,</span> <span class="n">y_pred</span><span class="p">,</span> <span class="n">multioutput</span><span class="o">=</span><span class="s1">&#39;raw_values&#39;</span><span class="p">)</span>
<span class="n">array</span><span class="p">([</span><span class="mf">0.41666667</span><span class="p">,</span> <span class="mf">1.</span>        <span class="p">])</span>
<span class="o">&gt;&gt;&gt;</span> <span class="n">mean_squared_error</span><span class="p">(</span><span class="n">y_true</span><span class="p">,</span> <span class="n">y_pred</span><span class="p">,</span> <span class="n">multioutput</span><span class="o">=</span><span class="p">[</span><span class="mf">0.3</span><span class="p">,</span> <span class="mf">0.7</span><span class="p">])</span>
<span class="mf">0.825</span><span class="o">...</span>
</code></pre></div>

</details>
<h3 id="mean_squared_log_error">mean_squared_log_error<a class="headerlink" href="#mean_squared_log_error" title="Permanent link">&para;</a></h3>
<details class="note" open="open"><summary>function mean_squared_log_error</summary><div class="highlight"><pre><span></span><code><span class="k">val</span> <span class="n">mean_squared_log_error</span> <span class="o">:</span>
  <span class="o">?</span><span class="n">sample_weight</span><span class="o">:[&gt;`</span><span class="nc">ArrayLike</span><span class="o">]</span> <span class="nn">Np</span><span class="p">.</span><span class="nn">Obj</span><span class="p">.</span><span class="n">t</span> <span class="o">-&gt;</span>
  <span class="o">?</span><span class="n">multioutput</span><span class="o">:[`</span><span class="nc">Raw_values</span> <span class="o">|</span> <span class="o">`</span><span class="nc">Uniform_average</span> <span class="o">|</span> <span class="o">`</span><span class="nc">Arr</span> <span class="k">of</span> <span class="o">[&gt;`</span><span class="nc">ArrayLike</span><span class="o">]</span> <span class="nn">Np</span><span class="p">.</span><span class="nn">Obj</span><span class="p">.</span><span class="n">t</span><span class="o">]</span> <span class="o">-&gt;</span>
  <span class="n">y_true</span><span class="o">:[&gt;`</span><span class="nc">ArrayLike</span><span class="o">]</span> <span class="nn">Np</span><span class="p">.</span><span class="nn">Obj</span><span class="p">.</span><span class="n">t</span> <span class="o">-&gt;</span>
  <span class="n">y_pred</span><span class="o">:[&gt;`</span><span class="nc">ArrayLike</span><span class="o">]</span> <span class="nn">Np</span><span class="p">.</span><span class="nn">Obj</span><span class="p">.</span><span class="n">t</span> <span class="o">-&gt;</span>
  <span class="kt">unit</span> <span class="o">-&gt;</span>
  <span class="o">[&gt;`</span><span class="nc">ArrayLike</span><span class="o">]</span> <span class="nn">Np</span><span class="p">.</span><span class="nn">Obj</span><span class="p">.</span><span class="n">t</span>
</code></pre></div>

<p>Mean squared logarithmic error regression loss</p>
<p>Read more in the :ref:<code>User Guide &lt;mean_squared_log_error&gt;</code>.</p>
<h4>Parameters</h4>
<ul>
<li>
<p><strong>y_true : array-like of shape (n_samples,) or (n_samples, n_outputs)</strong>
    Ground truth (correct) target values.</p>
</li>
<li>
<p><strong>y_pred : array-like of shape (n_samples,) or (n_samples, n_outputs)</strong>
    Estimated target values.</p>
</li>
<li>
<p><strong>sample_weight : array-like of shape (n_samples,), optional</strong>
    Sample weights.</p>
</li>
<li>
<p><strong>multioutput : string in ['raw_values', 'uniform_average']             or array-like of shape (n_outputs)</strong></p>
<p>Defines aggregating of multiple output values.
Array-like value defines weights used to average errors.</p>
<p>'raw_values' :
    Returns a full set of errors when the input is of multioutput
    format.</p>
<p>'uniform_average' :
    Errors of all outputs are averaged with uniform weight.</p>
</li>
</ul>
<h4>Returns</h4>
<ul>
<li><strong>loss : float or ndarray of floats</strong>
    A non-negative floating point value (the best value is 0.0), or an
    array of floating point values, one for each individual target.</li>
</ul>
<h4>Examples</h4>
<div class="highlight"><pre><span></span><code><span class="o">&gt;&gt;&gt;</span> <span class="kn">from</span> <span class="nn">sklearn.metrics</span> <span class="kn">import</span> <span class="n">mean_squared_log_error</span>
<span class="o">&gt;&gt;&gt;</span> <span class="n">y_true</span> <span class="o">=</span> <span class="p">[</span><span class="mi">3</span><span class="p">,</span> <span class="mi">5</span><span class="p">,</span> <span class="mf">2.5</span><span class="p">,</span> <span class="mi">7</span><span class="p">]</span>
<span class="o">&gt;&gt;&gt;</span> <span class="n">y_pred</span> <span class="o">=</span> <span class="p">[</span><span class="mf">2.5</span><span class="p">,</span> <span class="mi">5</span><span class="p">,</span> <span class="mi">4</span><span class="p">,</span> <span class="mi">8</span><span class="p">]</span>
<span class="o">&gt;&gt;&gt;</span> <span class="n">mean_squared_log_error</span><span class="p">(</span><span class="n">y_true</span><span class="p">,</span> <span class="n">y_pred</span><span class="p">)</span>
<span class="mf">0.039</span><span class="o">...</span>
<span class="o">&gt;&gt;&gt;</span> <span class="n">y_true</span> <span class="o">=</span> <span class="p">[[</span><span class="mf">0.5</span><span class="p">,</span> <span class="mi">1</span><span class="p">],</span> <span class="p">[</span><span class="mi">1</span><span class="p">,</span> <span class="mi">2</span><span class="p">],</span> <span class="p">[</span><span class="mi">7</span><span class="p">,</span> <span class="mi">6</span><span class="p">]]</span>
<span class="o">&gt;&gt;&gt;</span> <span class="n">y_pred</span> <span class="o">=</span> <span class="p">[[</span><span class="mf">0.5</span><span class="p">,</span> <span class="mi">2</span><span class="p">],</span> <span class="p">[</span><span class="mi">1</span><span class="p">,</span> <span class="mf">2.5</span><span class="p">],</span> <span class="p">[</span><span class="mi">8</span><span class="p">,</span> <span class="mi">8</span><span class="p">]]</span>
<span class="o">&gt;&gt;&gt;</span> <span class="n">mean_squared_log_error</span><span class="p">(</span><span class="n">y_true</span><span class="p">,</span> <span class="n">y_pred</span><span class="p">)</span>
<span class="mf">0.044</span><span class="o">...</span>
<span class="o">&gt;&gt;&gt;</span> <span class="n">mean_squared_log_error</span><span class="p">(</span><span class="n">y_true</span><span class="p">,</span> <span class="n">y_pred</span><span class="p">,</span> <span class="n">multioutput</span><span class="o">=</span><span class="s1">&#39;raw_values&#39;</span><span class="p">)</span>
<span class="n">array</span><span class="p">([</span><span class="mf">0.00462428</span><span class="p">,</span> <span class="mf">0.08377444</span><span class="p">])</span>
<span class="o">&gt;&gt;&gt;</span> <span class="n">mean_squared_log_error</span><span class="p">(</span><span class="n">y_true</span><span class="p">,</span> <span class="n">y_pred</span><span class="p">,</span> <span class="n">multioutput</span><span class="o">=</span><span class="p">[</span><span class="mf">0.3</span><span class="p">,</span> <span class="mf">0.7</span><span class="p">])</span>
<span class="mf">0.060</span><span class="o">...</span>
</code></pre></div>

</details>
<h3 id="mean_tweedie_deviance">mean_tweedie_deviance<a class="headerlink" href="#mean_tweedie_deviance" title="Permanent link">&para;</a></h3>
<details class="note" open="open"><summary>function mean_tweedie_deviance</summary><div class="highlight"><pre><span></span><code><span class="k">val</span> <span class="n">mean_tweedie_deviance</span> <span class="o">:</span>
  <span class="o">?</span><span class="n">sample_weight</span><span class="o">:[&gt;`</span><span class="nc">ArrayLike</span><span class="o">]</span> <span class="nn">Np</span><span class="p">.</span><span class="nn">Obj</span><span class="p">.</span><span class="n">t</span> <span class="o">-&gt;</span>
  <span class="o">?</span><span class="n">power</span><span class="o">:</span><span class="kt">float</span> <span class="o">-&gt;</span>
  <span class="n">y_true</span><span class="o">:[&gt;`</span><span class="nc">ArrayLike</span><span class="o">]</span> <span class="nn">Np</span><span class="p">.</span><span class="nn">Obj</span><span class="p">.</span><span class="n">t</span> <span class="o">-&gt;</span>
  <span class="n">y_pred</span><span class="o">:[&gt;`</span><span class="nc">ArrayLike</span><span class="o">]</span> <span class="nn">Np</span><span class="p">.</span><span class="nn">Obj</span><span class="p">.</span><span class="n">t</span> <span class="o">-&gt;</span>
  <span class="kt">unit</span> <span class="o">-&gt;</span>
  <span class="kt">float</span>
</code></pre></div>

<p>Mean Tweedie deviance regression loss.</p>
<p>Read more in the :ref:<code>User Guide &lt;mean_tweedie_deviance&gt;</code>.</p>
<h4>Parameters</h4>
<ul>
<li>
<p><strong>y_true : array-like of shape (n_samples,)</strong>
    Ground truth (correct) target values.</p>
</li>
<li>
<p><strong>y_pred : array-like of shape (n_samples,)</strong>
    Estimated target values.</p>
</li>
<li>
<p><strong>sample_weight : array-like of shape (n_samples,), default=None</strong>
    Sample weights.</p>
</li>
<li>
<p><strong>power : float, default=0</strong>
    Tweedie power parameter. Either power &lt;= 0 or power &gt;= 1.</p>
<p>The higher <code>p</code> the less weight is given to extreme
deviations between true and predicted targets.</p>
<ul>
<li>power &lt; 0: Extreme stable distribution. Requires: y_pred &gt; 0.</li>
<li>power = 0 : Normal distribution, output corresponds to
  mean_squared_error. y_true and y_pred can be any real numbers.</li>
<li>power = 1 : Poisson distribution. Requires: y_true &gt;= 0 and
  y_pred &gt; 0.</li>
<li>1 &lt; p &lt; 2 : Compound Poisson distribution. Requires: y_true &gt;= 0
  and y_pred &gt; 0.</li>
<li>power = 2 : Gamma distribution. Requires: y_true &gt; 0 and y_pred &gt; 0.</li>
<li>power = 3 : Inverse Gaussian distribution. Requires: y_true &gt; 0
  and y_pred &gt; 0.</li>
<li>otherwise : Positive stable distribution. Requires: y_true &gt; 0
  and y_pred &gt; 0.</li>
</ul>
</li>
</ul>
<h4>Returns</h4>
<ul>
<li><strong>loss : float</strong>
    A non-negative floating point value (the best value is 0.0).</li>
</ul>
<h4>Examples</h4>
<div class="highlight"><pre><span></span><code><span class="o">&gt;&gt;&gt;</span> <span class="kn">from</span> <span class="nn">sklearn.metrics</span> <span class="kn">import</span> <span class="n">mean_tweedie_deviance</span>
<span class="o">&gt;&gt;&gt;</span> <span class="n">y_true</span> <span class="o">=</span> <span class="p">[</span><span class="mi">2</span><span class="p">,</span> <span class="mi">0</span><span class="p">,</span> <span class="mi">1</span><span class="p">,</span> <span class="mi">4</span><span class="p">]</span>
<span class="o">&gt;&gt;&gt;</span> <span class="n">y_pred</span> <span class="o">=</span> <span class="p">[</span><span class="mf">0.5</span><span class="p">,</span> <span class="mf">0.5</span><span class="p">,</span> <span class="mf">2.</span><span class="p">,</span> <span class="mf">2.</span><span class="p">]</span>
<span class="o">&gt;&gt;&gt;</span> <span class="n">mean_tweedie_deviance</span><span class="p">(</span><span class="n">y_true</span><span class="p">,</span> <span class="n">y_pred</span><span class="p">,</span> <span class="n">power</span><span class="o">=</span><span class="mi">1</span><span class="p">)</span>
<span class="mf">1.4260</span><span class="o">...</span>
</code></pre></div>

</details>
<h3 id="median_absolute_error">median_absolute_error<a class="headerlink" href="#median_absolute_error" title="Permanent link">&para;</a></h3>
<details class="note" open="open"><summary>function median_absolute_error</summary><div class="highlight"><pre><span></span><code><span class="k">val</span> <span class="n">median_absolute_error</span> <span class="o">:</span>
  <span class="o">?</span><span class="n">multioutput</span><span class="o">:[`</span><span class="nc">Arr</span> <span class="k">of</span> <span class="o">[&gt;`</span><span class="nc">ArrayLike</span><span class="o">]</span> <span class="nn">Np</span><span class="p">.</span><span class="nn">Obj</span><span class="p">.</span><span class="n">t</span> <span class="o">|</span> <span class="o">`</span><span class="nc">Uniform_average</span> <span class="o">|</span> <span class="o">`</span><span class="nc">Raw_values</span><span class="o">]</span> <span class="o">-&gt;</span>
  <span class="n">y_true</span><span class="o">:[&gt;`</span><span class="nc">ArrayLike</span><span class="o">]</span> <span class="nn">Np</span><span class="p">.</span><span class="nn">Obj</span><span class="p">.</span><span class="n">t</span> <span class="o">-&gt;</span>
  <span class="n">y_pred</span><span class="o">:[&gt;`</span><span class="nc">ArrayLike</span><span class="o">]</span> <span class="nn">Np</span><span class="p">.</span><span class="nn">Obj</span><span class="p">.</span><span class="n">t</span> <span class="o">-&gt;</span>
  <span class="kt">unit</span> <span class="o">-&gt;</span>
  <span class="o">[&gt;`</span><span class="nc">ArrayLike</span><span class="o">]</span> <span class="nn">Np</span><span class="p">.</span><span class="nn">Obj</span><span class="p">.</span><span class="n">t</span>
</code></pre></div>

<p>Median absolute error regression loss</p>
<p>Median absolute error output is non-negative floating point. The best value
is 0.0. Read more in the :ref:<code>User Guide &lt;median_absolute_error&gt;</code>.</p>
<h4>Parameters</h4>
<ul>
<li>
<p><strong>y_true : array-like of shape = (n_samples) or (n_samples, n_outputs)</strong>
    Ground truth (correct) target values.</p>
</li>
<li>
<p><strong>y_pred : array-like of shape = (n_samples) or (n_samples, n_outputs)</strong>
    Estimated target values.</p>
</li>
<li>
<p><strong>multioutput : {'raw_values', 'uniform_average'} or array-like of shape                 (n_outputs,)</strong>
    Defines aggregating of multiple output values. Array-like value defines
    weights used to average errors.</p>
<p>'raw_values' :
    Returns a full set of errors in case of multioutput input.</p>
<p>'uniform_average' :
    Errors of all outputs are averaged with uniform weight.</p>
</li>
</ul>
<h4>Returns</h4>
<ul>
<li><strong>loss : float or ndarray of floats</strong>
    If multioutput is 'raw_values', then mean absolute error is returned
    for each output separately.
    If multioutput is 'uniform_average' or an ndarray of weights, then the
    weighted average of all output errors is returned.</li>
</ul>
<h4>Examples</h4>
<div class="highlight"><pre><span></span><code><span class="o">&gt;&gt;&gt;</span> <span class="kn">from</span> <span class="nn">sklearn.metrics</span> <span class="kn">import</span> <span class="n">median_absolute_error</span>
<span class="o">&gt;&gt;&gt;</span> <span class="n">y_true</span> <span class="o">=</span> <span class="p">[</span><span class="mi">3</span><span class="p">,</span> <span class="o">-</span><span class="mf">0.5</span><span class="p">,</span> <span class="mi">2</span><span class="p">,</span> <span class="mi">7</span><span class="p">]</span>
<span class="o">&gt;&gt;&gt;</span> <span class="n">y_pred</span> <span class="o">=</span> <span class="p">[</span><span class="mf">2.5</span><span class="p">,</span> <span class="mf">0.0</span><span class="p">,</span> <span class="mi">2</span><span class="p">,</span> <span class="mi">8</span><span class="p">]</span>
<span class="o">&gt;&gt;&gt;</span> <span class="n">median_absolute_error</span><span class="p">(</span><span class="n">y_true</span><span class="p">,</span> <span class="n">y_pred</span><span class="p">)</span>
<span class="mf">0.5</span>
<span class="o">&gt;&gt;&gt;</span> <span class="n">y_true</span> <span class="o">=</span> <span class="p">[[</span><span class="mf">0.5</span><span class="p">,</span> <span class="mi">1</span><span class="p">],</span> <span class="p">[</span><span class="o">-</span><span class="mi">1</span><span class="p">,</span> <span class="mi">1</span><span class="p">],</span> <span class="p">[</span><span class="mi">7</span><span class="p">,</span> <span class="o">-</span><span class="mi">6</span><span class="p">]]</span>
<span class="o">&gt;&gt;&gt;</span> <span class="n">y_pred</span> <span class="o">=</span> <span class="p">[[</span><span class="mi">0</span><span class="p">,</span> <span class="mi">2</span><span class="p">],</span> <span class="p">[</span><span class="o">-</span><span class="mi">1</span><span class="p">,</span> <span class="mi">2</span><span class="p">],</span> <span class="p">[</span><span class="mi">8</span><span class="p">,</span> <span class="o">-</span><span class="mi">5</span><span class="p">]]</span>
<span class="o">&gt;&gt;&gt;</span> <span class="n">median_absolute_error</span><span class="p">(</span><span class="n">y_true</span><span class="p">,</span> <span class="n">y_pred</span><span class="p">)</span>
<span class="mf">0.75</span>
<span class="o">&gt;&gt;&gt;</span> <span class="n">median_absolute_error</span><span class="p">(</span><span class="n">y_true</span><span class="p">,</span> <span class="n">y_pred</span><span class="p">,</span> <span class="n">multioutput</span><span class="o">=</span><span class="s1">&#39;raw_values&#39;</span><span class="p">)</span>
<span class="n">array</span><span class="p">([</span><span class="mf">0.5</span><span class="p">,</span> <span class="mf">1.</span> <span class="p">])</span>
<span class="o">&gt;&gt;&gt;</span> <span class="n">median_absolute_error</span><span class="p">(</span><span class="n">y_true</span><span class="p">,</span> <span class="n">y_pred</span><span class="p">,</span> <span class="n">multioutput</span><span class="o">=</span><span class="p">[</span><span class="mf">0.3</span><span class="p">,</span> <span class="mf">0.7</span><span class="p">])</span>
<span class="mf">0.85</span>
</code></pre></div>

</details>
<h3 id="multilabel_confusion_matrix">multilabel_confusion_matrix<a class="headerlink" href="#multilabel_confusion_matrix" title="Permanent link">&para;</a></h3>
<details class="note" open="open"><summary>function multilabel_confusion_matrix</summary><div class="highlight"><pre><span></span><code><span class="k">val</span> <span class="n">multilabel_confusion_matrix</span> <span class="o">:</span>
  <span class="o">?</span><span class="n">sample_weight</span><span class="o">:[&gt;`</span><span class="nc">ArrayLike</span><span class="o">]</span> <span class="nn">Np</span><span class="p">.</span><span class="nn">Obj</span><span class="p">.</span><span class="n">t</span> <span class="o">-&gt;</span>
  <span class="o">?</span><span class="n">labels</span><span class="o">:[&gt;`</span><span class="nc">ArrayLike</span><span class="o">]</span> <span class="nn">Np</span><span class="p">.</span><span class="nn">Obj</span><span class="p">.</span><span class="n">t</span> <span class="o">-&gt;</span>
  <span class="o">?</span><span class="n">samplewise</span><span class="o">:</span><span class="kt">bool</span> <span class="o">-&gt;</span>
  <span class="n">y_true</span><span class="o">:[&gt;`</span><span class="nc">ArrayLike</span><span class="o">]</span> <span class="nn">Np</span><span class="p">.</span><span class="nn">Obj</span><span class="p">.</span><span class="n">t</span> <span class="o">-&gt;</span>
  <span class="n">y_pred</span><span class="o">:[&gt;`</span><span class="nc">ArrayLike</span><span class="o">]</span> <span class="nn">Np</span><span class="p">.</span><span class="nn">Obj</span><span class="p">.</span><span class="n">t</span> <span class="o">-&gt;</span>
  <span class="kt">unit</span> <span class="o">-&gt;</span>
  <span class="o">[&gt;`</span><span class="nc">ArrayLike</span><span class="o">]</span> <span class="nn">Np</span><span class="p">.</span><span class="nn">Obj</span><span class="p">.</span><span class="n">t</span>
</code></pre></div>

<p>Compute a confusion matrix for each class or sample</p>
<p>.. versionadded:: 0.21</p>
<p>Compute class-wise (default) or sample-wise (samplewise=True) multilabel
confusion matrix to evaluate the accuracy of a classification, and output
confusion matrices for each class or sample.</p>
<p>In multilabel confusion matrix :math:<code>MCM</code>, the count of true negatives</p>
<ul>
<li><strong>is :math:<code>MCM_{:,0,0}</code>, false negatives is :math:<code>MCM_{:,1,0}</code>,</strong>
true positives is :math:<code>MCM_{:,1,1}</code> and false positives is
:math:<code>MCM_{:,0,1}</code>.</li>
</ul>
<p>Multiclass data will be treated as if binarized under a one-vs-rest
transformation. Returned confusion matrices will be in the order of
sorted unique labels in the union of (y_true, y_pred).</p>
<p>Read more in the :ref:<code>User Guide &lt;multilabel_confusion_matrix&gt;</code>.</p>
<h4>Parameters</h4>
<ul>
<li>
<p><strong>y_true : 1d array-like, or label indicator array / sparse matrix</strong>
    of shape (n_samples, n_outputs) or (n_samples,)
    Ground truth (correct) target values.</p>
</li>
<li>
<p><strong>y_pred : 1d array-like, or label indicator array / sparse matrix</strong>
    of shape (n_samples, n_outputs) or (n_samples,)
    Estimated targets as returned by a classifier</p>
</li>
<li>
<p><strong>sample_weight : array-like of shape (n_samples,), default=None</strong>
    Sample weights</p>
</li>
<li>
<p><strong>labels : array-like</strong>
    A list of classes or column indices to select some (or to force
    inclusion of classes absent from the data)</p>
</li>
<li>
<p><strong>samplewise : bool, default=False</strong>
    In the multilabel case, this calculates a confusion matrix per sample</p>
</li>
</ul>
<h4>Returns</h4>
<ul>
<li><strong>multi_confusion : array, shape (n_outputs, 2, 2)</strong>
    A 2x2 confusion matrix corresponding to each output in the input.
    When calculating class-wise multi_confusion (default), then
    n_outputs = n_labels; when calculating sample-wise multi_confusion
    (samplewise=True), n_outputs = n_samples. If <code>labels</code> is defined,
    the results will be returned in the order specified in <code>labels</code>,
    otherwise the results will be returned in sorted order by default.</li>
</ul>
<h4>See also</h4>
<p>confusion_matrix</p>
<h4>Notes</h4>
<p>The multilabel_confusion_matrix calculates class-wise or sample-wise
multilabel confusion matrices, and in multiclass tasks, labels are
binarized under a one-vs-rest way; while confusion_matrix calculates
one confusion matrix for confusion between every two classes.</p>
<h4>Examples</h4>
<p>Multilabel-indicator case:</p>
<div class="highlight"><pre><span></span><code><span class="o">&gt;&gt;&gt;</span> <span class="kn">import</span> <span class="nn">numpy</span> <span class="k">as</span> <span class="nn">np</span>
<span class="o">&gt;&gt;&gt;</span> <span class="kn">from</span> <span class="nn">sklearn.metrics</span> <span class="kn">import</span> <span class="n">multilabel_confusion_matrix</span>
<span class="o">&gt;&gt;&gt;</span> <span class="n">y_true</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">array</span><span class="p">([[</span><span class="mi">1</span><span class="p">,</span> <span class="mi">0</span><span class="p">,</span> <span class="mi">1</span><span class="p">],</span>
<span class="o">...</span>                    <span class="p">[</span><span class="mi">0</span><span class="p">,</span> <span class="mi">1</span><span class="p">,</span> <span class="mi">0</span><span class="p">]])</span>
<span class="o">&gt;&gt;&gt;</span> <span class="n">y_pred</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">array</span><span class="p">([[</span><span class="mi">1</span><span class="p">,</span> <span class="mi">0</span><span class="p">,</span> <span class="mi">0</span><span class="p">],</span>
<span class="o">...</span>                    <span class="p">[</span><span class="mi">0</span><span class="p">,</span> <span class="mi">1</span><span class="p">,</span> <span class="mi">1</span><span class="p">]])</span>
<span class="o">&gt;&gt;&gt;</span> <span class="n">multilabel_confusion_matrix</span><span class="p">(</span><span class="n">y_true</span><span class="p">,</span> <span class="n">y_pred</span><span class="p">)</span>
<span class="n">array</span><span class="p">([[[</span><span class="mi">1</span><span class="p">,</span> <span class="mi">0</span><span class="p">],</span>
        <span class="p">[</span><span class="mi">0</span><span class="p">,</span> <span class="mi">1</span><span class="p">]],</span>
<span class="o">&lt;</span><span class="n">BLANKLINE</span><span class="o">&gt;</span>
       <span class="p">[[</span><span class="mi">1</span><span class="p">,</span> <span class="mi">0</span><span class="p">],</span>
        <span class="p">[</span><span class="mi">0</span><span class="p">,</span> <span class="mi">1</span><span class="p">]],</span>
<span class="o">&lt;</span><span class="n">BLANKLINE</span><span class="o">&gt;</span>
       <span class="p">[[</span><span class="mi">0</span><span class="p">,</span> <span class="mi">1</span><span class="p">],</span>
        <span class="p">[</span><span class="mi">1</span><span class="p">,</span> <span class="mi">0</span><span class="p">]]])</span>
</code></pre></div>

<p>Multiclass case:</p>
<div class="highlight"><pre><span></span><code><span class="o">&gt;&gt;&gt;</span> <span class="n">y_true</span> <span class="o">=</span> <span class="p">[</span><span class="s1">&#39;cat&#39;</span><span class="p">,</span> <span class="s1">&#39;ant&#39;</span><span class="p">,</span> <span class="s1">&#39;cat&#39;</span><span class="p">,</span> <span class="s1">&#39;cat&#39;</span><span class="p">,</span> <span class="s1">&#39;ant&#39;</span><span class="p">,</span> <span class="s1">&#39;bird&#39;</span><span class="p">]</span>
<span class="o">&gt;&gt;&gt;</span> <span class="n">y_pred</span> <span class="o">=</span> <span class="p">[</span><span class="s1">&#39;ant&#39;</span><span class="p">,</span> <span class="s1">&#39;ant&#39;</span><span class="p">,</span> <span class="s1">&#39;cat&#39;</span><span class="p">,</span> <span class="s1">&#39;cat&#39;</span><span class="p">,</span> <span class="s1">&#39;ant&#39;</span><span class="p">,</span> <span class="s1">&#39;cat&#39;</span><span class="p">]</span>
<span class="o">&gt;&gt;&gt;</span> <span class="n">multilabel_confusion_matrix</span><span class="p">(</span><span class="n">y_true</span><span class="p">,</span> <span class="n">y_pred</span><span class="p">,</span>
<span class="o">...</span>                             <span class="n">labels</span><span class="o">=</span><span class="p">[</span><span class="s1">&#39;ant&#39;</span><span class="p">,</span> <span class="s1">&#39;bird&#39;</span><span class="p">,</span> <span class="s1">&#39;cat&#39;</span><span class="p">])</span>
<span class="n">array</span><span class="p">([[[</span><span class="mi">3</span><span class="p">,</span> <span class="mi">1</span><span class="p">],</span>
        <span class="p">[</span><span class="mi">0</span><span class="p">,</span> <span class="mi">2</span><span class="p">]],</span>
<span class="o">&lt;</span><span class="n">BLANKLINE</span><span class="o">&gt;</span>
       <span class="p">[[</span><span class="mi">5</span><span class="p">,</span> <span class="mi">0</span><span class="p">],</span>
        <span class="p">[</span><span class="mi">1</span><span class="p">,</span> <span class="mi">0</span><span class="p">]],</span>
<span class="o">&lt;</span><span class="n">BLANKLINE</span><span class="o">&gt;</span>
       <span class="p">[[</span><span class="mi">2</span><span class="p">,</span> <span class="mi">1</span><span class="p">],</span>
        <span class="p">[</span><span class="mi">1</span><span class="p">,</span> <span class="mi">2</span><span class="p">]]])</span>
</code></pre></div>

</details>
<h3 id="mutual_info_score_1">mutual_info_score<a class="headerlink" href="#mutual_info_score_1" title="Permanent link">&para;</a></h3>
<details class="note" open="open"><summary>function mutual_info_score</summary><div class="highlight"><pre><span></span><code><span class="k">val</span> <span class="n">mutual_info_score</span> <span class="o">:</span>
  <span class="o">?</span><span class="n">contingency</span><span class="o">:[&gt;`</span><span class="nc">ArrayLike</span><span class="o">]</span> <span class="nn">Np</span><span class="p">.</span><span class="nn">Obj</span><span class="p">.</span><span class="n">t</span> <span class="o">-&gt;</span>
  <span class="n">labels_true</span><span class="o">:[&gt;`</span><span class="nc">ArrayLike</span><span class="o">]</span> <span class="nn">Np</span><span class="p">.</span><span class="nn">Obj</span><span class="p">.</span><span class="n">t</span> <span class="o">-&gt;</span>
  <span class="n">labels_pred</span><span class="o">:[&gt;`</span><span class="nc">ArrayLike</span><span class="o">]</span> <span class="nn">Np</span><span class="p">.</span><span class="nn">Obj</span><span class="p">.</span><span class="n">t</span> <span class="o">-&gt;</span>
  <span class="kt">unit</span> <span class="o">-&gt;</span>
  <span class="kt">float</span>
</code></pre></div>

<p>Mutual Information between two clusterings.</p>
<p>The Mutual Information is a measure of the similarity between two labels of
the same data. Where :math:<code>|U_i|</code> is the number of the samples
in cluster :math:<code>U_i</code> and :math:<code>|V_j|</code> is the number of the
samples in cluster :math:<code>V_j</code>, the Mutual Information
between clusterings :math:<code>U</code> and :math:<code>V</code> is given as:</p>
<div>
<div class="MathJax_Preview">
    MI(U,V)=\sum_{i=1}^{ |U| } \sum_{j=1}^{ |V| } \frac{ |U_i\cap V_j| }{N}
    \log\frac{N|U_i \cap V_j| }{ |U_i||V_j| }
</div>
<script type="math/tex; mode=display">
    MI(U,V)=\sum_{i=1}^{ |U| } \sum_{j=1}^{ |V| } \frac{ |U_i\cap V_j| }{N}
    \log\frac{N|U_i \cap V_j| }{ |U_i||V_j| }
</script>
</div>
<p>This metric is independent of the absolute values of the labels:
a permutation of the class or cluster label values won't change the
score value in any way.</p>
<p>This metric is furthermore symmetric: switching <code>label_true</code> with
<code>label_pred</code> will return the same score value. This can be useful to
measure the agreement of two independent label assignments strategies
on the same dataset when the real ground truth is not known.</p>
<p>Read more in the :ref:<code>User Guide &lt;mutual_info_score&gt;</code>.</p>
<h4>Parameters</h4>
<ul>
<li>
<p><strong>labels_true : int array, shape = [n_samples]</strong>
    A clustering of the data into disjoint subsets.</p>
</li>
<li>
<p><strong>labels_pred : int array-like of shape (n_samples,)</strong>
    A clustering of the data into disjoint subsets.</p>
</li>
<li>
<p><strong>contingency : {None, array, sparse matrix},                   shape = [n_classes_true, n_classes_pred]</strong>
    A contingency matrix given by the :func:<code>contingency_matrix</code> function.
    If value is <code>None</code>, it will be computed, otherwise the given value is
    used, with <code>labels_true</code> and <code>labels_pred</code> ignored.</p>
</li>
</ul>
<h4>Returns</h4>
<ul>
<li><strong>mi : float</strong>
   Mutual information, a non-negative value</li>
</ul>
<h4>Notes</h4>
<p>The logarithm used is the natural logarithm (base-e).</p>
<h4>See also</h4>
<ul>
<li>
<p><strong>adjusted_mutual_info_score: Adjusted against chance Mutual Information</strong></p>
</li>
<li>
<p><strong>normalized_mutual_info_score: Normalized Mutual Information</strong></p>
</li>
</ul>
</details>
<h3 id="nan_euclidean_distances_1">nan_euclidean_distances<a class="headerlink" href="#nan_euclidean_distances_1" title="Permanent link">&para;</a></h3>
<details class="note" open="open"><summary>function nan_euclidean_distances</summary><div class="highlight"><pre><span></span><code><span class="k">val</span> <span class="n">nan_euclidean_distances</span> <span class="o">:</span>
  <span class="o">?</span><span class="n">y</span><span class="o">:[&gt;`</span><span class="nc">ArrayLike</span><span class="o">]</span> <span class="nn">Np</span><span class="p">.</span><span class="nn">Obj</span><span class="p">.</span><span class="n">t</span> <span class="o">-&gt;</span>
  <span class="o">?</span><span class="n">squared</span><span class="o">:</span><span class="kt">bool</span> <span class="o">-&gt;</span>
  <span class="o">?</span><span class="n">missing_values</span><span class="o">:[`</span><span class="nc">Np_nan</span> <span class="k">of</span> <span class="nn">Py</span><span class="p">.</span><span class="nn">Object</span><span class="p">.</span><span class="n">t</span> <span class="o">|</span> <span class="o">`</span><span class="nc">I</span> <span class="k">of</span> <span class="kt">int</span><span class="o">]</span> <span class="o">-&gt;</span>
  <span class="o">?</span><span class="n">copy</span><span class="o">:</span><span class="kt">bool</span> <span class="o">-&gt;</span>
  <span class="n">x</span><span class="o">:[&gt;`</span><span class="nc">ArrayLike</span><span class="o">]</span> <span class="nn">Np</span><span class="p">.</span><span class="nn">Obj</span><span class="p">.</span><span class="n">t</span> <span class="o">-&gt;</span>
  <span class="kt">unit</span> <span class="o">-&gt;</span>
  <span class="o">[&gt;`</span><span class="nc">ArrayLike</span><span class="o">]</span> <span class="nn">Np</span><span class="p">.</span><span class="nn">Obj</span><span class="p">.</span><span class="n">t</span>
</code></pre></div>

<p>Calculate the euclidean distances in the presence of missing values.</p>
<p>Compute the euclidean distance between each pair of samples in X and Y,
where Y=X is assumed if Y=None. When calculating the distance between a
pair of samples, this formulation ignores feature coordinates with a
missing value in either sample and scales up the weight of the remaining
coordinates:</p>
<div class="codehilite"><pre><span></span><code>dist(x,y) = sqrt(weight * sq. distance from present coordinates)
where,
weight = Total # of coordinates / # of present coordinates
</code></pre></div>


<p>For example, the distance between <code>[3, na, na, 6]</code> and <code>[1, na, 4, 5]</code>
is:</p>
<div class="codehilite"><pre><span></span><code>.. math::
    \sqrt{\frac{4}{2}((3-1)^2 + (6-5)^2)}
</code></pre></div>


<p>If all the coordinates are missing or if there are no common present
coordinates then NaN is returned for that pair.</p>
<p>Read more in the :ref:<code>User Guide &lt;metrics&gt;</code>.</p>
<p>.. versionadded:: 0.22</p>
<h4>Parameters</h4>
<ul>
<li>
<p><strong>X : array-like, shape=(n_samples_1, n_features)</strong></p>
</li>
<li>
<p><strong>Y : array-like, shape=(n_samples_2, n_features)</strong></p>
</li>
<li>
<p><strong>squared : bool, default=False</strong>
    Return squared Euclidean distances.</p>
</li>
<li>
<p><strong>missing_values : np.nan or int, default=np.nan</strong>
    Representation of missing value</p>
</li>
<li>
<p><strong>copy : boolean, default=True</strong>
    Make and use a deep copy of X and Y (if Y exists)</p>
</li>
</ul>
<h4>Returns</h4>
<ul>
<li><strong>distances : array, shape (n_samples_1, n_samples_2)</strong></li>
</ul>
<h4>Examples</h4>
<div class="highlight"><pre><span></span><code><span class="o">&gt;&gt;&gt;</span> <span class="kn">from</span> <span class="nn">sklearn.metrics.pairwise</span> <span class="kn">import</span> <span class="n">nan_euclidean_distances</span>
<span class="o">&gt;&gt;&gt;</span> <span class="n">nan</span> <span class="o">=</span> <span class="nb">float</span><span class="p">(</span><span class="s1">&#39;NaN&#39;</span><span class="p">)</span>
<span class="o">&gt;&gt;&gt;</span> <span class="n">X</span> <span class="o">=</span> <span class="p">[[</span><span class="mi">0</span><span class="p">,</span> <span class="mi">1</span><span class="p">],</span> <span class="p">[</span><span class="mi">1</span><span class="p">,</span> <span class="n">nan</span><span class="p">]]</span>
<span class="o">&gt;&gt;&gt;</span> <span class="n">nan_euclidean_distances</span><span class="p">(</span><span class="n">X</span><span class="p">,</span> <span class="n">X</span><span class="p">)</span> <span class="c1"># distance between rows of X</span>
<span class="n">array</span><span class="p">([[</span><span class="mf">0.</span>        <span class="p">,</span> <span class="mf">1.41421356</span><span class="p">],</span>
       <span class="p">[</span><span class="mf">1.41421356</span><span class="p">,</span> <span class="mf">0.</span>        <span class="p">]])</span>
</code></pre></div>

<div class="highlight"><pre><span></span><code><span class="o">&gt;&gt;&gt;</span> <span class="c1"># get distance to origin</span>
<span class="o">&gt;&gt;&gt;</span> <span class="n">nan_euclidean_distances</span><span class="p">(</span><span class="n">X</span><span class="p">,</span> <span class="p">[[</span><span class="mi">0</span><span class="p">,</span> <span class="mi">0</span><span class="p">]])</span>
<span class="n">array</span><span class="p">([[</span><span class="mf">1.</span>        <span class="p">],</span>
       <span class="p">[</span><span class="mf">1.41421356</span><span class="p">]])</span>
</code></pre></div>

<h4>References</h4>
<ul>
<li>
<p>John K. Dixon, 'Pattern Recognition with Partly Missing Data',
  IEEE Transactions on Systems, Man, and Cybernetics, Volume: 9, Issue:
  10, pp. 617 - 621, Oct. 1979.</p>
</li>
<li>
<p><strong>http://ieeexplore.ieee.org/abstract/document/4310090/</strong></p>
</li>
</ul>
<h4>See also</h4>
<ul>
<li><strong>paired_distances : distances between pairs of elements of X and Y.</strong></li>
</ul>
</details>
<h3 id="ndcg_score">ndcg_score<a class="headerlink" href="#ndcg_score" title="Permanent link">&para;</a></h3>
<details class="note" open="open"><summary>function ndcg_score</summary><div class="highlight"><pre><span></span><code><span class="k">val</span> <span class="n">ndcg_score</span> <span class="o">:</span>
  <span class="o">?</span><span class="n">k</span><span class="o">:</span><span class="kt">int</span> <span class="o">-&gt;</span>
  <span class="o">?</span><span class="n">sample_weight</span><span class="o">:[&gt;`</span><span class="nc">ArrayLike</span><span class="o">]</span> <span class="nn">Np</span><span class="p">.</span><span class="nn">Obj</span><span class="p">.</span><span class="n">t</span> <span class="o">-&gt;</span>
  <span class="o">?</span><span class="n">ignore_ties</span><span class="o">:</span><span class="kt">bool</span> <span class="o">-&gt;</span>
  <span class="n">y_true</span><span class="o">:[&gt;`</span><span class="nc">ArrayLike</span><span class="o">]</span> <span class="nn">Np</span><span class="p">.</span><span class="nn">Obj</span><span class="p">.</span><span class="n">t</span> <span class="o">-&gt;</span>
  <span class="n">y_score</span><span class="o">:[&gt;`</span><span class="nc">ArrayLike</span><span class="o">]</span> <span class="nn">Np</span><span class="p">.</span><span class="nn">Obj</span><span class="p">.</span><span class="n">t</span> <span class="o">-&gt;</span>
  <span class="kt">unit</span> <span class="o">-&gt;</span>
  <span class="kt">float</span>
</code></pre></div>

<p>Compute Normalized Discounted Cumulative Gain.</p>
<p>Sum the true scores ranked in the order induced by the predicted scores,
after applying a logarithmic discount. Then divide by the best possible
score (Ideal DCG, obtained for a perfect ranking) to obtain a score between
0 and 1.</p>
<p>This ranking metric yields a high value if true labels are ranked high by
<code>y_score</code>.</p>
<h4>Parameters</h4>
<ul>
<li>
<p><strong>y_true : ndarray, shape (n_samples, n_labels)</strong>
    True targets of multilabel classification, or true scores of entities
    to be ranked.</p>
</li>
<li>
<p><strong>y_score : ndarray, shape (n_samples, n_labels)</strong>
    Target scores, can either be probability estimates, confidence values,
    or non-thresholded measure of decisions (as returned by
    'decision_function' on some classifiers).</p>
</li>
<li>
<p><strong>k : int, optional (default=None)</strong>
    Only consider the highest k scores in the ranking. If None, use all
    outputs.</p>
</li>
<li>
<p><strong>sample_weight : ndarray, shape (n_samples,), optional (default=None)</strong>
    Sample weights. If None, all samples are given the same weight.</p>
</li>
<li>
<p><strong>ignore_ties : bool, optional (default=False)</strong>
    Assume that there are no ties in y_score (which is likely to be the
    case if y_score is continuous) for efficiency gains.</p>
</li>
</ul>
<h4>Returns</h4>
<ul>
<li><strong>normalized_discounted_cumulative_gain : float in [0., 1.]</strong>
    The averaged NDCG scores for all samples.</li>
</ul>
<h4>See also</h4>
<ul>
<li><strong>dcg_score : Discounted Cumulative Gain (not normalized).</strong></li>
</ul>
<h4>References</h4>
<p><code>Wikipedia entry for Discounted Cumulative Gain
&lt;https://en.wikipedia.org/wiki/Discounted_cumulative_gain&gt;</code>_</p>
<p>Jarvelin, K., &amp; Kekalainen, J. (2002).
Cumulated gain-based evaluation of IR techniques. ACM Transactions on
Information Systems (TOIS), 20(4), 422-446.</p>
<p>Wang, Y., Wang, L., Li, Y., He, D., Chen, W., &amp; Liu, T. Y. (2013, May).
A theoretical analysis of NDCG ranking measures. In Proceedings of the 26th
Annual Conference on Learning Theory (COLT 2013)</p>
<p>McSherry, F., &amp; Najork, M. (2008, March). Computing information retrieval
performance measures efficiently in the presence of tied scores. In
European conference on information retrieval (pp. 414-421). Springer,
Berlin, Heidelberg.</p>
<h4>Examples</h4>
<div class="highlight"><pre><span></span><code><span class="o">&gt;&gt;&gt;</span> <span class="kn">from</span> <span class="nn">sklearn.metrics</span> <span class="kn">import</span> <span class="n">ndcg_score</span>
<span class="o">&gt;&gt;&gt;</span> <span class="c1"># we have groud-truth relevance of some answers to a query:</span>
<span class="o">&gt;&gt;&gt;</span> <span class="n">true_relevance</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">asarray</span><span class="p">([[</span><span class="mi">10</span><span class="p">,</span> <span class="mi">0</span><span class="p">,</span> <span class="mi">0</span><span class="p">,</span> <span class="mi">1</span><span class="p">,</span> <span class="mi">5</span><span class="p">]])</span>
<span class="o">&gt;&gt;&gt;</span> <span class="c1"># we predict some scores (relevance) for the answers</span>
<span class="o">&gt;&gt;&gt;</span> <span class="n">scores</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">asarray</span><span class="p">([[</span><span class="o">.</span><span class="mi">1</span><span class="p">,</span> <span class="o">.</span><span class="mi">2</span><span class="p">,</span> <span class="o">.</span><span class="mi">3</span><span class="p">,</span> <span class="mi">4</span><span class="p">,</span> <span class="mi">70</span><span class="p">]])</span>
<span class="o">&gt;&gt;&gt;</span> <span class="n">ndcg_score</span><span class="p">(</span><span class="n">true_relevance</span><span class="p">,</span> <span class="n">scores</span><span class="p">)</span>
<span class="mf">0.69</span><span class="o">...</span>
<span class="o">&gt;&gt;&gt;</span> <span class="n">scores</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">asarray</span><span class="p">([[</span><span class="o">.</span><span class="mi">05</span><span class="p">,</span> <span class="mf">1.1</span><span class="p">,</span> <span class="mf">1.</span><span class="p">,</span> <span class="o">.</span><span class="mi">5</span><span class="p">,</span> <span class="o">.</span><span class="mi">0</span><span class="p">]])</span>
<span class="o">&gt;&gt;&gt;</span> <span class="n">ndcg_score</span><span class="p">(</span><span class="n">true_relevance</span><span class="p">,</span> <span class="n">scores</span><span class="p">)</span>
<span class="mf">0.49</span><span class="o">...</span>
<span class="o">&gt;&gt;&gt;</span> <span class="c1"># we can set k to truncate the sum; only top k answers contribute.</span>
<span class="o">&gt;&gt;&gt;</span> <span class="n">ndcg_score</span><span class="p">(</span><span class="n">true_relevance</span><span class="p">,</span> <span class="n">scores</span><span class="p">,</span> <span class="n">k</span><span class="o">=</span><span class="mi">4</span><span class="p">)</span>
<span class="mf">0.35</span><span class="o">...</span>
<span class="o">&gt;&gt;&gt;</span> <span class="c1"># the normalization takes k into account so a perfect answer</span>
<span class="o">&gt;&gt;&gt;</span> <span class="c1"># would still get 1.0</span>
<span class="o">&gt;&gt;&gt;</span> <span class="n">ndcg_score</span><span class="p">(</span><span class="n">true_relevance</span><span class="p">,</span> <span class="n">true_relevance</span><span class="p">,</span> <span class="n">k</span><span class="o">=</span><span class="mi">4</span><span class="p">)</span>
<span class="mf">1.0</span>
<span class="o">&gt;&gt;&gt;</span> <span class="c1"># now we have some ties in our prediction</span>
<span class="o">&gt;&gt;&gt;</span> <span class="n">scores</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">asarray</span><span class="p">([[</span><span class="mi">1</span><span class="p">,</span> <span class="mi">0</span><span class="p">,</span> <span class="mi">0</span><span class="p">,</span> <span class="mi">0</span><span class="p">,</span> <span class="mi">1</span><span class="p">]])</span>
<span class="o">&gt;&gt;&gt;</span> <span class="c1"># by default ties are averaged, so here we get the average (normalized)</span>
<span class="o">&gt;&gt;&gt;</span> <span class="c1"># true relevance of our top predictions: (10 / 10 + 5 / 10) / 2 = .75</span>
<span class="o">&gt;&gt;&gt;</span> <span class="n">ndcg_score</span><span class="p">(</span><span class="n">true_relevance</span><span class="p">,</span> <span class="n">scores</span><span class="p">,</span> <span class="n">k</span><span class="o">=</span><span class="mi">1</span><span class="p">)</span>
<span class="mf">0.75</span>
<span class="o">&gt;&gt;&gt;</span> <span class="c1"># we can choose to ignore ties for faster results, but only</span>
<span class="o">&gt;&gt;&gt;</span> <span class="c1"># if we know there aren&#39;t ties in our scores, otherwise we get</span>
<span class="o">&gt;&gt;&gt;</span> <span class="c1"># wrong results:</span>
<span class="o">&gt;&gt;&gt;</span> <span class="n">ndcg_score</span><span class="p">(</span><span class="n">true_relevance</span><span class="p">,</span>
<span class="o">...</span>           <span class="n">scores</span><span class="p">,</span> <span class="n">k</span><span class="o">=</span><span class="mi">1</span><span class="p">,</span> <span class="n">ignore_ties</span><span class="o">=</span><span class="kc">True</span><span class="p">)</span>
<span class="mf">0.5</span>
</code></pre></div>

</details>
<h3 id="normalized_mutual_info_score_1">normalized_mutual_info_score<a class="headerlink" href="#normalized_mutual_info_score_1" title="Permanent link">&para;</a></h3>
<details class="note" open="open"><summary>function normalized_mutual_info_score</summary><div class="highlight"><pre><span></span><code><span class="k">val</span> <span class="n">normalized_mutual_info_score</span> <span class="o">:</span>
  <span class="o">?</span><span class="n">average_method</span><span class="o">:</span><span class="kt">string</span> <span class="o">-&gt;</span>
  <span class="n">labels_true</span><span class="o">:[&gt;`</span><span class="nc">ArrayLike</span><span class="o">]</span> <span class="nn">Np</span><span class="p">.</span><span class="nn">Obj</span><span class="p">.</span><span class="n">t</span> <span class="o">-&gt;</span>
  <span class="n">labels_pred</span><span class="o">:[&gt;`</span><span class="nc">ArrayLike</span><span class="o">]</span> <span class="nn">Np</span><span class="p">.</span><span class="nn">Obj</span><span class="p">.</span><span class="n">t</span> <span class="o">-&gt;</span>
  <span class="kt">unit</span> <span class="o">-&gt;</span>
  <span class="kt">float</span>
</code></pre></div>

<p>Normalized Mutual Information between two clusterings.</p>
<p>Normalized Mutual Information (NMI) is a normalization of the Mutual
Information (MI) score to scale the results between 0 (no mutual
information) and 1 (perfect correlation). In this function, mutual
information is normalized by some generalized mean of <code>H(labels_true)</code>
and <code>H(labels_pred))</code>, defined by the <code>average_method</code>.</p>
<p>This measure is not adjusted for chance. Therefore
:func:<code>adjusted_mutual_info_score</code> might be preferred.</p>
<p>This metric is independent of the absolute values of the labels:
a permutation of the class or cluster label values won't change the
score value in any way.</p>
<p>This metric is furthermore symmetric: switching <code>label_true</code> with
<code>label_pred</code> will return the same score value. This can be useful to
measure the agreement of two independent label assignments strategies
on the same dataset when the real ground truth is not known.</p>
<p>Read more in the :ref:<code>User Guide &lt;mutual_info_score&gt;</code>.</p>
<h4>Parameters</h4>
<ul>
<li>
<p><strong>labels_true : int array, shape = [n_samples]</strong>
    A clustering of the data into disjoint subsets.</p>
</li>
<li>
<p><strong>labels_pred : int array-like of shape (n_samples,)</strong>
    A clustering of the data into disjoint subsets.</p>
</li>
<li>
<p><strong>average_method : string, optional (default: 'arithmetic')</strong>
    How to compute the normalizer in the denominator. Possible options
    are 'min', 'geometric', 'arithmetic', and 'max'.</p>
<p>.. versionadded:: 0.20</p>
<p>.. versionchanged:: 0.22
   The default value of <code>average_method</code> changed from 'geometric' to
   'arithmetic'.</p>
</li>
</ul>
<h4>Returns</h4>
<ul>
<li><strong>nmi : float</strong>
   score between 0.0 and 1.0. 1.0 stands for perfectly complete labeling</li>
</ul>
<h4>See also</h4>
<ul>
<li>
<p><strong>v_measure_score: V-Measure (NMI with arithmetic mean option.)</strong></p>
</li>
<li>
<p><strong>adjusted_rand_score: Adjusted Rand Index</strong></p>
</li>
<li>
<p><strong>adjusted_mutual_info_score: Adjusted Mutual Information (adjusted</strong>
    against chance)</p>
</li>
</ul>
<h4>Examples</h4>
<p>Perfect labelings are both homogeneous and complete, hence have
score 1.0::</p>
<blockquote>
<blockquote>
<blockquote>
<p>from sklearn.metrics.cluster import normalized_mutual_info_score
normalized_mutual_info_score([0, 0, 1, 1], [0, 0, 1, 1])
  ... # doctest: +SKIP
  1.0
normalized_mutual_info_score([0, 0, 1, 1], [1, 1, 0, 0])
  ... # doctest: +SKIP
  1.0</p>
</blockquote>
</blockquote>
</blockquote>
<p>If classes members are completely split across different clusters,
the assignment is totally in-complete, hence the NMI is null::</p>
<blockquote>
<blockquote>
<blockquote>
<p>normalized_mutual_info_score([0, 0, 0, 0], [0, 1, 2, 3])
  ... # doctest: +SKIP
  0.0</p>
</blockquote>
</blockquote>
</blockquote>
</details>
<h3 id="pairwise_distances_1">pairwise_distances<a class="headerlink" href="#pairwise_distances_1" title="Permanent link">&para;</a></h3>
<details class="note" open="open"><summary>function pairwise_distances</summary><div class="highlight"><pre><span></span><code><span class="k">val</span> <span class="n">pairwise_distances</span> <span class="o">:</span>
  <span class="o">?</span><span class="n">y</span><span class="o">:[&gt;`</span><span class="nc">ArrayLike</span><span class="o">]</span> <span class="nn">Np</span><span class="p">.</span><span class="nn">Obj</span><span class="p">.</span><span class="n">t</span> <span class="o">-&gt;</span>
  <span class="o">?</span><span class="n">metric</span><span class="o">:[`</span><span class="nc">S</span> <span class="k">of</span> <span class="kt">string</span> <span class="o">|</span> <span class="o">`</span><span class="nc">Callable</span> <span class="k">of</span> <span class="nn">Py</span><span class="p">.</span><span class="nn">Object</span><span class="p">.</span><span class="n">t</span><span class="o">]</span> <span class="o">-&gt;</span>
  <span class="o">?</span><span class="n">n_jobs</span><span class="o">:</span><span class="kt">int</span> <span class="o">-&gt;</span>
  <span class="o">?</span><span class="n">force_all_finite</span><span class="o">:[`</span><span class="nc">Allow_nan</span> <span class="o">|</span> <span class="o">`</span><span class="nc">Bool</span> <span class="k">of</span> <span class="kt">bool</span><span class="o">]</span> <span class="o">-&gt;</span>
  <span class="o">?</span><span class="n">kwds</span><span class="o">:(</span><span class="kt">string</span> <span class="o">*</span> <span class="nn">Py</span><span class="p">.</span><span class="nn">Object</span><span class="p">.</span><span class="n">t</span><span class="o">)</span> <span class="kt">list</span> <span class="o">-&gt;</span>
  <span class="n">x</span><span class="o">:[`</span><span class="nc">Arr</span> <span class="k">of</span> <span class="o">[&gt;`</span><span class="nc">ArrayLike</span><span class="o">]</span> <span class="nn">Np</span><span class="p">.</span><span class="nn">Obj</span><span class="p">.</span><span class="n">t</span> <span class="o">|</span> <span class="o">`</span><span class="nc">Otherwise</span> <span class="k">of</span> <span class="nn">Py</span><span class="p">.</span><span class="nn">Object</span><span class="p">.</span><span class="n">t</span><span class="o">]</span> <span class="o">-&gt;</span>
  <span class="kt">unit</span> <span class="o">-&gt;</span>
  <span class="o">[&gt;`</span><span class="nc">ArrayLike</span><span class="o">]</span> <span class="nn">Np</span><span class="p">.</span><span class="nn">Obj</span><span class="p">.</span><span class="n">t</span>
</code></pre></div>

<p>Compute the distance matrix from a vector array X and optional Y.</p>
<p>This method takes either a vector array or a distance matrix, and returns
a distance matrix. If the input is a vector array, the distances are
computed. If the input is a distances matrix, it is returned instead.</p>
<p>This method provides a safe way to take a distance matrix as input, while
preserving compatibility with many other algorithms that take a vector
array.</p>
<p>If Y is given (default is None), then the returned matrix is the pairwise
distance between the arrays from both X and Y.</p>
<p>Valid values for metric are:</p>
<ul>
<li>
<p>From scikit-learn: ['cityblock', 'cosine', 'euclidean', 'l1', 'l2',
  'manhattan']. These metrics support sparse matrix
  inputs.
  ['nan_euclidean'] but it does not yet support sparse matrices.</p>
</li>
<li>
<p>From scipy.spatial.distance: ['braycurtis', 'canberra', 'chebyshev',
  'correlation', 'dice', 'hamming', 'jaccard', 'kulsinski', 'mahalanobis',
  'minkowski', 'rogerstanimoto', 'russellrao', 'seuclidean',
  'sokalmichener', 'sokalsneath', 'sqeuclidean', 'yule']
  See the documentation for scipy.spatial.distance for details on these
  metrics. These metrics do not support sparse matrix inputs.</p>
</li>
</ul>
<p>Note that in the case of 'cityblock', 'cosine' and 'euclidean' (which are
valid scipy.spatial.distance metrics), the scikit-learn implementation
will be used, which is faster and has support for sparse matrices (except
for 'cityblock'). For a verbose description of the metrics from
scikit-learn, see the <strong>doc</strong> of the sklearn.pairwise.distance_metrics
function.</p>
<p>Read more in the :ref:<code>User Guide &lt;metrics&gt;</code>.</p>
<h4>Parameters</h4>
<ul>
<li>
<p><strong>X : array [n_samples_a, n_samples_a] if metric == 'precomputed', or,              [n_samples_a, n_features] otherwise</strong>
    Array of pairwise distances between samples, or a feature array.</p>
</li>
<li>
<p><strong>Y : array [n_samples_b, n_features], optional</strong>
    An optional second feature array. Only allowed if
    metric != 'precomputed'.</p>
</li>
<li>
<p><strong>metric : string, or callable</strong>
    The metric to use when calculating distance between instances in a
    feature array. If metric is a string, it must be one of the options
    allowed by scipy.spatial.distance.pdist for its metric parameter, or
    a metric listed in pairwise.PAIRWISE_DISTANCE_FUNCTIONS.
    If metric is 'precomputed', X is assumed to be a distance matrix.
    Alternatively, if metric is a callable function, it is called on each
    pair of instances (rows) and the resulting value recorded. The callable
    should take two arrays from X as input and return a value indicating
    the distance between them.</p>
</li>
<li>
<p><strong>n_jobs : int or None, optional (default=None)</strong>
    The number of jobs to use for the computation. This works by breaking
    down the pairwise matrix into n_jobs even slices and computing them in
    parallel.</p>
<p><code>None</code> means 1 unless in a :obj:<code>joblib.parallel_backend</code> context.
<code>-1</code> means using all processors. See :term:<code>Glossary &lt;n_jobs&gt;</code>
for more details.</p>
</li>
<li>
<p><strong>force_all_finite : boolean or 'allow-nan', (default=True)</strong>
    Whether to raise an error on np.inf, np.nan, pd.NA in array. The
    possibilities are:</p>
<ul>
<li>True: Force all values of array to be finite.</li>
<li>False: accepts np.inf, np.nan, pd.NA in array.</li>
<li>'allow-nan': accepts only np.nan and pd.NA values in array. Values
  cannot be infinite.</li>
</ul>
<p>.. versionadded:: 0.22
   <code>force_all_finite</code> accepts the string <code>'allow-nan'</code>.</p>
<p>.. versionchanged:: 0.23
   Accepts <code>pd.NA</code> and converts it into <code>np.nan</code></p>
</li>
<li>
<p><strong>**kwds : optional keyword parameters</strong>
    Any further parameters are passed directly to the distance function.
    If using a scipy.spatial.distance metric, the parameters are still
    metric dependent. See the scipy docs for usage examples.</p>
</li>
</ul>
<h4>Returns</h4>
<ul>
<li><strong>D : array [n_samples_a, n_samples_a] or [n_samples_a, n_samples_b]</strong>
    A distance matrix D such that D_{i, j} is the distance between the
    ith and jth vectors of the given matrix X, if Y is None.
    If Y is not None, then D_{i, j} is the distance between the ith array
    from X and the jth array from Y.</li>
</ul>
<h4>See also</h4>
<ul>
<li>
<p><strong>pairwise_distances_chunked : performs the same calculation as this</strong>
    function, but returns a generator of chunks of the distance matrix, in
    order to limit memory usage.</p>
</li>
<li>
<p><strong>paired_distances : Computes the distances between corresponding</strong>
                   elements of two arrays</p>
</li>
</ul>
</details>
<h3 id="pairwise_distances_argmin_1">pairwise_distances_argmin<a class="headerlink" href="#pairwise_distances_argmin_1" title="Permanent link">&para;</a></h3>
<details class="note" open="open"><summary>function pairwise_distances_argmin</summary><div class="highlight"><pre><span></span><code><span class="k">val</span> <span class="n">pairwise_distances_argmin</span> <span class="o">:</span>
  <span class="o">?</span><span class="n">axis</span><span class="o">:</span><span class="kt">int</span> <span class="o">-&gt;</span>
  <span class="o">?</span><span class="n">metric</span><span class="o">:[`</span><span class="nc">S</span> <span class="k">of</span> <span class="kt">string</span> <span class="o">|</span> <span class="o">`</span><span class="nc">Callable</span> <span class="k">of</span> <span class="nn">Py</span><span class="p">.</span><span class="nn">Object</span><span class="p">.</span><span class="n">t</span><span class="o">]</span> <span class="o">-&gt;</span>
  <span class="o">?</span><span class="n">metric_kwargs</span><span class="o">:</span><span class="nn">Dict</span><span class="p">.</span><span class="n">t</span> <span class="o">-&gt;</span>
  <span class="n">x</span><span class="o">:[&gt;`</span><span class="nc">ArrayLike</span><span class="o">]</span> <span class="nn">Np</span><span class="p">.</span><span class="nn">Obj</span><span class="p">.</span><span class="n">t</span> <span class="o">-&gt;</span>
  <span class="n">y</span><span class="o">:[&gt;`</span><span class="nc">ArrayLike</span><span class="o">]</span> <span class="nn">Np</span><span class="p">.</span><span class="nn">Obj</span><span class="p">.</span><span class="n">t</span> <span class="o">-&gt;</span>
  <span class="kt">unit</span> <span class="o">-&gt;</span>
  <span class="o">[&gt;`</span><span class="nc">ArrayLike</span><span class="o">]</span> <span class="nn">Np</span><span class="p">.</span><span class="nn">Obj</span><span class="p">.</span><span class="n">t</span>
</code></pre></div>

<p>Compute minimum distances between one point and a set of points.</p>
<p>This function computes for each row in X, the index of the row of Y which
is closest (according to the specified distance).</p>
<p>This is mostly equivalent to calling:</p>
<div class="codehilite"><pre><span></span><code>pairwise_distances(X, Y=Y, metric=metric).argmin(axis=axis)
</code></pre></div>


<p>but uses much less memory, and is faster for large arrays.</p>
<p>This function works with dense 2D arrays only.</p>
<h4>Parameters</h4>
<ul>
<li>
<p><strong>X : array-like</strong>
    Arrays containing points. Respective shapes (n_samples1, n_features)
    and (n_samples2, n_features)</p>
</li>
<li>
<p><strong>Y : array-like</strong>
    Arrays containing points. Respective shapes (n_samples1, n_features)
    and (n_samples2, n_features)</p>
</li>
<li>
<p><strong>axis : int, optional, default 1</strong>
    Axis along which the argmin and distances are to be computed.</p>
</li>
<li>
<p><strong>metric : string or callable</strong>
    metric to use for distance computation. Any metric from scikit-learn
    or scipy.spatial.distance can be used.</p>
<p>If metric is a callable function, it is called on each
pair of instances (rows) and the resulting value recorded. The callable
should take two arrays as input and return one value indicating the
distance between them. This works for Scipy's metrics, but is less
efficient than passing the metric name as a string.</p>
<p>Distance matrices are not supported.</p>
<p>Valid values for metric are:</p>
<ul>
<li>
<p>from scikit-learn: ['cityblock', 'cosine', 'euclidean', 'l1', 'l2',
  'manhattan']</p>
</li>
<li>
<p>from scipy.spatial.distance: ['braycurtis', 'canberra', 'chebyshev',
  'correlation', 'dice', 'hamming', 'jaccard', 'kulsinski',
  'mahalanobis', 'minkowski', 'rogerstanimoto', 'russellrao',
  'seuclidean', 'sokalmichener', 'sokalsneath', 'sqeuclidean',
  'yule']</p>
</li>
</ul>
<p>See the documentation for scipy.spatial.distance for details on these
metrics.</p>
</li>
<li>
<p><strong>metric_kwargs : dict</strong>
    keyword arguments to pass to specified metric function.</p>
</li>
</ul>
<h4>Returns</h4>
<ul>
<li>
<p><strong>argmin : numpy.ndarray</strong></p>
</li>
<li>
<p><strong>Y[argmin[i], :] is the row in Y that is closest to X[i, :].</strong></p>
</li>
</ul>
<h4>See also</h4>
<p>sklearn.metrics.pairwise_distances
sklearn.metrics.pairwise_distances_argmin_min</p>
</details>
<h3 id="pairwise_distances_argmin_min_1">pairwise_distances_argmin_min<a class="headerlink" href="#pairwise_distances_argmin_min_1" title="Permanent link">&para;</a></h3>
<details class="note" open="open"><summary>function pairwise_distances_argmin_min</summary><div class="highlight"><pre><span></span><code><span class="k">val</span> <span class="n">pairwise_distances_argmin_min</span> <span class="o">:</span>
  <span class="o">?</span><span class="n">axis</span><span class="o">:</span><span class="kt">int</span> <span class="o">-&gt;</span>
  <span class="o">?</span><span class="n">metric</span><span class="o">:[`</span><span class="nc">S</span> <span class="k">of</span> <span class="kt">string</span> <span class="o">|</span> <span class="o">`</span><span class="nc">Callable</span> <span class="k">of</span> <span class="nn">Py</span><span class="p">.</span><span class="nn">Object</span><span class="p">.</span><span class="n">t</span><span class="o">]</span> <span class="o">-&gt;</span>
  <span class="o">?</span><span class="n">metric_kwargs</span><span class="o">:</span><span class="nn">Dict</span><span class="p">.</span><span class="n">t</span> <span class="o">-&gt;</span>
  <span class="n">x</span><span class="o">:[&gt;`</span><span class="nc">ArrayLike</span><span class="o">]</span> <span class="nn">Np</span><span class="p">.</span><span class="nn">Obj</span><span class="p">.</span><span class="n">t</span> <span class="o">-&gt;</span>
  <span class="n">y</span><span class="o">:[&gt;`</span><span class="nc">ArrayLike</span><span class="o">]</span> <span class="nn">Np</span><span class="p">.</span><span class="nn">Obj</span><span class="p">.</span><span class="n">t</span> <span class="o">-&gt;</span>
  <span class="kt">unit</span> <span class="o">-&gt;</span>
  <span class="o">([&gt;`</span><span class="nc">ArrayLike</span><span class="o">]</span> <span class="nn">Np</span><span class="p">.</span><span class="nn">Obj</span><span class="p">.</span><span class="n">t</span> <span class="o">*</span> <span class="o">[&gt;`</span><span class="nc">ArrayLike</span><span class="o">]</span> <span class="nn">Np</span><span class="p">.</span><span class="nn">Obj</span><span class="p">.</span><span class="n">t</span><span class="o">)</span>
</code></pre></div>

<p>Compute minimum distances between one point and a set of points.</p>
<p>This function computes for each row in X, the index of the row of Y which
is closest (according to the specified distance). The minimal distances are
also returned.</p>
<p>This is mostly equivalent to calling:</p>
<div class="codehilite"><pre><span></span><code>(pairwise_distances(X, Y=Y, metric=metric).argmin(axis=axis),
 pairwise_distances(X, Y=Y, metric=metric).min(axis=axis))
</code></pre></div>


<p>but uses much less memory, and is faster for large arrays.</p>
<h4>Parameters</h4>
<ul>
<li>
<p><strong>X : {array-like, sparse matrix}, shape (n_samples1, n_features)</strong>
    Array containing points.</p>
</li>
<li>
<p><strong>Y : {array-like, sparse matrix}, shape (n_samples2, n_features)</strong>
    Arrays containing points.</p>
</li>
<li>
<p><strong>axis : int, optional, default 1</strong>
    Axis along which the argmin and distances are to be computed.</p>
</li>
<li>
<p><strong>metric : string or callable, default 'euclidean'</strong>
    metric to use for distance computation. Any metric from scikit-learn
    or scipy.spatial.distance can be used.</p>
<p>If metric is a callable function, it is called on each
pair of instances (rows) and the resulting value recorded. The callable
should take two arrays as input and return one value indicating the
distance between them. This works for Scipy's metrics, but is less
efficient than passing the metric name as a string.</p>
<p>Distance matrices are not supported.</p>
<p>Valid values for metric are:</p>
<ul>
<li>
<p>from scikit-learn: ['cityblock', 'cosine', 'euclidean', 'l1', 'l2',
  'manhattan']</p>
</li>
<li>
<p>from scipy.spatial.distance: ['braycurtis', 'canberra', 'chebyshev',
  'correlation', 'dice', 'hamming', 'jaccard', 'kulsinski',
  'mahalanobis', 'minkowski', 'rogerstanimoto', 'russellrao',
  'seuclidean', 'sokalmichener', 'sokalsneath', 'sqeuclidean',
  'yule']</p>
</li>
</ul>
<p>See the documentation for scipy.spatial.distance for details on these
metrics.</p>
</li>
<li>
<p><strong>metric_kwargs : dict, optional</strong>
    Keyword arguments to pass to specified metric function.</p>
</li>
</ul>
<h4>Returns</h4>
<ul>
<li>
<p><strong>argmin : numpy.ndarray</strong></p>
</li>
<li>
<p><strong>Y[argmin[i], :] is the row in Y that is closest to X[i, :].</strong></p>
</li>
<li>
<p><strong>distances : numpy.ndarray</strong>
    distances[i] is the distance between the i-th row in X and the
    argmin[i]-th row in Y.</p>
</li>
</ul>
<h4>See also</h4>
<p>sklearn.metrics.pairwise_distances
sklearn.metrics.pairwise_distances_argmin</p>
</details>
<h3 id="pairwise_distances_chunked_1">pairwise_distances_chunked<a class="headerlink" href="#pairwise_distances_chunked_1" title="Permanent link">&para;</a></h3>
<details class="note" open="open"><summary>function pairwise_distances_chunked</summary><div class="highlight"><pre><span></span><code><span class="k">val</span> <span class="n">pairwise_distances_chunked</span> <span class="o">:</span>
  <span class="o">?</span><span class="n">y</span><span class="o">:[&gt;`</span><span class="nc">ArrayLike</span><span class="o">]</span> <span class="nn">Np</span><span class="p">.</span><span class="nn">Obj</span><span class="p">.</span><span class="n">t</span> <span class="o">-&gt;</span>
  <span class="o">?</span><span class="n">reduce_func</span><span class="o">:</span><span class="nn">Py</span><span class="p">.</span><span class="nn">Object</span><span class="p">.</span><span class="n">t</span> <span class="o">-&gt;</span>
  <span class="o">?</span><span class="n">metric</span><span class="o">:[`</span><span class="nc">S</span> <span class="k">of</span> <span class="kt">string</span> <span class="o">|</span> <span class="o">`</span><span class="nc">Callable</span> <span class="k">of</span> <span class="nn">Py</span><span class="p">.</span><span class="nn">Object</span><span class="p">.</span><span class="n">t</span><span class="o">]</span> <span class="o">-&gt;</span>
  <span class="o">?</span><span class="n">n_jobs</span><span class="o">:</span><span class="kt">int</span> <span class="o">-&gt;</span>
  <span class="o">?</span><span class="n">working_memory</span><span class="o">:</span><span class="kt">int</span> <span class="o">-&gt;</span>
  <span class="o">?</span><span class="n">kwds</span><span class="o">:(</span><span class="kt">string</span> <span class="o">*</span> <span class="nn">Py</span><span class="p">.</span><span class="nn">Object</span><span class="p">.</span><span class="n">t</span><span class="o">)</span> <span class="kt">list</span> <span class="o">-&gt;</span>
  <span class="n">x</span><span class="o">:[&gt;`</span><span class="nc">ArrayLike</span><span class="o">]</span> <span class="nn">Np</span><span class="p">.</span><span class="nn">Obj</span><span class="p">.</span><span class="n">t</span> <span class="o">-&gt;</span>
  <span class="kt">unit</span> <span class="o">-&gt;</span>
  <span class="o">[&gt;`</span><span class="nc">ArrayLike</span><span class="o">]</span> <span class="nn">Np</span><span class="p">.</span><span class="nn">Obj</span><span class="p">.</span><span class="n">t</span> <span class="nn">Seq</span><span class="p">.</span><span class="n">t</span>
</code></pre></div>

<p>Generate a distance matrix chunk by chunk with optional reduction</p>
<p>In cases where not all of a pairwise distance matrix needs to be stored at
once, this is used to calculate pairwise distances in
<code>working_memory</code>-sized chunks.  If <code>reduce_func</code> is given, it is run
on each chunk and its return values are concatenated into lists, arrays
or sparse matrices.</p>
<h4>Parameters</h4>
<ul>
<li>
<p><strong>X : array [n_samples_a, n_samples_a] if metric == 'precomputed', or,</strong>
    [n_samples_a, n_features] otherwise
    Array of pairwise distances between samples, or a feature array.</p>
</li>
<li>
<p><strong>Y : array [n_samples_b, n_features], optional</strong>
    An optional second feature array. Only allowed if
    metric != 'precomputed'.</p>
</li>
<li>
<p><strong>reduce_func : callable, optional</strong>
    The function which is applied on each chunk of the distance matrix,
    reducing it to needed values.  <code>reduce_func(D_chunk, start)</code>
    is called repeatedly, where <code>D_chunk</code> is a contiguous vertical
    slice of the pairwise distance matrix, starting at row <code>start</code>.
    It should return one of: None; an array, a list, or a sparse matrix
    of length <code>D_chunk.shape[0]</code>; or a tuple of such objects. Returning
    None is useful for in-place operations, rather than reductions.</p>
<p>If None, pairwise_distances_chunked returns a generator of vertical
chunks of the distance matrix.</p>
</li>
<li>
<p><strong>metric : string, or callable</strong>
    The metric to use when calculating distance between instances in a
    feature array. If metric is a string, it must be one of the options
    allowed by scipy.spatial.distance.pdist for its metric parameter, or
    a metric listed in pairwise.PAIRWISE_DISTANCE_FUNCTIONS.
    If metric is 'precomputed', X is assumed to be a distance matrix.
    Alternatively, if metric is a callable function, it is called on each
    pair of instances (rows) and the resulting value recorded. The callable
    should take two arrays from X as input and return a value indicating
    the distance between them.</p>
</li>
<li>
<p><strong>n_jobs : int or None, optional (default=None)</strong>
    The number of jobs to use for the computation. This works by breaking
    down the pairwise matrix into n_jobs even slices and computing them in
    parallel.</p>
<p><code>None</code> means 1 unless in a :obj:<code>joblib.parallel_backend</code> context.
<code>-1</code> means using all processors. See :term:<code>Glossary &lt;n_jobs&gt;</code>
for more details.</p>
</li>
<li>
<p><strong>working_memory : int, optional</strong>
    The sought maximum memory for temporary distance matrix chunks.
    When None (default), the value of
    <code>sklearn.get_config()['working_memory']</code> is used.</p>
</li>
</ul>
<p><code>**kwds</code> : optional keyword parameters
    Any further parameters are passed directly to the distance function.
    If using a scipy.spatial.distance metric, the parameters are still
    metric dependent. See the scipy docs for usage examples.</p>
<h4>Yields</h4>
<ul>
<li><strong>D_chunk : array or sparse matrix</strong>
    A contiguous slice of distance matrix, optionally processed by
    <code>reduce_func</code>.</li>
</ul>
<h4>Examples</h4>
<p>Without reduce_func:</p>
<div class="highlight"><pre><span></span><code><span class="o">&gt;&gt;&gt;</span> <span class="kn">import</span> <span class="nn">numpy</span> <span class="k">as</span> <span class="nn">np</span>
<span class="o">&gt;&gt;&gt;</span> <span class="kn">from</span> <span class="nn">sklearn.metrics</span> <span class="kn">import</span> <span class="n">pairwise_distances_chunked</span>
<span class="o">&gt;&gt;&gt;</span> <span class="n">X</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">random</span><span class="o">.</span><span class="n">RandomState</span><span class="p">(</span><span class="mi">0</span><span class="p">)</span><span class="o">.</span><span class="n">rand</span><span class="p">(</span><span class="mi">5</span><span class="p">,</span> <span class="mi">3</span><span class="p">)</span>
<span class="o">&gt;&gt;&gt;</span> <span class="n">D_chunk</span> <span class="o">=</span> <span class="nb">next</span><span class="p">(</span><span class="n">pairwise_distances_chunked</span><span class="p">(</span><span class="n">X</span><span class="p">))</span>
<span class="o">&gt;&gt;&gt;</span> <span class="n">D_chunk</span>
<span class="n">array</span><span class="p">([[</span><span class="mf">0.</span>  <span class="o">...</span><span class="p">,</span> <span class="mf">0.29</span><span class="o">...</span><span class="p">,</span> <span class="mf">0.41</span><span class="o">...</span><span class="p">,</span> <span class="mf">0.19</span><span class="o">...</span><span class="p">,</span> <span class="mf">0.57</span><span class="o">...</span><span class="p">],</span>
       <span class="p">[</span><span class="mf">0.29</span><span class="o">...</span><span class="p">,</span> <span class="mf">0.</span>  <span class="o">...</span><span class="p">,</span> <span class="mf">0.57</span><span class="o">...</span><span class="p">,</span> <span class="mf">0.41</span><span class="o">...</span><span class="p">,</span> <span class="mf">0.76</span><span class="o">...</span><span class="p">],</span>
       <span class="p">[</span><span class="mf">0.41</span><span class="o">...</span><span class="p">,</span> <span class="mf">0.57</span><span class="o">...</span><span class="p">,</span> <span class="mf">0.</span>  <span class="o">...</span><span class="p">,</span> <span class="mf">0.44</span><span class="o">...</span><span class="p">,</span> <span class="mf">0.90</span><span class="o">...</span><span class="p">],</span>
       <span class="p">[</span><span class="mf">0.19</span><span class="o">...</span><span class="p">,</span> <span class="mf">0.41</span><span class="o">...</span><span class="p">,</span> <span class="mf">0.44</span><span class="o">...</span><span class="p">,</span> <span class="mf">0.</span>  <span class="o">...</span><span class="p">,</span> <span class="mf">0.51</span><span class="o">...</span><span class="p">],</span>
       <span class="p">[</span><span class="mf">0.57</span><span class="o">...</span><span class="p">,</span> <span class="mf">0.76</span><span class="o">...</span><span class="p">,</span> <span class="mf">0.90</span><span class="o">...</span><span class="p">,</span> <span class="mf">0.51</span><span class="o">...</span><span class="p">,</span> <span class="mf">0.</span>  <span class="o">...</span><span class="p">]])</span>
</code></pre></div>

<p>Retrieve all neighbors and average distance within radius r:</p>
<div class="highlight"><pre><span></span><code><span class="o">&gt;&gt;&gt;</span> <span class="n">r</span> <span class="o">=</span> <span class="o">.</span><span class="mi">2</span>
<span class="o">&gt;&gt;&gt;</span> <span class="k">def</span> <span class="nf">reduce_func</span><span class="p">(</span><span class="n">D_chunk</span><span class="p">,</span> <span class="n">start</span><span class="p">):</span>
<span class="o">...</span>     <span class="n">neigh</span> <span class="o">=</span> <span class="p">[</span><span class="n">np</span><span class="o">.</span><span class="n">flatnonzero</span><span class="p">(</span><span class="n">d</span> <span class="o">&lt;</span> <span class="n">r</span><span class="p">)</span> <span class="k">for</span> <span class="n">d</span> <span class="ow">in</span> <span class="n">D_chunk</span><span class="p">]</span>
<span class="o">...</span>     <span class="n">avg_dist</span> <span class="o">=</span> <span class="p">(</span><span class="n">D_chunk</span> <span class="o">*</span> <span class="p">(</span><span class="n">D_chunk</span> <span class="o">&lt;</span> <span class="n">r</span><span class="p">))</span><span class="o">.</span><span class="n">mean</span><span class="p">(</span><span class="n">axis</span><span class="o">=</span><span class="mi">1</span><span class="p">)</span>
<span class="o">...</span>     <span class="k">return</span> <span class="n">neigh</span><span class="p">,</span> <span class="n">avg_dist</span>
<span class="o">&gt;&gt;&gt;</span> <span class="n">gen</span> <span class="o">=</span> <span class="n">pairwise_distances_chunked</span><span class="p">(</span><span class="n">X</span><span class="p">,</span> <span class="n">reduce_func</span><span class="o">=</span><span class="n">reduce_func</span><span class="p">)</span>
<span class="o">&gt;&gt;&gt;</span> <span class="n">neigh</span><span class="p">,</span> <span class="n">avg_dist</span> <span class="o">=</span> <span class="nb">next</span><span class="p">(</span><span class="n">gen</span><span class="p">)</span>
<span class="o">&gt;&gt;&gt;</span> <span class="n">neigh</span>
<span class="p">[</span><span class="n">array</span><span class="p">([</span><span class="mi">0</span><span class="p">,</span> <span class="mi">3</span><span class="p">]),</span> <span class="n">array</span><span class="p">([</span><span class="mi">1</span><span class="p">]),</span> <span class="n">array</span><span class="p">([</span><span class="mi">2</span><span class="p">]),</span> <span class="n">array</span><span class="p">([</span><span class="mi">0</span><span class="p">,</span> <span class="mi">3</span><span class="p">]),</span> <span class="n">array</span><span class="p">([</span><span class="mi">4</span><span class="p">])]</span>
<span class="o">&gt;&gt;&gt;</span> <span class="n">avg_dist</span>
<span class="n">array</span><span class="p">([</span><span class="mf">0.039</span><span class="o">...</span><span class="p">,</span> <span class="mf">0.</span>        <span class="p">,</span> <span class="mf">0.</span>        <span class="p">,</span> <span class="mf">0.039</span><span class="o">...</span><span class="p">,</span> <span class="mf">0.</span>        <span class="p">])</span>
</code></pre></div>

<p>Where r is defined per sample, we need to make use of <code>start</code>:</p>
<div class="highlight"><pre><span></span><code><span class="o">&gt;&gt;&gt;</span> <span class="n">r</span> <span class="o">=</span> <span class="p">[</span><span class="o">.</span><span class="mi">2</span><span class="p">,</span> <span class="o">.</span><span class="mi">4</span><span class="p">,</span> <span class="o">.</span><span class="mi">4</span><span class="p">,</span> <span class="o">.</span><span class="mi">3</span><span class="p">,</span> <span class="o">.</span><span class="mi">1</span><span class="p">]</span>
<span class="o">&gt;&gt;&gt;</span> <span class="k">def</span> <span class="nf">reduce_func</span><span class="p">(</span><span class="n">D_chunk</span><span class="p">,</span> <span class="n">start</span><span class="p">):</span>
<span class="o">...</span>     <span class="n">neigh</span> <span class="o">=</span> <span class="p">[</span><span class="n">np</span><span class="o">.</span><span class="n">flatnonzero</span><span class="p">(</span><span class="n">d</span> <span class="o">&lt;</span> <span class="n">r</span><span class="p">[</span><span class="n">i</span><span class="p">])</span>
<span class="o">...</span>              <span class="k">for</span> <span class="n">i</span><span class="p">,</span> <span class="n">d</span> <span class="ow">in</span> <span class="nb">enumerate</span><span class="p">(</span><span class="n">D_chunk</span><span class="p">,</span> <span class="n">start</span><span class="p">)]</span>
<span class="o">...</span>     <span class="k">return</span> <span class="n">neigh</span>
<span class="o">&gt;&gt;&gt;</span> <span class="n">neigh</span> <span class="o">=</span> <span class="nb">next</span><span class="p">(</span><span class="n">pairwise_distances_chunked</span><span class="p">(</span><span class="n">X</span><span class="p">,</span> <span class="n">reduce_func</span><span class="o">=</span><span class="n">reduce_func</span><span class="p">))</span>
<span class="o">&gt;&gt;&gt;</span> <span class="n">neigh</span>
<span class="p">[</span><span class="n">array</span><span class="p">([</span><span class="mi">0</span><span class="p">,</span> <span class="mi">3</span><span class="p">]),</span> <span class="n">array</span><span class="p">([</span><span class="mi">0</span><span class="p">,</span> <span class="mi">1</span><span class="p">]),</span> <span class="n">array</span><span class="p">([</span><span class="mi">2</span><span class="p">]),</span> <span class="n">array</span><span class="p">([</span><span class="mi">0</span><span class="p">,</span> <span class="mi">3</span><span class="p">]),</span> <span class="n">array</span><span class="p">([</span><span class="mi">4</span><span class="p">])]</span>
</code></pre></div>

<p>Force row-by-row generation by reducing <code>working_memory</code>:</p>
<div class="highlight"><pre><span></span><code><span class="o">&gt;&gt;&gt;</span> <span class="n">gen</span> <span class="o">=</span> <span class="n">pairwise_distances_chunked</span><span class="p">(</span><span class="n">X</span><span class="p">,</span> <span class="n">reduce_func</span><span class="o">=</span><span class="n">reduce_func</span><span class="p">,</span>
<span class="o">...</span>                                  <span class="n">working_memory</span><span class="o">=</span><span class="mi">0</span><span class="p">)</span>
<span class="o">&gt;&gt;&gt;</span> <span class="nb">next</span><span class="p">(</span><span class="n">gen</span><span class="p">)</span>
<span class="p">[</span><span class="n">array</span><span class="p">([</span><span class="mi">0</span><span class="p">,</span> <span class="mi">3</span><span class="p">])]</span>
<span class="o">&gt;&gt;&gt;</span> <span class="nb">next</span><span class="p">(</span><span class="n">gen</span><span class="p">)</span>
<span class="p">[</span><span class="n">array</span><span class="p">([</span><span class="mi">0</span><span class="p">,</span> <span class="mi">1</span><span class="p">])]</span>
</code></pre></div>

</details>
<h3 id="pairwise_kernels_1">pairwise_kernels<a class="headerlink" href="#pairwise_kernels_1" title="Permanent link">&para;</a></h3>
<details class="note" open="open"><summary>function pairwise_kernels</summary><div class="highlight"><pre><span></span><code><span class="k">val</span> <span class="n">pairwise_kernels</span> <span class="o">:</span>
  <span class="o">?</span><span class="n">y</span><span class="o">:[&gt;`</span><span class="nc">ArrayLike</span><span class="o">]</span> <span class="nn">Np</span><span class="p">.</span><span class="nn">Obj</span><span class="p">.</span><span class="n">t</span> <span class="o">-&gt;</span>
  <span class="o">?</span><span class="n">metric</span><span class="o">:[`</span><span class="nc">S</span> <span class="k">of</span> <span class="kt">string</span> <span class="o">|</span> <span class="o">`</span><span class="nc">Callable</span> <span class="k">of</span> <span class="nn">Py</span><span class="p">.</span><span class="nn">Object</span><span class="p">.</span><span class="n">t</span><span class="o">]</span> <span class="o">-&gt;</span>
  <span class="o">?</span><span class="n">filter_params</span><span class="o">:</span><span class="kt">bool</span> <span class="o">-&gt;</span>
  <span class="o">?</span><span class="n">n_jobs</span><span class="o">:</span><span class="kt">int</span> <span class="o">-&gt;</span>
  <span class="o">?</span><span class="n">kwds</span><span class="o">:(</span><span class="kt">string</span> <span class="o">*</span> <span class="nn">Py</span><span class="p">.</span><span class="nn">Object</span><span class="p">.</span><span class="n">t</span><span class="o">)</span> <span class="kt">list</span> <span class="o">-&gt;</span>
  <span class="n">x</span><span class="o">:[`</span><span class="nc">Arr</span> <span class="k">of</span> <span class="o">[&gt;`</span><span class="nc">ArrayLike</span><span class="o">]</span> <span class="nn">Np</span><span class="p">.</span><span class="nn">Obj</span><span class="p">.</span><span class="n">t</span> <span class="o">|</span> <span class="o">`</span><span class="nc">Otherwise</span> <span class="k">of</span> <span class="nn">Py</span><span class="p">.</span><span class="nn">Object</span><span class="p">.</span><span class="n">t</span><span class="o">]</span> <span class="o">-&gt;</span>
  <span class="kt">unit</span> <span class="o">-&gt;</span>
  <span class="o">[&gt;`</span><span class="nc">ArrayLike</span><span class="o">]</span> <span class="nn">Np</span><span class="p">.</span><span class="nn">Obj</span><span class="p">.</span><span class="n">t</span>
</code></pre></div>

<p>Compute the kernel between arrays X and optional array Y.</p>
<p>This method takes either a vector array or a kernel matrix, and returns
a kernel matrix. If the input is a vector array, the kernels are
computed. If the input is a kernel matrix, it is returned instead.</p>
<p>This method provides a safe way to take a kernel matrix as input, while
preserving compatibility with many other algorithms that take a vector
array.</p>
<p>If Y is given (default is None), then the returned matrix is the pairwise
kernel between the arrays from both X and Y.</p>
<p>Valid values for metric are:
    ['additive_chi2', 'chi2', 'linear', 'poly', 'polynomial', 'rbf',
    'laplacian', 'sigmoid', 'cosine']</p>
<p>Read more in the :ref:<code>User Guide &lt;metrics&gt;</code>.</p>
<h4>Parameters</h4>
<ul>
<li>
<p><strong>X : array [n_samples_a, n_samples_a] if metric == 'precomputed', or,              [n_samples_a, n_features] otherwise</strong>
    Array of pairwise kernels between samples, or a feature array.</p>
</li>
<li>
<p><strong>Y : array [n_samples_b, n_features]</strong>
    A second feature array only if X has shape [n_samples_a, n_features].</p>
</li>
<li>
<p><strong>metric : string, or callable</strong>
    The metric to use when calculating kernel between instances in a
    feature array. If metric is a string, it must be one of the metrics
    in pairwise.PAIRWISE_KERNEL_FUNCTIONS.
    If metric is 'precomputed', X is assumed to be a kernel matrix.
    Alternatively, if metric is a callable function, it is called on each
    pair of instances (rows) and the resulting value recorded. The callable
    should take two rows from X as input and return the corresponding
    kernel value as a single number. This means that callables from
    :mod:<code>sklearn.metrics.pairwise</code> are not allowed, as they operate on
    matrices, not single samples. Use the string identifying the kernel
    instead.</p>
</li>
<li>
<p><strong>filter_params : boolean</strong>
    Whether to filter invalid parameters or not.</p>
</li>
<li>
<p><strong>n_jobs : int or None, optional (default=None)</strong>
    The number of jobs to use for the computation. This works by breaking
    down the pairwise matrix into n_jobs even slices and computing them in
    parallel.</p>
<p><code>None</code> means 1 unless in a :obj:<code>joblib.parallel_backend</code> context.
<code>-1</code> means using all processors. See :term:<code>Glossary &lt;n_jobs&gt;</code>
for more details.</p>
</li>
<li>
<p><strong>**kwds : optional keyword parameters</strong>
    Any further parameters are passed directly to the kernel function.</p>
</li>
</ul>
<h4>Returns</h4>
<ul>
<li><strong>K : array [n_samples_a, n_samples_a] or [n_samples_a, n_samples_b]</strong>
    A kernel matrix K such that K_{i, j} is the kernel between the
    ith and jth vectors of the given matrix X, if Y is None.
    If Y is not None, then K_{i, j} is the kernel between the ith array
    from X and the jth array from Y.</li>
</ul>
<h4>Notes</h4>
<p>If metric is 'precomputed', Y is ignored and X is returned.</p>
</details>
<h3 id="plot_confusion_matrix">plot_confusion_matrix<a class="headerlink" href="#plot_confusion_matrix" title="Permanent link">&para;</a></h3>
<details class="note" open="open"><summary>function plot_confusion_matrix</summary><div class="highlight"><pre><span></span><code><span class="k">val</span> <span class="n">plot_confusion_matrix</span> <span class="o">:</span>
  <span class="o">?</span><span class="n">labels</span><span class="o">:[&gt;`</span><span class="nc">ArrayLike</span><span class="o">]</span> <span class="nn">Np</span><span class="p">.</span><span class="nn">Obj</span><span class="p">.</span><span class="n">t</span> <span class="o">-&gt;</span>
  <span class="o">?</span><span class="n">sample_weight</span><span class="o">:[&gt;`</span><span class="nc">ArrayLike</span><span class="o">]</span> <span class="nn">Np</span><span class="p">.</span><span class="nn">Obj</span><span class="p">.</span><span class="n">t</span> <span class="o">-&gt;</span>
  <span class="o">?</span><span class="n">normalize</span><span class="o">:[`</span><span class="nc">All</span> <span class="o">|</span> <span class="o">`</span><span class="nc">Pred</span> <span class="o">|</span> <span class="o">`</span><span class="nc">True</span><span class="o">]</span> <span class="o">-&gt;</span>
  <span class="o">?</span><span class="n">display_labels</span><span class="o">:[&gt;`</span><span class="nc">ArrayLike</span><span class="o">]</span> <span class="nn">Np</span><span class="p">.</span><span class="nn">Obj</span><span class="p">.</span><span class="n">t</span> <span class="o">-&gt;</span>
  <span class="o">?</span><span class="n">include_values</span><span class="o">:</span><span class="kt">bool</span> <span class="o">-&gt;</span>
  <span class="o">?</span><span class="n">xticks_rotation</span><span class="o">:[`</span><span class="nc">Horizontal</span> <span class="o">|</span> <span class="o">`</span><span class="nc">F</span> <span class="k">of</span> <span class="kt">float</span> <span class="o">|</span> <span class="o">`</span><span class="nc">Vertical</span><span class="o">]</span> <span class="o">-&gt;</span>
  <span class="o">?</span><span class="n">values_format</span><span class="o">:</span><span class="kt">string</span> <span class="o">-&gt;</span>
  <span class="o">?</span><span class="n">cmap</span><span class="o">:[`</span><span class="nc">S</span> <span class="k">of</span> <span class="kt">string</span> <span class="o">|</span> <span class="o">`</span><span class="nc">Matplotlib_Colormap</span> <span class="k">of</span> <span class="nn">Py</span><span class="p">.</span><span class="nn">Object</span><span class="p">.</span><span class="n">t</span><span class="o">]</span> <span class="o">-&gt;</span>
  <span class="o">?</span><span class="n">ax</span><span class="o">:</span><span class="nn">Py</span><span class="p">.</span><span class="nn">Object</span><span class="p">.</span><span class="n">t</span> <span class="o">-&gt;</span>
  <span class="n">estimator</span><span class="o">:[&gt;`</span><span class="nc">BaseEstimator</span><span class="o">]</span> <span class="nn">Np</span><span class="p">.</span><span class="nn">Obj</span><span class="p">.</span><span class="n">t</span> <span class="o">-&gt;</span>
  <span class="n">x</span><span class="o">:[&gt;`</span><span class="nc">ArrayLike</span><span class="o">]</span> <span class="nn">Np</span><span class="p">.</span><span class="nn">Obj</span><span class="p">.</span><span class="n">t</span> <span class="o">-&gt;</span>
  <span class="n">y_true</span><span class="o">:</span><span class="nn">Py</span><span class="p">.</span><span class="nn">Object</span><span class="p">.</span><span class="n">t</span> <span class="o">-&gt;</span>
  <span class="kt">unit</span> <span class="o">-&gt;</span>
  <span class="nn">Py</span><span class="p">.</span><span class="nn">Object</span><span class="p">.</span><span class="n">t</span>
</code></pre></div>

<p>Plot Confusion Matrix.</p>
<p>Read more in the :ref:<code>User Guide &lt;confusion_matrix&gt;</code>.</p>
<h4>Parameters</h4>
<ul>
<li>
<p><strong>estimator : estimator instance</strong>
    Fitted classifier or a fitted :class:<code>~sklearn.pipeline.Pipeline</code>
    in which the last estimator is a classifier.</p>
</li>
<li>
<p><strong>X : {array-like, sparse matrix} of shape (n_samples, n_features)</strong>
    Input values.</p>
</li>
<li>
<p><strong>y : array-like of shape (n_samples,)</strong>
    Target values.</p>
</li>
<li>
<p><strong>labels : array-like of shape (n_classes,), default=None</strong>
    List of labels to index the matrix. This may be used to reorder or
    select a subset of labels. If <code>None</code> is given, those that appear at
    least once in <code>y_true</code> or <code>y_pred</code> are used in sorted order.</p>
</li>
<li>
<p><strong>sample_weight : array-like of shape (n_samples,), default=None</strong>
    Sample weights.</p>
</li>
<li>
<p><strong>normalize : {'true', 'pred', 'all'}, default=None</strong>
    Normalizes confusion matrix over the true (rows), predicted (columns)
    conditions or all the population. If None, confusion matrix will not be
    normalized.</p>
</li>
<li>
<p><strong>display_labels : array-like of shape (n_classes,), default=None</strong>
    Target names used for plotting. By default, <code>labels</code> will be used if
    it is defined, otherwise the unique labels of <code>y_true</code> and <code>y_pred</code>
    will be used.</p>
</li>
<li>
<p><strong>include_values : bool, default=True</strong>
    Includes values in confusion matrix.</p>
</li>
<li>
<p><strong>xticks_rotation : {'vertical', 'horizontal'} or float,                         default='horizontal'</strong>
    Rotation of xtick labels.</p>
</li>
<li>
<p><strong>values_format : str, default=None</strong>
    Format specification for values in confusion matrix. If <code>None</code>,
    the format specification is 'd' or '.2g' whichever is shorter.</p>
</li>
<li>
<p><strong>cmap : str or matplotlib Colormap, default='viridis'</strong>
    Colormap recognized by matplotlib.</p>
</li>
<li>
<p><strong>ax : matplotlib Axes, default=None</strong>
    Axes object to plot on. If <code>None</code>, a new figure and axes is
    created.</p>
</li>
</ul>
<h4>Returns</h4>
<ul>
<li><strong>display : :class:<code>~sklearn.metrics.ConfusionMatrixDisplay</code></strong></li>
</ul>
<h4>Examples</h4>
<div class="highlight"><pre><span></span><code><span class="o">&gt;&gt;&gt;</span> <span class="kn">import</span> <span class="nn">matplotlib.pyplot</span> <span class="k">as</span> <span class="nn">plt</span>  <span class="c1"># doctest: +SKIP</span>
<span class="o">&gt;&gt;&gt;</span> <span class="kn">from</span> <span class="nn">sklearn.datasets</span> <span class="kn">import</span> <span class="n">make_classification</span>
<span class="o">&gt;&gt;&gt;</span> <span class="kn">from</span> <span class="nn">sklearn.metrics</span> <span class="kn">import</span> <span class="n">plot_confusion_matrix</span>
<span class="o">&gt;&gt;&gt;</span> <span class="kn">from</span> <span class="nn">sklearn.model_selection</span> <span class="kn">import</span> <span class="n">train_test_split</span>
<span class="o">&gt;&gt;&gt;</span> <span class="kn">from</span> <span class="nn">sklearn.svm</span> <span class="kn">import</span> <span class="n">SVC</span>
<span class="o">&gt;&gt;&gt;</span> <span class="n">X</span><span class="p">,</span> <span class="n">y</span> <span class="o">=</span> <span class="n">make_classification</span><span class="p">(</span><span class="n">random_state</span><span class="o">=</span><span class="mi">0</span><span class="p">)</span>
<span class="o">&gt;&gt;&gt;</span> <span class="n">X_train</span><span class="p">,</span> <span class="n">X_test</span><span class="p">,</span> <span class="n">y_train</span><span class="p">,</span> <span class="n">y_test</span> <span class="o">=</span> <span class="n">train_test_split</span><span class="p">(</span>
<span class="o">...</span>         <span class="n">X</span><span class="p">,</span> <span class="n">y</span><span class="p">,</span> <span class="n">random_state</span><span class="o">=</span><span class="mi">0</span><span class="p">)</span>
<span class="o">&gt;&gt;&gt;</span> <span class="n">clf</span> <span class="o">=</span> <span class="n">SVC</span><span class="p">(</span><span class="n">random_state</span><span class="o">=</span><span class="mi">0</span><span class="p">)</span>
<span class="o">&gt;&gt;&gt;</span> <span class="n">clf</span><span class="o">.</span><span class="n">fit</span><span class="p">(</span><span class="n">X_train</span><span class="p">,</span> <span class="n">y_train</span><span class="p">)</span>
<span class="n">SVC</span><span class="p">(</span><span class="n">random_state</span><span class="o">=</span><span class="mi">0</span><span class="p">)</span>
<span class="o">&gt;&gt;&gt;</span> <span class="n">plot_confusion_matrix</span><span class="p">(</span><span class="n">clf</span><span class="p">,</span> <span class="n">X_test</span><span class="p">,</span> <span class="n">y_test</span><span class="p">)</span>  <span class="c1"># doctest: +SKIP</span>
<span class="o">&gt;&gt;&gt;</span> <span class="n">plt</span><span class="o">.</span><span class="n">show</span><span class="p">()</span>  <span class="c1"># doctest: +SKIP</span>
</code></pre></div>

</details>
<h3 id="plot_precision_recall_curve">plot_precision_recall_curve<a class="headerlink" href="#plot_precision_recall_curve" title="Permanent link">&para;</a></h3>
<details class="note" open="open"><summary>function plot_precision_recall_curve</summary><div class="highlight"><pre><span></span><code><span class="k">val</span> <span class="n">plot_precision_recall_curve</span> <span class="o">:</span>
  <span class="o">?</span><span class="n">sample_weight</span><span class="o">:[&gt;`</span><span class="nc">ArrayLike</span><span class="o">]</span> <span class="nn">Np</span><span class="p">.</span><span class="nn">Obj</span><span class="p">.</span><span class="n">t</span> <span class="o">-&gt;</span>
  <span class="o">?</span><span class="n">response_method</span><span class="o">:[`</span><span class="nc">Predict_proba</span> <span class="o">|</span> <span class="o">`</span><span class="nc">Decision_function</span> <span class="o">|</span> <span class="o">`</span><span class="nc">Auto</span><span class="o">]</span> <span class="o">-&gt;</span>
  <span class="o">?</span><span class="n">name</span><span class="o">:</span><span class="kt">string</span> <span class="o">-&gt;</span>
  <span class="o">?</span><span class="n">ax</span><span class="o">:</span><span class="nn">Py</span><span class="p">.</span><span class="nn">Object</span><span class="p">.</span><span class="n">t</span> <span class="o">-&gt;</span>
  <span class="o">?</span><span class="n">kwargs</span><span class="o">:(</span><span class="kt">string</span> <span class="o">*</span> <span class="nn">Py</span><span class="p">.</span><span class="nn">Object</span><span class="p">.</span><span class="n">t</span><span class="o">)</span> <span class="kt">list</span> <span class="o">-&gt;</span>
  <span class="n">estimator</span><span class="o">:[&gt;`</span><span class="nc">BaseEstimator</span><span class="o">]</span> <span class="nn">Np</span><span class="p">.</span><span class="nn">Obj</span><span class="p">.</span><span class="n">t</span> <span class="o">-&gt;</span>
  <span class="n">x</span><span class="o">:[&gt;`</span><span class="nc">ArrayLike</span><span class="o">]</span> <span class="nn">Np</span><span class="p">.</span><span class="nn">Obj</span><span class="p">.</span><span class="n">t</span> <span class="o">-&gt;</span>
  <span class="n">y</span><span class="o">:[&gt;`</span><span class="nc">ArrayLike</span><span class="o">]</span> <span class="nn">Np</span><span class="p">.</span><span class="nn">Obj</span><span class="p">.</span><span class="n">t</span> <span class="o">-&gt;</span>
  <span class="kt">unit</span> <span class="o">-&gt;</span>
  <span class="nn">Py</span><span class="p">.</span><span class="nn">Object</span><span class="p">.</span><span class="n">t</span>
</code></pre></div>

<p>Plot Precision Recall Curve for binary classifiers.</p>
<p>Extra keyword arguments will be passed to matplotlib's <code>plot</code>.</p>
<p>Read more in the :ref:<code>User Guide &lt;precision_recall_f_measure_metrics&gt;</code>.</p>
<h4>Parameters</h4>
<ul>
<li>
<p><strong>estimator : estimator instance</strong>
    Fitted classifier or a fitted :class:<code>~sklearn.pipeline.Pipeline</code>
    in which the last estimator is a classifier.</p>
</li>
<li>
<p><strong>X : {array-like, sparse matrix} of shape (n_samples, n_features)</strong>
    Input values.</p>
</li>
<li>
<p><strong>y : array-like of shape (n_samples,)</strong>
    Binary target values.</p>
</li>
<li>
<p><strong>sample_weight : array-like of shape (n_samples,), default=None</strong>
    Sample weights.</p>
</li>
<li>
<p><strong>response_method : {'predict_proba', 'decision_function', 'auto'},                       default='auto'</strong>
    Specifies whether to use :term:<code>predict_proba</code> or
    :term:<code>decision_function</code> as the target response. If set to 'auto',
    :term:<code>predict_proba</code> is tried first and if it does not exist
    :term:<code>decision_function</code> is tried next.</p>
</li>
<li>
<p><strong>name : str, default=None</strong>
    Name for labeling curve. If <code>None</code>, the name of the
    estimator is used.</p>
</li>
<li>
<p><strong>ax : matplotlib axes, default=None</strong>
    Axes object to plot on. If <code>None</code>, a new figure and axes is created.</p>
</li>
<li>
<p><strong>**kwargs : dict</strong>
    Keyword arguments to be passed to matplotlib's <code>plot</code>.</p>
</li>
</ul>
<h4>Returns</h4>
<ul>
<li><strong>display : :class:<code>~sklearn.metrics.PrecisionRecallDisplay</code></strong>
    Object that stores computed values.</li>
</ul>
</details>
<h3 id="plot_roc_curve">plot_roc_curve<a class="headerlink" href="#plot_roc_curve" title="Permanent link">&para;</a></h3>
<details class="note" open="open"><summary>function plot_roc_curve</summary><div class="highlight"><pre><span></span><code><span class="k">val</span> <span class="n">plot_roc_curve</span> <span class="o">:</span>
  <span class="o">?</span><span class="n">sample_weight</span><span class="o">:[&gt;`</span><span class="nc">ArrayLike</span><span class="o">]</span> <span class="nn">Np</span><span class="p">.</span><span class="nn">Obj</span><span class="p">.</span><span class="n">t</span> <span class="o">-&gt;</span>
  <span class="o">?</span><span class="n">drop_intermediate</span><span class="o">:</span><span class="kt">bool</span> <span class="o">-&gt;</span>
  <span class="o">?</span><span class="n">response_method</span><span class="o">:[`</span><span class="nc">Predict_proba</span> <span class="o">|</span> <span class="o">`</span><span class="nc">Decision_function</span> <span class="o">|</span> <span class="o">`</span><span class="nc">Auto</span><span class="o">]</span> <span class="o">-&gt;</span>
  <span class="o">?</span><span class="n">name</span><span class="o">:</span><span class="kt">string</span> <span class="o">-&gt;</span>
  <span class="o">?</span><span class="n">ax</span><span class="o">:</span><span class="nn">Py</span><span class="p">.</span><span class="nn">Object</span><span class="p">.</span><span class="n">t</span> <span class="o">-&gt;</span>
  <span class="o">?</span><span class="n">kwargs</span><span class="o">:(</span><span class="kt">string</span> <span class="o">*</span> <span class="nn">Py</span><span class="p">.</span><span class="nn">Object</span><span class="p">.</span><span class="n">t</span><span class="o">)</span> <span class="kt">list</span> <span class="o">-&gt;</span>
  <span class="n">estimator</span><span class="o">:[&gt;`</span><span class="nc">BaseEstimator</span><span class="o">]</span> <span class="nn">Np</span><span class="p">.</span><span class="nn">Obj</span><span class="p">.</span><span class="n">t</span> <span class="o">-&gt;</span>
  <span class="n">x</span><span class="o">:[&gt;`</span><span class="nc">ArrayLike</span><span class="o">]</span> <span class="nn">Np</span><span class="p">.</span><span class="nn">Obj</span><span class="p">.</span><span class="n">t</span> <span class="o">-&gt;</span>
  <span class="n">y</span><span class="o">:[&gt;`</span><span class="nc">ArrayLike</span><span class="o">]</span> <span class="nn">Np</span><span class="p">.</span><span class="nn">Obj</span><span class="p">.</span><span class="n">t</span> <span class="o">-&gt;</span>
  <span class="kt">unit</span> <span class="o">-&gt;</span>
  <span class="nn">Py</span><span class="p">.</span><span class="nn">Object</span><span class="p">.</span><span class="n">t</span>
</code></pre></div>

<p>Plot Receiver operating characteristic (ROC) curve.</p>
<p>Extra keyword arguments will be passed to matplotlib's <code>plot</code>.</p>
<p>Read more in the :ref:<code>User Guide &lt;visualizations&gt;</code>.</p>
<h4>Parameters</h4>
<ul>
<li>
<p><strong>estimator : estimator instance</strong>
    Fitted classifier or a fitted :class:<code>~sklearn.pipeline.Pipeline</code>
    in which the last estimator is a classifier.</p>
</li>
<li>
<p><strong>X : {array-like, sparse matrix} of shape (n_samples, n_features)</strong>
    Input values.</p>
</li>
<li>
<p><strong>y : array-like of shape (n_samples,)</strong>
    Target values.</p>
</li>
<li>
<p><strong>sample_weight : array-like of shape (n_samples,), default=None</strong>
    Sample weights.</p>
</li>
<li>
<p><strong>drop_intermediate : boolean, default=True</strong>
    Whether to drop some suboptimal thresholds which would not appear
    on a plotted ROC curve. This is useful in order to create lighter
    ROC curves.</p>
</li>
<li>
<p><strong>response_method : {'predict_proba', 'decision_function', 'auto'}     default='auto'</strong>
    Specifies whether to use :term:<code>predict_proba</code> or
    :term:<code>decision_function</code> as the target response. If set to 'auto',
    :term:<code>predict_proba</code> is tried first and if it does not exist
    :term:<code>decision_function</code> is tried next.</p>
</li>
<li>
<p><strong>name : str, default=None</strong>
    Name of ROC Curve for labeling. If <code>None</code>, use the name of the
    estimator.</p>
</li>
<li>
<p><strong>ax : matplotlib axes, default=None</strong>
    Axes object to plot on. If <code>None</code>, a new figure and axes is created.</p>
</li>
</ul>
<h4>Returns</h4>
<ul>
<li><strong>display : :class:<code>~sklearn.metrics.RocCurveDisplay</code></strong>
    Object that stores computed values.</li>
</ul>
<h4>Examples</h4>
<div class="highlight"><pre><span></span><code><span class="o">&gt;&gt;&gt;</span> <span class="kn">import</span> <span class="nn">matplotlib.pyplot</span> <span class="k">as</span> <span class="nn">plt</span>  <span class="c1"># doctest: +SKIP</span>
<span class="o">&gt;&gt;&gt;</span> <span class="kn">from</span> <span class="nn">sklearn</span> <span class="kn">import</span> <span class="n">datasets</span><span class="p">,</span> <span class="n">metrics</span><span class="p">,</span> <span class="n">model_selection</span><span class="p">,</span> <span class="n">svm</span>
<span class="o">&gt;&gt;&gt;</span> <span class="n">X</span><span class="p">,</span> <span class="n">y</span> <span class="o">=</span> <span class="n">datasets</span><span class="o">.</span><span class="n">make_classification</span><span class="p">(</span><span class="n">random_state</span><span class="o">=</span><span class="mi">0</span><span class="p">)</span>
<span class="o">&gt;&gt;&gt;</span> <span class="n">X_train</span><span class="p">,</span> <span class="n">X_test</span><span class="p">,</span> <span class="n">y_train</span><span class="p">,</span> <span class="n">y_test</span> <span class="o">=</span> <span class="n">model_selection</span><span class="o">.</span><span class="n">train_test_split</span><span class="p">(</span>            <span class="n">X</span><span class="p">,</span> <span class="n">y</span><span class="p">,</span> <span class="n">random_state</span><span class="o">=</span><span class="mi">0</span><span class="p">)</span>
<span class="o">&gt;&gt;&gt;</span> <span class="n">clf</span> <span class="o">=</span> <span class="n">svm</span><span class="o">.</span><span class="n">SVC</span><span class="p">(</span><span class="n">random_state</span><span class="o">=</span><span class="mi">0</span><span class="p">)</span>
<span class="o">&gt;&gt;&gt;</span> <span class="n">clf</span><span class="o">.</span><span class="n">fit</span><span class="p">(</span><span class="n">X_train</span><span class="p">,</span> <span class="n">y_train</span><span class="p">)</span>
<span class="n">SVC</span><span class="p">(</span><span class="n">random_state</span><span class="o">=</span><span class="mi">0</span><span class="p">)</span>
<span class="o">&gt;&gt;&gt;</span> <span class="n">metrics</span><span class="o">.</span><span class="n">plot_roc_curve</span><span class="p">(</span><span class="n">clf</span><span class="p">,</span> <span class="n">X_test</span><span class="p">,</span> <span class="n">y_test</span><span class="p">)</span>  <span class="c1"># doctest: +SKIP</span>
<span class="o">&gt;&gt;&gt;</span> <span class="n">plt</span><span class="o">.</span><span class="n">show</span><span class="p">()</span>                                   <span class="c1"># doctest: +SKIP</span>
</code></pre></div>

</details>
<h3 id="precision_recall_curve">precision_recall_curve<a class="headerlink" href="#precision_recall_curve" title="Permanent link">&para;</a></h3>
<details class="note" open="open"><summary>function precision_recall_curve</summary><div class="highlight"><pre><span></span><code><span class="k">val</span> <span class="n">precision_recall_curve</span> <span class="o">:</span>
  <span class="o">?</span><span class="n">pos_label</span><span class="o">:[`</span><span class="nc">S</span> <span class="k">of</span> <span class="kt">string</span> <span class="o">|</span> <span class="o">`</span><span class="nc">I</span> <span class="k">of</span> <span class="kt">int</span><span class="o">]</span> <span class="o">-&gt;</span>
  <span class="o">?</span><span class="n">sample_weight</span><span class="o">:[&gt;`</span><span class="nc">ArrayLike</span><span class="o">]</span> <span class="nn">Np</span><span class="p">.</span><span class="nn">Obj</span><span class="p">.</span><span class="n">t</span> <span class="o">-&gt;</span>
  <span class="n">y_true</span><span class="o">:[&gt;`</span><span class="nc">ArrayLike</span><span class="o">]</span> <span class="nn">Np</span><span class="p">.</span><span class="nn">Obj</span><span class="p">.</span><span class="n">t</span> <span class="o">-&gt;</span>
  <span class="n">probas_pred</span><span class="o">:[&gt;`</span><span class="nc">ArrayLike</span><span class="o">]</span> <span class="nn">Np</span><span class="p">.</span><span class="nn">Obj</span><span class="p">.</span><span class="n">t</span> <span class="o">-&gt;</span>
  <span class="kt">unit</span> <span class="o">-&gt;</span>
  <span class="o">([&gt;`</span><span class="nc">ArrayLike</span><span class="o">]</span> <span class="nn">Np</span><span class="p">.</span><span class="nn">Obj</span><span class="p">.</span><span class="n">t</span> <span class="o">*</span> <span class="o">[&gt;`</span><span class="nc">ArrayLike</span><span class="o">]</span> <span class="nn">Np</span><span class="p">.</span><span class="nn">Obj</span><span class="p">.</span><span class="n">t</span> <span class="o">*</span> <span class="o">[&gt;`</span><span class="nc">ArrayLike</span><span class="o">]</span> <span class="nn">Np</span><span class="p">.</span><span class="nn">Obj</span><span class="p">.</span><span class="n">t</span><span class="o">)</span>
</code></pre></div>

<p>Compute precision-recall pairs for different probability thresholds</p>
<ul>
<li><strong>Note: this implementation is restricted to the binary classification task.</strong></li>
</ul>
<p>The precision is the ratio <code>tp / (tp + fp)</code> where <code>tp</code> is the number of
true positives and <code>fp</code> the number of false positives. The precision is
intuitively the ability of the classifier not to label as positive a sample
that is negative.</p>
<p>The recall is the ratio <code>tp / (tp + fn)</code> where <code>tp</code> is the number of
true positives and <code>fn</code> the number of false negatives. The recall is
intuitively the ability of the classifier to find all the positive samples.</p>
<p>The last precision and recall values are 1. and 0. respectively and do not
have a corresponding threshold.  This ensures that the graph starts on the
y axis.</p>
<p>Read more in the :ref:<code>User Guide &lt;precision_recall_f_measure_metrics&gt;</code>.</p>
<h4>Parameters</h4>
<ul>
<li>
<p><strong>y_true : array, shape = [n_samples]</strong>
    True binary labels. If labels are not either {-1, 1} or {0, 1}, then
    pos_label should be explicitly given.</p>
</li>
<li>
<p><strong>probas_pred : array, shape = [n_samples]</strong>
    Estimated probabilities or decision function.</p>
</li>
<li>
<p><strong>pos_label : int or str, default=None</strong>
    The label of the positive class.
    When <code>pos_label=None</code>, if y_true is in {-1, 1} or {0, 1},
    <code>pos_label</code> is set to 1, otherwise an error will be raised.</p>
</li>
<li>
<p><strong>sample_weight : array-like of shape (n_samples,), default=None</strong>
    Sample weights.</p>
</li>
</ul>
<h4>Returns</h4>
<ul>
<li>
<p><strong>precision : array, shape = [n_thresholds + 1]</strong>
    Precision values such that element i is the precision of
    predictions with score &gt;= thresholds[i] and the last element is 1.</p>
</li>
<li>
<p><strong>recall : array, shape = [n_thresholds + 1]</strong>
    Decreasing recall values such that element i is the recall of
    predictions with score &gt;= thresholds[i] and the last element is 0.</p>
</li>
<li>
<p><strong>thresholds : array, shape = [n_thresholds &lt;= len(np.unique(probas_pred))]</strong>
    Increasing thresholds on the decision function used to compute
    precision and recall.</p>
</li>
</ul>
<h4>See also</h4>
<ul>
<li>
<p><strong>average_precision_score : Compute average precision from prediction scores</strong></p>
</li>
<li>
<p><strong>roc_curve : Compute Receiver operating characteristic (ROC) curve</strong></p>
</li>
</ul>
<h4>Examples</h4>
<div class="highlight"><pre><span></span><code><span class="o">&gt;&gt;&gt;</span> <span class="kn">import</span> <span class="nn">numpy</span> <span class="k">as</span> <span class="nn">np</span>
<span class="o">&gt;&gt;&gt;</span> <span class="kn">from</span> <span class="nn">sklearn.metrics</span> <span class="kn">import</span> <span class="n">precision_recall_curve</span>
<span class="o">&gt;&gt;&gt;</span> <span class="n">y_true</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">array</span><span class="p">([</span><span class="mi">0</span><span class="p">,</span> <span class="mi">0</span><span class="p">,</span> <span class="mi">1</span><span class="p">,</span> <span class="mi">1</span><span class="p">])</span>
<span class="o">&gt;&gt;&gt;</span> <span class="n">y_scores</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">array</span><span class="p">([</span><span class="mf">0.1</span><span class="p">,</span> <span class="mf">0.4</span><span class="p">,</span> <span class="mf">0.35</span><span class="p">,</span> <span class="mf">0.8</span><span class="p">])</span>
<span class="o">&gt;&gt;&gt;</span> <span class="n">precision</span><span class="p">,</span> <span class="n">recall</span><span class="p">,</span> <span class="n">thresholds</span> <span class="o">=</span> <span class="n">precision_recall_curve</span><span class="p">(</span>
<span class="o">...</span>     <span class="n">y_true</span><span class="p">,</span> <span class="n">y_scores</span><span class="p">)</span>
<span class="o">&gt;&gt;&gt;</span> <span class="n">precision</span>
<span class="n">array</span><span class="p">([</span><span class="mf">0.66666667</span><span class="p">,</span> <span class="mf">0.5</span>       <span class="p">,</span> <span class="mf">1.</span>        <span class="p">,</span> <span class="mf">1.</span>        <span class="p">])</span>
<span class="o">&gt;&gt;&gt;</span> <span class="n">recall</span>
<span class="n">array</span><span class="p">([</span><span class="mf">1.</span> <span class="p">,</span> <span class="mf">0.5</span><span class="p">,</span> <span class="mf">0.5</span><span class="p">,</span> <span class="mf">0.</span> <span class="p">])</span>
<span class="o">&gt;&gt;&gt;</span> <span class="n">thresholds</span>
<span class="n">array</span><span class="p">([</span><span class="mf">0.35</span><span class="p">,</span> <span class="mf">0.4</span> <span class="p">,</span> <span class="mf">0.8</span> <span class="p">])</span>
</code></pre></div>

</details>
<h3 id="precision_recall_fscore_support">precision_recall_fscore_support<a class="headerlink" href="#precision_recall_fscore_support" title="Permanent link">&para;</a></h3>
<details class="note" open="open"><summary>function precision_recall_fscore_support</summary><div class="highlight"><pre><span></span><code><span class="k">val</span> <span class="n">precision_recall_fscore_support</span> <span class="o">:</span>
  <span class="o">?</span><span class="n">beta</span><span class="o">:</span><span class="kt">float</span> <span class="o">-&gt;</span>
  <span class="o">?</span><span class="n">labels</span><span class="o">:[&gt;`</span><span class="nc">ArrayLike</span><span class="o">]</span> <span class="nn">Np</span><span class="p">.</span><span class="nn">Obj</span><span class="p">.</span><span class="n">t</span> <span class="o">-&gt;</span>
  <span class="o">?</span><span class="n">pos_label</span><span class="o">:[`</span><span class="nc">S</span> <span class="k">of</span> <span class="kt">string</span> <span class="o">|</span> <span class="o">`</span><span class="nc">I</span> <span class="k">of</span> <span class="kt">int</span><span class="o">]</span> <span class="o">-&gt;</span>
  <span class="o">?</span><span class="n">average</span><span class="o">:[`</span><span class="nc">Macro</span> <span class="o">|</span> <span class="o">`</span><span class="nc">Weighted</span> <span class="o">|</span> <span class="o">`</span><span class="nc">Samples</span> <span class="o">|</span> <span class="o">`</span><span class="nc">Micro</span> <span class="o">|</span> <span class="o">`</span><span class="nc">Binary</span><span class="o">]</span> <span class="o">-&gt;</span>
  <span class="o">?</span><span class="n">warn_for</span><span class="o">:</span><span class="nn">Py</span><span class="p">.</span><span class="nn">Object</span><span class="p">.</span><span class="n">t</span> <span class="o">-&gt;</span>
  <span class="o">?</span><span class="n">sample_weight</span><span class="o">:[&gt;`</span><span class="nc">ArrayLike</span><span class="o">]</span> <span class="nn">Np</span><span class="p">.</span><span class="nn">Obj</span><span class="p">.</span><span class="n">t</span> <span class="o">-&gt;</span>
  <span class="o">?</span><span class="n">zero_division</span><span class="o">:[`</span><span class="nc">Warn</span> <span class="o">|</span> <span class="o">`</span><span class="nc">Zero</span> <span class="o">|</span> <span class="o">`</span><span class="nc">One</span><span class="o">]</span> <span class="o">-&gt;</span>
  <span class="n">y_true</span><span class="o">:[&gt;`</span><span class="nc">ArrayLike</span><span class="o">]</span> <span class="nn">Np</span><span class="p">.</span><span class="nn">Obj</span><span class="p">.</span><span class="n">t</span> <span class="o">-&gt;</span>
  <span class="n">y_pred</span><span class="o">:[&gt;`</span><span class="nc">ArrayLike</span><span class="o">]</span> <span class="nn">Np</span><span class="p">.</span><span class="nn">Obj</span><span class="p">.</span><span class="n">t</span> <span class="o">-&gt;</span>
  <span class="kt">unit</span> <span class="o">-&gt;</span>
  <span class="o">([&gt;`</span><span class="nc">ArrayLike</span><span class="o">]</span> <span class="nn">Np</span><span class="p">.</span><span class="nn">Obj</span><span class="p">.</span><span class="n">t</span> <span class="o">*</span> <span class="o">[&gt;`</span><span class="nc">ArrayLike</span><span class="o">]</span> <span class="nn">Np</span><span class="p">.</span><span class="nn">Obj</span><span class="p">.</span><span class="n">t</span> <span class="o">*</span> <span class="o">[&gt;`</span><span class="nc">ArrayLike</span><span class="o">]</span> <span class="nn">Np</span><span class="p">.</span><span class="nn">Obj</span><span class="p">.</span><span class="n">t</span> <span class="o">*</span> <span class="o">[&gt;`</span><span class="nc">ArrayLike</span><span class="o">]</span> <span class="nn">Np</span><span class="p">.</span><span class="nn">Obj</span><span class="p">.</span><span class="n">t</span> <span class="n">option</span><span class="o">)</span>
</code></pre></div>

<p>Compute precision, recall, F-measure and support for each class</p>
<p>The precision is the ratio <code>tp / (tp + fp)</code> where <code>tp</code> is the number of
true positives and <code>fp</code> the number of false positives. The precision is
intuitively the ability of the classifier not to label as positive a sample
that is negative.</p>
<p>The recall is the ratio <code>tp / (tp + fn)</code> where <code>tp</code> is the number of
true positives and <code>fn</code> the number of false negatives. The recall is
intuitively the ability of the classifier to find all the positive samples.</p>
<p>The F-beta score can be interpreted as a weighted harmonic mean of
the precision and recall, where an F-beta score reaches its best
value at 1 and worst score at 0.</p>
<p>The F-beta score weights recall more than precision by a factor of
<code>beta</code>. <code>beta == 1.0</code> means recall and precision are equally important.</p>
<p>The support is the number of occurrences of each class in <code>y_true</code>.</p>
<p>If <code>pos_label is None</code> and in binary classification, this function
returns the average precision, recall and F-measure if <code>average</code>
is one of <code>'micro'</code>, <code>'macro'</code>, <code>'weighted'</code> or <code>'samples'</code>.</p>
<p>Read more in the :ref:<code>User Guide &lt;precision_recall_f_measure_metrics&gt;</code>.</p>
<h4>Parameters</h4>
<ul>
<li>
<p><strong>y_true : 1d array-like, or label indicator array / sparse matrix</strong>
    Ground truth (correct) target values.</p>
</li>
<li>
<p><strong>y_pred : 1d array-like, or label indicator array / sparse matrix</strong>
    Estimated targets as returned by a classifier.</p>
</li>
<li>
<p><strong>beta : float, 1.0 by default</strong>
    The strength of recall versus precision in the F-score.</p>
</li>
<li>
<p><strong>labels : list, optional</strong>
    The set of labels to include when <code>average != 'binary'</code>, and their
    order if <code>average is None</code>. Labels present in the data can be
    excluded, for example to calculate a multiclass average ignoring a
    majority negative class, while labels not present in the data will
    result in 0 components in a macro average. For multilabel targets,
    labels are column indices. By default, all labels in <code>y_true</code> and
    <code>y_pred</code> are used in sorted order.</p>
</li>
<li>
<p><strong>pos_label : str or int, 1 by default</strong>
    The class to report if <code>average='binary'</code> and the data is binary.
    If the data are multiclass or multilabel, this will be ignored;
    setting <code>labels=[pos_label]</code> and <code>average != 'binary'</code> will report
    scores for that label only.</p>
</li>
<li>
<p><strong>average : string, [None (default), 'binary', 'micro', 'macro', 'samples',                        'weighted']</strong>
    If <code>None</code>, the scores for each class are returned. Otherwise, this
    determines the type of averaging performed on the data:</p>
<p><code>'binary'</code>:
    Only report results for the class specified by <code>pos_label</code>.
    This is applicable only if targets (<code>y_{true,pred}</code>) are binary.
<code>'micro'</code>:
    Calculate metrics globally by counting the total true positives,
    false negatives and false positives.
<code>'macro'</code>:
    Calculate metrics for each label, and find their unweighted
    mean.  This does not take label imbalance into account.
<code>'weighted'</code>:
    Calculate metrics for each label, and find their average weighted
    by support (the number of true instances for each label). This
    alters 'macro' to account for label imbalance; it can result in an
    F-score that is not between precision and recall.
<code>'samples'</code>:
    Calculate metrics for each instance, and find their average (only
    meaningful for multilabel classification where this differs from
    :func:<code>accuracy_score</code>).</p>
</li>
<li>
<p><strong>warn_for : tuple or set, for internal use</strong>
    This determines which warnings will be made in the case that this
    function is being used to return only one of its metrics.</p>
</li>
<li>
<p><strong>sample_weight : array-like of shape (n_samples,), default=None</strong>
    Sample weights.</p>
</li>
<li>
<p><strong>zero_division : 'warn', 0 or 1, default='warn'</strong>
    Sets the value to return when there is a zero division:</p>
<ul>
<li>recall: when there are no positive labels</li>
<li>precision: when there are no positive predictions</li>
<li>f-score: both</li>
</ul>
<p>If set to 'warn', this acts as 0, but warnings are also raised.</p>
</li>
</ul>
<h4>Returns</h4>
<ul>
<li>
<p><strong>precision : float (if average is not None) or array of float, shape =        [n_unique_labels]</strong></p>
</li>
<li>
<p><strong>recall : float (if average is not None) or array of float, , shape =        [n_unique_labels]</strong></p>
</li>
<li>
<p><strong>fbeta_score : float (if average is not None) or array of float, shape =        [n_unique_labels]</strong></p>
</li>
<li>
<p><strong>support : None (if average is not None) or array of int, shape =        [n_unique_labels]</strong>
    The number of occurrences of each label in <code>y_true</code>.</p>
</li>
</ul>
<h4>References</h4>
<p>.. [1] <code>Wikipedia entry for the Precision and recall
       &lt;https://en.wikipedia.org/wiki/Precision_and_recall&gt;</code>_</p>
<p>.. [2] <code>Wikipedia entry for the F1-score
       &lt;https://en.wikipedia.org/wiki/F1_score&gt;</code>_</p>
<p>.. [3] <code>Discriminative Methods for Multi-labeled Classification Advances
       in Knowledge Discovery and Data Mining (2004), pp. 22-30 by Shantanu
       Godbole, Sunita Sarawagi
       &lt;http://www.godbole.net/shantanu/pubs/multilabelsvm-pakdd04.pdf&gt;</code>_</p>
<h4>Examples</h4>
<div class="highlight"><pre><span></span><code><span class="o">&gt;&gt;&gt;</span> <span class="kn">import</span> <span class="nn">numpy</span> <span class="k">as</span> <span class="nn">np</span>
<span class="o">&gt;&gt;&gt;</span> <span class="kn">from</span> <span class="nn">sklearn.metrics</span> <span class="kn">import</span> <span class="n">precision_recall_fscore_support</span>
<span class="o">&gt;&gt;&gt;</span> <span class="n">y_true</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">array</span><span class="p">([</span><span class="s1">&#39;cat&#39;</span><span class="p">,</span> <span class="s1">&#39;dog&#39;</span><span class="p">,</span> <span class="s1">&#39;pig&#39;</span><span class="p">,</span> <span class="s1">&#39;cat&#39;</span><span class="p">,</span> <span class="s1">&#39;dog&#39;</span><span class="p">,</span> <span class="s1">&#39;pig&#39;</span><span class="p">])</span>
<span class="o">&gt;&gt;&gt;</span> <span class="n">y_pred</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">array</span><span class="p">([</span><span class="s1">&#39;cat&#39;</span><span class="p">,</span> <span class="s1">&#39;pig&#39;</span><span class="p">,</span> <span class="s1">&#39;dog&#39;</span><span class="p">,</span> <span class="s1">&#39;cat&#39;</span><span class="p">,</span> <span class="s1">&#39;cat&#39;</span><span class="p">,</span> <span class="s1">&#39;dog&#39;</span><span class="p">])</span>
<span class="o">&gt;&gt;&gt;</span> <span class="n">precision_recall_fscore_support</span><span class="p">(</span><span class="n">y_true</span><span class="p">,</span> <span class="n">y_pred</span><span class="p">,</span> <span class="n">average</span><span class="o">=</span><span class="s1">&#39;macro&#39;</span><span class="p">)</span>
<span class="p">(</span><span class="mf">0.22</span><span class="o">...</span><span class="p">,</span> <span class="mf">0.33</span><span class="o">...</span><span class="p">,</span> <span class="mf">0.26</span><span class="o">...</span><span class="p">,</span> <span class="kc">None</span><span class="p">)</span>
<span class="o">&gt;&gt;&gt;</span> <span class="n">precision_recall_fscore_support</span><span class="p">(</span><span class="n">y_true</span><span class="p">,</span> <span class="n">y_pred</span><span class="p">,</span> <span class="n">average</span><span class="o">=</span><span class="s1">&#39;micro&#39;</span><span class="p">)</span>
<span class="p">(</span><span class="mf">0.33</span><span class="o">...</span><span class="p">,</span> <span class="mf">0.33</span><span class="o">...</span><span class="p">,</span> <span class="mf">0.33</span><span class="o">...</span><span class="p">,</span> <span class="kc">None</span><span class="p">)</span>
<span class="o">&gt;&gt;&gt;</span> <span class="n">precision_recall_fscore_support</span><span class="p">(</span><span class="n">y_true</span><span class="p">,</span> <span class="n">y_pred</span><span class="p">,</span> <span class="n">average</span><span class="o">=</span><span class="s1">&#39;weighted&#39;</span><span class="p">)</span>
<span class="p">(</span><span class="mf">0.22</span><span class="o">...</span><span class="p">,</span> <span class="mf">0.33</span><span class="o">...</span><span class="p">,</span> <span class="mf">0.26</span><span class="o">...</span><span class="p">,</span> <span class="kc">None</span><span class="p">)</span>
</code></pre></div>

<p>It is possible to compute per-label precisions, recalls, F1-scores and
supports instead of averaging:</p>
<div class="highlight"><pre><span></span><code><span class="o">&gt;&gt;&gt;</span> <span class="n">precision_recall_fscore_support</span><span class="p">(</span><span class="n">y_true</span><span class="p">,</span> <span class="n">y_pred</span><span class="p">,</span> <span class="n">average</span><span class="o">=</span><span class="kc">None</span><span class="p">,</span>
<span class="o">...</span> <span class="n">labels</span><span class="o">=</span><span class="p">[</span><span class="s1">&#39;pig&#39;</span><span class="p">,</span> <span class="s1">&#39;dog&#39;</span><span class="p">,</span> <span class="s1">&#39;cat&#39;</span><span class="p">])</span>
<span class="p">(</span><span class="n">array</span><span class="p">([</span><span class="mf">0.</span>        <span class="p">,</span> <span class="mf">0.</span>        <span class="p">,</span> <span class="mf">0.66</span><span class="o">...</span><span class="p">]),</span>
 <span class="n">array</span><span class="p">([</span><span class="mf">0.</span><span class="p">,</span> <span class="mf">0.</span><span class="p">,</span> <span class="mf">1.</span><span class="p">]),</span> <span class="n">array</span><span class="p">([</span><span class="mf">0.</span> <span class="p">,</span> <span class="mf">0.</span> <span class="p">,</span> <span class="mf">0.8</span><span class="p">]),</span>
 <span class="n">array</span><span class="p">([</span><span class="mi">2</span><span class="p">,</span> <span class="mi">2</span><span class="p">,</span> <span class="mi">2</span><span class="p">]))</span>
</code></pre></div>

<h4>Notes</h4>
<p>When <code>true positive + false positive == 0</code>, precision is undefined;
When <code>true positive + false negative == 0</code>, recall is undefined.
In such cases, by default the metric will be set to 0, as will f-score,
and <code>UndefinedMetricWarning</code> will be raised. This behavior can be
modified with <code>zero_division</code>.</p>
</details>
<h3 id="precision_score">precision_score<a class="headerlink" href="#precision_score" title="Permanent link">&para;</a></h3>
<details class="note" open="open"><summary>function precision_score</summary><div class="highlight"><pre><span></span><code><span class="k">val</span> <span class="n">precision_score</span> <span class="o">:</span>
  <span class="o">?</span><span class="n">labels</span><span class="o">:[&gt;`</span><span class="nc">ArrayLike</span><span class="o">]</span> <span class="nn">Np</span><span class="p">.</span><span class="nn">Obj</span><span class="p">.</span><span class="n">t</span> <span class="o">-&gt;</span>
  <span class="o">?</span><span class="n">pos_label</span><span class="o">:[`</span><span class="nc">S</span> <span class="k">of</span> <span class="kt">string</span> <span class="o">|</span> <span class="o">`</span><span class="nc">I</span> <span class="k">of</span> <span class="kt">int</span><span class="o">]</span> <span class="o">-&gt;</span>
  <span class="o">?</span><span class="n">average</span><span class="o">:[`</span><span class="nc">Macro</span> <span class="o">|</span> <span class="o">`</span><span class="nc">Weighted</span> <span class="o">|</span> <span class="o">`</span><span class="nc">Samples</span> <span class="o">|</span> <span class="o">`</span><span class="nc">Micro</span> <span class="o">|</span> <span class="o">`</span><span class="nc">Binary</span> <span class="o">|</span> <span class="o">`</span><span class="nc">None</span><span class="o">]</span> <span class="o">-&gt;</span>
  <span class="o">?</span><span class="n">sample_weight</span><span class="o">:[&gt;`</span><span class="nc">ArrayLike</span><span class="o">]</span> <span class="nn">Np</span><span class="p">.</span><span class="nn">Obj</span><span class="p">.</span><span class="n">t</span> <span class="o">-&gt;</span>
  <span class="o">?</span><span class="n">zero_division</span><span class="o">:[`</span><span class="nc">Warn</span> <span class="o">|</span> <span class="o">`</span><span class="nc">Zero</span> <span class="o">|</span> <span class="o">`</span><span class="nc">One</span><span class="o">]</span> <span class="o">-&gt;</span>
  <span class="n">y_true</span><span class="o">:[&gt;`</span><span class="nc">ArrayLike</span><span class="o">]</span> <span class="nn">Np</span><span class="p">.</span><span class="nn">Obj</span><span class="p">.</span><span class="n">t</span> <span class="o">-&gt;</span>
  <span class="n">y_pred</span><span class="o">:[&gt;`</span><span class="nc">ArrayLike</span><span class="o">]</span> <span class="nn">Np</span><span class="p">.</span><span class="nn">Obj</span><span class="p">.</span><span class="n">t</span> <span class="o">-&gt;</span>
  <span class="kt">unit</span> <span class="o">-&gt;</span>
  <span class="o">[&gt;`</span><span class="nc">ArrayLike</span><span class="o">]</span> <span class="nn">Np</span><span class="p">.</span><span class="nn">Obj</span><span class="p">.</span><span class="n">t</span>
</code></pre></div>

<p>Compute the precision</p>
<p>The precision is the ratio <code>tp / (tp + fp)</code> where <code>tp</code> is the number of
true positives and <code>fp</code> the number of false positives. The precision is
intuitively the ability of the classifier not to label as positive a sample
that is negative.</p>
<p>The best value is 1 and the worst value is 0.</p>
<p>Read more in the :ref:<code>User Guide &lt;precision_recall_f_measure_metrics&gt;</code>.</p>
<h4>Parameters</h4>
<ul>
<li>
<p><strong>y_true : 1d array-like, or label indicator array / sparse matrix</strong>
    Ground truth (correct) target values.</p>
</li>
<li>
<p><strong>y_pred : 1d array-like, or label indicator array / sparse matrix</strong>
    Estimated targets as returned by a classifier.</p>
</li>
<li>
<p><strong>labels : list, optional</strong>
    The set of labels to include when <code>average != 'binary'</code>, and their
    order if <code>average is None</code>. Labels present in the data can be
    excluded, for example to calculate a multiclass average ignoring a
    majority negative class, while labels not present in the data will
    result in 0 components in a macro average. For multilabel targets,
    labels are column indices. By default, all labels in <code>y_true</code> and
    <code>y_pred</code> are used in sorted order.</p>
<p>.. versionchanged:: 0.17
   parameter <em>labels</em> improved for multiclass problem.</p>
</li>
<li>
<p><strong>pos_label : str or int, 1 by default</strong>
    The class to report if <code>average='binary'</code> and the data is binary.
    If the data are multiclass or multilabel, this will be ignored;
    setting <code>labels=[pos_label]</code> and <code>average != 'binary'</code> will report
    scores for that label only.</p>
</li>
<li>
<p><strong>average : string, [None, 'binary' (default), 'micro', 'macro', 'samples',                        'weighted']</strong>
    This parameter is required for multiclass/multilabel targets.
    If <code>None</code>, the scores for each class are returned. Otherwise, this
    determines the type of averaging performed on the data:</p>
<p><code>'binary'</code>:
    Only report results for the class specified by <code>pos_label</code>.
    This is applicable only if targets (<code>y_{true,pred}</code>) are binary.
<code>'micro'</code>:
    Calculate metrics globally by counting the total true positives,
    false negatives and false positives.
<code>'macro'</code>:
    Calculate metrics for each label, and find their unweighted
    mean.  This does not take label imbalance into account.
<code>'weighted'</code>:
    Calculate metrics for each label, and find their average weighted
    by support (the number of true instances for each label). This
    alters 'macro' to account for label imbalance; it can result in an
    F-score that is not between precision and recall.
<code>'samples'</code>:
    Calculate metrics for each instance, and find their average (only
    meaningful for multilabel classification where this differs from
    :func:<code>accuracy_score</code>).</p>
</li>
<li>
<p><strong>sample_weight : array-like of shape (n_samples,), default=None</strong>
    Sample weights.</p>
</li>
<li>
<p><strong>zero_division : 'warn', 0 or 1, default='warn'</strong>
    Sets the value to return when there is a zero division. If set to
    'warn', this acts as 0, but warnings are also raised.</p>
</li>
</ul>
<h4>Returns</h4>
<ul>
<li><strong>precision : float (if average is not None) or array of float, shape =        [n_unique_labels]</strong>
    Precision of the positive class in binary classification or weighted
    average of the precision of each class for the multiclass task.</li>
</ul>
<h4>See also</h4>
<p>precision_recall_fscore_support, multilabel_confusion_matrix</p>
<h4>Examples</h4>
<div class="highlight"><pre><span></span><code><span class="o">&gt;&gt;&gt;</span> <span class="kn">from</span> <span class="nn">sklearn.metrics</span> <span class="kn">import</span> <span class="n">precision_score</span>
<span class="o">&gt;&gt;&gt;</span> <span class="n">y_true</span> <span class="o">=</span> <span class="p">[</span><span class="mi">0</span><span class="p">,</span> <span class="mi">1</span><span class="p">,</span> <span class="mi">2</span><span class="p">,</span> <span class="mi">0</span><span class="p">,</span> <span class="mi">1</span><span class="p">,</span> <span class="mi">2</span><span class="p">]</span>
<span class="o">&gt;&gt;&gt;</span> <span class="n">y_pred</span> <span class="o">=</span> <span class="p">[</span><span class="mi">0</span><span class="p">,</span> <span class="mi">2</span><span class="p">,</span> <span class="mi">1</span><span class="p">,</span> <span class="mi">0</span><span class="p">,</span> <span class="mi">0</span><span class="p">,</span> <span class="mi">1</span><span class="p">]</span>
<span class="o">&gt;&gt;&gt;</span> <span class="n">precision_score</span><span class="p">(</span><span class="n">y_true</span><span class="p">,</span> <span class="n">y_pred</span><span class="p">,</span> <span class="n">average</span><span class="o">=</span><span class="s1">&#39;macro&#39;</span><span class="p">)</span>
<span class="mf">0.22</span><span class="o">...</span>
<span class="o">&gt;&gt;&gt;</span> <span class="n">precision_score</span><span class="p">(</span><span class="n">y_true</span><span class="p">,</span> <span class="n">y_pred</span><span class="p">,</span> <span class="n">average</span><span class="o">=</span><span class="s1">&#39;micro&#39;</span><span class="p">)</span>
<span class="mf">0.33</span><span class="o">...</span>
<span class="o">&gt;&gt;&gt;</span> <span class="n">precision_score</span><span class="p">(</span><span class="n">y_true</span><span class="p">,</span> <span class="n">y_pred</span><span class="p">,</span> <span class="n">average</span><span class="o">=</span><span class="s1">&#39;weighted&#39;</span><span class="p">)</span>
<span class="mf">0.22</span><span class="o">...</span>
<span class="o">&gt;&gt;&gt;</span> <span class="n">precision_score</span><span class="p">(</span><span class="n">y_true</span><span class="p">,</span> <span class="n">y_pred</span><span class="p">,</span> <span class="n">average</span><span class="o">=</span><span class="kc">None</span><span class="p">)</span>
<span class="n">array</span><span class="p">([</span><span class="mf">0.66</span><span class="o">...</span><span class="p">,</span> <span class="mf">0.</span>        <span class="p">,</span> <span class="mf">0.</span>        <span class="p">])</span>
<span class="o">&gt;&gt;&gt;</span> <span class="n">y_pred</span> <span class="o">=</span> <span class="p">[</span><span class="mi">0</span><span class="p">,</span> <span class="mi">0</span><span class="p">,</span> <span class="mi">0</span><span class="p">,</span> <span class="mi">0</span><span class="p">,</span> <span class="mi">0</span><span class="p">,</span> <span class="mi">0</span><span class="p">]</span>
<span class="o">&gt;&gt;&gt;</span> <span class="n">precision_score</span><span class="p">(</span><span class="n">y_true</span><span class="p">,</span> <span class="n">y_pred</span><span class="p">,</span> <span class="n">average</span><span class="o">=</span><span class="kc">None</span><span class="p">)</span>
<span class="n">array</span><span class="p">([</span><span class="mf">0.33</span><span class="o">...</span><span class="p">,</span> <span class="mf">0.</span>        <span class="p">,</span> <span class="mf">0.</span>        <span class="p">])</span>
<span class="o">&gt;&gt;&gt;</span> <span class="n">precision_score</span><span class="p">(</span><span class="n">y_true</span><span class="p">,</span> <span class="n">y_pred</span><span class="p">,</span> <span class="n">average</span><span class="o">=</span><span class="kc">None</span><span class="p">,</span> <span class="n">zero_division</span><span class="o">=</span><span class="mi">1</span><span class="p">)</span>
<span class="n">array</span><span class="p">([</span><span class="mf">0.33</span><span class="o">...</span><span class="p">,</span> <span class="mf">1.</span>        <span class="p">,</span> <span class="mf">1.</span>        <span class="p">])</span>
</code></pre></div>

<h4>Notes</h4>
<p>When <code>true positive + false positive == 0</code>, precision returns 0 and
raises <code>UndefinedMetricWarning</code>. This behavior can be
modified with <code>zero_division</code>.</p>
</details>
<h3 id="r2_score">r2_score<a class="headerlink" href="#r2_score" title="Permanent link">&para;</a></h3>
<details class="note" open="open"><summary>function r2_score</summary><div class="highlight"><pre><span></span><code><span class="k">val</span> <span class="n">r2_score</span> <span class="o">:</span>
  <span class="o">?</span><span class="n">sample_weight</span><span class="o">:[&gt;`</span><span class="nc">ArrayLike</span><span class="o">]</span> <span class="nn">Np</span><span class="p">.</span><span class="nn">Obj</span><span class="p">.</span><span class="n">t</span> <span class="o">-&gt;</span>
  <span class="o">?</span><span class="n">multioutput</span><span class="o">:[`</span><span class="nc">Arr</span> <span class="k">of</span> <span class="o">[&gt;`</span><span class="nc">ArrayLike</span><span class="o">]</span> <span class="nn">Np</span><span class="p">.</span><span class="nn">Obj</span><span class="p">.</span><span class="n">t</span> <span class="o">|</span> <span class="o">`</span><span class="nc">Variance_weighted</span> <span class="o">|</span> <span class="o">`</span><span class="nc">Uniform_average</span> <span class="o">|</span> <span class="o">`</span><span class="nc">Raw_values</span> <span class="o">|</span> <span class="o">`</span><span class="nc">None</span><span class="o">]</span> <span class="o">-&gt;</span>
  <span class="n">y_true</span><span class="o">:[&gt;`</span><span class="nc">ArrayLike</span><span class="o">]</span> <span class="nn">Np</span><span class="p">.</span><span class="nn">Obj</span><span class="p">.</span><span class="n">t</span> <span class="o">-&gt;</span>
  <span class="n">y_pred</span><span class="o">:[&gt;`</span><span class="nc">ArrayLike</span><span class="o">]</span> <span class="nn">Np</span><span class="p">.</span><span class="nn">Obj</span><span class="p">.</span><span class="n">t</span> <span class="o">-&gt;</span>
  <span class="kt">unit</span> <span class="o">-&gt;</span>
  <span class="o">[&gt;`</span><span class="nc">ArrayLike</span><span class="o">]</span> <span class="nn">Np</span><span class="p">.</span><span class="nn">Obj</span><span class="p">.</span><span class="n">t</span>
</code></pre></div>

<p>R^2 (coefficient of determination) regression score function.</p>
<p>Best possible score is 1.0 and it can be negative (because the
model can be arbitrarily worse). A constant model that always
predicts the expected value of y, disregarding the input features,
would get a R^2 score of 0.0.</p>
<p>Read more in the :ref:<code>User Guide &lt;r2_score&gt;</code>.</p>
<h4>Parameters</h4>
<ul>
<li>
<p><strong>y_true : array-like of shape (n_samples,) or (n_samples, n_outputs)</strong>
    Ground truth (correct) target values.</p>
</li>
<li>
<p><strong>y_pred : array-like of shape (n_samples,) or (n_samples, n_outputs)</strong>
    Estimated target values.</p>
</li>
<li>
<p><strong>sample_weight : array-like of shape (n_samples,), optional</strong>
    Sample weights.</p>
</li>
<li>
<p><strong>multioutput : string in ['raw_values', 'uniform_average', 'variance_weighted'] or None or array-like of shape (n_outputs)</strong></p>
<p>Defines aggregating of multiple output scores.
Array-like value defines weights used to average scores.
Default is 'uniform_average'.</p>
<p>'raw_values' :
    Returns a full set of scores in case of multioutput input.</p>
<p>'uniform_average' :
    Scores of all outputs are averaged with uniform weight.</p>
<p>'variance_weighted' :
    Scores of all outputs are averaged, weighted by the variances
    of each individual output.</p>
<p>.. versionchanged:: 0.19
    Default value of multioutput is 'uniform_average'.</p>
</li>
</ul>
<h4>Returns</h4>
<ul>
<li><strong>z : float or ndarray of floats</strong>
    The R^2 score or ndarray of scores if 'multioutput' is
    'raw_values'.</li>
</ul>
<h4>Notes</h4>
<p>This is not a symmetric function.</p>
<p>Unlike most other scores, R^2 score may be negative (it need not actually
be the square of a quantity R).</p>
<p>This metric is not well-defined for single samples and will return a NaN
value if n_samples is less than two.</p>
<h4>References</h4>
<p>.. [1] <code>Wikipedia entry on the Coefficient of determination
        &lt;https://en.wikipedia.org/wiki/Coefficient_of_determination&gt;</code>_</p>
<h4>Examples</h4>
<div class="highlight"><pre><span></span><code><span class="o">&gt;&gt;&gt;</span> <span class="kn">from</span> <span class="nn">sklearn.metrics</span> <span class="kn">import</span> <span class="n">r2_score</span>
<span class="o">&gt;&gt;&gt;</span> <span class="n">y_true</span> <span class="o">=</span> <span class="p">[</span><span class="mi">3</span><span class="p">,</span> <span class="o">-</span><span class="mf">0.5</span><span class="p">,</span> <span class="mi">2</span><span class="p">,</span> <span class="mi">7</span><span class="p">]</span>
<span class="o">&gt;&gt;&gt;</span> <span class="n">y_pred</span> <span class="o">=</span> <span class="p">[</span><span class="mf">2.5</span><span class="p">,</span> <span class="mf">0.0</span><span class="p">,</span> <span class="mi">2</span><span class="p">,</span> <span class="mi">8</span><span class="p">]</span>
<span class="o">&gt;&gt;&gt;</span> <span class="n">r2_score</span><span class="p">(</span><span class="n">y_true</span><span class="p">,</span> <span class="n">y_pred</span><span class="p">)</span>
<span class="mf">0.948</span><span class="o">...</span>
<span class="o">&gt;&gt;&gt;</span> <span class="n">y_true</span> <span class="o">=</span> <span class="p">[[</span><span class="mf">0.5</span><span class="p">,</span> <span class="mi">1</span><span class="p">],</span> <span class="p">[</span><span class="o">-</span><span class="mi">1</span><span class="p">,</span> <span class="mi">1</span><span class="p">],</span> <span class="p">[</span><span class="mi">7</span><span class="p">,</span> <span class="o">-</span><span class="mi">6</span><span class="p">]]</span>
<span class="o">&gt;&gt;&gt;</span> <span class="n">y_pred</span> <span class="o">=</span> <span class="p">[[</span><span class="mi">0</span><span class="p">,</span> <span class="mi">2</span><span class="p">],</span> <span class="p">[</span><span class="o">-</span><span class="mi">1</span><span class="p">,</span> <span class="mi">2</span><span class="p">],</span> <span class="p">[</span><span class="mi">8</span><span class="p">,</span> <span class="o">-</span><span class="mi">5</span><span class="p">]]</span>
<span class="o">&gt;&gt;&gt;</span> <span class="n">r2_score</span><span class="p">(</span><span class="n">y_true</span><span class="p">,</span> <span class="n">y_pred</span><span class="p">,</span>
<span class="o">...</span>          <span class="n">multioutput</span><span class="o">=</span><span class="s1">&#39;variance_weighted&#39;</span><span class="p">)</span>
<span class="mf">0.938</span><span class="o">...</span>
<span class="o">&gt;&gt;&gt;</span> <span class="n">y_true</span> <span class="o">=</span> <span class="p">[</span><span class="mi">1</span><span class="p">,</span> <span class="mi">2</span><span class="p">,</span> <span class="mi">3</span><span class="p">]</span>
<span class="o">&gt;&gt;&gt;</span> <span class="n">y_pred</span> <span class="o">=</span> <span class="p">[</span><span class="mi">1</span><span class="p">,</span> <span class="mi">2</span><span class="p">,</span> <span class="mi">3</span><span class="p">]</span>
<span class="o">&gt;&gt;&gt;</span> <span class="n">r2_score</span><span class="p">(</span><span class="n">y_true</span><span class="p">,</span> <span class="n">y_pred</span><span class="p">)</span>
<span class="mf">1.0</span>
<span class="o">&gt;&gt;&gt;</span> <span class="n">y_true</span> <span class="o">=</span> <span class="p">[</span><span class="mi">1</span><span class="p">,</span> <span class="mi">2</span><span class="p">,</span> <span class="mi">3</span><span class="p">]</span>
<span class="o">&gt;&gt;&gt;</span> <span class="n">y_pred</span> <span class="o">=</span> <span class="p">[</span><span class="mi">2</span><span class="p">,</span> <span class="mi">2</span><span class="p">,</span> <span class="mi">2</span><span class="p">]</span>
<span class="o">&gt;&gt;&gt;</span> <span class="n">r2_score</span><span class="p">(</span><span class="n">y_true</span><span class="p">,</span> <span class="n">y_pred</span><span class="p">)</span>
<span class="mf">0.0</span>
<span class="o">&gt;&gt;&gt;</span> <span class="n">y_true</span> <span class="o">=</span> <span class="p">[</span><span class="mi">1</span><span class="p">,</span> <span class="mi">2</span><span class="p">,</span> <span class="mi">3</span><span class="p">]</span>
<span class="o">&gt;&gt;&gt;</span> <span class="n">y_pred</span> <span class="o">=</span> <span class="p">[</span><span class="mi">3</span><span class="p">,</span> <span class="mi">2</span><span class="p">,</span> <span class="mi">1</span><span class="p">]</span>
<span class="o">&gt;&gt;&gt;</span> <span class="n">r2_score</span><span class="p">(</span><span class="n">y_true</span><span class="p">,</span> <span class="n">y_pred</span><span class="p">)</span>
<span class="o">-</span><span class="mf">3.0</span>
</code></pre></div>

</details>
<h3 id="recall_score">recall_score<a class="headerlink" href="#recall_score" title="Permanent link">&para;</a></h3>
<details class="note" open="open"><summary>function recall_score</summary><div class="highlight"><pre><span></span><code><span class="k">val</span> <span class="n">recall_score</span> <span class="o">:</span>
  <span class="o">?</span><span class="n">labels</span><span class="o">:[&gt;`</span><span class="nc">ArrayLike</span><span class="o">]</span> <span class="nn">Np</span><span class="p">.</span><span class="nn">Obj</span><span class="p">.</span><span class="n">t</span> <span class="o">-&gt;</span>
  <span class="o">?</span><span class="n">pos_label</span><span class="o">:[`</span><span class="nc">S</span> <span class="k">of</span> <span class="kt">string</span> <span class="o">|</span> <span class="o">`</span><span class="nc">I</span> <span class="k">of</span> <span class="kt">int</span><span class="o">]</span> <span class="o">-&gt;</span>
  <span class="o">?</span><span class="n">average</span><span class="o">:[`</span><span class="nc">Macro</span> <span class="o">|</span> <span class="o">`</span><span class="nc">Weighted</span> <span class="o">|</span> <span class="o">`</span><span class="nc">Samples</span> <span class="o">|</span> <span class="o">`</span><span class="nc">Micro</span> <span class="o">|</span> <span class="o">`</span><span class="nc">Binary</span> <span class="o">|</span> <span class="o">`</span><span class="nc">None</span><span class="o">]</span> <span class="o">-&gt;</span>
  <span class="o">?</span><span class="n">sample_weight</span><span class="o">:[&gt;`</span><span class="nc">ArrayLike</span><span class="o">]</span> <span class="nn">Np</span><span class="p">.</span><span class="nn">Obj</span><span class="p">.</span><span class="n">t</span> <span class="o">-&gt;</span>
  <span class="o">?</span><span class="n">zero_division</span><span class="o">:[`</span><span class="nc">Warn</span> <span class="o">|</span> <span class="o">`</span><span class="nc">Zero</span> <span class="o">|</span> <span class="o">`</span><span class="nc">One</span><span class="o">]</span> <span class="o">-&gt;</span>
  <span class="n">y_true</span><span class="o">:[&gt;`</span><span class="nc">ArrayLike</span><span class="o">]</span> <span class="nn">Np</span><span class="p">.</span><span class="nn">Obj</span><span class="p">.</span><span class="n">t</span> <span class="o">-&gt;</span>
  <span class="n">y_pred</span><span class="o">:[&gt;`</span><span class="nc">ArrayLike</span><span class="o">]</span> <span class="nn">Np</span><span class="p">.</span><span class="nn">Obj</span><span class="p">.</span><span class="n">t</span> <span class="o">-&gt;</span>
  <span class="kt">unit</span> <span class="o">-&gt;</span>
  <span class="o">[&gt;`</span><span class="nc">ArrayLike</span><span class="o">]</span> <span class="nn">Np</span><span class="p">.</span><span class="nn">Obj</span><span class="p">.</span><span class="n">t</span>
</code></pre></div>

<p>Compute the recall</p>
<p>The recall is the ratio <code>tp / (tp + fn)</code> where <code>tp</code> is the number of
true positives and <code>fn</code> the number of false negatives. The recall is
intuitively the ability of the classifier to find all the positive samples.</p>
<p>The best value is 1 and the worst value is 0.</p>
<p>Read more in the :ref:<code>User Guide &lt;precision_recall_f_measure_metrics&gt;</code>.</p>
<h4>Parameters</h4>
<ul>
<li>
<p><strong>y_true : 1d array-like, or label indicator array / sparse matrix</strong>
    Ground truth (correct) target values.</p>
</li>
<li>
<p><strong>y_pred : 1d array-like, or label indicator array / sparse matrix</strong>
    Estimated targets as returned by a classifier.</p>
</li>
<li>
<p><strong>labels : list, optional</strong>
    The set of labels to include when <code>average != 'binary'</code>, and their
    order if <code>average is None</code>. Labels present in the data can be
    excluded, for example to calculate a multiclass average ignoring a
    majority negative class, while labels not present in the data will
    result in 0 components in a macro average. For multilabel targets,
    labels are column indices. By default, all labels in <code>y_true</code> and
    <code>y_pred</code> are used in sorted order.</p>
<p>.. versionchanged:: 0.17
   parameter <em>labels</em> improved for multiclass problem.</p>
</li>
<li>
<p><strong>pos_label : str or int, 1 by default</strong>
    The class to report if <code>average='binary'</code> and the data is binary.
    If the data are multiclass or multilabel, this will be ignored;
    setting <code>labels=[pos_label]</code> and <code>average != 'binary'</code> will report
    scores for that label only.</p>
</li>
<li>
<p><strong>average : string, [None, 'binary' (default), 'micro', 'macro', 'samples',                        'weighted']</strong>
    This parameter is required for multiclass/multilabel targets.
    If <code>None</code>, the scores for each class are returned. Otherwise, this
    determines the type of averaging performed on the data:</p>
<p><code>'binary'</code>:
    Only report results for the class specified by <code>pos_label</code>.
    This is applicable only if targets (<code>y_{true,pred}</code>) are binary.
<code>'micro'</code>:
    Calculate metrics globally by counting the total true positives,
    false negatives and false positives.
<code>'macro'</code>:
    Calculate metrics for each label, and find their unweighted
    mean.  This does not take label imbalance into account.
<code>'weighted'</code>:
    Calculate metrics for each label, and find their average weighted
    by support (the number of true instances for each label). This
    alters 'macro' to account for label imbalance; it can result in an
    F-score that is not between precision and recall.
<code>'samples'</code>:
    Calculate metrics for each instance, and find their average (only
    meaningful for multilabel classification where this differs from
    :func:<code>accuracy_score</code>).</p>
</li>
<li>
<p><strong>sample_weight : array-like of shape (n_samples,), default=None</strong>
    Sample weights.</p>
</li>
<li>
<p><strong>zero_division : 'warn', 0 or 1, default='warn'</strong>
    Sets the value to return when there is a zero division. If set to
    'warn', this acts as 0, but warnings are also raised.</p>
</li>
</ul>
<h4>Returns</h4>
<ul>
<li><strong>recall : float (if average is not None) or array of float, shape =        [n_unique_labels]</strong>
    Recall of the positive class in binary classification or weighted
    average of the recall of each class for the multiclass task.</li>
</ul>
<h4>See also</h4>
<p>precision_recall_fscore_support, balanced_accuracy_score,
multilabel_confusion_matrix</p>
<h4>Examples</h4>
<div class="highlight"><pre><span></span><code><span class="o">&gt;&gt;&gt;</span> <span class="kn">from</span> <span class="nn">sklearn.metrics</span> <span class="kn">import</span> <span class="n">recall_score</span>
<span class="o">&gt;&gt;&gt;</span> <span class="n">y_true</span> <span class="o">=</span> <span class="p">[</span><span class="mi">0</span><span class="p">,</span> <span class="mi">1</span><span class="p">,</span> <span class="mi">2</span><span class="p">,</span> <span class="mi">0</span><span class="p">,</span> <span class="mi">1</span><span class="p">,</span> <span class="mi">2</span><span class="p">]</span>
<span class="o">&gt;&gt;&gt;</span> <span class="n">y_pred</span> <span class="o">=</span> <span class="p">[</span><span class="mi">0</span><span class="p">,</span> <span class="mi">2</span><span class="p">,</span> <span class="mi">1</span><span class="p">,</span> <span class="mi">0</span><span class="p">,</span> <span class="mi">0</span><span class="p">,</span> <span class="mi">1</span><span class="p">]</span>
<span class="o">&gt;&gt;&gt;</span> <span class="n">recall_score</span><span class="p">(</span><span class="n">y_true</span><span class="p">,</span> <span class="n">y_pred</span><span class="p">,</span> <span class="n">average</span><span class="o">=</span><span class="s1">&#39;macro&#39;</span><span class="p">)</span>
<span class="mf">0.33</span><span class="o">...</span>
<span class="o">&gt;&gt;&gt;</span> <span class="n">recall_score</span><span class="p">(</span><span class="n">y_true</span><span class="p">,</span> <span class="n">y_pred</span><span class="p">,</span> <span class="n">average</span><span class="o">=</span><span class="s1">&#39;micro&#39;</span><span class="p">)</span>
<span class="mf">0.33</span><span class="o">...</span>
<span class="o">&gt;&gt;&gt;</span> <span class="n">recall_score</span><span class="p">(</span><span class="n">y_true</span><span class="p">,</span> <span class="n">y_pred</span><span class="p">,</span> <span class="n">average</span><span class="o">=</span><span class="s1">&#39;weighted&#39;</span><span class="p">)</span>
<span class="mf">0.33</span><span class="o">...</span>
<span class="o">&gt;&gt;&gt;</span> <span class="n">recall_score</span><span class="p">(</span><span class="n">y_true</span><span class="p">,</span> <span class="n">y_pred</span><span class="p">,</span> <span class="n">average</span><span class="o">=</span><span class="kc">None</span><span class="p">)</span>
<span class="n">array</span><span class="p">([</span><span class="mf">1.</span><span class="p">,</span> <span class="mf">0.</span><span class="p">,</span> <span class="mf">0.</span><span class="p">])</span>
<span class="o">&gt;&gt;&gt;</span> <span class="n">y_true</span> <span class="o">=</span> <span class="p">[</span><span class="mi">0</span><span class="p">,</span> <span class="mi">0</span><span class="p">,</span> <span class="mi">0</span><span class="p">,</span> <span class="mi">0</span><span class="p">,</span> <span class="mi">0</span><span class="p">,</span> <span class="mi">0</span><span class="p">]</span>
<span class="o">&gt;&gt;&gt;</span> <span class="n">recall_score</span><span class="p">(</span><span class="n">y_true</span><span class="p">,</span> <span class="n">y_pred</span><span class="p">,</span> <span class="n">average</span><span class="o">=</span><span class="kc">None</span><span class="p">)</span>
<span class="n">array</span><span class="p">([</span><span class="mf">0.5</span><span class="p">,</span> <span class="mf">0.</span> <span class="p">,</span> <span class="mf">0.</span> <span class="p">])</span>
<span class="o">&gt;&gt;&gt;</span> <span class="n">recall_score</span><span class="p">(</span><span class="n">y_true</span><span class="p">,</span> <span class="n">y_pred</span><span class="p">,</span> <span class="n">average</span><span class="o">=</span><span class="kc">None</span><span class="p">,</span> <span class="n">zero_division</span><span class="o">=</span><span class="mi">1</span><span class="p">)</span>
<span class="n">array</span><span class="p">([</span><span class="mf">0.5</span><span class="p">,</span> <span class="mf">1.</span> <span class="p">,</span> <span class="mf">1.</span> <span class="p">])</span>
</code></pre></div>

<h4>Notes</h4>
<p>When <code>true positive + false negative == 0</code>, recall returns 0 and raises
<code>UndefinedMetricWarning</code>. This behavior can be modified with
<code>zero_division</code>.</p>
</details>
<h3 id="roc_auc_score">roc_auc_score<a class="headerlink" href="#roc_auc_score" title="Permanent link">&para;</a></h3>
<details class="note" open="open"><summary>function roc_auc_score</summary><div class="highlight"><pre><span></span><code><span class="k">val</span> <span class="n">roc_auc_score</span> <span class="o">:</span>
  <span class="o">?</span><span class="n">average</span><span class="o">:[`</span><span class="nc">Macro</span> <span class="o">|</span> <span class="o">`</span><span class="nc">Micro</span> <span class="o">|</span> <span class="o">`</span><span class="nc">Weighted</span> <span class="o">|</span> <span class="o">`</span><span class="nc">Samples</span> <span class="o">|</span> <span class="o">`</span><span class="nc">None</span><span class="o">]</span> <span class="o">-&gt;</span>
  <span class="o">?</span><span class="n">sample_weight</span><span class="o">:[&gt;`</span><span class="nc">ArrayLike</span><span class="o">]</span> <span class="nn">Np</span><span class="p">.</span><span class="nn">Obj</span><span class="p">.</span><span class="n">t</span> <span class="o">-&gt;</span>
  <span class="o">?</span><span class="n">max_fpr</span><span class="o">:</span><span class="nn">Py</span><span class="p">.</span><span class="nn">Object</span><span class="p">.</span><span class="n">t</span> <span class="o">-&gt;</span>
  <span class="o">?</span><span class="n">multi_class</span><span class="o">:[`</span><span class="nc">Raise</span> <span class="o">|</span> <span class="o">`</span><span class="nc">Ovr</span> <span class="o">|</span> <span class="o">`</span><span class="nc">Ovo</span><span class="o">]</span> <span class="o">-&gt;</span>
  <span class="o">?</span><span class="n">labels</span><span class="o">:[&gt;`</span><span class="nc">ArrayLike</span><span class="o">]</span> <span class="nn">Np</span><span class="p">.</span><span class="nn">Obj</span><span class="p">.</span><span class="n">t</span> <span class="o">-&gt;</span>
  <span class="n">y_true</span><span class="o">:[&gt;`</span><span class="nc">ArrayLike</span><span class="o">]</span> <span class="nn">Np</span><span class="p">.</span><span class="nn">Obj</span><span class="p">.</span><span class="n">t</span> <span class="o">-&gt;</span>
  <span class="n">y_score</span><span class="o">:[&gt;`</span><span class="nc">ArrayLike</span><span class="o">]</span> <span class="nn">Np</span><span class="p">.</span><span class="nn">Obj</span><span class="p">.</span><span class="n">t</span> <span class="o">-&gt;</span>
  <span class="kt">unit</span> <span class="o">-&gt;</span>
  <span class="kt">float</span>
</code></pre></div>

<p>Compute Area Under the Receiver Operating Characteristic Curve (ROC AUC)
from prediction scores.</p>
<ul>
<li><strong>Note: this implementation can be used with binary, multiclass and</strong>
multilabel classification, but some restrictions apply (see Parameters).</li>
</ul>
<p>Read more in the :ref:<code>User Guide &lt;roc_metrics&gt;</code>.</p>
<h4>Parameters</h4>
<ul>
<li>
<p><strong>y_true : array-like of shape (n_samples,) or (n_samples, n_classes)</strong>
    True labels or binary label indicators. The binary and multiclass cases
    expect labels with shape (n_samples,) while the multilabel case expects
    binary label indicators with shape (n_samples, n_classes).</p>
</li>
<li>
<p><strong>y_score : array-like of shape (n_samples,) or (n_samples, n_classes)</strong>
    Target scores. In the binary and multilabel cases, these can be either
    probability estimates or non-thresholded decision values (as returned
    by <code>decision_function</code> on some classifiers). In the multiclass case,
    these must be probability estimates which sum to 1. The binary
    case expects a shape (n_samples,), and the scores must be the scores of
    the class with the greater label. The multiclass and multilabel
    cases expect a shape (n_samples, n_classes). In the multiclass case,
    the order of the class scores must correspond to the order of
    <code>labels</code>, if provided, or else to the numerical or lexicographical
    order of the labels in <code>y_true</code>.</p>
</li>
<li>
<p><strong>average : {'micro', 'macro', 'samples', 'weighted'} or None,             default='macro'</strong>
    If <code>None</code>, the scores for each class are returned. Otherwise,
    this determines the type of averaging performed on the data:</p>
</li>
<li>
<p><strong>Note: multiclass ROC AUC currently only handles the 'macro' and</strong>
    'weighted' averages.</p>
<p><code>'micro'</code>:
    Calculate metrics globally by considering each element of the label
    indicator matrix as a label.
<code>'macro'</code>:
    Calculate metrics for each label, and find their unweighted
    mean.  This does not take label imbalance into account.
<code>'weighted'</code>:
    Calculate metrics for each label, and find their average, weighted
    by support (the number of true instances for each label).
<code>'samples'</code>:
    Calculate metrics for each instance, and find their average.</p>
<p>Will be ignored when <code>y_true</code> is binary.</p>
</li>
<li>
<p><strong>sample_weight : array-like of shape (n_samples,), default=None</strong>
    Sample weights.</p>
</li>
<li>
<p><strong>max_fpr : float &gt; 0 and &lt;= 1, default=None</strong>
    If not <code>None</code>, the standardized partial AUC [2]_ over the range
    [0, max_fpr] is returned. For the multiclass case, <code>max_fpr</code>,
    should be either equal to <code>None</code> or <code>1.0</code> as AUC ROC partial
    computation currently is not supported for multiclass.</p>
</li>
<li>
<p><strong>multi_class : {'raise', 'ovr', 'ovo'}, default='raise'</strong>
    Multiclass only. Determines the type of configuration to use. The
    default value raises an error, so either <code>'ovr'</code> or <code>'ovo'</code> must be
    passed explicitly.</p>
<p><code>'ovr'</code>:
    Computes the AUC of each class against the rest [3]<em> [4]</em>. This
    treats the multiclass case in the same way as the multilabel case.
    Sensitive to class imbalance even when <code>average == 'macro'</code>,
    because class imbalance affects the composition of each of the
    'rest' groupings.
<code>'ovo'</code>:
    Computes the average AUC of all possible pairwise combinations of
    classes [5]_. Insensitive to class imbalance when
    <code>average == 'macro'</code>.</p>
</li>
<li>
<p><strong>labels : array-like of shape (n_classes,), default=None</strong>
    Multiclass only. List of labels that index the classes in <code>y_score</code>.
    If <code>None</code>, the numerical or lexicographical order of the labels in
    <code>y_true</code> is used.</p>
</li>
</ul>
<h4>Returns</h4>
<ul>
<li><strong>auc : float</strong></li>
</ul>
<h4>References</h4>
<p>.. [1] <code>Wikipedia entry for the Receiver operating characteristic
        &lt;https://en.wikipedia.org/wiki/Receiver_operating_characteristic&gt;</code>_</p>
<p>.. [2] <code>Analyzing a portion of the ROC curve. McClish, 1989
        &lt;https://www.ncbi.nlm.nih.gov/pubmed/2668680&gt;</code>_</p>
<p>.. [3] Provost, F., Domingos, P. (2000). Well-trained PETs: Improving
       probability estimation trees (Section 6.2), CeDER Working Paper
       #IS-00-04, Stern School of Business, New York University.</p>
<p>.. [4] <code>Fawcett, T. (2006). An introduction to ROC analysis. Pattern
        Recognition Letters, 27(8), 861-874.
        &lt;https://www.sciencedirect.com/science/article/pii/S016786550500303X&gt;</code>_</p>
<p>.. [5] <code>Hand, D.J., Till, R.J. (2001). A Simple Generalisation of the Area
        Under the ROC Curve for Multiple Class Classification Problems.
        Machine Learning, 45(2), 171-186.
        &lt;http://link.springer.com/article/10.1023/A:1010920819831&gt;</code>_</p>
<h4>See also</h4>
<ul>
<li>
<p><strong>average_precision_score : Area under the precision-recall curve</strong></p>
</li>
<li>
<p><strong>roc_curve : Compute Receiver operating characteristic (ROC) curve</strong></p>
</li>
</ul>
<h4>Examples</h4>
<div class="highlight"><pre><span></span><code><span class="o">&gt;&gt;&gt;</span> <span class="kn">import</span> <span class="nn">numpy</span> <span class="k">as</span> <span class="nn">np</span>
<span class="o">&gt;&gt;&gt;</span> <span class="kn">from</span> <span class="nn">sklearn.metrics</span> <span class="kn">import</span> <span class="n">roc_auc_score</span>
<span class="o">&gt;&gt;&gt;</span> <span class="n">y_true</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">array</span><span class="p">([</span><span class="mi">0</span><span class="p">,</span> <span class="mi">0</span><span class="p">,</span> <span class="mi">1</span><span class="p">,</span> <span class="mi">1</span><span class="p">])</span>
<span class="o">&gt;&gt;&gt;</span> <span class="n">y_scores</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">array</span><span class="p">([</span><span class="mf">0.1</span><span class="p">,</span> <span class="mf">0.4</span><span class="p">,</span> <span class="mf">0.35</span><span class="p">,</span> <span class="mf">0.8</span><span class="p">])</span>
<span class="o">&gt;&gt;&gt;</span> <span class="n">roc_auc_score</span><span class="p">(</span><span class="n">y_true</span><span class="p">,</span> <span class="n">y_scores</span><span class="p">)</span>
<span class="mf">0.75</span>
</code></pre></div>

</details>
<h3 id="roc_curve">roc_curve<a class="headerlink" href="#roc_curve" title="Permanent link">&para;</a></h3>
<details class="note" open="open"><summary>function roc_curve</summary><div class="highlight"><pre><span></span><code><span class="k">val</span> <span class="n">roc_curve</span> <span class="o">:</span>
  <span class="o">?</span><span class="n">pos_label</span><span class="o">:[`</span><span class="nc">S</span> <span class="k">of</span> <span class="kt">string</span> <span class="o">|</span> <span class="o">`</span><span class="nc">I</span> <span class="k">of</span> <span class="kt">int</span><span class="o">]</span> <span class="o">-&gt;</span>
  <span class="o">?</span><span class="n">sample_weight</span><span class="o">:[&gt;`</span><span class="nc">ArrayLike</span><span class="o">]</span> <span class="nn">Np</span><span class="p">.</span><span class="nn">Obj</span><span class="p">.</span><span class="n">t</span> <span class="o">-&gt;</span>
  <span class="o">?</span><span class="n">drop_intermediate</span><span class="o">:</span><span class="kt">bool</span> <span class="o">-&gt;</span>
  <span class="n">y_true</span><span class="o">:[&gt;`</span><span class="nc">ArrayLike</span><span class="o">]</span> <span class="nn">Np</span><span class="p">.</span><span class="nn">Obj</span><span class="p">.</span><span class="n">t</span> <span class="o">-&gt;</span>
  <span class="n">y_score</span><span class="o">:[&gt;`</span><span class="nc">ArrayLike</span><span class="o">]</span> <span class="nn">Np</span><span class="p">.</span><span class="nn">Obj</span><span class="p">.</span><span class="n">t</span> <span class="o">-&gt;</span>
  <span class="kt">unit</span> <span class="o">-&gt;</span>
  <span class="o">([&gt;`</span><span class="nc">ArrayLike</span><span class="o">]</span> <span class="nn">Np</span><span class="p">.</span><span class="nn">Obj</span><span class="p">.</span><span class="n">t</span> <span class="o">*</span> <span class="o">[&gt;`</span><span class="nc">ArrayLike</span><span class="o">]</span> <span class="nn">Np</span><span class="p">.</span><span class="nn">Obj</span><span class="p">.</span><span class="n">t</span> <span class="o">*</span> <span class="o">[&gt;`</span><span class="nc">ArrayLike</span><span class="o">]</span> <span class="nn">Np</span><span class="p">.</span><span class="nn">Obj</span><span class="p">.</span><span class="n">t</span><span class="o">)</span>
</code></pre></div>

<p>Compute Receiver operating characteristic (ROC)</p>
<ul>
<li><strong>Note: this implementation is restricted to the binary classification task.</strong></li>
</ul>
<p>Read more in the :ref:<code>User Guide &lt;roc_metrics&gt;</code>.</p>
<h4>Parameters</h4>
<ul>
<li>
<p><strong>y_true : array, shape = [n_samples]</strong>
    True binary labels. If labels are not either {-1, 1} or {0, 1}, then
    pos_label should be explicitly given.</p>
</li>
<li>
<p><strong>y_score : array, shape = [n_samples]</strong>
    Target scores, can either be probability estimates of the positive
    class, confidence values, or non-thresholded measure of decisions
    (as returned by 'decision_function' on some classifiers).</p>
</li>
<li>
<p><strong>pos_label : int or str, default=None</strong>
    The label of the positive class.
    When <code>pos_label=None</code>, if y_true is in {-1, 1} or {0, 1},
    <code>pos_label</code> is set to 1, otherwise an error will be raised.</p>
</li>
<li>
<p><strong>sample_weight : array-like of shape (n_samples,), default=None</strong>
    Sample weights.</p>
</li>
<li>
<p><strong>drop_intermediate : boolean, optional (default=True)</strong>
    Whether to drop some suboptimal thresholds which would not appear
    on a plotted ROC curve. This is useful in order to create lighter
    ROC curves.</p>
<p>.. versionadded:: 0.17
   parameter <em>drop_intermediate</em>.</p>
</li>
</ul>
<h4>Returns</h4>
<ul>
<li>
<p><strong>fpr : array, shape = [&gt;2]</strong>
    Increasing false positive rates such that element i is the false
    positive rate of predictions with score &gt;= thresholds[i].</p>
</li>
<li>
<p><strong>tpr : array, shape = [&gt;2]</strong>
    Increasing true positive rates such that element i is the true
    positive rate of predictions with score &gt;= thresholds[i].</p>
</li>
<li>
<p><strong>thresholds : array, shape = [n_thresholds]</strong>
    Decreasing thresholds on the decision function used to compute
    fpr and tpr. <code>thresholds[0]</code> represents no instances being predicted
    and is arbitrarily set to <code>max(y_score) + 1</code>.</p>
</li>
</ul>
<h4>See also</h4>
<ul>
<li><strong>roc_auc_score : Compute the area under the ROC curve</strong></li>
</ul>
<h4>Notes</h4>
<p>Since the thresholds are sorted from low to high values, they
are reversed upon returning them to ensure they correspond to both <code>fpr</code>
and <code>tpr</code>, which are sorted in reversed order during their calculation.</p>
<h4>References</h4>
<p>.. [1] <code>Wikipedia entry for the Receiver operating characteristic
        &lt;https://en.wikipedia.org/wiki/Receiver_operating_characteristic&gt;</code>_</p>
<p>.. [2] Fawcett T. An introduction to ROC analysis[J]. Pattern Recognition
       Letters, 2006, 27(8):861-874.</p>
<h4>Examples</h4>
<div class="highlight"><pre><span></span><code><span class="o">&gt;&gt;&gt;</span> <span class="kn">import</span> <span class="nn">numpy</span> <span class="k">as</span> <span class="nn">np</span>
<span class="o">&gt;&gt;&gt;</span> <span class="kn">from</span> <span class="nn">sklearn</span> <span class="kn">import</span> <span class="n">metrics</span>
<span class="o">&gt;&gt;&gt;</span> <span class="n">y</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">array</span><span class="p">([</span><span class="mi">1</span><span class="p">,</span> <span class="mi">1</span><span class="p">,</span> <span class="mi">2</span><span class="p">,</span> <span class="mi">2</span><span class="p">])</span>
<span class="o">&gt;&gt;&gt;</span> <span class="n">scores</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">array</span><span class="p">([</span><span class="mf">0.1</span><span class="p">,</span> <span class="mf">0.4</span><span class="p">,</span> <span class="mf">0.35</span><span class="p">,</span> <span class="mf">0.8</span><span class="p">])</span>
<span class="o">&gt;&gt;&gt;</span> <span class="n">fpr</span><span class="p">,</span> <span class="n">tpr</span><span class="p">,</span> <span class="n">thresholds</span> <span class="o">=</span> <span class="n">metrics</span><span class="o">.</span><span class="n">roc_curve</span><span class="p">(</span><span class="n">y</span><span class="p">,</span> <span class="n">scores</span><span class="p">,</span> <span class="n">pos_label</span><span class="o">=</span><span class="mi">2</span><span class="p">)</span>
<span class="o">&gt;&gt;&gt;</span> <span class="n">fpr</span>
<span class="n">array</span><span class="p">([</span><span class="mf">0.</span> <span class="p">,</span> <span class="mf">0.</span> <span class="p">,</span> <span class="mf">0.5</span><span class="p">,</span> <span class="mf">0.5</span><span class="p">,</span> <span class="mf">1.</span> <span class="p">])</span>
<span class="o">&gt;&gt;&gt;</span> <span class="n">tpr</span>
<span class="n">array</span><span class="p">([</span><span class="mf">0.</span> <span class="p">,</span> <span class="mf">0.5</span><span class="p">,</span> <span class="mf">0.5</span><span class="p">,</span> <span class="mf">1.</span> <span class="p">,</span> <span class="mf">1.</span> <span class="p">])</span>
<span class="o">&gt;&gt;&gt;</span> <span class="n">thresholds</span>
<span class="n">array</span><span class="p">([</span><span class="mf">1.8</span> <span class="p">,</span> <span class="mf">0.8</span> <span class="p">,</span> <span class="mf">0.4</span> <span class="p">,</span> <span class="mf">0.35</span><span class="p">,</span> <span class="mf">0.1</span> <span class="p">])</span>
</code></pre></div>

</details>
<h3 id="silhouette_samples_1">silhouette_samples<a class="headerlink" href="#silhouette_samples_1" title="Permanent link">&para;</a></h3>
<details class="note" open="open"><summary>function silhouette_samples</summary><div class="highlight"><pre><span></span><code><span class="k">val</span> <span class="n">silhouette_samples</span> <span class="o">:</span>
  <span class="o">?</span><span class="n">metric</span><span class="o">:[`</span><span class="nc">S</span> <span class="k">of</span> <span class="kt">string</span> <span class="o">|</span> <span class="o">`</span><span class="nc">Callable</span> <span class="k">of</span> <span class="nn">Py</span><span class="p">.</span><span class="nn">Object</span><span class="p">.</span><span class="n">t</span><span class="o">]</span> <span class="o">-&gt;</span>
  <span class="o">?</span><span class="n">kwds</span><span class="o">:(</span><span class="kt">string</span> <span class="o">*</span> <span class="nn">Py</span><span class="p">.</span><span class="nn">Object</span><span class="p">.</span><span class="n">t</span><span class="o">)</span> <span class="kt">list</span> <span class="o">-&gt;</span>
  <span class="n">x</span><span class="o">:[`</span><span class="nc">Arr</span> <span class="k">of</span> <span class="o">[&gt;`</span><span class="nc">ArrayLike</span><span class="o">]</span> <span class="nn">Np</span><span class="p">.</span><span class="nn">Obj</span><span class="p">.</span><span class="n">t</span> <span class="o">|</span> <span class="o">`</span><span class="nc">Otherwise</span> <span class="k">of</span> <span class="nn">Py</span><span class="p">.</span><span class="nn">Object</span><span class="p">.</span><span class="n">t</span><span class="o">]</span> <span class="o">-&gt;</span>
  <span class="n">labels</span><span class="o">:[&gt;`</span><span class="nc">ArrayLike</span><span class="o">]</span> <span class="nn">Np</span><span class="p">.</span><span class="nn">Obj</span><span class="p">.</span><span class="n">t</span> <span class="o">-&gt;</span>
  <span class="kt">unit</span> <span class="o">-&gt;</span>
  <span class="o">[&gt;`</span><span class="nc">ArrayLike</span><span class="o">]</span> <span class="nn">Np</span><span class="p">.</span><span class="nn">Obj</span><span class="p">.</span><span class="n">t</span>
</code></pre></div>

<p>Compute the Silhouette Coefficient for each sample.</p>
<p>The Silhouette Coefficient is a measure of how well samples are clustered
with samples that are similar to themselves. Clustering models with a high
Silhouette Coefficient are said to be dense, where samples in the same
cluster are similar to each other, and well separated, where samples in
different clusters are not very similar to each other.</p>
<p>The Silhouette Coefficient is calculated using the mean intra-cluster
distance (<code>a</code>) and the mean nearest-cluster distance (<code>b</code>) for each
sample.  The Silhouette Coefficient for a sample is <code>(b - a) / max(a,
b)</code>.
Note that Silhouette Coefficient is only defined if number of labels
is 2 &lt;= n_labels &lt;= n_samples - 1.</p>
<p>This function returns the Silhouette Coefficient for each sample.</p>
<p>The best value is 1 and the worst value is -1. Values near 0 indicate
overlapping clusters.</p>
<p>Read more in the :ref:<code>User Guide &lt;silhouette_coefficient&gt;</code>.</p>
<h4>Parameters</h4>
<ul>
<li>
<p><strong>X : array [n_samples_a, n_samples_a] if metric == 'precomputed', or,              [n_samples_a, n_features] otherwise</strong>
    Array of pairwise distances between samples, or a feature array.</p>
</li>
<li>
<p><strong>labels : array, shape = [n_samples]</strong>
         label values for each sample</p>
</li>
<li>
<p><strong>metric : string, or callable</strong>
    The metric to use when calculating distance between instances in a
    feature array. If metric is a string, it must be one of the options
    allowed by :func:<code>sklearn.metrics.pairwise.pairwise_distances</code>. If X is
    the distance array itself, use 'precomputed' as the metric. Precomputed
    distance matrices must have 0 along the diagonal.</p>
</li>
</ul>
<p><code>**kwds</code> : optional keyword parameters
    Any further parameters are passed directly to the distance function.
    If using a <code>scipy.spatial.distance</code> metric, the parameters are still
    metric dependent. See the scipy docs for usage examples.</p>
<h4>Returns</h4>
<ul>
<li><strong>silhouette : array, shape = [n_samples]</strong>
    Silhouette Coefficient for each samples.</li>
</ul>
<h4>References</h4>
<p>.. [1] <code>Peter J. Rousseeuw (1987). 'Silhouettes: a Graphical Aid to the
   Interpretation and Validation of Cluster Analysis'. Computational
   and Applied Mathematics 20: 53-65.
   &lt;https://www.sciencedirect.com/science/article/pii/0377042787901257&gt;</code>_</p>
<p>.. [2] <code>Wikipedia entry on the Silhouette Coefficient
   &lt;https://en.wikipedia.org/wiki/Silhouette_(clustering)&gt;</code>_</p>
</details>
<h3 id="silhouette_score_1">silhouette_score<a class="headerlink" href="#silhouette_score_1" title="Permanent link">&para;</a></h3>
<details class="note" open="open"><summary>function silhouette_score</summary><div class="highlight"><pre><span></span><code><span class="k">val</span> <span class="n">silhouette_score</span> <span class="o">:</span>
  <span class="o">?</span><span class="n">metric</span><span class="o">:[`</span><span class="nc">S</span> <span class="k">of</span> <span class="kt">string</span> <span class="o">|</span> <span class="o">`</span><span class="nc">Callable</span> <span class="k">of</span> <span class="nn">Py</span><span class="p">.</span><span class="nn">Object</span><span class="p">.</span><span class="n">t</span><span class="o">]</span> <span class="o">-&gt;</span>
  <span class="o">?</span><span class="n">sample_size</span><span class="o">:</span><span class="kt">int</span> <span class="o">-&gt;</span>
  <span class="o">?</span><span class="n">random_state</span><span class="o">:</span><span class="kt">int</span> <span class="o">-&gt;</span>
  <span class="o">?</span><span class="n">kwds</span><span class="o">:(</span><span class="kt">string</span> <span class="o">*</span> <span class="nn">Py</span><span class="p">.</span><span class="nn">Object</span><span class="p">.</span><span class="n">t</span><span class="o">)</span> <span class="kt">list</span> <span class="o">-&gt;</span>
  <span class="n">x</span><span class="o">:[`</span><span class="nc">Arr</span> <span class="k">of</span> <span class="o">[&gt;`</span><span class="nc">ArrayLike</span><span class="o">]</span> <span class="nn">Np</span><span class="p">.</span><span class="nn">Obj</span><span class="p">.</span><span class="n">t</span> <span class="o">|</span> <span class="o">`</span><span class="nc">Otherwise</span> <span class="k">of</span> <span class="nn">Py</span><span class="p">.</span><span class="nn">Object</span><span class="p">.</span><span class="n">t</span><span class="o">]</span> <span class="o">-&gt;</span>
  <span class="n">labels</span><span class="o">:[&gt;`</span><span class="nc">ArrayLike</span><span class="o">]</span> <span class="nn">Np</span><span class="p">.</span><span class="nn">Obj</span><span class="p">.</span><span class="n">t</span> <span class="o">-&gt;</span>
  <span class="kt">unit</span> <span class="o">-&gt;</span>
  <span class="kt">float</span>
</code></pre></div>

<p>Compute the mean Silhouette Coefficient of all samples.</p>
<p>The Silhouette Coefficient is calculated using the mean intra-cluster
distance (<code>a</code>) and the mean nearest-cluster distance (<code>b</code>) for each
sample.  The Silhouette Coefficient for a sample is <code>(b - a) / max(a,
b)</code>.  To clarify, <code>b</code> is the distance between a sample and the nearest
cluster that the sample is not a part of.
Note that Silhouette Coefficient is only defined if number of labels
is 2 &lt;= n_labels &lt;= n_samples - 1.</p>
<p>This function returns the mean Silhouette Coefficient over all samples.
To obtain the values for each sample, use :func:<code>silhouette_samples</code>.</p>
<p>The best value is 1 and the worst value is -1. Values near 0 indicate
overlapping clusters. Negative values generally indicate that a sample has
been assigned to the wrong cluster, as a different cluster is more similar.</p>
<p>Read more in the :ref:<code>User Guide &lt;silhouette_coefficient&gt;</code>.</p>
<h4>Parameters</h4>
<ul>
<li>
<p><strong>X : array [n_samples_a, n_samples_a] if metric == 'precomputed', or,              [n_samples_a, n_features] otherwise</strong>
    Array of pairwise distances between samples, or a feature array.</p>
</li>
<li>
<p><strong>labels : array, shape = [n_samples]</strong>
     Predicted labels for each sample.</p>
</li>
<li>
<p><strong>metric : string, or callable</strong>
    The metric to use when calculating distance between instances in a
    feature array. If metric is a string, it must be one of the options
    allowed by :func:<code>metrics.pairwise.pairwise_distances
    &lt;sklearn.metrics.pairwise.pairwise_distances&gt;</code>. If X is the distance
    array itself, use <code>metric='precomputed'</code>.</p>
</li>
<li>
<p><strong>sample_size : int or None</strong>
    The size of the sample to use when computing the Silhouette Coefficient
    on a random subset of the data.
    If <code>sample_size is None</code>, no sampling is used.</p>
</li>
<li>
<p><strong>random_state : int, RandomState instance or None, optional (default=None)</strong>
    Determines random number generation for selecting a subset of samples.
    Used when <code>sample_size is not None</code>.
    Pass an int for reproducible results across multiple function calls.</p>
</li>
<li>
<p><strong>See :term:<code>Glossary &lt;random_state&gt;</code>.</strong></p>
</li>
<li>
<p><strong>**kwds : optional keyword parameters</strong>
    Any further parameters are passed directly to the distance function.
    If using a scipy.spatial.distance metric, the parameters are still
    metric dependent. See the scipy docs for usage examples.</p>
</li>
</ul>
<h4>Returns</h4>
<ul>
<li><strong>silhouette : float</strong>
    Mean Silhouette Coefficient for all samples.</li>
</ul>
<h4>References</h4>
<p>.. [1] <code>Peter J. Rousseeuw (1987). 'Silhouettes: a Graphical Aid to the
   Interpretation and Validation of Cluster Analysis'. Computational
   and Applied Mathematics 20: 53-65.
   &lt;https://www.sciencedirect.com/science/article/pii/0377042787901257&gt;</code>_</p>
<p>.. [2] <code>Wikipedia entry on the Silhouette Coefficient
       &lt;https://en.wikipedia.org/wiki/Silhouette_(clustering)&gt;</code>_</p>
</details>
<h3 id="v_measure_score_1">v_measure_score<a class="headerlink" href="#v_measure_score_1" title="Permanent link">&para;</a></h3>
<details class="note" open="open"><summary>function v_measure_score</summary><div class="highlight"><pre><span></span><code><span class="k">val</span> <span class="n">v_measure_score</span> <span class="o">:</span>
  <span class="o">?</span><span class="n">beta</span><span class="o">:</span><span class="kt">float</span> <span class="o">-&gt;</span>
  <span class="n">labels_true</span><span class="o">:[&gt;`</span><span class="nc">ArrayLike</span><span class="o">]</span> <span class="nn">Np</span><span class="p">.</span><span class="nn">Obj</span><span class="p">.</span><span class="n">t</span> <span class="o">-&gt;</span>
  <span class="n">labels_pred</span><span class="o">:[&gt;`</span><span class="nc">ArrayLike</span><span class="o">]</span> <span class="nn">Np</span><span class="p">.</span><span class="nn">Obj</span><span class="p">.</span><span class="n">t</span> <span class="o">-&gt;</span>
  <span class="kt">unit</span> <span class="o">-&gt;</span>
  <span class="kt">float</span>
</code></pre></div>

<p>V-measure cluster labeling given a ground truth.</p>
<p>This score is identical to :func:<code>normalized_mutual_info_score</code> with
the <code>'arithmetic'</code> option for averaging.</p>
<p>The V-measure is the harmonic mean between homogeneity and completeness::</p>
<div class="codehilite"><pre><span></span><code>v = (1 + beta) * homogeneity * completeness
     / (beta * homogeneity + completeness)
</code></pre></div>


<p>This metric is independent of the absolute values of the labels:
a permutation of the class or cluster label values won't change the
score value in any way.</p>
<p>This metric is furthermore symmetric: switching <code>label_true</code> with
<code>label_pred</code> will return the same score value. This can be useful to
measure the agreement of two independent label assignments strategies
on the same dataset when the real ground truth is not known.</p>
<p>Read more in the :ref:<code>User Guide &lt;homogeneity_completeness&gt;</code>.</p>
<h4>Parameters</h4>
<ul>
<li>
<p><strong>labels_true : int array, shape = [n_samples]</strong>
    ground truth class labels to be used as a reference</p>
</li>
<li>
<p><strong>labels_pred : array-like of shape (n_samples,)</strong>
    cluster labels to evaluate</p>
</li>
<li>
<p><strong>beta : float</strong>
    Ratio of weight attributed to <code>homogeneity</code> vs <code>completeness</code>.
    If <code>beta</code> is greater than 1, <code>completeness</code> is weighted more
    strongly in the calculation. If <code>beta</code> is less than 1,
    <code>homogeneity</code> is weighted more strongly.</p>
</li>
</ul>
<h4>Returns</h4>
<ul>
<li><strong>v_measure : float</strong>
   score between 0.0 and 1.0. 1.0 stands for perfectly complete labeling</li>
</ul>
<h4>References</h4>
<p>.. [1] <code>Andrew Rosenberg and Julia Hirschberg, 2007. V-Measure: A
   conditional entropy-based external cluster evaluation measure
   &lt;https://aclweb.org/anthology/D/D07/D07-1043.pdf&gt;</code>_</p>
<h4>See also</h4>
<p>homogeneity_score
completeness_score
normalized_mutual_info_score</p>
<h4>Examples</h4>
<p>Perfect labelings are both homogeneous and complete, hence have score 1.0::</p>
<blockquote>
<blockquote>
<blockquote>
<p>from sklearn.metrics.cluster import v_measure_score
v_measure_score([0, 0, 1, 1], [0, 0, 1, 1])
  1.0
v_measure_score([0, 0, 1, 1], [1, 1, 0, 0])
  1.0</p>
</blockquote>
</blockquote>
</blockquote>
<p>Labelings that assign all classes members to the same clusters
are complete be not homogeneous, hence penalized::</p>
<blockquote>
<blockquote>
<blockquote>
<p>print('%.6f' % v_measure_score([0, 0, 1, 2], [0, 0, 1, 1]))
  0.8...
print('%.6f' % v_measure_score([0, 1, 2, 3], [0, 0, 1, 1]))
  0.66...</p>
</blockquote>
</blockquote>
</blockquote>
<p>Labelings that have pure clusters with members coming from the same
classes are homogeneous but un-necessary splits harms completeness
and thus penalize V-measure as well::</p>
<blockquote>
<blockquote>
<blockquote>
<p>print('%.6f' % v_measure_score([0, 0, 1, 1], [0, 0, 1, 2]))
  0.8...
print('%.6f' % v_measure_score([0, 0, 1, 1], [0, 1, 2, 3]))
  0.66...</p>
</blockquote>
</blockquote>
</blockquote>
<p>If classes members are completely split across different clusters,
the assignment is totally incomplete, hence the V-Measure is null::</p>
<blockquote>
<blockquote>
<blockquote>
<p>print('%.6f' % v_measure_score([0, 0, 0, 0], [0, 1, 2, 3]))
  0.0...</p>
</blockquote>
</blockquote>
</blockquote>
<p>Clusters that include samples from totally different classes totally
destroy the homogeneity of the labeling, hence::</p>
<blockquote>
<blockquote>
<blockquote>
<p>print('%.6f' % v_measure_score([0, 0, 1, 1], [0, 0, 0, 0]))
  0.0...</p>
</blockquote>
</blockquote>
</blockquote>
</details>
<h3 id="zero_one_loss">zero_one_loss<a class="headerlink" href="#zero_one_loss" title="Permanent link">&para;</a></h3>
<details class="note" open="open"><summary>function zero_one_loss</summary><div class="highlight"><pre><span></span><code><span class="k">val</span> <span class="n">zero_one_loss</span> <span class="o">:</span>
  <span class="o">?</span><span class="n">normalize</span><span class="o">:</span><span class="kt">bool</span> <span class="o">-&gt;</span>
  <span class="o">?</span><span class="n">sample_weight</span><span class="o">:[&gt;`</span><span class="nc">ArrayLike</span><span class="o">]</span> <span class="nn">Np</span><span class="p">.</span><span class="nn">Obj</span><span class="p">.</span><span class="n">t</span> <span class="o">-&gt;</span>
  <span class="n">y_true</span><span class="o">:[&gt;`</span><span class="nc">ArrayLike</span><span class="o">]</span> <span class="nn">Np</span><span class="p">.</span><span class="nn">Obj</span><span class="p">.</span><span class="n">t</span> <span class="o">-&gt;</span>
  <span class="n">y_pred</span><span class="o">:[&gt;`</span><span class="nc">ArrayLike</span><span class="o">]</span> <span class="nn">Np</span><span class="p">.</span><span class="nn">Obj</span><span class="p">.</span><span class="n">t</span> <span class="o">-&gt;</span>
  <span class="kt">unit</span> <span class="o">-&gt;</span>
  <span class="o">[`</span><span class="nc">F</span> <span class="k">of</span> <span class="kt">float</span> <span class="o">|</span> <span class="o">`</span><span class="nc">I</span> <span class="k">of</span> <span class="kt">int</span><span class="o">]</span>
</code></pre></div>

<p>Zero-one classification loss.</p>
<p>If normalize is <code>True</code>, return the fraction of misclassifications
(float), else it returns the number of misclassifications (int). The best
performance is 0.</p>
<p>Read more in the :ref:<code>User Guide &lt;zero_one_loss&gt;</code>.</p>
<h4>Parameters</h4>
<ul>
<li>
<p><strong>y_true : 1d array-like, or label indicator array / sparse matrix</strong>
    Ground truth (correct) labels.</p>
</li>
<li>
<p><strong>y_pred : 1d array-like, or label indicator array / sparse matrix</strong>
    Predicted labels, as returned by a classifier.</p>
</li>
<li>
<p><strong>normalize : bool, optional (default=True)</strong>
    If <code>False</code>, return the number of misclassifications.
    Otherwise, return the fraction of misclassifications.</p>
</li>
<li>
<p><strong>sample_weight : array-like of shape (n_samples,), default=None</strong>
    Sample weights.</p>
</li>
</ul>
<h4>Returns</h4>
<ul>
<li><strong>loss : float or int,</strong>
    If <code>normalize == True</code>, return the fraction of misclassifications
    (float), else it returns the number of misclassifications (int).</li>
</ul>
<h4>Notes</h4>
<p>In multilabel classification, the zero_one_loss function corresponds to
the subset zero-one loss: for each sample, the entire set of labels must be
correctly predicted, otherwise the loss for that sample is equal to one.</p>
<h4>See also</h4>
<p>accuracy_score, hamming_loss, jaccard_score</p>
<h4>Examples</h4>
<div class="highlight"><pre><span></span><code><span class="o">&gt;&gt;&gt;</span> <span class="kn">from</span> <span class="nn">sklearn.metrics</span> <span class="kn">import</span> <span class="n">zero_one_loss</span>
<span class="o">&gt;&gt;&gt;</span> <span class="n">y_pred</span> <span class="o">=</span> <span class="p">[</span><span class="mi">1</span><span class="p">,</span> <span class="mi">2</span><span class="p">,</span> <span class="mi">3</span><span class="p">,</span> <span class="mi">4</span><span class="p">]</span>
<span class="o">&gt;&gt;&gt;</span> <span class="n">y_true</span> <span class="o">=</span> <span class="p">[</span><span class="mi">2</span><span class="p">,</span> <span class="mi">2</span><span class="p">,</span> <span class="mi">3</span><span class="p">,</span> <span class="mi">4</span><span class="p">]</span>
<span class="o">&gt;&gt;&gt;</span> <span class="n">zero_one_loss</span><span class="p">(</span><span class="n">y_true</span><span class="p">,</span> <span class="n">y_pred</span><span class="p">)</span>
<span class="mf">0.25</span>
<span class="o">&gt;&gt;&gt;</span> <span class="n">zero_one_loss</span><span class="p">(</span><span class="n">y_true</span><span class="p">,</span> <span class="n">y_pred</span><span class="p">,</span> <span class="n">normalize</span><span class="o">=</span><span class="kc">False</span><span class="p">)</span>
<span class="mi">1</span>
</code></pre></div>

<p>In the multilabel case with binary label indicators:</p>
<div class="highlight"><pre><span></span><code><span class="o">&gt;&gt;&gt;</span> <span class="kn">import</span> <span class="nn">numpy</span> <span class="k">as</span> <span class="nn">np</span>
<span class="o">&gt;&gt;&gt;</span> <span class="n">zero_one_loss</span><span class="p">(</span><span class="n">np</span><span class="o">.</span><span class="n">array</span><span class="p">([[</span><span class="mi">0</span><span class="p">,</span> <span class="mi">1</span><span class="p">],</span> <span class="p">[</span><span class="mi">1</span><span class="p">,</span> <span class="mi">1</span><span class="p">]]),</span> <span class="n">np</span><span class="o">.</span><span class="n">ones</span><span class="p">((</span><span class="mi">2</span><span class="p">,</span> <span class="mi">2</span><span class="p">)))</span>
<span class="mf">0.5</span>
</code></pre></div>

</details>
                
              
              
                


              
            </article>
          </div>
        </div>
      </main>
      
        
<footer class="md-footer">
  
    <div class="md-footer-nav">
      <nav class="md-footer-nav__inner md-grid" aria-label="Footer">
        
          <a href="../Manifold/" class="md-footer-nav__link md-footer-nav__link--prev" rel="prev">
            <div class="md-footer-nav__button md-icon">
              <svg xmlns="http://www.w3.org/2000/svg" viewBox="0 0 24 24"><path d="M20 11v2H8l5.5 5.5-1.42 1.42L4.16 12l7.92-7.92L13.5 5.5 8 11h12z"/></svg>
            </div>
            <div class="md-footer-nav__title">
              <div class="md-ellipsis">
                <span class="md-footer-nav__direction">
                  Previous
                </span>
                Manifold
              </div>
            </div>
          </a>
        
        
          <a href="../Mixture/" class="md-footer-nav__link md-footer-nav__link--next" rel="next">
            <div class="md-footer-nav__title">
              <div class="md-ellipsis">
                <span class="md-footer-nav__direction">
                  Next
                </span>
                Mixture
              </div>
            </div>
            <div class="md-footer-nav__button md-icon">
              <svg xmlns="http://www.w3.org/2000/svg" viewBox="0 0 24 24"><path d="M4 11v2h12l-5.5 5.5 1.42 1.42L19.84 12l-7.92-7.92L10.5 5.5 16 11H4z"/></svg>
            </div>
          </a>
        
      </nav>
    </div>
  
  <div class="md-footer-meta md-typeset">
    <div class="md-footer-meta__inner md-grid">
      <div class="md-footer-copyright">
        
        Made with
        <a href="https://squidfunk.github.io/mkdocs-material/" target="_blank" rel="noopener">
          Material for MkDocs
        </a>
      </div>
      
    </div>
  </div>
</footer>
      
    </div>
    
      <script src="../../assets/javascripts/vendor.0ac82a11.min.js"></script>
      <script src="../../assets/javascripts/bundle.f81dfb4d.min.js"></script><script id="__lang" type="application/json">{"clipboard.copy": "Copy to clipboard", "clipboard.copied": "Copied to clipboard", "search.config.lang": "en", "search.config.pipeline": "trimmer, stopWordFilter", "search.config.separator": "[\\s\\-]+", "search.placeholder": "Search", "search.result.placeholder": "Type to start searching", "search.result.none": "No matching documents", "search.result.one": "1 matching document", "search.result.other": "# matching documents", "search.result.more.one": "1 more on this page", "search.result.more.other": "# more on this page", "search.result.term.missing": "Missing"}</script>
      
      <script>
        app = initialize({
          base: "../..",
          features: ['instant', 'tabs'],
          search: Object.assign({
            worker: "../../assets/javascripts/worker/search.4ac00218.min.js"
          }, typeof search !== "undefined" && search)
        })
      </script>
      
        <script src="https://cdnjs.cloudflare.com/ajax/libs/mathjax/2.7.0/MathJax.js?config=TeX-MML-AM_CHTML"></script>
      
    
  </body>
</html>