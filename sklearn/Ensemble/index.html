


<!doctype html>
<html lang="en" class="no-js">
  <head>
    
      <meta charset="utf-8">
      <meta name="viewport" content="width=device-width,initial-scale=1">
      
      
      
      <link rel="shortcut icon" href="../../assets/images/favicon.png">
      <meta name="generator" content="mkdocs-1.1.2, mkdocs-material-5.2.3">
    
    
      
        <title>Ensemble - OCaml scikit-learn interface</title>
      
    
    
      <link rel="stylesheet" href="../../assets/stylesheets/main.6e35a1a6.min.css">
      
        <link rel="stylesheet" href="../../assets/stylesheets/palette.a46bcfb3.min.css">
      
      
        
        
        <meta name="theme-color" content="#3f51b5">
      
    
    
    
      
        <link href="https://fonts.gstatic.com" rel="preconnect" crossorigin>
        <link rel="stylesheet" href="https://fonts.googleapis.com/css?family=Roboto:300,400,400i,700%7CRoboto+Mono&display=fallback">
        <style>body,input{font-family:"Roboto",-apple-system,BlinkMacSystemFont,Helvetica,Arial,sans-serif}code,kbd,pre{font-family:"Roboto Mono",SFMono-Regular,Consolas,Menlo,monospace}</style>
      
    
    
    
    
      
    
    
  </head>
  
  
    
    
    
    <body dir="ltr" data-md-color-scheme="" data-md-color-primary="indigo" data-md-color-accent="indigo">
  
    <input class="md-toggle" data-md-toggle="drawer" type="checkbox" id="__drawer" autocomplete="off">
    <input class="md-toggle" data-md-toggle="search" type="checkbox" id="__search" autocomplete="off">
    <label class="md-overlay" for="__drawer"></label>
    <div data-md-component="skip">
      
        
        <a href="#parameters" class="md-skip">
          Skip to content
        </a>
      
    </div>
    <div data-md-component="announce">
      
    </div>
    
      <header class="md-header" data-md-component="header">
  <nav class="md-header-nav md-grid" aria-label="Header">
    <a href="../.." title="OCaml scikit-learn interface" class="md-header-nav__button md-logo" aria-label="OCaml scikit-learn interface">
      
  
  <svg xmlns="http://www.w3.org/2000/svg" viewBox="0 0 24 24"><path d="M12 8a3 3 0 003-3 3 3 0 00-3-3 3 3 0 00-3 3 3 3 0 003 3m0 3.54C9.64 9.35 6.5 8 3 8v11c3.5 0 6.64 1.35 9 3.54 2.36-2.19 5.5-3.54 9-3.54V8c-3.5 0-6.64 1.35-9 3.54z"/></svg>

    </a>
    <label class="md-header-nav__button md-icon" for="__drawer">
      <svg xmlns="http://www.w3.org/2000/svg" viewBox="0 0 24 24"><path d="M3 6h18v2H3V6m0 5h18v2H3v-2m0 5h18v2H3v-2z"/></svg>
    </label>
    <div class="md-header-nav__title" data-md-component="header-title">
      
        <div class="md-header-nav__ellipsis">
          <span class="md-header-nav__topic md-ellipsis">
            OCaml scikit-learn interface
          </span>
          <span class="md-header-nav__topic md-ellipsis">
            
              Ensemble
            
          </span>
        </div>
      
    </div>
    
      <label class="md-header-nav__button md-icon" for="__search">
        <svg xmlns="http://www.w3.org/2000/svg" viewBox="0 0 24 24"><path d="M9.5 3A6.5 6.5 0 0116 9.5c0 1.61-.59 3.09-1.56 4.23l.27.27h.79l5 5-1.5 1.5-5-5v-.79l-.27-.27A6.516 6.516 0 019.5 16 6.5 6.5 0 013 9.5 6.5 6.5 0 019.5 3m0 2C7 5 5 7 5 9.5S7 14 9.5 14 14 12 14 9.5 12 5 9.5 5z"/></svg>
      </label>
      
<div class="md-search" data-md-component="search" role="dialog">
  <label class="md-search__overlay" for="__search"></label>
  <div class="md-search__inner" role="search">
    <form class="md-search__form" name="search">
      <input type="text" class="md-search__input" name="query" aria-label="Search" placeholder="Search" autocapitalize="off" autocorrect="off" autocomplete="off" spellcheck="false" data-md-component="search-query" data-md-state="active">
      <label class="md-search__icon md-icon" for="__search">
        <svg xmlns="http://www.w3.org/2000/svg" viewBox="0 0 24 24"><path d="M9.5 3A6.5 6.5 0 0116 9.5c0 1.61-.59 3.09-1.56 4.23l.27.27h.79l5 5-1.5 1.5-5-5v-.79l-.27-.27A6.516 6.516 0 019.5 16 6.5 6.5 0 013 9.5 6.5 6.5 0 019.5 3m0 2C7 5 5 7 5 9.5S7 14 9.5 14 14 12 14 9.5 12 5 9.5 5z"/></svg>
        <svg xmlns="http://www.w3.org/2000/svg" viewBox="0 0 24 24"><path d="M20 11v2H8l5.5 5.5-1.42 1.42L4.16 12l7.92-7.92L13.5 5.5 8 11h12z"/></svg>
      </label>
      <button type="reset" class="md-search__icon md-icon" aria-label="Clear" data-md-component="search-reset" tabindex="-1">
        <svg xmlns="http://www.w3.org/2000/svg" viewBox="0 0 24 24"><path d="M19 6.41L17.59 5 12 10.59 6.41 5 5 6.41 10.59 12 5 17.59 6.41 19 12 13.41 17.59 19 19 17.59 13.41 12 19 6.41z"/></svg>
      </button>
    </form>
    <div class="md-search__output">
      <div class="md-search__scrollwrap" data-md-scrollfix>
        <div class="md-search-result" data-md-component="search-result">
          <div class="md-search-result__meta">
            Initializing search
          </div>
          <ol class="md-search-result__list"></ol>
        </div>
      </div>
    </div>
  </div>
</div>
    
    
      <div class="md-header-nav__source">
        
<a href="https://github.com/lehy/ocaml-sklearn/" title="Go to repository" class="md-source">
  <div class="md-source__icon md-icon">
    
    <svg xmlns="http://www.w3.org/2000/svg" viewBox="0 0 448 512"><path d="M439.55 236.05L244 40.45a28.87 28.87 0 00-40.81 0l-40.66 40.63 51.52 51.52c27.06-9.14 52.68 16.77 43.39 43.68l49.66 49.66c34.23-11.8 61.18 31 35.47 56.69-26.49 26.49-70.21-2.87-56-37.34L240.22 199v121.85c25.3 12.54 22.26 41.85 9.08 55a34.34 34.34 0 01-48.55 0c-17.57-17.6-11.07-46.91 11.25-56v-123c-20.8-8.51-24.6-30.74-18.64-45L142.57 101 8.45 235.14a28.86 28.86 0 000 40.81l195.61 195.6a28.86 28.86 0 0040.8 0l194.69-194.69a28.86 28.86 0 000-40.81z"/></svg>
  </div>
  <div class="md-source__repository">
    lehy/ocaml-sklearn
  </div>
</a>
      </div>
    
  </nav>
</header>
    
    <div class="md-container" data-md-component="container">
      
        
      
      
        
          

  

<nav class="md-tabs md-tabs--active" aria-label="Tabs" data-md-component="tabs">
  <div class="md-tabs__inner md-grid">
    <ul class="md-tabs__list">
      
        
  <li class="md-tabs__item">
    
      <a href="../.." class="md-tabs__link">
        Home
      </a>
    
  </li>

      
        
  
  
    <li class="md-tabs__item">
      
        <a href="../../np/" class="md-tabs__link">
          Np
        </a>
      
    </li>
  

      
        
  
  
    <li class="md-tabs__item">
      
        <a href="../../scipy/" class="md-tabs__link">
          Scipy
        </a>
      
    </li>
  

      
        
  
  
    <li class="md-tabs__item">
      
        <a href="../Base/" class="md-tabs__link md-tabs__link--active">
          Sklearn
        </a>
      
    </li>
  

      
    </ul>
  </div>
</nav>
        
      
      <main class="md-main" data-md-component="main">
        <div class="md-main__inner md-grid">
          
            
              <div class="md-sidebar md-sidebar--primary" data-md-component="navigation">
                <div class="md-sidebar__scrollwrap">
                  <div class="md-sidebar__inner">
                    <nav class="md-nav md-nav--primary" aria-label="Navigation" data-md-level="0">
  <label class="md-nav__title" for="__drawer">
    <a href="../.." title="OCaml scikit-learn interface" class="md-nav__button md-logo" aria-label="OCaml scikit-learn interface">
      
  
  <svg xmlns="http://www.w3.org/2000/svg" viewBox="0 0 24 24"><path d="M12 8a3 3 0 003-3 3 3 0 00-3-3 3 3 0 00-3 3 3 3 0 003 3m0 3.54C9.64 9.35 6.5 8 3 8v11c3.5 0 6.64 1.35 9 3.54 2.36-2.19 5.5-3.54 9-3.54V8c-3.5 0-6.64 1.35-9 3.54z"/></svg>

    </a>
    OCaml scikit-learn interface
  </label>
  
    <div class="md-nav__source">
      
<a href="https://github.com/lehy/ocaml-sklearn/" title="Go to repository" class="md-source">
  <div class="md-source__icon md-icon">
    
    <svg xmlns="http://www.w3.org/2000/svg" viewBox="0 0 448 512"><path d="M439.55 236.05L244 40.45a28.87 28.87 0 00-40.81 0l-40.66 40.63 51.52 51.52c27.06-9.14 52.68 16.77 43.39 43.68l49.66 49.66c34.23-11.8 61.18 31 35.47 56.69-26.49 26.49-70.21-2.87-56-37.34L240.22 199v121.85c25.3 12.54 22.26 41.85 9.08 55a34.34 34.34 0 01-48.55 0c-17.57-17.6-11.07-46.91 11.25-56v-123c-20.8-8.51-24.6-30.74-18.64-45L142.57 101 8.45 235.14a28.86 28.86 0 000 40.81l195.61 195.6a28.86 28.86 0 0040.8 0l194.69-194.69a28.86 28.86 0 000-40.81z"/></svg>
  </div>
  <div class="md-source__repository">
    lehy/ocaml-sklearn
  </div>
</a>
    </div>
  
  <ul class="md-nav__list" data-md-scrollfix>
    
      
      
      


  <li class="md-nav__item">
    <a href="../.." title="Home" class="md-nav__link">
      Home
    </a>
  </li>

    
      
      
      


  <li class="md-nav__item md-nav__item--nested">
    
      <input class="md-nav__toggle md-toggle" data-md-toggle="nav-2" type="checkbox" id="nav-2">
    
    <label class="md-nav__link" for="nav-2">
      Np
      <span class="md-nav__icon md-icon">
        <svg xmlns="http://www.w3.org/2000/svg" viewBox="0 0 24 24"><path d="M8.59 16.58L13.17 12 8.59 7.41 10 6l6 6-6 6-1.41-1.42z"/></svg>
      </span>
    </label>
    <nav class="md-nav" aria-label="Np" data-md-level="1">
      <label class="md-nav__title" for="nav-2">
        <span class="md-nav__icon md-icon">
          <svg xmlns="http://www.w3.org/2000/svg" viewBox="0 0 24 24"><path d="M20 11v2H8l5.5 5.5-1.42 1.42L4.16 12l7.92-7.92L13.5 5.5 8 11h12z"/></svg>
        </span>
        Np
      </label>
      <ul class="md-nav__list" data-md-scrollfix>
        
        
          
          
          


  <li class="md-nav__item">
    <a href="../../np/" title="Numpy for OCaml" class="md-nav__link">
      Numpy for OCaml
    </a>
  </li>

        
          
          
          


  <li class="md-nav__item">
    <a href="../../np/Numpy/" title="Numpy" class="md-nav__link">
      Numpy
    </a>
  </li>

        
          
          
          


  <li class="md-nav__item">
    <a href="../../np/NumpyRaw/" title="NumpyRaw" class="md-nav__link">
      NumpyRaw
    </a>
  </li>

        
          
          
          


  <li class="md-nav__item">
    <a href="../../np/PyList/" title="PyList" class="md-nav__link">
      PyList
    </a>
  </li>

        
          
          
          


  <li class="md-nav__item">
    <a href="../../np/dtype/" title="Dtype" class="md-nav__link">
      Dtype
    </a>
  </li>

        
          
          
          


  <li class="md-nav__item">
    <a href="../../np/obj/" title="Obj" class="md-nav__link">
      Obj
    </a>
  </li>

        
      </ul>
    </nav>
  </li>

    
      
      
      


  <li class="md-nav__item md-nav__item--nested">
    
      <input class="md-nav__toggle md-toggle" data-md-toggle="nav-3" type="checkbox" id="nav-3">
    
    <label class="md-nav__link" for="nav-3">
      Scipy
      <span class="md-nav__icon md-icon">
        <svg xmlns="http://www.w3.org/2000/svg" viewBox="0 0 24 24"><path d="M8.59 16.58L13.17 12 8.59 7.41 10 6l6 6-6 6-1.41-1.42z"/></svg>
      </span>
    </label>
    <nav class="md-nav" aria-label="Scipy" data-md-level="1">
      <label class="md-nav__title" for="nav-3">
        <span class="md-nav__icon md-icon">
          <svg xmlns="http://www.w3.org/2000/svg" viewBox="0 0 24 24"><path d="M20 11v2H8l5.5 5.5-1.42 1.42L4.16 12l7.92-7.92L13.5 5.5 8 11h12z"/></svg>
        </span>
        Scipy
      </label>
      <ul class="md-nav__list" data-md-scrollfix>
        
        
          
          
          


  <li class="md-nav__item">
    <a href="../../scipy/" title="SciPy library for OCaml" class="md-nav__link">
      SciPy library for OCaml
    </a>
  </li>

        
          
          
          


  <li class="md-nav__item">
    <a href="../../scipy/Cluster/" title="Cluster" class="md-nav__link">
      Cluster
    </a>
  </li>

        
          
          
          


  <li class="md-nav__item">
    <a href="../../scipy/Conftest/" title="Conftest" class="md-nav__link">
      Conftest
    </a>
  </li>

        
          
          
          


  <li class="md-nav__item">
    <a href="../../scipy/Constants/" title="Constants" class="md-nav__link">
      Constants
    </a>
  </li>

        
          
          
          


  <li class="md-nav__item">
    <a href="../../scipy/Fft/" title="Fft" class="md-nav__link">
      Fft
    </a>
  </li>

        
          
          
          


  <li class="md-nav__item">
    <a href="../../scipy/Fftpack/" title="Fftpack" class="md-nav__link">
      Fftpack
    </a>
  </li>

        
          
          
          


  <li class="md-nav__item">
    <a href="../../scipy/Integrate/" title="Integrate" class="md-nav__link">
      Integrate
    </a>
  </li>

        
          
          
          


  <li class="md-nav__item">
    <a href="../../scipy/Interpolate/" title="Interpolate" class="md-nav__link">
      Interpolate
    </a>
  </li>

        
          
          
          


  <li class="md-nav__item">
    <a href="../../scipy/Io/" title="Io" class="md-nav__link">
      Io
    </a>
  </li>

        
          
          
          


  <li class="md-nav__item">
    <a href="../../scipy/Linalg/" title="Linalg" class="md-nav__link">
      Linalg
    </a>
  </li>

        
          
          
          


  <li class="md-nav__item">
    <a href="../../scipy/Misc/" title="Misc" class="md-nav__link">
      Misc
    </a>
  </li>

        
          
          
          


  <li class="md-nav__item">
    <a href="../../scipy/Ndimage/" title="Ndimage" class="md-nav__link">
      Ndimage
    </a>
  </li>

        
          
          
          


  <li class="md-nav__item">
    <a href="../../scipy/Odr/" title="Odr" class="md-nav__link">
      Odr
    </a>
  </li>

        
          
          
          


  <li class="md-nav__item">
    <a href="../../scipy/Optimize/" title="Optimize" class="md-nav__link">
      Optimize
    </a>
  </li>

        
          
          
          


  <li class="md-nav__item">
    <a href="../../scipy/Setup/" title="Setup" class="md-nav__link">
      Setup
    </a>
  </li>

        
          
          
          


  <li class="md-nav__item">
    <a href="../../scipy/Signal/" title="Signal" class="md-nav__link">
      Signal
    </a>
  </li>

        
          
          
          


  <li class="md-nav__item">
    <a href="../../scipy/Sparse/" title="Sparse" class="md-nav__link">
      Sparse
    </a>
  </li>

        
          
          
          


  <li class="md-nav__item">
    <a href="../../scipy/Spatial/" title="Spatial" class="md-nav__link">
      Spatial
    </a>
  </li>

        
          
          
          


  <li class="md-nav__item">
    <a href="../../scipy/Special/" title="Special" class="md-nav__link">
      Special
    </a>
  </li>

        
          
          
          


  <li class="md-nav__item">
    <a href="../../scipy/Stats/" title="Stats" class="md-nav__link">
      Stats
    </a>
  </li>

        
          
          
          


  <li class="md-nav__item">
    <a href="../../scipy/Version/" title="Version" class="md-nav__link">
      Version
    </a>
  </li>

        
          
          
          


  <li class="md-nav__item">
    <a href="../../scipy/wrap_version/" title="Wrap version" class="md-nav__link">
      Wrap version
    </a>
  </li>

        
      </ul>
    </nav>
  </li>

    
      
      
      

  


  <li class="md-nav__item md-nav__item--active md-nav__item--nested">
    
      <input class="md-nav__toggle md-toggle" data-md-toggle="nav-4" type="checkbox" id="nav-4" checked>
    
    <label class="md-nav__link" for="nav-4">
      Sklearn
      <span class="md-nav__icon md-icon">
        <svg xmlns="http://www.w3.org/2000/svg" viewBox="0 0 24 24"><path d="M8.59 16.58L13.17 12 8.59 7.41 10 6l6 6-6 6-1.41-1.42z"/></svg>
      </span>
    </label>
    <nav class="md-nav" aria-label="Sklearn" data-md-level="1">
      <label class="md-nav__title" for="nav-4">
        <span class="md-nav__icon md-icon">
          <svg xmlns="http://www.w3.org/2000/svg" viewBox="0 0 24 24"><path d="M20 11v2H8l5.5 5.5-1.42 1.42L4.16 12l7.92-7.92L13.5 5.5 8 11h12z"/></svg>
        </span>
        Sklearn
      </label>
      <ul class="md-nav__list" data-md-scrollfix>
        
        
          
          
          


  <li class="md-nav__item">
    <a href="../Base/" title="Base" class="md-nav__link">
      Base
    </a>
  </li>

        
          
          
          


  <li class="md-nav__item">
    <a href="../Calibration/" title="Calibration" class="md-nav__link">
      Calibration
    </a>
  </li>

        
          
          
          


  <li class="md-nav__item">
    <a href="../Cluster/" title="Cluster" class="md-nav__link">
      Cluster
    </a>
  </li>

        
          
          
          


  <li class="md-nav__item">
    <a href="../Compose/" title="Compose" class="md-nav__link">
      Compose
    </a>
  </li>

        
          
          
          


  <li class="md-nav__item">
    <a href="../Conftest/" title="Conftest" class="md-nav__link">
      Conftest
    </a>
  </li>

        
          
          
          


  <li class="md-nav__item">
    <a href="../Covariance/" title="Covariance" class="md-nav__link">
      Covariance
    </a>
  </li>

        
          
          
          


  <li class="md-nav__item">
    <a href="../Cross_decomposition/" title="Cross decomposition" class="md-nav__link">
      Cross decomposition
    </a>
  </li>

        
          
          
          


  <li class="md-nav__item">
    <a href="../Datasets/" title="Datasets" class="md-nav__link">
      Datasets
    </a>
  </li>

        
          
          
          


  <li class="md-nav__item">
    <a href="../Decomposition/" title="Decomposition" class="md-nav__link">
      Decomposition
    </a>
  </li>

        
          
          
          


  <li class="md-nav__item">
    <a href="../Discriminant_analysis/" title="Discriminant analysis" class="md-nav__link">
      Discriminant analysis
    </a>
  </li>

        
          
          
          


  <li class="md-nav__item">
    <a href="../Dummy/" title="Dummy" class="md-nav__link">
      Dummy
    </a>
  </li>

        
          
          
          

  


  <li class="md-nav__item md-nav__item--active">
    
    <input class="md-nav__toggle md-toggle" data-md-toggle="toc" type="checkbox" id="__toc">
    
    
      <label class="md-nav__link md-nav__link--active" for="__toc">
        Ensemble
        <span class="md-nav__icon md-icon">
          <svg xmlns="http://www.w3.org/2000/svg" viewBox="0 0 24 24"><path d="M3 9h14V7H3v2m0 4h14v-2H3v2m0 4h14v-2H3v2m16 0h2v-2h-2v2m0-10v2h2V7h-2m0 6h2v-2h-2v2z"/></svg>
        </span>
      </label>
    
    <a href="./" title="Ensemble" class="md-nav__link md-nav__link--active">
      Ensemble
    </a>
    
      
<nav class="md-nav md-nav--secondary" aria-label="Table of contents">
  
  
  
    <label class="md-nav__title" for="__toc">
      <span class="md-nav__icon md-icon">
        <svg xmlns="http://www.w3.org/2000/svg" viewBox="0 0 24 24"><path d="M20 11v2H8l5.5 5.5-1.42 1.42L4.16 12l7.92-7.92L13.5 5.5 8 11h12z"/></svg>
      </span>
      Table of contents
    </label>
    <ul class="md-nav__list" data-md-scrollfix>
      
        <li class="md-nav__item">
  <a href="#parameters" class="md-nav__link">
    Parameters
  </a>
  
</li>
      
        <li class="md-nav__item">
  <a href="#attributes" class="md-nav__link">
    Attributes
  </a>
  
</li>
      
        <li class="md-nav__item">
  <a href="#see-also" class="md-nav__link">
    See Also
  </a>
  
</li>
      
        <li class="md-nav__item">
  <a href="#references" class="md-nav__link">
    References
  </a>
  
</li>
      
        <li class="md-nav__item">
  <a href="#examples" class="md-nav__link">
    Examples
  </a>
  
</li>
      
        <li class="md-nav__item">
  <a href="#parameters_1" class="md-nav__link">
    Parameters
  </a>
  
</li>
      
        <li class="md-nav__item">
  <a href="#returns" class="md-nav__link">
    Returns
  </a>
  
</li>
      
        <li class="md-nav__item">
  <a href="#parameters_2" class="md-nav__link">
    Parameters
  </a>
  
</li>
      
        <li class="md-nav__item">
  <a href="#returns_1" class="md-nav__link">
    Returns
  </a>
  
</li>
      
        <li class="md-nav__item">
  <a href="#parameters_3" class="md-nav__link">
    Parameters
  </a>
  
</li>
      
        <li class="md-nav__item">
  <a href="#returns_2" class="md-nav__link">
    Returns
  </a>
  
</li>
      
        <li class="md-nav__item">
  <a href="#parameters_4" class="md-nav__link">
    Parameters
  </a>
  
</li>
      
        <li class="md-nav__item">
  <a href="#returns_3" class="md-nav__link">
    Returns
  </a>
  
</li>
      
        <li class="md-nav__item">
  <a href="#parameters_5" class="md-nav__link">
    Parameters
  </a>
  
</li>
      
        <li class="md-nav__item">
  <a href="#returns_4" class="md-nav__link">
    Returns
  </a>
  
</li>
      
        <li class="md-nav__item">
  <a href="#parameters_6" class="md-nav__link">
    Parameters
  </a>
  
</li>
      
        <li class="md-nav__item">
  <a href="#returns_5" class="md-nav__link">
    Returns
  </a>
  
</li>
      
        <li class="md-nav__item">
  <a href="#parameters_7" class="md-nav__link">
    Parameters
  </a>
  
</li>
      
        <li class="md-nav__item">
  <a href="#returns_6" class="md-nav__link">
    Returns
  </a>
  
</li>
      
        <li class="md-nav__item">
  <a href="#parameters_8" class="md-nav__link">
    Parameters
  </a>
  
</li>
      
        <li class="md-nav__item">
  <a href="#returns_7" class="md-nav__link">
    Returns
  </a>
  
</li>
      
        <li class="md-nav__item">
  <a href="#parameters_9" class="md-nav__link">
    Parameters
  </a>
  
</li>
      
        <li class="md-nav__item">
  <a href="#yields" class="md-nav__link">
    Yields
  </a>
  
</li>
      
        <li class="md-nav__item">
  <a href="#parameters_10" class="md-nav__link">
    Parameters
  </a>
  
</li>
      
        <li class="md-nav__item">
  <a href="#yields_1" class="md-nav__link">
    Yields
  </a>
  
</li>
      
        <li class="md-nav__item">
  <a href="#parameters_11" class="md-nav__link">
    Parameters
  </a>
  
</li>
      
        <li class="md-nav__item">
  <a href="#yields_2" class="md-nav__link">
    Yields
  </a>
  
</li>
      
        <li class="md-nav__item">
  <a href="#parameters_12" class="md-nav__link">
    Parameters
  </a>
  
</li>
      
        <li class="md-nav__item">
  <a href="#yields_3" class="md-nav__link">
    Yields
  </a>
  
</li>
      
        <li class="md-nav__item">
  <a href="#parameters_13" class="md-nav__link">
    Parameters
  </a>
  
</li>
      
        <li class="md-nav__item">
  <a href="#attributes_1" class="md-nav__link">
    Attributes
  </a>
  
</li>
      
        <li class="md-nav__item">
  <a href="#examples_1" class="md-nav__link">
    Examples
  </a>
  
</li>
      
        <li class="md-nav__item">
  <a href="#see-also_1" class="md-nav__link">
    See also
  </a>
  
</li>
      
        <li class="md-nav__item">
  <a href="#references_1" class="md-nav__link">
    References
  </a>
  
</li>
      
        <li class="md-nav__item">
  <a href="#parameters_14" class="md-nav__link">
    Parameters
  </a>
  
</li>
      
        <li class="md-nav__item">
  <a href="#returns_8" class="md-nav__link">
    Returns
  </a>
  
</li>
      
        <li class="md-nav__item">
  <a href="#parameters_15" class="md-nav__link">
    Parameters
  </a>
  
</li>
      
        <li class="md-nav__item">
  <a href="#returns_9" class="md-nav__link">
    Returns
  </a>
  
</li>
      
        <li class="md-nav__item">
  <a href="#parameters_16" class="md-nav__link">
    Parameters
  </a>
  
</li>
      
        <li class="md-nav__item">
  <a href="#returns_10" class="md-nav__link">
    Returns
  </a>
  
</li>
      
        <li class="md-nav__item">
  <a href="#parameters_17" class="md-nav__link">
    Parameters
  </a>
  
</li>
      
        <li class="md-nav__item">
  <a href="#returns_11" class="md-nav__link">
    Returns
  </a>
  
</li>
      
        <li class="md-nav__item">
  <a href="#notes" class="md-nav__link">
    Notes
  </a>
  
</li>
      
        <li class="md-nav__item">
  <a href="#parameters_18" class="md-nav__link">
    Parameters
  </a>
  
</li>
      
        <li class="md-nav__item">
  <a href="#returns_12" class="md-nav__link">
    Returns
  </a>
  
</li>
      
        <li class="md-nav__item">
  <a href="#parameters_19" class="md-nav__link">
    Parameters
  </a>
  
</li>
      
        <li class="md-nav__item">
  <a href="#yields_4" class="md-nav__link">
    Yields
  </a>
  
</li>
      
        <li class="md-nav__item">
  <a href="#parameters_20" class="md-nav__link">
    Parameters
  </a>
  
</li>
      
        <li class="md-nav__item">
  <a href="#yields_5" class="md-nav__link">
    Yields
  </a>
  
</li>
      
        <li class="md-nav__item">
  <a href="#parameters_21" class="md-nav__link">
    Parameters
  </a>
  
</li>
      
        <li class="md-nav__item">
  <a href="#attributes_2" class="md-nav__link">
    Attributes
  </a>
  
</li>
      
        <li class="md-nav__item">
  <a href="#examples_2" class="md-nav__link">
    Examples
  </a>
  
</li>
      
        <li class="md-nav__item">
  <a href="#references_2" class="md-nav__link">
    References
  </a>
  
</li>
      
        <li class="md-nav__item">
  <a href="#parameters_22" class="md-nav__link">
    Parameters
  </a>
  
</li>
      
        <li class="md-nav__item">
  <a href="#returns_13" class="md-nav__link">
    Returns
  </a>
  
</li>
      
        <li class="md-nav__item">
  <a href="#parameters_23" class="md-nav__link">
    Parameters
  </a>
  
</li>
      
        <li class="md-nav__item">
  <a href="#returns_14" class="md-nav__link">
    Returns
  </a>
  
</li>
      
        <li class="md-nav__item">
  <a href="#parameters_24" class="md-nav__link">
    Parameters
  </a>
  
</li>
      
        <li class="md-nav__item">
  <a href="#returns_15" class="md-nav__link">
    Returns
  </a>
  
</li>
      
        <li class="md-nav__item">
  <a href="#parameters_25" class="md-nav__link">
    Parameters
  </a>
  
</li>
      
        <li class="md-nav__item">
  <a href="#returns_16" class="md-nav__link">
    Returns
  </a>
  
</li>
      
        <li class="md-nav__item">
  <a href="#parameters_26" class="md-nav__link">
    Parameters
  </a>
  
</li>
      
        <li class="md-nav__item">
  <a href="#returns_17" class="md-nav__link">
    Returns
  </a>
  
</li>
      
        <li class="md-nav__item">
  <a href="#parameters_27" class="md-nav__link">
    Parameters
  </a>
  
</li>
      
        <li class="md-nav__item">
  <a href="#returns_18" class="md-nav__link">
    Returns
  </a>
  
</li>
      
        <li class="md-nav__item">
  <a href="#parameters_28" class="md-nav__link">
    Parameters
  </a>
  
</li>
      
        <li class="md-nav__item">
  <a href="#returns_19" class="md-nav__link">
    Returns
  </a>
  
</li>
      
        <li class="md-nav__item">
  <a href="#parameters_29" class="md-nav__link">
    Parameters
  </a>
  
</li>
      
        <li class="md-nav__item">
  <a href="#attributes_3" class="md-nav__link">
    Attributes
  </a>
  
</li>
      
        <li class="md-nav__item">
  <a href="#examples_3" class="md-nav__link">
    Examples
  </a>
  
</li>
      
        <li class="md-nav__item">
  <a href="#references_3" class="md-nav__link">
    References
  </a>
  
</li>
      
        <li class="md-nav__item">
  <a href="#parameters_30" class="md-nav__link">
    Parameters
  </a>
  
</li>
      
        <li class="md-nav__item">
  <a href="#returns_20" class="md-nav__link">
    Returns
  </a>
  
</li>
      
        <li class="md-nav__item">
  <a href="#parameters_31" class="md-nav__link">
    Parameters
  </a>
  
</li>
      
        <li class="md-nav__item">
  <a href="#returns_21" class="md-nav__link">
    Returns
  </a>
  
</li>
      
        <li class="md-nav__item">
  <a href="#parameters_32" class="md-nav__link">
    Parameters
  </a>
  
</li>
      
        <li class="md-nav__item">
  <a href="#returns_22" class="md-nav__link">
    Returns
  </a>
  
</li>
      
        <li class="md-nav__item">
  <a href="#parameters_33" class="md-nav__link">
    Parameters
  </a>
  
</li>
      
        <li class="md-nav__item">
  <a href="#returns_23" class="md-nav__link">
    Returns
  </a>
  
</li>
      
        <li class="md-nav__item">
  <a href="#notes_1" class="md-nav__link">
    Notes
  </a>
  
</li>
      
        <li class="md-nav__item">
  <a href="#parameters_34" class="md-nav__link">
    Parameters
  </a>
  
</li>
      
        <li class="md-nav__item">
  <a href="#returns_24" class="md-nav__link">
    Returns
  </a>
  
</li>
      
        <li class="md-nav__item">
  <a href="#parameters_35" class="md-nav__link">
    Parameters
  </a>
  
</li>
      
        <li class="md-nav__item">
  <a href="#returns_25" class="md-nav__link">
    Returns
  </a>
  
</li>
      
        <li class="md-nav__item">
  <a href="#parameters_36" class="md-nav__link">
    Parameters
  </a>
  
</li>
      
        <li class="md-nav__item">
  <a href="#returns_26" class="md-nav__link">
    Returns
  </a>
  
</li>
      
        <li class="md-nav__item">
  <a href="#parameters_37" class="md-nav__link">
    Parameters
  </a>
  
</li>
      
        <li class="md-nav__item">
  <a href="#attributes_4" class="md-nav__link">
    Attributes
  </a>
  
</li>
      
        <li class="md-nav__item">
  <a href="#notes_2" class="md-nav__link">
    Notes
  </a>
  
</li>
      
        <li class="md-nav__item">
  <a href="#examples_4" class="md-nav__link">
    Examples
  </a>
  
</li>
      
        <li class="md-nav__item">
  <a href="#references_4" class="md-nav__link">
    References
  </a>
  
</li>
      
        <li class="md-nav__item">
  <a href="#see-also_2" class="md-nav__link">
    See Also
  </a>
  
</li>
      
        <li class="md-nav__item">
  <a href="#parameters_38" class="md-nav__link">
    Parameters
  </a>
  
</li>
      
        <li class="md-nav__item">
  <a href="#returns_27" class="md-nav__link">
    Returns
  </a>
  
</li>
      
        <li class="md-nav__item">
  <a href="#parameters_39" class="md-nav__link">
    Parameters
  </a>
  
</li>
      
        <li class="md-nav__item">
  <a href="#returns_28" class="md-nav__link">
    Returns
  </a>
  
</li>
      
        <li class="md-nav__item">
  <a href="#parameters_40" class="md-nav__link">
    Parameters
  </a>
  
</li>
      
        <li class="md-nav__item">
  <a href="#returns_29" class="md-nav__link">
    Returns
  </a>
  
</li>
      
        <li class="md-nav__item">
  <a href="#parameters_41" class="md-nav__link">
    Parameters
  </a>
  
</li>
      
        <li class="md-nav__item">
  <a href="#returns_30" class="md-nav__link">
    Returns
  </a>
  
</li>
      
        <li class="md-nav__item">
  <a href="#parameters_42" class="md-nav__link">
    Parameters
  </a>
  
</li>
      
        <li class="md-nav__item">
  <a href="#returns_31" class="md-nav__link">
    Returns
  </a>
  
</li>
      
        <li class="md-nav__item">
  <a href="#parameters_43" class="md-nav__link">
    Parameters
  </a>
  
</li>
      
        <li class="md-nav__item">
  <a href="#returns_32" class="md-nav__link">
    Returns
  </a>
  
</li>
      
        <li class="md-nav__item">
  <a href="#parameters_44" class="md-nav__link">
    Parameters
  </a>
  
</li>
      
        <li class="md-nav__item">
  <a href="#returns_33" class="md-nav__link">
    Returns
  </a>
  
</li>
      
        <li class="md-nav__item">
  <a href="#parameters_45" class="md-nav__link">
    Parameters
  </a>
  
</li>
      
        <li class="md-nav__item">
  <a href="#returns_34" class="md-nav__link">
    Returns
  </a>
  
</li>
      
        <li class="md-nav__item">
  <a href="#parameters_46" class="md-nav__link">
    Parameters
  </a>
  
</li>
      
        <li class="md-nav__item">
  <a href="#returns_35" class="md-nav__link">
    Returns
  </a>
  
</li>
      
        <li class="md-nav__item">
  <a href="#parameters_47" class="md-nav__link">
    Parameters
  </a>
  
</li>
      
        <li class="md-nav__item">
  <a href="#attributes_5" class="md-nav__link">
    Attributes
  </a>
  
</li>
      
        <li class="md-nav__item">
  <a href="#notes_3" class="md-nav__link">
    Notes
  </a>
  
</li>
      
        <li class="md-nav__item">
  <a href="#references_5" class="md-nav__link">
    References
  </a>
  
</li>
      
        <li class="md-nav__item">
  <a href="#see-also_3" class="md-nav__link">
    See Also
  </a>
  
</li>
      
        <li class="md-nav__item">
  <a href="#parameters_48" class="md-nav__link">
    Parameters
  </a>
  
</li>
      
        <li class="md-nav__item">
  <a href="#returns_36" class="md-nav__link">
    Returns
  </a>
  
</li>
      
        <li class="md-nav__item">
  <a href="#parameters_49" class="md-nav__link">
    Parameters
  </a>
  
</li>
      
        <li class="md-nav__item">
  <a href="#returns_37" class="md-nav__link">
    Returns
  </a>
  
</li>
      
        <li class="md-nav__item">
  <a href="#parameters_50" class="md-nav__link">
    Parameters
  </a>
  
</li>
      
        <li class="md-nav__item">
  <a href="#returns_38" class="md-nav__link">
    Returns
  </a>
  
</li>
      
        <li class="md-nav__item">
  <a href="#parameters_51" class="md-nav__link">
    Parameters
  </a>
  
</li>
      
        <li class="md-nav__item">
  <a href="#returns_39" class="md-nav__link">
    Returns
  </a>
  
</li>
      
        <li class="md-nav__item">
  <a href="#parameters_52" class="md-nav__link">
    Parameters
  </a>
  
</li>
      
        <li class="md-nav__item">
  <a href="#returns_40" class="md-nav__link">
    Returns
  </a>
  
</li>
      
        <li class="md-nav__item">
  <a href="#parameters_53" class="md-nav__link">
    Parameters
  </a>
  
</li>
      
        <li class="md-nav__item">
  <a href="#returns_41" class="md-nav__link">
    Returns
  </a>
  
</li>
      
        <li class="md-nav__item">
  <a href="#notes_4" class="md-nav__link">
    Notes
  </a>
  
</li>
      
        <li class="md-nav__item">
  <a href="#parameters_54" class="md-nav__link">
    Parameters
  </a>
  
</li>
      
        <li class="md-nav__item">
  <a href="#returns_42" class="md-nav__link">
    Returns
  </a>
  
</li>
      
        <li class="md-nav__item">
  <a href="#parameters_55" class="md-nav__link">
    Parameters
  </a>
  
</li>
      
        <li class="md-nav__item">
  <a href="#attributes_6" class="md-nav__link">
    Attributes
  </a>
  
</li>
      
        <li class="md-nav__item">
  <a href="#notes_5" class="md-nav__link">
    Notes
  </a>
  
</li>
      
        <li class="md-nav__item">
  <a href="#see-also_4" class="md-nav__link">
    See also
  </a>
  
</li>
      
        <li class="md-nav__item">
  <a href="#references_6" class="md-nav__link">
    References
  </a>
  
</li>
      
        <li class="md-nav__item">
  <a href="#parameters_56" class="md-nav__link">
    Parameters
  </a>
  
</li>
      
        <li class="md-nav__item">
  <a href="#returns_43" class="md-nav__link">
    Returns
  </a>
  
</li>
      
        <li class="md-nav__item">
  <a href="#parameters_57" class="md-nav__link">
    Parameters
  </a>
  
</li>
      
        <li class="md-nav__item">
  <a href="#returns_44" class="md-nav__link">
    Returns
  </a>
  
</li>
      
        <li class="md-nav__item">
  <a href="#parameters_58" class="md-nav__link">
    Parameters
  </a>
  
</li>
      
        <li class="md-nav__item">
  <a href="#returns_45" class="md-nav__link">
    Returns
  </a>
  
</li>
      
        <li class="md-nav__item">
  <a href="#parameters_59" class="md-nav__link">
    Parameters
  </a>
  
</li>
      
        <li class="md-nav__item">
  <a href="#returns_46" class="md-nav__link">
    Returns
  </a>
  
</li>
      
        <li class="md-nav__item">
  <a href="#parameters_60" class="md-nav__link">
    Parameters
  </a>
  
</li>
      
        <li class="md-nav__item">
  <a href="#returns_47" class="md-nav__link">
    Returns
  </a>
  
</li>
      
        <li class="md-nav__item">
  <a href="#parameters_61" class="md-nav__link">
    Parameters
  </a>
  
</li>
      
        <li class="md-nav__item">
  <a href="#raises" class="md-nav__link">
    Raises
  </a>
  
</li>
      
        <li class="md-nav__item">
  <a href="#returns_48" class="md-nav__link">
    Returns
  </a>
  
</li>
      
        <li class="md-nav__item">
  <a href="#parameters_62" class="md-nav__link">
    Parameters
  </a>
  
</li>
      
        <li class="md-nav__item">
  <a href="#raises_1" class="md-nav__link">
    Raises
  </a>
  
</li>
      
        <li class="md-nav__item">
  <a href="#returns_49" class="md-nav__link">
    Returns
  </a>
  
</li>
      
        <li class="md-nav__item">
  <a href="#parameters_63" class="md-nav__link">
    Parameters
  </a>
  
</li>
      
        <li class="md-nav__item">
  <a href="#returns_50" class="md-nav__link">
    Returns
  </a>
  
</li>
      
        <li class="md-nav__item">
  <a href="#parameters_64" class="md-nav__link">
    Parameters
  </a>
  
</li>
      
        <li class="md-nav__item">
  <a href="#returns_51" class="md-nav__link">
    Returns
  </a>
  
</li>
      
        <li class="md-nav__item">
  <a href="#parameters_65" class="md-nav__link">
    Parameters
  </a>
  
</li>
      
        <li class="md-nav__item">
  <a href="#returns_52" class="md-nav__link">
    Returns
  </a>
  
</li>
      
        <li class="md-nav__item">
  <a href="#parameters_66" class="md-nav__link">
    Parameters
  </a>
  
</li>
      
        <li class="md-nav__item">
  <a href="#returns_53" class="md-nav__link">
    Returns
  </a>
  
</li>
      
        <li class="md-nav__item">
  <a href="#parameters_67" class="md-nav__link">
    Parameters
  </a>
  
</li>
      
        <li class="md-nav__item">
  <a href="#returns_54" class="md-nav__link">
    Returns
  </a>
  
</li>
      
        <li class="md-nav__item">
  <a href="#parameters_68" class="md-nav__link">
    Parameters
  </a>
  
</li>
      
        <li class="md-nav__item">
  <a href="#attributes_7" class="md-nav__link">
    Attributes
  </a>
  
</li>
      
        <li class="md-nav__item">
  <a href="#notes_6" class="md-nav__link">
    Notes
  </a>
  
</li>
      
        <li class="md-nav__item">
  <a href="#see-also_5" class="md-nav__link">
    See also
  </a>
  
</li>
      
        <li class="md-nav__item">
  <a href="#references_7" class="md-nav__link">
    References
  </a>
  
</li>
      
        <li class="md-nav__item">
  <a href="#parameters_69" class="md-nav__link">
    Parameters
  </a>
  
</li>
      
        <li class="md-nav__item">
  <a href="#returns_55" class="md-nav__link">
    Returns
  </a>
  
</li>
      
        <li class="md-nav__item">
  <a href="#parameters_70" class="md-nav__link">
    Parameters
  </a>
  
</li>
      
        <li class="md-nav__item">
  <a href="#returns_56" class="md-nav__link">
    Returns
  </a>
  
</li>
      
        <li class="md-nav__item">
  <a href="#parameters_71" class="md-nav__link">
    Parameters
  </a>
  
</li>
      
        <li class="md-nav__item">
  <a href="#returns_57" class="md-nav__link">
    Returns
  </a>
  
</li>
      
        <li class="md-nav__item">
  <a href="#parameters_72" class="md-nav__link">
    Parameters
  </a>
  
</li>
      
        <li class="md-nav__item">
  <a href="#returns_58" class="md-nav__link">
    Returns
  </a>
  
</li>
      
        <li class="md-nav__item">
  <a href="#parameters_73" class="md-nav__link">
    Parameters
  </a>
  
</li>
      
        <li class="md-nav__item">
  <a href="#returns_59" class="md-nav__link">
    Returns
  </a>
  
</li>
      
        <li class="md-nav__item">
  <a href="#notes_7" class="md-nav__link">
    Notes
  </a>
  
</li>
      
        <li class="md-nav__item">
  <a href="#parameters_74" class="md-nav__link">
    Parameters
  </a>
  
</li>
      
        <li class="md-nav__item">
  <a href="#returns_60" class="md-nav__link">
    Returns
  </a>
  
</li>
      
        <li class="md-nav__item">
  <a href="#parameters_75" class="md-nav__link">
    Parameters
  </a>
  
</li>
      
        <li class="md-nav__item">
  <a href="#returns_61" class="md-nav__link">
    Returns
  </a>
  
</li>
      
        <li class="md-nav__item">
  <a href="#parameters_76" class="md-nav__link">
    Parameters
  </a>
  
</li>
      
        <li class="md-nav__item">
  <a href="#attributes_8" class="md-nav__link">
    Attributes
  </a>
  
</li>
      
        <li class="md-nav__item">
  <a href="#notes_8" class="md-nav__link">
    Notes
  </a>
  
</li>
      
        <li class="md-nav__item">
  <a href="#references_8" class="md-nav__link">
    References
  </a>
  
</li>
      
        <li class="md-nav__item">
  <a href="#see-also_6" class="md-nav__link">
    See Also
  </a>
  
</li>
      
        <li class="md-nav__item">
  <a href="#examples_5" class="md-nav__link">
    Examples
  </a>
  
</li>
      
        <li class="md-nav__item">
  <a href="#parameters_77" class="md-nav__link">
    Parameters
  </a>
  
</li>
      
        <li class="md-nav__item">
  <a href="#returns_62" class="md-nav__link">
    Returns
  </a>
  
</li>
      
        <li class="md-nav__item">
  <a href="#parameters_78" class="md-nav__link">
    Parameters
  </a>
  
</li>
      
        <li class="md-nav__item">
  <a href="#returns_63" class="md-nav__link">
    Returns
  </a>
  
</li>
      
        <li class="md-nav__item">
  <a href="#parameters_79" class="md-nav__link">
    Parameters
  </a>
  
</li>
      
        <li class="md-nav__item">
  <a href="#returns_64" class="md-nav__link">
    Returns
  </a>
  
</li>
      
        <li class="md-nav__item">
  <a href="#parameters_80" class="md-nav__link">
    Parameters
  </a>
  
</li>
      
        <li class="md-nav__item">
  <a href="#returns_65" class="md-nav__link">
    Returns
  </a>
  
</li>
      
        <li class="md-nav__item">
  <a href="#parameters_81" class="md-nav__link">
    Parameters
  </a>
  
</li>
      
        <li class="md-nav__item">
  <a href="#returns_66" class="md-nav__link">
    Returns
  </a>
  
</li>
      
        <li class="md-nav__item">
  <a href="#parameters_82" class="md-nav__link">
    Parameters
  </a>
  
</li>
      
        <li class="md-nav__item">
  <a href="#returns_67" class="md-nav__link">
    Returns
  </a>
  
</li>
      
        <li class="md-nav__item">
  <a href="#parameters_83" class="md-nav__link">
    Parameters
  </a>
  
</li>
      
        <li class="md-nav__item">
  <a href="#returns_68" class="md-nav__link">
    Returns
  </a>
  
</li>
      
        <li class="md-nav__item">
  <a href="#parameters_84" class="md-nav__link">
    Parameters
  </a>
  
</li>
      
        <li class="md-nav__item">
  <a href="#attributes_9" class="md-nav__link">
    Attributes
  </a>
  
</li>
      
        <li class="md-nav__item">
  <a href="#examples_6" class="md-nav__link">
    Examples
  </a>
  
</li>
      
        <li class="md-nav__item">
  <a href="#notes_9" class="md-nav__link">
    Notes
  </a>
  
</li>
      
        <li class="md-nav__item">
  <a href="#references_9" class="md-nav__link">
    References
  </a>
  
</li>
      
        <li class="md-nav__item">
  <a href="#see-also_7" class="md-nav__link">
    See Also
  </a>
  
</li>
      
        <li class="md-nav__item">
  <a href="#parameters_85" class="md-nav__link">
    Parameters
  </a>
  
</li>
      
        <li class="md-nav__item">
  <a href="#returns_69" class="md-nav__link">
    Returns
  </a>
  
</li>
      
        <li class="md-nav__item">
  <a href="#parameters_86" class="md-nav__link">
    Parameters
  </a>
  
</li>
      
        <li class="md-nav__item">
  <a href="#returns_70" class="md-nav__link">
    Returns
  </a>
  
</li>
      
        <li class="md-nav__item">
  <a href="#parameters_87" class="md-nav__link">
    Parameters
  </a>
  
</li>
      
        <li class="md-nav__item">
  <a href="#returns_71" class="md-nav__link">
    Returns
  </a>
  
</li>
      
        <li class="md-nav__item">
  <a href="#parameters_88" class="md-nav__link">
    Parameters
  </a>
  
</li>
      
        <li class="md-nav__item">
  <a href="#returns_72" class="md-nav__link">
    Returns
  </a>
  
</li>
      
        <li class="md-nav__item">
  <a href="#parameters_89" class="md-nav__link">
    Parameters
  </a>
  
</li>
      
        <li class="md-nav__item">
  <a href="#returns_73" class="md-nav__link">
    Returns
  </a>
  
</li>
      
        <li class="md-nav__item">
  <a href="#parameters_90" class="md-nav__link">
    Parameters
  </a>
  
</li>
      
        <li class="md-nav__item">
  <a href="#returns_74" class="md-nav__link">
    Returns
  </a>
  
</li>
      
        <li class="md-nav__item">
  <a href="#parameters_91" class="md-nav__link">
    Parameters
  </a>
  
</li>
      
        <li class="md-nav__item">
  <a href="#returns_75" class="md-nav__link">
    Returns
  </a>
  
</li>
      
        <li class="md-nav__item">
  <a href="#parameters_92" class="md-nav__link">
    Parameters
  </a>
  
</li>
      
        <li class="md-nav__item">
  <a href="#returns_76" class="md-nav__link">
    Returns
  </a>
  
</li>
      
        <li class="md-nav__item">
  <a href="#parameters_93" class="md-nav__link">
    Parameters
  </a>
  
</li>
      
        <li class="md-nav__item">
  <a href="#returns_77" class="md-nav__link">
    Returns
  </a>
  
</li>
      
        <li class="md-nav__item">
  <a href="#parameters_94" class="md-nav__link">
    Parameters
  </a>
  
</li>
      
        <li class="md-nav__item">
  <a href="#attributes_10" class="md-nav__link">
    Attributes
  </a>
  
</li>
      
        <li class="md-nav__item">
  <a href="#examples_7" class="md-nav__link">
    Examples
  </a>
  
</li>
      
        <li class="md-nav__item">
  <a href="#notes_10" class="md-nav__link">
    Notes
  </a>
  
</li>
      
        <li class="md-nav__item">
  <a href="#references_10" class="md-nav__link">
    References
  </a>
  
</li>
      
        <li class="md-nav__item">
  <a href="#see-also_8" class="md-nav__link">
    See Also
  </a>
  
</li>
      
        <li class="md-nav__item">
  <a href="#parameters_95" class="md-nav__link">
    Parameters
  </a>
  
</li>
      
        <li class="md-nav__item">
  <a href="#returns_78" class="md-nav__link">
    Returns
  </a>
  
</li>
      
        <li class="md-nav__item">
  <a href="#parameters_96" class="md-nav__link">
    Parameters
  </a>
  
</li>
      
        <li class="md-nav__item">
  <a href="#returns_79" class="md-nav__link">
    Returns
  </a>
  
</li>
      
        <li class="md-nav__item">
  <a href="#parameters_97" class="md-nav__link">
    Parameters
  </a>
  
</li>
      
        <li class="md-nav__item">
  <a href="#returns_80" class="md-nav__link">
    Returns
  </a>
  
</li>
      
        <li class="md-nav__item">
  <a href="#parameters_98" class="md-nav__link">
    Parameters
  </a>
  
</li>
      
        <li class="md-nav__item">
  <a href="#returns_81" class="md-nav__link">
    Returns
  </a>
  
</li>
      
        <li class="md-nav__item">
  <a href="#parameters_99" class="md-nav__link">
    Parameters
  </a>
  
</li>
      
        <li class="md-nav__item">
  <a href="#returns_82" class="md-nav__link">
    Returns
  </a>
  
</li>
      
        <li class="md-nav__item">
  <a href="#parameters_100" class="md-nav__link">
    Parameters
  </a>
  
</li>
      
        <li class="md-nav__item">
  <a href="#returns_83" class="md-nav__link">
    Returns
  </a>
  
</li>
      
        <li class="md-nav__item">
  <a href="#notes_11" class="md-nav__link">
    Notes
  </a>
  
</li>
      
        <li class="md-nav__item">
  <a href="#parameters_101" class="md-nav__link">
    Parameters
  </a>
  
</li>
      
        <li class="md-nav__item">
  <a href="#returns_84" class="md-nav__link">
    Returns
  </a>
  
</li>
      
        <li class="md-nav__item">
  <a href="#parameters_102" class="md-nav__link">
    Parameters
  </a>
  
</li>
      
        <li class="md-nav__item">
  <a href="#attributes_11" class="md-nav__link">
    Attributes
  </a>
  
</li>
      
        <li class="md-nav__item">
  <a href="#references_11" class="md-nav__link">
    References
  </a>
  
</li>
      
        <li class="md-nav__item">
  <a href="#parameters_103" class="md-nav__link">
    Parameters
  </a>
  
</li>
      
        <li class="md-nav__item">
  <a href="#returns_85" class="md-nav__link">
    Returns
  </a>
  
</li>
      
        <li class="md-nav__item">
  <a href="#parameters_104" class="md-nav__link">
    Parameters
  </a>
  
</li>
      
        <li class="md-nav__item">
  <a href="#returns_86" class="md-nav__link">
    Returns
  </a>
  
</li>
      
        <li class="md-nav__item">
  <a href="#parameters_105" class="md-nav__link">
    Parameters
  </a>
  
</li>
      
        <li class="md-nav__item">
  <a href="#returns_87" class="md-nav__link">
    Returns
  </a>
  
</li>
      
        <li class="md-nav__item">
  <a href="#parameters_106" class="md-nav__link">
    Parameters
  </a>
  
</li>
      
        <li class="md-nav__item">
  <a href="#returns_88" class="md-nav__link">
    Returns
  </a>
  
</li>
      
        <li class="md-nav__item">
  <a href="#parameters_107" class="md-nav__link">
    Parameters
  </a>
  
</li>
      
        <li class="md-nav__item">
  <a href="#returns_89" class="md-nav__link">
    Returns
  </a>
  
</li>
      
        <li class="md-nav__item">
  <a href="#parameters_108" class="md-nav__link">
    Parameters
  </a>
  
</li>
      
        <li class="md-nav__item">
  <a href="#returns_90" class="md-nav__link">
    Returns
  </a>
  
</li>
      
        <li class="md-nav__item">
  <a href="#parameters_109" class="md-nav__link">
    Parameters
  </a>
  
</li>
      
        <li class="md-nav__item">
  <a href="#returns_91" class="md-nav__link">
    Returns
  </a>
  
</li>
      
        <li class="md-nav__item">
  <a href="#parameters_110" class="md-nav__link">
    Parameters
  </a>
  
</li>
      
        <li class="md-nav__item">
  <a href="#attributes_12" class="md-nav__link">
    Attributes
  </a>
  
</li>
      
        <li class="md-nav__item">
  <a href="#notes_12" class="md-nav__link">
    Notes
  </a>
  
</li>
      
        <li class="md-nav__item">
  <a href="#references_12" class="md-nav__link">
    References
  </a>
  
</li>
      
        <li class="md-nav__item">
  <a href="#examples_8" class="md-nav__link">
    Examples
  </a>
  
</li>
      
        <li class="md-nav__item">
  <a href="#parameters_111" class="md-nav__link">
    Parameters
  </a>
  
</li>
      
        <li class="md-nav__item">
  <a href="#returns_92" class="md-nav__link">
    Returns
  </a>
  
</li>
      
        <li class="md-nav__item">
  <a href="#parameters_112" class="md-nav__link">
    Parameters
  </a>
  
</li>
      
        <li class="md-nav__item">
  <a href="#returns_93" class="md-nav__link">
    Returns
  </a>
  
</li>
      
        <li class="md-nav__item">
  <a href="#parameters_113" class="md-nav__link">
    Parameters
  </a>
  
</li>
      
        <li class="md-nav__item">
  <a href="#returns_94" class="md-nav__link">
    Returns
  </a>
  
</li>
      
        <li class="md-nav__item">
  <a href="#parameters_114" class="md-nav__link">
    Parameters
  </a>
  
</li>
      
        <li class="md-nav__item">
  <a href="#parameters_115" class="md-nav__link">
    Parameters
  </a>
  
</li>
      
        <li class="md-nav__item">
  <a href="#returns_95" class="md-nav__link">
    Returns
  </a>
  
</li>
      
        <li class="md-nav__item">
  <a href="#parameters_116" class="md-nav__link">
    Parameters
  </a>
  
</li>
      
        <li class="md-nav__item">
  <a href="#returns_96" class="md-nav__link">
    Returns
  </a>
  
</li>
      
        <li class="md-nav__item">
  <a href="#parameters_117" class="md-nav__link">
    Parameters
  </a>
  
</li>
      
        <li class="md-nav__item">
  <a href="#returns_97" class="md-nav__link">
    Returns
  </a>
  
</li>
      
        <li class="md-nav__item">
  <a href="#parameters_118" class="md-nav__link">
    Parameters
  </a>
  
</li>
      
        <li class="md-nav__item">
  <a href="#parameters_119" class="md-nav__link">
    Parameters
  </a>
  
</li>
      
        <li class="md-nav__item">
  <a href="#returns_98" class="md-nav__link">
    Returns
  </a>
  
</li>
      
        <li class="md-nav__item">
  <a href="#parameters_120" class="md-nav__link">
    Parameters
  </a>
  
</li>
      
        <li class="md-nav__item">
  <a href="#attributes_13" class="md-nav__link">
    Attributes
  </a>
  
</li>
      
        <li class="md-nav__item">
  <a href="#references_13" class="md-nav__link">
    References
  </a>
  
</li>
      
        <li class="md-nav__item">
  <a href="#examples_9" class="md-nav__link">
    Examples
  </a>
  
</li>
      
        <li class="md-nav__item">
  <a href="#parameters_121" class="md-nav__link">
    Parameters
  </a>
  
</li>
      
        <li class="md-nav__item">
  <a href="#returns_99" class="md-nav__link">
    Returns
  </a>
  
</li>
      
        <li class="md-nav__item">
  <a href="#parameters_122" class="md-nav__link">
    Parameters
  </a>
  
</li>
      
        <li class="md-nav__item">
  <a href="#returns_100" class="md-nav__link">
    Returns
  </a>
  
</li>
      
        <li class="md-nav__item">
  <a href="#parameters_123" class="md-nav__link">
    Parameters
  </a>
  
</li>
      
        <li class="md-nav__item">
  <a href="#parameters_124" class="md-nav__link">
    Parameters
  </a>
  
</li>
      
        <li class="md-nav__item">
  <a href="#returns_101" class="md-nav__link">
    Returns
  </a>
  
</li>
      
        <li class="md-nav__item">
  <a href="#parameters_125" class="md-nav__link">
    Parameters
  </a>
  
</li>
      
        <li class="md-nav__item">
  <a href="#returns_102" class="md-nav__link">
    Returns
  </a>
  
</li>
      
        <li class="md-nav__item">
  <a href="#notes_13" class="md-nav__link">
    Notes
  </a>
  
</li>
      
        <li class="md-nav__item">
  <a href="#parameters_126" class="md-nav__link">
    Parameters
  </a>
  
</li>
      
        <li class="md-nav__item">
  <a href="#parameters_127" class="md-nav__link">
    Parameters
  </a>
  
</li>
      
        <li class="md-nav__item">
  <a href="#returns_103" class="md-nav__link">
    Returns
  </a>
  
</li>
      
        <li class="md-nav__item">
  <a href="#parameters_128" class="md-nav__link">
    Parameters
  </a>
  
</li>
      
        <li class="md-nav__item">
  <a href="#attributes_14" class="md-nav__link">
    Attributes
  </a>
  
</li>
      
        <li class="md-nav__item">
  <a href="#see-also_9" class="md-nav__link">
    See Also
  </a>
  
</li>
      
        <li class="md-nav__item">
  <a href="#examples_10" class="md-nav__link">
    Examples
  </a>
  
</li>
      
        <li class="md-nav__item">
  <a href="#parameters_129" class="md-nav__link">
    Parameters
  </a>
  
</li>
      
        <li class="md-nav__item">
  <a href="#returns_104" class="md-nav__link">
    Returns
  </a>
  
</li>
      
        <li class="md-nav__item">
  <a href="#parameters_130" class="md-nav__link">
    Parameters
  </a>
  
</li>
      
        <li class="md-nav__item">
  <a href="#returns_105" class="md-nav__link">
    Returns
  </a>
  
</li>
      
        <li class="md-nav__item">
  <a href="#parameters_131" class="md-nav__link">
    Parameters
  </a>
  
</li>
      
        <li class="md-nav__item">
  <a href="#parameters_132" class="md-nav__link">
    Parameters
  </a>
  
</li>
      
        <li class="md-nav__item">
  <a href="#returns_106" class="md-nav__link">
    Returns
  </a>
  
</li>
      
        <li class="md-nav__item">
  <a href="#parameters_133" class="md-nav__link">
    Parameters
  </a>
  
</li>
      
        <li class="md-nav__item">
  <a href="#returns_107" class="md-nav__link">
    Returns
  </a>
  
</li>
      
        <li class="md-nav__item">
  <a href="#parameters_134" class="md-nav__link">
    Parameters
  </a>
  
</li>
      
        <li class="md-nav__item">
  <a href="#parameters_135" class="md-nav__link">
    Parameters
  </a>
  
</li>
      
        <li class="md-nav__item">
  <a href="#returns_108" class="md-nav__link">
    Returns
  </a>
  
</li>
      
        <li class="md-nav__item">
  <a href="#parameters_136" class="md-nav__link">
    Parameters
  </a>
  
</li>
      
        <li class="md-nav__item">
  <a href="#attributes_15" class="md-nav__link">
    Attributes
  </a>
  
</li>
      
        <li class="md-nav__item">
  <a href="#see-also_10" class="md-nav__link">
    See Also
  </a>
  
</li>
      
        <li class="md-nav__item">
  <a href="#examples_11" class="md-nav__link">
    Examples
  </a>
  
</li>
      
        <li class="md-nav__item">
  <a href="#parameters_137" class="md-nav__link">
    Parameters
  </a>
  
</li>
      
        <li class="md-nav__item">
  <a href="#returns_109" class="md-nav__link">
    Returns
  </a>
  
</li>
      
        <li class="md-nav__item">
  <a href="#parameters_138" class="md-nav__link">
    Parameters
  </a>
  
</li>
      
        <li class="md-nav__item">
  <a href="#returns_110" class="md-nav__link">
    Returns
  </a>
  
</li>
      
        <li class="md-nav__item">
  <a href="#parameters_139" class="md-nav__link">
    Parameters
  </a>
  
</li>
      
        <li class="md-nav__item">
  <a href="#parameters_140" class="md-nav__link">
    Parameters
  </a>
  
</li>
      
        <li class="md-nav__item">
  <a href="#returns_111" class="md-nav__link">
    Returns
  </a>
  
</li>
      
        <li class="md-nav__item">
  <a href="#parameters_141" class="md-nav__link">
    Parameters
  </a>
  
</li>
      
        <li class="md-nav__item">
  <a href="#returns_112" class="md-nav__link">
    Returns
  </a>
  
</li>
      
        <li class="md-nav__item">
  <a href="#notes_14" class="md-nav__link">
    Notes
  </a>
  
</li>
      
        <li class="md-nav__item">
  <a href="#parameters_142" class="md-nav__link">
    Parameters
  </a>
  
</li>
      
        <li class="md-nav__item">
  <a href="#parameters_143" class="md-nav__link">
    Parameters
  </a>
  
</li>
      
        <li class="md-nav__item">
  <a href="#returns_113" class="md-nav__link">
    Returns
  </a>
  
</li>
      
        <li class="md-nav__item">
  <a href="#parameters_144" class="md-nav__link">
    Parameters
  </a>
  
</li>
      
        <li class="md-nav__item">
  <a href="#returns_114" class="md-nav__link">
    Returns
  </a>
  
</li>
      
        <li class="md-nav__item">
  <a href="#parameters_145" class="md-nav__link">
    Parameters
  </a>
  
</li>
      
        <li class="md-nav__item">
  <a href="#returns_115" class="md-nav__link">
    Returns
  </a>
  
</li>
      
        <li class="md-nav__item">
  <a href="#parameters_146" class="md-nav__link">
    Parameters
  </a>
  
</li>
      
        <li class="md-nav__item">
  <a href="#returns_116" class="md-nav__link">
    Returns
  </a>
  
</li>
      
        <li class="md-nav__item">
  <a href="#parameters_147" class="md-nav__link">
    Parameters
  </a>
  
</li>
      
        <li class="md-nav__item">
  <a href="#returns_117" class="md-nav__link">
    Returns
  </a>
  
</li>
      
        <li class="md-nav__item">
  <a href="#parameters_148" class="md-nav__link">
    Parameters
  </a>
  
</li>
      
        <li class="md-nav__item">
  <a href="#returns_118" class="md-nav__link">
    Returns
  </a>
  
</li>
      
        <li class="md-nav__item">
  <a href="#parameters_149" class="md-nav__link">
    Parameters
  </a>
  
</li>
      
        <li class="md-nav__item">
  <a href="#returns_119" class="md-nav__link">
    Returns
  </a>
  
</li>
      
        <li class="md-nav__item">
  <a href="#examples_12" class="md-nav__link">
    Examples
  </a>
  
</li>
      
        <li class="md-nav__item">
  <a href="#parameters_150" class="md-nav__link">
    Parameters
  </a>
  
</li>
      
        <li class="md-nav__item">
  <a href="#returns_120" class="md-nav__link">
    Returns
  </a>
  
</li>
      
        <li class="md-nav__item">
  <a href="#parameters_151" class="md-nav__link">
    Parameters
  </a>
  
</li>
      
        <li class="md-nav__item">
  <a href="#returns_121" class="md-nav__link">
    Returns
  </a>
  
</li>
      
        <li class="md-nav__item">
  <a href="#raises_2" class="md-nav__link">
    Raises
  </a>
  
</li>
      
        <li class="md-nav__item">
  <a href="#parameters_152" class="md-nav__link">
    Parameters
  </a>
  
</li>
      
        <li class="md-nav__item">
  <a href="#returns_122" class="md-nav__link">
    Returns
  </a>
  
</li>
      
        <li class="md-nav__item">
  <a href="#notes_15" class="md-nav__link">
    Notes
  </a>
  
</li>
      
        <li class="md-nav__item">
  <a href="#references_14" class="md-nav__link">
    References
  </a>
  
</li>
      
        <li class="md-nav__item">
  <a href="#examples_13" class="md-nav__link">
    Examples
  </a>
  
</li>
      
        <li class="md-nav__item">
  <a href="#parameters_153" class="md-nav__link">
    Parameters
  </a>
  
</li>
      
        <li class="md-nav__item">
  <a href="#returns_123" class="md-nav__link">
    Returns
  </a>
  
</li>
      
        <li class="md-nav__item">
  <a href="#examples_14" class="md-nav__link">
    Examples
  </a>
  
</li>
      
        <li class="md-nav__item">
  <a href="#parameters_154" class="md-nav__link">
    Parameters
  </a>
  
</li>
      
        <li class="md-nav__item">
  <a href="#returns_124" class="md-nav__link">
    Returns
  </a>
  
</li>
      
        <li class="md-nav__item">
  <a href="#examples_15" class="md-nav__link">
    Examples
  </a>
  
</li>
      
    </ul>
  
</nav>
    
  </li>

        
          
          
          


  <li class="md-nav__item">
    <a href="../Exceptions/" title="Exceptions" class="md-nav__link">
      Exceptions
    </a>
  </li>

        
          
          
          


  <li class="md-nav__item">
    <a href="../Experimental/" title="Experimental" class="md-nav__link">
      Experimental
    </a>
  </li>

        
          
          
          


  <li class="md-nav__item">
    <a href="../Externals/" title="Externals" class="md-nav__link">
      Externals
    </a>
  </li>

        
          
          
          


  <li class="md-nav__item">
    <a href="../Feature_extraction/" title="Feature extraction" class="md-nav__link">
      Feature extraction
    </a>
  </li>

        
          
          
          


  <li class="md-nav__item">
    <a href="../Feature_selection/" title="Feature selection" class="md-nav__link">
      Feature selection
    </a>
  </li>

        
          
          
          


  <li class="md-nav__item">
    <a href="../Gaussian_process/" title="Gaussian process" class="md-nav__link">
      Gaussian process
    </a>
  </li>

        
          
          
          


  <li class="md-nav__item">
    <a href="../Impute/" title="Impute" class="md-nav__link">
      Impute
    </a>
  </li>

        
          
          
          


  <li class="md-nav__item">
    <a href="../Inspection/" title="Inspection" class="md-nav__link">
      Inspection
    </a>
  </li>

        
          
          
          


  <li class="md-nav__item">
    <a href="../Isotonic/" title="Isotonic" class="md-nav__link">
      Isotonic
    </a>
  </li>

        
          
          
          


  <li class="md-nav__item">
    <a href="../Kernel_approximation/" title="Kernel approximation" class="md-nav__link">
      Kernel approximation
    </a>
  </li>

        
          
          
          


  <li class="md-nav__item">
    <a href="../Kernel_ridge/" title="Kernel ridge" class="md-nav__link">
      Kernel ridge
    </a>
  </li>

        
          
          
          


  <li class="md-nav__item">
    <a href="../Linear_model/" title="Linear model" class="md-nav__link">
      Linear model
    </a>
  </li>

        
          
          
          


  <li class="md-nav__item">
    <a href="../Manifold/" title="Manifold" class="md-nav__link">
      Manifold
    </a>
  </li>

        
          
          
          


  <li class="md-nav__item">
    <a href="../Metrics/" title="Metrics" class="md-nav__link">
      Metrics
    </a>
  </li>

        
          
          
          


  <li class="md-nav__item">
    <a href="../Mixture/" title="Mixture" class="md-nav__link">
      Mixture
    </a>
  </li>

        
          
          
          


  <li class="md-nav__item">
    <a href="../Model_selection/" title="Model selection" class="md-nav__link">
      Model selection
    </a>
  </li>

        
          
          
          


  <li class="md-nav__item">
    <a href="../Multiclass/" title="Multiclass" class="md-nav__link">
      Multiclass
    </a>
  </li>

        
          
          
          


  <li class="md-nav__item">
    <a href="../Multioutput/" title="Multioutput" class="md-nav__link">
      Multioutput
    </a>
  </li>

        
          
          
          


  <li class="md-nav__item">
    <a href="../Naive_bayes/" title="Naive bayes" class="md-nav__link">
      Naive bayes
    </a>
  </li>

        
          
          
          


  <li class="md-nav__item">
    <a href="../Neighbors/" title="Neighbors" class="md-nav__link">
      Neighbors
    </a>
  </li>

        
          
          
          


  <li class="md-nav__item">
    <a href="../Neural_network/" title="Neural network" class="md-nav__link">
      Neural network
    </a>
  </li>

        
          
          
          


  <li class="md-nav__item">
    <a href="../Pipeline/" title="Pipeline" class="md-nav__link">
      Pipeline
    </a>
  </li>

        
          
          
          


  <li class="md-nav__item">
    <a href="../Preprocessing/" title="Preprocessing" class="md-nav__link">
      Preprocessing
    </a>
  </li>

        
          
          
          


  <li class="md-nav__item">
    <a href="../Random_projection/" title="Random projection" class="md-nav__link">
      Random projection
    </a>
  </li>

        
          
          
          


  <li class="md-nav__item">
    <a href="../Semi_supervised/" title="Semi supervised" class="md-nav__link">
      Semi supervised
    </a>
  </li>

        
          
          
          


  <li class="md-nav__item">
    <a href="../Setup/" title="Setup" class="md-nav__link">
      Setup
    </a>
  </li>

        
          
          
          


  <li class="md-nav__item">
    <a href="../Svm/" title="Svm" class="md-nav__link">
      Svm
    </a>
  </li>

        
          
          
          


  <li class="md-nav__item">
    <a href="../Tests/" title="Tests" class="md-nav__link">
      Tests
    </a>
  </li>

        
          
          
          


  <li class="md-nav__item">
    <a href="../Tree/" title="Tree" class="md-nav__link">
      Tree
    </a>
  </li>

        
          
          
          


  <li class="md-nav__item">
    <a href="../Utils/" title="Utils" class="md-nav__link">
      Utils
    </a>
  </li>

        
          
          
          


  <li class="md-nav__item">
    <a href="../arr/" title="Arr" class="md-nav__link">
      Arr
    </a>
  </li>

        
          
          
          


  <li class="md-nav__item">
    <a href="../dict/" title="Dict" class="md-nav__link">
      Dict
    </a>
  </li>

        
          
          
          


  <li class="md-nav__item">
    <a href="../wrap_version/" title="Wrap version" class="md-nav__link">
      Wrap version
    </a>
  </li>

        
      </ul>
    </nav>
  </li>

    
  </ul>
</nav>
                  </div>
                </div>
              </div>
            
            
              <div class="md-sidebar md-sidebar--secondary" data-md-component="toc">
                <div class="md-sidebar__scrollwrap">
                  <div class="md-sidebar__inner">
                    
<nav class="md-nav md-nav--secondary" aria-label="Table of contents">
  
  
  
    <label class="md-nav__title" for="__toc">
      <span class="md-nav__icon md-icon">
        <svg xmlns="http://www.w3.org/2000/svg" viewBox="0 0 24 24"><path d="M20 11v2H8l5.5 5.5-1.42 1.42L4.16 12l7.92-7.92L13.5 5.5 8 11h12z"/></svg>
      </span>
      Table of contents
    </label>
    <ul class="md-nav__list" data-md-scrollfix>
      
        <li class="md-nav__item">
  <a href="#parameters" class="md-nav__link">
    Parameters
  </a>
  
</li>
      
        <li class="md-nav__item">
  <a href="#attributes" class="md-nav__link">
    Attributes
  </a>
  
</li>
      
        <li class="md-nav__item">
  <a href="#see-also" class="md-nav__link">
    See Also
  </a>
  
</li>
      
        <li class="md-nav__item">
  <a href="#references" class="md-nav__link">
    References
  </a>
  
</li>
      
        <li class="md-nav__item">
  <a href="#examples" class="md-nav__link">
    Examples
  </a>
  
</li>
      
        <li class="md-nav__item">
  <a href="#parameters_1" class="md-nav__link">
    Parameters
  </a>
  
</li>
      
        <li class="md-nav__item">
  <a href="#returns" class="md-nav__link">
    Returns
  </a>
  
</li>
      
        <li class="md-nav__item">
  <a href="#parameters_2" class="md-nav__link">
    Parameters
  </a>
  
</li>
      
        <li class="md-nav__item">
  <a href="#returns_1" class="md-nav__link">
    Returns
  </a>
  
</li>
      
        <li class="md-nav__item">
  <a href="#parameters_3" class="md-nav__link">
    Parameters
  </a>
  
</li>
      
        <li class="md-nav__item">
  <a href="#returns_2" class="md-nav__link">
    Returns
  </a>
  
</li>
      
        <li class="md-nav__item">
  <a href="#parameters_4" class="md-nav__link">
    Parameters
  </a>
  
</li>
      
        <li class="md-nav__item">
  <a href="#returns_3" class="md-nav__link">
    Returns
  </a>
  
</li>
      
        <li class="md-nav__item">
  <a href="#parameters_5" class="md-nav__link">
    Parameters
  </a>
  
</li>
      
        <li class="md-nav__item">
  <a href="#returns_4" class="md-nav__link">
    Returns
  </a>
  
</li>
      
        <li class="md-nav__item">
  <a href="#parameters_6" class="md-nav__link">
    Parameters
  </a>
  
</li>
      
        <li class="md-nav__item">
  <a href="#returns_5" class="md-nav__link">
    Returns
  </a>
  
</li>
      
        <li class="md-nav__item">
  <a href="#parameters_7" class="md-nav__link">
    Parameters
  </a>
  
</li>
      
        <li class="md-nav__item">
  <a href="#returns_6" class="md-nav__link">
    Returns
  </a>
  
</li>
      
        <li class="md-nav__item">
  <a href="#parameters_8" class="md-nav__link">
    Parameters
  </a>
  
</li>
      
        <li class="md-nav__item">
  <a href="#returns_7" class="md-nav__link">
    Returns
  </a>
  
</li>
      
        <li class="md-nav__item">
  <a href="#parameters_9" class="md-nav__link">
    Parameters
  </a>
  
</li>
      
        <li class="md-nav__item">
  <a href="#yields" class="md-nav__link">
    Yields
  </a>
  
</li>
      
        <li class="md-nav__item">
  <a href="#parameters_10" class="md-nav__link">
    Parameters
  </a>
  
</li>
      
        <li class="md-nav__item">
  <a href="#yields_1" class="md-nav__link">
    Yields
  </a>
  
</li>
      
        <li class="md-nav__item">
  <a href="#parameters_11" class="md-nav__link">
    Parameters
  </a>
  
</li>
      
        <li class="md-nav__item">
  <a href="#yields_2" class="md-nav__link">
    Yields
  </a>
  
</li>
      
        <li class="md-nav__item">
  <a href="#parameters_12" class="md-nav__link">
    Parameters
  </a>
  
</li>
      
        <li class="md-nav__item">
  <a href="#yields_3" class="md-nav__link">
    Yields
  </a>
  
</li>
      
        <li class="md-nav__item">
  <a href="#parameters_13" class="md-nav__link">
    Parameters
  </a>
  
</li>
      
        <li class="md-nav__item">
  <a href="#attributes_1" class="md-nav__link">
    Attributes
  </a>
  
</li>
      
        <li class="md-nav__item">
  <a href="#examples_1" class="md-nav__link">
    Examples
  </a>
  
</li>
      
        <li class="md-nav__item">
  <a href="#see-also_1" class="md-nav__link">
    See also
  </a>
  
</li>
      
        <li class="md-nav__item">
  <a href="#references_1" class="md-nav__link">
    References
  </a>
  
</li>
      
        <li class="md-nav__item">
  <a href="#parameters_14" class="md-nav__link">
    Parameters
  </a>
  
</li>
      
        <li class="md-nav__item">
  <a href="#returns_8" class="md-nav__link">
    Returns
  </a>
  
</li>
      
        <li class="md-nav__item">
  <a href="#parameters_15" class="md-nav__link">
    Parameters
  </a>
  
</li>
      
        <li class="md-nav__item">
  <a href="#returns_9" class="md-nav__link">
    Returns
  </a>
  
</li>
      
        <li class="md-nav__item">
  <a href="#parameters_16" class="md-nav__link">
    Parameters
  </a>
  
</li>
      
        <li class="md-nav__item">
  <a href="#returns_10" class="md-nav__link">
    Returns
  </a>
  
</li>
      
        <li class="md-nav__item">
  <a href="#parameters_17" class="md-nav__link">
    Parameters
  </a>
  
</li>
      
        <li class="md-nav__item">
  <a href="#returns_11" class="md-nav__link">
    Returns
  </a>
  
</li>
      
        <li class="md-nav__item">
  <a href="#notes" class="md-nav__link">
    Notes
  </a>
  
</li>
      
        <li class="md-nav__item">
  <a href="#parameters_18" class="md-nav__link">
    Parameters
  </a>
  
</li>
      
        <li class="md-nav__item">
  <a href="#returns_12" class="md-nav__link">
    Returns
  </a>
  
</li>
      
        <li class="md-nav__item">
  <a href="#parameters_19" class="md-nav__link">
    Parameters
  </a>
  
</li>
      
        <li class="md-nav__item">
  <a href="#yields_4" class="md-nav__link">
    Yields
  </a>
  
</li>
      
        <li class="md-nav__item">
  <a href="#parameters_20" class="md-nav__link">
    Parameters
  </a>
  
</li>
      
        <li class="md-nav__item">
  <a href="#yields_5" class="md-nav__link">
    Yields
  </a>
  
</li>
      
        <li class="md-nav__item">
  <a href="#parameters_21" class="md-nav__link">
    Parameters
  </a>
  
</li>
      
        <li class="md-nav__item">
  <a href="#attributes_2" class="md-nav__link">
    Attributes
  </a>
  
</li>
      
        <li class="md-nav__item">
  <a href="#examples_2" class="md-nav__link">
    Examples
  </a>
  
</li>
      
        <li class="md-nav__item">
  <a href="#references_2" class="md-nav__link">
    References
  </a>
  
</li>
      
        <li class="md-nav__item">
  <a href="#parameters_22" class="md-nav__link">
    Parameters
  </a>
  
</li>
      
        <li class="md-nav__item">
  <a href="#returns_13" class="md-nav__link">
    Returns
  </a>
  
</li>
      
        <li class="md-nav__item">
  <a href="#parameters_23" class="md-nav__link">
    Parameters
  </a>
  
</li>
      
        <li class="md-nav__item">
  <a href="#returns_14" class="md-nav__link">
    Returns
  </a>
  
</li>
      
        <li class="md-nav__item">
  <a href="#parameters_24" class="md-nav__link">
    Parameters
  </a>
  
</li>
      
        <li class="md-nav__item">
  <a href="#returns_15" class="md-nav__link">
    Returns
  </a>
  
</li>
      
        <li class="md-nav__item">
  <a href="#parameters_25" class="md-nav__link">
    Parameters
  </a>
  
</li>
      
        <li class="md-nav__item">
  <a href="#returns_16" class="md-nav__link">
    Returns
  </a>
  
</li>
      
        <li class="md-nav__item">
  <a href="#parameters_26" class="md-nav__link">
    Parameters
  </a>
  
</li>
      
        <li class="md-nav__item">
  <a href="#returns_17" class="md-nav__link">
    Returns
  </a>
  
</li>
      
        <li class="md-nav__item">
  <a href="#parameters_27" class="md-nav__link">
    Parameters
  </a>
  
</li>
      
        <li class="md-nav__item">
  <a href="#returns_18" class="md-nav__link">
    Returns
  </a>
  
</li>
      
        <li class="md-nav__item">
  <a href="#parameters_28" class="md-nav__link">
    Parameters
  </a>
  
</li>
      
        <li class="md-nav__item">
  <a href="#returns_19" class="md-nav__link">
    Returns
  </a>
  
</li>
      
        <li class="md-nav__item">
  <a href="#parameters_29" class="md-nav__link">
    Parameters
  </a>
  
</li>
      
        <li class="md-nav__item">
  <a href="#attributes_3" class="md-nav__link">
    Attributes
  </a>
  
</li>
      
        <li class="md-nav__item">
  <a href="#examples_3" class="md-nav__link">
    Examples
  </a>
  
</li>
      
        <li class="md-nav__item">
  <a href="#references_3" class="md-nav__link">
    References
  </a>
  
</li>
      
        <li class="md-nav__item">
  <a href="#parameters_30" class="md-nav__link">
    Parameters
  </a>
  
</li>
      
        <li class="md-nav__item">
  <a href="#returns_20" class="md-nav__link">
    Returns
  </a>
  
</li>
      
        <li class="md-nav__item">
  <a href="#parameters_31" class="md-nav__link">
    Parameters
  </a>
  
</li>
      
        <li class="md-nav__item">
  <a href="#returns_21" class="md-nav__link">
    Returns
  </a>
  
</li>
      
        <li class="md-nav__item">
  <a href="#parameters_32" class="md-nav__link">
    Parameters
  </a>
  
</li>
      
        <li class="md-nav__item">
  <a href="#returns_22" class="md-nav__link">
    Returns
  </a>
  
</li>
      
        <li class="md-nav__item">
  <a href="#parameters_33" class="md-nav__link">
    Parameters
  </a>
  
</li>
      
        <li class="md-nav__item">
  <a href="#returns_23" class="md-nav__link">
    Returns
  </a>
  
</li>
      
        <li class="md-nav__item">
  <a href="#notes_1" class="md-nav__link">
    Notes
  </a>
  
</li>
      
        <li class="md-nav__item">
  <a href="#parameters_34" class="md-nav__link">
    Parameters
  </a>
  
</li>
      
        <li class="md-nav__item">
  <a href="#returns_24" class="md-nav__link">
    Returns
  </a>
  
</li>
      
        <li class="md-nav__item">
  <a href="#parameters_35" class="md-nav__link">
    Parameters
  </a>
  
</li>
      
        <li class="md-nav__item">
  <a href="#returns_25" class="md-nav__link">
    Returns
  </a>
  
</li>
      
        <li class="md-nav__item">
  <a href="#parameters_36" class="md-nav__link">
    Parameters
  </a>
  
</li>
      
        <li class="md-nav__item">
  <a href="#returns_26" class="md-nav__link">
    Returns
  </a>
  
</li>
      
        <li class="md-nav__item">
  <a href="#parameters_37" class="md-nav__link">
    Parameters
  </a>
  
</li>
      
        <li class="md-nav__item">
  <a href="#attributes_4" class="md-nav__link">
    Attributes
  </a>
  
</li>
      
        <li class="md-nav__item">
  <a href="#notes_2" class="md-nav__link">
    Notes
  </a>
  
</li>
      
        <li class="md-nav__item">
  <a href="#examples_4" class="md-nav__link">
    Examples
  </a>
  
</li>
      
        <li class="md-nav__item">
  <a href="#references_4" class="md-nav__link">
    References
  </a>
  
</li>
      
        <li class="md-nav__item">
  <a href="#see-also_2" class="md-nav__link">
    See Also
  </a>
  
</li>
      
        <li class="md-nav__item">
  <a href="#parameters_38" class="md-nav__link">
    Parameters
  </a>
  
</li>
      
        <li class="md-nav__item">
  <a href="#returns_27" class="md-nav__link">
    Returns
  </a>
  
</li>
      
        <li class="md-nav__item">
  <a href="#parameters_39" class="md-nav__link">
    Parameters
  </a>
  
</li>
      
        <li class="md-nav__item">
  <a href="#returns_28" class="md-nav__link">
    Returns
  </a>
  
</li>
      
        <li class="md-nav__item">
  <a href="#parameters_40" class="md-nav__link">
    Parameters
  </a>
  
</li>
      
        <li class="md-nav__item">
  <a href="#returns_29" class="md-nav__link">
    Returns
  </a>
  
</li>
      
        <li class="md-nav__item">
  <a href="#parameters_41" class="md-nav__link">
    Parameters
  </a>
  
</li>
      
        <li class="md-nav__item">
  <a href="#returns_30" class="md-nav__link">
    Returns
  </a>
  
</li>
      
        <li class="md-nav__item">
  <a href="#parameters_42" class="md-nav__link">
    Parameters
  </a>
  
</li>
      
        <li class="md-nav__item">
  <a href="#returns_31" class="md-nav__link">
    Returns
  </a>
  
</li>
      
        <li class="md-nav__item">
  <a href="#parameters_43" class="md-nav__link">
    Parameters
  </a>
  
</li>
      
        <li class="md-nav__item">
  <a href="#returns_32" class="md-nav__link">
    Returns
  </a>
  
</li>
      
        <li class="md-nav__item">
  <a href="#parameters_44" class="md-nav__link">
    Parameters
  </a>
  
</li>
      
        <li class="md-nav__item">
  <a href="#returns_33" class="md-nav__link">
    Returns
  </a>
  
</li>
      
        <li class="md-nav__item">
  <a href="#parameters_45" class="md-nav__link">
    Parameters
  </a>
  
</li>
      
        <li class="md-nav__item">
  <a href="#returns_34" class="md-nav__link">
    Returns
  </a>
  
</li>
      
        <li class="md-nav__item">
  <a href="#parameters_46" class="md-nav__link">
    Parameters
  </a>
  
</li>
      
        <li class="md-nav__item">
  <a href="#returns_35" class="md-nav__link">
    Returns
  </a>
  
</li>
      
        <li class="md-nav__item">
  <a href="#parameters_47" class="md-nav__link">
    Parameters
  </a>
  
</li>
      
        <li class="md-nav__item">
  <a href="#attributes_5" class="md-nav__link">
    Attributes
  </a>
  
</li>
      
        <li class="md-nav__item">
  <a href="#notes_3" class="md-nav__link">
    Notes
  </a>
  
</li>
      
        <li class="md-nav__item">
  <a href="#references_5" class="md-nav__link">
    References
  </a>
  
</li>
      
        <li class="md-nav__item">
  <a href="#see-also_3" class="md-nav__link">
    See Also
  </a>
  
</li>
      
        <li class="md-nav__item">
  <a href="#parameters_48" class="md-nav__link">
    Parameters
  </a>
  
</li>
      
        <li class="md-nav__item">
  <a href="#returns_36" class="md-nav__link">
    Returns
  </a>
  
</li>
      
        <li class="md-nav__item">
  <a href="#parameters_49" class="md-nav__link">
    Parameters
  </a>
  
</li>
      
        <li class="md-nav__item">
  <a href="#returns_37" class="md-nav__link">
    Returns
  </a>
  
</li>
      
        <li class="md-nav__item">
  <a href="#parameters_50" class="md-nav__link">
    Parameters
  </a>
  
</li>
      
        <li class="md-nav__item">
  <a href="#returns_38" class="md-nav__link">
    Returns
  </a>
  
</li>
      
        <li class="md-nav__item">
  <a href="#parameters_51" class="md-nav__link">
    Parameters
  </a>
  
</li>
      
        <li class="md-nav__item">
  <a href="#returns_39" class="md-nav__link">
    Returns
  </a>
  
</li>
      
        <li class="md-nav__item">
  <a href="#parameters_52" class="md-nav__link">
    Parameters
  </a>
  
</li>
      
        <li class="md-nav__item">
  <a href="#returns_40" class="md-nav__link">
    Returns
  </a>
  
</li>
      
        <li class="md-nav__item">
  <a href="#parameters_53" class="md-nav__link">
    Parameters
  </a>
  
</li>
      
        <li class="md-nav__item">
  <a href="#returns_41" class="md-nav__link">
    Returns
  </a>
  
</li>
      
        <li class="md-nav__item">
  <a href="#notes_4" class="md-nav__link">
    Notes
  </a>
  
</li>
      
        <li class="md-nav__item">
  <a href="#parameters_54" class="md-nav__link">
    Parameters
  </a>
  
</li>
      
        <li class="md-nav__item">
  <a href="#returns_42" class="md-nav__link">
    Returns
  </a>
  
</li>
      
        <li class="md-nav__item">
  <a href="#parameters_55" class="md-nav__link">
    Parameters
  </a>
  
</li>
      
        <li class="md-nav__item">
  <a href="#attributes_6" class="md-nav__link">
    Attributes
  </a>
  
</li>
      
        <li class="md-nav__item">
  <a href="#notes_5" class="md-nav__link">
    Notes
  </a>
  
</li>
      
        <li class="md-nav__item">
  <a href="#see-also_4" class="md-nav__link">
    See also
  </a>
  
</li>
      
        <li class="md-nav__item">
  <a href="#references_6" class="md-nav__link">
    References
  </a>
  
</li>
      
        <li class="md-nav__item">
  <a href="#parameters_56" class="md-nav__link">
    Parameters
  </a>
  
</li>
      
        <li class="md-nav__item">
  <a href="#returns_43" class="md-nav__link">
    Returns
  </a>
  
</li>
      
        <li class="md-nav__item">
  <a href="#parameters_57" class="md-nav__link">
    Parameters
  </a>
  
</li>
      
        <li class="md-nav__item">
  <a href="#returns_44" class="md-nav__link">
    Returns
  </a>
  
</li>
      
        <li class="md-nav__item">
  <a href="#parameters_58" class="md-nav__link">
    Parameters
  </a>
  
</li>
      
        <li class="md-nav__item">
  <a href="#returns_45" class="md-nav__link">
    Returns
  </a>
  
</li>
      
        <li class="md-nav__item">
  <a href="#parameters_59" class="md-nav__link">
    Parameters
  </a>
  
</li>
      
        <li class="md-nav__item">
  <a href="#returns_46" class="md-nav__link">
    Returns
  </a>
  
</li>
      
        <li class="md-nav__item">
  <a href="#parameters_60" class="md-nav__link">
    Parameters
  </a>
  
</li>
      
        <li class="md-nav__item">
  <a href="#returns_47" class="md-nav__link">
    Returns
  </a>
  
</li>
      
        <li class="md-nav__item">
  <a href="#parameters_61" class="md-nav__link">
    Parameters
  </a>
  
</li>
      
        <li class="md-nav__item">
  <a href="#raises" class="md-nav__link">
    Raises
  </a>
  
</li>
      
        <li class="md-nav__item">
  <a href="#returns_48" class="md-nav__link">
    Returns
  </a>
  
</li>
      
        <li class="md-nav__item">
  <a href="#parameters_62" class="md-nav__link">
    Parameters
  </a>
  
</li>
      
        <li class="md-nav__item">
  <a href="#raises_1" class="md-nav__link">
    Raises
  </a>
  
</li>
      
        <li class="md-nav__item">
  <a href="#returns_49" class="md-nav__link">
    Returns
  </a>
  
</li>
      
        <li class="md-nav__item">
  <a href="#parameters_63" class="md-nav__link">
    Parameters
  </a>
  
</li>
      
        <li class="md-nav__item">
  <a href="#returns_50" class="md-nav__link">
    Returns
  </a>
  
</li>
      
        <li class="md-nav__item">
  <a href="#parameters_64" class="md-nav__link">
    Parameters
  </a>
  
</li>
      
        <li class="md-nav__item">
  <a href="#returns_51" class="md-nav__link">
    Returns
  </a>
  
</li>
      
        <li class="md-nav__item">
  <a href="#parameters_65" class="md-nav__link">
    Parameters
  </a>
  
</li>
      
        <li class="md-nav__item">
  <a href="#returns_52" class="md-nav__link">
    Returns
  </a>
  
</li>
      
        <li class="md-nav__item">
  <a href="#parameters_66" class="md-nav__link">
    Parameters
  </a>
  
</li>
      
        <li class="md-nav__item">
  <a href="#returns_53" class="md-nav__link">
    Returns
  </a>
  
</li>
      
        <li class="md-nav__item">
  <a href="#parameters_67" class="md-nav__link">
    Parameters
  </a>
  
</li>
      
        <li class="md-nav__item">
  <a href="#returns_54" class="md-nav__link">
    Returns
  </a>
  
</li>
      
        <li class="md-nav__item">
  <a href="#parameters_68" class="md-nav__link">
    Parameters
  </a>
  
</li>
      
        <li class="md-nav__item">
  <a href="#attributes_7" class="md-nav__link">
    Attributes
  </a>
  
</li>
      
        <li class="md-nav__item">
  <a href="#notes_6" class="md-nav__link">
    Notes
  </a>
  
</li>
      
        <li class="md-nav__item">
  <a href="#see-also_5" class="md-nav__link">
    See also
  </a>
  
</li>
      
        <li class="md-nav__item">
  <a href="#references_7" class="md-nav__link">
    References
  </a>
  
</li>
      
        <li class="md-nav__item">
  <a href="#parameters_69" class="md-nav__link">
    Parameters
  </a>
  
</li>
      
        <li class="md-nav__item">
  <a href="#returns_55" class="md-nav__link">
    Returns
  </a>
  
</li>
      
        <li class="md-nav__item">
  <a href="#parameters_70" class="md-nav__link">
    Parameters
  </a>
  
</li>
      
        <li class="md-nav__item">
  <a href="#returns_56" class="md-nav__link">
    Returns
  </a>
  
</li>
      
        <li class="md-nav__item">
  <a href="#parameters_71" class="md-nav__link">
    Parameters
  </a>
  
</li>
      
        <li class="md-nav__item">
  <a href="#returns_57" class="md-nav__link">
    Returns
  </a>
  
</li>
      
        <li class="md-nav__item">
  <a href="#parameters_72" class="md-nav__link">
    Parameters
  </a>
  
</li>
      
        <li class="md-nav__item">
  <a href="#returns_58" class="md-nav__link">
    Returns
  </a>
  
</li>
      
        <li class="md-nav__item">
  <a href="#parameters_73" class="md-nav__link">
    Parameters
  </a>
  
</li>
      
        <li class="md-nav__item">
  <a href="#returns_59" class="md-nav__link">
    Returns
  </a>
  
</li>
      
        <li class="md-nav__item">
  <a href="#notes_7" class="md-nav__link">
    Notes
  </a>
  
</li>
      
        <li class="md-nav__item">
  <a href="#parameters_74" class="md-nav__link">
    Parameters
  </a>
  
</li>
      
        <li class="md-nav__item">
  <a href="#returns_60" class="md-nav__link">
    Returns
  </a>
  
</li>
      
        <li class="md-nav__item">
  <a href="#parameters_75" class="md-nav__link">
    Parameters
  </a>
  
</li>
      
        <li class="md-nav__item">
  <a href="#returns_61" class="md-nav__link">
    Returns
  </a>
  
</li>
      
        <li class="md-nav__item">
  <a href="#parameters_76" class="md-nav__link">
    Parameters
  </a>
  
</li>
      
        <li class="md-nav__item">
  <a href="#attributes_8" class="md-nav__link">
    Attributes
  </a>
  
</li>
      
        <li class="md-nav__item">
  <a href="#notes_8" class="md-nav__link">
    Notes
  </a>
  
</li>
      
        <li class="md-nav__item">
  <a href="#references_8" class="md-nav__link">
    References
  </a>
  
</li>
      
        <li class="md-nav__item">
  <a href="#see-also_6" class="md-nav__link">
    See Also
  </a>
  
</li>
      
        <li class="md-nav__item">
  <a href="#examples_5" class="md-nav__link">
    Examples
  </a>
  
</li>
      
        <li class="md-nav__item">
  <a href="#parameters_77" class="md-nav__link">
    Parameters
  </a>
  
</li>
      
        <li class="md-nav__item">
  <a href="#returns_62" class="md-nav__link">
    Returns
  </a>
  
</li>
      
        <li class="md-nav__item">
  <a href="#parameters_78" class="md-nav__link">
    Parameters
  </a>
  
</li>
      
        <li class="md-nav__item">
  <a href="#returns_63" class="md-nav__link">
    Returns
  </a>
  
</li>
      
        <li class="md-nav__item">
  <a href="#parameters_79" class="md-nav__link">
    Parameters
  </a>
  
</li>
      
        <li class="md-nav__item">
  <a href="#returns_64" class="md-nav__link">
    Returns
  </a>
  
</li>
      
        <li class="md-nav__item">
  <a href="#parameters_80" class="md-nav__link">
    Parameters
  </a>
  
</li>
      
        <li class="md-nav__item">
  <a href="#returns_65" class="md-nav__link">
    Returns
  </a>
  
</li>
      
        <li class="md-nav__item">
  <a href="#parameters_81" class="md-nav__link">
    Parameters
  </a>
  
</li>
      
        <li class="md-nav__item">
  <a href="#returns_66" class="md-nav__link">
    Returns
  </a>
  
</li>
      
        <li class="md-nav__item">
  <a href="#parameters_82" class="md-nav__link">
    Parameters
  </a>
  
</li>
      
        <li class="md-nav__item">
  <a href="#returns_67" class="md-nav__link">
    Returns
  </a>
  
</li>
      
        <li class="md-nav__item">
  <a href="#parameters_83" class="md-nav__link">
    Parameters
  </a>
  
</li>
      
        <li class="md-nav__item">
  <a href="#returns_68" class="md-nav__link">
    Returns
  </a>
  
</li>
      
        <li class="md-nav__item">
  <a href="#parameters_84" class="md-nav__link">
    Parameters
  </a>
  
</li>
      
        <li class="md-nav__item">
  <a href="#attributes_9" class="md-nav__link">
    Attributes
  </a>
  
</li>
      
        <li class="md-nav__item">
  <a href="#examples_6" class="md-nav__link">
    Examples
  </a>
  
</li>
      
        <li class="md-nav__item">
  <a href="#notes_9" class="md-nav__link">
    Notes
  </a>
  
</li>
      
        <li class="md-nav__item">
  <a href="#references_9" class="md-nav__link">
    References
  </a>
  
</li>
      
        <li class="md-nav__item">
  <a href="#see-also_7" class="md-nav__link">
    See Also
  </a>
  
</li>
      
        <li class="md-nav__item">
  <a href="#parameters_85" class="md-nav__link">
    Parameters
  </a>
  
</li>
      
        <li class="md-nav__item">
  <a href="#returns_69" class="md-nav__link">
    Returns
  </a>
  
</li>
      
        <li class="md-nav__item">
  <a href="#parameters_86" class="md-nav__link">
    Parameters
  </a>
  
</li>
      
        <li class="md-nav__item">
  <a href="#returns_70" class="md-nav__link">
    Returns
  </a>
  
</li>
      
        <li class="md-nav__item">
  <a href="#parameters_87" class="md-nav__link">
    Parameters
  </a>
  
</li>
      
        <li class="md-nav__item">
  <a href="#returns_71" class="md-nav__link">
    Returns
  </a>
  
</li>
      
        <li class="md-nav__item">
  <a href="#parameters_88" class="md-nav__link">
    Parameters
  </a>
  
</li>
      
        <li class="md-nav__item">
  <a href="#returns_72" class="md-nav__link">
    Returns
  </a>
  
</li>
      
        <li class="md-nav__item">
  <a href="#parameters_89" class="md-nav__link">
    Parameters
  </a>
  
</li>
      
        <li class="md-nav__item">
  <a href="#returns_73" class="md-nav__link">
    Returns
  </a>
  
</li>
      
        <li class="md-nav__item">
  <a href="#parameters_90" class="md-nav__link">
    Parameters
  </a>
  
</li>
      
        <li class="md-nav__item">
  <a href="#returns_74" class="md-nav__link">
    Returns
  </a>
  
</li>
      
        <li class="md-nav__item">
  <a href="#parameters_91" class="md-nav__link">
    Parameters
  </a>
  
</li>
      
        <li class="md-nav__item">
  <a href="#returns_75" class="md-nav__link">
    Returns
  </a>
  
</li>
      
        <li class="md-nav__item">
  <a href="#parameters_92" class="md-nav__link">
    Parameters
  </a>
  
</li>
      
        <li class="md-nav__item">
  <a href="#returns_76" class="md-nav__link">
    Returns
  </a>
  
</li>
      
        <li class="md-nav__item">
  <a href="#parameters_93" class="md-nav__link">
    Parameters
  </a>
  
</li>
      
        <li class="md-nav__item">
  <a href="#returns_77" class="md-nav__link">
    Returns
  </a>
  
</li>
      
        <li class="md-nav__item">
  <a href="#parameters_94" class="md-nav__link">
    Parameters
  </a>
  
</li>
      
        <li class="md-nav__item">
  <a href="#attributes_10" class="md-nav__link">
    Attributes
  </a>
  
</li>
      
        <li class="md-nav__item">
  <a href="#examples_7" class="md-nav__link">
    Examples
  </a>
  
</li>
      
        <li class="md-nav__item">
  <a href="#notes_10" class="md-nav__link">
    Notes
  </a>
  
</li>
      
        <li class="md-nav__item">
  <a href="#references_10" class="md-nav__link">
    References
  </a>
  
</li>
      
        <li class="md-nav__item">
  <a href="#see-also_8" class="md-nav__link">
    See Also
  </a>
  
</li>
      
        <li class="md-nav__item">
  <a href="#parameters_95" class="md-nav__link">
    Parameters
  </a>
  
</li>
      
        <li class="md-nav__item">
  <a href="#returns_78" class="md-nav__link">
    Returns
  </a>
  
</li>
      
        <li class="md-nav__item">
  <a href="#parameters_96" class="md-nav__link">
    Parameters
  </a>
  
</li>
      
        <li class="md-nav__item">
  <a href="#returns_79" class="md-nav__link">
    Returns
  </a>
  
</li>
      
        <li class="md-nav__item">
  <a href="#parameters_97" class="md-nav__link">
    Parameters
  </a>
  
</li>
      
        <li class="md-nav__item">
  <a href="#returns_80" class="md-nav__link">
    Returns
  </a>
  
</li>
      
        <li class="md-nav__item">
  <a href="#parameters_98" class="md-nav__link">
    Parameters
  </a>
  
</li>
      
        <li class="md-nav__item">
  <a href="#returns_81" class="md-nav__link">
    Returns
  </a>
  
</li>
      
        <li class="md-nav__item">
  <a href="#parameters_99" class="md-nav__link">
    Parameters
  </a>
  
</li>
      
        <li class="md-nav__item">
  <a href="#returns_82" class="md-nav__link">
    Returns
  </a>
  
</li>
      
        <li class="md-nav__item">
  <a href="#parameters_100" class="md-nav__link">
    Parameters
  </a>
  
</li>
      
        <li class="md-nav__item">
  <a href="#returns_83" class="md-nav__link">
    Returns
  </a>
  
</li>
      
        <li class="md-nav__item">
  <a href="#notes_11" class="md-nav__link">
    Notes
  </a>
  
</li>
      
        <li class="md-nav__item">
  <a href="#parameters_101" class="md-nav__link">
    Parameters
  </a>
  
</li>
      
        <li class="md-nav__item">
  <a href="#returns_84" class="md-nav__link">
    Returns
  </a>
  
</li>
      
        <li class="md-nav__item">
  <a href="#parameters_102" class="md-nav__link">
    Parameters
  </a>
  
</li>
      
        <li class="md-nav__item">
  <a href="#attributes_11" class="md-nav__link">
    Attributes
  </a>
  
</li>
      
        <li class="md-nav__item">
  <a href="#references_11" class="md-nav__link">
    References
  </a>
  
</li>
      
        <li class="md-nav__item">
  <a href="#parameters_103" class="md-nav__link">
    Parameters
  </a>
  
</li>
      
        <li class="md-nav__item">
  <a href="#returns_85" class="md-nav__link">
    Returns
  </a>
  
</li>
      
        <li class="md-nav__item">
  <a href="#parameters_104" class="md-nav__link">
    Parameters
  </a>
  
</li>
      
        <li class="md-nav__item">
  <a href="#returns_86" class="md-nav__link">
    Returns
  </a>
  
</li>
      
        <li class="md-nav__item">
  <a href="#parameters_105" class="md-nav__link">
    Parameters
  </a>
  
</li>
      
        <li class="md-nav__item">
  <a href="#returns_87" class="md-nav__link">
    Returns
  </a>
  
</li>
      
        <li class="md-nav__item">
  <a href="#parameters_106" class="md-nav__link">
    Parameters
  </a>
  
</li>
      
        <li class="md-nav__item">
  <a href="#returns_88" class="md-nav__link">
    Returns
  </a>
  
</li>
      
        <li class="md-nav__item">
  <a href="#parameters_107" class="md-nav__link">
    Parameters
  </a>
  
</li>
      
        <li class="md-nav__item">
  <a href="#returns_89" class="md-nav__link">
    Returns
  </a>
  
</li>
      
        <li class="md-nav__item">
  <a href="#parameters_108" class="md-nav__link">
    Parameters
  </a>
  
</li>
      
        <li class="md-nav__item">
  <a href="#returns_90" class="md-nav__link">
    Returns
  </a>
  
</li>
      
        <li class="md-nav__item">
  <a href="#parameters_109" class="md-nav__link">
    Parameters
  </a>
  
</li>
      
        <li class="md-nav__item">
  <a href="#returns_91" class="md-nav__link">
    Returns
  </a>
  
</li>
      
        <li class="md-nav__item">
  <a href="#parameters_110" class="md-nav__link">
    Parameters
  </a>
  
</li>
      
        <li class="md-nav__item">
  <a href="#attributes_12" class="md-nav__link">
    Attributes
  </a>
  
</li>
      
        <li class="md-nav__item">
  <a href="#notes_12" class="md-nav__link">
    Notes
  </a>
  
</li>
      
        <li class="md-nav__item">
  <a href="#references_12" class="md-nav__link">
    References
  </a>
  
</li>
      
        <li class="md-nav__item">
  <a href="#examples_8" class="md-nav__link">
    Examples
  </a>
  
</li>
      
        <li class="md-nav__item">
  <a href="#parameters_111" class="md-nav__link">
    Parameters
  </a>
  
</li>
      
        <li class="md-nav__item">
  <a href="#returns_92" class="md-nav__link">
    Returns
  </a>
  
</li>
      
        <li class="md-nav__item">
  <a href="#parameters_112" class="md-nav__link">
    Parameters
  </a>
  
</li>
      
        <li class="md-nav__item">
  <a href="#returns_93" class="md-nav__link">
    Returns
  </a>
  
</li>
      
        <li class="md-nav__item">
  <a href="#parameters_113" class="md-nav__link">
    Parameters
  </a>
  
</li>
      
        <li class="md-nav__item">
  <a href="#returns_94" class="md-nav__link">
    Returns
  </a>
  
</li>
      
        <li class="md-nav__item">
  <a href="#parameters_114" class="md-nav__link">
    Parameters
  </a>
  
</li>
      
        <li class="md-nav__item">
  <a href="#parameters_115" class="md-nav__link">
    Parameters
  </a>
  
</li>
      
        <li class="md-nav__item">
  <a href="#returns_95" class="md-nav__link">
    Returns
  </a>
  
</li>
      
        <li class="md-nav__item">
  <a href="#parameters_116" class="md-nav__link">
    Parameters
  </a>
  
</li>
      
        <li class="md-nav__item">
  <a href="#returns_96" class="md-nav__link">
    Returns
  </a>
  
</li>
      
        <li class="md-nav__item">
  <a href="#parameters_117" class="md-nav__link">
    Parameters
  </a>
  
</li>
      
        <li class="md-nav__item">
  <a href="#returns_97" class="md-nav__link">
    Returns
  </a>
  
</li>
      
        <li class="md-nav__item">
  <a href="#parameters_118" class="md-nav__link">
    Parameters
  </a>
  
</li>
      
        <li class="md-nav__item">
  <a href="#parameters_119" class="md-nav__link">
    Parameters
  </a>
  
</li>
      
        <li class="md-nav__item">
  <a href="#returns_98" class="md-nav__link">
    Returns
  </a>
  
</li>
      
        <li class="md-nav__item">
  <a href="#parameters_120" class="md-nav__link">
    Parameters
  </a>
  
</li>
      
        <li class="md-nav__item">
  <a href="#attributes_13" class="md-nav__link">
    Attributes
  </a>
  
</li>
      
        <li class="md-nav__item">
  <a href="#references_13" class="md-nav__link">
    References
  </a>
  
</li>
      
        <li class="md-nav__item">
  <a href="#examples_9" class="md-nav__link">
    Examples
  </a>
  
</li>
      
        <li class="md-nav__item">
  <a href="#parameters_121" class="md-nav__link">
    Parameters
  </a>
  
</li>
      
        <li class="md-nav__item">
  <a href="#returns_99" class="md-nav__link">
    Returns
  </a>
  
</li>
      
        <li class="md-nav__item">
  <a href="#parameters_122" class="md-nav__link">
    Parameters
  </a>
  
</li>
      
        <li class="md-nav__item">
  <a href="#returns_100" class="md-nav__link">
    Returns
  </a>
  
</li>
      
        <li class="md-nav__item">
  <a href="#parameters_123" class="md-nav__link">
    Parameters
  </a>
  
</li>
      
        <li class="md-nav__item">
  <a href="#parameters_124" class="md-nav__link">
    Parameters
  </a>
  
</li>
      
        <li class="md-nav__item">
  <a href="#returns_101" class="md-nav__link">
    Returns
  </a>
  
</li>
      
        <li class="md-nav__item">
  <a href="#parameters_125" class="md-nav__link">
    Parameters
  </a>
  
</li>
      
        <li class="md-nav__item">
  <a href="#returns_102" class="md-nav__link">
    Returns
  </a>
  
</li>
      
        <li class="md-nav__item">
  <a href="#notes_13" class="md-nav__link">
    Notes
  </a>
  
</li>
      
        <li class="md-nav__item">
  <a href="#parameters_126" class="md-nav__link">
    Parameters
  </a>
  
</li>
      
        <li class="md-nav__item">
  <a href="#parameters_127" class="md-nav__link">
    Parameters
  </a>
  
</li>
      
        <li class="md-nav__item">
  <a href="#returns_103" class="md-nav__link">
    Returns
  </a>
  
</li>
      
        <li class="md-nav__item">
  <a href="#parameters_128" class="md-nav__link">
    Parameters
  </a>
  
</li>
      
        <li class="md-nav__item">
  <a href="#attributes_14" class="md-nav__link">
    Attributes
  </a>
  
</li>
      
        <li class="md-nav__item">
  <a href="#see-also_9" class="md-nav__link">
    See Also
  </a>
  
</li>
      
        <li class="md-nav__item">
  <a href="#examples_10" class="md-nav__link">
    Examples
  </a>
  
</li>
      
        <li class="md-nav__item">
  <a href="#parameters_129" class="md-nav__link">
    Parameters
  </a>
  
</li>
      
        <li class="md-nav__item">
  <a href="#returns_104" class="md-nav__link">
    Returns
  </a>
  
</li>
      
        <li class="md-nav__item">
  <a href="#parameters_130" class="md-nav__link">
    Parameters
  </a>
  
</li>
      
        <li class="md-nav__item">
  <a href="#returns_105" class="md-nav__link">
    Returns
  </a>
  
</li>
      
        <li class="md-nav__item">
  <a href="#parameters_131" class="md-nav__link">
    Parameters
  </a>
  
</li>
      
        <li class="md-nav__item">
  <a href="#parameters_132" class="md-nav__link">
    Parameters
  </a>
  
</li>
      
        <li class="md-nav__item">
  <a href="#returns_106" class="md-nav__link">
    Returns
  </a>
  
</li>
      
        <li class="md-nav__item">
  <a href="#parameters_133" class="md-nav__link">
    Parameters
  </a>
  
</li>
      
        <li class="md-nav__item">
  <a href="#returns_107" class="md-nav__link">
    Returns
  </a>
  
</li>
      
        <li class="md-nav__item">
  <a href="#parameters_134" class="md-nav__link">
    Parameters
  </a>
  
</li>
      
        <li class="md-nav__item">
  <a href="#parameters_135" class="md-nav__link">
    Parameters
  </a>
  
</li>
      
        <li class="md-nav__item">
  <a href="#returns_108" class="md-nav__link">
    Returns
  </a>
  
</li>
      
        <li class="md-nav__item">
  <a href="#parameters_136" class="md-nav__link">
    Parameters
  </a>
  
</li>
      
        <li class="md-nav__item">
  <a href="#attributes_15" class="md-nav__link">
    Attributes
  </a>
  
</li>
      
        <li class="md-nav__item">
  <a href="#see-also_10" class="md-nav__link">
    See Also
  </a>
  
</li>
      
        <li class="md-nav__item">
  <a href="#examples_11" class="md-nav__link">
    Examples
  </a>
  
</li>
      
        <li class="md-nav__item">
  <a href="#parameters_137" class="md-nav__link">
    Parameters
  </a>
  
</li>
      
        <li class="md-nav__item">
  <a href="#returns_109" class="md-nav__link">
    Returns
  </a>
  
</li>
      
        <li class="md-nav__item">
  <a href="#parameters_138" class="md-nav__link">
    Parameters
  </a>
  
</li>
      
        <li class="md-nav__item">
  <a href="#returns_110" class="md-nav__link">
    Returns
  </a>
  
</li>
      
        <li class="md-nav__item">
  <a href="#parameters_139" class="md-nav__link">
    Parameters
  </a>
  
</li>
      
        <li class="md-nav__item">
  <a href="#parameters_140" class="md-nav__link">
    Parameters
  </a>
  
</li>
      
        <li class="md-nav__item">
  <a href="#returns_111" class="md-nav__link">
    Returns
  </a>
  
</li>
      
        <li class="md-nav__item">
  <a href="#parameters_141" class="md-nav__link">
    Parameters
  </a>
  
</li>
      
        <li class="md-nav__item">
  <a href="#returns_112" class="md-nav__link">
    Returns
  </a>
  
</li>
      
        <li class="md-nav__item">
  <a href="#notes_14" class="md-nav__link">
    Notes
  </a>
  
</li>
      
        <li class="md-nav__item">
  <a href="#parameters_142" class="md-nav__link">
    Parameters
  </a>
  
</li>
      
        <li class="md-nav__item">
  <a href="#parameters_143" class="md-nav__link">
    Parameters
  </a>
  
</li>
      
        <li class="md-nav__item">
  <a href="#returns_113" class="md-nav__link">
    Returns
  </a>
  
</li>
      
        <li class="md-nav__item">
  <a href="#parameters_144" class="md-nav__link">
    Parameters
  </a>
  
</li>
      
        <li class="md-nav__item">
  <a href="#returns_114" class="md-nav__link">
    Returns
  </a>
  
</li>
      
        <li class="md-nav__item">
  <a href="#parameters_145" class="md-nav__link">
    Parameters
  </a>
  
</li>
      
        <li class="md-nav__item">
  <a href="#returns_115" class="md-nav__link">
    Returns
  </a>
  
</li>
      
        <li class="md-nav__item">
  <a href="#parameters_146" class="md-nav__link">
    Parameters
  </a>
  
</li>
      
        <li class="md-nav__item">
  <a href="#returns_116" class="md-nav__link">
    Returns
  </a>
  
</li>
      
        <li class="md-nav__item">
  <a href="#parameters_147" class="md-nav__link">
    Parameters
  </a>
  
</li>
      
        <li class="md-nav__item">
  <a href="#returns_117" class="md-nav__link">
    Returns
  </a>
  
</li>
      
        <li class="md-nav__item">
  <a href="#parameters_148" class="md-nav__link">
    Parameters
  </a>
  
</li>
      
        <li class="md-nav__item">
  <a href="#returns_118" class="md-nav__link">
    Returns
  </a>
  
</li>
      
        <li class="md-nav__item">
  <a href="#parameters_149" class="md-nav__link">
    Parameters
  </a>
  
</li>
      
        <li class="md-nav__item">
  <a href="#returns_119" class="md-nav__link">
    Returns
  </a>
  
</li>
      
        <li class="md-nav__item">
  <a href="#examples_12" class="md-nav__link">
    Examples
  </a>
  
</li>
      
        <li class="md-nav__item">
  <a href="#parameters_150" class="md-nav__link">
    Parameters
  </a>
  
</li>
      
        <li class="md-nav__item">
  <a href="#returns_120" class="md-nav__link">
    Returns
  </a>
  
</li>
      
        <li class="md-nav__item">
  <a href="#parameters_151" class="md-nav__link">
    Parameters
  </a>
  
</li>
      
        <li class="md-nav__item">
  <a href="#returns_121" class="md-nav__link">
    Returns
  </a>
  
</li>
      
        <li class="md-nav__item">
  <a href="#raises_2" class="md-nav__link">
    Raises
  </a>
  
</li>
      
        <li class="md-nav__item">
  <a href="#parameters_152" class="md-nav__link">
    Parameters
  </a>
  
</li>
      
        <li class="md-nav__item">
  <a href="#returns_122" class="md-nav__link">
    Returns
  </a>
  
</li>
      
        <li class="md-nav__item">
  <a href="#notes_15" class="md-nav__link">
    Notes
  </a>
  
</li>
      
        <li class="md-nav__item">
  <a href="#references_14" class="md-nav__link">
    References
  </a>
  
</li>
      
        <li class="md-nav__item">
  <a href="#examples_13" class="md-nav__link">
    Examples
  </a>
  
</li>
      
        <li class="md-nav__item">
  <a href="#parameters_153" class="md-nav__link">
    Parameters
  </a>
  
</li>
      
        <li class="md-nav__item">
  <a href="#returns_123" class="md-nav__link">
    Returns
  </a>
  
</li>
      
        <li class="md-nav__item">
  <a href="#examples_14" class="md-nav__link">
    Examples
  </a>
  
</li>
      
        <li class="md-nav__item">
  <a href="#parameters_154" class="md-nav__link">
    Parameters
  </a>
  
</li>
      
        <li class="md-nav__item">
  <a href="#returns_124" class="md-nav__link">
    Returns
  </a>
  
</li>
      
        <li class="md-nav__item">
  <a href="#examples_15" class="md-nav__link">
    Examples
  </a>
  
</li>
      
    </ul>
  
</nav>
                  </div>
                </div>
              </div>
            
          
          <div class="md-content">
            <article class="md-content__inner md-typeset">
              
                
                  <a href="https://github.com/lehy/ocaml-sklearn/edit/master/docs/sklearn/Ensemble.md" title="Edit this page" class="md-content__button md-icon">
                    <svg xmlns="http://www.w3.org/2000/svg" viewBox="0 0 24 24"><path d="M20.71 7.04c.39-.39.39-1.04 0-1.41l-2.34-2.34c-.37-.39-1.02-.39-1.41 0l-1.84 1.83 3.75 3.75M3 17.25V21h3.75L17.81 9.93l-3.75-3.75L3 17.25z"/></svg>
                  </a>
                
                
                  
                
                
                  <h1>Ensemble</h1>
                
                <p>Get an attribute of this module as a Py.Object.t.
This is useful to pass a Python function to another function.</p>
<div class="highlight"><pre><span></span><code><span class="k">val</span> <span class="n">get_py</span> <span class="o">:</span> <span class="kt">string</span> <span class="o">-&gt;</span> <span class="nn">Py</span><span class="p">.</span><span class="nn">Object</span><span class="p">.</span><span class="n">t</span>

<span class="k">module</span> <span class="nc">AdaBoostClassifier</span> <span class="o">:</span> <span class="k">sig</span>
<span class="k">type</span> <span class="n">tag</span> <span class="o">=</span> <span class="o">[`</span><span class="nc">AdaBoostClassifier</span><span class="o">]</span>
<span class="k">type</span> <span class="n">t</span> <span class="o">=</span> <span class="o">[`</span><span class="nc">AdaBoostClassifier</span> <span class="o">|</span> <span class="o">`</span><span class="nc">BaseEnsemble</span> <span class="o">|</span> <span class="o">`</span><span class="nc">BaseEstimator</span> <span class="o">|</span> <span class="o">`</span><span class="nc">BaseWeightBoosting</span> <span class="o">|</span> <span class="o">`</span><span class="nc">ClassifierMixin</span> <span class="o">|</span> <span class="o">`</span><span class="nc">MetaEstimatorMixin</span> <span class="o">|</span> <span class="o">`</span><span class="nc">Object</span><span class="o">]</span> <span class="nn">Obj</span><span class="p">.</span><span class="n">t</span>
<span class="k">val</span> <span class="n">of_pyobject</span> <span class="o">:</span> <span class="nn">Py</span><span class="p">.</span><span class="nn">Object</span><span class="p">.</span><span class="n">t</span> <span class="o">-&gt;</span> <span class="n">t</span>
<span class="k">val</span> <span class="n">to_pyobject</span> <span class="o">:</span> <span class="o">[&gt;</span> <span class="n">tag</span><span class="o">]</span> <span class="nn">Obj</span><span class="p">.</span><span class="n">t</span> <span class="o">-&gt;</span> <span class="nn">Py</span><span class="p">.</span><span class="nn">Object</span><span class="p">.</span><span class="n">t</span>

<span class="k">val</span> <span class="n">as_classifier</span> <span class="o">:</span> <span class="n">t</span> <span class="o">-&gt;</span> <span class="o">[`</span><span class="nc">ClassifierMixin</span><span class="o">]</span> <span class="nn">Obj</span><span class="p">.</span><span class="n">t</span>
<span class="k">val</span> <span class="n">as_meta_estimator</span> <span class="o">:</span> <span class="n">t</span> <span class="o">-&gt;</span> <span class="o">[`</span><span class="nc">MetaEstimatorMixin</span><span class="o">]</span> <span class="nn">Obj</span><span class="p">.</span><span class="n">t</span>
<span class="k">val</span> <span class="n">as_weight_boosting</span> <span class="o">:</span> <span class="n">t</span> <span class="o">-&gt;</span> <span class="o">[`</span><span class="nc">BaseWeightBoosting</span><span class="o">]</span> <span class="nn">Obj</span><span class="p">.</span><span class="n">t</span>
<span class="k">val</span> <span class="n">as_estimator</span> <span class="o">:</span> <span class="n">t</span> <span class="o">-&gt;</span> <span class="o">[`</span><span class="nc">BaseEstimator</span><span class="o">]</span> <span class="nn">Obj</span><span class="p">.</span><span class="n">t</span>
<span class="k">val</span> <span class="n">as_ensemble</span> <span class="o">:</span> <span class="n">t</span> <span class="o">-&gt;</span> <span class="o">[`</span><span class="nc">BaseEnsemble</span><span class="o">]</span> <span class="nn">Obj</span><span class="p">.</span><span class="n">t</span>
<span class="k">val</span> <span class="n">create</span> <span class="o">:</span> <span class="o">?</span><span class="n">base_estimator</span><span class="o">:[&gt;`</span><span class="nc">BaseEstimator</span><span class="o">]</span> <span class="nn">Np</span><span class="p">.</span><span class="nn">Obj</span><span class="p">.</span><span class="n">t</span> <span class="o">-&gt;</span> <span class="o">?</span><span class="n">n_estimators</span><span class="o">:</span><span class="kt">int</span> <span class="o">-&gt;</span> <span class="o">?</span><span class="n">learning_rate</span><span class="o">:</span><span class="kt">float</span> <span class="o">-&gt;</span> <span class="o">?</span><span class="n">algorithm</span><span class="o">:[`</span><span class="nc">SAMME</span> <span class="o">|</span> <span class="o">`</span><span class="nc">SAMME_R</span><span class="o">]</span> <span class="o">-&gt;</span> <span class="o">?</span><span class="n">random_state</span><span class="o">:</span><span class="kt">int</span> <span class="o">-&gt;</span> <span class="kt">unit</span> <span class="o">-&gt;</span> <span class="n">t</span>
</code></pre></div>

<p>An AdaBoost classifier.</p>
<p>An AdaBoost [1] classifier is a meta-estimator that begins by fitting a
classifier on the original dataset and then fits additional copies of the
classifier on the same dataset but where the weights of incorrectly
classified instances are adjusted such that subsequent classifiers focus
more on difficult cases.</p>
<p>This class implements the algorithm known as AdaBoost-SAMME [2].</p>
<p>Read more in the :ref:<code>User Guide &lt;adaboost&gt;</code>.</p>
<p>.. versionadded:: 0.14</p>
<h2 id="parameters">Parameters<a class="headerlink" href="#parameters" title="Permanent link">&para;</a></h2>
<p>base_estimator : object, optional (default=None)
The base estimator from which the boosted ensemble is built.
Support for sample weighting is required, as well as proper
<code>classes_</code> and <code>n_classes_</code> attributes. If <code>None</code>, then
the base estimator is <code>DecisionTreeClassifier(max_depth=1)</code>.</p>
<p>n_estimators : int, optional (default=50)
The maximum number of estimators at which boosting is terminated.
In case of perfect fit, the learning procedure is stopped early.</p>
<p>learning_rate : float, optional (default=1.)
Learning rate shrinks the contribution of each classifier by
<code>learning_rate</code>. There is a trade-off between <code>learning_rate</code> and
<code>n_estimators</code>.</p>
<p>algorithm : {'SAMME', 'SAMME.R'}, optional (default='SAMME.R')
If 'SAMME.R' then use the SAMME.R real boosting algorithm.
<code>base_estimator</code> must support calculation of class probabilities.
If 'SAMME' then use the SAMME discrete boosting algorithm.
The SAMME.R algorithm typically converges faster than SAMME,
achieving a lower test error with fewer boosting iterations.</p>
<p>random_state : int, RandomState instance or None, optional (default=None)
If int, random_state is the seed used by the random number generator;
If RandomState instance, random_state is the random number generator;
If None, the random number generator is the RandomState instance used
by <code>np.random</code>.</p>
<h2 id="attributes">Attributes<a class="headerlink" href="#attributes" title="Permanent link">&para;</a></h2>
<p>base_estimator_ : estimator
The base estimator from which the ensemble is grown.</p>
<p>estimators_ : list of classifiers
The collection of fitted sub-estimators.</p>
<p>classes_ : array of shape (n_classes,)
The classes labels.</p>
<p>n_classes_ : int
The number of classes.</p>
<p>estimator_weights_ : array of floats
Weights for each estimator in the boosted ensemble.</p>
<p>estimator_errors_ : array of floats
Classification error for each estimator in the boosted
ensemble.</p>
<p>feature_importances_ : ndarray of shape (n_features,)
The feature importances if supported by the <code>base_estimator</code>.</p>
<h2 id="see-also">See Also<a class="headerlink" href="#see-also" title="Permanent link">&para;</a></h2>
<p>AdaBoostRegressor
An AdaBoost regressor that begins by fitting a regressor on the
original dataset and then fits additional copies of the regressor
on the same dataset but where the weights of instances are
adjusted according to the error of the current prediction.</p>
<p>GradientBoostingClassifier
GB builds an additive model in a forward stage-wise fashion. Regression
trees are fit on the negative gradient of the binomial or multinomial
deviance loss function. Binary classification is a special case where
only a single regression tree is induced.</p>
<p>sklearn.tree.DecisionTreeClassifier
A non-parametric supervised learning method used for classification.
Creates a model that predicts the value of a target variable by
learning simple decision rules inferred from the data features.</p>
<h2 id="references">References<a class="headerlink" href="#references" title="Permanent link">&para;</a></h2>
<p>.. [1] Y. Freund, R. Schapire, 'A Decision-Theoretic Generalization of
on-Line Learning and an Application to Boosting', 1995.</p>
<p>.. [2] J. Zhu, H. Zou, S. Rosset, T. Hastie, 'Multi-class AdaBoost', 2009.</p>
<h2 id="examples">Examples<a class="headerlink" href="#examples" title="Permanent link">&para;</a></h2>
<blockquote>
<blockquote>
<blockquote>
<p>from sklearn.ensemble import AdaBoostClassifier
from sklearn.datasets import make_classification
X, y = make_classification(n_samples=1000, n_features=4,
...                            n_informative=2, n_redundant=0,
...                            random_state=0, shuffle=False)
clf = AdaBoostClassifier(n_estimators=100, random_state=0)
clf.fit(X, y)
AdaBoostClassifier(n_estimators=100, random_state=0)
clf.feature_importances_
array([0.28..., 0.42..., 0.14..., 0.16...])
clf.predict([[0, 0, 0, 0]])
array([1])
clf.score(X, y)
0.983...</p>
</blockquote>
</blockquote>
</blockquote>
<div class="highlight"><pre><span></span><code><span class="k">val</span> <span class="n">get_item</span> <span class="o">:</span> <span class="n">index</span><span class="o">:</span><span class="nn">Py</span><span class="p">.</span><span class="nn">Object</span><span class="p">.</span><span class="n">t</span> <span class="o">-&gt;</span> <span class="o">[&gt;</span> <span class="n">tag</span><span class="o">]</span> <span class="nn">Obj</span><span class="p">.</span><span class="n">t</span> <span class="o">-&gt;</span> <span class="nn">Py</span><span class="p">.</span><span class="nn">Object</span><span class="p">.</span><span class="n">t</span>
</code></pre></div>

<p>Return the index'th estimator in the ensemble.</p>
<div class="highlight"><pre><span></span><code><span class="k">val</span> <span class="n">iter</span> <span class="o">:</span> <span class="o">[&gt;</span> <span class="n">tag</span><span class="o">]</span> <span class="nn">Obj</span><span class="p">.</span><span class="n">t</span> <span class="o">-&gt;</span> <span class="nn">Dict</span><span class="p">.</span><span class="n">t</span> <span class="nn">Seq</span><span class="p">.</span><span class="n">t</span>
</code></pre></div>

<p>Return iterator over estimators in the ensemble.</p>
<div class="highlight"><pre><span></span><code><span class="k">val</span> <span class="n">decision_function</span> <span class="o">:</span> <span class="n">x</span><span class="o">:[&gt;`</span><span class="nc">ArrayLike</span><span class="o">]</span> <span class="nn">Np</span><span class="p">.</span><span class="nn">Obj</span><span class="p">.</span><span class="n">t</span> <span class="o">-&gt;</span> <span class="o">[&gt;</span> <span class="n">tag</span><span class="o">]</span> <span class="nn">Obj</span><span class="p">.</span><span class="n">t</span> <span class="o">-&gt;</span> <span class="o">[&gt;`</span><span class="nc">ArrayLike</span><span class="o">]</span> <span class="nn">Np</span><span class="p">.</span><span class="nn">Obj</span><span class="p">.</span><span class="n">t</span>
</code></pre></div>

<p>Compute the decision function of <code>X</code>.</p>
<h2 id="parameters_1">Parameters<a class="headerlink" href="#parameters_1" title="Permanent link">&para;</a></h2>
<p>X : {array-like, sparse matrix} of shape (n_samples, n_features)
The training input samples. Sparse matrix can be CSC, CSR, COO,
DOK, or LIL. COO, DOK, and LIL are converted to CSR.</p>
<h2 id="returns">Returns<a class="headerlink" href="#returns" title="Permanent link">&para;</a></h2>
<p>score : array, shape = [n_samples, k]
The decision function of the input samples. The order of
outputs is the same of that of the :term:<code>classes_</code> attribute.
Binary classification is a special cases with <code>k == 1</code>,
otherwise <code>k==n_classes</code>. For binary classification,
values closer to -1 or 1 mean more like the first or second
class in <code>classes_</code>, respectively.</p>
<div class="highlight"><pre><span></span><code><span class="k">val</span> <span class="n">fit</span> <span class="o">:</span> <span class="o">?</span><span class="n">sample_weight</span><span class="o">:[&gt;`</span><span class="nc">ArrayLike</span><span class="o">]</span> <span class="nn">Np</span><span class="p">.</span><span class="nn">Obj</span><span class="p">.</span><span class="n">t</span> <span class="o">-&gt;</span> <span class="n">x</span><span class="o">:[&gt;`</span><span class="nc">ArrayLike</span><span class="o">]</span> <span class="nn">Np</span><span class="p">.</span><span class="nn">Obj</span><span class="p">.</span><span class="n">t</span> <span class="o">-&gt;</span> <span class="n">y</span><span class="o">:[&gt;`</span><span class="nc">ArrayLike</span><span class="o">]</span> <span class="nn">Np</span><span class="p">.</span><span class="nn">Obj</span><span class="p">.</span><span class="n">t</span> <span class="o">-&gt;</span> <span class="o">[&gt;</span> <span class="n">tag</span><span class="o">]</span> <span class="nn">Obj</span><span class="p">.</span><span class="n">t</span> <span class="o">-&gt;</span> <span class="n">t</span>
</code></pre></div>

<p>Build a boosted classifier from the training set (X, y).</p>
<h2 id="parameters_2">Parameters<a class="headerlink" href="#parameters_2" title="Permanent link">&para;</a></h2>
<p>X : {array-like, sparse matrix} of shape (n_samples, n_features)
The training input samples. Sparse matrix can be CSC, CSR, COO,
DOK, or LIL. COO, DOK, and LIL are converted to CSR.</p>
<p>y : array-like of shape (n_samples,)
The target values (class labels).</p>
<p>sample_weight : array-like of shape (n_samples,), default=None
Sample weights. If None, the sample weights are initialized to
<code>1 / n_samples</code>.</p>
<h2 id="returns_1">Returns<a class="headerlink" href="#returns_1" title="Permanent link">&para;</a></h2>
<p>self : object
Fitted estimator.</p>
<div class="highlight"><pre><span></span><code><span class="k">val</span> <span class="n">get_params</span> <span class="o">:</span> <span class="o">?</span><span class="n">deep</span><span class="o">:</span><span class="kt">bool</span> <span class="o">-&gt;</span> <span class="o">[&gt;</span> <span class="n">tag</span><span class="o">]</span> <span class="nn">Obj</span><span class="p">.</span><span class="n">t</span> <span class="o">-&gt;</span> <span class="nn">Dict</span><span class="p">.</span><span class="n">t</span>
</code></pre></div>

<p>Get parameters for this estimator.</p>
<h2 id="parameters_3">Parameters<a class="headerlink" href="#parameters_3" title="Permanent link">&para;</a></h2>
<p>deep : bool, default=True
If True, will return the parameters for this estimator and
contained subobjects that are estimators.</p>
<h2 id="returns_2">Returns<a class="headerlink" href="#returns_2" title="Permanent link">&para;</a></h2>
<p>params : mapping of string to any
Parameter names mapped to their values.</p>
<div class="highlight"><pre><span></span><code><span class="k">val</span> <span class="n">predict</span> <span class="o">:</span> <span class="n">x</span><span class="o">:[&gt;`</span><span class="nc">ArrayLike</span><span class="o">]</span> <span class="nn">Np</span><span class="p">.</span><span class="nn">Obj</span><span class="p">.</span><span class="n">t</span> <span class="o">-&gt;</span> <span class="o">[&gt;</span> <span class="n">tag</span><span class="o">]</span> <span class="nn">Obj</span><span class="p">.</span><span class="n">t</span> <span class="o">-&gt;</span> <span class="o">[&gt;`</span><span class="nc">ArrayLike</span><span class="o">]</span> <span class="nn">Np</span><span class="p">.</span><span class="nn">Obj</span><span class="p">.</span><span class="n">t</span>
</code></pre></div>

<p>Predict classes for X.</p>
<p>The predicted class of an input sample is computed as the weighted mean
prediction of the classifiers in the ensemble.</p>
<h2 id="parameters_4">Parameters<a class="headerlink" href="#parameters_4" title="Permanent link">&para;</a></h2>
<p>X : {array-like, sparse matrix} of shape (n_samples, n_features)
The training input samples. Sparse matrix can be CSC, CSR, COO,
DOK, or LIL. COO, DOK, and LIL are converted to CSR.</p>
<h2 id="returns_3">Returns<a class="headerlink" href="#returns_3" title="Permanent link">&para;</a></h2>
<p>y : ndarray of shape (n_samples,)
The predicted classes.</p>
<div class="highlight"><pre><span></span><code><span class="k">val</span> <span class="n">predict_log_proba</span> <span class="o">:</span> <span class="n">x</span><span class="o">:[&gt;`</span><span class="nc">ArrayLike</span><span class="o">]</span> <span class="nn">Np</span><span class="p">.</span><span class="nn">Obj</span><span class="p">.</span><span class="n">t</span> <span class="o">-&gt;</span> <span class="o">[&gt;</span> <span class="n">tag</span><span class="o">]</span> <span class="nn">Obj</span><span class="p">.</span><span class="n">t</span> <span class="o">-&gt;</span> <span class="o">[&gt;`</span><span class="nc">ArrayLike</span><span class="o">]</span> <span class="nn">Np</span><span class="p">.</span><span class="nn">Obj</span><span class="p">.</span><span class="n">t</span>
</code></pre></div>

<p>Predict class log-probabilities for X.</p>
<p>The predicted class log-probabilities of an input sample is computed as
the weighted mean predicted class log-probabilities of the classifiers
in the ensemble.</p>
<h2 id="parameters_5">Parameters<a class="headerlink" href="#parameters_5" title="Permanent link">&para;</a></h2>
<p>X : {array-like, sparse matrix} of shape (n_samples, n_features)
The training input samples. Sparse matrix can be CSC, CSR, COO,
DOK, or LIL. COO, DOK, and LIL are converted to CSR.</p>
<h2 id="returns_4">Returns<a class="headerlink" href="#returns_4" title="Permanent link">&para;</a></h2>
<p>p : array of shape (n_samples, n_classes)
The class probabilities of the input samples. The order of
outputs is the same of that of the :term:<code>classes_</code> attribute.</p>
<div class="highlight"><pre><span></span><code><span class="k">val</span> <span class="n">predict_proba</span> <span class="o">:</span> <span class="n">x</span><span class="o">:[&gt;`</span><span class="nc">ArrayLike</span><span class="o">]</span> <span class="nn">Np</span><span class="p">.</span><span class="nn">Obj</span><span class="p">.</span><span class="n">t</span> <span class="o">-&gt;</span> <span class="o">[&gt;</span> <span class="n">tag</span><span class="o">]</span> <span class="nn">Obj</span><span class="p">.</span><span class="n">t</span> <span class="o">-&gt;</span> <span class="o">[&gt;`</span><span class="nc">ArrayLike</span><span class="o">]</span> <span class="nn">Np</span><span class="p">.</span><span class="nn">Obj</span><span class="p">.</span><span class="n">t</span>
</code></pre></div>

<p>Predict class probabilities for X.</p>
<p>The predicted class probabilities of an input sample is computed as
the weighted mean predicted class probabilities of the classifiers
in the ensemble.</p>
<h2 id="parameters_6">Parameters<a class="headerlink" href="#parameters_6" title="Permanent link">&para;</a></h2>
<p>X : {array-like, sparse matrix} of shape (n_samples, n_features)
The training input samples. Sparse matrix can be CSC, CSR, COO,
DOK, or LIL. COO, DOK, and LIL are converted to CSR.</p>
<h2 id="returns_5">Returns<a class="headerlink" href="#returns_5" title="Permanent link">&para;</a></h2>
<p>p : array of shape (n_samples, n_classes)
The class probabilities of the input samples. The order of
outputs is the same of that of the :term:<code>classes_</code> attribute.</p>
<div class="highlight"><pre><span></span><code><span class="k">val</span> <span class="n">score</span> <span class="o">:</span> <span class="o">?</span><span class="n">sample_weight</span><span class="o">:[&gt;`</span><span class="nc">ArrayLike</span><span class="o">]</span> <span class="nn">Np</span><span class="p">.</span><span class="nn">Obj</span><span class="p">.</span><span class="n">t</span> <span class="o">-&gt;</span> <span class="n">x</span><span class="o">:[&gt;`</span><span class="nc">ArrayLike</span><span class="o">]</span> <span class="nn">Np</span><span class="p">.</span><span class="nn">Obj</span><span class="p">.</span><span class="n">t</span> <span class="o">-&gt;</span> <span class="n">y</span><span class="o">:[&gt;`</span><span class="nc">ArrayLike</span><span class="o">]</span> <span class="nn">Np</span><span class="p">.</span><span class="nn">Obj</span><span class="p">.</span><span class="n">t</span> <span class="o">-&gt;</span> <span class="o">[&gt;</span> <span class="n">tag</span><span class="o">]</span> <span class="nn">Obj</span><span class="p">.</span><span class="n">t</span> <span class="o">-&gt;</span> <span class="kt">float</span>
</code></pre></div>

<p>Return the mean accuracy on the given test data and labels.</p>
<p>In multi-label classification, this is the subset accuracy
which is a harsh metric since you require for each sample that
each label set be correctly predicted.</p>
<h2 id="parameters_7">Parameters<a class="headerlink" href="#parameters_7" title="Permanent link">&para;</a></h2>
<p>X : array-like of shape (n_samples, n_features)
Test samples.</p>
<p>y : array-like of shape (n_samples,) or (n_samples, n_outputs)
True labels for X.</p>
<p>sample_weight : array-like of shape (n_samples,), default=None
Sample weights.</p>
<h2 id="returns_6">Returns<a class="headerlink" href="#returns_6" title="Permanent link">&para;</a></h2>
<p>score : float
Mean accuracy of self.predict(X) wrt. y.</p>
<div class="highlight"><pre><span></span><code><span class="k">val</span> <span class="n">set_params</span> <span class="o">:</span> <span class="o">?</span><span class="n">params</span><span class="o">:(</span><span class="kt">string</span> <span class="o">*</span> <span class="nn">Py</span><span class="p">.</span><span class="nn">Object</span><span class="p">.</span><span class="n">t</span><span class="o">)</span> <span class="kt">list</span> <span class="o">-&gt;</span> <span class="o">[&gt;</span> <span class="n">tag</span><span class="o">]</span> <span class="nn">Obj</span><span class="p">.</span><span class="n">t</span> <span class="o">-&gt;</span> <span class="n">t</span>
</code></pre></div>

<p>Set the parameters of this estimator.</p>
<p>The method works on simple estimators as well as on nested objects
(such as pipelines). The latter have parameters of the form
<code>&lt;component&gt;__&lt;parameter&gt;</code> so that it's possible to update each
component of a nested object.</p>
<h2 id="parameters_8">Parameters<a class="headerlink" href="#parameters_8" title="Permanent link">&para;</a></h2>
<p>**params : dict
Estimator parameters.</p>
<h2 id="returns_7">Returns<a class="headerlink" href="#returns_7" title="Permanent link">&para;</a></h2>
<p>self : object
Estimator instance.</p>
<div class="highlight"><pre><span></span><code><span class="k">val</span> <span class="n">staged_decision_function</span> <span class="o">:</span> <span class="n">x</span><span class="o">:[&gt;`</span><span class="nc">ArrayLike</span><span class="o">]</span> <span class="nn">Np</span><span class="p">.</span><span class="nn">Obj</span><span class="p">.</span><span class="n">t</span> <span class="o">-&gt;</span> <span class="o">[&gt;</span> <span class="n">tag</span><span class="o">]</span> <span class="nn">Obj</span><span class="p">.</span><span class="n">t</span> <span class="o">-&gt;</span> <span class="o">[&gt;`</span><span class="nc">ArrayLike</span><span class="o">]</span> <span class="nn">Np</span><span class="p">.</span><span class="nn">Obj</span><span class="p">.</span><span class="n">t</span> <span class="nn">Seq</span><span class="p">.</span><span class="n">t</span>
</code></pre></div>

<p>Compute decision function of <code>X</code> for each boosting iteration.</p>
<p>This method allows monitoring (i.e. determine error on testing set)
after each boosting iteration.</p>
<h2 id="parameters_9">Parameters<a class="headerlink" href="#parameters_9" title="Permanent link">&para;</a></h2>
<p>X : {array-like, sparse matrix} of shape (n_samples, n_features)
The training input samples. Sparse matrix can be CSC, CSR, COO,
DOK, or LIL. COO, DOK, and LIL are converted to CSR.</p>
<h2 id="yields">Yields<a class="headerlink" href="#yields" title="Permanent link">&para;</a></h2>
<p>score : generator of array, shape = [n_samples, k]
The decision function of the input samples. The order of
outputs is the same of that of the :term:<code>classes_</code> attribute.
Binary classification is a special cases with <code>k == 1</code>,
otherwise <code>k==n_classes</code>. For binary classification,
values closer to -1 or 1 mean more like the first or second
class in <code>classes_</code>, respectively.</p>
<div class="highlight"><pre><span></span><code><span class="k">val</span> <span class="n">staged_predict</span> <span class="o">:</span> <span class="n">x</span><span class="o">:[&gt;`</span><span class="nc">ArrayLike</span><span class="o">]</span> <span class="nn">Np</span><span class="p">.</span><span class="nn">Obj</span><span class="p">.</span><span class="n">t</span> <span class="o">-&gt;</span> <span class="o">[&gt;</span> <span class="n">tag</span><span class="o">]</span> <span class="nn">Obj</span><span class="p">.</span><span class="n">t</span> <span class="o">-&gt;</span> <span class="o">[&gt;`</span><span class="nc">ArrayLike</span><span class="o">]</span> <span class="nn">Np</span><span class="p">.</span><span class="nn">Obj</span><span class="p">.</span><span class="n">t</span> <span class="nn">Seq</span><span class="p">.</span><span class="n">t</span>
</code></pre></div>

<p>Return staged predictions for X.</p>
<p>The predicted class of an input sample is computed as the weighted mean
prediction of the classifiers in the ensemble.</p>
<p>This generator method yields the ensemble prediction after each
iteration of boosting and therefore allows monitoring, such as to
determine the prediction on a test set after each boost.</p>
<h2 id="parameters_10">Parameters<a class="headerlink" href="#parameters_10" title="Permanent link">&para;</a></h2>
<p>X : array-like of shape (n_samples, n_features)
The input samples. Sparse matrix can be CSC, CSR, COO,
DOK, or LIL. COO, DOK, and LIL are converted to CSR.</p>
<h2 id="yields_1">Yields<a class="headerlink" href="#yields_1" title="Permanent link">&para;</a></h2>
<p>y : generator of array, shape = [n_samples]
The predicted classes.</p>
<div class="highlight"><pre><span></span><code><span class="k">val</span> <span class="n">staged_predict_proba</span> <span class="o">:</span> <span class="n">x</span><span class="o">:[&gt;`</span><span class="nc">ArrayLike</span><span class="o">]</span> <span class="nn">Np</span><span class="p">.</span><span class="nn">Obj</span><span class="p">.</span><span class="n">t</span> <span class="o">-&gt;</span> <span class="o">[&gt;</span> <span class="n">tag</span><span class="o">]</span> <span class="nn">Obj</span><span class="p">.</span><span class="n">t</span> <span class="o">-&gt;</span> <span class="o">[&gt;`</span><span class="nc">ArrayLike</span><span class="o">]</span> <span class="nn">Np</span><span class="p">.</span><span class="nn">Obj</span><span class="p">.</span><span class="n">t</span> <span class="nn">Seq</span><span class="p">.</span><span class="n">t</span>
</code></pre></div>

<p>Predict class probabilities for X.</p>
<p>The predicted class probabilities of an input sample is computed as
the weighted mean predicted class probabilities of the classifiers
in the ensemble.</p>
<p>This generator method yields the ensemble predicted class probabilities
after each iteration of boosting and therefore allows monitoring, such
as to determine the predicted class probabilities on a test set after
each boost.</p>
<h2 id="parameters_11">Parameters<a class="headerlink" href="#parameters_11" title="Permanent link">&para;</a></h2>
<p>X : {array-like, sparse matrix} of shape (n_samples, n_features)
The training input samples. Sparse matrix can be CSC, CSR, COO,
DOK, or LIL. COO, DOK, and LIL are converted to CSR.</p>
<h2 id="yields_2">Yields<a class="headerlink" href="#yields_2" title="Permanent link">&para;</a></h2>
<p>p : generator of array, shape = [n_samples]
The class probabilities of the input samples. The order of
outputs is the same of that of the :term:<code>classes_</code> attribute.</p>
<div class="highlight"><pre><span></span><code><span class="k">val</span> <span class="n">staged_score</span> <span class="o">:</span> <span class="o">?</span><span class="n">sample_weight</span><span class="o">:[&gt;`</span><span class="nc">ArrayLike</span><span class="o">]</span> <span class="nn">Np</span><span class="p">.</span><span class="nn">Obj</span><span class="p">.</span><span class="n">t</span> <span class="o">-&gt;</span> <span class="n">x</span><span class="o">:[&gt;`</span><span class="nc">ArrayLike</span><span class="o">]</span> <span class="nn">Np</span><span class="p">.</span><span class="nn">Obj</span><span class="p">.</span><span class="n">t</span> <span class="o">-&gt;</span> <span class="n">y</span><span class="o">:[&gt;`</span><span class="nc">ArrayLike</span><span class="o">]</span> <span class="nn">Np</span><span class="p">.</span><span class="nn">Obj</span><span class="p">.</span><span class="n">t</span> <span class="o">-&gt;</span> <span class="o">[&gt;</span> <span class="n">tag</span><span class="o">]</span> <span class="nn">Obj</span><span class="p">.</span><span class="n">t</span> <span class="o">-&gt;</span> <span class="nn">Py</span><span class="p">.</span><span class="nn">Object</span><span class="p">.</span><span class="n">t</span>
</code></pre></div>

<p>Return staged scores for X, y.</p>
<p>This generator method yields the ensemble score after each iteration of
boosting and therefore allows monitoring, such as to determine the
score on a test set after each boost.</p>
<h2 id="parameters_12">Parameters<a class="headerlink" href="#parameters_12" title="Permanent link">&para;</a></h2>
<p>X : {array-like, sparse matrix} of shape (n_samples, n_features)
The training input samples. Sparse matrix can be CSC, CSR, COO,
DOK, or LIL. COO, DOK, and LIL are converted to CSR.</p>
<p>y : array-like of shape (n_samples,)
Labels for X.</p>
<p>sample_weight : array-like of shape (n_samples,), default=None
Sample weights.</p>
<h2 id="yields_3">Yields<a class="headerlink" href="#yields_3" title="Permanent link">&para;</a></h2>
<p>z : float</p>
<p>Attribute base_estimator_: get value or raise Not_found if None.</p>
<div class="highlight"><pre><span></span><code><span class="k">val</span> <span class="n">base_estimator_</span> <span class="o">:</span> <span class="n">t</span> <span class="o">-&gt;</span> <span class="o">[`</span><span class="nc">BaseEstimator</span><span class="o">|`</span><span class="nc">Object</span><span class="o">]</span> <span class="nn">Np</span><span class="p">.</span><span class="nn">Obj</span><span class="p">.</span><span class="n">t</span>
</code></pre></div>

<p>Attribute base_estimator_: get value as an option.</p>
<div class="highlight"><pre><span></span><code><span class="k">val</span> <span class="n">base_estimator_opt</span> <span class="o">:</span> <span class="n">t</span> <span class="o">-&gt;</span> <span class="o">([`</span><span class="nc">BaseEstimator</span><span class="o">|`</span><span class="nc">Object</span><span class="o">]</span> <span class="nn">Np</span><span class="p">.</span><span class="nn">Obj</span><span class="p">.</span><span class="n">t</span><span class="o">)</span> <span class="n">option</span>
</code></pre></div>

<p>Attribute estimators_: get value or raise Not_found if None.</p>
<div class="highlight"><pre><span></span><code><span class="k">val</span> <span class="n">estimators_</span> <span class="o">:</span> <span class="n">t</span> <span class="o">-&gt;</span> <span class="nn">Py</span><span class="p">.</span><span class="nn">Object</span><span class="p">.</span><span class="n">t</span>
</code></pre></div>

<p>Attribute estimators_: get value as an option.</p>
<div class="highlight"><pre><span></span><code><span class="k">val</span> <span class="n">estimators_opt</span> <span class="o">:</span> <span class="n">t</span> <span class="o">-&gt;</span> <span class="o">(</span><span class="nn">Py</span><span class="p">.</span><span class="nn">Object</span><span class="p">.</span><span class="n">t</span><span class="o">)</span> <span class="n">option</span>
</code></pre></div>

<p>Attribute classes_: get value or raise Not_found if None.</p>
<div class="highlight"><pre><span></span><code><span class="k">val</span> <span class="n">classes_</span> <span class="o">:</span> <span class="n">t</span> <span class="o">-&gt;</span> <span class="o">[&gt;`</span><span class="nc">ArrayLike</span><span class="o">]</span> <span class="nn">Np</span><span class="p">.</span><span class="nn">Obj</span><span class="p">.</span><span class="n">t</span>
</code></pre></div>

<p>Attribute classes_: get value as an option.</p>
<div class="highlight"><pre><span></span><code><span class="k">val</span> <span class="n">classes_opt</span> <span class="o">:</span> <span class="n">t</span> <span class="o">-&gt;</span> <span class="o">([&gt;`</span><span class="nc">ArrayLike</span><span class="o">]</span> <span class="nn">Np</span><span class="p">.</span><span class="nn">Obj</span><span class="p">.</span><span class="n">t</span><span class="o">)</span> <span class="n">option</span>
</code></pre></div>

<p>Attribute n_classes_: get value or raise Not_found if None.</p>
<div class="highlight"><pre><span></span><code><span class="k">val</span> <span class="n">n_classes_</span> <span class="o">:</span> <span class="n">t</span> <span class="o">-&gt;</span> <span class="kt">int</span>
</code></pre></div>

<p>Attribute n_classes_: get value as an option.</p>
<div class="highlight"><pre><span></span><code><span class="k">val</span> <span class="n">n_classes_opt</span> <span class="o">:</span> <span class="n">t</span> <span class="o">-&gt;</span> <span class="o">(</span><span class="kt">int</span><span class="o">)</span> <span class="n">option</span>
</code></pre></div>

<p>Attribute estimator_weights_: get value or raise Not_found if None.</p>
<div class="highlight"><pre><span></span><code><span class="k">val</span> <span class="n">estimator_weights_</span> <span class="o">:</span> <span class="n">t</span> <span class="o">-&gt;</span> <span class="o">[&gt;`</span><span class="nc">ArrayLike</span><span class="o">]</span> <span class="nn">Np</span><span class="p">.</span><span class="nn">Obj</span><span class="p">.</span><span class="n">t</span>
</code></pre></div>

<p>Attribute estimator_weights_: get value as an option.</p>
<div class="highlight"><pre><span></span><code><span class="k">val</span> <span class="n">estimator_weights_opt</span> <span class="o">:</span> <span class="n">t</span> <span class="o">-&gt;</span> <span class="o">([&gt;`</span><span class="nc">ArrayLike</span><span class="o">]</span> <span class="nn">Np</span><span class="p">.</span><span class="nn">Obj</span><span class="p">.</span><span class="n">t</span><span class="o">)</span> <span class="n">option</span>
</code></pre></div>

<p>Attribute estimator_errors_: get value or raise Not_found if None.</p>
<div class="highlight"><pre><span></span><code><span class="k">val</span> <span class="n">estimator_errors_</span> <span class="o">:</span> <span class="n">t</span> <span class="o">-&gt;</span> <span class="o">[&gt;`</span><span class="nc">ArrayLike</span><span class="o">]</span> <span class="nn">Np</span><span class="p">.</span><span class="nn">Obj</span><span class="p">.</span><span class="n">t</span>
</code></pre></div>

<p>Attribute estimator_errors_: get value as an option.</p>
<div class="highlight"><pre><span></span><code><span class="k">val</span> <span class="n">estimator_errors_opt</span> <span class="o">:</span> <span class="n">t</span> <span class="o">-&gt;</span> <span class="o">([&gt;`</span><span class="nc">ArrayLike</span><span class="o">]</span> <span class="nn">Np</span><span class="p">.</span><span class="nn">Obj</span><span class="p">.</span><span class="n">t</span><span class="o">)</span> <span class="n">option</span>
</code></pre></div>

<p>Attribute feature_importances_: get value or raise Not_found if None.</p>
<div class="highlight"><pre><span></span><code><span class="k">val</span> <span class="n">feature_importances_</span> <span class="o">:</span> <span class="n">t</span> <span class="o">-&gt;</span> <span class="o">[&gt;`</span><span class="nc">ArrayLike</span><span class="o">]</span> <span class="nn">Np</span><span class="p">.</span><span class="nn">Obj</span><span class="p">.</span><span class="n">t</span>
</code></pre></div>

<p>Attribute feature_importances_: get value as an option.</p>
<div class="highlight"><pre><span></span><code><span class="k">val</span> <span class="n">feature_importances_opt</span> <span class="o">:</span> <span class="n">t</span> <span class="o">-&gt;</span> <span class="o">([&gt;`</span><span class="nc">ArrayLike</span><span class="o">]</span> <span class="nn">Np</span><span class="p">.</span><span class="nn">Obj</span><span class="p">.</span><span class="n">t</span><span class="o">)</span> <span class="n">option</span>
</code></pre></div>

<p>Print the object to a human-readable representation.</p>
<div class="highlight"><pre><span></span><code><span class="k">val</span> <span class="n">to_string</span> <span class="o">:</span> <span class="n">t</span> <span class="o">-&gt;</span> <span class="kt">string</span>
</code></pre></div>

<p>Print the object to a human-readable representation.</p>
<div class="highlight"><pre><span></span><code><span class="k">val</span> <span class="n">show</span> <span class="o">:</span> <span class="n">t</span> <span class="o">-&gt;</span> <span class="kt">string</span>
</code></pre></div>

<p>Pretty-print the object to a formatter.</p>
<div class="highlight"><pre><span></span><code><span class="k">val</span> <span class="n">pp</span> <span class="o">:</span> <span class="nn">Format</span><span class="p">.</span><span class="n">formatter</span> <span class="o">-&gt;</span> <span class="n">t</span> <span class="o">-&gt;</span> <span class="kt">unit</span> <span class="o">[@@</span><span class="n">ocaml</span><span class="o">.</span><span class="n">toplevel_printer</span><span class="o">]</span>



<span class="k">module</span> <span class="nc">AdaBoostRegressor</span> <span class="o">:</span> <span class="k">sig</span>
<span class="k">type</span> <span class="n">tag</span> <span class="o">=</span> <span class="o">[`</span><span class="nc">AdaBoostRegressor</span><span class="o">]</span>
<span class="k">type</span> <span class="n">t</span> <span class="o">=</span> <span class="o">[`</span><span class="nc">AdaBoostRegressor</span> <span class="o">|</span> <span class="o">`</span><span class="nc">BaseEnsemble</span> <span class="o">|</span> <span class="o">`</span><span class="nc">BaseEstimator</span> <span class="o">|</span> <span class="o">`</span><span class="nc">BaseWeightBoosting</span> <span class="o">|</span> <span class="o">`</span><span class="nc">MetaEstimatorMixin</span> <span class="o">|</span> <span class="o">`</span><span class="nc">Object</span> <span class="o">|</span> <span class="o">`</span><span class="nc">RegressorMixin</span><span class="o">]</span> <span class="nn">Obj</span><span class="p">.</span><span class="n">t</span>
<span class="k">val</span> <span class="n">of_pyobject</span> <span class="o">:</span> <span class="nn">Py</span><span class="p">.</span><span class="nn">Object</span><span class="p">.</span><span class="n">t</span> <span class="o">-&gt;</span> <span class="n">t</span>
<span class="k">val</span> <span class="n">to_pyobject</span> <span class="o">:</span> <span class="o">[&gt;</span> <span class="n">tag</span><span class="o">]</span> <span class="nn">Obj</span><span class="p">.</span><span class="n">t</span> <span class="o">-&gt;</span> <span class="nn">Py</span><span class="p">.</span><span class="nn">Object</span><span class="p">.</span><span class="n">t</span>

<span class="k">val</span> <span class="n">as_regressor</span> <span class="o">:</span> <span class="n">t</span> <span class="o">-&gt;</span> <span class="o">[`</span><span class="nc">RegressorMixin</span><span class="o">]</span> <span class="nn">Obj</span><span class="p">.</span><span class="n">t</span>
<span class="k">val</span> <span class="n">as_meta_estimator</span> <span class="o">:</span> <span class="n">t</span> <span class="o">-&gt;</span> <span class="o">[`</span><span class="nc">MetaEstimatorMixin</span><span class="o">]</span> <span class="nn">Obj</span><span class="p">.</span><span class="n">t</span>
<span class="k">val</span> <span class="n">as_weight_boosting</span> <span class="o">:</span> <span class="n">t</span> <span class="o">-&gt;</span> <span class="o">[`</span><span class="nc">BaseWeightBoosting</span><span class="o">]</span> <span class="nn">Obj</span><span class="p">.</span><span class="n">t</span>
<span class="k">val</span> <span class="n">as_estimator</span> <span class="o">:</span> <span class="n">t</span> <span class="o">-&gt;</span> <span class="o">[`</span><span class="nc">BaseEstimator</span><span class="o">]</span> <span class="nn">Obj</span><span class="p">.</span><span class="n">t</span>
<span class="k">val</span> <span class="n">as_ensemble</span> <span class="o">:</span> <span class="n">t</span> <span class="o">-&gt;</span> <span class="o">[`</span><span class="nc">BaseEnsemble</span><span class="o">]</span> <span class="nn">Obj</span><span class="p">.</span><span class="n">t</span>
<span class="k">val</span> <span class="n">create</span> <span class="o">:</span> <span class="o">?</span><span class="n">base_estimator</span><span class="o">:[&gt;`</span><span class="nc">BaseEstimator</span><span class="o">]</span> <span class="nn">Np</span><span class="p">.</span><span class="nn">Obj</span><span class="p">.</span><span class="n">t</span> <span class="o">-&gt;</span> <span class="o">?</span><span class="n">n_estimators</span><span class="o">:</span><span class="kt">int</span> <span class="o">-&gt;</span> <span class="o">?</span><span class="n">learning_rate</span><span class="o">:</span><span class="kt">float</span> <span class="o">-&gt;</span> <span class="o">?</span><span class="n">loss</span><span class="o">:[`</span><span class="nc">Linear</span> <span class="o">|</span> <span class="o">`</span><span class="nc">Square</span> <span class="o">|</span> <span class="o">`</span><span class="nc">Exponential</span><span class="o">]</span> <span class="o">-&gt;</span> <span class="o">?</span><span class="n">random_state</span><span class="o">:</span><span class="kt">int</span> <span class="o">-&gt;</span> <span class="kt">unit</span> <span class="o">-&gt;</span> <span class="n">t</span>
</code></pre></div>

<p>An AdaBoost regressor.</p>
<p>An AdaBoost [1] regressor is a meta-estimator that begins by fitting a
regressor on the original dataset and then fits additional copies of the
regressor on the same dataset but where the weights of instances are
adjusted according to the error of the current prediction. As such,
subsequent regressors focus more on difficult cases.</p>
<p>This class implements the algorithm known as AdaBoost.R2 [2].</p>
<p>Read more in the :ref:<code>User Guide &lt;adaboost&gt;</code>.</p>
<p>.. versionadded:: 0.14</p>
<h2 id="parameters_13">Parameters<a class="headerlink" href="#parameters_13" title="Permanent link">&para;</a></h2>
<p>base_estimator : object, optional (default=None)
The base estimator from which the boosted ensemble is built.
If <code>None</code>, then the base estimator is
<code>DecisionTreeRegressor(max_depth=3)</code>.</p>
<p>n_estimators : integer, optional (default=50)
The maximum number of estimators at which boosting is terminated.
In case of perfect fit, the learning procedure is stopped early.</p>
<p>learning_rate : float, optional (default=1.)
Learning rate shrinks the contribution of each regressor by
<code>learning_rate</code>. There is a trade-off between <code>learning_rate</code> and
<code>n_estimators</code>.</p>
<p>loss : {'linear', 'square', 'exponential'}, optional (default='linear')
The loss function to use when updating the weights after each
boosting iteration.</p>
<p>random_state : int, RandomState instance or None, optional (default=None)
If int, random_state is the seed used by the random number generator;
If RandomState instance, random_state is the random number generator;
If None, the random number generator is the RandomState instance used
by <code>np.random</code>.</p>
<h2 id="attributes_1">Attributes<a class="headerlink" href="#attributes_1" title="Permanent link">&para;</a></h2>
<p>base_estimator_ : estimator
The base estimator from which the ensemble is grown.</p>
<p>estimators_ : list of classifiers
The collection of fitted sub-estimators.</p>
<p>estimator_weights_ : array of floats
Weights for each estimator in the boosted ensemble.</p>
<p>estimator_errors_ : array of floats
Regression error for each estimator in the boosted ensemble.</p>
<p>feature_importances_ : ndarray of shape (n_features,)
The feature importances if supported by the <code>base_estimator</code>.</p>
<h2 id="examples_1">Examples<a class="headerlink" href="#examples_1" title="Permanent link">&para;</a></h2>
<blockquote>
<blockquote>
<blockquote>
<p>from sklearn.ensemble import AdaBoostRegressor
from sklearn.datasets import make_regression
X, y = make_regression(n_features=4, n_informative=2,
...                        random_state=0, shuffle=False)
regr = AdaBoostRegressor(random_state=0, n_estimators=100)
regr.fit(X, y)
AdaBoostRegressor(n_estimators=100, random_state=0)
regr.feature_importances_
array([0.2788..., 0.7109..., 0.0065..., 0.0036...])
regr.predict([[0, 0, 0, 0]])
array([4.7972...])
regr.score(X, y)
0.9771...</p>
</blockquote>
</blockquote>
</blockquote>
<h2 id="see-also_1">See also<a class="headerlink" href="#see-also_1" title="Permanent link">&para;</a></h2>
<p>AdaBoostClassifier, GradientBoostingRegressor,
sklearn.tree.DecisionTreeRegressor</p>
<h2 id="references_1">References<a class="headerlink" href="#references_1" title="Permanent link">&para;</a></h2>
<p>.. [1] Y. Freund, R. Schapire, 'A Decision-Theoretic Generalization of
on-Line Learning and an Application to Boosting', 1995.</p>
<p>.. [2] H. Drucker, 'Improving Regressors using Boosting Techniques', 1997.</p>
<div class="highlight"><pre><span></span><code><span class="k">val</span> <span class="n">get_item</span> <span class="o">:</span> <span class="n">index</span><span class="o">:</span><span class="nn">Py</span><span class="p">.</span><span class="nn">Object</span><span class="p">.</span><span class="n">t</span> <span class="o">-&gt;</span> <span class="o">[&gt;</span> <span class="n">tag</span><span class="o">]</span> <span class="nn">Obj</span><span class="p">.</span><span class="n">t</span> <span class="o">-&gt;</span> <span class="nn">Py</span><span class="p">.</span><span class="nn">Object</span><span class="p">.</span><span class="n">t</span>
</code></pre></div>

<p>Return the index'th estimator in the ensemble.</p>
<div class="highlight"><pre><span></span><code><span class="k">val</span> <span class="n">iter</span> <span class="o">:</span> <span class="o">[&gt;</span> <span class="n">tag</span><span class="o">]</span> <span class="nn">Obj</span><span class="p">.</span><span class="n">t</span> <span class="o">-&gt;</span> <span class="nn">Dict</span><span class="p">.</span><span class="n">t</span> <span class="nn">Seq</span><span class="p">.</span><span class="n">t</span>
</code></pre></div>

<p>Return iterator over estimators in the ensemble.</p>
<div class="highlight"><pre><span></span><code><span class="k">val</span> <span class="n">fit</span> <span class="o">:</span> <span class="o">?</span><span class="n">sample_weight</span><span class="o">:[&gt;`</span><span class="nc">ArrayLike</span><span class="o">]</span> <span class="nn">Np</span><span class="p">.</span><span class="nn">Obj</span><span class="p">.</span><span class="n">t</span> <span class="o">-&gt;</span> <span class="n">x</span><span class="o">:[&gt;`</span><span class="nc">ArrayLike</span><span class="o">]</span> <span class="nn">Np</span><span class="p">.</span><span class="nn">Obj</span><span class="p">.</span><span class="n">t</span> <span class="o">-&gt;</span> <span class="n">y</span><span class="o">:[&gt;`</span><span class="nc">ArrayLike</span><span class="o">]</span> <span class="nn">Np</span><span class="p">.</span><span class="nn">Obj</span><span class="p">.</span><span class="n">t</span> <span class="o">-&gt;</span> <span class="o">[&gt;</span> <span class="n">tag</span><span class="o">]</span> <span class="nn">Obj</span><span class="p">.</span><span class="n">t</span> <span class="o">-&gt;</span> <span class="n">t</span>
</code></pre></div>

<p>Build a boosted regressor from the training set (X, y).</p>
<h2 id="parameters_14">Parameters<a class="headerlink" href="#parameters_14" title="Permanent link">&para;</a></h2>
<p>X : {array-like, sparse matrix} of shape (n_samples, n_features)
The training input samples. Sparse matrix can be CSC, CSR, COO,
DOK, or LIL. COO, DOK, and LIL are converted to CSR.</p>
<p>y : array-like of shape (n_samples,)
The target values (real numbers).</p>
<p>sample_weight : array-like of shape (n_samples,), default=None
Sample weights. If None, the sample weights are initialized to
1 / n_samples.</p>
<h2 id="returns_8">Returns<a class="headerlink" href="#returns_8" title="Permanent link">&para;</a></h2>
<p>self : object</p>
<div class="highlight"><pre><span></span><code><span class="k">val</span> <span class="n">get_params</span> <span class="o">:</span> <span class="o">?</span><span class="n">deep</span><span class="o">:</span><span class="kt">bool</span> <span class="o">-&gt;</span> <span class="o">[&gt;</span> <span class="n">tag</span><span class="o">]</span> <span class="nn">Obj</span><span class="p">.</span><span class="n">t</span> <span class="o">-&gt;</span> <span class="nn">Dict</span><span class="p">.</span><span class="n">t</span>
</code></pre></div>

<p>Get parameters for this estimator.</p>
<h2 id="parameters_15">Parameters<a class="headerlink" href="#parameters_15" title="Permanent link">&para;</a></h2>
<p>deep : bool, default=True
If True, will return the parameters for this estimator and
contained subobjects that are estimators.</p>
<h2 id="returns_9">Returns<a class="headerlink" href="#returns_9" title="Permanent link">&para;</a></h2>
<p>params : mapping of string to any
Parameter names mapped to their values.</p>
<div class="highlight"><pre><span></span><code><span class="k">val</span> <span class="n">predict</span> <span class="o">:</span> <span class="n">x</span><span class="o">:[&gt;`</span><span class="nc">ArrayLike</span><span class="o">]</span> <span class="nn">Np</span><span class="p">.</span><span class="nn">Obj</span><span class="p">.</span><span class="n">t</span> <span class="o">-&gt;</span> <span class="o">[&gt;</span> <span class="n">tag</span><span class="o">]</span> <span class="nn">Obj</span><span class="p">.</span><span class="n">t</span> <span class="o">-&gt;</span> <span class="o">[&gt;`</span><span class="nc">ArrayLike</span><span class="o">]</span> <span class="nn">Np</span><span class="p">.</span><span class="nn">Obj</span><span class="p">.</span><span class="n">t</span>
</code></pre></div>

<p>Predict regression value for X.</p>
<p>The predicted regression value of an input sample is computed
as the weighted median prediction of the classifiers in the ensemble.</p>
<h2 id="parameters_16">Parameters<a class="headerlink" href="#parameters_16" title="Permanent link">&para;</a></h2>
<p>X : {array-like, sparse matrix} of shape (n_samples, n_features)
The training input samples. Sparse matrix can be CSC, CSR, COO,
DOK, or LIL. COO, DOK, and LIL are converted to CSR.</p>
<h2 id="returns_10">Returns<a class="headerlink" href="#returns_10" title="Permanent link">&para;</a></h2>
<p>y : ndarray of shape (n_samples,)
The predicted regression values.</p>
<div class="highlight"><pre><span></span><code><span class="k">val</span> <span class="n">score</span> <span class="o">:</span> <span class="o">?</span><span class="n">sample_weight</span><span class="o">:[&gt;`</span><span class="nc">ArrayLike</span><span class="o">]</span> <span class="nn">Np</span><span class="p">.</span><span class="nn">Obj</span><span class="p">.</span><span class="n">t</span> <span class="o">-&gt;</span> <span class="n">x</span><span class="o">:[&gt;`</span><span class="nc">ArrayLike</span><span class="o">]</span> <span class="nn">Np</span><span class="p">.</span><span class="nn">Obj</span><span class="p">.</span><span class="n">t</span> <span class="o">-&gt;</span> <span class="n">y</span><span class="o">:[&gt;`</span><span class="nc">ArrayLike</span><span class="o">]</span> <span class="nn">Np</span><span class="p">.</span><span class="nn">Obj</span><span class="p">.</span><span class="n">t</span> <span class="o">-&gt;</span> <span class="o">[&gt;</span> <span class="n">tag</span><span class="o">]</span> <span class="nn">Obj</span><span class="p">.</span><span class="n">t</span> <span class="o">-&gt;</span> <span class="kt">float</span>
</code></pre></div>

<p>Return the coefficient of determination R^2 of the prediction.</p>
<p>The coefficient R^2 is defined as (1 - u/v), where u is the residual
sum of squares ((y_true - y_pred) <strong> 2).sum() and v is the total
sum of squares ((y_true - y_true.mean()) </strong> 2).sum().
The best possible score is 1.0 and it can be negative (because the
model can be arbitrarily worse). A constant model that always
predicts the expected value of y, disregarding the input features,
would get a R^2 score of 0.0.</p>
<h2 id="parameters_17">Parameters<a class="headerlink" href="#parameters_17" title="Permanent link">&para;</a></h2>
<p>X : array-like of shape (n_samples, n_features)
Test samples. For some estimators this may be a
precomputed kernel matrix or a list of generic objects instead,
shape = (n_samples, n_samples_fitted),
where n_samples_fitted is the number of
samples used in the fitting for the estimator.</p>
<p>y : array-like of shape (n_samples,) or (n_samples, n_outputs)
True values for X.</p>
<p>sample_weight : array-like of shape (n_samples,), default=None
Sample weights.</p>
<h2 id="returns_11">Returns<a class="headerlink" href="#returns_11" title="Permanent link">&para;</a></h2>
<p>score : float
R^2 of self.predict(X) wrt. y.</p>
<h2 id="notes">Notes<a class="headerlink" href="#notes" title="Permanent link">&para;</a></h2>
<p>The R2 score used when calling <code>score</code> on a regressor will use
<code>multioutput='uniform_average'</code> from version 0.23 to keep consistent
with :func:<code>~sklearn.metrics.r2_score</code>. This will influence the
<code>score</code> method of all the multioutput regressors (except for
:class:<code>~sklearn.multioutput.MultiOutputRegressor</code>). To specify the
default value manually and avoid the warning, please either call
:func:<code>~sklearn.metrics.r2_score</code> directly or make a custom scorer with
:func:<code>~sklearn.metrics.make_scorer</code> (the built-in scorer <code>'r2'</code> uses
<code>multioutput='uniform_average'</code>).</p>
<div class="highlight"><pre><span></span><code><span class="k">val</span> <span class="n">set_params</span> <span class="o">:</span> <span class="o">?</span><span class="n">params</span><span class="o">:(</span><span class="kt">string</span> <span class="o">*</span> <span class="nn">Py</span><span class="p">.</span><span class="nn">Object</span><span class="p">.</span><span class="n">t</span><span class="o">)</span> <span class="kt">list</span> <span class="o">-&gt;</span> <span class="o">[&gt;</span> <span class="n">tag</span><span class="o">]</span> <span class="nn">Obj</span><span class="p">.</span><span class="n">t</span> <span class="o">-&gt;</span> <span class="n">t</span>
</code></pre></div>

<p>Set the parameters of this estimator.</p>
<p>The method works on simple estimators as well as on nested objects
(such as pipelines). The latter have parameters of the form
<code>&lt;component&gt;__&lt;parameter&gt;</code> so that it's possible to update each
component of a nested object.</p>
<h2 id="parameters_18">Parameters<a class="headerlink" href="#parameters_18" title="Permanent link">&para;</a></h2>
<p>**params : dict
Estimator parameters.</p>
<h2 id="returns_12">Returns<a class="headerlink" href="#returns_12" title="Permanent link">&para;</a></h2>
<p>self : object
Estimator instance.</p>
<div class="highlight"><pre><span></span><code><span class="k">val</span> <span class="n">staged_predict</span> <span class="o">:</span> <span class="n">x</span><span class="o">:[&gt;`</span><span class="nc">ArrayLike</span><span class="o">]</span> <span class="nn">Np</span><span class="p">.</span><span class="nn">Obj</span><span class="p">.</span><span class="n">t</span> <span class="o">-&gt;</span> <span class="o">[&gt;</span> <span class="n">tag</span><span class="o">]</span> <span class="nn">Obj</span><span class="p">.</span><span class="n">t</span> <span class="o">-&gt;</span> <span class="o">[&gt;`</span><span class="nc">ArrayLike</span><span class="o">]</span> <span class="nn">Np</span><span class="p">.</span><span class="nn">Obj</span><span class="p">.</span><span class="n">t</span> <span class="nn">Seq</span><span class="p">.</span><span class="n">t</span>
</code></pre></div>

<p>Return staged predictions for X.</p>
<p>The predicted regression value of an input sample is computed
as the weighted median prediction of the classifiers in the ensemble.</p>
<p>This generator method yields the ensemble prediction after each
iteration of boosting and therefore allows monitoring, such as to
determine the prediction on a test set after each boost.</p>
<h2 id="parameters_19">Parameters<a class="headerlink" href="#parameters_19" title="Permanent link">&para;</a></h2>
<p>X : {array-like, sparse matrix} of shape (n_samples, n_features)
The training input samples.</p>
<h2 id="yields_4">Yields<a class="headerlink" href="#yields_4" title="Permanent link">&para;</a></h2>
<p>y : generator of array, shape = [n_samples]
The predicted regression values.</p>
<div class="highlight"><pre><span></span><code><span class="k">val</span> <span class="n">staged_score</span> <span class="o">:</span> <span class="o">?</span><span class="n">sample_weight</span><span class="o">:[&gt;`</span><span class="nc">ArrayLike</span><span class="o">]</span> <span class="nn">Np</span><span class="p">.</span><span class="nn">Obj</span><span class="p">.</span><span class="n">t</span> <span class="o">-&gt;</span> <span class="n">x</span><span class="o">:[&gt;`</span><span class="nc">ArrayLike</span><span class="o">]</span> <span class="nn">Np</span><span class="p">.</span><span class="nn">Obj</span><span class="p">.</span><span class="n">t</span> <span class="o">-&gt;</span> <span class="n">y</span><span class="o">:[&gt;`</span><span class="nc">ArrayLike</span><span class="o">]</span> <span class="nn">Np</span><span class="p">.</span><span class="nn">Obj</span><span class="p">.</span><span class="n">t</span> <span class="o">-&gt;</span> <span class="o">[&gt;</span> <span class="n">tag</span><span class="o">]</span> <span class="nn">Obj</span><span class="p">.</span><span class="n">t</span> <span class="o">-&gt;</span> <span class="nn">Py</span><span class="p">.</span><span class="nn">Object</span><span class="p">.</span><span class="n">t</span>
</code></pre></div>

<p>Return staged scores for X, y.</p>
<p>This generator method yields the ensemble score after each iteration of
boosting and therefore allows monitoring, such as to determine the
score on a test set after each boost.</p>
<h2 id="parameters_20">Parameters<a class="headerlink" href="#parameters_20" title="Permanent link">&para;</a></h2>
<p>X : {array-like, sparse matrix} of shape (n_samples, n_features)
The training input samples. Sparse matrix can be CSC, CSR, COO,
DOK, or LIL. COO, DOK, and LIL are converted to CSR.</p>
<p>y : array-like of shape (n_samples,)
Labels for X.</p>
<p>sample_weight : array-like of shape (n_samples,), default=None
Sample weights.</p>
<h2 id="yields_5">Yields<a class="headerlink" href="#yields_5" title="Permanent link">&para;</a></h2>
<p>z : float</p>
<p>Attribute base_estimator_: get value or raise Not_found if None.</p>
<div class="highlight"><pre><span></span><code><span class="k">val</span> <span class="n">base_estimator_</span> <span class="o">:</span> <span class="n">t</span> <span class="o">-&gt;</span> <span class="o">[`</span><span class="nc">BaseEstimator</span><span class="o">|`</span><span class="nc">Object</span><span class="o">]</span> <span class="nn">Np</span><span class="p">.</span><span class="nn">Obj</span><span class="p">.</span><span class="n">t</span>
</code></pre></div>

<p>Attribute base_estimator_: get value as an option.</p>
<div class="highlight"><pre><span></span><code><span class="k">val</span> <span class="n">base_estimator_opt</span> <span class="o">:</span> <span class="n">t</span> <span class="o">-&gt;</span> <span class="o">([`</span><span class="nc">BaseEstimator</span><span class="o">|`</span><span class="nc">Object</span><span class="o">]</span> <span class="nn">Np</span><span class="p">.</span><span class="nn">Obj</span><span class="p">.</span><span class="n">t</span><span class="o">)</span> <span class="n">option</span>
</code></pre></div>

<p>Attribute estimators_: get value or raise Not_found if None.</p>
<div class="highlight"><pre><span></span><code><span class="k">val</span> <span class="n">estimators_</span> <span class="o">:</span> <span class="n">t</span> <span class="o">-&gt;</span> <span class="nn">Py</span><span class="p">.</span><span class="nn">Object</span><span class="p">.</span><span class="n">t</span>
</code></pre></div>

<p>Attribute estimators_: get value as an option.</p>
<div class="highlight"><pre><span></span><code><span class="k">val</span> <span class="n">estimators_opt</span> <span class="o">:</span> <span class="n">t</span> <span class="o">-&gt;</span> <span class="o">(</span><span class="nn">Py</span><span class="p">.</span><span class="nn">Object</span><span class="p">.</span><span class="n">t</span><span class="o">)</span> <span class="n">option</span>
</code></pre></div>

<p>Attribute estimator_weights_: get value or raise Not_found if None.</p>
<div class="highlight"><pre><span></span><code><span class="k">val</span> <span class="n">estimator_weights_</span> <span class="o">:</span> <span class="n">t</span> <span class="o">-&gt;</span> <span class="o">[&gt;`</span><span class="nc">ArrayLike</span><span class="o">]</span> <span class="nn">Np</span><span class="p">.</span><span class="nn">Obj</span><span class="p">.</span><span class="n">t</span>
</code></pre></div>

<p>Attribute estimator_weights_: get value as an option.</p>
<div class="highlight"><pre><span></span><code><span class="k">val</span> <span class="n">estimator_weights_opt</span> <span class="o">:</span> <span class="n">t</span> <span class="o">-&gt;</span> <span class="o">([&gt;`</span><span class="nc">ArrayLike</span><span class="o">]</span> <span class="nn">Np</span><span class="p">.</span><span class="nn">Obj</span><span class="p">.</span><span class="n">t</span><span class="o">)</span> <span class="n">option</span>
</code></pre></div>

<p>Attribute estimator_errors_: get value or raise Not_found if None.</p>
<div class="highlight"><pre><span></span><code><span class="k">val</span> <span class="n">estimator_errors_</span> <span class="o">:</span> <span class="n">t</span> <span class="o">-&gt;</span> <span class="o">[&gt;`</span><span class="nc">ArrayLike</span><span class="o">]</span> <span class="nn">Np</span><span class="p">.</span><span class="nn">Obj</span><span class="p">.</span><span class="n">t</span>
</code></pre></div>

<p>Attribute estimator_errors_: get value as an option.</p>
<div class="highlight"><pre><span></span><code><span class="k">val</span> <span class="n">estimator_errors_opt</span> <span class="o">:</span> <span class="n">t</span> <span class="o">-&gt;</span> <span class="o">([&gt;`</span><span class="nc">ArrayLike</span><span class="o">]</span> <span class="nn">Np</span><span class="p">.</span><span class="nn">Obj</span><span class="p">.</span><span class="n">t</span><span class="o">)</span> <span class="n">option</span>
</code></pre></div>

<p>Attribute feature_importances_: get value or raise Not_found if None.</p>
<div class="highlight"><pre><span></span><code><span class="k">val</span> <span class="n">feature_importances_</span> <span class="o">:</span> <span class="n">t</span> <span class="o">-&gt;</span> <span class="o">[&gt;`</span><span class="nc">ArrayLike</span><span class="o">]</span> <span class="nn">Np</span><span class="p">.</span><span class="nn">Obj</span><span class="p">.</span><span class="n">t</span>
</code></pre></div>

<p>Attribute feature_importances_: get value as an option.</p>
<div class="highlight"><pre><span></span><code><span class="k">val</span> <span class="n">feature_importances_opt</span> <span class="o">:</span> <span class="n">t</span> <span class="o">-&gt;</span> <span class="o">([&gt;`</span><span class="nc">ArrayLike</span><span class="o">]</span> <span class="nn">Np</span><span class="p">.</span><span class="nn">Obj</span><span class="p">.</span><span class="n">t</span><span class="o">)</span> <span class="n">option</span>
</code></pre></div>

<p>Print the object to a human-readable representation.</p>
<div class="highlight"><pre><span></span><code><span class="k">val</span> <span class="n">to_string</span> <span class="o">:</span> <span class="n">t</span> <span class="o">-&gt;</span> <span class="kt">string</span>
</code></pre></div>

<p>Print the object to a human-readable representation.</p>
<div class="highlight"><pre><span></span><code><span class="k">val</span> <span class="n">show</span> <span class="o">:</span> <span class="n">t</span> <span class="o">-&gt;</span> <span class="kt">string</span>
</code></pre></div>

<p>Pretty-print the object to a formatter.</p>
<div class="highlight"><pre><span></span><code><span class="k">val</span> <span class="n">pp</span> <span class="o">:</span> <span class="nn">Format</span><span class="p">.</span><span class="n">formatter</span> <span class="o">-&gt;</span> <span class="n">t</span> <span class="o">-&gt;</span> <span class="kt">unit</span> <span class="o">[@@</span><span class="n">ocaml</span><span class="o">.</span><span class="n">toplevel_printer</span><span class="o">]</span>



<span class="k">module</span> <span class="nc">BaggingClassifier</span> <span class="o">:</span> <span class="k">sig</span>
<span class="k">type</span> <span class="n">tag</span> <span class="o">=</span> <span class="o">[`</span><span class="nc">BaggingClassifier</span><span class="o">]</span>
<span class="k">type</span> <span class="n">t</span> <span class="o">=</span> <span class="o">[`</span><span class="nc">BaggingClassifier</span> <span class="o">|</span> <span class="o">`</span><span class="nc">BaseBagging</span> <span class="o">|</span> <span class="o">`</span><span class="nc">BaseEnsemble</span> <span class="o">|</span> <span class="o">`</span><span class="nc">BaseEstimator</span> <span class="o">|</span> <span class="o">`</span><span class="nc">ClassifierMixin</span> <span class="o">|</span> <span class="o">`</span><span class="nc">MetaEstimatorMixin</span> <span class="o">|</span> <span class="o">`</span><span class="nc">Object</span><span class="o">]</span> <span class="nn">Obj</span><span class="p">.</span><span class="n">t</span>
<span class="k">val</span> <span class="n">of_pyobject</span> <span class="o">:</span> <span class="nn">Py</span><span class="p">.</span><span class="nn">Object</span><span class="p">.</span><span class="n">t</span> <span class="o">-&gt;</span> <span class="n">t</span>
<span class="k">val</span> <span class="n">to_pyobject</span> <span class="o">:</span> <span class="o">[&gt;</span> <span class="n">tag</span><span class="o">]</span> <span class="nn">Obj</span><span class="p">.</span><span class="n">t</span> <span class="o">-&gt;</span> <span class="nn">Py</span><span class="p">.</span><span class="nn">Object</span><span class="p">.</span><span class="n">t</span>

<span class="k">val</span> <span class="n">as_classifier</span> <span class="o">:</span> <span class="n">t</span> <span class="o">-&gt;</span> <span class="o">[`</span><span class="nc">ClassifierMixin</span><span class="o">]</span> <span class="nn">Obj</span><span class="p">.</span><span class="n">t</span>
<span class="k">val</span> <span class="n">as_meta_estimator</span> <span class="o">:</span> <span class="n">t</span> <span class="o">-&gt;</span> <span class="o">[`</span><span class="nc">MetaEstimatorMixin</span><span class="o">]</span> <span class="nn">Obj</span><span class="p">.</span><span class="n">t</span>
<span class="k">val</span> <span class="n">as_estimator</span> <span class="o">:</span> <span class="n">t</span> <span class="o">-&gt;</span> <span class="o">[`</span><span class="nc">BaseEstimator</span><span class="o">]</span> <span class="nn">Obj</span><span class="p">.</span><span class="n">t</span>
<span class="k">val</span> <span class="n">as_bagging</span> <span class="o">:</span> <span class="n">t</span> <span class="o">-&gt;</span> <span class="o">[`</span><span class="nc">BaseBagging</span><span class="o">]</span> <span class="nn">Obj</span><span class="p">.</span><span class="n">t</span>
<span class="k">val</span> <span class="n">as_ensemble</span> <span class="o">:</span> <span class="n">t</span> <span class="o">-&gt;</span> <span class="o">[`</span><span class="nc">BaseEnsemble</span><span class="o">]</span> <span class="nn">Obj</span><span class="p">.</span><span class="n">t</span>
<span class="k">val</span> <span class="n">create</span> <span class="o">:</span> <span class="o">?</span><span class="n">base_estimator</span><span class="o">:[&gt;`</span><span class="nc">BaseEstimator</span><span class="o">]</span> <span class="nn">Np</span><span class="p">.</span><span class="nn">Obj</span><span class="p">.</span><span class="n">t</span> <span class="o">-&gt;</span> <span class="o">?</span><span class="n">n_estimators</span><span class="o">:</span><span class="kt">int</span> <span class="o">-&gt;</span> <span class="o">?</span><span class="n">max_samples</span><span class="o">:[`</span><span class="nc">F</span> <span class="k">of</span> <span class="kt">float</span> <span class="o">|</span> <span class="o">`</span><span class="nc">I</span> <span class="k">of</span> <span class="kt">int</span><span class="o">]</span> <span class="o">-&gt;</span> <span class="o">?</span><span class="n">max_features</span><span class="o">:[`</span><span class="nc">F</span> <span class="k">of</span> <span class="kt">float</span> <span class="o">|</span> <span class="o">`</span><span class="nc">I</span> <span class="k">of</span> <span class="kt">int</span><span class="o">]</span> <span class="o">-&gt;</span> <span class="o">?</span><span class="n">bootstrap</span><span class="o">:</span><span class="kt">bool</span> <span class="o">-&gt;</span> <span class="o">?</span><span class="n">bootstrap_features</span><span class="o">:</span><span class="kt">bool</span> <span class="o">-&gt;</span> <span class="o">?</span><span class="n">oob_score</span><span class="o">:</span><span class="kt">bool</span> <span class="o">-&gt;</span> <span class="o">?</span><span class="n">warm_start</span><span class="o">:</span><span class="kt">bool</span> <span class="o">-&gt;</span> <span class="o">?</span><span class="n">n_jobs</span><span class="o">:</span><span class="kt">int</span> <span class="o">-&gt;</span> <span class="o">?</span><span class="n">random_state</span><span class="o">:</span><span class="kt">int</span> <span class="o">-&gt;</span> <span class="o">?</span><span class="n">verbose</span><span class="o">:</span><span class="kt">int</span> <span class="o">-&gt;</span> <span class="kt">unit</span> <span class="o">-&gt;</span> <span class="n">t</span>
</code></pre></div>

<p>A Bagging classifier.</p>
<p>A Bagging classifier is an ensemble meta-estimator that fits base
classifiers each on random subsets of the original dataset and then
aggregate their individual predictions (either by voting or by averaging)
to form a final prediction. Such a meta-estimator can typically be used as
a way to reduce the variance of a black-box estimator (e.g., a decision
tree), by introducing randomization into its construction procedure and
then making an ensemble out of it.</p>
<p>This algorithm encompasses several works from the literature. When random
subsets of the dataset are drawn as random subsets of the samples, then
this algorithm is known as Pasting [1]<em>. If samples are drawn with
replacement, then the method is known as Bagging [2]</em>. When random subsets
of the dataset are drawn as random subsets of the features, then the method
is known as Random Subspaces [3]<em>. Finally, when base estimators are built
on subsets of both samples and features, then the method is known as
Random Patches [4]</em>.</p>
<p>Read more in the :ref:<code>User Guide &lt;bagging&gt;</code>.</p>
<p>.. versionadded:: 0.15</p>
<h2 id="parameters_21">Parameters<a class="headerlink" href="#parameters_21" title="Permanent link">&para;</a></h2>
<p>base_estimator : object or None, optional (default=None)
The base estimator to fit on random subsets of the dataset.
If None, then the base estimator is a decision tree.</p>
<p>n_estimators : int, optional (default=10)
The number of base estimators in the ensemble.</p>
<p>max_samples : int or float, optional (default=1.0)
The number of samples to draw from X to train each base estimator.</p>
<ul>
<li>If int, then draw <code>max_samples</code> samples.</li>
<li>If float, then draw <code>max_samples * X.shape[0]</code> samples.</li>
</ul>
<p>max_features : int or float, optional (default=1.0)
The number of features to draw from X to train each base estimator.</p>
<ul>
<li>If int, then draw <code>max_features</code> features.</li>
<li>If float, then draw <code>max_features * X.shape[1]</code> features.</li>
</ul>
<p>bootstrap : boolean, optional (default=True)
Whether samples are drawn with replacement. If False, sampling
without replacement is performed.</p>
<p>bootstrap_features : boolean, optional (default=False)
Whether features are drawn with replacement.</p>
<p>oob_score : bool, optional (default=False)
Whether to use out-of-bag samples to estimate
the generalization error.</p>
<p>warm_start : bool, optional (default=False)
When set to True, reuse the solution of the previous call to fit
and add more estimators to the ensemble, otherwise, just fit
a whole new ensemble. See :term:<code>the Glossary &lt;warm_start&gt;</code>.</p>
<p>.. versionadded:: 0.17
<em>warm_start</em> constructor parameter.</p>
<p>n_jobs : int or None, optional (default=None)
The number of jobs to run in parallel for both :meth:<code>fit</code> and
:meth:<code>predict</code>. <code>None</code> means 1 unless in a
:obj:<code>joblib.parallel_backend</code> context. <code>-1</code> means using all
processors. See :term:<code>Glossary &lt;n_jobs&gt;</code> for more details.</p>
<p>random_state : int, RandomState instance or None, optional (default=None)
If int, random_state is the seed used by the random number generator;
If RandomState instance, random_state is the random number generator;
If None, the random number generator is the RandomState instance used
by <code>np.random</code>.</p>
<p>verbose : int, optional (default=0)
Controls the verbosity when fitting and predicting.</p>
<h2 id="attributes_2">Attributes<a class="headerlink" href="#attributes_2" title="Permanent link">&para;</a></h2>
<p>base_estimator_ : estimator
The base estimator from which the ensemble is grown.</p>
<p>n_features_ : int
The number of features when :meth:<code>fit</code> is performed.</p>
<p>estimators_ : list of estimators
The collection of fitted base estimators.</p>
<p>estimators_samples_ : list of arrays
The subset of drawn samples (i.e., the in-bag samples) for each base
estimator. Each subset is defined by an array of the indices selected.</p>
<p>estimators_features_ : list of arrays
The subset of drawn features for each base estimator.</p>
<p>classes_ : array of shape (n_classes,)
The classes labels.</p>
<p>n_classes_ : int or list
The number of classes.</p>
<p>oob_score_ : float
Score of the training dataset obtained using an out-of-bag estimate.
This attribute exists only when <code>oob_score</code> is True.</p>
<p>oob_decision_function_ : array of shape (n_samples, n_classes)
Decision function computed with out-of-bag estimate on the training
set. If n_estimators is small it might be possible that a data point
was never left out during the bootstrap. In this case,
<code>oob_decision_function_</code> might contain NaN. This attribute exists
only when <code>oob_score</code> is True.</p>
<h2 id="examples_2">Examples<a class="headerlink" href="#examples_2" title="Permanent link">&para;</a></h2>
<blockquote>
<blockquote>
<blockquote>
<p>from sklearn.svm import SVC
from sklearn.ensemble import BaggingClassifier
from sklearn.datasets import make_classification
X, y = make_classification(n_samples=100, n_features=4,
...                            n_informative=2, n_redundant=0,
...                            random_state=0, shuffle=False)
clf = BaggingClassifier(base_estimator=SVC(),
...                         n_estimators=10, random_state=0).fit(X, y)
clf.predict([[0, 0, 0, 0]])
array([1])</p>
</blockquote>
</blockquote>
</blockquote>
<h2 id="references_2">References<a class="headerlink" href="#references_2" title="Permanent link">&para;</a></h2>
<p>.. [1] L. Breiman, 'Pasting small votes for classification in large
databases and on-line', Machine Learning, 36(1), 85-103, 1999.</p>
<p>.. [2] L. Breiman, 'Bagging predictors', Machine Learning, 24(2), 123-140,
1996.</p>
<p>.. [3] T. Ho, 'The random subspace method for constructing decision
forests', Pattern Analysis and Machine Intelligence, 20(8), 832-844,
1998.</p>
<p>.. [4] G. Louppe and P. Geurts, 'Ensembles on Random Patches', Machine
Learning and Knowledge Discovery in Databases, 346-361, 2012.</p>
<div class="highlight"><pre><span></span><code><span class="k">val</span> <span class="n">get_item</span> <span class="o">:</span> <span class="n">index</span><span class="o">:</span><span class="nn">Py</span><span class="p">.</span><span class="nn">Object</span><span class="p">.</span><span class="n">t</span> <span class="o">-&gt;</span> <span class="o">[&gt;</span> <span class="n">tag</span><span class="o">]</span> <span class="nn">Obj</span><span class="p">.</span><span class="n">t</span> <span class="o">-&gt;</span> <span class="nn">Py</span><span class="p">.</span><span class="nn">Object</span><span class="p">.</span><span class="n">t</span>
</code></pre></div>

<p>Return the index'th estimator in the ensemble.</p>
<div class="highlight"><pre><span></span><code><span class="k">val</span> <span class="n">iter</span> <span class="o">:</span> <span class="o">[&gt;</span> <span class="n">tag</span><span class="o">]</span> <span class="nn">Obj</span><span class="p">.</span><span class="n">t</span> <span class="o">-&gt;</span> <span class="nn">Dict</span><span class="p">.</span><span class="n">t</span> <span class="nn">Seq</span><span class="p">.</span><span class="n">t</span>
</code></pre></div>

<p>Return iterator over estimators in the ensemble.</p>
<div class="highlight"><pre><span></span><code><span class="k">val</span> <span class="n">fit</span> <span class="o">:</span> <span class="o">?</span><span class="n">sample_weight</span><span class="o">:[&gt;`</span><span class="nc">ArrayLike</span><span class="o">]</span> <span class="nn">Np</span><span class="p">.</span><span class="nn">Obj</span><span class="p">.</span><span class="n">t</span> <span class="o">-&gt;</span> <span class="n">x</span><span class="o">:[&gt;`</span><span class="nc">ArrayLike</span><span class="o">]</span> <span class="nn">Np</span><span class="p">.</span><span class="nn">Obj</span><span class="p">.</span><span class="n">t</span> <span class="o">-&gt;</span> <span class="n">y</span><span class="o">:[&gt;`</span><span class="nc">ArrayLike</span><span class="o">]</span> <span class="nn">Np</span><span class="p">.</span><span class="nn">Obj</span><span class="p">.</span><span class="n">t</span> <span class="o">-&gt;</span> <span class="o">[&gt;</span> <span class="n">tag</span><span class="o">]</span> <span class="nn">Obj</span><span class="p">.</span><span class="n">t</span> <span class="o">-&gt;</span> <span class="n">t</span>
</code></pre></div>

<p>Build a Bagging ensemble of estimators from the training
set (X, y).</p>
<h2 id="parameters_22">Parameters<a class="headerlink" href="#parameters_22" title="Permanent link">&para;</a></h2>
<p>X : {array-like, sparse matrix} of shape (n_samples, n_features)
The training input samples. Sparse matrices are accepted only if
they are supported by the base estimator.</p>
<p>y : array-like of shape (n_samples,)
The target values (class labels in classification, real numbers in
regression).</p>
<p>sample_weight : array-like of shape (n_samples,), default=None
Sample weights. If None, then samples are equally weighted.
Note that this is supported only if the base estimator supports
sample weighting.</p>
<h2 id="returns_13">Returns<a class="headerlink" href="#returns_13" title="Permanent link">&para;</a></h2>
<p>self : object</p>
<div class="highlight"><pre><span></span><code><span class="k">val</span> <span class="n">get_params</span> <span class="o">:</span> <span class="o">?</span><span class="n">deep</span><span class="o">:</span><span class="kt">bool</span> <span class="o">-&gt;</span> <span class="o">[&gt;</span> <span class="n">tag</span><span class="o">]</span> <span class="nn">Obj</span><span class="p">.</span><span class="n">t</span> <span class="o">-&gt;</span> <span class="nn">Dict</span><span class="p">.</span><span class="n">t</span>
</code></pre></div>

<p>Get parameters for this estimator.</p>
<h2 id="parameters_23">Parameters<a class="headerlink" href="#parameters_23" title="Permanent link">&para;</a></h2>
<p>deep : bool, default=True
If True, will return the parameters for this estimator and
contained subobjects that are estimators.</p>
<h2 id="returns_14">Returns<a class="headerlink" href="#returns_14" title="Permanent link">&para;</a></h2>
<p>params : mapping of string to any
Parameter names mapped to their values.</p>
<div class="highlight"><pre><span></span><code><span class="k">val</span> <span class="n">predict</span> <span class="o">:</span> <span class="n">x</span><span class="o">:[&gt;`</span><span class="nc">ArrayLike</span><span class="o">]</span> <span class="nn">Np</span><span class="p">.</span><span class="nn">Obj</span><span class="p">.</span><span class="n">t</span> <span class="o">-&gt;</span> <span class="o">[&gt;</span> <span class="n">tag</span><span class="o">]</span> <span class="nn">Obj</span><span class="p">.</span><span class="n">t</span> <span class="o">-&gt;</span> <span class="o">[&gt;`</span><span class="nc">ArrayLike</span><span class="o">]</span> <span class="nn">Np</span><span class="p">.</span><span class="nn">Obj</span><span class="p">.</span><span class="n">t</span>
</code></pre></div>

<p>Predict class for X.</p>
<p>The predicted class of an input sample is computed as the class with
the highest mean predicted probability. If base estimators do not
implement a <code>predict_proba</code> method, then it resorts to voting.</p>
<h2 id="parameters_24">Parameters<a class="headerlink" href="#parameters_24" title="Permanent link">&para;</a></h2>
<p>X : {array-like, sparse matrix} of shape (n_samples, n_features)
The training input samples. Sparse matrices are accepted only if
they are supported by the base estimator.</p>
<h2 id="returns_15">Returns<a class="headerlink" href="#returns_15" title="Permanent link">&para;</a></h2>
<p>y : ndarray of shape (n_samples,)
The predicted classes.</p>
<div class="highlight"><pre><span></span><code><span class="k">val</span> <span class="n">predict_log_proba</span> <span class="o">:</span> <span class="n">x</span><span class="o">:[&gt;`</span><span class="nc">ArrayLike</span><span class="o">]</span> <span class="nn">Np</span><span class="p">.</span><span class="nn">Obj</span><span class="p">.</span><span class="n">t</span> <span class="o">-&gt;</span> <span class="o">[&gt;</span> <span class="n">tag</span><span class="o">]</span> <span class="nn">Obj</span><span class="p">.</span><span class="n">t</span> <span class="o">-&gt;</span> <span class="o">[&gt;`</span><span class="nc">ArrayLike</span><span class="o">]</span> <span class="nn">Np</span><span class="p">.</span><span class="nn">Obj</span><span class="p">.</span><span class="n">t</span>
</code></pre></div>

<p>Predict class log-probabilities for X.</p>
<p>The predicted class log-probabilities of an input sample is computed as
the log of the mean predicted class probabilities of the base
estimators in the ensemble.</p>
<h2 id="parameters_25">Parameters<a class="headerlink" href="#parameters_25" title="Permanent link">&para;</a></h2>
<p>X : {array-like, sparse matrix} of shape (n_samples, n_features)
The training input samples. Sparse matrices are accepted only if
they are supported by the base estimator.</p>
<h2 id="returns_16">Returns<a class="headerlink" href="#returns_16" title="Permanent link">&para;</a></h2>
<p>p : array of shape (n_samples, n_classes)
The class log-probabilities of the input samples. The order of the
classes corresponds to that in the attribute :term:<code>classes_</code>.</p>
<div class="highlight"><pre><span></span><code><span class="k">val</span> <span class="n">predict_proba</span> <span class="o">:</span> <span class="n">x</span><span class="o">:[&gt;`</span><span class="nc">ArrayLike</span><span class="o">]</span> <span class="nn">Np</span><span class="p">.</span><span class="nn">Obj</span><span class="p">.</span><span class="n">t</span> <span class="o">-&gt;</span> <span class="o">[&gt;</span> <span class="n">tag</span><span class="o">]</span> <span class="nn">Obj</span><span class="p">.</span><span class="n">t</span> <span class="o">-&gt;</span> <span class="o">[&gt;`</span><span class="nc">ArrayLike</span><span class="o">]</span> <span class="nn">Np</span><span class="p">.</span><span class="nn">Obj</span><span class="p">.</span><span class="n">t</span>
</code></pre></div>

<p>Predict class probabilities for X.</p>
<p>The predicted class probabilities of an input sample is computed as
the mean predicted class probabilities of the base estimators in the
ensemble. If base estimators do not implement a <code>predict_proba</code>
method, then it resorts to voting and the predicted class probabilities
of an input sample represents the proportion of estimators predicting
each class.</p>
<h2 id="parameters_26">Parameters<a class="headerlink" href="#parameters_26" title="Permanent link">&para;</a></h2>
<p>X : {array-like, sparse matrix} of shape (n_samples, n_features)
The training input samples. Sparse matrices are accepted only if
they are supported by the base estimator.</p>
<h2 id="returns_17">Returns<a class="headerlink" href="#returns_17" title="Permanent link">&para;</a></h2>
<p>p : array of shape (n_samples, n_classes)
The class probabilities of the input samples. The order of the
classes corresponds to that in the attribute :term:<code>classes_</code>.</p>
<div class="highlight"><pre><span></span><code><span class="k">val</span> <span class="n">score</span> <span class="o">:</span> <span class="o">?</span><span class="n">sample_weight</span><span class="o">:[&gt;`</span><span class="nc">ArrayLike</span><span class="o">]</span> <span class="nn">Np</span><span class="p">.</span><span class="nn">Obj</span><span class="p">.</span><span class="n">t</span> <span class="o">-&gt;</span> <span class="n">x</span><span class="o">:[&gt;`</span><span class="nc">ArrayLike</span><span class="o">]</span> <span class="nn">Np</span><span class="p">.</span><span class="nn">Obj</span><span class="p">.</span><span class="n">t</span> <span class="o">-&gt;</span> <span class="n">y</span><span class="o">:[&gt;`</span><span class="nc">ArrayLike</span><span class="o">]</span> <span class="nn">Np</span><span class="p">.</span><span class="nn">Obj</span><span class="p">.</span><span class="n">t</span> <span class="o">-&gt;</span> <span class="o">[&gt;</span> <span class="n">tag</span><span class="o">]</span> <span class="nn">Obj</span><span class="p">.</span><span class="n">t</span> <span class="o">-&gt;</span> <span class="kt">float</span>
</code></pre></div>

<p>Return the mean accuracy on the given test data and labels.</p>
<p>In multi-label classification, this is the subset accuracy
which is a harsh metric since you require for each sample that
each label set be correctly predicted.</p>
<h2 id="parameters_27">Parameters<a class="headerlink" href="#parameters_27" title="Permanent link">&para;</a></h2>
<p>X : array-like of shape (n_samples, n_features)
Test samples.</p>
<p>y : array-like of shape (n_samples,) or (n_samples, n_outputs)
True labels for X.</p>
<p>sample_weight : array-like of shape (n_samples,), default=None
Sample weights.</p>
<h2 id="returns_18">Returns<a class="headerlink" href="#returns_18" title="Permanent link">&para;</a></h2>
<p>score : float
Mean accuracy of self.predict(X) wrt. y.</p>
<div class="highlight"><pre><span></span><code><span class="k">val</span> <span class="n">set_params</span> <span class="o">:</span> <span class="o">?</span><span class="n">params</span><span class="o">:(</span><span class="kt">string</span> <span class="o">*</span> <span class="nn">Py</span><span class="p">.</span><span class="nn">Object</span><span class="p">.</span><span class="n">t</span><span class="o">)</span> <span class="kt">list</span> <span class="o">-&gt;</span> <span class="o">[&gt;</span> <span class="n">tag</span><span class="o">]</span> <span class="nn">Obj</span><span class="p">.</span><span class="n">t</span> <span class="o">-&gt;</span> <span class="n">t</span>
</code></pre></div>

<p>Set the parameters of this estimator.</p>
<p>The method works on simple estimators as well as on nested objects
(such as pipelines). The latter have parameters of the form
<code>&lt;component&gt;__&lt;parameter&gt;</code> so that it's possible to update each
component of a nested object.</p>
<h2 id="parameters_28">Parameters<a class="headerlink" href="#parameters_28" title="Permanent link">&para;</a></h2>
<p>**params : dict
Estimator parameters.</p>
<h2 id="returns_19">Returns<a class="headerlink" href="#returns_19" title="Permanent link">&para;</a></h2>
<p>self : object
Estimator instance.</p>
<p>Attribute base_estimator_: get value or raise Not_found if None.</p>
<div class="highlight"><pre><span></span><code><span class="k">val</span> <span class="n">base_estimator_</span> <span class="o">:</span> <span class="n">t</span> <span class="o">-&gt;</span> <span class="o">[`</span><span class="nc">BaseEstimator</span><span class="o">|`</span><span class="nc">Object</span><span class="o">]</span> <span class="nn">Np</span><span class="p">.</span><span class="nn">Obj</span><span class="p">.</span><span class="n">t</span>
</code></pre></div>

<p>Attribute base_estimator_: get value as an option.</p>
<div class="highlight"><pre><span></span><code><span class="k">val</span> <span class="n">base_estimator_opt</span> <span class="o">:</span> <span class="n">t</span> <span class="o">-&gt;</span> <span class="o">([`</span><span class="nc">BaseEstimator</span><span class="o">|`</span><span class="nc">Object</span><span class="o">]</span> <span class="nn">Np</span><span class="p">.</span><span class="nn">Obj</span><span class="p">.</span><span class="n">t</span><span class="o">)</span> <span class="n">option</span>
</code></pre></div>

<p>Attribute n_features_: get value or raise Not_found if None.</p>
<div class="highlight"><pre><span></span><code><span class="k">val</span> <span class="n">n_features_</span> <span class="o">:</span> <span class="n">t</span> <span class="o">-&gt;</span> <span class="kt">int</span>
</code></pre></div>

<p>Attribute n_features_: get value as an option.</p>
<div class="highlight"><pre><span></span><code><span class="k">val</span> <span class="n">n_features_opt</span> <span class="o">:</span> <span class="n">t</span> <span class="o">-&gt;</span> <span class="o">(</span><span class="kt">int</span><span class="o">)</span> <span class="n">option</span>
</code></pre></div>

<p>Attribute estimators_: get value or raise Not_found if None.</p>
<div class="highlight"><pre><span></span><code><span class="k">val</span> <span class="n">estimators_</span> <span class="o">:</span> <span class="n">t</span> <span class="o">-&gt;</span> <span class="o">[`</span><span class="nc">BaseEstimator</span><span class="o">|`</span><span class="nc">Object</span><span class="o">]</span> <span class="nn">Np</span><span class="p">.</span><span class="nn">Obj</span><span class="p">.</span><span class="n">t</span> <span class="kt">list</span>
</code></pre></div>

<p>Attribute estimators_: get value as an option.</p>
<div class="highlight"><pre><span></span><code><span class="k">val</span> <span class="n">estimators_opt</span> <span class="o">:</span> <span class="n">t</span> <span class="o">-&gt;</span> <span class="o">([`</span><span class="nc">BaseEstimator</span><span class="o">|`</span><span class="nc">Object</span><span class="o">]</span> <span class="nn">Np</span><span class="p">.</span><span class="nn">Obj</span><span class="p">.</span><span class="n">t</span> <span class="kt">list</span><span class="o">)</span> <span class="n">option</span>
</code></pre></div>

<p>Attribute estimators_samples_: get value or raise Not_found if None.</p>
<div class="highlight"><pre><span></span><code><span class="k">val</span> <span class="n">estimators_samples_</span> <span class="o">:</span> <span class="n">t</span> <span class="o">-&gt;</span> <span class="nn">Np</span><span class="p">.</span><span class="nn">Numpy</span><span class="p">.</span><span class="nn">Ndarray</span><span class="p">.</span><span class="nn">List</span><span class="p">.</span><span class="n">t</span>
</code></pre></div>

<p>Attribute estimators_samples_: get value as an option.</p>
<div class="highlight"><pre><span></span><code><span class="k">val</span> <span class="n">estimators_samples_opt</span> <span class="o">:</span> <span class="n">t</span> <span class="o">-&gt;</span> <span class="o">(</span><span class="nn">Np</span><span class="p">.</span><span class="nn">Numpy</span><span class="p">.</span><span class="nn">Ndarray</span><span class="p">.</span><span class="nn">List</span><span class="p">.</span><span class="n">t</span><span class="o">)</span> <span class="n">option</span>
</code></pre></div>

<p>Attribute estimators_features_: get value or raise Not_found if None.</p>
<div class="highlight"><pre><span></span><code><span class="k">val</span> <span class="n">estimators_features_</span> <span class="o">:</span> <span class="n">t</span> <span class="o">-&gt;</span> <span class="nn">Np</span><span class="p">.</span><span class="nn">Numpy</span><span class="p">.</span><span class="nn">Ndarray</span><span class="p">.</span><span class="nn">List</span><span class="p">.</span><span class="n">t</span>
</code></pre></div>

<p>Attribute estimators_features_: get value as an option.</p>
<div class="highlight"><pre><span></span><code><span class="k">val</span> <span class="n">estimators_features_opt</span> <span class="o">:</span> <span class="n">t</span> <span class="o">-&gt;</span> <span class="o">(</span><span class="nn">Np</span><span class="p">.</span><span class="nn">Numpy</span><span class="p">.</span><span class="nn">Ndarray</span><span class="p">.</span><span class="nn">List</span><span class="p">.</span><span class="n">t</span><span class="o">)</span> <span class="n">option</span>
</code></pre></div>

<p>Attribute classes_: get value or raise Not_found if None.</p>
<div class="highlight"><pre><span></span><code><span class="k">val</span> <span class="n">classes_</span> <span class="o">:</span> <span class="n">t</span> <span class="o">-&gt;</span> <span class="o">[&gt;`</span><span class="nc">ArrayLike</span><span class="o">]</span> <span class="nn">Np</span><span class="p">.</span><span class="nn">Obj</span><span class="p">.</span><span class="n">t</span>
</code></pre></div>

<p>Attribute classes_: get value as an option.</p>
<div class="highlight"><pre><span></span><code><span class="k">val</span> <span class="n">classes_opt</span> <span class="o">:</span> <span class="n">t</span> <span class="o">-&gt;</span> <span class="o">([&gt;`</span><span class="nc">ArrayLike</span><span class="o">]</span> <span class="nn">Np</span><span class="p">.</span><span class="nn">Obj</span><span class="p">.</span><span class="n">t</span><span class="o">)</span> <span class="n">option</span>
</code></pre></div>

<p>Attribute n_classes_: get value or raise Not_found if None.</p>
<div class="highlight"><pre><span></span><code><span class="k">val</span> <span class="n">n_classes_</span> <span class="o">:</span> <span class="n">t</span> <span class="o">-&gt;</span> <span class="nn">Py</span><span class="p">.</span><span class="nn">Object</span><span class="p">.</span><span class="n">t</span>
</code></pre></div>

<p>Attribute n_classes_: get value as an option.</p>
<div class="highlight"><pre><span></span><code><span class="k">val</span> <span class="n">n_classes_opt</span> <span class="o">:</span> <span class="n">t</span> <span class="o">-&gt;</span> <span class="o">(</span><span class="nn">Py</span><span class="p">.</span><span class="nn">Object</span><span class="p">.</span><span class="n">t</span><span class="o">)</span> <span class="n">option</span>
</code></pre></div>

<p>Attribute oob_score_: get value or raise Not_found if None.</p>
<div class="highlight"><pre><span></span><code><span class="k">val</span> <span class="n">oob_score_</span> <span class="o">:</span> <span class="n">t</span> <span class="o">-&gt;</span> <span class="kt">float</span>
</code></pre></div>

<p>Attribute oob_score_: get value as an option.</p>
<div class="highlight"><pre><span></span><code><span class="k">val</span> <span class="n">oob_score_opt</span> <span class="o">:</span> <span class="n">t</span> <span class="o">-&gt;</span> <span class="o">(</span><span class="kt">float</span><span class="o">)</span> <span class="n">option</span>
</code></pre></div>

<p>Attribute oob_decision_function_: get value or raise Not_found if None.</p>
<div class="highlight"><pre><span></span><code><span class="k">val</span> <span class="n">oob_decision_function_</span> <span class="o">:</span> <span class="n">t</span> <span class="o">-&gt;</span> <span class="o">[&gt;`</span><span class="nc">ArrayLike</span><span class="o">]</span> <span class="nn">Np</span><span class="p">.</span><span class="nn">Obj</span><span class="p">.</span><span class="n">t</span>
</code></pre></div>

<p>Attribute oob_decision_function_: get value as an option.</p>
<div class="highlight"><pre><span></span><code><span class="k">val</span> <span class="n">oob_decision_function_opt</span> <span class="o">:</span> <span class="n">t</span> <span class="o">-&gt;</span> <span class="o">([&gt;`</span><span class="nc">ArrayLike</span><span class="o">]</span> <span class="nn">Np</span><span class="p">.</span><span class="nn">Obj</span><span class="p">.</span><span class="n">t</span><span class="o">)</span> <span class="n">option</span>
</code></pre></div>

<p>Print the object to a human-readable representation.</p>
<div class="highlight"><pre><span></span><code><span class="k">val</span> <span class="n">to_string</span> <span class="o">:</span> <span class="n">t</span> <span class="o">-&gt;</span> <span class="kt">string</span>
</code></pre></div>

<p>Print the object to a human-readable representation.</p>
<div class="highlight"><pre><span></span><code><span class="k">val</span> <span class="n">show</span> <span class="o">:</span> <span class="n">t</span> <span class="o">-&gt;</span> <span class="kt">string</span>
</code></pre></div>

<p>Pretty-print the object to a formatter.</p>
<div class="highlight"><pre><span></span><code><span class="k">val</span> <span class="n">pp</span> <span class="o">:</span> <span class="nn">Format</span><span class="p">.</span><span class="n">formatter</span> <span class="o">-&gt;</span> <span class="n">t</span> <span class="o">-&gt;</span> <span class="kt">unit</span> <span class="o">[@@</span><span class="n">ocaml</span><span class="o">.</span><span class="n">toplevel_printer</span><span class="o">]</span>



<span class="k">module</span> <span class="nc">BaggingRegressor</span> <span class="o">:</span> <span class="k">sig</span>
<span class="k">type</span> <span class="n">tag</span> <span class="o">=</span> <span class="o">[`</span><span class="nc">BaggingRegressor</span><span class="o">]</span>
<span class="k">type</span> <span class="n">t</span> <span class="o">=</span> <span class="o">[`</span><span class="nc">BaggingRegressor</span> <span class="o">|</span> <span class="o">`</span><span class="nc">BaseBagging</span> <span class="o">|</span> <span class="o">`</span><span class="nc">BaseEnsemble</span> <span class="o">|</span> <span class="o">`</span><span class="nc">BaseEstimator</span> <span class="o">|</span> <span class="o">`</span><span class="nc">MetaEstimatorMixin</span> <span class="o">|</span> <span class="o">`</span><span class="nc">Object</span> <span class="o">|</span> <span class="o">`</span><span class="nc">RegressorMixin</span><span class="o">]</span> <span class="nn">Obj</span><span class="p">.</span><span class="n">t</span>
<span class="k">val</span> <span class="n">of_pyobject</span> <span class="o">:</span> <span class="nn">Py</span><span class="p">.</span><span class="nn">Object</span><span class="p">.</span><span class="n">t</span> <span class="o">-&gt;</span> <span class="n">t</span>
<span class="k">val</span> <span class="n">to_pyobject</span> <span class="o">:</span> <span class="o">[&gt;</span> <span class="n">tag</span><span class="o">]</span> <span class="nn">Obj</span><span class="p">.</span><span class="n">t</span> <span class="o">-&gt;</span> <span class="nn">Py</span><span class="p">.</span><span class="nn">Object</span><span class="p">.</span><span class="n">t</span>

<span class="k">val</span> <span class="n">as_regressor</span> <span class="o">:</span> <span class="n">t</span> <span class="o">-&gt;</span> <span class="o">[`</span><span class="nc">RegressorMixin</span><span class="o">]</span> <span class="nn">Obj</span><span class="p">.</span><span class="n">t</span>
<span class="k">val</span> <span class="n">as_meta_estimator</span> <span class="o">:</span> <span class="n">t</span> <span class="o">-&gt;</span> <span class="o">[`</span><span class="nc">MetaEstimatorMixin</span><span class="o">]</span> <span class="nn">Obj</span><span class="p">.</span><span class="n">t</span>
<span class="k">val</span> <span class="n">as_estimator</span> <span class="o">:</span> <span class="n">t</span> <span class="o">-&gt;</span> <span class="o">[`</span><span class="nc">BaseEstimator</span><span class="o">]</span> <span class="nn">Obj</span><span class="p">.</span><span class="n">t</span>
<span class="k">val</span> <span class="n">as_bagging</span> <span class="o">:</span> <span class="n">t</span> <span class="o">-&gt;</span> <span class="o">[`</span><span class="nc">BaseBagging</span><span class="o">]</span> <span class="nn">Obj</span><span class="p">.</span><span class="n">t</span>
<span class="k">val</span> <span class="n">as_ensemble</span> <span class="o">:</span> <span class="n">t</span> <span class="o">-&gt;</span> <span class="o">[`</span><span class="nc">BaseEnsemble</span><span class="o">]</span> <span class="nn">Obj</span><span class="p">.</span><span class="n">t</span>
<span class="k">val</span> <span class="n">create</span> <span class="o">:</span> <span class="o">?</span><span class="n">base_estimator</span><span class="o">:[&gt;`</span><span class="nc">BaseEstimator</span><span class="o">]</span> <span class="nn">Np</span><span class="p">.</span><span class="nn">Obj</span><span class="p">.</span><span class="n">t</span> <span class="o">-&gt;</span> <span class="o">?</span><span class="n">n_estimators</span><span class="o">:</span><span class="kt">int</span> <span class="o">-&gt;</span> <span class="o">?</span><span class="n">max_samples</span><span class="o">:[`</span><span class="nc">F</span> <span class="k">of</span> <span class="kt">float</span> <span class="o">|</span> <span class="o">`</span><span class="nc">I</span> <span class="k">of</span> <span class="kt">int</span><span class="o">]</span> <span class="o">-&gt;</span> <span class="o">?</span><span class="n">max_features</span><span class="o">:[`</span><span class="nc">F</span> <span class="k">of</span> <span class="kt">float</span> <span class="o">|</span> <span class="o">`</span><span class="nc">I</span> <span class="k">of</span> <span class="kt">int</span><span class="o">]</span> <span class="o">-&gt;</span> <span class="o">?</span><span class="n">bootstrap</span><span class="o">:</span><span class="kt">bool</span> <span class="o">-&gt;</span> <span class="o">?</span><span class="n">bootstrap_features</span><span class="o">:</span><span class="kt">bool</span> <span class="o">-&gt;</span> <span class="o">?</span><span class="n">oob_score</span><span class="o">:</span><span class="kt">bool</span> <span class="o">-&gt;</span> <span class="o">?</span><span class="n">warm_start</span><span class="o">:</span><span class="kt">bool</span> <span class="o">-&gt;</span> <span class="o">?</span><span class="n">n_jobs</span><span class="o">:</span><span class="kt">int</span> <span class="o">-&gt;</span> <span class="o">?</span><span class="n">random_state</span><span class="o">:</span><span class="kt">int</span> <span class="o">-&gt;</span> <span class="o">?</span><span class="n">verbose</span><span class="o">:</span><span class="kt">int</span> <span class="o">-&gt;</span> <span class="kt">unit</span> <span class="o">-&gt;</span> <span class="n">t</span>
</code></pre></div>

<p>A Bagging regressor.</p>
<p>A Bagging regressor is an ensemble meta-estimator that fits base
regressors each on random subsets of the original dataset and then
aggregate their individual predictions (either by voting or by averaging)
to form a final prediction. Such a meta-estimator can typically be used as
a way to reduce the variance of a black-box estimator (e.g., a decision
tree), by introducing randomization into its construction procedure and
then making an ensemble out of it.</p>
<p>This algorithm encompasses several works from the literature. When random
subsets of the dataset are drawn as random subsets of the samples, then
this algorithm is known as Pasting [1]<em>. If samples are drawn with
replacement, then the method is known as Bagging [2]</em>. When random subsets
of the dataset are drawn as random subsets of the features, then the method
is known as Random Subspaces [3]<em>. Finally, when base estimators are built
on subsets of both samples and features, then the method is known as
Random Patches [4]</em>.</p>
<p>Read more in the :ref:<code>User Guide &lt;bagging&gt;</code>.</p>
<p>.. versionadded:: 0.15</p>
<h2 id="parameters_29">Parameters<a class="headerlink" href="#parameters_29" title="Permanent link">&para;</a></h2>
<p>base_estimator : object or None, optional (default=None)
The base estimator to fit on random subsets of the dataset.
If None, then the base estimator is a decision tree.</p>
<p>n_estimators : int, optional (default=10)
The number of base estimators in the ensemble.</p>
<p>max_samples : int or float, optional (default=1.0)
The number of samples to draw from X to train each base estimator.</p>
<ul>
<li>If int, then draw <code>max_samples</code> samples.</li>
<li>If float, then draw <code>max_samples * X.shape[0]</code> samples.</li>
</ul>
<p>max_features : int or float, optional (default=1.0)
The number of features to draw from X to train each base estimator.</p>
<ul>
<li>If int, then draw <code>max_features</code> features.</li>
<li>If float, then draw <code>max_features * X.shape[1]</code> features.</li>
</ul>
<p>bootstrap : boolean, optional (default=True)
Whether samples are drawn with replacement. If False, sampling
without replacement is performed.</p>
<p>bootstrap_features : boolean, optional (default=False)
Whether features are drawn with replacement.</p>
<p>oob_score : bool
Whether to use out-of-bag samples to estimate
the generalization error.</p>
<p>warm_start : bool, optional (default=False)
When set to True, reuse the solution of the previous call to fit
and add more estimators to the ensemble, otherwise, just fit
a whole new ensemble. See :term:<code>the Glossary &lt;warm_start&gt;</code>.</p>
<p>n_jobs : int or None, optional (default=None)
The number of jobs to run in parallel for both :meth:<code>fit</code> and
:meth:<code>predict</code>. <code>None</code> means 1 unless in a
:obj:<code>joblib.parallel_backend</code> context. <code>-1</code> means using all
processors. See :term:<code>Glossary &lt;n_jobs&gt;</code> for more details.</p>
<p>random_state : int, RandomState instance or None, optional (default=None)
If int, random_state is the seed used by the random number generator;
If RandomState instance, random_state is the random number generator;
If None, the random number generator is the RandomState instance used
by <code>np.random</code>.</p>
<p>verbose : int, optional (default=0)
Controls the verbosity when fitting and predicting.</p>
<h2 id="attributes_3">Attributes<a class="headerlink" href="#attributes_3" title="Permanent link">&para;</a></h2>
<p>base_estimator_ : estimator
The base estimator from which the ensemble is grown.</p>
<p>n_features_ : int
The number of features when :meth:<code>fit</code> is performed.</p>
<p>estimators_ : list of estimators
The collection of fitted sub-estimators.</p>
<p>estimators_samples_ : list of arrays
The subset of drawn samples (i.e., the in-bag samples) for each base
estimator. Each subset is defined by an array of the indices selected.</p>
<p>estimators_features_ : list of arrays
The subset of drawn features for each base estimator.</p>
<p>oob_score_ : float
Score of the training dataset obtained using an out-of-bag estimate.
This attribute exists only when <code>oob_score</code> is True.</p>
<p>oob_prediction_ : ndarray of shape (n_samples,)
Prediction computed with out-of-bag estimate on the training
set. If n_estimators is small it might be possible that a data point
was never left out during the bootstrap. In this case,
<code>oob_prediction_</code> might contain NaN. This attribute exists only
when <code>oob_score</code> is True.</p>
<h2 id="examples_3">Examples<a class="headerlink" href="#examples_3" title="Permanent link">&para;</a></h2>
<blockquote>
<blockquote>
<blockquote>
<p>from sklearn.svm import SVR
from sklearn.ensemble import BaggingRegressor
from sklearn.datasets import make_regression
X, y = make_regression(n_samples=100, n_features=4,
...                        n_informative=2, n_targets=1,
...                        random_state=0, shuffle=False)
regr = BaggingRegressor(base_estimator=SVR(),
...                         n_estimators=10, random_state=0).fit(X, y)
regr.predict([[0, 0, 0, 0]])
array([-2.8720...])</p>
</blockquote>
</blockquote>
</blockquote>
<h2 id="references_3">References<a class="headerlink" href="#references_3" title="Permanent link">&para;</a></h2>
<p>.. [1] L. Breiman, 'Pasting small votes for classification in large
databases and on-line', Machine Learning, 36(1), 85-103, 1999.</p>
<p>.. [2] L. Breiman, 'Bagging predictors', Machine Learning, 24(2), 123-140,
1996.</p>
<p>.. [3] T. Ho, 'The random subspace method for constructing decision
forests', Pattern Analysis and Machine Intelligence, 20(8), 832-844,
1998.</p>
<p>.. [4] G. Louppe and P. Geurts, 'Ensembles on Random Patches', Machine
Learning and Knowledge Discovery in Databases, 346-361, 2012.</p>
<div class="highlight"><pre><span></span><code><span class="k">val</span> <span class="n">get_item</span> <span class="o">:</span> <span class="n">index</span><span class="o">:</span><span class="nn">Py</span><span class="p">.</span><span class="nn">Object</span><span class="p">.</span><span class="n">t</span> <span class="o">-&gt;</span> <span class="o">[&gt;</span> <span class="n">tag</span><span class="o">]</span> <span class="nn">Obj</span><span class="p">.</span><span class="n">t</span> <span class="o">-&gt;</span> <span class="nn">Py</span><span class="p">.</span><span class="nn">Object</span><span class="p">.</span><span class="n">t</span>
</code></pre></div>

<p>Return the index'th estimator in the ensemble.</p>
<div class="highlight"><pre><span></span><code><span class="k">val</span> <span class="n">iter</span> <span class="o">:</span> <span class="o">[&gt;</span> <span class="n">tag</span><span class="o">]</span> <span class="nn">Obj</span><span class="p">.</span><span class="n">t</span> <span class="o">-&gt;</span> <span class="nn">Dict</span><span class="p">.</span><span class="n">t</span> <span class="nn">Seq</span><span class="p">.</span><span class="n">t</span>
</code></pre></div>

<p>Return iterator over estimators in the ensemble.</p>
<div class="highlight"><pre><span></span><code><span class="k">val</span> <span class="n">fit</span> <span class="o">:</span> <span class="o">?</span><span class="n">sample_weight</span><span class="o">:[&gt;`</span><span class="nc">ArrayLike</span><span class="o">]</span> <span class="nn">Np</span><span class="p">.</span><span class="nn">Obj</span><span class="p">.</span><span class="n">t</span> <span class="o">-&gt;</span> <span class="n">x</span><span class="o">:[&gt;`</span><span class="nc">ArrayLike</span><span class="o">]</span> <span class="nn">Np</span><span class="p">.</span><span class="nn">Obj</span><span class="p">.</span><span class="n">t</span> <span class="o">-&gt;</span> <span class="n">y</span><span class="o">:[&gt;`</span><span class="nc">ArrayLike</span><span class="o">]</span> <span class="nn">Np</span><span class="p">.</span><span class="nn">Obj</span><span class="p">.</span><span class="n">t</span> <span class="o">-&gt;</span> <span class="o">[&gt;</span> <span class="n">tag</span><span class="o">]</span> <span class="nn">Obj</span><span class="p">.</span><span class="n">t</span> <span class="o">-&gt;</span> <span class="n">t</span>
</code></pre></div>

<p>Build a Bagging ensemble of estimators from the training
set (X, y).</p>
<h2 id="parameters_30">Parameters<a class="headerlink" href="#parameters_30" title="Permanent link">&para;</a></h2>
<p>X : {array-like, sparse matrix} of shape (n_samples, n_features)
The training input samples. Sparse matrices are accepted only if
they are supported by the base estimator.</p>
<p>y : array-like of shape (n_samples,)
The target values (class labels in classification, real numbers in
regression).</p>
<p>sample_weight : array-like of shape (n_samples,), default=None
Sample weights. If None, then samples are equally weighted.
Note that this is supported only if the base estimator supports
sample weighting.</p>
<h2 id="returns_20">Returns<a class="headerlink" href="#returns_20" title="Permanent link">&para;</a></h2>
<p>self : object</p>
<div class="highlight"><pre><span></span><code><span class="k">val</span> <span class="n">get_params</span> <span class="o">:</span> <span class="o">?</span><span class="n">deep</span><span class="o">:</span><span class="kt">bool</span> <span class="o">-&gt;</span> <span class="o">[&gt;</span> <span class="n">tag</span><span class="o">]</span> <span class="nn">Obj</span><span class="p">.</span><span class="n">t</span> <span class="o">-&gt;</span> <span class="nn">Dict</span><span class="p">.</span><span class="n">t</span>
</code></pre></div>

<p>Get parameters for this estimator.</p>
<h2 id="parameters_31">Parameters<a class="headerlink" href="#parameters_31" title="Permanent link">&para;</a></h2>
<p>deep : bool, default=True
If True, will return the parameters for this estimator and
contained subobjects that are estimators.</p>
<h2 id="returns_21">Returns<a class="headerlink" href="#returns_21" title="Permanent link">&para;</a></h2>
<p>params : mapping of string to any
Parameter names mapped to their values.</p>
<div class="highlight"><pre><span></span><code><span class="k">val</span> <span class="n">predict</span> <span class="o">:</span> <span class="n">x</span><span class="o">:[&gt;`</span><span class="nc">ArrayLike</span><span class="o">]</span> <span class="nn">Np</span><span class="p">.</span><span class="nn">Obj</span><span class="p">.</span><span class="n">t</span> <span class="o">-&gt;</span> <span class="o">[&gt;</span> <span class="n">tag</span><span class="o">]</span> <span class="nn">Obj</span><span class="p">.</span><span class="n">t</span> <span class="o">-&gt;</span> <span class="o">[&gt;`</span><span class="nc">ArrayLike</span><span class="o">]</span> <span class="nn">Np</span><span class="p">.</span><span class="nn">Obj</span><span class="p">.</span><span class="n">t</span>
</code></pre></div>

<p>Predict regression target for X.</p>
<p>The predicted regression target of an input sample is computed as the
mean predicted regression targets of the estimators in the ensemble.</p>
<h2 id="parameters_32">Parameters<a class="headerlink" href="#parameters_32" title="Permanent link">&para;</a></h2>
<p>X : {array-like, sparse matrix} of shape (n_samples, n_features)
The training input samples. Sparse matrices are accepted only if
they are supported by the base estimator.</p>
<h2 id="returns_22">Returns<a class="headerlink" href="#returns_22" title="Permanent link">&para;</a></h2>
<p>y : ndarray of shape (n_samples,)
The predicted values.</p>
<div class="highlight"><pre><span></span><code><span class="k">val</span> <span class="n">score</span> <span class="o">:</span> <span class="o">?</span><span class="n">sample_weight</span><span class="o">:[&gt;`</span><span class="nc">ArrayLike</span><span class="o">]</span> <span class="nn">Np</span><span class="p">.</span><span class="nn">Obj</span><span class="p">.</span><span class="n">t</span> <span class="o">-&gt;</span> <span class="n">x</span><span class="o">:[&gt;`</span><span class="nc">ArrayLike</span><span class="o">]</span> <span class="nn">Np</span><span class="p">.</span><span class="nn">Obj</span><span class="p">.</span><span class="n">t</span> <span class="o">-&gt;</span> <span class="n">y</span><span class="o">:[&gt;`</span><span class="nc">ArrayLike</span><span class="o">]</span> <span class="nn">Np</span><span class="p">.</span><span class="nn">Obj</span><span class="p">.</span><span class="n">t</span> <span class="o">-&gt;</span> <span class="o">[&gt;</span> <span class="n">tag</span><span class="o">]</span> <span class="nn">Obj</span><span class="p">.</span><span class="n">t</span> <span class="o">-&gt;</span> <span class="kt">float</span>
</code></pre></div>

<p>Return the coefficient of determination R^2 of the prediction.</p>
<p>The coefficient R^2 is defined as (1 - u/v), where u is the residual
sum of squares ((y_true - y_pred) <strong> 2).sum() and v is the total
sum of squares ((y_true - y_true.mean()) </strong> 2).sum().
The best possible score is 1.0 and it can be negative (because the
model can be arbitrarily worse). A constant model that always
predicts the expected value of y, disregarding the input features,
would get a R^2 score of 0.0.</p>
<h2 id="parameters_33">Parameters<a class="headerlink" href="#parameters_33" title="Permanent link">&para;</a></h2>
<p>X : array-like of shape (n_samples, n_features)
Test samples. For some estimators this may be a
precomputed kernel matrix or a list of generic objects instead,
shape = (n_samples, n_samples_fitted),
where n_samples_fitted is the number of
samples used in the fitting for the estimator.</p>
<p>y : array-like of shape (n_samples,) or (n_samples, n_outputs)
True values for X.</p>
<p>sample_weight : array-like of shape (n_samples,), default=None
Sample weights.</p>
<h2 id="returns_23">Returns<a class="headerlink" href="#returns_23" title="Permanent link">&para;</a></h2>
<p>score : float
R^2 of self.predict(X) wrt. y.</p>
<h2 id="notes_1">Notes<a class="headerlink" href="#notes_1" title="Permanent link">&para;</a></h2>
<p>The R2 score used when calling <code>score</code> on a regressor will use
<code>multioutput='uniform_average'</code> from version 0.23 to keep consistent
with :func:<code>~sklearn.metrics.r2_score</code>. This will influence the
<code>score</code> method of all the multioutput regressors (except for
:class:<code>~sklearn.multioutput.MultiOutputRegressor</code>). To specify the
default value manually and avoid the warning, please either call
:func:<code>~sklearn.metrics.r2_score</code> directly or make a custom scorer with
:func:<code>~sklearn.metrics.make_scorer</code> (the built-in scorer <code>'r2'</code> uses
<code>multioutput='uniform_average'</code>).</p>
<div class="highlight"><pre><span></span><code><span class="k">val</span> <span class="n">set_params</span> <span class="o">:</span> <span class="o">?</span><span class="n">params</span><span class="o">:(</span><span class="kt">string</span> <span class="o">*</span> <span class="nn">Py</span><span class="p">.</span><span class="nn">Object</span><span class="p">.</span><span class="n">t</span><span class="o">)</span> <span class="kt">list</span> <span class="o">-&gt;</span> <span class="o">[&gt;</span> <span class="n">tag</span><span class="o">]</span> <span class="nn">Obj</span><span class="p">.</span><span class="n">t</span> <span class="o">-&gt;</span> <span class="n">t</span>
</code></pre></div>

<p>Set the parameters of this estimator.</p>
<p>The method works on simple estimators as well as on nested objects
(such as pipelines). The latter have parameters of the form
<code>&lt;component&gt;__&lt;parameter&gt;</code> so that it's possible to update each
component of a nested object.</p>
<h2 id="parameters_34">Parameters<a class="headerlink" href="#parameters_34" title="Permanent link">&para;</a></h2>
<p>**params : dict
Estimator parameters.</p>
<h2 id="returns_24">Returns<a class="headerlink" href="#returns_24" title="Permanent link">&para;</a></h2>
<p>self : object
Estimator instance.</p>
<p>Attribute base_estimator_: get value or raise Not_found if None.</p>
<div class="highlight"><pre><span></span><code><span class="k">val</span> <span class="n">base_estimator_</span> <span class="o">:</span> <span class="n">t</span> <span class="o">-&gt;</span> <span class="o">[`</span><span class="nc">BaseEstimator</span><span class="o">|`</span><span class="nc">Object</span><span class="o">]</span> <span class="nn">Np</span><span class="p">.</span><span class="nn">Obj</span><span class="p">.</span><span class="n">t</span>
</code></pre></div>

<p>Attribute base_estimator_: get value as an option.</p>
<div class="highlight"><pre><span></span><code><span class="k">val</span> <span class="n">base_estimator_opt</span> <span class="o">:</span> <span class="n">t</span> <span class="o">-&gt;</span> <span class="o">([`</span><span class="nc">BaseEstimator</span><span class="o">|`</span><span class="nc">Object</span><span class="o">]</span> <span class="nn">Np</span><span class="p">.</span><span class="nn">Obj</span><span class="p">.</span><span class="n">t</span><span class="o">)</span> <span class="n">option</span>
</code></pre></div>

<p>Attribute n_features_: get value or raise Not_found if None.</p>
<div class="highlight"><pre><span></span><code><span class="k">val</span> <span class="n">n_features_</span> <span class="o">:</span> <span class="n">t</span> <span class="o">-&gt;</span> <span class="kt">int</span>
</code></pre></div>

<p>Attribute n_features_: get value as an option.</p>
<div class="highlight"><pre><span></span><code><span class="k">val</span> <span class="n">n_features_opt</span> <span class="o">:</span> <span class="n">t</span> <span class="o">-&gt;</span> <span class="o">(</span><span class="kt">int</span><span class="o">)</span> <span class="n">option</span>
</code></pre></div>

<p>Attribute estimators_: get value or raise Not_found if None.</p>
<div class="highlight"><pre><span></span><code><span class="k">val</span> <span class="n">estimators_</span> <span class="o">:</span> <span class="n">t</span> <span class="o">-&gt;</span> <span class="o">[`</span><span class="nc">BaseEstimator</span><span class="o">|`</span><span class="nc">Object</span><span class="o">]</span> <span class="nn">Np</span><span class="p">.</span><span class="nn">Obj</span><span class="p">.</span><span class="n">t</span> <span class="kt">list</span>
</code></pre></div>

<p>Attribute estimators_: get value as an option.</p>
<div class="highlight"><pre><span></span><code><span class="k">val</span> <span class="n">estimators_opt</span> <span class="o">:</span> <span class="n">t</span> <span class="o">-&gt;</span> <span class="o">([`</span><span class="nc">BaseEstimator</span><span class="o">|`</span><span class="nc">Object</span><span class="o">]</span> <span class="nn">Np</span><span class="p">.</span><span class="nn">Obj</span><span class="p">.</span><span class="n">t</span> <span class="kt">list</span><span class="o">)</span> <span class="n">option</span>
</code></pre></div>

<p>Attribute estimators_samples_: get value or raise Not_found if None.</p>
<div class="highlight"><pre><span></span><code><span class="k">val</span> <span class="n">estimators_samples_</span> <span class="o">:</span> <span class="n">t</span> <span class="o">-&gt;</span> <span class="nn">Np</span><span class="p">.</span><span class="nn">Numpy</span><span class="p">.</span><span class="nn">Ndarray</span><span class="p">.</span><span class="nn">List</span><span class="p">.</span><span class="n">t</span>
</code></pre></div>

<p>Attribute estimators_samples_: get value as an option.</p>
<div class="highlight"><pre><span></span><code><span class="k">val</span> <span class="n">estimators_samples_opt</span> <span class="o">:</span> <span class="n">t</span> <span class="o">-&gt;</span> <span class="o">(</span><span class="nn">Np</span><span class="p">.</span><span class="nn">Numpy</span><span class="p">.</span><span class="nn">Ndarray</span><span class="p">.</span><span class="nn">List</span><span class="p">.</span><span class="n">t</span><span class="o">)</span> <span class="n">option</span>
</code></pre></div>

<p>Attribute estimators_features_: get value or raise Not_found if None.</p>
<div class="highlight"><pre><span></span><code><span class="k">val</span> <span class="n">estimators_features_</span> <span class="o">:</span> <span class="n">t</span> <span class="o">-&gt;</span> <span class="nn">Np</span><span class="p">.</span><span class="nn">Numpy</span><span class="p">.</span><span class="nn">Ndarray</span><span class="p">.</span><span class="nn">List</span><span class="p">.</span><span class="n">t</span>
</code></pre></div>

<p>Attribute estimators_features_: get value as an option.</p>
<div class="highlight"><pre><span></span><code><span class="k">val</span> <span class="n">estimators_features_opt</span> <span class="o">:</span> <span class="n">t</span> <span class="o">-&gt;</span> <span class="o">(</span><span class="nn">Np</span><span class="p">.</span><span class="nn">Numpy</span><span class="p">.</span><span class="nn">Ndarray</span><span class="p">.</span><span class="nn">List</span><span class="p">.</span><span class="n">t</span><span class="o">)</span> <span class="n">option</span>
</code></pre></div>

<p>Attribute oob_score_: get value or raise Not_found if None.</p>
<div class="highlight"><pre><span></span><code><span class="k">val</span> <span class="n">oob_score_</span> <span class="o">:</span> <span class="n">t</span> <span class="o">-&gt;</span> <span class="kt">float</span>
</code></pre></div>

<p>Attribute oob_score_: get value as an option.</p>
<div class="highlight"><pre><span></span><code><span class="k">val</span> <span class="n">oob_score_opt</span> <span class="o">:</span> <span class="n">t</span> <span class="o">-&gt;</span> <span class="o">(</span><span class="kt">float</span><span class="o">)</span> <span class="n">option</span>
</code></pre></div>

<p>Attribute oob_prediction_: get value or raise Not_found if None.</p>
<div class="highlight"><pre><span></span><code><span class="k">val</span> <span class="n">oob_prediction_</span> <span class="o">:</span> <span class="n">t</span> <span class="o">-&gt;</span> <span class="o">[&gt;`</span><span class="nc">ArrayLike</span><span class="o">]</span> <span class="nn">Np</span><span class="p">.</span><span class="nn">Obj</span><span class="p">.</span><span class="n">t</span>
</code></pre></div>

<p>Attribute oob_prediction_: get value as an option.</p>
<div class="highlight"><pre><span></span><code><span class="k">val</span> <span class="n">oob_prediction_opt</span> <span class="o">:</span> <span class="n">t</span> <span class="o">-&gt;</span> <span class="o">([&gt;`</span><span class="nc">ArrayLike</span><span class="o">]</span> <span class="nn">Np</span><span class="p">.</span><span class="nn">Obj</span><span class="p">.</span><span class="n">t</span><span class="o">)</span> <span class="n">option</span>
</code></pre></div>

<p>Print the object to a human-readable representation.</p>
<div class="highlight"><pre><span></span><code><span class="k">val</span> <span class="n">to_string</span> <span class="o">:</span> <span class="n">t</span> <span class="o">-&gt;</span> <span class="kt">string</span>
</code></pre></div>

<p>Print the object to a human-readable representation.</p>
<div class="highlight"><pre><span></span><code><span class="k">val</span> <span class="n">show</span> <span class="o">:</span> <span class="n">t</span> <span class="o">-&gt;</span> <span class="kt">string</span>
</code></pre></div>

<p>Pretty-print the object to a formatter.</p>
<div class="highlight"><pre><span></span><code><span class="k">val</span> <span class="n">pp</span> <span class="o">:</span> <span class="nn">Format</span><span class="p">.</span><span class="n">formatter</span> <span class="o">-&gt;</span> <span class="n">t</span> <span class="o">-&gt;</span> <span class="kt">unit</span> <span class="o">[@@</span><span class="n">ocaml</span><span class="o">.</span><span class="n">toplevel_printer</span><span class="o">]</span>



<span class="k">module</span> <span class="nc">BaseEnsemble</span> <span class="o">:</span> <span class="k">sig</span>
<span class="k">type</span> <span class="n">tag</span> <span class="o">=</span> <span class="o">[`</span><span class="nc">BaseEnsemble</span><span class="o">]</span>
<span class="k">type</span> <span class="n">t</span> <span class="o">=</span> <span class="o">[`</span><span class="nc">BaseEnsemble</span> <span class="o">|</span> <span class="o">`</span><span class="nc">BaseEstimator</span> <span class="o">|</span> <span class="o">`</span><span class="nc">MetaEstimatorMixin</span> <span class="o">|</span> <span class="o">`</span><span class="nc">Object</span><span class="o">]</span> <span class="nn">Obj</span><span class="p">.</span><span class="n">t</span>
<span class="k">val</span> <span class="n">of_pyobject</span> <span class="o">:</span> <span class="nn">Py</span><span class="p">.</span><span class="nn">Object</span><span class="p">.</span><span class="n">t</span> <span class="o">-&gt;</span> <span class="n">t</span>
<span class="k">val</span> <span class="n">to_pyobject</span> <span class="o">:</span> <span class="o">[&gt;</span> <span class="n">tag</span><span class="o">]</span> <span class="nn">Obj</span><span class="p">.</span><span class="n">t</span> <span class="o">-&gt;</span> <span class="nn">Py</span><span class="p">.</span><span class="nn">Object</span><span class="p">.</span><span class="n">t</span>

<span class="k">val</span> <span class="n">as_estimator</span> <span class="o">:</span> <span class="n">t</span> <span class="o">-&gt;</span> <span class="o">[`</span><span class="nc">BaseEstimator</span><span class="o">]</span> <span class="nn">Obj</span><span class="p">.</span><span class="n">t</span>
<span class="k">val</span> <span class="n">as_meta_estimator</span> <span class="o">:</span> <span class="n">t</span> <span class="o">-&gt;</span> <span class="o">[`</span><span class="nc">MetaEstimatorMixin</span><span class="o">]</span> <span class="nn">Obj</span><span class="p">.</span><span class="n">t</span>
<span class="k">val</span> <span class="n">get_item</span> <span class="o">:</span> <span class="n">index</span><span class="o">:</span><span class="nn">Py</span><span class="p">.</span><span class="nn">Object</span><span class="p">.</span><span class="n">t</span> <span class="o">-&gt;</span> <span class="o">[&gt;</span> <span class="n">tag</span><span class="o">]</span> <span class="nn">Obj</span><span class="p">.</span><span class="n">t</span> <span class="o">-&gt;</span> <span class="nn">Py</span><span class="p">.</span><span class="nn">Object</span><span class="p">.</span><span class="n">t</span>
</code></pre></div>

<p>Return the index'th estimator in the ensemble.</p>
<div class="highlight"><pre><span></span><code><span class="k">val</span> <span class="n">iter</span> <span class="o">:</span> <span class="o">[&gt;</span> <span class="n">tag</span><span class="o">]</span> <span class="nn">Obj</span><span class="p">.</span><span class="n">t</span> <span class="o">-&gt;</span> <span class="nn">Dict</span><span class="p">.</span><span class="n">t</span> <span class="nn">Seq</span><span class="p">.</span><span class="n">t</span>
</code></pre></div>

<p>Return iterator over estimators in the ensemble.</p>
<div class="highlight"><pre><span></span><code><span class="k">val</span> <span class="n">get_params</span> <span class="o">:</span> <span class="o">?</span><span class="n">deep</span><span class="o">:</span><span class="kt">bool</span> <span class="o">-&gt;</span> <span class="o">[&gt;</span> <span class="n">tag</span><span class="o">]</span> <span class="nn">Obj</span><span class="p">.</span><span class="n">t</span> <span class="o">-&gt;</span> <span class="nn">Dict</span><span class="p">.</span><span class="n">t</span>
</code></pre></div>

<p>Get parameters for this estimator.</p>
<h2 id="parameters_35">Parameters<a class="headerlink" href="#parameters_35" title="Permanent link">&para;</a></h2>
<p>deep : bool, default=True
If True, will return the parameters for this estimator and
contained subobjects that are estimators.</p>
<h2 id="returns_25">Returns<a class="headerlink" href="#returns_25" title="Permanent link">&para;</a></h2>
<p>params : mapping of string to any
Parameter names mapped to their values.</p>
<div class="highlight"><pre><span></span><code><span class="k">val</span> <span class="n">set_params</span> <span class="o">:</span> <span class="o">?</span><span class="n">params</span><span class="o">:(</span><span class="kt">string</span> <span class="o">*</span> <span class="nn">Py</span><span class="p">.</span><span class="nn">Object</span><span class="p">.</span><span class="n">t</span><span class="o">)</span> <span class="kt">list</span> <span class="o">-&gt;</span> <span class="o">[&gt;</span> <span class="n">tag</span><span class="o">]</span> <span class="nn">Obj</span><span class="p">.</span><span class="n">t</span> <span class="o">-&gt;</span> <span class="n">t</span>
</code></pre></div>

<p>Set the parameters of this estimator.</p>
<p>The method works on simple estimators as well as on nested objects
(such as pipelines). The latter have parameters of the form
<code>&lt;component&gt;__&lt;parameter&gt;</code> so that it's possible to update each
component of a nested object.</p>
<h2 id="parameters_36">Parameters<a class="headerlink" href="#parameters_36" title="Permanent link">&para;</a></h2>
<p>**params : dict
Estimator parameters.</p>
<h2 id="returns_26">Returns<a class="headerlink" href="#returns_26" title="Permanent link">&para;</a></h2>
<p>self : object
Estimator instance.</p>
<p>Attribute base_estimator_: get value or raise Not_found if None.</p>
<div class="highlight"><pre><span></span><code><span class="k">val</span> <span class="n">base_estimator_</span> <span class="o">:</span> <span class="n">t</span> <span class="o">-&gt;</span> <span class="o">[`</span><span class="nc">BaseEstimator</span><span class="o">|`</span><span class="nc">Object</span><span class="o">]</span> <span class="nn">Np</span><span class="p">.</span><span class="nn">Obj</span><span class="p">.</span><span class="n">t</span>
</code></pre></div>

<p>Attribute base_estimator_: get value as an option.</p>
<div class="highlight"><pre><span></span><code><span class="k">val</span> <span class="n">base_estimator_opt</span> <span class="o">:</span> <span class="n">t</span> <span class="o">-&gt;</span> <span class="o">([`</span><span class="nc">BaseEstimator</span><span class="o">|`</span><span class="nc">Object</span><span class="o">]</span> <span class="nn">Np</span><span class="p">.</span><span class="nn">Obj</span><span class="p">.</span><span class="n">t</span><span class="o">)</span> <span class="n">option</span>
</code></pre></div>

<p>Attribute estimators_: get value or raise Not_found if None.</p>
<div class="highlight"><pre><span></span><code><span class="k">val</span> <span class="n">estimators_</span> <span class="o">:</span> <span class="n">t</span> <span class="o">-&gt;</span> <span class="o">[`</span><span class="nc">BaseEstimator</span><span class="o">|`</span><span class="nc">Object</span><span class="o">]</span> <span class="nn">Np</span><span class="p">.</span><span class="nn">Obj</span><span class="p">.</span><span class="n">t</span> <span class="kt">list</span>
</code></pre></div>

<p>Attribute estimators_: get value as an option.</p>
<div class="highlight"><pre><span></span><code><span class="k">val</span> <span class="n">estimators_opt</span> <span class="o">:</span> <span class="n">t</span> <span class="o">-&gt;</span> <span class="o">([`</span><span class="nc">BaseEstimator</span><span class="o">|`</span><span class="nc">Object</span><span class="o">]</span> <span class="nn">Np</span><span class="p">.</span><span class="nn">Obj</span><span class="p">.</span><span class="n">t</span> <span class="kt">list</span><span class="o">)</span> <span class="n">option</span>
</code></pre></div>

<p>Print the object to a human-readable representation.</p>
<div class="highlight"><pre><span></span><code><span class="k">val</span> <span class="n">to_string</span> <span class="o">:</span> <span class="n">t</span> <span class="o">-&gt;</span> <span class="kt">string</span>
</code></pre></div>

<p>Print the object to a human-readable representation.</p>
<div class="highlight"><pre><span></span><code><span class="k">val</span> <span class="n">show</span> <span class="o">:</span> <span class="n">t</span> <span class="o">-&gt;</span> <span class="kt">string</span>
</code></pre></div>

<p>Pretty-print the object to a formatter.</p>
<div class="highlight"><pre><span></span><code><span class="k">val</span> <span class="n">pp</span> <span class="o">:</span> <span class="nn">Format</span><span class="p">.</span><span class="n">formatter</span> <span class="o">-&gt;</span> <span class="n">t</span> <span class="o">-&gt;</span> <span class="kt">unit</span> <span class="o">[@@</span><span class="n">ocaml</span><span class="o">.</span><span class="n">toplevel_printer</span><span class="o">]</span>



<span class="k">module</span> <span class="nc">ExtraTreesClassifier</span> <span class="o">:</span> <span class="k">sig</span>
<span class="k">type</span> <span class="n">tag</span> <span class="o">=</span> <span class="o">[`</span><span class="nc">ExtraTreesClassifier</span><span class="o">]</span>
<span class="k">type</span> <span class="n">t</span> <span class="o">=</span> <span class="o">[`</span><span class="nc">BaseEnsemble</span> <span class="o">|</span> <span class="o">`</span><span class="nc">BaseEstimator</span> <span class="o">|</span> <span class="o">`</span><span class="nc">BaseForest</span> <span class="o">|</span> <span class="o">`</span><span class="nc">ClassifierMixin</span> <span class="o">|</span> <span class="o">`</span><span class="nc">ExtraTreesClassifier</span> <span class="o">|</span> <span class="o">`</span><span class="nc">MetaEstimatorMixin</span> <span class="o">|</span> <span class="o">`</span><span class="nc">MultiOutputMixin</span> <span class="o">|</span> <span class="o">`</span><span class="nc">Object</span><span class="o">]</span> <span class="nn">Obj</span><span class="p">.</span><span class="n">t</span>
<span class="k">val</span> <span class="n">of_pyobject</span> <span class="o">:</span> <span class="nn">Py</span><span class="p">.</span><span class="nn">Object</span><span class="p">.</span><span class="n">t</span> <span class="o">-&gt;</span> <span class="n">t</span>
<span class="k">val</span> <span class="n">to_pyobject</span> <span class="o">:</span> <span class="o">[&gt;</span> <span class="n">tag</span><span class="o">]</span> <span class="nn">Obj</span><span class="p">.</span><span class="n">t</span> <span class="o">-&gt;</span> <span class="nn">Py</span><span class="p">.</span><span class="nn">Object</span><span class="p">.</span><span class="n">t</span>

<span class="k">val</span> <span class="n">as_classifier</span> <span class="o">:</span> <span class="n">t</span> <span class="o">-&gt;</span> <span class="o">[`</span><span class="nc">ClassifierMixin</span><span class="o">]</span> <span class="nn">Obj</span><span class="p">.</span><span class="n">t</span>
<span class="k">val</span> <span class="n">as_multi_output</span> <span class="o">:</span> <span class="n">t</span> <span class="o">-&gt;</span> <span class="o">[`</span><span class="nc">MultiOutputMixin</span><span class="o">]</span> <span class="nn">Obj</span><span class="p">.</span><span class="n">t</span>
<span class="k">val</span> <span class="n">as_meta_estimator</span> <span class="o">:</span> <span class="n">t</span> <span class="o">-&gt;</span> <span class="o">[`</span><span class="nc">MetaEstimatorMixin</span><span class="o">]</span> <span class="nn">Obj</span><span class="p">.</span><span class="n">t</span>
<span class="k">val</span> <span class="n">as_estimator</span> <span class="o">:</span> <span class="n">t</span> <span class="o">-&gt;</span> <span class="o">[`</span><span class="nc">BaseEstimator</span><span class="o">]</span> <span class="nn">Obj</span><span class="p">.</span><span class="n">t</span>
<span class="k">val</span> <span class="n">as_ensemble</span> <span class="o">:</span> <span class="n">t</span> <span class="o">-&gt;</span> <span class="o">[`</span><span class="nc">BaseEnsemble</span><span class="o">]</span> <span class="nn">Obj</span><span class="p">.</span><span class="n">t</span>
<span class="k">val</span> <span class="n">as_forest</span> <span class="o">:</span> <span class="n">t</span> <span class="o">-&gt;</span> <span class="o">[`</span><span class="nc">BaseForest</span><span class="o">]</span> <span class="nn">Obj</span><span class="p">.</span><span class="n">t</span>
<span class="k">val</span> <span class="n">create</span> <span class="o">:</span> <span class="o">?</span><span class="n">n_estimators</span><span class="o">:</span><span class="kt">int</span> <span class="o">-&gt;</span> <span class="o">?</span><span class="n">criterion</span><span class="o">:</span><span class="kt">string</span> <span class="o">-&gt;</span> <span class="o">?</span><span class="n">max_depth</span><span class="o">:</span><span class="kt">int</span> <span class="o">-&gt;</span> <span class="o">?</span><span class="n">min_samples_split</span><span class="o">:[`</span><span class="nc">F</span> <span class="k">of</span> <span class="kt">float</span> <span class="o">|</span> <span class="o">`</span><span class="nc">I</span> <span class="k">of</span> <span class="kt">int</span><span class="o">]</span> <span class="o">-&gt;</span> <span class="o">?</span><span class="n">min_samples_leaf</span><span class="o">:[`</span><span class="nc">F</span> <span class="k">of</span> <span class="kt">float</span> <span class="o">|</span> <span class="o">`</span><span class="nc">I</span> <span class="k">of</span> <span class="kt">int</span><span class="o">]</span> <span class="o">-&gt;</span> <span class="o">?</span><span class="n">min_weight_fraction_leaf</span><span class="o">:</span><span class="kt">float</span> <span class="o">-&gt;</span> <span class="o">?</span><span class="n">max_features</span><span class="o">:[`</span><span class="nc">F</span> <span class="k">of</span> <span class="kt">float</span> <span class="o">|</span> <span class="o">`</span><span class="nc">S</span> <span class="k">of</span> <span class="kt">string</span> <span class="o">|</span> <span class="o">`</span><span class="nc">I</span> <span class="k">of</span> <span class="kt">int</span> <span class="o">|</span> <span class="o">`</span><span class="nc">None</span><span class="o">]</span> <span class="o">-&gt;</span> <span class="o">?</span><span class="n">max_leaf_nodes</span><span class="o">:</span><span class="kt">int</span> <span class="o">-&gt;</span> <span class="o">?</span><span class="n">min_impurity_decrease</span><span class="o">:</span><span class="kt">float</span> <span class="o">-&gt;</span> <span class="o">?</span><span class="n">min_impurity_split</span><span class="o">:</span><span class="kt">float</span> <span class="o">-&gt;</span> <span class="o">?</span><span class="n">bootstrap</span><span class="o">:</span><span class="kt">bool</span> <span class="o">-&gt;</span> <span class="o">?</span><span class="n">oob_score</span><span class="o">:</span><span class="kt">bool</span> <span class="o">-&gt;</span> <span class="o">?</span><span class="n">n_jobs</span><span class="o">:</span><span class="kt">int</span> <span class="o">-&gt;</span> <span class="o">?</span><span class="n">random_state</span><span class="o">:</span><span class="kt">int</span> <span class="o">-&gt;</span> <span class="o">?</span><span class="n">verbose</span><span class="o">:</span><span class="kt">int</span> <span class="o">-&gt;</span> <span class="o">?</span><span class="n">warm_start</span><span class="o">:</span><span class="kt">bool</span> <span class="o">-&gt;</span> <span class="o">?</span><span class="n">class_weight</span><span class="o">:[`</span><span class="nc">List_of_dicts</span> <span class="k">of</span> <span class="nn">Py</span><span class="p">.</span><span class="nn">Object</span><span class="p">.</span><span class="n">t</span> <span class="o">|</span> <span class="o">`</span><span class="nc">Balanced_subsample</span> <span class="o">|</span> <span class="o">`</span><span class="nc">DictIntToFloat</span> <span class="k">of</span> <span class="o">(</span><span class="kt">int</span> <span class="o">*</span> <span class="kt">float</span><span class="o">)</span> <span class="kt">list</span> <span class="o">|</span> <span class="o">`</span><span class="nc">Balanced</span><span class="o">]</span> <span class="o">-&gt;</span> <span class="o">?</span><span class="n">ccp_alpha</span><span class="o">:</span><span class="kt">float</span> <span class="o">-&gt;</span> <span class="o">?</span><span class="n">max_samples</span><span class="o">:[`</span><span class="nc">F</span> <span class="k">of</span> <span class="kt">float</span> <span class="o">|</span> <span class="o">`</span><span class="nc">I</span> <span class="k">of</span> <span class="kt">int</span><span class="o">]</span> <span class="o">-&gt;</span> <span class="kt">unit</span> <span class="o">-&gt;</span> <span class="n">t</span>
</code></pre></div>

<p>An extra-trees classifier.</p>
<p>This class implements a meta estimator that fits a number of
randomized decision trees (a.k.a. extra-trees) on various sub-samples
of the dataset and uses averaging to improve the predictive accuracy
and control over-fitting.</p>
<p>Read more in the :ref:<code>User Guide &lt;forest&gt;</code>.</p>
<h2 id="parameters_37">Parameters<a class="headerlink" href="#parameters_37" title="Permanent link">&para;</a></h2>
<p>n_estimators : integer, optional (default=10)
The number of trees in the forest.</p>
<p>.. versionchanged:: 0.22
The default value of <code>n_estimators</code> changed from 10 to 100
in 0.22.</p>
<p>criterion : string, optional (default='gini')
The function to measure the quality of a split. Supported criteria are
'gini' for the Gini impurity and 'entropy' for the information gain.</p>
<p>max_depth : integer or None, optional (default=None)
The maximum depth of the tree. If None, then nodes are expanded until
all leaves are pure or until all leaves contain less than
min_samples_split samples.</p>
<p>min_samples_split : int, float, optional (default=2)
The minimum number of samples required to split an internal node:</p>
<ul>
<li>If int, then consider <code>min_samples_split</code> as the minimum number.</li>
<li>If float, then <code>min_samples_split</code> is a fraction and
<code>ceil(min_samples_split * n_samples)</code> are the minimum
number of samples for each split.</li>
</ul>
<p>.. versionchanged:: 0.18
Added float values for fractions.</p>
<p>min_samples_leaf : int, float, optional (default=1)
The minimum number of samples required to be at a leaf node.
A split point at any depth will only be considered if it leaves at
least <code>min_samples_leaf</code> training samples in each of the left and
right branches.  This may have the effect of smoothing the model,
especially in regression.</p>
<ul>
<li>If int, then consider <code>min_samples_leaf</code> as the minimum number.</li>
<li>If float, then <code>min_samples_leaf</code> is a fraction and
<code>ceil(min_samples_leaf * n_samples)</code> are the minimum
number of samples for each node.</li>
</ul>
<p>.. versionchanged:: 0.18
Added float values for fractions.</p>
<p>min_weight_fraction_leaf : float, optional (default=0.)
The minimum weighted fraction of the sum total of weights (of all
the input samples) required to be at a leaf node. Samples have
equal weight when sample_weight is not provided.</p>
<p>max_features : int, float, string or None, optional (default='auto')
The number of features to consider when looking for the best split:</p>
<ul>
<li>If int, then consider <code>max_features</code> features at each split.</li>
<li>If float, then <code>max_features</code> is a fraction and
<code>int(max_features * n_features)</code> features are considered at each
split.</li>
<li>If 'auto', then <code>max_features=sqrt(n_features)</code>.</li>
<li>If 'sqrt', then <code>max_features=sqrt(n_features)</code>.</li>
<li>If 'log2', then <code>max_features=log2(n_features)</code>.</li>
<li>If None, then <code>max_features=n_features</code>.</li>
</ul>
<p>Note: the search for a split does not stop until at least one
valid partition of the node samples is found, even if it requires to
effectively inspect more than <code>max_features</code> features.</p>
<p>max_leaf_nodes : int or None, optional (default=None)
Grow trees with <code>max_leaf_nodes</code> in best-first fashion.
Best nodes are defined as relative reduction in impurity.
If None then unlimited number of leaf nodes.</p>
<p>min_impurity_decrease : float, optional (default=0.)
A node will be split if this split induces a decrease of the impurity
greater than or equal to this value.</p>
<p>The weighted impurity decrease equation is the following::</p>
<p>N_t / N * (impurity - N_t_R / N_t * right_impurity
- N_t_L / N_t * left_impurity)</p>
<p>where <code>N</code> is the total number of samples, <code>N_t</code> is the number of
samples at the current node, <code>N_t_L</code> is the number of samples in the
left child, and <code>N_t_R</code> is the number of samples in the right child.</p>
<p><code>N</code>, <code>N_t</code>, <code>N_t_R</code> and <code>N_t_L</code> all refer to the weighted sum,
if <code>sample_weight</code> is passed.</p>
<p>.. versionadded:: 0.19</p>
<p>min_impurity_split : float, (default=1e-7)
Threshold for early stopping in tree growth. A node will split
if its impurity is above the threshold, otherwise it is a leaf.</p>
<p>.. deprecated:: 0.19
<code>min_impurity_split</code> has been deprecated in favor of
<code>min_impurity_decrease</code> in 0.19. The default value of
<code>min_impurity_split</code> will change from 1e-7 to 0 in 0.23 and it
will be removed in 0.25. Use <code>min_impurity_decrease</code> instead.</p>
<p>bootstrap : boolean, optional (default=False)
Whether bootstrap samples are used when building trees. If False, the
whole dataset is used to build each tree.</p>
<p>oob_score : bool, optional (default=False)
Whether to use out-of-bag samples to estimate
the generalization accuracy.</p>
<p>n_jobs : int or None, optional (default=None)
The number of jobs to run in parallel. :meth:<code>fit</code>, :meth:<code>predict</code>,
:meth:<code>decision_path</code> and :meth:<code>apply</code> are all parallelized over the
trees. <code>None</code> means 1 unless in a :obj:<code>joblib.parallel_backend</code>
context. <code>-1</code> means using all processors. See :term:<code>Glossary
&lt;n_jobs&gt;</code> for more details.</p>
<p>random_state : int, RandomState instance or None, optional (default=None)
Controls 3 sources of randomness:</p>
<ul>
<li>the bootstrapping of the samples used when building trees
(if <code>bootstrap=True</code>)</li>
<li>the sampling of the features to consider when looking for the best
split at each node (if <code>max_features &lt; n_features</code>)</li>
<li>the draw of the splits for each of the <code>max_features</code></li>
</ul>
<p>See :term:<code>Glossary &lt;random_state&gt;</code> for details.</p>
<p>verbose : int, optional (default=0)
Controls the verbosity when fitting and predicting.</p>
<p>warm_start : bool, optional (default=False)
When set to <code>True</code>, reuse the solution of the previous call to fit
and add more estimators to the ensemble, otherwise, just fit a whole
new forest. See :term:<code>the Glossary &lt;warm_start&gt;</code>.</p>
<p>class_weight : dict, list of dicts, 'balanced', 'balanced_subsample' or     None, optional (default=None)
Weights associated with classes in the form <code>{class_label: weight}</code>.
If not given, all classes are supposed to have weight one. For
multi-output problems, a list of dicts can be provided in the same
order as the columns of y.</p>
<p>Note that for multioutput (including multilabel) weights should be
defined for each class of every column in its own dict. For example,
for four-class multilabel classification weights should be
[{0: 1, 1: 1}, {0: 1, 1: 5}, {0: 1, 1: 1}, {0: 1, 1: 1}] instead of
[{1:1}, {2:5}, {3:1}, {4:1}].</p>
<p>The 'balanced' mode uses the values of y to automatically adjust
weights inversely proportional to class frequencies in the input data
as <code>n_samples / (n_classes * np.bincount(y))</code></p>
<p>The 'balanced_subsample' mode is the same as 'balanced' except that
weights are computed based on the bootstrap sample for every tree
grown.</p>
<p>For multi-output, the weights of each column of y will be multiplied.</p>
<p>Note that these weights will be multiplied with sample_weight (passed
through the fit method) if sample_weight is specified.</p>
<p>ccp_alpha : non-negative float, optional (default=0.0)
Complexity parameter used for Minimal Cost-Complexity Pruning. The
subtree with the largest cost complexity that is smaller than
<code>ccp_alpha</code> will be chosen. By default, no pruning is performed. See
:ref:<code>minimal_cost_complexity_pruning</code> for details.</p>
<p>.. versionadded:: 0.22</p>
<p>max_samples : int or float, default=None
If bootstrap is True, the number of samples to draw from X
to train each base estimator.</p>
<ul>
<li>If None (default), then draw <code>X.shape[0]</code> samples.</li>
<li>If int, then draw <code>max_samples</code> samples.</li>
<li>If float, then draw <code>max_samples * X.shape[0]</code> samples. Thus,
<code>max_samples</code> should be in the interval <code>(0, 1)</code>.</li>
</ul>
<p>.. versionadded:: 0.22</p>
<h2 id="attributes_4">Attributes<a class="headerlink" href="#attributes_4" title="Permanent link">&para;</a></h2>
<p>base_estimator_ : ExtraTreeClassifier
The child estimator template used to create the collection of fitted
sub-estimators.</p>
<p>estimators_ : list of DecisionTreeClassifier
The collection of fitted sub-estimators.</p>
<p>classes_ : array of shape (n_classes,) or a list of such arrays
The classes labels (single output problem), or a list of arrays of
class labels (multi-output problem).</p>
<p>n_classes_ : int or list
The number of classes (single output problem), or a list containing the
number of classes for each output (multi-output problem).</p>
<p>feature_importances_ : ndarray of shape (n_features,)
The feature importances (the higher, the more important the feature).</p>
<p>n_features_ : int
The number of features when <code>fit</code> is performed.</p>
<p>n_outputs_ : int
The number of outputs when <code>fit</code> is performed.</p>
<p>oob_score_ : float
Score of the training dataset obtained using an out-of-bag estimate.
This attribute exists only when <code>oob_score</code> is True.</p>
<p>oob_decision_function_ : array of shape (n_samples, n_classes)
Decision function computed with out-of-bag estimate on the training
set. If n_estimators is small it might be possible that a data point
was never left out during the bootstrap. In this case,
<code>oob_decision_function_</code> might contain NaN. This attribute exists
only when <code>oob_score</code> is True.</p>
<h2 id="notes_2">Notes<a class="headerlink" href="#notes_2" title="Permanent link">&para;</a></h2>
<p>The default values for the parameters controlling the size of the trees
(e.g. <code>max_depth</code>, <code>min_samples_leaf</code>, etc.) lead to fully grown and
unpruned trees which can potentially be very large on some data sets. To
reduce memory consumption, the complexity and size of the trees should be
controlled by setting those parameter values.</p>
<h2 id="examples_4">Examples<a class="headerlink" href="#examples_4" title="Permanent link">&para;</a></h2>
<blockquote>
<blockquote>
<blockquote>
<p>from sklearn.ensemble import ExtraTreesClassifier
from sklearn.datasets import make_classification
X, y = make_classification(n_features=4, random_state=0)
clf = ExtraTreesClassifier(n_estimators=100, random_state=0)
clf.fit(X, y)
ExtraTreesClassifier(random_state=0)
clf.predict([[0, 0, 0, 0]])
array([1])</p>
</blockquote>
</blockquote>
</blockquote>
<h2 id="references_4">References<a class="headerlink" href="#references_4" title="Permanent link">&para;</a></h2>
<p>.. [1] P. Geurts, D. Ernst., and L. Wehenkel, 'Extremely randomized
trees', Machine Learning, 63(1), 3-42, 2006.</p>
<h2 id="see-also_2">See Also<a class="headerlink" href="#see-also_2" title="Permanent link">&para;</a></h2>
<p>sklearn.tree.ExtraTreeClassifier : Base classifier for this ensemble.
RandomForestClassifier : Ensemble Classifier based on trees with optimal
splits.</p>
<div class="highlight"><pre><span></span><code><span class="k">val</span> <span class="n">get_item</span> <span class="o">:</span> <span class="n">index</span><span class="o">:</span><span class="nn">Py</span><span class="p">.</span><span class="nn">Object</span><span class="p">.</span><span class="n">t</span> <span class="o">-&gt;</span> <span class="o">[&gt;</span> <span class="n">tag</span><span class="o">]</span> <span class="nn">Obj</span><span class="p">.</span><span class="n">t</span> <span class="o">-&gt;</span> <span class="nn">Py</span><span class="p">.</span><span class="nn">Object</span><span class="p">.</span><span class="n">t</span>
</code></pre></div>

<p>Return the index'th estimator in the ensemble.</p>
<div class="highlight"><pre><span></span><code><span class="k">val</span> <span class="n">iter</span> <span class="o">:</span> <span class="o">[&gt;</span> <span class="n">tag</span><span class="o">]</span> <span class="nn">Obj</span><span class="p">.</span><span class="n">t</span> <span class="o">-&gt;</span> <span class="nn">Dict</span><span class="p">.</span><span class="n">t</span> <span class="nn">Seq</span><span class="p">.</span><span class="n">t</span>
</code></pre></div>

<p>Return iterator over estimators in the ensemble.</p>
<div class="highlight"><pre><span></span><code><span class="k">val</span> <span class="n">apply</span> <span class="o">:</span> <span class="n">x</span><span class="o">:</span><span class="nn">Py</span><span class="p">.</span><span class="nn">Object</span><span class="p">.</span><span class="n">t</span> <span class="o">-&gt;</span> <span class="o">[&gt;</span> <span class="n">tag</span><span class="o">]</span> <span class="nn">Obj</span><span class="p">.</span><span class="n">t</span> <span class="o">-&gt;</span> <span class="o">[&gt;`</span><span class="nc">ArrayLike</span><span class="o">]</span> <span class="nn">Np</span><span class="p">.</span><span class="nn">Obj</span><span class="p">.</span><span class="n">t</span>
</code></pre></div>

<p>Apply trees in the forest to X, return leaf indices.</p>
<h2 id="parameters_38">Parameters<a class="headerlink" href="#parameters_38" title="Permanent link">&para;</a></h2>
<p>X : {array-like or sparse matrix} of shape (n_samples, n_features)
The input samples. Internally, its dtype will be converted to
<code>dtype=np.float32</code>. If a sparse matrix is provided, it will be
converted into a sparse <code>csr_matrix</code>.</p>
<h2 id="returns_27">Returns<a class="headerlink" href="#returns_27" title="Permanent link">&para;</a></h2>
<p>X_leaves : array_like, shape = [n_samples, n_estimators]
For each datapoint x in X and for each tree in the forest,
return the index of the leaf x ends up in.</p>
<div class="highlight"><pre><span></span><code><span class="k">val</span> <span class="n">decision_path</span> <span class="o">:</span> <span class="n">x</span><span class="o">:</span><span class="nn">Py</span><span class="p">.</span><span class="nn">Object</span><span class="p">.</span><span class="n">t</span> <span class="o">-&gt;</span> <span class="o">[&gt;</span> <span class="n">tag</span><span class="o">]</span> <span class="nn">Obj</span><span class="p">.</span><span class="n">t</span> <span class="o">-&gt;</span> <span class="o">(</span><span class="nn">Py</span><span class="p">.</span><span class="nn">Object</span><span class="p">.</span><span class="n">t</span> <span class="o">*</span> <span class="nn">Py</span><span class="p">.</span><span class="nn">Object</span><span class="p">.</span><span class="n">t</span><span class="o">)</span>
</code></pre></div>

<p>Return the decision path in the forest.</p>
<p>.. versionadded:: 0.18</p>
<h2 id="parameters_39">Parameters<a class="headerlink" href="#parameters_39" title="Permanent link">&para;</a></h2>
<p>X : {array-like or sparse matrix} of shape (n_samples, n_features)
The input samples. Internally, its dtype will be converted to
<code>dtype=np.float32</code>. If a sparse matrix is provided, it will be
converted into a sparse <code>csr_matrix</code>.</p>
<h2 id="returns_28">Returns<a class="headerlink" href="#returns_28" title="Permanent link">&para;</a></h2>
<p>indicator : sparse csr array, shape = [n_samples, n_nodes]
Return a node indicator matrix where non zero elements
indicates that the samples goes through the nodes.</p>
<p>n_nodes_ptr : array of size (n_estimators + 1, )
The columns from indicator[n_nodes_ptr[i]:n_nodes_ptr[i+1]]
gives the indicator value for the i-th estimator.</p>
<div class="highlight"><pre><span></span><code><span class="k">val</span> <span class="n">fit</span> <span class="o">:</span> <span class="o">?</span><span class="n">sample_weight</span><span class="o">:[&gt;`</span><span class="nc">ArrayLike</span><span class="o">]</span> <span class="nn">Np</span><span class="p">.</span><span class="nn">Obj</span><span class="p">.</span><span class="n">t</span> <span class="o">-&gt;</span> <span class="n">x</span><span class="o">:[&gt;`</span><span class="nc">ArrayLike</span><span class="o">]</span> <span class="nn">Np</span><span class="p">.</span><span class="nn">Obj</span><span class="p">.</span><span class="n">t</span> <span class="o">-&gt;</span> <span class="n">y</span><span class="o">:[&gt;`</span><span class="nc">ArrayLike</span><span class="o">]</span> <span class="nn">Np</span><span class="p">.</span><span class="nn">Obj</span><span class="p">.</span><span class="n">t</span> <span class="o">-&gt;</span> <span class="o">[&gt;</span> <span class="n">tag</span><span class="o">]</span> <span class="nn">Obj</span><span class="p">.</span><span class="n">t</span> <span class="o">-&gt;</span> <span class="n">t</span>
</code></pre></div>

<p>Build a forest of trees from the training set (X, y).</p>
<h2 id="parameters_40">Parameters<a class="headerlink" href="#parameters_40" title="Permanent link">&para;</a></h2>
<p>X : array-like or sparse matrix of shape (n_samples, n_features)
The training input samples. Internally, its dtype will be converted
to <code>dtype=np.float32</code>. If a sparse matrix is provided, it will be
converted into a sparse <code>csc_matrix</code>.</p>
<p>y : array-like of shape (n_samples,) or (n_samples, n_outputs)
The target values (class labels in classification, real numbers in
regression).</p>
<p>sample_weight : array-like of shape (n_samples,), default=None
Sample weights. If None, then samples are equally weighted. Splits
that would create child nodes with net zero or negative weight are
ignored while searching for a split in each node. In the case of
classification, splits are also ignored if they would result in any
single class carrying a negative weight in either child node.</p>
<h2 id="returns_29">Returns<a class="headerlink" href="#returns_29" title="Permanent link">&para;</a></h2>
<p>self : object</p>
<div class="highlight"><pre><span></span><code><span class="k">val</span> <span class="n">get_params</span> <span class="o">:</span> <span class="o">?</span><span class="n">deep</span><span class="o">:</span><span class="kt">bool</span> <span class="o">-&gt;</span> <span class="o">[&gt;</span> <span class="n">tag</span><span class="o">]</span> <span class="nn">Obj</span><span class="p">.</span><span class="n">t</span> <span class="o">-&gt;</span> <span class="nn">Dict</span><span class="p">.</span><span class="n">t</span>
</code></pre></div>

<p>Get parameters for this estimator.</p>
<h2 id="parameters_41">Parameters<a class="headerlink" href="#parameters_41" title="Permanent link">&para;</a></h2>
<p>deep : bool, default=True
If True, will return the parameters for this estimator and
contained subobjects that are estimators.</p>
<h2 id="returns_30">Returns<a class="headerlink" href="#returns_30" title="Permanent link">&para;</a></h2>
<p>params : mapping of string to any
Parameter names mapped to their values.</p>
<div class="highlight"><pre><span></span><code><span class="k">val</span> <span class="n">predict</span> <span class="o">:</span> <span class="n">x</span><span class="o">:[&gt;`</span><span class="nc">ArrayLike</span><span class="o">]</span> <span class="nn">Np</span><span class="p">.</span><span class="nn">Obj</span><span class="p">.</span><span class="n">t</span> <span class="o">-&gt;</span> <span class="o">[&gt;</span> <span class="n">tag</span><span class="o">]</span> <span class="nn">Obj</span><span class="p">.</span><span class="n">t</span> <span class="o">-&gt;</span> <span class="o">[&gt;`</span><span class="nc">ArrayLike</span><span class="o">]</span> <span class="nn">Np</span><span class="p">.</span><span class="nn">Obj</span><span class="p">.</span><span class="n">t</span>
</code></pre></div>

<p>Predict class for X.</p>
<p>The predicted class of an input sample is a vote by the trees in
the forest, weighted by their probability estimates. That is,
the predicted class is the one with highest mean probability
estimate across the trees.</p>
<h2 id="parameters_42">Parameters<a class="headerlink" href="#parameters_42" title="Permanent link">&para;</a></h2>
<p>X : array-like or sparse matrix of shape (n_samples, n_features)
The input samples. Internally, its dtype will be converted to
<code>dtype=np.float32</code>. If a sparse matrix is provided, it will be
converted into a sparse <code>csr_matrix</code>.</p>
<h2 id="returns_31">Returns<a class="headerlink" href="#returns_31" title="Permanent link">&para;</a></h2>
<p>y : array-like of shape (n_samples,) or (n_samples, n_outputs)
The predicted classes.</p>
<div class="highlight"><pre><span></span><code><span class="k">val</span> <span class="n">predict_log_proba</span> <span class="o">:</span> <span class="n">x</span><span class="o">:[&gt;`</span><span class="nc">ArrayLike</span><span class="o">]</span> <span class="nn">Np</span><span class="p">.</span><span class="nn">Obj</span><span class="p">.</span><span class="n">t</span> <span class="o">-&gt;</span> <span class="o">[&gt;</span> <span class="n">tag</span><span class="o">]</span> <span class="nn">Obj</span><span class="p">.</span><span class="n">t</span> <span class="o">-&gt;</span> <span class="nn">Py</span><span class="p">.</span><span class="nn">Object</span><span class="p">.</span><span class="n">t</span>
</code></pre></div>

<p>Predict class log-probabilities for X.</p>
<p>The predicted class log-probabilities of an input sample is computed as
the log of the mean predicted class probabilities of the trees in the
forest.</p>
<h2 id="parameters_43">Parameters<a class="headerlink" href="#parameters_43" title="Permanent link">&para;</a></h2>
<p>X : array-like or sparse matrix of shape (n_samples, n_features)
The input samples. Internally, its dtype will be converted to
<code>dtype=np.float32</code>. If a sparse matrix is provided, it will be
converted into a sparse <code>csr_matrix</code>.</p>
<h2 id="returns_32">Returns<a class="headerlink" href="#returns_32" title="Permanent link">&para;</a></h2>
<p>p : array of shape (n_samples, n_classes), or a list of n_outputs
such arrays if n_outputs &gt; 1.
The class probabilities of the input samples. The order of the
classes corresponds to that in the attribute :term:<code>classes_</code>.</p>
<div class="highlight"><pre><span></span><code><span class="k">val</span> <span class="n">predict_proba</span> <span class="o">:</span> <span class="n">x</span><span class="o">:[&gt;`</span><span class="nc">ArrayLike</span><span class="o">]</span> <span class="nn">Np</span><span class="p">.</span><span class="nn">Obj</span><span class="p">.</span><span class="n">t</span> <span class="o">-&gt;</span> <span class="o">[&gt;</span> <span class="n">tag</span><span class="o">]</span> <span class="nn">Obj</span><span class="p">.</span><span class="n">t</span> <span class="o">-&gt;</span> <span class="o">[&gt;`</span><span class="nc">ArrayLike</span><span class="o">]</span> <span class="nn">Np</span><span class="p">.</span><span class="nn">Obj</span><span class="p">.</span><span class="n">t</span>
</code></pre></div>

<p>Predict class probabilities for X.</p>
<p>The predicted class probabilities of an input sample are computed as
the mean predicted class probabilities of the trees in the forest.
The class probability of a single tree is the fraction of samples of
the same class in a leaf.</p>
<h2 id="parameters_44">Parameters<a class="headerlink" href="#parameters_44" title="Permanent link">&para;</a></h2>
<p>X : array-like or sparse matrix of shape (n_samples, n_features)
The input samples. Internally, its dtype will be converted to
<code>dtype=np.float32</code>. If a sparse matrix is provided, it will be
converted into a sparse <code>csr_matrix</code>.</p>
<h2 id="returns_33">Returns<a class="headerlink" href="#returns_33" title="Permanent link">&para;</a></h2>
<p>p : array of shape (n_samples, n_classes), or a list of n_outputs
such arrays if n_outputs &gt; 1.
The class probabilities of the input samples. The order of the
classes corresponds to that in the attribute :term:<code>classes_</code>.</p>
<div class="highlight"><pre><span></span><code><span class="k">val</span> <span class="n">score</span> <span class="o">:</span> <span class="o">?</span><span class="n">sample_weight</span><span class="o">:[&gt;`</span><span class="nc">ArrayLike</span><span class="o">]</span> <span class="nn">Np</span><span class="p">.</span><span class="nn">Obj</span><span class="p">.</span><span class="n">t</span> <span class="o">-&gt;</span> <span class="n">x</span><span class="o">:[&gt;`</span><span class="nc">ArrayLike</span><span class="o">]</span> <span class="nn">Np</span><span class="p">.</span><span class="nn">Obj</span><span class="p">.</span><span class="n">t</span> <span class="o">-&gt;</span> <span class="n">y</span><span class="o">:[&gt;`</span><span class="nc">ArrayLike</span><span class="o">]</span> <span class="nn">Np</span><span class="p">.</span><span class="nn">Obj</span><span class="p">.</span><span class="n">t</span> <span class="o">-&gt;</span> <span class="o">[&gt;</span> <span class="n">tag</span><span class="o">]</span> <span class="nn">Obj</span><span class="p">.</span><span class="n">t</span> <span class="o">-&gt;</span> <span class="kt">float</span>
</code></pre></div>

<p>Return the mean accuracy on the given test data and labels.</p>
<p>In multi-label classification, this is the subset accuracy
which is a harsh metric since you require for each sample that
each label set be correctly predicted.</p>
<h2 id="parameters_45">Parameters<a class="headerlink" href="#parameters_45" title="Permanent link">&para;</a></h2>
<p>X : array-like of shape (n_samples, n_features)
Test samples.</p>
<p>y : array-like of shape (n_samples,) or (n_samples, n_outputs)
True labels for X.</p>
<p>sample_weight : array-like of shape (n_samples,), default=None
Sample weights.</p>
<h2 id="returns_34">Returns<a class="headerlink" href="#returns_34" title="Permanent link">&para;</a></h2>
<p>score : float
Mean accuracy of self.predict(X) wrt. y.</p>
<div class="highlight"><pre><span></span><code><span class="k">val</span> <span class="n">set_params</span> <span class="o">:</span> <span class="o">?</span><span class="n">params</span><span class="o">:(</span><span class="kt">string</span> <span class="o">*</span> <span class="nn">Py</span><span class="p">.</span><span class="nn">Object</span><span class="p">.</span><span class="n">t</span><span class="o">)</span> <span class="kt">list</span> <span class="o">-&gt;</span> <span class="o">[&gt;</span> <span class="n">tag</span><span class="o">]</span> <span class="nn">Obj</span><span class="p">.</span><span class="n">t</span> <span class="o">-&gt;</span> <span class="n">t</span>
</code></pre></div>

<p>Set the parameters of this estimator.</p>
<p>The method works on simple estimators as well as on nested objects
(such as pipelines). The latter have parameters of the form
<code>&lt;component&gt;__&lt;parameter&gt;</code> so that it's possible to update each
component of a nested object.</p>
<h2 id="parameters_46">Parameters<a class="headerlink" href="#parameters_46" title="Permanent link">&para;</a></h2>
<p>**params : dict
Estimator parameters.</p>
<h2 id="returns_35">Returns<a class="headerlink" href="#returns_35" title="Permanent link">&para;</a></h2>
<p>self : object
Estimator instance.</p>
<p>Attribute base_estimator_: get value or raise Not_found if None.</p>
<div class="highlight"><pre><span></span><code><span class="k">val</span> <span class="n">base_estimator_</span> <span class="o">:</span> <span class="n">t</span> <span class="o">-&gt;</span> <span class="nn">Py</span><span class="p">.</span><span class="nn">Object</span><span class="p">.</span><span class="n">t</span>
</code></pre></div>

<p>Attribute base_estimator_: get value as an option.</p>
<div class="highlight"><pre><span></span><code><span class="k">val</span> <span class="n">base_estimator_opt</span> <span class="o">:</span> <span class="n">t</span> <span class="o">-&gt;</span> <span class="o">(</span><span class="nn">Py</span><span class="p">.</span><span class="nn">Object</span><span class="p">.</span><span class="n">t</span><span class="o">)</span> <span class="n">option</span>
</code></pre></div>

<p>Attribute estimators_: get value or raise Not_found if None.</p>
<div class="highlight"><pre><span></span><code><span class="k">val</span> <span class="n">estimators_</span> <span class="o">:</span> <span class="n">t</span> <span class="o">-&gt;</span> <span class="nn">Py</span><span class="p">.</span><span class="nn">Object</span><span class="p">.</span><span class="n">t</span>
</code></pre></div>

<p>Attribute estimators_: get value as an option.</p>
<div class="highlight"><pre><span></span><code><span class="k">val</span> <span class="n">estimators_opt</span> <span class="o">:</span> <span class="n">t</span> <span class="o">-&gt;</span> <span class="o">(</span><span class="nn">Py</span><span class="p">.</span><span class="nn">Object</span><span class="p">.</span><span class="n">t</span><span class="o">)</span> <span class="n">option</span>
</code></pre></div>

<p>Attribute classes_: get value or raise Not_found if None.</p>
<div class="highlight"><pre><span></span><code><span class="k">val</span> <span class="n">classes_</span> <span class="o">:</span> <span class="n">t</span> <span class="o">-&gt;</span> <span class="o">[&gt;`</span><span class="nc">ArrayLike</span><span class="o">]</span> <span class="nn">Np</span><span class="p">.</span><span class="nn">Obj</span><span class="p">.</span><span class="n">t</span>
</code></pre></div>

<p>Attribute classes_: get value as an option.</p>
<div class="highlight"><pre><span></span><code><span class="k">val</span> <span class="n">classes_opt</span> <span class="o">:</span> <span class="n">t</span> <span class="o">-&gt;</span> <span class="o">([&gt;`</span><span class="nc">ArrayLike</span><span class="o">]</span> <span class="nn">Np</span><span class="p">.</span><span class="nn">Obj</span><span class="p">.</span><span class="n">t</span><span class="o">)</span> <span class="n">option</span>
</code></pre></div>

<p>Attribute n_classes_: get value or raise Not_found if None.</p>
<div class="highlight"><pre><span></span><code><span class="k">val</span> <span class="n">n_classes_</span> <span class="o">:</span> <span class="n">t</span> <span class="o">-&gt;</span> <span class="nn">Py</span><span class="p">.</span><span class="nn">Object</span><span class="p">.</span><span class="n">t</span>
</code></pre></div>

<p>Attribute n_classes_: get value as an option.</p>
<div class="highlight"><pre><span></span><code><span class="k">val</span> <span class="n">n_classes_opt</span> <span class="o">:</span> <span class="n">t</span> <span class="o">-&gt;</span> <span class="o">(</span><span class="nn">Py</span><span class="p">.</span><span class="nn">Object</span><span class="p">.</span><span class="n">t</span><span class="o">)</span> <span class="n">option</span>
</code></pre></div>

<p>Attribute feature_importances_: get value or raise Not_found if None.</p>
<div class="highlight"><pre><span></span><code><span class="k">val</span> <span class="n">feature_importances_</span> <span class="o">:</span> <span class="n">t</span> <span class="o">-&gt;</span> <span class="o">[&gt;`</span><span class="nc">ArrayLike</span><span class="o">]</span> <span class="nn">Np</span><span class="p">.</span><span class="nn">Obj</span><span class="p">.</span><span class="n">t</span>
</code></pre></div>

<p>Attribute feature_importances_: get value as an option.</p>
<div class="highlight"><pre><span></span><code><span class="k">val</span> <span class="n">feature_importances_opt</span> <span class="o">:</span> <span class="n">t</span> <span class="o">-&gt;</span> <span class="o">([&gt;`</span><span class="nc">ArrayLike</span><span class="o">]</span> <span class="nn">Np</span><span class="p">.</span><span class="nn">Obj</span><span class="p">.</span><span class="n">t</span><span class="o">)</span> <span class="n">option</span>
</code></pre></div>

<p>Attribute n_features_: get value or raise Not_found if None.</p>
<div class="highlight"><pre><span></span><code><span class="k">val</span> <span class="n">n_features_</span> <span class="o">:</span> <span class="n">t</span> <span class="o">-&gt;</span> <span class="kt">int</span>
</code></pre></div>

<p>Attribute n_features_: get value as an option.</p>
<div class="highlight"><pre><span></span><code><span class="k">val</span> <span class="n">n_features_opt</span> <span class="o">:</span> <span class="n">t</span> <span class="o">-&gt;</span> <span class="o">(</span><span class="kt">int</span><span class="o">)</span> <span class="n">option</span>
</code></pre></div>

<p>Attribute n_outputs_: get value or raise Not_found if None.</p>
<div class="highlight"><pre><span></span><code><span class="k">val</span> <span class="n">n_outputs_</span> <span class="o">:</span> <span class="n">t</span> <span class="o">-&gt;</span> <span class="kt">int</span>
</code></pre></div>

<p>Attribute n_outputs_: get value as an option.</p>
<div class="highlight"><pre><span></span><code><span class="k">val</span> <span class="n">n_outputs_opt</span> <span class="o">:</span> <span class="n">t</span> <span class="o">-&gt;</span> <span class="o">(</span><span class="kt">int</span><span class="o">)</span> <span class="n">option</span>
</code></pre></div>

<p>Attribute oob_score_: get value or raise Not_found if None.</p>
<div class="highlight"><pre><span></span><code><span class="k">val</span> <span class="n">oob_score_</span> <span class="o">:</span> <span class="n">t</span> <span class="o">-&gt;</span> <span class="kt">float</span>
</code></pre></div>

<p>Attribute oob_score_: get value as an option.</p>
<div class="highlight"><pre><span></span><code><span class="k">val</span> <span class="n">oob_score_opt</span> <span class="o">:</span> <span class="n">t</span> <span class="o">-&gt;</span> <span class="o">(</span><span class="kt">float</span><span class="o">)</span> <span class="n">option</span>
</code></pre></div>

<p>Attribute oob_decision_function_: get value or raise Not_found if None.</p>
<div class="highlight"><pre><span></span><code><span class="k">val</span> <span class="n">oob_decision_function_</span> <span class="o">:</span> <span class="n">t</span> <span class="o">-&gt;</span> <span class="o">[&gt;`</span><span class="nc">ArrayLike</span><span class="o">]</span> <span class="nn">Np</span><span class="p">.</span><span class="nn">Obj</span><span class="p">.</span><span class="n">t</span>
</code></pre></div>

<p>Attribute oob_decision_function_: get value as an option.</p>
<div class="highlight"><pre><span></span><code><span class="k">val</span> <span class="n">oob_decision_function_opt</span> <span class="o">:</span> <span class="n">t</span> <span class="o">-&gt;</span> <span class="o">([&gt;`</span><span class="nc">ArrayLike</span><span class="o">]</span> <span class="nn">Np</span><span class="p">.</span><span class="nn">Obj</span><span class="p">.</span><span class="n">t</span><span class="o">)</span> <span class="n">option</span>
</code></pre></div>

<p>Print the object to a human-readable representation.</p>
<div class="highlight"><pre><span></span><code><span class="k">val</span> <span class="n">to_string</span> <span class="o">:</span> <span class="n">t</span> <span class="o">-&gt;</span> <span class="kt">string</span>
</code></pre></div>

<p>Print the object to a human-readable representation.</p>
<div class="highlight"><pre><span></span><code><span class="k">val</span> <span class="n">show</span> <span class="o">:</span> <span class="n">t</span> <span class="o">-&gt;</span> <span class="kt">string</span>
</code></pre></div>

<p>Pretty-print the object to a formatter.</p>
<div class="highlight"><pre><span></span><code><span class="k">val</span> <span class="n">pp</span> <span class="o">:</span> <span class="nn">Format</span><span class="p">.</span><span class="n">formatter</span> <span class="o">-&gt;</span> <span class="n">t</span> <span class="o">-&gt;</span> <span class="kt">unit</span> <span class="o">[@@</span><span class="n">ocaml</span><span class="o">.</span><span class="n">toplevel_printer</span><span class="o">]</span>



<span class="k">module</span> <span class="nc">ExtraTreesRegressor</span> <span class="o">:</span> <span class="k">sig</span>
<span class="k">type</span> <span class="n">tag</span> <span class="o">=</span> <span class="o">[`</span><span class="nc">ExtraTreesRegressor</span><span class="o">]</span>
<span class="k">type</span> <span class="n">t</span> <span class="o">=</span> <span class="o">[`</span><span class="nc">BaseEnsemble</span> <span class="o">|</span> <span class="o">`</span><span class="nc">BaseEstimator</span> <span class="o">|</span> <span class="o">`</span><span class="nc">BaseForest</span> <span class="o">|</span> <span class="o">`</span><span class="nc">ExtraTreesRegressor</span> <span class="o">|</span> <span class="o">`</span><span class="nc">MetaEstimatorMixin</span> <span class="o">|</span> <span class="o">`</span><span class="nc">MultiOutputMixin</span> <span class="o">|</span> <span class="o">`</span><span class="nc">Object</span> <span class="o">|</span> <span class="o">`</span><span class="nc">RegressorMixin</span><span class="o">]</span> <span class="nn">Obj</span><span class="p">.</span><span class="n">t</span>
<span class="k">val</span> <span class="n">of_pyobject</span> <span class="o">:</span> <span class="nn">Py</span><span class="p">.</span><span class="nn">Object</span><span class="p">.</span><span class="n">t</span> <span class="o">-&gt;</span> <span class="n">t</span>
<span class="k">val</span> <span class="n">to_pyobject</span> <span class="o">:</span> <span class="o">[&gt;</span> <span class="n">tag</span><span class="o">]</span> <span class="nn">Obj</span><span class="p">.</span><span class="n">t</span> <span class="o">-&gt;</span> <span class="nn">Py</span><span class="p">.</span><span class="nn">Object</span><span class="p">.</span><span class="n">t</span>

<span class="k">val</span> <span class="n">as_regressor</span> <span class="o">:</span> <span class="n">t</span> <span class="o">-&gt;</span> <span class="o">[`</span><span class="nc">RegressorMixin</span><span class="o">]</span> <span class="nn">Obj</span><span class="p">.</span><span class="n">t</span>
<span class="k">val</span> <span class="n">as_multi_output</span> <span class="o">:</span> <span class="n">t</span> <span class="o">-&gt;</span> <span class="o">[`</span><span class="nc">MultiOutputMixin</span><span class="o">]</span> <span class="nn">Obj</span><span class="p">.</span><span class="n">t</span>
<span class="k">val</span> <span class="n">as_meta_estimator</span> <span class="o">:</span> <span class="n">t</span> <span class="o">-&gt;</span> <span class="o">[`</span><span class="nc">MetaEstimatorMixin</span><span class="o">]</span> <span class="nn">Obj</span><span class="p">.</span><span class="n">t</span>
<span class="k">val</span> <span class="n">as_estimator</span> <span class="o">:</span> <span class="n">t</span> <span class="o">-&gt;</span> <span class="o">[`</span><span class="nc">BaseEstimator</span><span class="o">]</span> <span class="nn">Obj</span><span class="p">.</span><span class="n">t</span>
<span class="k">val</span> <span class="n">as_ensemble</span> <span class="o">:</span> <span class="n">t</span> <span class="o">-&gt;</span> <span class="o">[`</span><span class="nc">BaseEnsemble</span><span class="o">]</span> <span class="nn">Obj</span><span class="p">.</span><span class="n">t</span>
<span class="k">val</span> <span class="n">as_forest</span> <span class="o">:</span> <span class="n">t</span> <span class="o">-&gt;</span> <span class="o">[`</span><span class="nc">BaseForest</span><span class="o">]</span> <span class="nn">Obj</span><span class="p">.</span><span class="n">t</span>
<span class="k">val</span> <span class="n">create</span> <span class="o">:</span> <span class="o">?</span><span class="n">n_estimators</span><span class="o">:</span><span class="kt">int</span> <span class="o">-&gt;</span> <span class="o">?</span><span class="n">criterion</span><span class="o">:</span><span class="kt">string</span> <span class="o">-&gt;</span> <span class="o">?</span><span class="n">max_depth</span><span class="o">:</span><span class="kt">int</span> <span class="o">-&gt;</span> <span class="o">?</span><span class="n">min_samples_split</span><span class="o">:[`</span><span class="nc">F</span> <span class="k">of</span> <span class="kt">float</span> <span class="o">|</span> <span class="o">`</span><span class="nc">I</span> <span class="k">of</span> <span class="kt">int</span><span class="o">]</span> <span class="o">-&gt;</span> <span class="o">?</span><span class="n">min_samples_leaf</span><span class="o">:[`</span><span class="nc">F</span> <span class="k">of</span> <span class="kt">float</span> <span class="o">|</span> <span class="o">`</span><span class="nc">I</span> <span class="k">of</span> <span class="kt">int</span><span class="o">]</span> <span class="o">-&gt;</span> <span class="o">?</span><span class="n">min_weight_fraction_leaf</span><span class="o">:</span><span class="kt">float</span> <span class="o">-&gt;</span> <span class="o">?</span><span class="n">max_features</span><span class="o">:[`</span><span class="nc">F</span> <span class="k">of</span> <span class="kt">float</span> <span class="o">|</span> <span class="o">`</span><span class="nc">S</span> <span class="k">of</span> <span class="kt">string</span> <span class="o">|</span> <span class="o">`</span><span class="nc">I</span> <span class="k">of</span> <span class="kt">int</span> <span class="o">|</span> <span class="o">`</span><span class="nc">None</span><span class="o">]</span> <span class="o">-&gt;</span> <span class="o">?</span><span class="n">max_leaf_nodes</span><span class="o">:</span><span class="kt">int</span> <span class="o">-&gt;</span> <span class="o">?</span><span class="n">min_impurity_decrease</span><span class="o">:</span><span class="kt">float</span> <span class="o">-&gt;</span> <span class="o">?</span><span class="n">min_impurity_split</span><span class="o">:</span><span class="kt">float</span> <span class="o">-&gt;</span> <span class="o">?</span><span class="n">bootstrap</span><span class="o">:</span><span class="kt">bool</span> <span class="o">-&gt;</span> <span class="o">?</span><span class="n">oob_score</span><span class="o">:</span><span class="kt">bool</span> <span class="o">-&gt;</span> <span class="o">?</span><span class="n">n_jobs</span><span class="o">:</span><span class="kt">int</span> <span class="o">-&gt;</span> <span class="o">?</span><span class="n">random_state</span><span class="o">:</span><span class="kt">int</span> <span class="o">-&gt;</span> <span class="o">?</span><span class="n">verbose</span><span class="o">:</span><span class="kt">int</span> <span class="o">-&gt;</span> <span class="o">?</span><span class="n">warm_start</span><span class="o">:</span><span class="kt">bool</span> <span class="o">-&gt;</span> <span class="o">?</span><span class="n">ccp_alpha</span><span class="o">:</span><span class="kt">float</span> <span class="o">-&gt;</span> <span class="o">?</span><span class="n">max_samples</span><span class="o">:[`</span><span class="nc">F</span> <span class="k">of</span> <span class="kt">float</span> <span class="o">|</span> <span class="o">`</span><span class="nc">I</span> <span class="k">of</span> <span class="kt">int</span><span class="o">]</span> <span class="o">-&gt;</span> <span class="kt">unit</span> <span class="o">-&gt;</span> <span class="n">t</span>
</code></pre></div>

<p>An extra-trees regressor.</p>
<p>This class implements a meta estimator that fits a number of
randomized decision trees (a.k.a. extra-trees) on various sub-samples
of the dataset and uses averaging to improve the predictive accuracy
and control over-fitting.</p>
<p>Read more in the :ref:<code>User Guide &lt;forest&gt;</code>.</p>
<h2 id="parameters_47">Parameters<a class="headerlink" href="#parameters_47" title="Permanent link">&para;</a></h2>
<p>n_estimators : integer, optional (default=10)
The number of trees in the forest.</p>
<p>.. versionchanged:: 0.22
The default value of <code>n_estimators</code> changed from 10 to 100
in 0.22.</p>
<p>criterion : string, optional (default='mse')
The function to measure the quality of a split. Supported criteria
are 'mse' for the mean squared error, which is equal to variance
reduction as feature selection criterion, and 'mae' for the mean
absolute error.</p>
<p>.. versionadded:: 0.18
Mean Absolute Error (MAE) criterion.</p>
<p>max_depth : integer or None, optional (default=None)
The maximum depth of the tree. If None, then nodes are expanded until
all leaves are pure or until all leaves contain less than
min_samples_split samples.</p>
<p>min_samples_split : int, float, optional (default=2)
The minimum number of samples required to split an internal node:</p>
<ul>
<li>If int, then consider <code>min_samples_split</code> as the minimum number.</li>
<li>If float, then <code>min_samples_split</code> is a fraction and
<code>ceil(min_samples_split * n_samples)</code> are the minimum
number of samples for each split.</li>
</ul>
<p>.. versionchanged:: 0.18
Added float values for fractions.</p>
<p>min_samples_leaf : int, float, optional (default=1)
The minimum number of samples required to be at a leaf node.
A split point at any depth will only be considered if it leaves at
least <code>min_samples_leaf</code> training samples in each of the left and
right branches.  This may have the effect of smoothing the model,
especially in regression.</p>
<ul>
<li>If int, then consider <code>min_samples_leaf</code> as the minimum number.</li>
<li>If float, then <code>min_samples_leaf</code> is a fraction and
<code>ceil(min_samples_leaf * n_samples)</code> are the minimum
number of samples for each node.</li>
</ul>
<p>.. versionchanged:: 0.18
Added float values for fractions.</p>
<p>min_weight_fraction_leaf : float, optional (default=0.)
The minimum weighted fraction of the sum total of weights (of all
the input samples) required to be at a leaf node. Samples have
equal weight when sample_weight is not provided.</p>
<p>max_features : int, float, string or None, optional (default='auto')
The number of features to consider when looking for the best split:</p>
<ul>
<li>If int, then consider <code>max_features</code> features at each split.</li>
<li>If float, then <code>max_features</code> is a fraction and
<code>int(max_features * n_features)</code> features are considered at each
split.</li>
<li>If 'auto', then <code>max_features=n_features</code>.</li>
<li>If 'sqrt', then <code>max_features=sqrt(n_features)</code>.</li>
<li>If 'log2', then <code>max_features=log2(n_features)</code>.</li>
<li>If None, then <code>max_features=n_features</code>.</li>
</ul>
<p>Note: the search for a split does not stop until at least one
valid partition of the node samples is found, even if it requires to
effectively inspect more than <code>max_features</code> features.</p>
<p>max_leaf_nodes : int or None, optional (default=None)
Grow trees with <code>max_leaf_nodes</code> in best-first fashion.
Best nodes are defined as relative reduction in impurity.
If None then unlimited number of leaf nodes.</p>
<p>min_impurity_decrease : float, optional (default=0.)
A node will be split if this split induces a decrease of the impurity
greater than or equal to this value.</p>
<p>The weighted impurity decrease equation is the following::</p>
<p>N_t / N * (impurity - N_t_R / N_t * right_impurity
- N_t_L / N_t * left_impurity)</p>
<p>where <code>N</code> is the total number of samples, <code>N_t</code> is the number of
samples at the current node, <code>N_t_L</code> is the number of samples in the
left child, and <code>N_t_R</code> is the number of samples in the right child.</p>
<p><code>N</code>, <code>N_t</code>, <code>N_t_R</code> and <code>N_t_L</code> all refer to the weighted sum,
if <code>sample_weight</code> is passed.</p>
<p>.. versionadded:: 0.19</p>
<p>min_impurity_split : float, (default=1e-7)
Threshold for early stopping in tree growth. A node will split
if its impurity is above the threshold, otherwise it is a leaf.</p>
<p>.. deprecated:: 0.19
<code>min_impurity_split</code> has been deprecated in favor of
<code>min_impurity_decrease</code> in 0.19. The default value of
<code>min_impurity_split</code> will change from 1e-7 to 0 in 0.23 and it
will be removed in 0.25. Use <code>min_impurity_decrease</code> instead.</p>
<p>bootstrap : boolean, optional (default=False)
Whether bootstrap samples are used when building trees. If False, the
whole dataset is used to build each tree.</p>
<p>oob_score : bool, optional (default=False)
Whether to use out-of-bag samples to estimate the R^2 on unseen data.</p>
<p>n_jobs : int or None, optional (default=None)
The number of jobs to run in parallel. :meth:<code>fit</code>, :meth:<code>predict</code>,
:meth:<code>decision_path</code> and :meth:<code>apply</code> are all parallelized over the
trees. <code>None</code> means 1 unless in a :obj:<code>joblib.parallel_backend</code>
context. <code>-1</code> means using all processors. See :term:<code>Glossary
&lt;n_jobs&gt;</code> for more details.</p>
<p>random_state : int, RandomState instance or None, optional (default=None)
Controls 3 sources of randomness:</p>
<ul>
<li>the bootstrapping of the samples used when building trees
(if <code>bootstrap=True</code>)</li>
<li>the sampling of the features to consider when looking for the best
split at each node (if <code>max_features &lt; n_features</code>)</li>
<li>the draw of the splits for each of the <code>max_features</code></li>
</ul>
<p>See :term:<code>Glossary &lt;random_state&gt;</code> for details.</p>
<p>verbose : int, optional (default=0)
Controls the verbosity when fitting and predicting.</p>
<p>warm_start : bool, optional (default=False)
When set to <code>True</code>, reuse the solution of the previous call to fit
and add more estimators to the ensemble, otherwise, just fit a whole
new forest. See :term:<code>the Glossary &lt;warm_start&gt;</code>.</p>
<p>ccp_alpha : non-negative float, optional (default=0.0)
Complexity parameter used for Minimal Cost-Complexity Pruning. The
subtree with the largest cost complexity that is smaller than
<code>ccp_alpha</code> will be chosen. By default, no pruning is performed. See
:ref:<code>minimal_cost_complexity_pruning</code> for details.</p>
<p>.. versionadded:: 0.22</p>
<p>max_samples : int or float, default=None
If bootstrap is True, the number of samples to draw from X
to train each base estimator.</p>
<ul>
<li>If None (default), then draw <code>X.shape[0]</code> samples.</li>
<li>If int, then draw <code>max_samples</code> samples.</li>
<li>If float, then draw <code>max_samples * X.shape[0]</code> samples. Thus,
<code>max_samples</code> should be in the interval <code>(0, 1)</code>.</li>
</ul>
<p>.. versionadded:: 0.22</p>
<h2 id="attributes_5">Attributes<a class="headerlink" href="#attributes_5" title="Permanent link">&para;</a></h2>
<p>base_estimator_ : ExtraTreeRegressor
The child estimator template used to create the collection of fitted
sub-estimators.</p>
<p>estimators_ : list of DecisionTreeRegressor
The collection of fitted sub-estimators.</p>
<p>feature_importances_ : ndarray of shape (n_features,)
The feature importances (the higher, the more important the feature).</p>
<p>n_features_ : int
The number of features.</p>
<p>n_outputs_ : int
The number of outputs.</p>
<p>oob_score_ : float
Score of the training dataset obtained using an out-of-bag estimate.
This attribute exists only when <code>oob_score</code> is True.</p>
<p>oob_prediction_ : ndarray of shape (n_samples,)
Prediction computed with out-of-bag estimate on the training set.
This attribute exists only when <code>oob_score</code> is True.</p>
<h2 id="notes_3">Notes<a class="headerlink" href="#notes_3" title="Permanent link">&para;</a></h2>
<p>The default values for the parameters controlling the size of the trees
(e.g. <code>max_depth</code>, <code>min_samples_leaf</code>, etc.) lead to fully grown and
unpruned trees which can potentially be very large on some data sets. To
reduce memory consumption, the complexity and size of the trees should be
controlled by setting those parameter values.</p>
<h2 id="references_5">References<a class="headerlink" href="#references_5" title="Permanent link">&para;</a></h2>
<p>.. [1] P. Geurts, D. Ernst., and L. Wehenkel, 'Extremely randomized trees',
Machine Learning, 63(1), 3-42, 2006.</p>
<h2 id="see-also_3">See Also<a class="headerlink" href="#see-also_3" title="Permanent link">&para;</a></h2>
<p>sklearn.tree.ExtraTreeRegressor: Base estimator for this ensemble.
RandomForestRegressor: Ensemble regressor using trees with optimal splits.</p>
<div class="highlight"><pre><span></span><code><span class="k">val</span> <span class="n">get_item</span> <span class="o">:</span> <span class="n">index</span><span class="o">:</span><span class="nn">Py</span><span class="p">.</span><span class="nn">Object</span><span class="p">.</span><span class="n">t</span> <span class="o">-&gt;</span> <span class="o">[&gt;</span> <span class="n">tag</span><span class="o">]</span> <span class="nn">Obj</span><span class="p">.</span><span class="n">t</span> <span class="o">-&gt;</span> <span class="nn">Py</span><span class="p">.</span><span class="nn">Object</span><span class="p">.</span><span class="n">t</span>
</code></pre></div>

<p>Return the index'th estimator in the ensemble.</p>
<div class="highlight"><pre><span></span><code><span class="k">val</span> <span class="n">iter</span> <span class="o">:</span> <span class="o">[&gt;</span> <span class="n">tag</span><span class="o">]</span> <span class="nn">Obj</span><span class="p">.</span><span class="n">t</span> <span class="o">-&gt;</span> <span class="nn">Dict</span><span class="p">.</span><span class="n">t</span> <span class="nn">Seq</span><span class="p">.</span><span class="n">t</span>
</code></pre></div>

<p>Return iterator over estimators in the ensemble.</p>
<div class="highlight"><pre><span></span><code><span class="k">val</span> <span class="n">apply</span> <span class="o">:</span> <span class="n">x</span><span class="o">:</span><span class="nn">Py</span><span class="p">.</span><span class="nn">Object</span><span class="p">.</span><span class="n">t</span> <span class="o">-&gt;</span> <span class="o">[&gt;</span> <span class="n">tag</span><span class="o">]</span> <span class="nn">Obj</span><span class="p">.</span><span class="n">t</span> <span class="o">-&gt;</span> <span class="o">[&gt;`</span><span class="nc">ArrayLike</span><span class="o">]</span> <span class="nn">Np</span><span class="p">.</span><span class="nn">Obj</span><span class="p">.</span><span class="n">t</span>
</code></pre></div>

<p>Apply trees in the forest to X, return leaf indices.</p>
<h2 id="parameters_48">Parameters<a class="headerlink" href="#parameters_48" title="Permanent link">&para;</a></h2>
<p>X : {array-like or sparse matrix} of shape (n_samples, n_features)
The input samples. Internally, its dtype will be converted to
<code>dtype=np.float32</code>. If a sparse matrix is provided, it will be
converted into a sparse <code>csr_matrix</code>.</p>
<h2 id="returns_36">Returns<a class="headerlink" href="#returns_36" title="Permanent link">&para;</a></h2>
<p>X_leaves : array_like, shape = [n_samples, n_estimators]
For each datapoint x in X and for each tree in the forest,
return the index of the leaf x ends up in.</p>
<div class="highlight"><pre><span></span><code><span class="k">val</span> <span class="n">decision_path</span> <span class="o">:</span> <span class="n">x</span><span class="o">:</span><span class="nn">Py</span><span class="p">.</span><span class="nn">Object</span><span class="p">.</span><span class="n">t</span> <span class="o">-&gt;</span> <span class="o">[&gt;</span> <span class="n">tag</span><span class="o">]</span> <span class="nn">Obj</span><span class="p">.</span><span class="n">t</span> <span class="o">-&gt;</span> <span class="o">(</span><span class="nn">Py</span><span class="p">.</span><span class="nn">Object</span><span class="p">.</span><span class="n">t</span> <span class="o">*</span> <span class="nn">Py</span><span class="p">.</span><span class="nn">Object</span><span class="p">.</span><span class="n">t</span><span class="o">)</span>
</code></pre></div>

<p>Return the decision path in the forest.</p>
<p>.. versionadded:: 0.18</p>
<h2 id="parameters_49">Parameters<a class="headerlink" href="#parameters_49" title="Permanent link">&para;</a></h2>
<p>X : {array-like or sparse matrix} of shape (n_samples, n_features)
The input samples. Internally, its dtype will be converted to
<code>dtype=np.float32</code>. If a sparse matrix is provided, it will be
converted into a sparse <code>csr_matrix</code>.</p>
<h2 id="returns_37">Returns<a class="headerlink" href="#returns_37" title="Permanent link">&para;</a></h2>
<p>indicator : sparse csr array, shape = [n_samples, n_nodes]
Return a node indicator matrix where non zero elements
indicates that the samples goes through the nodes.</p>
<p>n_nodes_ptr : array of size (n_estimators + 1, )
The columns from indicator[n_nodes_ptr[i]:n_nodes_ptr[i+1]]
gives the indicator value for the i-th estimator.</p>
<div class="highlight"><pre><span></span><code><span class="k">val</span> <span class="n">fit</span> <span class="o">:</span> <span class="o">?</span><span class="n">sample_weight</span><span class="o">:[&gt;`</span><span class="nc">ArrayLike</span><span class="o">]</span> <span class="nn">Np</span><span class="p">.</span><span class="nn">Obj</span><span class="p">.</span><span class="n">t</span> <span class="o">-&gt;</span> <span class="n">x</span><span class="o">:[&gt;`</span><span class="nc">ArrayLike</span><span class="o">]</span> <span class="nn">Np</span><span class="p">.</span><span class="nn">Obj</span><span class="p">.</span><span class="n">t</span> <span class="o">-&gt;</span> <span class="n">y</span><span class="o">:[&gt;`</span><span class="nc">ArrayLike</span><span class="o">]</span> <span class="nn">Np</span><span class="p">.</span><span class="nn">Obj</span><span class="p">.</span><span class="n">t</span> <span class="o">-&gt;</span> <span class="o">[&gt;</span> <span class="n">tag</span><span class="o">]</span> <span class="nn">Obj</span><span class="p">.</span><span class="n">t</span> <span class="o">-&gt;</span> <span class="n">t</span>
</code></pre></div>

<p>Build a forest of trees from the training set (X, y).</p>
<h2 id="parameters_50">Parameters<a class="headerlink" href="#parameters_50" title="Permanent link">&para;</a></h2>
<p>X : array-like or sparse matrix of shape (n_samples, n_features)
The training input samples. Internally, its dtype will be converted
to <code>dtype=np.float32</code>. If a sparse matrix is provided, it will be
converted into a sparse <code>csc_matrix</code>.</p>
<p>y : array-like of shape (n_samples,) or (n_samples, n_outputs)
The target values (class labels in classification, real numbers in
regression).</p>
<p>sample_weight : array-like of shape (n_samples,), default=None
Sample weights. If None, then samples are equally weighted. Splits
that would create child nodes with net zero or negative weight are
ignored while searching for a split in each node. In the case of
classification, splits are also ignored if they would result in any
single class carrying a negative weight in either child node.</p>
<h2 id="returns_38">Returns<a class="headerlink" href="#returns_38" title="Permanent link">&para;</a></h2>
<p>self : object</p>
<div class="highlight"><pre><span></span><code><span class="k">val</span> <span class="n">get_params</span> <span class="o">:</span> <span class="o">?</span><span class="n">deep</span><span class="o">:</span><span class="kt">bool</span> <span class="o">-&gt;</span> <span class="o">[&gt;</span> <span class="n">tag</span><span class="o">]</span> <span class="nn">Obj</span><span class="p">.</span><span class="n">t</span> <span class="o">-&gt;</span> <span class="nn">Dict</span><span class="p">.</span><span class="n">t</span>
</code></pre></div>

<p>Get parameters for this estimator.</p>
<h2 id="parameters_51">Parameters<a class="headerlink" href="#parameters_51" title="Permanent link">&para;</a></h2>
<p>deep : bool, default=True
If True, will return the parameters for this estimator and
contained subobjects that are estimators.</p>
<h2 id="returns_39">Returns<a class="headerlink" href="#returns_39" title="Permanent link">&para;</a></h2>
<p>params : mapping of string to any
Parameter names mapped to their values.</p>
<div class="highlight"><pre><span></span><code><span class="k">val</span> <span class="n">predict</span> <span class="o">:</span> <span class="n">x</span><span class="o">:[&gt;`</span><span class="nc">ArrayLike</span><span class="o">]</span> <span class="nn">Np</span><span class="p">.</span><span class="nn">Obj</span><span class="p">.</span><span class="n">t</span> <span class="o">-&gt;</span> <span class="o">[&gt;</span> <span class="n">tag</span><span class="o">]</span> <span class="nn">Obj</span><span class="p">.</span><span class="n">t</span> <span class="o">-&gt;</span> <span class="o">[&gt;`</span><span class="nc">ArrayLike</span><span class="o">]</span> <span class="nn">Np</span><span class="p">.</span><span class="nn">Obj</span><span class="p">.</span><span class="n">t</span>
</code></pre></div>

<p>Predict regression target for X.</p>
<p>The predicted regression target of an input sample is computed as the
mean predicted regression targets of the trees in the forest.</p>
<h2 id="parameters_52">Parameters<a class="headerlink" href="#parameters_52" title="Permanent link">&para;</a></h2>
<p>X : array-like or sparse matrix of shape (n_samples, n_features)
The input samples. Internally, its dtype will be converted to
<code>dtype=np.float32</code>. If a sparse matrix is provided, it will be
converted into a sparse <code>csr_matrix</code>.</p>
<h2 id="returns_40">Returns<a class="headerlink" href="#returns_40" title="Permanent link">&para;</a></h2>
<p>y : array-like of shape (n_samples,) or (n_samples, n_outputs)
The predicted values.</p>
<div class="highlight"><pre><span></span><code><span class="k">val</span> <span class="n">score</span> <span class="o">:</span> <span class="o">?</span><span class="n">sample_weight</span><span class="o">:[&gt;`</span><span class="nc">ArrayLike</span><span class="o">]</span> <span class="nn">Np</span><span class="p">.</span><span class="nn">Obj</span><span class="p">.</span><span class="n">t</span> <span class="o">-&gt;</span> <span class="n">x</span><span class="o">:[&gt;`</span><span class="nc">ArrayLike</span><span class="o">]</span> <span class="nn">Np</span><span class="p">.</span><span class="nn">Obj</span><span class="p">.</span><span class="n">t</span> <span class="o">-&gt;</span> <span class="n">y</span><span class="o">:[&gt;`</span><span class="nc">ArrayLike</span><span class="o">]</span> <span class="nn">Np</span><span class="p">.</span><span class="nn">Obj</span><span class="p">.</span><span class="n">t</span> <span class="o">-&gt;</span> <span class="o">[&gt;</span> <span class="n">tag</span><span class="o">]</span> <span class="nn">Obj</span><span class="p">.</span><span class="n">t</span> <span class="o">-&gt;</span> <span class="kt">float</span>
</code></pre></div>

<p>Return the coefficient of determination R^2 of the prediction.</p>
<p>The coefficient R^2 is defined as (1 - u/v), where u is the residual
sum of squares ((y_true - y_pred) <strong> 2).sum() and v is the total
sum of squares ((y_true - y_true.mean()) </strong> 2).sum().
The best possible score is 1.0 and it can be negative (because the
model can be arbitrarily worse). A constant model that always
predicts the expected value of y, disregarding the input features,
would get a R^2 score of 0.0.</p>
<h2 id="parameters_53">Parameters<a class="headerlink" href="#parameters_53" title="Permanent link">&para;</a></h2>
<p>X : array-like of shape (n_samples, n_features)
Test samples. For some estimators this may be a
precomputed kernel matrix or a list of generic objects instead,
shape = (n_samples, n_samples_fitted),
where n_samples_fitted is the number of
samples used in the fitting for the estimator.</p>
<p>y : array-like of shape (n_samples,) or (n_samples, n_outputs)
True values for X.</p>
<p>sample_weight : array-like of shape (n_samples,), default=None
Sample weights.</p>
<h2 id="returns_41">Returns<a class="headerlink" href="#returns_41" title="Permanent link">&para;</a></h2>
<p>score : float
R^2 of self.predict(X) wrt. y.</p>
<h2 id="notes_4">Notes<a class="headerlink" href="#notes_4" title="Permanent link">&para;</a></h2>
<p>The R2 score used when calling <code>score</code> on a regressor will use
<code>multioutput='uniform_average'</code> from version 0.23 to keep consistent
with :func:<code>~sklearn.metrics.r2_score</code>. This will influence the
<code>score</code> method of all the multioutput regressors (except for
:class:<code>~sklearn.multioutput.MultiOutputRegressor</code>). To specify the
default value manually and avoid the warning, please either call
:func:<code>~sklearn.metrics.r2_score</code> directly or make a custom scorer with
:func:<code>~sklearn.metrics.make_scorer</code> (the built-in scorer <code>'r2'</code> uses
<code>multioutput='uniform_average'</code>).</p>
<div class="highlight"><pre><span></span><code><span class="k">val</span> <span class="n">set_params</span> <span class="o">:</span> <span class="o">?</span><span class="n">params</span><span class="o">:(</span><span class="kt">string</span> <span class="o">*</span> <span class="nn">Py</span><span class="p">.</span><span class="nn">Object</span><span class="p">.</span><span class="n">t</span><span class="o">)</span> <span class="kt">list</span> <span class="o">-&gt;</span> <span class="o">[&gt;</span> <span class="n">tag</span><span class="o">]</span> <span class="nn">Obj</span><span class="p">.</span><span class="n">t</span> <span class="o">-&gt;</span> <span class="n">t</span>
</code></pre></div>

<p>Set the parameters of this estimator.</p>
<p>The method works on simple estimators as well as on nested objects
(such as pipelines). The latter have parameters of the form
<code>&lt;component&gt;__&lt;parameter&gt;</code> so that it's possible to update each
component of a nested object.</p>
<h2 id="parameters_54">Parameters<a class="headerlink" href="#parameters_54" title="Permanent link">&para;</a></h2>
<p>**params : dict
Estimator parameters.</p>
<h2 id="returns_42">Returns<a class="headerlink" href="#returns_42" title="Permanent link">&para;</a></h2>
<p>self : object
Estimator instance.</p>
<p>Attribute base_estimator_: get value or raise Not_found if None.</p>
<div class="highlight"><pre><span></span><code><span class="k">val</span> <span class="n">base_estimator_</span> <span class="o">:</span> <span class="n">t</span> <span class="o">-&gt;</span> <span class="nn">Py</span><span class="p">.</span><span class="nn">Object</span><span class="p">.</span><span class="n">t</span>
</code></pre></div>

<p>Attribute base_estimator_: get value as an option.</p>
<div class="highlight"><pre><span></span><code><span class="k">val</span> <span class="n">base_estimator_opt</span> <span class="o">:</span> <span class="n">t</span> <span class="o">-&gt;</span> <span class="o">(</span><span class="nn">Py</span><span class="p">.</span><span class="nn">Object</span><span class="p">.</span><span class="n">t</span><span class="o">)</span> <span class="n">option</span>
</code></pre></div>

<p>Attribute estimators_: get value or raise Not_found if None.</p>
<div class="highlight"><pre><span></span><code><span class="k">val</span> <span class="n">estimators_</span> <span class="o">:</span> <span class="n">t</span> <span class="o">-&gt;</span> <span class="nn">Py</span><span class="p">.</span><span class="nn">Object</span><span class="p">.</span><span class="n">t</span>
</code></pre></div>

<p>Attribute estimators_: get value as an option.</p>
<div class="highlight"><pre><span></span><code><span class="k">val</span> <span class="n">estimators_opt</span> <span class="o">:</span> <span class="n">t</span> <span class="o">-&gt;</span> <span class="o">(</span><span class="nn">Py</span><span class="p">.</span><span class="nn">Object</span><span class="p">.</span><span class="n">t</span><span class="o">)</span> <span class="n">option</span>
</code></pre></div>

<p>Attribute feature_importances_: get value or raise Not_found if None.</p>
<div class="highlight"><pre><span></span><code><span class="k">val</span> <span class="n">feature_importances_</span> <span class="o">:</span> <span class="n">t</span> <span class="o">-&gt;</span> <span class="o">[&gt;`</span><span class="nc">ArrayLike</span><span class="o">]</span> <span class="nn">Np</span><span class="p">.</span><span class="nn">Obj</span><span class="p">.</span><span class="n">t</span>
</code></pre></div>

<p>Attribute feature_importances_: get value as an option.</p>
<div class="highlight"><pre><span></span><code><span class="k">val</span> <span class="n">feature_importances_opt</span> <span class="o">:</span> <span class="n">t</span> <span class="o">-&gt;</span> <span class="o">([&gt;`</span><span class="nc">ArrayLike</span><span class="o">]</span> <span class="nn">Np</span><span class="p">.</span><span class="nn">Obj</span><span class="p">.</span><span class="n">t</span><span class="o">)</span> <span class="n">option</span>
</code></pre></div>

<p>Attribute n_features_: get value or raise Not_found if None.</p>
<div class="highlight"><pre><span></span><code><span class="k">val</span> <span class="n">n_features_</span> <span class="o">:</span> <span class="n">t</span> <span class="o">-&gt;</span> <span class="kt">int</span>
</code></pre></div>

<p>Attribute n_features_: get value as an option.</p>
<div class="highlight"><pre><span></span><code><span class="k">val</span> <span class="n">n_features_opt</span> <span class="o">:</span> <span class="n">t</span> <span class="o">-&gt;</span> <span class="o">(</span><span class="kt">int</span><span class="o">)</span> <span class="n">option</span>
</code></pre></div>

<p>Attribute n_outputs_: get value or raise Not_found if None.</p>
<div class="highlight"><pre><span></span><code><span class="k">val</span> <span class="n">n_outputs_</span> <span class="o">:</span> <span class="n">t</span> <span class="o">-&gt;</span> <span class="kt">int</span>
</code></pre></div>

<p>Attribute n_outputs_: get value as an option.</p>
<div class="highlight"><pre><span></span><code><span class="k">val</span> <span class="n">n_outputs_opt</span> <span class="o">:</span> <span class="n">t</span> <span class="o">-&gt;</span> <span class="o">(</span><span class="kt">int</span><span class="o">)</span> <span class="n">option</span>
</code></pre></div>

<p>Attribute oob_score_: get value or raise Not_found if None.</p>
<div class="highlight"><pre><span></span><code><span class="k">val</span> <span class="n">oob_score_</span> <span class="o">:</span> <span class="n">t</span> <span class="o">-&gt;</span> <span class="kt">float</span>
</code></pre></div>

<p>Attribute oob_score_: get value as an option.</p>
<div class="highlight"><pre><span></span><code><span class="k">val</span> <span class="n">oob_score_opt</span> <span class="o">:</span> <span class="n">t</span> <span class="o">-&gt;</span> <span class="o">(</span><span class="kt">float</span><span class="o">)</span> <span class="n">option</span>
</code></pre></div>

<p>Attribute oob_prediction_: get value or raise Not_found if None.</p>
<div class="highlight"><pre><span></span><code><span class="k">val</span> <span class="n">oob_prediction_</span> <span class="o">:</span> <span class="n">t</span> <span class="o">-&gt;</span> <span class="o">[&gt;`</span><span class="nc">ArrayLike</span><span class="o">]</span> <span class="nn">Np</span><span class="p">.</span><span class="nn">Obj</span><span class="p">.</span><span class="n">t</span>
</code></pre></div>

<p>Attribute oob_prediction_: get value as an option.</p>
<div class="highlight"><pre><span></span><code><span class="k">val</span> <span class="n">oob_prediction_opt</span> <span class="o">:</span> <span class="n">t</span> <span class="o">-&gt;</span> <span class="o">([&gt;`</span><span class="nc">ArrayLike</span><span class="o">]</span> <span class="nn">Np</span><span class="p">.</span><span class="nn">Obj</span><span class="p">.</span><span class="n">t</span><span class="o">)</span> <span class="n">option</span>
</code></pre></div>

<p>Print the object to a human-readable representation.</p>
<div class="highlight"><pre><span></span><code><span class="k">val</span> <span class="n">to_string</span> <span class="o">:</span> <span class="n">t</span> <span class="o">-&gt;</span> <span class="kt">string</span>
</code></pre></div>

<p>Print the object to a human-readable representation.</p>
<div class="highlight"><pre><span></span><code><span class="k">val</span> <span class="n">show</span> <span class="o">:</span> <span class="n">t</span> <span class="o">-&gt;</span> <span class="kt">string</span>
</code></pre></div>

<p>Pretty-print the object to a formatter.</p>
<div class="highlight"><pre><span></span><code><span class="k">val</span> <span class="n">pp</span> <span class="o">:</span> <span class="nn">Format</span><span class="p">.</span><span class="n">formatter</span> <span class="o">-&gt;</span> <span class="n">t</span> <span class="o">-&gt;</span> <span class="kt">unit</span> <span class="o">[@@</span><span class="n">ocaml</span><span class="o">.</span><span class="n">toplevel_printer</span><span class="o">]</span>



<span class="k">module</span> <span class="nc">GradientBoostingClassifier</span> <span class="o">:</span> <span class="k">sig</span>
<span class="k">type</span> <span class="n">tag</span> <span class="o">=</span> <span class="o">[`</span><span class="nc">GradientBoostingClassifier</span><span class="o">]</span>
<span class="k">type</span> <span class="n">t</span> <span class="o">=</span> <span class="o">[`</span><span class="nc">BaseEnsemble</span> <span class="o">|</span> <span class="o">`</span><span class="nc">BaseEstimator</span> <span class="o">|</span> <span class="o">`</span><span class="nc">BaseGradientBoosting</span> <span class="o">|</span> <span class="o">`</span><span class="nc">ClassifierMixin</span> <span class="o">|</span> <span class="o">`</span><span class="nc">GradientBoostingClassifier</span> <span class="o">|</span> <span class="o">`</span><span class="nc">MetaEstimatorMixin</span> <span class="o">|</span> <span class="o">`</span><span class="nc">Object</span><span class="o">]</span> <span class="nn">Obj</span><span class="p">.</span><span class="n">t</span>
<span class="k">val</span> <span class="n">of_pyobject</span> <span class="o">:</span> <span class="nn">Py</span><span class="p">.</span><span class="nn">Object</span><span class="p">.</span><span class="n">t</span> <span class="o">-&gt;</span> <span class="n">t</span>
<span class="k">val</span> <span class="n">to_pyobject</span> <span class="o">:</span> <span class="o">[&gt;</span> <span class="n">tag</span><span class="o">]</span> <span class="nn">Obj</span><span class="p">.</span><span class="n">t</span> <span class="o">-&gt;</span> <span class="nn">Py</span><span class="p">.</span><span class="nn">Object</span><span class="p">.</span><span class="n">t</span>

<span class="k">val</span> <span class="n">as_classifier</span> <span class="o">:</span> <span class="n">t</span> <span class="o">-&gt;</span> <span class="o">[`</span><span class="nc">ClassifierMixin</span><span class="o">]</span> <span class="nn">Obj</span><span class="p">.</span><span class="n">t</span>
<span class="k">val</span> <span class="n">as_gradient_boosting</span> <span class="o">:</span> <span class="n">t</span> <span class="o">-&gt;</span> <span class="o">[`</span><span class="nc">BaseGradientBoosting</span><span class="o">]</span> <span class="nn">Obj</span><span class="p">.</span><span class="n">t</span>
<span class="k">val</span> <span class="n">as_meta_estimator</span> <span class="o">:</span> <span class="n">t</span> <span class="o">-&gt;</span> <span class="o">[`</span><span class="nc">MetaEstimatorMixin</span><span class="o">]</span> <span class="nn">Obj</span><span class="p">.</span><span class="n">t</span>
<span class="k">val</span> <span class="n">as_estimator</span> <span class="o">:</span> <span class="n">t</span> <span class="o">-&gt;</span> <span class="o">[`</span><span class="nc">BaseEstimator</span><span class="o">]</span> <span class="nn">Obj</span><span class="p">.</span><span class="n">t</span>
<span class="k">val</span> <span class="n">as_ensemble</span> <span class="o">:</span> <span class="n">t</span> <span class="o">-&gt;</span> <span class="o">[`</span><span class="nc">BaseEnsemble</span><span class="o">]</span> <span class="nn">Obj</span><span class="p">.</span><span class="n">t</span>
<span class="k">val</span> <span class="n">create</span> <span class="o">:</span> <span class="o">?</span><span class="n">loss</span><span class="o">:[`</span><span class="nc">Deviance</span> <span class="o">|</span> <span class="o">`</span><span class="nc">Exponential</span><span class="o">]</span> <span class="o">-&gt;</span> <span class="o">?</span><span class="n">learning_rate</span><span class="o">:</span><span class="kt">float</span> <span class="o">-&gt;</span> <span class="o">?</span><span class="n">n_estimators</span><span class="o">:</span><span class="kt">int</span> <span class="o">-&gt;</span> <span class="o">?</span><span class="n">subsample</span><span class="o">:</span><span class="kt">float</span> <span class="o">-&gt;</span> <span class="o">?</span><span class="n">criterion</span><span class="o">:</span><span class="kt">string</span> <span class="o">-&gt;</span> <span class="o">?</span><span class="n">min_samples_split</span><span class="o">:[`</span><span class="nc">F</span> <span class="k">of</span> <span class="kt">float</span> <span class="o">|</span> <span class="o">`</span><span class="nc">I</span> <span class="k">of</span> <span class="kt">int</span><span class="o">]</span> <span class="o">-&gt;</span> <span class="o">?</span><span class="n">min_samples_leaf</span><span class="o">:[`</span><span class="nc">F</span> <span class="k">of</span> <span class="kt">float</span> <span class="o">|</span> <span class="o">`</span><span class="nc">I</span> <span class="k">of</span> <span class="kt">int</span><span class="o">]</span> <span class="o">-&gt;</span> <span class="o">?</span><span class="n">min_weight_fraction_leaf</span><span class="o">:</span><span class="kt">float</span> <span class="o">-&gt;</span> <span class="o">?</span><span class="n">max_depth</span><span class="o">:</span><span class="kt">int</span> <span class="o">-&gt;</span> <span class="o">?</span><span class="n">min_impurity_decrease</span><span class="o">:</span><span class="kt">float</span> <span class="o">-&gt;</span> <span class="o">?</span><span class="n">min_impurity_split</span><span class="o">:</span><span class="kt">float</span> <span class="o">-&gt;</span> <span class="o">?</span><span class="n">init</span><span class="o">:[`</span><span class="nc">BaseEstimator</span> <span class="k">of</span> <span class="o">[&gt;`</span><span class="nc">BaseEstimator</span><span class="o">]</span> <span class="nn">Np</span><span class="p">.</span><span class="nn">Obj</span><span class="p">.</span><span class="n">t</span> <span class="o">|</span> <span class="o">`</span><span class="nc">Zero</span><span class="o">]</span> <span class="o">-&gt;</span> <span class="o">?</span><span class="n">random_state</span><span class="o">:</span><span class="kt">int</span> <span class="o">-&gt;</span> <span class="o">?</span><span class="n">max_features</span><span class="o">:[`</span><span class="nc">F</span> <span class="k">of</span> <span class="kt">float</span> <span class="o">|</span> <span class="o">`</span><span class="nc">S</span> <span class="k">of</span> <span class="kt">string</span> <span class="o">|</span> <span class="o">`</span><span class="nc">I</span> <span class="k">of</span> <span class="kt">int</span><span class="o">]</span> <span class="o">-&gt;</span> <span class="o">?</span><span class="n">verbose</span><span class="o">:</span><span class="kt">int</span> <span class="o">-&gt;</span> <span class="o">?</span><span class="n">max_leaf_nodes</span><span class="o">:</span><span class="kt">int</span> <span class="o">-&gt;</span> <span class="o">?</span><span class="n">warm_start</span><span class="o">:</span><span class="kt">bool</span> <span class="o">-&gt;</span> <span class="o">?</span><span class="n">presort</span><span class="o">:</span><span class="nn">Py</span><span class="p">.</span><span class="nn">Object</span><span class="p">.</span><span class="n">t</span> <span class="o">-&gt;</span> <span class="o">?</span><span class="n">validation_fraction</span><span class="o">:</span><span class="kt">float</span> <span class="o">-&gt;</span> <span class="o">?</span><span class="n">n_iter_no_change</span><span class="o">:</span><span class="kt">int</span> <span class="o">-&gt;</span> <span class="o">?</span><span class="n">tol</span><span class="o">:</span><span class="kt">float</span> <span class="o">-&gt;</span> <span class="o">?</span><span class="n">ccp_alpha</span><span class="o">:</span><span class="kt">float</span> <span class="o">-&gt;</span> <span class="kt">unit</span> <span class="o">-&gt;</span> <span class="n">t</span>
</code></pre></div>

<p>Gradient Boosting for classification.</p>
<p>GB builds an additive model in a
forward stage-wise fashion; it allows for the optimization of
arbitrary differentiable loss functions. In each stage <code>n_classes_</code>
regression trees are fit on the negative gradient of the
binomial or multinomial deviance loss function. Binary classification
is a special case where only a single regression tree is induced.</p>
<p>Read more in the :ref:<code>User Guide &lt;gradient_boosting&gt;</code>.</p>
<h2 id="parameters_55">Parameters<a class="headerlink" href="#parameters_55" title="Permanent link">&para;</a></h2>
<p>loss : {'deviance', 'exponential'}, optional (default='deviance')
loss function to be optimized. 'deviance' refers to
deviance (= logistic regression) for classification
with probabilistic outputs. For loss 'exponential' gradient
boosting recovers the AdaBoost algorithm.</p>
<p>learning_rate : float, optional (default=0.1)
learning rate shrinks the contribution of each tree by <code>learning_rate</code>.
There is a trade-off between learning_rate and n_estimators.</p>
<p>n_estimators : int (default=100)
The number of boosting stages to perform. Gradient boosting
is fairly robust to over-fitting so a large number usually
results in better performance.</p>
<p>subsample : float, optional (default=1.0)
The fraction of samples to be used for fitting the individual base
learners. If smaller than 1.0 this results in Stochastic Gradient
Boosting. <code>subsample</code> interacts with the parameter <code>n_estimators</code>.
Choosing <code>subsample &lt; 1.0</code> leads to a reduction of variance
and an increase in bias.</p>
<p>criterion : string, optional (default='friedman_mse')
The function to measure the quality of a split. Supported criteria
are 'friedman_mse' for the mean squared error with improvement
score by Friedman, 'mse' for mean squared error, and 'mae' for
the mean absolute error. The default value of 'friedman_mse' is
generally the best as it can provide a better approximation in
some cases.</p>
<p>.. versionadded:: 0.18</p>
<p>min_samples_split : int, float, optional (default=2)
The minimum number of samples required to split an internal node:</p>
<ul>
<li>If int, then consider <code>min_samples_split</code> as the minimum number.</li>
<li>If float, then <code>min_samples_split</code> is a fraction and
<code>ceil(min_samples_split * n_samples)</code> are the minimum
number of samples for each split.</li>
</ul>
<p>.. versionchanged:: 0.18
Added float values for fractions.</p>
<p>min_samples_leaf : int, float, optional (default=1)
The minimum number of samples required to be at a leaf node.
A split point at any depth will only be considered if it leaves at
least <code>min_samples_leaf</code> training samples in each of the left and
right branches.  This may have the effect of smoothing the model,
especially in regression.</p>
<ul>
<li>If int, then consider <code>min_samples_leaf</code> as the minimum number.</li>
<li>If float, then <code>min_samples_leaf</code> is a fraction and
<code>ceil(min_samples_leaf * n_samples)</code> are the minimum
number of samples for each node.</li>
</ul>
<p>.. versionchanged:: 0.18
Added float values for fractions.</p>
<p>min_weight_fraction_leaf : float, optional (default=0.)
The minimum weighted fraction of the sum total of weights (of all
the input samples) required to be at a leaf node. Samples have
equal weight when sample_weight is not provided.</p>
<p>max_depth : integer, optional (default=3)
maximum depth of the individual regression estimators. The maximum
depth limits the number of nodes in the tree. Tune this parameter
for best performance; the best value depends on the interaction
of the input variables.</p>
<p>min_impurity_decrease : float, optional (default=0.)
A node will be split if this split induces a decrease of the impurity
greater than or equal to this value.</p>
<p>The weighted impurity decrease equation is the following::</p>
<p>N_t / N * (impurity - N_t_R / N_t * right_impurity
- N_t_L / N_t * left_impurity)</p>
<p>where <code>N</code> is the total number of samples, <code>N_t</code> is the number of
samples at the current node, <code>N_t_L</code> is the number of samples in the
left child, and <code>N_t_R</code> is the number of samples in the right child.</p>
<p><code>N</code>, <code>N_t</code>, <code>N_t_R</code> and <code>N_t_L</code> all refer to the weighted sum,
if <code>sample_weight</code> is passed.</p>
<p>.. versionadded:: 0.19</p>
<p>min_impurity_split : float, (default=1e-7)
Threshold for early stopping in tree growth. A node will split
if its impurity is above the threshold, otherwise it is a leaf.</p>
<p>.. deprecated:: 0.19
<code>min_impurity_split</code> has been deprecated in favor of
<code>min_impurity_decrease</code> in 0.19. The default value of
<code>min_impurity_split</code> will change from 1e-7 to 0 in 0.23 and it
will be removed in 0.25. Use <code>min_impurity_decrease</code> instead.</p>
<p>init : estimator or 'zero', optional (default=None)
An estimator object that is used to compute the initial predictions.
<code>init</code> has to provide :meth:<code>fit</code> and :meth:<code>predict_proba</code>. If
'zero', the initial raw predictions are set to zero. By default, a
<code>DummyEstimator</code> predicting the classes priors is used.</p>
<p>random_state : int, RandomState instance or None, optional (default=None)
If int, random_state is the seed used by the random number generator;
If RandomState instance, random_state is the random number generator;
If None, the random number generator is the RandomState instance used
by <code>np.random</code>.</p>
<p>max_features : int, float, string or None, optional (default=None)
The number of features to consider when looking for the best split:</p>
<ul>
<li>If int, then consider <code>max_features</code> features at each split.</li>
<li>If float, then <code>max_features</code> is a fraction and
<code>int(max_features * n_features)</code> features are considered at each
split.</li>
<li>If 'auto', then <code>max_features=sqrt(n_features)</code>.</li>
<li>If 'sqrt', then <code>max_features=sqrt(n_features)</code>.</li>
<li>If 'log2', then <code>max_features=log2(n_features)</code>.</li>
<li>If None, then <code>max_features=n_features</code>.</li>
</ul>
<p>Choosing <code>max_features &lt; n_features</code> leads to a reduction of variance
and an increase in bias.</p>
<p>Note: the search for a split does not stop until at least one
valid partition of the node samples is found, even if it requires to
effectively inspect more than <code>max_features</code> features.</p>
<p>verbose : int, default: 0
Enable verbose output. If 1 then it prints progress and performance
once in a while (the more trees the lower the frequency). If greater
than 1 then it prints progress and performance for every tree.</p>
<p>max_leaf_nodes : int or None, optional (default=None)
Grow trees with <code>max_leaf_nodes</code> in best-first fashion.
Best nodes are defined as relative reduction in impurity.
If None then unlimited number of leaf nodes.</p>
<p>warm_start : bool, default: False
When set to <code>True</code>, reuse the solution of the previous call to fit
and add more estimators to the ensemble, otherwise, just erase the
previous solution. See :term:<code>the Glossary &lt;warm_start&gt;</code>.</p>
<p>presort : deprecated, default='deprecated'
This parameter is deprecated and will be removed in v0.24.</p>
<p>.. deprecated :: 0.22</p>
<p>validation_fraction : float, optional, default 0.1
The proportion of training data to set aside as validation set for
early stopping. Must be between 0 and 1.
Only used if <code>n_iter_no_change</code> is set to an integer.</p>
<p>.. versionadded:: 0.20</p>
<p>n_iter_no_change : int, default None
<code>n_iter_no_change</code> is used to decide if early stopping will be used
to terminate training when validation score is not improving. By
default it is set to None to disable early stopping. If set to a
number, it will set aside <code>validation_fraction</code> size of the training
data as validation and terminate training when validation score is not
improving in all of the previous <code>n_iter_no_change</code> numbers of
iterations. The split is stratified.</p>
<p>.. versionadded:: 0.20</p>
<p>tol : float, optional, default 1e-4
Tolerance for the early stopping. When the loss is not improving
by at least tol for <code>n_iter_no_change</code> iterations (if set to a
number), the training stops.</p>
<p>.. versionadded:: 0.20</p>
<p>ccp_alpha : non-negative float, optional (default=0.0)
Complexity parameter used for Minimal Cost-Complexity Pruning. The
subtree with the largest cost complexity that is smaller than
<code>ccp_alpha</code> will be chosen. By default, no pruning is performed. See
:ref:<code>minimal_cost_complexity_pruning</code> for details.</p>
<p>.. versionadded:: 0.22</p>
<h2 id="attributes_6">Attributes<a class="headerlink" href="#attributes_6" title="Permanent link">&para;</a></h2>
<p>n_estimators_ : int
The number of estimators as selected by early stopping (if
<code>n_iter_no_change</code> is specified). Otherwise it is set to
<code>n_estimators</code>.</p>
<p>.. versionadded:: 0.20</p>
<p>feature_importances_ : array, shape (n_features,)
The feature importances (the higher, the more important the feature).</p>
<p>oob_improvement_ : array, shape (n_estimators,)
The improvement in loss (= deviance) on the out-of-bag samples
relative to the previous iteration.
<code>oob_improvement_[0]</code> is the improvement in
loss of the first stage over the <code>init</code> estimator.
Only available if <code>subsample &lt; 1.0</code></p>
<p>train_score_ : array, shape (n_estimators,)
The i-th score <code>train_score_[i]</code> is the deviance (= loss) of the
model at iteration <code>i</code> on the in-bag sample.
If <code>subsample == 1</code> this is the deviance on the training data.</p>
<p>loss_ : LossFunction
The concrete <code>LossFunction</code> object.</p>
<p>init_ : estimator
The estimator that provides the initial predictions.
Set via the <code>init</code> argument or <code>loss.init_estimator</code>.</p>
<p>estimators_ : ndarray of DecisionTreeRegressor,shape (n_estimators, <code>loss_.K</code>)
The collection of fitted sub-estimators. <code>loss_.K</code> is 1 for binary
classification, otherwise n_classes.</p>
<p>classes_ : array of shape (n_classes,)
The classes labels.</p>
<h2 id="notes_5">Notes<a class="headerlink" href="#notes_5" title="Permanent link">&para;</a></h2>
<p>The features are always randomly permuted at each split. Therefore,
the best found split may vary, even with the same training data and
<code>max_features=n_features</code>, if the improvement of the criterion is
identical for several splits enumerated during the search of the best
split. To obtain a deterministic behaviour during fitting,
<code>random_state</code> has to be fixed.</p>
<h2 id="see-also_4">See also<a class="headerlink" href="#see-also_4" title="Permanent link">&para;</a></h2>
<p>sklearn.ensemble.HistGradientBoostingClassifier,
sklearn.tree.DecisionTreeClassifier, RandomForestClassifier
AdaBoostClassifier</p>
<h2 id="references_6">References<a class="headerlink" href="#references_6" title="Permanent link">&para;</a></h2>
<p>J. Friedman, Greedy Function Approximation: A Gradient Boosting
Machine, The Annals of Statistics, Vol. 29, No. 5, 2001.</p>
<p>J. Friedman, Stochastic Gradient Boosting, 1999</p>
<p>T. Hastie, R. Tibshirani and J. Friedman.
Elements of Statistical Learning Ed. 2, Springer, 2009.</p>
<div class="highlight"><pre><span></span><code><span class="k">val</span> <span class="n">get_item</span> <span class="o">:</span> <span class="n">index</span><span class="o">:</span><span class="nn">Py</span><span class="p">.</span><span class="nn">Object</span><span class="p">.</span><span class="n">t</span> <span class="o">-&gt;</span> <span class="o">[&gt;</span> <span class="n">tag</span><span class="o">]</span> <span class="nn">Obj</span><span class="p">.</span><span class="n">t</span> <span class="o">-&gt;</span> <span class="nn">Py</span><span class="p">.</span><span class="nn">Object</span><span class="p">.</span><span class="n">t</span>
</code></pre></div>

<p>Return the index'th estimator in the ensemble.</p>
<div class="highlight"><pre><span></span><code><span class="k">val</span> <span class="n">iter</span> <span class="o">:</span> <span class="o">[&gt;</span> <span class="n">tag</span><span class="o">]</span> <span class="nn">Obj</span><span class="p">.</span><span class="n">t</span> <span class="o">-&gt;</span> <span class="nn">Dict</span><span class="p">.</span><span class="n">t</span> <span class="nn">Seq</span><span class="p">.</span><span class="n">t</span>
</code></pre></div>

<p>Return iterator over estimators in the ensemble.</p>
<div class="highlight"><pre><span></span><code><span class="k">val</span> <span class="n">apply</span> <span class="o">:</span> <span class="n">x</span><span class="o">:[&gt;`</span><span class="nc">ArrayLike</span><span class="o">]</span> <span class="nn">Np</span><span class="p">.</span><span class="nn">Obj</span><span class="p">.</span><span class="n">t</span> <span class="o">-&gt;</span> <span class="o">[&gt;</span> <span class="n">tag</span><span class="o">]</span> <span class="nn">Obj</span><span class="p">.</span><span class="n">t</span> <span class="o">-&gt;</span> <span class="o">[&gt;`</span><span class="nc">ArrayLike</span><span class="o">]</span> <span class="nn">Np</span><span class="p">.</span><span class="nn">Obj</span><span class="p">.</span><span class="n">t</span>
</code></pre></div>

<p>Apply trees in the ensemble to X, return leaf indices.</p>
<p>.. versionadded:: 0.17</p>
<h2 id="parameters_56">Parameters<a class="headerlink" href="#parameters_56" title="Permanent link">&para;</a></h2>
<p>X : {array-like, sparse matrix}, shape (n_samples, n_features)
The input samples. Internally, its dtype will be converted to
<code>dtype=np.float32</code>. If a sparse matrix is provided, it will
be converted to a sparse <code>csr_matrix</code>.</p>
<h2 id="returns_43">Returns<a class="headerlink" href="#returns_43" title="Permanent link">&para;</a></h2>
<p>X_leaves : array-like, shape (n_samples, n_estimators, n_classes)
For each datapoint x in X and for each tree in the ensemble,
return the index of the leaf x ends up in each estimator.
In the case of binary classification n_classes is 1.</p>
<div class="highlight"><pre><span></span><code><span class="k">val</span> <span class="n">decision_function</span> <span class="o">:</span> <span class="n">x</span><span class="o">:[&gt;`</span><span class="nc">ArrayLike</span><span class="o">]</span> <span class="nn">Np</span><span class="p">.</span><span class="nn">Obj</span><span class="p">.</span><span class="n">t</span> <span class="o">-&gt;</span> <span class="o">[&gt;</span> <span class="n">tag</span><span class="o">]</span> <span class="nn">Obj</span><span class="p">.</span><span class="n">t</span> <span class="o">-&gt;</span> <span class="o">[&gt;`</span><span class="nc">ArrayLike</span><span class="o">]</span> <span class="nn">Np</span><span class="p">.</span><span class="nn">Obj</span><span class="p">.</span><span class="n">t</span>
</code></pre></div>

<p>Compute the decision function of <code>X</code>.</p>
<h2 id="parameters_57">Parameters<a class="headerlink" href="#parameters_57" title="Permanent link">&para;</a></h2>
<p>X : {array-like, sparse matrix}, shape (n_samples, n_features)
The input samples. Internally, it will be converted to
<code>dtype=np.float32</code> and if a sparse matrix is provided
to a sparse <code>csr_matrix</code>.</p>
<h2 id="returns_44">Returns<a class="headerlink" href="#returns_44" title="Permanent link">&para;</a></h2>
<p>score : array, shape (n_samples, n_classes) or (n_samples,)
The decision function of the input samples, which corresponds to
the raw values predicted from the trees of the ensemble . The
order of the classes corresponds to that in the attribute
:term:<code>classes_</code>. Regression and binary classification produce an
array of shape [n_samples].</p>
<div class="highlight"><pre><span></span><code><span class="k">val</span> <span class="n">fit</span> <span class="o">:</span> <span class="o">?</span><span class="n">sample_weight</span><span class="o">:[&gt;`</span><span class="nc">ArrayLike</span><span class="o">]</span> <span class="nn">Np</span><span class="p">.</span><span class="nn">Obj</span><span class="p">.</span><span class="n">t</span> <span class="o">-&gt;</span> <span class="o">?</span><span class="n">monitor</span><span class="o">:</span><span class="nn">Py</span><span class="p">.</span><span class="nn">Object</span><span class="p">.</span><span class="n">t</span> <span class="o">-&gt;</span> <span class="n">x</span><span class="o">:[&gt;`</span><span class="nc">ArrayLike</span><span class="o">]</span> <span class="nn">Np</span><span class="p">.</span><span class="nn">Obj</span><span class="p">.</span><span class="n">t</span> <span class="o">-&gt;</span> <span class="n">y</span><span class="o">:[&gt;`</span><span class="nc">ArrayLike</span><span class="o">]</span> <span class="nn">Np</span><span class="p">.</span><span class="nn">Obj</span><span class="p">.</span><span class="n">t</span> <span class="o">-&gt;</span> <span class="o">[&gt;</span> <span class="n">tag</span><span class="o">]</span> <span class="nn">Obj</span><span class="p">.</span><span class="n">t</span> <span class="o">-&gt;</span> <span class="n">t</span>
</code></pre></div>

<p>Fit the gradient boosting model.</p>
<h2 id="parameters_58">Parameters<a class="headerlink" href="#parameters_58" title="Permanent link">&para;</a></h2>
<p>X : {array-like, sparse matrix}, shape (n_samples, n_features)
The input samples. Internally, it will be converted to
<code>dtype=np.float32</code> and if a sparse matrix is provided
to a sparse <code>csr_matrix</code>.</p>
<p>y : array-like, shape (n_samples,)
Target values (strings or integers in classification, real numbers
in regression)
For classification, labels must correspond to classes.</p>
<p>sample_weight : array-like, shape (n_samples,) or None
Sample weights. If None, then samples are equally weighted. Splits
that would create child nodes with net zero or negative weight are
ignored while searching for a split in each node. In the case of
classification, splits are also ignored if they would result in any
single class carrying a negative weight in either child node.</p>
<p>monitor : callable, optional
The monitor is called after each iteration with the current
iteration, a reference to the estimator and the local variables of
<code>_fit_stages</code> as keyword arguments <code>callable(i, self,
locals())</code>. If the callable returns <code>True</code> the fitting procedure
is stopped. The monitor can be used for various things such as
computing held-out estimates, early stopping, model introspect, and
snapshoting.</p>
<h2 id="returns_45">Returns<a class="headerlink" href="#returns_45" title="Permanent link">&para;</a></h2>
<p>self : object</p>
<div class="highlight"><pre><span></span><code><span class="k">val</span> <span class="n">get_params</span> <span class="o">:</span> <span class="o">?</span><span class="n">deep</span><span class="o">:</span><span class="kt">bool</span> <span class="o">-&gt;</span> <span class="o">[&gt;</span> <span class="n">tag</span><span class="o">]</span> <span class="nn">Obj</span><span class="p">.</span><span class="n">t</span> <span class="o">-&gt;</span> <span class="nn">Dict</span><span class="p">.</span><span class="n">t</span>
</code></pre></div>

<p>Get parameters for this estimator.</p>
<h2 id="parameters_59">Parameters<a class="headerlink" href="#parameters_59" title="Permanent link">&para;</a></h2>
<p>deep : bool, default=True
If True, will return the parameters for this estimator and
contained subobjects that are estimators.</p>
<h2 id="returns_46">Returns<a class="headerlink" href="#returns_46" title="Permanent link">&para;</a></h2>
<p>params : mapping of string to any
Parameter names mapped to their values.</p>
<div class="highlight"><pre><span></span><code><span class="k">val</span> <span class="n">predict</span> <span class="o">:</span> <span class="n">x</span><span class="o">:[&gt;`</span><span class="nc">ArrayLike</span><span class="o">]</span> <span class="nn">Np</span><span class="p">.</span><span class="nn">Obj</span><span class="p">.</span><span class="n">t</span> <span class="o">-&gt;</span> <span class="o">[&gt;</span> <span class="n">tag</span><span class="o">]</span> <span class="nn">Obj</span><span class="p">.</span><span class="n">t</span> <span class="o">-&gt;</span> <span class="o">[&gt;`</span><span class="nc">ArrayLike</span><span class="o">]</span> <span class="nn">Np</span><span class="p">.</span><span class="nn">Obj</span><span class="p">.</span><span class="n">t</span>
</code></pre></div>

<p>Predict class for X.</p>
<h2 id="parameters_60">Parameters<a class="headerlink" href="#parameters_60" title="Permanent link">&para;</a></h2>
<p>X : {array-like, sparse matrix}, shape (n_samples, n_features)
The input samples. Internally, it will be converted to
<code>dtype=np.float32</code> and if a sparse matrix is provided
to a sparse <code>csr_matrix</code>.</p>
<h2 id="returns_47">Returns<a class="headerlink" href="#returns_47" title="Permanent link">&para;</a></h2>
<p>y : array, shape (n_samples,)
The predicted values.</p>
<div class="highlight"><pre><span></span><code><span class="k">val</span> <span class="n">predict_log_proba</span> <span class="o">:</span> <span class="n">x</span><span class="o">:[&gt;`</span><span class="nc">ArrayLike</span><span class="o">]</span> <span class="nn">Np</span><span class="p">.</span><span class="nn">Obj</span><span class="p">.</span><span class="n">t</span> <span class="o">-&gt;</span> <span class="o">[&gt;</span> <span class="n">tag</span><span class="o">]</span> <span class="nn">Obj</span><span class="p">.</span><span class="n">t</span> <span class="o">-&gt;</span> <span class="o">[&gt;`</span><span class="nc">ArrayLike</span><span class="o">]</span> <span class="nn">Np</span><span class="p">.</span><span class="nn">Obj</span><span class="p">.</span><span class="n">t</span>
</code></pre></div>

<p>Predict class log-probabilities for X.</p>
<h2 id="parameters_61">Parameters<a class="headerlink" href="#parameters_61" title="Permanent link">&para;</a></h2>
<p>X : {array-like, sparse matrix}, shape (n_samples, n_features)
The input samples. Internally, it will be converted to
<code>dtype=np.float32</code> and if a sparse matrix is provided
to a sparse <code>csr_matrix</code>.</p>
<h2 id="raises">Raises<a class="headerlink" href="#raises" title="Permanent link">&para;</a></h2>
<p>AttributeError
If the <code>loss</code> does not support probabilities.</p>
<h2 id="returns_48">Returns<a class="headerlink" href="#returns_48" title="Permanent link">&para;</a></h2>
<p>p : array, shape (n_samples, n_classes)
The class log-probabilities of the input samples. The order of the
classes corresponds to that in the attribute :term:<code>classes_</code>.</p>
<div class="highlight"><pre><span></span><code><span class="k">val</span> <span class="n">predict_proba</span> <span class="o">:</span> <span class="n">x</span><span class="o">:[&gt;`</span><span class="nc">ArrayLike</span><span class="o">]</span> <span class="nn">Np</span><span class="p">.</span><span class="nn">Obj</span><span class="p">.</span><span class="n">t</span> <span class="o">-&gt;</span> <span class="o">[&gt;</span> <span class="n">tag</span><span class="o">]</span> <span class="nn">Obj</span><span class="p">.</span><span class="n">t</span> <span class="o">-&gt;</span> <span class="o">[&gt;`</span><span class="nc">ArrayLike</span><span class="o">]</span> <span class="nn">Np</span><span class="p">.</span><span class="nn">Obj</span><span class="p">.</span><span class="n">t</span>
</code></pre></div>

<p>Predict class probabilities for X.</p>
<h2 id="parameters_62">Parameters<a class="headerlink" href="#parameters_62" title="Permanent link">&para;</a></h2>
<p>X : {array-like, sparse matrix}, shape (n_samples, n_features)
The input samples. Internally, it will be converted to
<code>dtype=np.float32</code> and if a sparse matrix is provided
to a sparse <code>csr_matrix</code>.</p>
<h2 id="raises_1">Raises<a class="headerlink" href="#raises_1" title="Permanent link">&para;</a></h2>
<p>AttributeError
If the <code>loss</code> does not support probabilities.</p>
<h2 id="returns_49">Returns<a class="headerlink" href="#returns_49" title="Permanent link">&para;</a></h2>
<p>p : array, shape (n_samples, n_classes)
The class probabilities of the input samples. The order of the
classes corresponds to that in the attribute :term:<code>classes_</code>.</p>
<div class="highlight"><pre><span></span><code><span class="k">val</span> <span class="n">score</span> <span class="o">:</span> <span class="o">?</span><span class="n">sample_weight</span><span class="o">:[&gt;`</span><span class="nc">ArrayLike</span><span class="o">]</span> <span class="nn">Np</span><span class="p">.</span><span class="nn">Obj</span><span class="p">.</span><span class="n">t</span> <span class="o">-&gt;</span> <span class="n">x</span><span class="o">:[&gt;`</span><span class="nc">ArrayLike</span><span class="o">]</span> <span class="nn">Np</span><span class="p">.</span><span class="nn">Obj</span><span class="p">.</span><span class="n">t</span> <span class="o">-&gt;</span> <span class="n">y</span><span class="o">:[&gt;`</span><span class="nc">ArrayLike</span><span class="o">]</span> <span class="nn">Np</span><span class="p">.</span><span class="nn">Obj</span><span class="p">.</span><span class="n">t</span> <span class="o">-&gt;</span> <span class="o">[&gt;</span> <span class="n">tag</span><span class="o">]</span> <span class="nn">Obj</span><span class="p">.</span><span class="n">t</span> <span class="o">-&gt;</span> <span class="kt">float</span>
</code></pre></div>

<p>Return the mean accuracy on the given test data and labels.</p>
<p>In multi-label classification, this is the subset accuracy
which is a harsh metric since you require for each sample that
each label set be correctly predicted.</p>
<h2 id="parameters_63">Parameters<a class="headerlink" href="#parameters_63" title="Permanent link">&para;</a></h2>
<p>X : array-like of shape (n_samples, n_features)
Test samples.</p>
<p>y : array-like of shape (n_samples,) or (n_samples, n_outputs)
True labels for X.</p>
<p>sample_weight : array-like of shape (n_samples,), default=None
Sample weights.</p>
<h2 id="returns_50">Returns<a class="headerlink" href="#returns_50" title="Permanent link">&para;</a></h2>
<p>score : float
Mean accuracy of self.predict(X) wrt. y.</p>
<div class="highlight"><pre><span></span><code><span class="k">val</span> <span class="n">set_params</span> <span class="o">:</span> <span class="o">?</span><span class="n">params</span><span class="o">:(</span><span class="kt">string</span> <span class="o">*</span> <span class="nn">Py</span><span class="p">.</span><span class="nn">Object</span><span class="p">.</span><span class="n">t</span><span class="o">)</span> <span class="kt">list</span> <span class="o">-&gt;</span> <span class="o">[&gt;</span> <span class="n">tag</span><span class="o">]</span> <span class="nn">Obj</span><span class="p">.</span><span class="n">t</span> <span class="o">-&gt;</span> <span class="n">t</span>
</code></pre></div>

<p>Set the parameters of this estimator.</p>
<p>The method works on simple estimators as well as on nested objects
(such as pipelines). The latter have parameters of the form
<code>&lt;component&gt;__&lt;parameter&gt;</code> so that it's possible to update each
component of a nested object.</p>
<h2 id="parameters_64">Parameters<a class="headerlink" href="#parameters_64" title="Permanent link">&para;</a></h2>
<p>**params : dict
Estimator parameters.</p>
<h2 id="returns_51">Returns<a class="headerlink" href="#returns_51" title="Permanent link">&para;</a></h2>
<p>self : object
Estimator instance.</p>
<div class="highlight"><pre><span></span><code><span class="k">val</span> <span class="n">staged_decision_function</span> <span class="o">:</span> <span class="n">x</span><span class="o">:[&gt;`</span><span class="nc">ArrayLike</span><span class="o">]</span> <span class="nn">Np</span><span class="p">.</span><span class="nn">Obj</span><span class="p">.</span><span class="n">t</span> <span class="o">-&gt;</span> <span class="o">[&gt;</span> <span class="n">tag</span><span class="o">]</span> <span class="nn">Obj</span><span class="p">.</span><span class="n">t</span> <span class="o">-&gt;</span> <span class="o">[&gt;`</span><span class="nc">ArrayLike</span><span class="o">]</span> <span class="nn">Np</span><span class="p">.</span><span class="nn">Obj</span><span class="p">.</span><span class="n">t</span> <span class="nn">Seq</span><span class="p">.</span><span class="n">t</span>
</code></pre></div>

<p>Compute decision function of <code>X</code> for each iteration.</p>
<p>This method allows monitoring (i.e. determine error on testing set)
after each stage.</p>
<h2 id="parameters_65">Parameters<a class="headerlink" href="#parameters_65" title="Permanent link">&para;</a></h2>
<p>X : {array-like, sparse matrix}, shape (n_samples, n_features)
The input samples. Internally, it will be converted to
<code>dtype=np.float32</code> and if a sparse matrix is provided
to a sparse <code>csr_matrix</code>.</p>
<h2 id="returns_52">Returns<a class="headerlink" href="#returns_52" title="Permanent link">&para;</a></h2>
<p>score : generator of array, shape (n_samples, k)
The decision function of the input samples, which corresponds to
the raw values predicted from the trees of the ensemble . The
classes corresponds to that in the attribute :term:<code>classes_</code>.
Regression and binary classification are special cases with
<code>k == 1</code>, otherwise <code>k==n_classes</code>.</p>
<div class="highlight"><pre><span></span><code><span class="k">val</span> <span class="n">staged_predict</span> <span class="o">:</span> <span class="n">x</span><span class="o">:[&gt;`</span><span class="nc">ArrayLike</span><span class="o">]</span> <span class="nn">Np</span><span class="p">.</span><span class="nn">Obj</span><span class="p">.</span><span class="n">t</span> <span class="o">-&gt;</span> <span class="o">[&gt;</span> <span class="n">tag</span><span class="o">]</span> <span class="nn">Obj</span><span class="p">.</span><span class="n">t</span> <span class="o">-&gt;</span> <span class="o">[&gt;`</span><span class="nc">ArrayLike</span><span class="o">]</span> <span class="nn">Np</span><span class="p">.</span><span class="nn">Obj</span><span class="p">.</span><span class="n">t</span> <span class="nn">Seq</span><span class="p">.</span><span class="n">t</span>
</code></pre></div>

<p>Predict class at each stage for X.</p>
<p>This method allows monitoring (i.e. determine error on testing set)
after each stage.</p>
<h2 id="parameters_66">Parameters<a class="headerlink" href="#parameters_66" title="Permanent link">&para;</a></h2>
<p>X : {array-like, sparse matrix}, shape (n_samples, n_features)
The input samples. Internally, it will be converted to
<code>dtype=np.float32</code> and if a sparse matrix is provided
to a sparse <code>csr_matrix</code>.</p>
<h2 id="returns_53">Returns<a class="headerlink" href="#returns_53" title="Permanent link">&para;</a></h2>
<p>y : generator of array of shape (n_samples,)
The predicted value of the input samples.</p>
<div class="highlight"><pre><span></span><code><span class="k">val</span> <span class="n">staged_predict_proba</span> <span class="o">:</span> <span class="n">x</span><span class="o">:[&gt;`</span><span class="nc">ArrayLike</span><span class="o">]</span> <span class="nn">Np</span><span class="p">.</span><span class="nn">Obj</span><span class="p">.</span><span class="n">t</span> <span class="o">-&gt;</span> <span class="o">[&gt;</span> <span class="n">tag</span><span class="o">]</span> <span class="nn">Obj</span><span class="p">.</span><span class="n">t</span> <span class="o">-&gt;</span> <span class="o">[&gt;`</span><span class="nc">ArrayLike</span><span class="o">]</span> <span class="nn">Np</span><span class="p">.</span><span class="nn">Obj</span><span class="p">.</span><span class="n">t</span> <span class="nn">Seq</span><span class="p">.</span><span class="n">t</span>
</code></pre></div>

<p>Predict class probabilities at each stage for X.</p>
<p>This method allows monitoring (i.e. determine error on testing set)
after each stage.</p>
<h2 id="parameters_67">Parameters<a class="headerlink" href="#parameters_67" title="Permanent link">&para;</a></h2>
<p>X : {array-like, sparse matrix}, shape (n_samples, n_features)
The input samples. Internally, it will be converted to
<code>dtype=np.float32</code> and if a sparse matrix is provided
to a sparse <code>csr_matrix</code>.</p>
<h2 id="returns_54">Returns<a class="headerlink" href="#returns_54" title="Permanent link">&para;</a></h2>
<p>y : generator of array of shape (n_samples,)
The predicted value of the input samples.</p>
<p>Attribute n_estimators_: get value or raise Not_found if None.</p>
<div class="highlight"><pre><span></span><code><span class="k">val</span> <span class="n">n_estimators_</span> <span class="o">:</span> <span class="n">t</span> <span class="o">-&gt;</span> <span class="kt">int</span>
</code></pre></div>

<p>Attribute n_estimators_: get value as an option.</p>
<div class="highlight"><pre><span></span><code><span class="k">val</span> <span class="n">n_estimators_opt</span> <span class="o">:</span> <span class="n">t</span> <span class="o">-&gt;</span> <span class="o">(</span><span class="kt">int</span><span class="o">)</span> <span class="n">option</span>
</code></pre></div>

<p>Attribute feature_importances_: get value or raise Not_found if None.</p>
<div class="highlight"><pre><span></span><code><span class="k">val</span> <span class="n">feature_importances_</span> <span class="o">:</span> <span class="n">t</span> <span class="o">-&gt;</span> <span class="o">[&gt;`</span><span class="nc">ArrayLike</span><span class="o">]</span> <span class="nn">Np</span><span class="p">.</span><span class="nn">Obj</span><span class="p">.</span><span class="n">t</span>
</code></pre></div>

<p>Attribute feature_importances_: get value as an option.</p>
<div class="highlight"><pre><span></span><code><span class="k">val</span> <span class="n">feature_importances_opt</span> <span class="o">:</span> <span class="n">t</span> <span class="o">-&gt;</span> <span class="o">([&gt;`</span><span class="nc">ArrayLike</span><span class="o">]</span> <span class="nn">Np</span><span class="p">.</span><span class="nn">Obj</span><span class="p">.</span><span class="n">t</span><span class="o">)</span> <span class="n">option</span>
</code></pre></div>

<p>Attribute oob_improvement_: get value or raise Not_found if None.</p>
<div class="highlight"><pre><span></span><code><span class="k">val</span> <span class="n">oob_improvement_</span> <span class="o">:</span> <span class="n">t</span> <span class="o">-&gt;</span> <span class="o">[&gt;`</span><span class="nc">ArrayLike</span><span class="o">]</span> <span class="nn">Np</span><span class="p">.</span><span class="nn">Obj</span><span class="p">.</span><span class="n">t</span>
</code></pre></div>

<p>Attribute oob_improvement_: get value as an option.</p>
<div class="highlight"><pre><span></span><code><span class="k">val</span> <span class="n">oob_improvement_opt</span> <span class="o">:</span> <span class="n">t</span> <span class="o">-&gt;</span> <span class="o">([&gt;`</span><span class="nc">ArrayLike</span><span class="o">]</span> <span class="nn">Np</span><span class="p">.</span><span class="nn">Obj</span><span class="p">.</span><span class="n">t</span><span class="o">)</span> <span class="n">option</span>
</code></pre></div>

<p>Attribute train_score_: get value or raise Not_found if None.</p>
<div class="highlight"><pre><span></span><code><span class="k">val</span> <span class="n">train_score_</span> <span class="o">:</span> <span class="n">t</span> <span class="o">-&gt;</span> <span class="o">[&gt;`</span><span class="nc">ArrayLike</span><span class="o">]</span> <span class="nn">Np</span><span class="p">.</span><span class="nn">Obj</span><span class="p">.</span><span class="n">t</span>
</code></pre></div>

<p>Attribute train_score_: get value as an option.</p>
<div class="highlight"><pre><span></span><code><span class="k">val</span> <span class="n">train_score_opt</span> <span class="o">:</span> <span class="n">t</span> <span class="o">-&gt;</span> <span class="o">([&gt;`</span><span class="nc">ArrayLike</span><span class="o">]</span> <span class="nn">Np</span><span class="p">.</span><span class="nn">Obj</span><span class="p">.</span><span class="n">t</span><span class="o">)</span> <span class="n">option</span>
</code></pre></div>

<p>Attribute loss_: get value or raise Not_found if None.</p>
<div class="highlight"><pre><span></span><code><span class="k">val</span> <span class="n">loss_</span> <span class="o">:</span> <span class="n">t</span> <span class="o">-&gt;</span> <span class="nn">Np</span><span class="p">.</span><span class="nn">NumpyRaw</span><span class="p">.</span><span class="nn">Ndarray</span><span class="p">.</span><span class="n">t</span> <span class="o">-&gt;</span> <span class="nn">Np</span><span class="p">.</span><span class="nn">NumpyRaw</span><span class="p">.</span><span class="nn">Ndarray</span><span class="p">.</span><span class="n">t</span> <span class="o">-&gt;</span> <span class="kt">float</span>
</code></pre></div>

<p>Attribute loss_: get value as an option.</p>
<div class="highlight"><pre><span></span><code><span class="k">val</span> <span class="n">loss_opt</span> <span class="o">:</span> <span class="n">t</span> <span class="o">-&gt;</span> <span class="o">(</span><span class="nn">Np</span><span class="p">.</span><span class="nn">NumpyRaw</span><span class="p">.</span><span class="nn">Ndarray</span><span class="p">.</span><span class="n">t</span> <span class="o">-&gt;</span> <span class="nn">Np</span><span class="p">.</span><span class="nn">NumpyRaw</span><span class="p">.</span><span class="nn">Ndarray</span><span class="p">.</span><span class="n">t</span> <span class="o">-&gt;</span> <span class="kt">float</span><span class="o">)</span> <span class="n">option</span>
</code></pre></div>

<p>Attribute init_: get value or raise Not_found if None.</p>
<div class="highlight"><pre><span></span><code><span class="k">val</span> <span class="n">init_</span> <span class="o">:</span> <span class="n">t</span> <span class="o">-&gt;</span> <span class="o">[`</span><span class="nc">BaseEstimator</span><span class="o">|`</span><span class="nc">Object</span><span class="o">]</span> <span class="nn">Np</span><span class="p">.</span><span class="nn">Obj</span><span class="p">.</span><span class="n">t</span>
</code></pre></div>

<p>Attribute init_: get value as an option.</p>
<div class="highlight"><pre><span></span><code><span class="k">val</span> <span class="n">init_opt</span> <span class="o">:</span> <span class="n">t</span> <span class="o">-&gt;</span> <span class="o">([`</span><span class="nc">BaseEstimator</span><span class="o">|`</span><span class="nc">Object</span><span class="o">]</span> <span class="nn">Np</span><span class="p">.</span><span class="nn">Obj</span><span class="p">.</span><span class="n">t</span><span class="o">)</span> <span class="n">option</span>
</code></pre></div>

<p>Attribute estimators_: get value or raise Not_found if None.</p>
<div class="highlight"><pre><span></span><code><span class="k">val</span> <span class="n">estimators_</span> <span class="o">:</span> <span class="n">t</span> <span class="o">-&gt;</span> <span class="nn">Py</span><span class="p">.</span><span class="nn">Object</span><span class="p">.</span><span class="n">t</span>
</code></pre></div>

<p>Attribute estimators_: get value as an option.</p>
<div class="highlight"><pre><span></span><code><span class="k">val</span> <span class="n">estimators_opt</span> <span class="o">:</span> <span class="n">t</span> <span class="o">-&gt;</span> <span class="o">(</span><span class="nn">Py</span><span class="p">.</span><span class="nn">Object</span><span class="p">.</span><span class="n">t</span><span class="o">)</span> <span class="n">option</span>
</code></pre></div>

<p>Attribute classes_: get value or raise Not_found if None.</p>
<div class="highlight"><pre><span></span><code><span class="k">val</span> <span class="n">classes_</span> <span class="o">:</span> <span class="n">t</span> <span class="o">-&gt;</span> <span class="o">[&gt;`</span><span class="nc">ArrayLike</span><span class="o">]</span> <span class="nn">Np</span><span class="p">.</span><span class="nn">Obj</span><span class="p">.</span><span class="n">t</span>
</code></pre></div>

<p>Attribute classes_: get value as an option.</p>
<div class="highlight"><pre><span></span><code><span class="k">val</span> <span class="n">classes_opt</span> <span class="o">:</span> <span class="n">t</span> <span class="o">-&gt;</span> <span class="o">([&gt;`</span><span class="nc">ArrayLike</span><span class="o">]</span> <span class="nn">Np</span><span class="p">.</span><span class="nn">Obj</span><span class="p">.</span><span class="n">t</span><span class="o">)</span> <span class="n">option</span>
</code></pre></div>

<p>Print the object to a human-readable representation.</p>
<div class="highlight"><pre><span></span><code><span class="k">val</span> <span class="n">to_string</span> <span class="o">:</span> <span class="n">t</span> <span class="o">-&gt;</span> <span class="kt">string</span>
</code></pre></div>

<p>Print the object to a human-readable representation.</p>
<div class="highlight"><pre><span></span><code><span class="k">val</span> <span class="n">show</span> <span class="o">:</span> <span class="n">t</span> <span class="o">-&gt;</span> <span class="kt">string</span>
</code></pre></div>

<p>Pretty-print the object to a formatter.</p>
<div class="highlight"><pre><span></span><code><span class="k">val</span> <span class="n">pp</span> <span class="o">:</span> <span class="nn">Format</span><span class="p">.</span><span class="n">formatter</span> <span class="o">-&gt;</span> <span class="n">t</span> <span class="o">-&gt;</span> <span class="kt">unit</span> <span class="o">[@@</span><span class="n">ocaml</span><span class="o">.</span><span class="n">toplevel_printer</span><span class="o">]</span>



<span class="k">module</span> <span class="nc">GradientBoostingRegressor</span> <span class="o">:</span> <span class="k">sig</span>
<span class="k">type</span> <span class="n">tag</span> <span class="o">=</span> <span class="o">[`</span><span class="nc">GradientBoostingRegressor</span><span class="o">]</span>
<span class="k">type</span> <span class="n">t</span> <span class="o">=</span> <span class="o">[`</span><span class="nc">BaseEnsemble</span> <span class="o">|</span> <span class="o">`</span><span class="nc">BaseEstimator</span> <span class="o">|</span> <span class="o">`</span><span class="nc">BaseGradientBoosting</span> <span class="o">|</span> <span class="o">`</span><span class="nc">GradientBoostingRegressor</span> <span class="o">|</span> <span class="o">`</span><span class="nc">MetaEstimatorMixin</span> <span class="o">|</span> <span class="o">`</span><span class="nc">Object</span> <span class="o">|</span> <span class="o">`</span><span class="nc">RegressorMixin</span><span class="o">]</span> <span class="nn">Obj</span><span class="p">.</span><span class="n">t</span>
<span class="k">val</span> <span class="n">of_pyobject</span> <span class="o">:</span> <span class="nn">Py</span><span class="p">.</span><span class="nn">Object</span><span class="p">.</span><span class="n">t</span> <span class="o">-&gt;</span> <span class="n">t</span>
<span class="k">val</span> <span class="n">to_pyobject</span> <span class="o">:</span> <span class="o">[&gt;</span> <span class="n">tag</span><span class="o">]</span> <span class="nn">Obj</span><span class="p">.</span><span class="n">t</span> <span class="o">-&gt;</span> <span class="nn">Py</span><span class="p">.</span><span class="nn">Object</span><span class="p">.</span><span class="n">t</span>

<span class="k">val</span> <span class="n">as_regressor</span> <span class="o">:</span> <span class="n">t</span> <span class="o">-&gt;</span> <span class="o">[`</span><span class="nc">RegressorMixin</span><span class="o">]</span> <span class="nn">Obj</span><span class="p">.</span><span class="n">t</span>
<span class="k">val</span> <span class="n">as_gradient_boosting</span> <span class="o">:</span> <span class="n">t</span> <span class="o">-&gt;</span> <span class="o">[`</span><span class="nc">BaseGradientBoosting</span><span class="o">]</span> <span class="nn">Obj</span><span class="p">.</span><span class="n">t</span>
<span class="k">val</span> <span class="n">as_meta_estimator</span> <span class="o">:</span> <span class="n">t</span> <span class="o">-&gt;</span> <span class="o">[`</span><span class="nc">MetaEstimatorMixin</span><span class="o">]</span> <span class="nn">Obj</span><span class="p">.</span><span class="n">t</span>
<span class="k">val</span> <span class="n">as_estimator</span> <span class="o">:</span> <span class="n">t</span> <span class="o">-&gt;</span> <span class="o">[`</span><span class="nc">BaseEstimator</span><span class="o">]</span> <span class="nn">Obj</span><span class="p">.</span><span class="n">t</span>
<span class="k">val</span> <span class="n">as_ensemble</span> <span class="o">:</span> <span class="n">t</span> <span class="o">-&gt;</span> <span class="o">[`</span><span class="nc">BaseEnsemble</span><span class="o">]</span> <span class="nn">Obj</span><span class="p">.</span><span class="n">t</span>
<span class="k">val</span> <span class="n">create</span> <span class="o">:</span> <span class="o">?</span><span class="n">loss</span><span class="o">:[`</span><span class="nc">Ls</span> <span class="o">|</span> <span class="o">`</span><span class="nc">Lad</span> <span class="o">|</span> <span class="o">`</span><span class="nc">Huber</span> <span class="o">|</span> <span class="o">`</span><span class="nc">Quantile</span><span class="o">]</span> <span class="o">-&gt;</span> <span class="o">?</span><span class="n">learning_rate</span><span class="o">:</span><span class="kt">float</span> <span class="o">-&gt;</span> <span class="o">?</span><span class="n">n_estimators</span><span class="o">:</span><span class="kt">int</span> <span class="o">-&gt;</span> <span class="o">?</span><span class="n">subsample</span><span class="o">:</span><span class="kt">float</span> <span class="o">-&gt;</span> <span class="o">?</span><span class="n">criterion</span><span class="o">:</span><span class="kt">string</span> <span class="o">-&gt;</span> <span class="o">?</span><span class="n">min_samples_split</span><span class="o">:[`</span><span class="nc">F</span> <span class="k">of</span> <span class="kt">float</span> <span class="o">|</span> <span class="o">`</span><span class="nc">I</span> <span class="k">of</span> <span class="kt">int</span><span class="o">]</span> <span class="o">-&gt;</span> <span class="o">?</span><span class="n">min_samples_leaf</span><span class="o">:[`</span><span class="nc">F</span> <span class="k">of</span> <span class="kt">float</span> <span class="o">|</span> <span class="o">`</span><span class="nc">I</span> <span class="k">of</span> <span class="kt">int</span><span class="o">]</span> <span class="o">-&gt;</span> <span class="o">?</span><span class="n">min_weight_fraction_leaf</span><span class="o">:</span><span class="kt">float</span> <span class="o">-&gt;</span> <span class="o">?</span><span class="n">max_depth</span><span class="o">:</span><span class="kt">int</span> <span class="o">-&gt;</span> <span class="o">?</span><span class="n">min_impurity_decrease</span><span class="o">:</span><span class="kt">float</span> <span class="o">-&gt;</span> <span class="o">?</span><span class="n">min_impurity_split</span><span class="o">:</span><span class="kt">float</span> <span class="o">-&gt;</span> <span class="o">?</span><span class="n">init</span><span class="o">:[`</span><span class="nc">BaseEstimator</span> <span class="k">of</span> <span class="o">[&gt;`</span><span class="nc">BaseEstimator</span><span class="o">]</span> <span class="nn">Np</span><span class="p">.</span><span class="nn">Obj</span><span class="p">.</span><span class="n">t</span> <span class="o">|</span> <span class="o">`</span><span class="nc">Zero</span><span class="o">]</span> <span class="o">-&gt;</span> <span class="o">?</span><span class="n">random_state</span><span class="o">:</span><span class="kt">int</span> <span class="o">-&gt;</span> <span class="o">?</span><span class="n">max_features</span><span class="o">:[`</span><span class="nc">F</span> <span class="k">of</span> <span class="kt">float</span> <span class="o">|</span> <span class="o">`</span><span class="nc">S</span> <span class="k">of</span> <span class="kt">string</span> <span class="o">|</span> <span class="o">`</span><span class="nc">I</span> <span class="k">of</span> <span class="kt">int</span><span class="o">]</span> <span class="o">-&gt;</span> <span class="o">?</span><span class="n">alpha</span><span class="o">:</span><span class="kt">float</span> <span class="o">-&gt;</span> <span class="o">?</span><span class="n">verbose</span><span class="o">:</span><span class="kt">int</span> <span class="o">-&gt;</span> <span class="o">?</span><span class="n">max_leaf_nodes</span><span class="o">:</span><span class="kt">int</span> <span class="o">-&gt;</span> <span class="o">?</span><span class="n">warm_start</span><span class="o">:</span><span class="kt">bool</span> <span class="o">-&gt;</span> <span class="o">?</span><span class="n">presort</span><span class="o">:</span><span class="nn">Py</span><span class="p">.</span><span class="nn">Object</span><span class="p">.</span><span class="n">t</span> <span class="o">-&gt;</span> <span class="o">?</span><span class="n">validation_fraction</span><span class="o">:</span><span class="kt">float</span> <span class="o">-&gt;</span> <span class="o">?</span><span class="n">n_iter_no_change</span><span class="o">:</span><span class="kt">int</span> <span class="o">-&gt;</span> <span class="o">?</span><span class="n">tol</span><span class="o">:</span><span class="kt">float</span> <span class="o">-&gt;</span> <span class="o">?</span><span class="n">ccp_alpha</span><span class="o">:</span><span class="kt">float</span> <span class="o">-&gt;</span> <span class="kt">unit</span> <span class="o">-&gt;</span> <span class="n">t</span>
</code></pre></div>

<p>Gradient Boosting for regression.</p>
<p>GB builds an additive model in a forward stage-wise fashion;
it allows for the optimization of arbitrary differentiable loss functions.
In each stage a regression tree is fit on the negative gradient of the
given loss function.</p>
<p>Read more in the :ref:<code>User Guide &lt;gradient_boosting&gt;</code>.</p>
<h2 id="parameters_68">Parameters<a class="headerlink" href="#parameters_68" title="Permanent link">&para;</a></h2>
<p>loss : {'ls', 'lad', 'huber', 'quantile'}, optional (default='ls')
loss function to be optimized. 'ls' refers to least squares
regression. 'lad' (least absolute deviation) is a highly robust
loss function solely based on order information of the input
variables. 'huber' is a combination of the two. 'quantile'
allows quantile regression (use <code>alpha</code> to specify the quantile).</p>
<p>learning_rate : float, optional (default=0.1)
learning rate shrinks the contribution of each tree by <code>learning_rate</code>.
There is a trade-off between learning_rate and n_estimators.</p>
<p>n_estimators : int (default=100)
The number of boosting stages to perform. Gradient boosting
is fairly robust to over-fitting so a large number usually
results in better performance.</p>
<p>subsample : float, optional (default=1.0)
The fraction of samples to be used for fitting the individual base
learners. If smaller than 1.0 this results in Stochastic Gradient
Boosting. <code>subsample</code> interacts with the parameter <code>n_estimators</code>.
Choosing <code>subsample &lt; 1.0</code> leads to a reduction of variance
and an increase in bias.</p>
<p>criterion : string, optional (default='friedman_mse')
The function to measure the quality of a split. Supported criteria
are 'friedman_mse' for the mean squared error with improvement
score by Friedman, 'mse' for mean squared error, and 'mae' for
the mean absolute error. The default value of 'friedman_mse' is
generally the best as it can provide a better approximation in
some cases.</p>
<p>.. versionadded:: 0.18</p>
<p>min_samples_split : int, float, optional (default=2)
The minimum number of samples required to split an internal node:</p>
<ul>
<li>If int, then consider <code>min_samples_split</code> as the minimum number.</li>
<li>If float, then <code>min_samples_split</code> is a fraction and
<code>ceil(min_samples_split * n_samples)</code> are the minimum
number of samples for each split.</li>
</ul>
<p>.. versionchanged:: 0.18
Added float values for fractions.</p>
<p>min_samples_leaf : int, float, optional (default=1)
The minimum number of samples required to be at a leaf node.
A split point at any depth will only be considered if it leaves at
least <code>min_samples_leaf</code> training samples in each of the left and
right branches.  This may have the effect of smoothing the model,
especially in regression.</p>
<ul>
<li>If int, then consider <code>min_samples_leaf</code> as the minimum number.</li>
<li>If float, then <code>min_samples_leaf</code> is a fraction and
<code>ceil(min_samples_leaf * n_samples)</code> are the minimum
number of samples for each node.</li>
</ul>
<p>.. versionchanged:: 0.18
Added float values for fractions.</p>
<p>min_weight_fraction_leaf : float, optional (default=0.)
The minimum weighted fraction of the sum total of weights (of all
the input samples) required to be at a leaf node. Samples have
equal weight when sample_weight is not provided.</p>
<p>max_depth : integer, optional (default=3)
maximum depth of the individual regression estimators. The maximum
depth limits the number of nodes in the tree. Tune this parameter
for best performance; the best value depends on the interaction
of the input variables.</p>
<p>min_impurity_decrease : float, optional (default=0.)
A node will be split if this split induces a decrease of the impurity
greater than or equal to this value.</p>
<p>The weighted impurity decrease equation is the following::</p>
<p>N_t / N * (impurity - N_t_R / N_t * right_impurity
- N_t_L / N_t * left_impurity)</p>
<p>where <code>N</code> is the total number of samples, <code>N_t</code> is the number of
samples at the current node, <code>N_t_L</code> is the number of samples in the
left child, and <code>N_t_R</code> is the number of samples in the right child.</p>
<p><code>N</code>, <code>N_t</code>, <code>N_t_R</code> and <code>N_t_L</code> all refer to the weighted sum,
if <code>sample_weight</code> is passed.</p>
<p>.. versionadded:: 0.19</p>
<p>min_impurity_split : float, (default=1e-7)
Threshold for early stopping in tree growth. A node will split
if its impurity is above the threshold, otherwise it is a leaf.</p>
<p>.. deprecated:: 0.19
<code>min_impurity_split</code> has been deprecated in favor of
<code>min_impurity_decrease</code> in 0.19. The default value of
<code>min_impurity_split</code> will change from 1e-7 to 0 in 0.23 and it
will be removed in 0.25. Use <code>min_impurity_decrease</code> instead.</p>
<p>init : estimator or 'zero', optional (default=None)
An estimator object that is used to compute the initial predictions.
<code>init</code> has to provide :term:<code>fit</code> and :term:<code>predict</code>. If 'zero', the
initial raw predictions are set to zero. By default a
<code>DummyEstimator</code> is used, predicting either the average target value
(for loss='ls'), or a quantile for the other losses.</p>
<p>random_state : int, RandomState instance or None, optional (default=None)
If int, random_state is the seed used by the random number generator;
If RandomState instance, random_state is the random number generator;
If None, the random number generator is the RandomState instance used
by <code>np.random</code>.</p>
<p>max_features : int, float, string or None, optional (default=None)
The number of features to consider when looking for the best split:</p>
<ul>
<li>If int, then consider <code>max_features</code> features at each split.</li>
<li>If float, then <code>max_features</code> is a fraction and
<code>int(max_features * n_features)</code> features are considered at each
split.</li>
<li>If 'auto', then <code>max_features=n_features</code>.</li>
<li>If 'sqrt', then <code>max_features=sqrt(n_features)</code>.</li>
<li>If 'log2', then <code>max_features=log2(n_features)</code>.</li>
<li>If None, then <code>max_features=n_features</code>.</li>
</ul>
<p>Choosing <code>max_features &lt; n_features</code> leads to a reduction of variance
and an increase in bias.</p>
<p>Note: the search for a split does not stop until at least one
valid partition of the node samples is found, even if it requires to
effectively inspect more than <code>max_features</code> features.</p>
<p>alpha : float (default=0.9)
The alpha-quantile of the huber loss function and the quantile
loss function. Only if <code>loss='huber'</code> or <code>loss='quantile'</code>.</p>
<p>verbose : int, default: 0
Enable verbose output. If 1 then it prints progress and performance
once in a while (the more trees the lower the frequency). If greater
than 1 then it prints progress and performance for every tree.</p>
<p>max_leaf_nodes : int or None, optional (default=None)
Grow trees with <code>max_leaf_nodes</code> in best-first fashion.
Best nodes are defined as relative reduction in impurity.
If None then unlimited number of leaf nodes.</p>
<p>warm_start : bool, default: False
When set to <code>True</code>, reuse the solution of the previous call to fit
and add more estimators to the ensemble, otherwise, just erase the
previous solution. See :term:<code>the Glossary &lt;warm_start&gt;</code>.</p>
<p>presort : deprecated, default='deprecated'
This parameter is deprecated and will be removed in v0.24.</p>
<p>.. deprecated :: 0.22</p>
<p>validation_fraction : float, optional, default 0.1
The proportion of training data to set aside as validation set for
early stopping. Must be between 0 and 1.
Only used if <code>n_iter_no_change</code> is set to an integer.</p>
<p>.. versionadded:: 0.20</p>
<p>n_iter_no_change : int, default None
<code>n_iter_no_change</code> is used to decide if early stopping will be used
to terminate training when validation score is not improving. By
default it is set to None to disable early stopping. If set to a
number, it will set aside <code>validation_fraction</code> size of the training
data as validation and terminate training when validation score is not
improving in all of the previous <code>n_iter_no_change</code> numbers of
iterations.</p>
<p>.. versionadded:: 0.20</p>
<p>tol : float, optional, default 1e-4
Tolerance for the early stopping. When the loss is not improving
by at least tol for <code>n_iter_no_change</code> iterations (if set to a
number), the training stops.</p>
<p>.. versionadded:: 0.20</p>
<p>ccp_alpha : non-negative float, optional (default=0.0)
Complexity parameter used for Minimal Cost-Complexity Pruning. The
subtree with the largest cost complexity that is smaller than
<code>ccp_alpha</code> will be chosen. By default, no pruning is performed. See
:ref:<code>minimal_cost_complexity_pruning</code> for details.</p>
<p>.. versionadded:: 0.22</p>
<h2 id="attributes_7">Attributes<a class="headerlink" href="#attributes_7" title="Permanent link">&para;</a></h2>
<p>feature_importances_ : array, shape (n_features,)
The feature importances (the higher, the more important the feature).</p>
<p>oob_improvement_ : array, shape (n_estimators,)
The improvement in loss (= deviance) on the out-of-bag samples
relative to the previous iteration.
<code>oob_improvement_[0]</code> is the improvement in
loss of the first stage over the <code>init</code> estimator.
Only available if <code>subsample &lt; 1.0</code></p>
<p>train_score_ : array, shape (n_estimators,)
The i-th score <code>train_score_[i]</code> is the deviance (= loss) of the
model at iteration <code>i</code> on the in-bag sample.
If <code>subsample == 1</code> this is the deviance on the training data.</p>
<p>loss_ : LossFunction
The concrete <code>LossFunction</code> object.</p>
<p>init_ : estimator
The estimator that provides the initial predictions.
Set via the <code>init</code> argument or <code>loss.init_estimator</code>.</p>
<p>estimators_ : array of DecisionTreeRegressor, shape (n_estimators, 1)
The collection of fitted sub-estimators.</p>
<h2 id="notes_6">Notes<a class="headerlink" href="#notes_6" title="Permanent link">&para;</a></h2>
<p>The features are always randomly permuted at each split. Therefore,
the best found split may vary, even with the same training data and
<code>max_features=n_features</code>, if the improvement of the criterion is
identical for several splits enumerated during the search of the best
split. To obtain a deterministic behaviour during fitting,
<code>random_state</code> has to be fixed.</p>
<h2 id="see-also_5">See also<a class="headerlink" href="#see-also_5" title="Permanent link">&para;</a></h2>
<p>sklearn.ensemble.HistGradientBoostingRegressor,
sklearn.tree.DecisionTreeRegressor, RandomForestRegressor</p>
<h2 id="references_7">References<a class="headerlink" href="#references_7" title="Permanent link">&para;</a></h2>
<p>J. Friedman, Greedy Function Approximation: A Gradient Boosting
Machine, The Annals of Statistics, Vol. 29, No. 5, 2001.</p>
<p>J. Friedman, Stochastic Gradient Boosting, 1999</p>
<p>T. Hastie, R. Tibshirani and J. Friedman.
Elements of Statistical Learning Ed. 2, Springer, 2009.</p>
<div class="highlight"><pre><span></span><code><span class="k">val</span> <span class="n">get_item</span> <span class="o">:</span> <span class="n">index</span><span class="o">:</span><span class="nn">Py</span><span class="p">.</span><span class="nn">Object</span><span class="p">.</span><span class="n">t</span> <span class="o">-&gt;</span> <span class="o">[&gt;</span> <span class="n">tag</span><span class="o">]</span> <span class="nn">Obj</span><span class="p">.</span><span class="n">t</span> <span class="o">-&gt;</span> <span class="nn">Py</span><span class="p">.</span><span class="nn">Object</span><span class="p">.</span><span class="n">t</span>
</code></pre></div>

<p>Return the index'th estimator in the ensemble.</p>
<div class="highlight"><pre><span></span><code><span class="k">val</span> <span class="n">iter</span> <span class="o">:</span> <span class="o">[&gt;</span> <span class="n">tag</span><span class="o">]</span> <span class="nn">Obj</span><span class="p">.</span><span class="n">t</span> <span class="o">-&gt;</span> <span class="nn">Dict</span><span class="p">.</span><span class="n">t</span> <span class="nn">Seq</span><span class="p">.</span><span class="n">t</span>
</code></pre></div>

<p>Return iterator over estimators in the ensemble.</p>
<div class="highlight"><pre><span></span><code><span class="k">val</span> <span class="n">apply</span> <span class="o">:</span> <span class="n">x</span><span class="o">:[&gt;`</span><span class="nc">ArrayLike</span><span class="o">]</span> <span class="nn">Np</span><span class="p">.</span><span class="nn">Obj</span><span class="p">.</span><span class="n">t</span> <span class="o">-&gt;</span> <span class="o">[&gt;</span> <span class="n">tag</span><span class="o">]</span> <span class="nn">Obj</span><span class="p">.</span><span class="n">t</span> <span class="o">-&gt;</span> <span class="o">[&gt;`</span><span class="nc">ArrayLike</span><span class="o">]</span> <span class="nn">Np</span><span class="p">.</span><span class="nn">Obj</span><span class="p">.</span><span class="n">t</span>
</code></pre></div>

<p>Apply trees in the ensemble to X, return leaf indices.</p>
<p>.. versionadded:: 0.17</p>
<h2 id="parameters_69">Parameters<a class="headerlink" href="#parameters_69" title="Permanent link">&para;</a></h2>
<p>X : {array-like, sparse matrix}, shape (n_samples, n_features)
The input samples. Internally, its dtype will be converted to
<code>dtype=np.float32</code>. If a sparse matrix is provided, it will
be converted to a sparse <code>csr_matrix</code>.</p>
<h2 id="returns_55">Returns<a class="headerlink" href="#returns_55" title="Permanent link">&para;</a></h2>
<p>X_leaves : array-like, shape (n_samples, n_estimators)
For each datapoint x in X and for each tree in the ensemble,
return the index of the leaf x ends up in each estimator.</p>
<div class="highlight"><pre><span></span><code><span class="k">val</span> <span class="n">fit</span> <span class="o">:</span> <span class="o">?</span><span class="n">sample_weight</span><span class="o">:[&gt;`</span><span class="nc">ArrayLike</span><span class="o">]</span> <span class="nn">Np</span><span class="p">.</span><span class="nn">Obj</span><span class="p">.</span><span class="n">t</span> <span class="o">-&gt;</span> <span class="o">?</span><span class="n">monitor</span><span class="o">:</span><span class="nn">Py</span><span class="p">.</span><span class="nn">Object</span><span class="p">.</span><span class="n">t</span> <span class="o">-&gt;</span> <span class="n">x</span><span class="o">:[&gt;`</span><span class="nc">ArrayLike</span><span class="o">]</span> <span class="nn">Np</span><span class="p">.</span><span class="nn">Obj</span><span class="p">.</span><span class="n">t</span> <span class="o">-&gt;</span> <span class="n">y</span><span class="o">:[&gt;`</span><span class="nc">ArrayLike</span><span class="o">]</span> <span class="nn">Np</span><span class="p">.</span><span class="nn">Obj</span><span class="p">.</span><span class="n">t</span> <span class="o">-&gt;</span> <span class="o">[&gt;</span> <span class="n">tag</span><span class="o">]</span> <span class="nn">Obj</span><span class="p">.</span><span class="n">t</span> <span class="o">-&gt;</span> <span class="n">t</span>
</code></pre></div>

<p>Fit the gradient boosting model.</p>
<h2 id="parameters_70">Parameters<a class="headerlink" href="#parameters_70" title="Permanent link">&para;</a></h2>
<p>X : {array-like, sparse matrix}, shape (n_samples, n_features)
The input samples. Internally, it will be converted to
<code>dtype=np.float32</code> and if a sparse matrix is provided
to a sparse <code>csr_matrix</code>.</p>
<p>y : array-like, shape (n_samples,)
Target values (strings or integers in classification, real numbers
in regression)
For classification, labels must correspond to classes.</p>
<p>sample_weight : array-like, shape (n_samples,) or None
Sample weights. If None, then samples are equally weighted. Splits
that would create child nodes with net zero or negative weight are
ignored while searching for a split in each node. In the case of
classification, splits are also ignored if they would result in any
single class carrying a negative weight in either child node.</p>
<p>monitor : callable, optional
The monitor is called after each iteration with the current
iteration, a reference to the estimator and the local variables of
<code>_fit_stages</code> as keyword arguments <code>callable(i, self,
locals())</code>. If the callable returns <code>True</code> the fitting procedure
is stopped. The monitor can be used for various things such as
computing held-out estimates, early stopping, model introspect, and
snapshoting.</p>
<h2 id="returns_56">Returns<a class="headerlink" href="#returns_56" title="Permanent link">&para;</a></h2>
<p>self : object</p>
<div class="highlight"><pre><span></span><code><span class="k">val</span> <span class="n">get_params</span> <span class="o">:</span> <span class="o">?</span><span class="n">deep</span><span class="o">:</span><span class="kt">bool</span> <span class="o">-&gt;</span> <span class="o">[&gt;</span> <span class="n">tag</span><span class="o">]</span> <span class="nn">Obj</span><span class="p">.</span><span class="n">t</span> <span class="o">-&gt;</span> <span class="nn">Dict</span><span class="p">.</span><span class="n">t</span>
</code></pre></div>

<p>Get parameters for this estimator.</p>
<h2 id="parameters_71">Parameters<a class="headerlink" href="#parameters_71" title="Permanent link">&para;</a></h2>
<p>deep : bool, default=True
If True, will return the parameters for this estimator and
contained subobjects that are estimators.</p>
<h2 id="returns_57">Returns<a class="headerlink" href="#returns_57" title="Permanent link">&para;</a></h2>
<p>params : mapping of string to any
Parameter names mapped to their values.</p>
<div class="highlight"><pre><span></span><code><span class="k">val</span> <span class="n">predict</span> <span class="o">:</span> <span class="n">x</span><span class="o">:[&gt;`</span><span class="nc">ArrayLike</span><span class="o">]</span> <span class="nn">Np</span><span class="p">.</span><span class="nn">Obj</span><span class="p">.</span><span class="n">t</span> <span class="o">-&gt;</span> <span class="o">[&gt;</span> <span class="n">tag</span><span class="o">]</span> <span class="nn">Obj</span><span class="p">.</span><span class="n">t</span> <span class="o">-&gt;</span> <span class="o">[&gt;`</span><span class="nc">ArrayLike</span><span class="o">]</span> <span class="nn">Np</span><span class="p">.</span><span class="nn">Obj</span><span class="p">.</span><span class="n">t</span>
</code></pre></div>

<p>Predict regression target for X.</p>
<h2 id="parameters_72">Parameters<a class="headerlink" href="#parameters_72" title="Permanent link">&para;</a></h2>
<p>X : {array-like, sparse matrix}, shape (n_samples, n_features)
The input samples. Internally, it will be converted to
<code>dtype=np.float32</code> and if a sparse matrix is provided
to a sparse <code>csr_matrix</code>.</p>
<h2 id="returns_58">Returns<a class="headerlink" href="#returns_58" title="Permanent link">&para;</a></h2>
<p>y : array, shape (n_samples,)
The predicted values.</p>
<div class="highlight"><pre><span></span><code><span class="k">val</span> <span class="n">score</span> <span class="o">:</span> <span class="o">?</span><span class="n">sample_weight</span><span class="o">:[&gt;`</span><span class="nc">ArrayLike</span><span class="o">]</span> <span class="nn">Np</span><span class="p">.</span><span class="nn">Obj</span><span class="p">.</span><span class="n">t</span> <span class="o">-&gt;</span> <span class="n">x</span><span class="o">:[&gt;`</span><span class="nc">ArrayLike</span><span class="o">]</span> <span class="nn">Np</span><span class="p">.</span><span class="nn">Obj</span><span class="p">.</span><span class="n">t</span> <span class="o">-&gt;</span> <span class="n">y</span><span class="o">:[&gt;`</span><span class="nc">ArrayLike</span><span class="o">]</span> <span class="nn">Np</span><span class="p">.</span><span class="nn">Obj</span><span class="p">.</span><span class="n">t</span> <span class="o">-&gt;</span> <span class="o">[&gt;</span> <span class="n">tag</span><span class="o">]</span> <span class="nn">Obj</span><span class="p">.</span><span class="n">t</span> <span class="o">-&gt;</span> <span class="kt">float</span>
</code></pre></div>

<p>Return the coefficient of determination R^2 of the prediction.</p>
<p>The coefficient R^2 is defined as (1 - u/v), where u is the residual
sum of squares ((y_true - y_pred) <strong> 2).sum() and v is the total
sum of squares ((y_true - y_true.mean()) </strong> 2).sum().
The best possible score is 1.0 and it can be negative (because the
model can be arbitrarily worse). A constant model that always
predicts the expected value of y, disregarding the input features,
would get a R^2 score of 0.0.</p>
<h2 id="parameters_73">Parameters<a class="headerlink" href="#parameters_73" title="Permanent link">&para;</a></h2>
<p>X : array-like of shape (n_samples, n_features)
Test samples. For some estimators this may be a
precomputed kernel matrix or a list of generic objects instead,
shape = (n_samples, n_samples_fitted),
where n_samples_fitted is the number of
samples used in the fitting for the estimator.</p>
<p>y : array-like of shape (n_samples,) or (n_samples, n_outputs)
True values for X.</p>
<p>sample_weight : array-like of shape (n_samples,), default=None
Sample weights.</p>
<h2 id="returns_59">Returns<a class="headerlink" href="#returns_59" title="Permanent link">&para;</a></h2>
<p>score : float
R^2 of self.predict(X) wrt. y.</p>
<h2 id="notes_7">Notes<a class="headerlink" href="#notes_7" title="Permanent link">&para;</a></h2>
<p>The R2 score used when calling <code>score</code> on a regressor will use
<code>multioutput='uniform_average'</code> from version 0.23 to keep consistent
with :func:<code>~sklearn.metrics.r2_score</code>. This will influence the
<code>score</code> method of all the multioutput regressors (except for
:class:<code>~sklearn.multioutput.MultiOutputRegressor</code>). To specify the
default value manually and avoid the warning, please either call
:func:<code>~sklearn.metrics.r2_score</code> directly or make a custom scorer with
:func:<code>~sklearn.metrics.make_scorer</code> (the built-in scorer <code>'r2'</code> uses
<code>multioutput='uniform_average'</code>).</p>
<div class="highlight"><pre><span></span><code><span class="k">val</span> <span class="n">set_params</span> <span class="o">:</span> <span class="o">?</span><span class="n">params</span><span class="o">:(</span><span class="kt">string</span> <span class="o">*</span> <span class="nn">Py</span><span class="p">.</span><span class="nn">Object</span><span class="p">.</span><span class="n">t</span><span class="o">)</span> <span class="kt">list</span> <span class="o">-&gt;</span> <span class="o">[&gt;</span> <span class="n">tag</span><span class="o">]</span> <span class="nn">Obj</span><span class="p">.</span><span class="n">t</span> <span class="o">-&gt;</span> <span class="n">t</span>
</code></pre></div>

<p>Set the parameters of this estimator.</p>
<p>The method works on simple estimators as well as on nested objects
(such as pipelines). The latter have parameters of the form
<code>&lt;component&gt;__&lt;parameter&gt;</code> so that it's possible to update each
component of a nested object.</p>
<h2 id="parameters_74">Parameters<a class="headerlink" href="#parameters_74" title="Permanent link">&para;</a></h2>
<p>**params : dict
Estimator parameters.</p>
<h2 id="returns_60">Returns<a class="headerlink" href="#returns_60" title="Permanent link">&para;</a></h2>
<p>self : object
Estimator instance.</p>
<div class="highlight"><pre><span></span><code><span class="k">val</span> <span class="n">staged_predict</span> <span class="o">:</span> <span class="n">x</span><span class="o">:[&gt;`</span><span class="nc">ArrayLike</span><span class="o">]</span> <span class="nn">Np</span><span class="p">.</span><span class="nn">Obj</span><span class="p">.</span><span class="n">t</span> <span class="o">-&gt;</span> <span class="o">[&gt;</span> <span class="n">tag</span><span class="o">]</span> <span class="nn">Obj</span><span class="p">.</span><span class="n">t</span> <span class="o">-&gt;</span> <span class="o">[&gt;`</span><span class="nc">ArrayLike</span><span class="o">]</span> <span class="nn">Np</span><span class="p">.</span><span class="nn">Obj</span><span class="p">.</span><span class="n">t</span> <span class="nn">Seq</span><span class="p">.</span><span class="n">t</span>
</code></pre></div>

<p>Predict regression target at each stage for X.</p>
<p>This method allows monitoring (i.e. determine error on testing set)
after each stage.</p>
<h2 id="parameters_75">Parameters<a class="headerlink" href="#parameters_75" title="Permanent link">&para;</a></h2>
<p>X : {array-like, sparse matrix}, shape (n_samples, n_features)
The input samples. Internally, it will be converted to
<code>dtype=np.float32</code> and if a sparse matrix is provided
to a sparse <code>csr_matrix</code>.</p>
<h2 id="returns_61">Returns<a class="headerlink" href="#returns_61" title="Permanent link">&para;</a></h2>
<p>y : generator of array of shape (n_samples,)
The predicted value of the input samples.</p>
<p>Attribute feature_importances_: get value or raise Not_found if None.</p>
<div class="highlight"><pre><span></span><code><span class="k">val</span> <span class="n">feature_importances_</span> <span class="o">:</span> <span class="n">t</span> <span class="o">-&gt;</span> <span class="o">[&gt;`</span><span class="nc">ArrayLike</span><span class="o">]</span> <span class="nn">Np</span><span class="p">.</span><span class="nn">Obj</span><span class="p">.</span><span class="n">t</span>
</code></pre></div>

<p>Attribute feature_importances_: get value as an option.</p>
<div class="highlight"><pre><span></span><code><span class="k">val</span> <span class="n">feature_importances_opt</span> <span class="o">:</span> <span class="n">t</span> <span class="o">-&gt;</span> <span class="o">([&gt;`</span><span class="nc">ArrayLike</span><span class="o">]</span> <span class="nn">Np</span><span class="p">.</span><span class="nn">Obj</span><span class="p">.</span><span class="n">t</span><span class="o">)</span> <span class="n">option</span>
</code></pre></div>

<p>Attribute oob_improvement_: get value or raise Not_found if None.</p>
<div class="highlight"><pre><span></span><code><span class="k">val</span> <span class="n">oob_improvement_</span> <span class="o">:</span> <span class="n">t</span> <span class="o">-&gt;</span> <span class="o">[&gt;`</span><span class="nc">ArrayLike</span><span class="o">]</span> <span class="nn">Np</span><span class="p">.</span><span class="nn">Obj</span><span class="p">.</span><span class="n">t</span>
</code></pre></div>

<p>Attribute oob_improvement_: get value as an option.</p>
<div class="highlight"><pre><span></span><code><span class="k">val</span> <span class="n">oob_improvement_opt</span> <span class="o">:</span> <span class="n">t</span> <span class="o">-&gt;</span> <span class="o">([&gt;`</span><span class="nc">ArrayLike</span><span class="o">]</span> <span class="nn">Np</span><span class="p">.</span><span class="nn">Obj</span><span class="p">.</span><span class="n">t</span><span class="o">)</span> <span class="n">option</span>
</code></pre></div>

<p>Attribute train_score_: get value or raise Not_found if None.</p>
<div class="highlight"><pre><span></span><code><span class="k">val</span> <span class="n">train_score_</span> <span class="o">:</span> <span class="n">t</span> <span class="o">-&gt;</span> <span class="o">[&gt;`</span><span class="nc">ArrayLike</span><span class="o">]</span> <span class="nn">Np</span><span class="p">.</span><span class="nn">Obj</span><span class="p">.</span><span class="n">t</span>
</code></pre></div>

<p>Attribute train_score_: get value as an option.</p>
<div class="highlight"><pre><span></span><code><span class="k">val</span> <span class="n">train_score_opt</span> <span class="o">:</span> <span class="n">t</span> <span class="o">-&gt;</span> <span class="o">([&gt;`</span><span class="nc">ArrayLike</span><span class="o">]</span> <span class="nn">Np</span><span class="p">.</span><span class="nn">Obj</span><span class="p">.</span><span class="n">t</span><span class="o">)</span> <span class="n">option</span>
</code></pre></div>

<p>Attribute loss_: get value or raise Not_found if None.</p>
<div class="highlight"><pre><span></span><code><span class="k">val</span> <span class="n">loss_</span> <span class="o">:</span> <span class="n">t</span> <span class="o">-&gt;</span> <span class="nn">Np</span><span class="p">.</span><span class="nn">NumpyRaw</span><span class="p">.</span><span class="nn">Ndarray</span><span class="p">.</span><span class="n">t</span> <span class="o">-&gt;</span> <span class="nn">Np</span><span class="p">.</span><span class="nn">NumpyRaw</span><span class="p">.</span><span class="nn">Ndarray</span><span class="p">.</span><span class="n">t</span> <span class="o">-&gt;</span> <span class="kt">float</span>
</code></pre></div>

<p>Attribute loss_: get value as an option.</p>
<div class="highlight"><pre><span></span><code><span class="k">val</span> <span class="n">loss_opt</span> <span class="o">:</span> <span class="n">t</span> <span class="o">-&gt;</span> <span class="o">(</span><span class="nn">Np</span><span class="p">.</span><span class="nn">NumpyRaw</span><span class="p">.</span><span class="nn">Ndarray</span><span class="p">.</span><span class="n">t</span> <span class="o">-&gt;</span> <span class="nn">Np</span><span class="p">.</span><span class="nn">NumpyRaw</span><span class="p">.</span><span class="nn">Ndarray</span><span class="p">.</span><span class="n">t</span> <span class="o">-&gt;</span> <span class="kt">float</span><span class="o">)</span> <span class="n">option</span>
</code></pre></div>

<p>Attribute init_: get value or raise Not_found if None.</p>
<div class="highlight"><pre><span></span><code><span class="k">val</span> <span class="n">init_</span> <span class="o">:</span> <span class="n">t</span> <span class="o">-&gt;</span> <span class="o">[`</span><span class="nc">BaseEstimator</span><span class="o">|`</span><span class="nc">Object</span><span class="o">]</span> <span class="nn">Np</span><span class="p">.</span><span class="nn">Obj</span><span class="p">.</span><span class="n">t</span>
</code></pre></div>

<p>Attribute init_: get value as an option.</p>
<div class="highlight"><pre><span></span><code><span class="k">val</span> <span class="n">init_opt</span> <span class="o">:</span> <span class="n">t</span> <span class="o">-&gt;</span> <span class="o">([`</span><span class="nc">BaseEstimator</span><span class="o">|`</span><span class="nc">Object</span><span class="o">]</span> <span class="nn">Np</span><span class="p">.</span><span class="nn">Obj</span><span class="p">.</span><span class="n">t</span><span class="o">)</span> <span class="n">option</span>
</code></pre></div>

<p>Attribute estimators_: get value or raise Not_found if None.</p>
<div class="highlight"><pre><span></span><code><span class="k">val</span> <span class="n">estimators_</span> <span class="o">:</span> <span class="n">t</span> <span class="o">-&gt;</span> <span class="nn">Py</span><span class="p">.</span><span class="nn">Object</span><span class="p">.</span><span class="n">t</span>
</code></pre></div>

<p>Attribute estimators_: get value as an option.</p>
<div class="highlight"><pre><span></span><code><span class="k">val</span> <span class="n">estimators_opt</span> <span class="o">:</span> <span class="n">t</span> <span class="o">-&gt;</span> <span class="o">(</span><span class="nn">Py</span><span class="p">.</span><span class="nn">Object</span><span class="p">.</span><span class="n">t</span><span class="o">)</span> <span class="n">option</span>
</code></pre></div>

<p>Print the object to a human-readable representation.</p>
<div class="highlight"><pre><span></span><code><span class="k">val</span> <span class="n">to_string</span> <span class="o">:</span> <span class="n">t</span> <span class="o">-&gt;</span> <span class="kt">string</span>
</code></pre></div>

<p>Print the object to a human-readable representation.</p>
<div class="highlight"><pre><span></span><code><span class="k">val</span> <span class="n">show</span> <span class="o">:</span> <span class="n">t</span> <span class="o">-&gt;</span> <span class="kt">string</span>
</code></pre></div>

<p>Pretty-print the object to a formatter.</p>
<div class="highlight"><pre><span></span><code><span class="k">val</span> <span class="n">pp</span> <span class="o">:</span> <span class="nn">Format</span><span class="p">.</span><span class="n">formatter</span> <span class="o">-&gt;</span> <span class="n">t</span> <span class="o">-&gt;</span> <span class="kt">unit</span> <span class="o">[@@</span><span class="n">ocaml</span><span class="o">.</span><span class="n">toplevel_printer</span><span class="o">]</span>



<span class="k">module</span> <span class="nc">IsolationForest</span> <span class="o">:</span> <span class="k">sig</span>
<span class="k">type</span> <span class="n">tag</span> <span class="o">=</span> <span class="o">[`</span><span class="nc">IsolationForest</span><span class="o">]</span>
<span class="k">type</span> <span class="n">t</span> <span class="o">=</span> <span class="o">[`</span><span class="nc">BaseBagging</span> <span class="o">|</span> <span class="o">`</span><span class="nc">BaseEnsemble</span> <span class="o">|</span> <span class="o">`</span><span class="nc">BaseEstimator</span> <span class="o">|</span> <span class="o">`</span><span class="nc">IsolationForest</span> <span class="o">|</span> <span class="o">`</span><span class="nc">MetaEstimatorMixin</span> <span class="o">|</span> <span class="o">`</span><span class="nc">Object</span> <span class="o">|</span> <span class="o">`</span><span class="nc">OutlierMixin</span><span class="o">]</span> <span class="nn">Obj</span><span class="p">.</span><span class="n">t</span>
<span class="k">val</span> <span class="n">of_pyobject</span> <span class="o">:</span> <span class="nn">Py</span><span class="p">.</span><span class="nn">Object</span><span class="p">.</span><span class="n">t</span> <span class="o">-&gt;</span> <span class="n">t</span>
<span class="k">val</span> <span class="n">to_pyobject</span> <span class="o">:</span> <span class="o">[&gt;</span> <span class="n">tag</span><span class="o">]</span> <span class="nn">Obj</span><span class="p">.</span><span class="n">t</span> <span class="o">-&gt;</span> <span class="nn">Py</span><span class="p">.</span><span class="nn">Object</span><span class="p">.</span><span class="n">t</span>

<span class="k">val</span> <span class="n">as_meta_estimator</span> <span class="o">:</span> <span class="n">t</span> <span class="o">-&gt;</span> <span class="o">[`</span><span class="nc">MetaEstimatorMixin</span><span class="o">]</span> <span class="nn">Obj</span><span class="p">.</span><span class="n">t</span>
<span class="k">val</span> <span class="n">as_outlier</span> <span class="o">:</span> <span class="n">t</span> <span class="o">-&gt;</span> <span class="o">[`</span><span class="nc">OutlierMixin</span><span class="o">]</span> <span class="nn">Obj</span><span class="p">.</span><span class="n">t</span>
<span class="k">val</span> <span class="n">as_estimator</span> <span class="o">:</span> <span class="n">t</span> <span class="o">-&gt;</span> <span class="o">[`</span><span class="nc">BaseEstimator</span><span class="o">]</span> <span class="nn">Obj</span><span class="p">.</span><span class="n">t</span>
<span class="k">val</span> <span class="n">as_bagging</span> <span class="o">:</span> <span class="n">t</span> <span class="o">-&gt;</span> <span class="o">[`</span><span class="nc">BaseBagging</span><span class="o">]</span> <span class="nn">Obj</span><span class="p">.</span><span class="n">t</span>
<span class="k">val</span> <span class="n">as_ensemble</span> <span class="o">:</span> <span class="n">t</span> <span class="o">-&gt;</span> <span class="o">[`</span><span class="nc">BaseEnsemble</span><span class="o">]</span> <span class="nn">Obj</span><span class="p">.</span><span class="n">t</span>
<span class="k">val</span> <span class="n">create</span> <span class="o">:</span> <span class="o">?</span><span class="n">n_estimators</span><span class="o">:</span><span class="kt">int</span> <span class="o">-&gt;</span> <span class="o">?</span><span class="n">max_samples</span><span class="o">:[`</span><span class="nc">F</span> <span class="k">of</span> <span class="kt">float</span> <span class="o">|</span> <span class="o">`</span><span class="nc">I</span> <span class="k">of</span> <span class="kt">int</span><span class="o">]</span> <span class="o">-&gt;</span> <span class="o">?</span><span class="n">contamination</span><span class="o">:[`</span><span class="nc">F</span> <span class="k">of</span> <span class="kt">float</span> <span class="o">|</span> <span class="o">`</span><span class="nc">Auto</span><span class="o">]</span> <span class="o">-&gt;</span> <span class="o">?</span><span class="n">max_features</span><span class="o">:[`</span><span class="nc">F</span> <span class="k">of</span> <span class="kt">float</span> <span class="o">|</span> <span class="o">`</span><span class="nc">I</span> <span class="k">of</span> <span class="kt">int</span><span class="o">]</span> <span class="o">-&gt;</span> <span class="o">?</span><span class="n">bootstrap</span><span class="o">:</span><span class="kt">bool</span> <span class="o">-&gt;</span> <span class="o">?</span><span class="n">n_jobs</span><span class="o">:</span><span class="kt">int</span> <span class="o">-&gt;</span> <span class="o">?</span><span class="n">behaviour</span><span class="o">:</span><span class="kt">string</span> <span class="o">-&gt;</span> <span class="o">?</span><span class="n">random_state</span><span class="o">:</span><span class="kt">int</span> <span class="o">-&gt;</span> <span class="o">?</span><span class="n">verbose</span><span class="o">:</span><span class="kt">int</span> <span class="o">-&gt;</span> <span class="o">?</span><span class="n">warm_start</span><span class="o">:</span><span class="kt">bool</span> <span class="o">-&gt;</span> <span class="kt">unit</span> <span class="o">-&gt;</span> <span class="n">t</span>
</code></pre></div>

<p>Isolation Forest Algorithm.</p>
<p>Return the anomaly score of each sample using the IsolationForest algorithm</p>
<p>The IsolationForest 'isolates' observations by randomly selecting a feature
and then randomly selecting a split value between the maximum and minimum
values of the selected feature.</p>
<p>Since recursive partitioning can be represented by a tree structure, the
number of splittings required to isolate a sample is equivalent to the path
length from the root node to the terminating node.</p>
<p>This path length, averaged over a forest of such random trees, is a
measure of normality and our decision function.</p>
<p>Random partitioning produces noticeably shorter paths for anomalies.
Hence, when a forest of random trees collectively produce shorter path
lengths for particular samples, they are highly likely to be anomalies.</p>
<p>Read more in the :ref:<code>User Guide &lt;isolation_forest&gt;</code>.</p>
<p>.. versionadded:: 0.18</p>
<h2 id="parameters_76">Parameters<a class="headerlink" href="#parameters_76" title="Permanent link">&para;</a></h2>
<p>n_estimators : int, optional (default=100)
The number of base estimators in the ensemble.</p>
<p>max_samples : int or float, optional (default='auto')
The number of samples to draw from X to train each base estimator.
- If int, then draw <code>max_samples</code> samples.
- If float, then draw <code>max_samples * X.shape[0]</code> samples.
- If 'auto', then <code>max_samples=min(256, n_samples)</code>.</p>
<p>If max_samples is larger than the number of samples provided,
all samples will be used for all trees (no sampling).</p>
<p>contamination : 'auto' or float, optional (default='auto')
The amount of contamination of the data set, i.e. the proportion
of outliers in the data set. Used when fitting to define the threshold
on the scores of the samples.</p>
<ul>
<li>If 'auto', the threshold is determined as in the
original paper.</li>
<li>If float, the contamination should be in the range [0, 0.5].</li>
</ul>
<p>.. versionchanged:: 0.22
The default value of <code>contamination</code> changed from 0.1
to <code>'auto'</code>.</p>
<p>max_features : int or float, optional (default=1.0)
The number of features to draw from X to train each base estimator.</p>
<ul>
<li>If int, then draw <code>max_features</code> features.</li>
<li>If float, then draw <code>max_features * X.shape[1]</code> features.</li>
</ul>
<p>bootstrap : bool, optional (default=False)
If True, individual trees are fit on random subsets of the training
data sampled with replacement. If False, sampling without replacement
is performed.</p>
<p>n_jobs : int or None, optional (default=None)
The number of jobs to run in parallel for both :meth:<code>fit</code> and
:meth:<code>predict</code>. <code>None</code> means 1 unless in a
:obj:<code>joblib.parallel_backend</code> context. <code>-1</code> means using all
processors. See :term:<code>Glossary &lt;n_jobs&gt;</code> for more details.</p>
<p>behaviour : str, default='deprecated'
This parameter has not effect, is deprecated, and will be removed.</p>
<p>.. versionadded:: 0.20
<code>behaviour</code> is added in 0.20 for back-compatibility purpose.</p>
<p>.. deprecated:: 0.20
<code>behaviour='old'</code> is deprecated in 0.20 and will not be possible
in 0.22.</p>
<p>.. deprecated:: 0.22
<code>behaviour</code> parameter is deprecated in 0.22 and removed in
0.24.</p>
<p>random_state : int, RandomState instance or None, optional (default=None)
If int, random_state is the seed used by the random number generator;
If RandomState instance, random_state is the random number generator;
If None, the random number generator is the RandomState instance used
by <code>np.random</code>.</p>
<p>verbose : int, optional (default=0)
Controls the verbosity of the tree building process.</p>
<p>warm_start : bool, optional (default=False)
When set to <code>True</code>, reuse the solution of the previous call to fit
and add more estimators to the ensemble, otherwise, just fit a whole
new forest. See :term:<code>the Glossary &lt;warm_start&gt;</code>.</p>
<p>.. versionadded:: 0.21</p>
<h2 id="attributes_8">Attributes<a class="headerlink" href="#attributes_8" title="Permanent link">&para;</a></h2>
<p>estimators_ : list of DecisionTreeClassifier
The collection of fitted sub-estimators.</p>
<p>estimators_samples_ : list of arrays
The subset of drawn samples (i.e., the in-bag samples) for each base
estimator.</p>
<p>max_samples_ : integer
The actual number of samples</p>
<p>offset_ : float
Offset used to define the decision function from the raw scores. We
have the relation: <code>decision_function = score_samples - offset_</code>.
<code>offset_</code> is defined as follows. When the contamination parameter is
set to 'auto', the offset is equal to -0.5 as the scores of inliers are
close to 0 and the scores of outliers are close to -1. When a
contamination parameter different than 'auto' is provided, the offset
is defined in such a way we obtain the expected number of outliers
(samples with decision function &lt; 0) in training.</p>
<h2 id="notes_8">Notes<a class="headerlink" href="#notes_8" title="Permanent link">&para;</a></h2>
<p>The implementation is based on an ensemble of ExtraTreeRegressor. The
maximum depth of each tree is set to <code>ceil(log_2(n))</code> where
:math:<code>n</code> is the number of samples used to build the tree
(see (Liu et al., 2008) for more details).</p>
<h2 id="references_8">References<a class="headerlink" href="#references_8" title="Permanent link">&para;</a></h2>
<p>.. [1] Liu, Fei Tony, Ting, Kai Ming and Zhou, Zhi-Hua. 'Isolation forest.'
Data Mining, 2008. ICDM'08. Eighth IEEE International Conference on.
.. [2] Liu, Fei Tony, Ting, Kai Ming and Zhou, Zhi-Hua. 'Isolation-based
anomaly detection.' ACM Transactions on Knowledge Discovery from
Data (TKDD) 6.1 (2012): 3.</p>
<h2 id="see-also_6">See Also<a class="headerlink" href="#see-also_6" title="Permanent link">&para;</a></h2>
<p>sklearn.covariance.EllipticEnvelope : An object for detecting outliers in a
Gaussian distributed dataset.
sklearn.svm.OneClassSVM : Unsupervised Outlier Detection.
Estimate the support of a high-dimensional distribution.
The implementation is based on libsvm.
sklearn.neighbors.LocalOutlierFactor : Unsupervised Outlier Detection
using Local Outlier Factor (LOF).</p>
<h2 id="examples_5">Examples<a class="headerlink" href="#examples_5" title="Permanent link">&para;</a></h2>
<blockquote>
<blockquote>
<blockquote>
<p>from sklearn.ensemble import IsolationForest
X = [[-1.1], [0.3], [0.5], [100]]
clf = IsolationForest(random_state=0).fit(X)
clf.predict([[0.1], [0], [90]])
array([ 1,  1, -1])</p>
</blockquote>
</blockquote>
</blockquote>
<div class="highlight"><pre><span></span><code><span class="k">val</span> <span class="n">get_item</span> <span class="o">:</span> <span class="n">index</span><span class="o">:</span><span class="nn">Py</span><span class="p">.</span><span class="nn">Object</span><span class="p">.</span><span class="n">t</span> <span class="o">-&gt;</span> <span class="o">[&gt;</span> <span class="n">tag</span><span class="o">]</span> <span class="nn">Obj</span><span class="p">.</span><span class="n">t</span> <span class="o">-&gt;</span> <span class="nn">Py</span><span class="p">.</span><span class="nn">Object</span><span class="p">.</span><span class="n">t</span>
</code></pre></div>

<p>Return the index'th estimator in the ensemble.</p>
<div class="highlight"><pre><span></span><code><span class="k">val</span> <span class="n">iter</span> <span class="o">:</span> <span class="o">[&gt;</span> <span class="n">tag</span><span class="o">]</span> <span class="nn">Obj</span><span class="p">.</span><span class="n">t</span> <span class="o">-&gt;</span> <span class="nn">Dict</span><span class="p">.</span><span class="n">t</span> <span class="nn">Seq</span><span class="p">.</span><span class="n">t</span>
</code></pre></div>

<p>Return iterator over estimators in the ensemble.</p>
<div class="highlight"><pre><span></span><code><span class="k">val</span> <span class="n">decision_function</span> <span class="o">:</span> <span class="n">x</span><span class="o">:[&gt;`</span><span class="nc">ArrayLike</span><span class="o">]</span> <span class="nn">Np</span><span class="p">.</span><span class="nn">Obj</span><span class="p">.</span><span class="n">t</span> <span class="o">-&gt;</span> <span class="o">[&gt;</span> <span class="n">tag</span><span class="o">]</span> <span class="nn">Obj</span><span class="p">.</span><span class="n">t</span> <span class="o">-&gt;</span> <span class="o">[&gt;`</span><span class="nc">ArrayLike</span><span class="o">]</span> <span class="nn">Np</span><span class="p">.</span><span class="nn">Obj</span><span class="p">.</span><span class="n">t</span>
</code></pre></div>

<p>Average anomaly score of X of the base classifiers.</p>
<p>The anomaly score of an input sample is computed as
the mean anomaly score of the trees in the forest.</p>
<p>The measure of normality of an observation given a tree is the depth
of the leaf containing this observation, which is equivalent to
the number of splittings required to isolate this point. In case of
several observations n_left in the leaf, the average path length of
a n_left samples isolation tree is added.</p>
<h2 id="parameters_77">Parameters<a class="headerlink" href="#parameters_77" title="Permanent link">&para;</a></h2>
<p>X : array-like or sparse matrix, shape (n_samples, n_features)
The input samples. Internally, it will be converted to
<code>dtype=np.float32</code> and if a sparse matrix is provided
to a sparse <code>csr_matrix</code>.</p>
<h2 id="returns_62">Returns<a class="headerlink" href="#returns_62" title="Permanent link">&para;</a></h2>
<p>scores : array, shape (n_samples,)
The anomaly score of the input samples.
The lower, the more abnormal. Negative scores represent outliers,
positive scores represent inliers.</p>
<div class="highlight"><pre><span></span><code><span class="k">val</span> <span class="n">fit</span> <span class="o">:</span> <span class="o">?</span><span class="n">y</span><span class="o">:</span><span class="nn">Py</span><span class="p">.</span><span class="nn">Object</span><span class="p">.</span><span class="n">t</span> <span class="o">-&gt;</span> <span class="o">?</span><span class="n">sample_weight</span><span class="o">:[&gt;`</span><span class="nc">ArrayLike</span><span class="o">]</span> <span class="nn">Np</span><span class="p">.</span><span class="nn">Obj</span><span class="p">.</span><span class="n">t</span> <span class="o">-&gt;</span> <span class="n">x</span><span class="o">:[&gt;`</span><span class="nc">ArrayLike</span><span class="o">]</span> <span class="nn">Np</span><span class="p">.</span><span class="nn">Obj</span><span class="p">.</span><span class="n">t</span> <span class="o">-&gt;</span> <span class="o">[&gt;</span> <span class="n">tag</span><span class="o">]</span> <span class="nn">Obj</span><span class="p">.</span><span class="n">t</span> <span class="o">-&gt;</span> <span class="n">t</span>
</code></pre></div>

<p>Fit estimator.</p>
<h2 id="parameters_78">Parameters<a class="headerlink" href="#parameters_78" title="Permanent link">&para;</a></h2>
<p>X : array-like or sparse matrix, shape (n_samples, n_features)
The input samples. Use <code>dtype=np.float32</code> for maximum
efficiency. Sparse matrices are also supported, use sparse
<code>csc_matrix</code> for maximum efficiency.</p>
<p>y : Ignored
Not used, present for API consistency by convention.</p>
<p>sample_weight : array-like of shape (n_samples,), default=None
Sample weights. If None, then samples are equally weighted.</p>
<h2 id="returns_63">Returns<a class="headerlink" href="#returns_63" title="Permanent link">&para;</a></h2>
<p>self : object
Fitted estimator.</p>
<div class="highlight"><pre><span></span><code><span class="k">val</span> <span class="n">fit_predict</span> <span class="o">:</span> <span class="o">?</span><span class="n">y</span><span class="o">:</span><span class="nn">Py</span><span class="p">.</span><span class="nn">Object</span><span class="p">.</span><span class="n">t</span> <span class="o">-&gt;</span> <span class="n">x</span><span class="o">:[&gt;`</span><span class="nc">ArrayLike</span><span class="o">]</span> <span class="nn">Np</span><span class="p">.</span><span class="nn">Obj</span><span class="p">.</span><span class="n">t</span> <span class="o">-&gt;</span> <span class="o">[&gt;</span> <span class="n">tag</span><span class="o">]</span> <span class="nn">Obj</span><span class="p">.</span><span class="n">t</span> <span class="o">-&gt;</span> <span class="o">[&gt;`</span><span class="nc">ArrayLike</span><span class="o">]</span> <span class="nn">Np</span><span class="p">.</span><span class="nn">Obj</span><span class="p">.</span><span class="n">t</span>
</code></pre></div>

<p>Perform fit on X and returns labels for X.</p>
<p>Returns -1 for outliers and 1 for inliers.</p>
<h2 id="parameters_79">Parameters<a class="headerlink" href="#parameters_79" title="Permanent link">&para;</a></h2>
<p>X : ndarray, shape (n_samples, n_features)
Input data.</p>
<p>y : Ignored
Not used, present for API consistency by convention.</p>
<h2 id="returns_64">Returns<a class="headerlink" href="#returns_64" title="Permanent link">&para;</a></h2>
<p>y : ndarray, shape (n_samples,)
1 for inliers, -1 for outliers.</p>
<div class="highlight"><pre><span></span><code><span class="k">val</span> <span class="n">get_params</span> <span class="o">:</span> <span class="o">?</span><span class="n">deep</span><span class="o">:</span><span class="kt">bool</span> <span class="o">-&gt;</span> <span class="o">[&gt;</span> <span class="n">tag</span><span class="o">]</span> <span class="nn">Obj</span><span class="p">.</span><span class="n">t</span> <span class="o">-&gt;</span> <span class="nn">Dict</span><span class="p">.</span><span class="n">t</span>
</code></pre></div>

<p>Get parameters for this estimator.</p>
<h2 id="parameters_80">Parameters<a class="headerlink" href="#parameters_80" title="Permanent link">&para;</a></h2>
<p>deep : bool, default=True
If True, will return the parameters for this estimator and
contained subobjects that are estimators.</p>
<h2 id="returns_65">Returns<a class="headerlink" href="#returns_65" title="Permanent link">&para;</a></h2>
<p>params : mapping of string to any
Parameter names mapped to their values.</p>
<div class="highlight"><pre><span></span><code><span class="k">val</span> <span class="n">predict</span> <span class="o">:</span> <span class="n">x</span><span class="o">:[&gt;`</span><span class="nc">ArrayLike</span><span class="o">]</span> <span class="nn">Np</span><span class="p">.</span><span class="nn">Obj</span><span class="p">.</span><span class="n">t</span> <span class="o">-&gt;</span> <span class="o">[&gt;</span> <span class="n">tag</span><span class="o">]</span> <span class="nn">Obj</span><span class="p">.</span><span class="n">t</span> <span class="o">-&gt;</span> <span class="o">[&gt;`</span><span class="nc">ArrayLike</span><span class="o">]</span> <span class="nn">Np</span><span class="p">.</span><span class="nn">Obj</span><span class="p">.</span><span class="n">t</span>
</code></pre></div>

<p>Predict if a particular sample is an outlier or not.</p>
<h2 id="parameters_81">Parameters<a class="headerlink" href="#parameters_81" title="Permanent link">&para;</a></h2>
<p>X : array-like or sparse matrix, shape (n_samples, n_features)
The input samples. Internally, it will be converted to
<code>dtype=np.float32</code> and if a sparse matrix is provided
to a sparse <code>csr_matrix</code>.</p>
<h2 id="returns_66">Returns<a class="headerlink" href="#returns_66" title="Permanent link">&para;</a></h2>
<p>is_inlier : array, shape (n_samples,)
For each observation, tells whether or not (+1 or -1) it should
be considered as an inlier according to the fitted model.</p>
<div class="highlight"><pre><span></span><code><span class="k">val</span> <span class="n">score_samples</span> <span class="o">:</span> <span class="n">x</span><span class="o">:[&gt;`</span><span class="nc">ArrayLike</span><span class="o">]</span> <span class="nn">Np</span><span class="p">.</span><span class="nn">Obj</span><span class="p">.</span><span class="n">t</span> <span class="o">-&gt;</span> <span class="o">[&gt;</span> <span class="n">tag</span><span class="o">]</span> <span class="nn">Obj</span><span class="p">.</span><span class="n">t</span> <span class="o">-&gt;</span> <span class="o">[&gt;`</span><span class="nc">ArrayLike</span><span class="o">]</span> <span class="nn">Np</span><span class="p">.</span><span class="nn">Obj</span><span class="p">.</span><span class="n">t</span>
</code></pre></div>

<p>Opposite of the anomaly score defined in the original paper.</p>
<p>The anomaly score of an input sample is computed as
the mean anomaly score of the trees in the forest.</p>
<p>The measure of normality of an observation given a tree is the depth
of the leaf containing this observation, which is equivalent to
the number of splittings required to isolate this point. In case of
several observations n_left in the leaf, the average path length of
a n_left samples isolation tree is added.</p>
<h2 id="parameters_82">Parameters<a class="headerlink" href="#parameters_82" title="Permanent link">&para;</a></h2>
<p>X : array-like or sparse matrix, shape (n_samples, n_features)
The input samples.</p>
<h2 id="returns_67">Returns<a class="headerlink" href="#returns_67" title="Permanent link">&para;</a></h2>
<p>scores : array, shape (n_samples,)
The anomaly score of the input samples.
The lower, the more abnormal.</p>
<div class="highlight"><pre><span></span><code><span class="k">val</span> <span class="n">set_params</span> <span class="o">:</span> <span class="o">?</span><span class="n">params</span><span class="o">:(</span><span class="kt">string</span> <span class="o">*</span> <span class="nn">Py</span><span class="p">.</span><span class="nn">Object</span><span class="p">.</span><span class="n">t</span><span class="o">)</span> <span class="kt">list</span> <span class="o">-&gt;</span> <span class="o">[&gt;</span> <span class="n">tag</span><span class="o">]</span> <span class="nn">Obj</span><span class="p">.</span><span class="n">t</span> <span class="o">-&gt;</span> <span class="n">t</span>
</code></pre></div>

<p>Set the parameters of this estimator.</p>
<p>The method works on simple estimators as well as on nested objects
(such as pipelines). The latter have parameters of the form
<code>&lt;component&gt;__&lt;parameter&gt;</code> so that it's possible to update each
component of a nested object.</p>
<h2 id="parameters_83">Parameters<a class="headerlink" href="#parameters_83" title="Permanent link">&para;</a></h2>
<p>**params : dict
Estimator parameters.</p>
<h2 id="returns_68">Returns<a class="headerlink" href="#returns_68" title="Permanent link">&para;</a></h2>
<p>self : object
Estimator instance.</p>
<p>Attribute estimators_: get value or raise Not_found if None.</p>
<div class="highlight"><pre><span></span><code><span class="k">val</span> <span class="n">estimators_</span> <span class="o">:</span> <span class="n">t</span> <span class="o">-&gt;</span> <span class="nn">Py</span><span class="p">.</span><span class="nn">Object</span><span class="p">.</span><span class="n">t</span>
</code></pre></div>

<p>Attribute estimators_: get value as an option.</p>
<div class="highlight"><pre><span></span><code><span class="k">val</span> <span class="n">estimators_opt</span> <span class="o">:</span> <span class="n">t</span> <span class="o">-&gt;</span> <span class="o">(</span><span class="nn">Py</span><span class="p">.</span><span class="nn">Object</span><span class="p">.</span><span class="n">t</span><span class="o">)</span> <span class="n">option</span>
</code></pre></div>

<p>Attribute estimators_samples_: get value or raise Not_found if None.</p>
<div class="highlight"><pre><span></span><code><span class="k">val</span> <span class="n">estimators_samples_</span> <span class="o">:</span> <span class="n">t</span> <span class="o">-&gt;</span> <span class="nn">Np</span><span class="p">.</span><span class="nn">Numpy</span><span class="p">.</span><span class="nn">Ndarray</span><span class="p">.</span><span class="nn">List</span><span class="p">.</span><span class="n">t</span>
</code></pre></div>

<p>Attribute estimators_samples_: get value as an option.</p>
<div class="highlight"><pre><span></span><code><span class="k">val</span> <span class="n">estimators_samples_opt</span> <span class="o">:</span> <span class="n">t</span> <span class="o">-&gt;</span> <span class="o">(</span><span class="nn">Np</span><span class="p">.</span><span class="nn">Numpy</span><span class="p">.</span><span class="nn">Ndarray</span><span class="p">.</span><span class="nn">List</span><span class="p">.</span><span class="n">t</span><span class="o">)</span> <span class="n">option</span>
</code></pre></div>

<p>Attribute max_samples_: get value or raise Not_found if None.</p>
<div class="highlight"><pre><span></span><code><span class="k">val</span> <span class="n">max_samples_</span> <span class="o">:</span> <span class="n">t</span> <span class="o">-&gt;</span> <span class="kt">int</span>
</code></pre></div>

<p>Attribute max_samples_: get value as an option.</p>
<div class="highlight"><pre><span></span><code><span class="k">val</span> <span class="n">max_samples_opt</span> <span class="o">:</span> <span class="n">t</span> <span class="o">-&gt;</span> <span class="o">(</span><span class="kt">int</span><span class="o">)</span> <span class="n">option</span>
</code></pre></div>

<p>Attribute offset_: get value or raise Not_found if None.</p>
<div class="highlight"><pre><span></span><code><span class="k">val</span> <span class="n">offset_</span> <span class="o">:</span> <span class="n">t</span> <span class="o">-&gt;</span> <span class="kt">float</span>
</code></pre></div>

<p>Attribute offset_: get value as an option.</p>
<div class="highlight"><pre><span></span><code><span class="k">val</span> <span class="n">offset_opt</span> <span class="o">:</span> <span class="n">t</span> <span class="o">-&gt;</span> <span class="o">(</span><span class="kt">float</span><span class="o">)</span> <span class="n">option</span>
</code></pre></div>

<p>Print the object to a human-readable representation.</p>
<div class="highlight"><pre><span></span><code><span class="k">val</span> <span class="n">to_string</span> <span class="o">:</span> <span class="n">t</span> <span class="o">-&gt;</span> <span class="kt">string</span>
</code></pre></div>

<p>Print the object to a human-readable representation.</p>
<div class="highlight"><pre><span></span><code><span class="k">val</span> <span class="n">show</span> <span class="o">:</span> <span class="n">t</span> <span class="o">-&gt;</span> <span class="kt">string</span>
</code></pre></div>

<p>Pretty-print the object to a formatter.</p>
<div class="highlight"><pre><span></span><code><span class="k">val</span> <span class="n">pp</span> <span class="o">:</span> <span class="nn">Format</span><span class="p">.</span><span class="n">formatter</span> <span class="o">-&gt;</span> <span class="n">t</span> <span class="o">-&gt;</span> <span class="kt">unit</span> <span class="o">[@@</span><span class="n">ocaml</span><span class="o">.</span><span class="n">toplevel_printer</span><span class="o">]</span>



<span class="k">module</span> <span class="nc">RandomForestClassifier</span> <span class="o">:</span> <span class="k">sig</span>
<span class="k">type</span> <span class="n">tag</span> <span class="o">=</span> <span class="o">[`</span><span class="nc">RandomForestClassifier</span><span class="o">]</span>
<span class="k">type</span> <span class="n">t</span> <span class="o">=</span> <span class="o">[`</span><span class="nc">BaseEnsemble</span> <span class="o">|</span> <span class="o">`</span><span class="nc">BaseEstimator</span> <span class="o">|</span> <span class="o">`</span><span class="nc">BaseForest</span> <span class="o">|</span> <span class="o">`</span><span class="nc">ClassifierMixin</span> <span class="o">|</span> <span class="o">`</span><span class="nc">MetaEstimatorMixin</span> <span class="o">|</span> <span class="o">`</span><span class="nc">MultiOutputMixin</span> <span class="o">|</span> <span class="o">`</span><span class="nc">Object</span> <span class="o">|</span> <span class="o">`</span><span class="nc">RandomForestClassifier</span><span class="o">]</span> <span class="nn">Obj</span><span class="p">.</span><span class="n">t</span>
<span class="k">val</span> <span class="n">of_pyobject</span> <span class="o">:</span> <span class="nn">Py</span><span class="p">.</span><span class="nn">Object</span><span class="p">.</span><span class="n">t</span> <span class="o">-&gt;</span> <span class="n">t</span>
<span class="k">val</span> <span class="n">to_pyobject</span> <span class="o">:</span> <span class="o">[&gt;</span> <span class="n">tag</span><span class="o">]</span> <span class="nn">Obj</span><span class="p">.</span><span class="n">t</span> <span class="o">-&gt;</span> <span class="nn">Py</span><span class="p">.</span><span class="nn">Object</span><span class="p">.</span><span class="n">t</span>

<span class="k">val</span> <span class="n">as_classifier</span> <span class="o">:</span> <span class="n">t</span> <span class="o">-&gt;</span> <span class="o">[`</span><span class="nc">ClassifierMixin</span><span class="o">]</span> <span class="nn">Obj</span><span class="p">.</span><span class="n">t</span>
<span class="k">val</span> <span class="n">as_multi_output</span> <span class="o">:</span> <span class="n">t</span> <span class="o">-&gt;</span> <span class="o">[`</span><span class="nc">MultiOutputMixin</span><span class="o">]</span> <span class="nn">Obj</span><span class="p">.</span><span class="n">t</span>
<span class="k">val</span> <span class="n">as_meta_estimator</span> <span class="o">:</span> <span class="n">t</span> <span class="o">-&gt;</span> <span class="o">[`</span><span class="nc">MetaEstimatorMixin</span><span class="o">]</span> <span class="nn">Obj</span><span class="p">.</span><span class="n">t</span>
<span class="k">val</span> <span class="n">as_estimator</span> <span class="o">:</span> <span class="n">t</span> <span class="o">-&gt;</span> <span class="o">[`</span><span class="nc">BaseEstimator</span><span class="o">]</span> <span class="nn">Obj</span><span class="p">.</span><span class="n">t</span>
<span class="k">val</span> <span class="n">as_ensemble</span> <span class="o">:</span> <span class="n">t</span> <span class="o">-&gt;</span> <span class="o">[`</span><span class="nc">BaseEnsemble</span><span class="o">]</span> <span class="nn">Obj</span><span class="p">.</span><span class="n">t</span>
<span class="k">val</span> <span class="n">as_forest</span> <span class="o">:</span> <span class="n">t</span> <span class="o">-&gt;</span> <span class="o">[`</span><span class="nc">BaseForest</span><span class="o">]</span> <span class="nn">Obj</span><span class="p">.</span><span class="n">t</span>
<span class="k">val</span> <span class="n">create</span> <span class="o">:</span> <span class="o">?</span><span class="n">n_estimators</span><span class="o">:</span><span class="kt">int</span> <span class="o">-&gt;</span> <span class="o">?</span><span class="n">criterion</span><span class="o">:</span><span class="kt">string</span> <span class="o">-&gt;</span> <span class="o">?</span><span class="n">max_depth</span><span class="o">:</span><span class="kt">int</span> <span class="o">-&gt;</span> <span class="o">?</span><span class="n">min_samples_split</span><span class="o">:[`</span><span class="nc">F</span> <span class="k">of</span> <span class="kt">float</span> <span class="o">|</span> <span class="o">`</span><span class="nc">I</span> <span class="k">of</span> <span class="kt">int</span><span class="o">]</span> <span class="o">-&gt;</span> <span class="o">?</span><span class="n">min_samples_leaf</span><span class="o">:[`</span><span class="nc">F</span> <span class="k">of</span> <span class="kt">float</span> <span class="o">|</span> <span class="o">`</span><span class="nc">I</span> <span class="k">of</span> <span class="kt">int</span><span class="o">]</span> <span class="o">-&gt;</span> <span class="o">?</span><span class="n">min_weight_fraction_leaf</span><span class="o">:</span><span class="kt">float</span> <span class="o">-&gt;</span> <span class="o">?</span><span class="n">max_features</span><span class="o">:[`</span><span class="nc">F</span> <span class="k">of</span> <span class="kt">float</span> <span class="o">|</span> <span class="o">`</span><span class="nc">S</span> <span class="k">of</span> <span class="kt">string</span> <span class="o">|</span> <span class="o">`</span><span class="nc">I</span> <span class="k">of</span> <span class="kt">int</span> <span class="o">|</span> <span class="o">`</span><span class="nc">None</span><span class="o">]</span> <span class="o">-&gt;</span> <span class="o">?</span><span class="n">max_leaf_nodes</span><span class="o">:</span><span class="kt">int</span> <span class="o">-&gt;</span> <span class="o">?</span><span class="n">min_impurity_decrease</span><span class="o">:</span><span class="kt">float</span> <span class="o">-&gt;</span> <span class="o">?</span><span class="n">min_impurity_split</span><span class="o">:</span><span class="kt">float</span> <span class="o">-&gt;</span> <span class="o">?</span><span class="n">bootstrap</span><span class="o">:</span><span class="kt">bool</span> <span class="o">-&gt;</span> <span class="o">?</span><span class="n">oob_score</span><span class="o">:</span><span class="kt">bool</span> <span class="o">-&gt;</span> <span class="o">?</span><span class="n">n_jobs</span><span class="o">:</span><span class="kt">int</span> <span class="o">-&gt;</span> <span class="o">?</span><span class="n">random_state</span><span class="o">:</span><span class="kt">int</span> <span class="o">-&gt;</span> <span class="o">?</span><span class="n">verbose</span><span class="o">:</span><span class="kt">int</span> <span class="o">-&gt;</span> <span class="o">?</span><span class="n">warm_start</span><span class="o">:</span><span class="kt">bool</span> <span class="o">-&gt;</span> <span class="o">?</span><span class="n">class_weight</span><span class="o">:[`</span><span class="nc">List_of_dicts</span> <span class="k">of</span> <span class="nn">Py</span><span class="p">.</span><span class="nn">Object</span><span class="p">.</span><span class="n">t</span> <span class="o">|</span> <span class="o">`</span><span class="nc">Balanced_subsample</span> <span class="o">|</span> <span class="o">`</span><span class="nc">DictIntToFloat</span> <span class="k">of</span> <span class="o">(</span><span class="kt">int</span> <span class="o">*</span> <span class="kt">float</span><span class="o">)</span> <span class="kt">list</span> <span class="o">|</span> <span class="o">`</span><span class="nc">Balanced</span><span class="o">]</span> <span class="o">-&gt;</span> <span class="o">?</span><span class="n">ccp_alpha</span><span class="o">:</span><span class="kt">float</span> <span class="o">-&gt;</span> <span class="o">?</span><span class="n">max_samples</span><span class="o">:[`</span><span class="nc">F</span> <span class="k">of</span> <span class="kt">float</span> <span class="o">|</span> <span class="o">`</span><span class="nc">I</span> <span class="k">of</span> <span class="kt">int</span><span class="o">]</span> <span class="o">-&gt;</span> <span class="kt">unit</span> <span class="o">-&gt;</span> <span class="n">t</span>
</code></pre></div>

<p>A random forest classifier.</p>
<p>A random forest is a meta estimator that fits a number of decision tree
classifiers on various sub-samples of the dataset and uses averaging to
improve the predictive accuracy and control over-fitting.
The sub-sample size is always the same as the original
input sample size but the samples are drawn with replacement if
<code>bootstrap=True</code> (default).</p>
<p>Read more in the :ref:<code>User Guide &lt;forest&gt;</code>.</p>
<h2 id="parameters_84">Parameters<a class="headerlink" href="#parameters_84" title="Permanent link">&para;</a></h2>
<p>n_estimators : integer, optional (default=100)
The number of trees in the forest.</p>
<p>.. versionchanged:: 0.22
The default value of <code>n_estimators</code> changed from 10 to 100
in 0.22.</p>
<p>criterion : string, optional (default='gini')
The function to measure the quality of a split. Supported criteria are
'gini' for the Gini impurity and 'entropy' for the information gain.
Note: this parameter is tree-specific.</p>
<p>max_depth : integer or None, optional (default=None)
The maximum depth of the tree. If None, then nodes are expanded until
all leaves are pure or until all leaves contain less than
min_samples_split samples.</p>
<p>min_samples_split : int, float, optional (default=2)
The minimum number of samples required to split an internal node:</p>
<ul>
<li>If int, then consider <code>min_samples_split</code> as the minimum number.</li>
<li>If float, then <code>min_samples_split</code> is a fraction and
<code>ceil(min_samples_split * n_samples)</code> are the minimum
number of samples for each split.</li>
</ul>
<p>.. versionchanged:: 0.18
Added float values for fractions.</p>
<p>min_samples_leaf : int, float, optional (default=1)
The minimum number of samples required to be at a leaf node.
A split point at any depth will only be considered if it leaves at
least <code>min_samples_leaf</code> training samples in each of the left and
right branches.  This may have the effect of smoothing the model,
especially in regression.</p>
<ul>
<li>If int, then consider <code>min_samples_leaf</code> as the minimum number.</li>
<li>If float, then <code>min_samples_leaf</code> is a fraction and
<code>ceil(min_samples_leaf * n_samples)</code> are the minimum
number of samples for each node.</li>
</ul>
<p>.. versionchanged:: 0.18
Added float values for fractions.</p>
<p>min_weight_fraction_leaf : float, optional (default=0.)
The minimum weighted fraction of the sum total of weights (of all
the input samples) required to be at a leaf node. Samples have
equal weight when sample_weight is not provided.</p>
<p>max_features : int, float, string or None, optional (default='auto')
The number of features to consider when looking for the best split:</p>
<ul>
<li>If int, then consider <code>max_features</code> features at each split.</li>
<li>If float, then <code>max_features</code> is a fraction and
<code>int(max_features * n_features)</code> features are considered at each
split.</li>
<li>If 'auto', then <code>max_features=sqrt(n_features)</code>.</li>
<li>If 'sqrt', then <code>max_features=sqrt(n_features)</code> (same as 'auto').</li>
<li>If 'log2', then <code>max_features=log2(n_features)</code>.</li>
<li>If None, then <code>max_features=n_features</code>.</li>
</ul>
<p>Note: the search for a split does not stop until at least one
valid partition of the node samples is found, even if it requires to
effectively inspect more than <code>max_features</code> features.</p>
<p>max_leaf_nodes : int or None, optional (default=None)
Grow trees with <code>max_leaf_nodes</code> in best-first fashion.
Best nodes are defined as relative reduction in impurity.
If None then unlimited number of leaf nodes.</p>
<p>min_impurity_decrease : float, optional (default=0.)
A node will be split if this split induces a decrease of the impurity
greater than or equal to this value.</p>
<p>The weighted impurity decrease equation is the following::</p>
<p>N_t / N * (impurity - N_t_R / N_t * right_impurity
- N_t_L / N_t * left_impurity)</p>
<p>where <code>N</code> is the total number of samples, <code>N_t</code> is the number of
samples at the current node, <code>N_t_L</code> is the number of samples in the
left child, and <code>N_t_R</code> is the number of samples in the right child.</p>
<p><code>N</code>, <code>N_t</code>, <code>N_t_R</code> and <code>N_t_L</code> all refer to the weighted sum,
if <code>sample_weight</code> is passed.</p>
<p>.. versionadded:: 0.19</p>
<p>min_impurity_split : float, (default=1e-7)
Threshold for early stopping in tree growth. A node will split
if its impurity is above the threshold, otherwise it is a leaf.</p>
<p>.. deprecated:: 0.19
<code>min_impurity_split</code> has been deprecated in favor of
<code>min_impurity_decrease</code> in 0.19. The default value of
<code>min_impurity_split</code> will change from 1e-7 to 0 in 0.23 and it
will be removed in 0.25. Use <code>min_impurity_decrease</code> instead.</p>
<p>bootstrap : boolean, optional (default=True)
Whether bootstrap samples are used when building trees. If False, the
whole datset is used to build each tree.</p>
<p>oob_score : bool (default=False)
Whether to use out-of-bag samples to estimate
the generalization accuracy.</p>
<p>n_jobs : int or None, optional (default=None)
The number of jobs to run in parallel. :meth:<code>fit</code>, :meth:<code>predict</code>,
:meth:<code>decision_path</code> and :meth:<code>apply</code> are all parallelized over the
trees. <code>None</code> means 1 unless in a :obj:<code>joblib.parallel_backend</code>
context. <code>-1</code> means using all processors. See :term:<code>Glossary
&lt;n_jobs&gt;</code> for more details.</p>
<p>random_state : int, RandomState instance or None, optional (default=None)
Controls both the randomness of the bootstrapping of the samples used
when building trees (if <code>bootstrap=True</code>) and the sampling of the
features to consider when looking for the best split at each node
(if <code>max_features &lt; n_features</code>).
See :term:<code>Glossary &lt;random_state&gt;</code> for details.</p>
<p>verbose : int, optional (default=0)
Controls the verbosity when fitting and predicting.</p>
<p>warm_start : bool, optional (default=False)
When set to <code>True</code>, reuse the solution of the previous call to fit
and add more estimators to the ensemble, otherwise, just fit a whole
new forest. See :term:<code>the Glossary &lt;warm_start&gt;</code>.</p>
<p>class_weight : dict, list of dicts, 'balanced', 'balanced_subsample' or     None, optional (default=None)
Weights associated with classes in the form <code>{class_label: weight}</code>.
If not given, all classes are supposed to have weight one. For
multi-output problems, a list of dicts can be provided in the same
order as the columns of y.</p>
<p>Note that for multioutput (including multilabel) weights should be
defined for each class of every column in its own dict. For example,
for four-class multilabel classification weights should be
[{0: 1, 1: 1}, {0: 1, 1: 5}, {0: 1, 1: 1}, {0: 1, 1: 1}] instead of
[{1:1}, {2:5}, {3:1}, {4:1}].</p>
<p>The 'balanced' mode uses the values of y to automatically adjust
weights inversely proportional to class frequencies in the input data
as <code>n_samples / (n_classes * np.bincount(y))</code></p>
<p>The 'balanced_subsample' mode is the same as 'balanced' except that
weights are computed based on the bootstrap sample for every tree
grown.</p>
<p>For multi-output, the weights of each column of y will be multiplied.</p>
<p>Note that these weights will be multiplied with sample_weight (passed
through the fit method) if sample_weight is specified.</p>
<p>ccp_alpha : non-negative float, optional (default=0.0)
Complexity parameter used for Minimal Cost-Complexity Pruning. The
subtree with the largest cost complexity that is smaller than
<code>ccp_alpha</code> will be chosen. By default, no pruning is performed. See
:ref:<code>minimal_cost_complexity_pruning</code> for details.</p>
<p>.. versionadded:: 0.22</p>
<p>max_samples : int or float, default=None
If bootstrap is True, the number of samples to draw from X
to train each base estimator.</p>
<ul>
<li>If None (default), then draw <code>X.shape[0]</code> samples.</li>
<li>If int, then draw <code>max_samples</code> samples.</li>
<li>If float, then draw <code>max_samples * X.shape[0]</code> samples. Thus,
<code>max_samples</code> should be in the interval <code>(0, 1)</code>.</li>
</ul>
<p>.. versionadded:: 0.22</p>
<h2 id="attributes_9">Attributes<a class="headerlink" href="#attributes_9" title="Permanent link">&para;</a></h2>
<p>base_estimator_ : DecisionTreeClassifier
The child estimator template used to create the collection of fitted
sub-estimators.</p>
<p>estimators_ : list of DecisionTreeClassifier
The collection of fitted sub-estimators.</p>
<p>classes_ : array of shape (n_classes,) or a list of such arrays
The classes labels (single output problem), or a list of arrays of
class labels (multi-output problem).</p>
<p>n_classes_ : int or list
The number of classes (single output problem), or a list containing the
number of classes for each output (multi-output problem).</p>
<p>n_features_ : int
The number of features when <code>fit</code> is performed.</p>
<p>n_outputs_ : int
The number of outputs when <code>fit</code> is performed.</p>
<p>feature_importances_ : ndarray of shape (n_features,)
The feature importances (the higher, the more important the feature).</p>
<p>oob_score_ : float
Score of the training dataset obtained using an out-of-bag estimate.
This attribute exists only when <code>oob_score</code> is True.</p>
<p>oob_decision_function_ : array of shape (n_samples, n_classes)
Decision function computed with out-of-bag estimate on the training
set. If n_estimators is small it might be possible that a data point
was never left out during the bootstrap. In this case,
<code>oob_decision_function_</code> might contain NaN. This attribute exists
only when <code>oob_score</code> is True.</p>
<h2 id="examples_6">Examples<a class="headerlink" href="#examples_6" title="Permanent link">&para;</a></h2>
<blockquote>
<blockquote>
<blockquote>
<p>from sklearn.ensemble import RandomForestClassifier
from sklearn.datasets import make_classification</p>
<p>X, y = make_classification(n_samples=1000, n_features=4,
...                            n_informative=2, n_redundant=0,
...                            random_state=0, shuffle=False)
clf = RandomForestClassifier(max_depth=2, random_state=0)
clf.fit(X, y)
RandomForestClassifier(max_depth=2, random_state=0)
print(clf.feature_importances_)
[0.14205973 0.76664038 0.0282433  0.06305659]
print(clf.predict([[0, 0, 0, 0]]))
[1]</p>
</blockquote>
</blockquote>
</blockquote>
<h2 id="notes_9">Notes<a class="headerlink" href="#notes_9" title="Permanent link">&para;</a></h2>
<p>The default values for the parameters controlling the size of the trees
(e.g. <code>max_depth</code>, <code>min_samples_leaf</code>, etc.) lead to fully grown and
unpruned trees which can potentially be very large on some data sets. To
reduce memory consumption, the complexity and size of the trees should be
controlled by setting those parameter values.</p>
<p>The features are always randomly permuted at each split. Therefore,
the best found split may vary, even with the same training data,
<code>max_features=n_features</code> and <code>bootstrap=False</code>, if the improvement
of the criterion is identical for several splits enumerated during the
search of the best split. To obtain a deterministic behaviour during
fitting, <code>random_state</code> has to be fixed.</p>
<h2 id="references_9">References<a class="headerlink" href="#references_9" title="Permanent link">&para;</a></h2>
<p>.. [1] L. Breiman, 'Random Forests', Machine Learning, 45(1), 5-32, 2001.</p>
<h2 id="see-also_7">See Also<a class="headerlink" href="#see-also_7" title="Permanent link">&para;</a></h2>
<p>DecisionTreeClassifier, ExtraTreesClassifier</p>
<div class="highlight"><pre><span></span><code><span class="k">val</span> <span class="n">get_item</span> <span class="o">:</span> <span class="n">index</span><span class="o">:</span><span class="nn">Py</span><span class="p">.</span><span class="nn">Object</span><span class="p">.</span><span class="n">t</span> <span class="o">-&gt;</span> <span class="o">[&gt;</span> <span class="n">tag</span><span class="o">]</span> <span class="nn">Obj</span><span class="p">.</span><span class="n">t</span> <span class="o">-&gt;</span> <span class="nn">Py</span><span class="p">.</span><span class="nn">Object</span><span class="p">.</span><span class="n">t</span>
</code></pre></div>

<p>Return the index'th estimator in the ensemble.</p>
<div class="highlight"><pre><span></span><code><span class="k">val</span> <span class="n">iter</span> <span class="o">:</span> <span class="o">[&gt;</span> <span class="n">tag</span><span class="o">]</span> <span class="nn">Obj</span><span class="p">.</span><span class="n">t</span> <span class="o">-&gt;</span> <span class="nn">Dict</span><span class="p">.</span><span class="n">t</span> <span class="nn">Seq</span><span class="p">.</span><span class="n">t</span>
</code></pre></div>

<p>Return iterator over estimators in the ensemble.</p>
<div class="highlight"><pre><span></span><code><span class="k">val</span> <span class="n">apply</span> <span class="o">:</span> <span class="n">x</span><span class="o">:</span><span class="nn">Py</span><span class="p">.</span><span class="nn">Object</span><span class="p">.</span><span class="n">t</span> <span class="o">-&gt;</span> <span class="o">[&gt;</span> <span class="n">tag</span><span class="o">]</span> <span class="nn">Obj</span><span class="p">.</span><span class="n">t</span> <span class="o">-&gt;</span> <span class="o">[&gt;`</span><span class="nc">ArrayLike</span><span class="o">]</span> <span class="nn">Np</span><span class="p">.</span><span class="nn">Obj</span><span class="p">.</span><span class="n">t</span>
</code></pre></div>

<p>Apply trees in the forest to X, return leaf indices.</p>
<h2 id="parameters_85">Parameters<a class="headerlink" href="#parameters_85" title="Permanent link">&para;</a></h2>
<p>X : {array-like or sparse matrix} of shape (n_samples, n_features)
The input samples. Internally, its dtype will be converted to
<code>dtype=np.float32</code>. If a sparse matrix is provided, it will be
converted into a sparse <code>csr_matrix</code>.</p>
<h2 id="returns_69">Returns<a class="headerlink" href="#returns_69" title="Permanent link">&para;</a></h2>
<p>X_leaves : array_like, shape = [n_samples, n_estimators]
For each datapoint x in X and for each tree in the forest,
return the index of the leaf x ends up in.</p>
<div class="highlight"><pre><span></span><code><span class="k">val</span> <span class="n">decision_path</span> <span class="o">:</span> <span class="n">x</span><span class="o">:</span><span class="nn">Py</span><span class="p">.</span><span class="nn">Object</span><span class="p">.</span><span class="n">t</span> <span class="o">-&gt;</span> <span class="o">[&gt;</span> <span class="n">tag</span><span class="o">]</span> <span class="nn">Obj</span><span class="p">.</span><span class="n">t</span> <span class="o">-&gt;</span> <span class="o">(</span><span class="nn">Py</span><span class="p">.</span><span class="nn">Object</span><span class="p">.</span><span class="n">t</span> <span class="o">*</span> <span class="nn">Py</span><span class="p">.</span><span class="nn">Object</span><span class="p">.</span><span class="n">t</span><span class="o">)</span>
</code></pre></div>

<p>Return the decision path in the forest.</p>
<p>.. versionadded:: 0.18</p>
<h2 id="parameters_86">Parameters<a class="headerlink" href="#parameters_86" title="Permanent link">&para;</a></h2>
<p>X : {array-like or sparse matrix} of shape (n_samples, n_features)
The input samples. Internally, its dtype will be converted to
<code>dtype=np.float32</code>. If a sparse matrix is provided, it will be
converted into a sparse <code>csr_matrix</code>.</p>
<h2 id="returns_70">Returns<a class="headerlink" href="#returns_70" title="Permanent link">&para;</a></h2>
<p>indicator : sparse csr array, shape = [n_samples, n_nodes]
Return a node indicator matrix where non zero elements
indicates that the samples goes through the nodes.</p>
<p>n_nodes_ptr : array of size (n_estimators + 1, )
The columns from indicator[n_nodes_ptr[i]:n_nodes_ptr[i+1]]
gives the indicator value for the i-th estimator.</p>
<div class="highlight"><pre><span></span><code><span class="k">val</span> <span class="n">fit</span> <span class="o">:</span> <span class="o">?</span><span class="n">sample_weight</span><span class="o">:[&gt;`</span><span class="nc">ArrayLike</span><span class="o">]</span> <span class="nn">Np</span><span class="p">.</span><span class="nn">Obj</span><span class="p">.</span><span class="n">t</span> <span class="o">-&gt;</span> <span class="n">x</span><span class="o">:[&gt;`</span><span class="nc">ArrayLike</span><span class="o">]</span> <span class="nn">Np</span><span class="p">.</span><span class="nn">Obj</span><span class="p">.</span><span class="n">t</span> <span class="o">-&gt;</span> <span class="n">y</span><span class="o">:[&gt;`</span><span class="nc">ArrayLike</span><span class="o">]</span> <span class="nn">Np</span><span class="p">.</span><span class="nn">Obj</span><span class="p">.</span><span class="n">t</span> <span class="o">-&gt;</span> <span class="o">[&gt;</span> <span class="n">tag</span><span class="o">]</span> <span class="nn">Obj</span><span class="p">.</span><span class="n">t</span> <span class="o">-&gt;</span> <span class="n">t</span>
</code></pre></div>

<p>Build a forest of trees from the training set (X, y).</p>
<h2 id="parameters_87">Parameters<a class="headerlink" href="#parameters_87" title="Permanent link">&para;</a></h2>
<p>X : array-like or sparse matrix of shape (n_samples, n_features)
The training input samples. Internally, its dtype will be converted
to <code>dtype=np.float32</code>. If a sparse matrix is provided, it will be
converted into a sparse <code>csc_matrix</code>.</p>
<p>y : array-like of shape (n_samples,) or (n_samples, n_outputs)
The target values (class labels in classification, real numbers in
regression).</p>
<p>sample_weight : array-like of shape (n_samples,), default=None
Sample weights. If None, then samples are equally weighted. Splits
that would create child nodes with net zero or negative weight are
ignored while searching for a split in each node. In the case of
classification, splits are also ignored if they would result in any
single class carrying a negative weight in either child node.</p>
<h2 id="returns_71">Returns<a class="headerlink" href="#returns_71" title="Permanent link">&para;</a></h2>
<p>self : object</p>
<div class="highlight"><pre><span></span><code><span class="k">val</span> <span class="n">get_params</span> <span class="o">:</span> <span class="o">?</span><span class="n">deep</span><span class="o">:</span><span class="kt">bool</span> <span class="o">-&gt;</span> <span class="o">[&gt;</span> <span class="n">tag</span><span class="o">]</span> <span class="nn">Obj</span><span class="p">.</span><span class="n">t</span> <span class="o">-&gt;</span> <span class="nn">Dict</span><span class="p">.</span><span class="n">t</span>
</code></pre></div>

<p>Get parameters for this estimator.</p>
<h2 id="parameters_88">Parameters<a class="headerlink" href="#parameters_88" title="Permanent link">&para;</a></h2>
<p>deep : bool, default=True
If True, will return the parameters for this estimator and
contained subobjects that are estimators.</p>
<h2 id="returns_72">Returns<a class="headerlink" href="#returns_72" title="Permanent link">&para;</a></h2>
<p>params : mapping of string to any
Parameter names mapped to their values.</p>
<div class="highlight"><pre><span></span><code><span class="k">val</span> <span class="n">predict</span> <span class="o">:</span> <span class="n">x</span><span class="o">:[&gt;`</span><span class="nc">ArrayLike</span><span class="o">]</span> <span class="nn">Np</span><span class="p">.</span><span class="nn">Obj</span><span class="p">.</span><span class="n">t</span> <span class="o">-&gt;</span> <span class="o">[&gt;</span> <span class="n">tag</span><span class="o">]</span> <span class="nn">Obj</span><span class="p">.</span><span class="n">t</span> <span class="o">-&gt;</span> <span class="o">[&gt;`</span><span class="nc">ArrayLike</span><span class="o">]</span> <span class="nn">Np</span><span class="p">.</span><span class="nn">Obj</span><span class="p">.</span><span class="n">t</span>
</code></pre></div>

<p>Predict class for X.</p>
<p>The predicted class of an input sample is a vote by the trees in
the forest, weighted by their probability estimates. That is,
the predicted class is the one with highest mean probability
estimate across the trees.</p>
<h2 id="parameters_89">Parameters<a class="headerlink" href="#parameters_89" title="Permanent link">&para;</a></h2>
<p>X : array-like or sparse matrix of shape (n_samples, n_features)
The input samples. Internally, its dtype will be converted to
<code>dtype=np.float32</code>. If a sparse matrix is provided, it will be
converted into a sparse <code>csr_matrix</code>.</p>
<h2 id="returns_73">Returns<a class="headerlink" href="#returns_73" title="Permanent link">&para;</a></h2>
<p>y : array-like of shape (n_samples,) or (n_samples, n_outputs)
The predicted classes.</p>
<div class="highlight"><pre><span></span><code><span class="k">val</span> <span class="n">predict_log_proba</span> <span class="o">:</span> <span class="n">x</span><span class="o">:[&gt;`</span><span class="nc">ArrayLike</span><span class="o">]</span> <span class="nn">Np</span><span class="p">.</span><span class="nn">Obj</span><span class="p">.</span><span class="n">t</span> <span class="o">-&gt;</span> <span class="o">[&gt;</span> <span class="n">tag</span><span class="o">]</span> <span class="nn">Obj</span><span class="p">.</span><span class="n">t</span> <span class="o">-&gt;</span> <span class="nn">Py</span><span class="p">.</span><span class="nn">Object</span><span class="p">.</span><span class="n">t</span>
</code></pre></div>

<p>Predict class log-probabilities for X.</p>
<p>The predicted class log-probabilities of an input sample is computed as
the log of the mean predicted class probabilities of the trees in the
forest.</p>
<h2 id="parameters_90">Parameters<a class="headerlink" href="#parameters_90" title="Permanent link">&para;</a></h2>
<p>X : array-like or sparse matrix of shape (n_samples, n_features)
The input samples. Internally, its dtype will be converted to
<code>dtype=np.float32</code>. If a sparse matrix is provided, it will be
converted into a sparse <code>csr_matrix</code>.</p>
<h2 id="returns_74">Returns<a class="headerlink" href="#returns_74" title="Permanent link">&para;</a></h2>
<p>p : array of shape (n_samples, n_classes), or a list of n_outputs
such arrays if n_outputs &gt; 1.
The class probabilities of the input samples. The order of the
classes corresponds to that in the attribute :term:<code>classes_</code>.</p>
<div class="highlight"><pre><span></span><code><span class="k">val</span> <span class="n">predict_proba</span> <span class="o">:</span> <span class="n">x</span><span class="o">:[&gt;`</span><span class="nc">ArrayLike</span><span class="o">]</span> <span class="nn">Np</span><span class="p">.</span><span class="nn">Obj</span><span class="p">.</span><span class="n">t</span> <span class="o">-&gt;</span> <span class="o">[&gt;</span> <span class="n">tag</span><span class="o">]</span> <span class="nn">Obj</span><span class="p">.</span><span class="n">t</span> <span class="o">-&gt;</span> <span class="o">[&gt;`</span><span class="nc">ArrayLike</span><span class="o">]</span> <span class="nn">Np</span><span class="p">.</span><span class="nn">Obj</span><span class="p">.</span><span class="n">t</span>
</code></pre></div>

<p>Predict class probabilities for X.</p>
<p>The predicted class probabilities of an input sample are computed as
the mean predicted class probabilities of the trees in the forest.
The class probability of a single tree is the fraction of samples of
the same class in a leaf.</p>
<h2 id="parameters_91">Parameters<a class="headerlink" href="#parameters_91" title="Permanent link">&para;</a></h2>
<p>X : array-like or sparse matrix of shape (n_samples, n_features)
The input samples. Internally, its dtype will be converted to
<code>dtype=np.float32</code>. If a sparse matrix is provided, it will be
converted into a sparse <code>csr_matrix</code>.</p>
<h2 id="returns_75">Returns<a class="headerlink" href="#returns_75" title="Permanent link">&para;</a></h2>
<p>p : array of shape (n_samples, n_classes), or a list of n_outputs
such arrays if n_outputs &gt; 1.
The class probabilities of the input samples. The order of the
classes corresponds to that in the attribute :term:<code>classes_</code>.</p>
<div class="highlight"><pre><span></span><code><span class="k">val</span> <span class="n">score</span> <span class="o">:</span> <span class="o">?</span><span class="n">sample_weight</span><span class="o">:[&gt;`</span><span class="nc">ArrayLike</span><span class="o">]</span> <span class="nn">Np</span><span class="p">.</span><span class="nn">Obj</span><span class="p">.</span><span class="n">t</span> <span class="o">-&gt;</span> <span class="n">x</span><span class="o">:[&gt;`</span><span class="nc">ArrayLike</span><span class="o">]</span> <span class="nn">Np</span><span class="p">.</span><span class="nn">Obj</span><span class="p">.</span><span class="n">t</span> <span class="o">-&gt;</span> <span class="n">y</span><span class="o">:[&gt;`</span><span class="nc">ArrayLike</span><span class="o">]</span> <span class="nn">Np</span><span class="p">.</span><span class="nn">Obj</span><span class="p">.</span><span class="n">t</span> <span class="o">-&gt;</span> <span class="o">[&gt;</span> <span class="n">tag</span><span class="o">]</span> <span class="nn">Obj</span><span class="p">.</span><span class="n">t</span> <span class="o">-&gt;</span> <span class="kt">float</span>
</code></pre></div>

<p>Return the mean accuracy on the given test data and labels.</p>
<p>In multi-label classification, this is the subset accuracy
which is a harsh metric since you require for each sample that
each label set be correctly predicted.</p>
<h2 id="parameters_92">Parameters<a class="headerlink" href="#parameters_92" title="Permanent link">&para;</a></h2>
<p>X : array-like of shape (n_samples, n_features)
Test samples.</p>
<p>y : array-like of shape (n_samples,) or (n_samples, n_outputs)
True labels for X.</p>
<p>sample_weight : array-like of shape (n_samples,), default=None
Sample weights.</p>
<h2 id="returns_76">Returns<a class="headerlink" href="#returns_76" title="Permanent link">&para;</a></h2>
<p>score : float
Mean accuracy of self.predict(X) wrt. y.</p>
<div class="highlight"><pre><span></span><code><span class="k">val</span> <span class="n">set_params</span> <span class="o">:</span> <span class="o">?</span><span class="n">params</span><span class="o">:(</span><span class="kt">string</span> <span class="o">*</span> <span class="nn">Py</span><span class="p">.</span><span class="nn">Object</span><span class="p">.</span><span class="n">t</span><span class="o">)</span> <span class="kt">list</span> <span class="o">-&gt;</span> <span class="o">[&gt;</span> <span class="n">tag</span><span class="o">]</span> <span class="nn">Obj</span><span class="p">.</span><span class="n">t</span> <span class="o">-&gt;</span> <span class="n">t</span>
</code></pre></div>

<p>Set the parameters of this estimator.</p>
<p>The method works on simple estimators as well as on nested objects
(such as pipelines). The latter have parameters of the form
<code>&lt;component&gt;__&lt;parameter&gt;</code> so that it's possible to update each
component of a nested object.</p>
<h2 id="parameters_93">Parameters<a class="headerlink" href="#parameters_93" title="Permanent link">&para;</a></h2>
<p>**params : dict
Estimator parameters.</p>
<h2 id="returns_77">Returns<a class="headerlink" href="#returns_77" title="Permanent link">&para;</a></h2>
<p>self : object
Estimator instance.</p>
<p>Attribute base_estimator_: get value or raise Not_found if None.</p>
<div class="highlight"><pre><span></span><code><span class="k">val</span> <span class="n">base_estimator_</span> <span class="o">:</span> <span class="n">t</span> <span class="o">-&gt;</span> <span class="nn">Py</span><span class="p">.</span><span class="nn">Object</span><span class="p">.</span><span class="n">t</span>
</code></pre></div>

<p>Attribute base_estimator_: get value as an option.</p>
<div class="highlight"><pre><span></span><code><span class="k">val</span> <span class="n">base_estimator_opt</span> <span class="o">:</span> <span class="n">t</span> <span class="o">-&gt;</span> <span class="o">(</span><span class="nn">Py</span><span class="p">.</span><span class="nn">Object</span><span class="p">.</span><span class="n">t</span><span class="o">)</span> <span class="n">option</span>
</code></pre></div>

<p>Attribute estimators_: get value or raise Not_found if None.</p>
<div class="highlight"><pre><span></span><code><span class="k">val</span> <span class="n">estimators_</span> <span class="o">:</span> <span class="n">t</span> <span class="o">-&gt;</span> <span class="nn">Py</span><span class="p">.</span><span class="nn">Object</span><span class="p">.</span><span class="n">t</span>
</code></pre></div>

<p>Attribute estimators_: get value as an option.</p>
<div class="highlight"><pre><span></span><code><span class="k">val</span> <span class="n">estimators_opt</span> <span class="o">:</span> <span class="n">t</span> <span class="o">-&gt;</span> <span class="o">(</span><span class="nn">Py</span><span class="p">.</span><span class="nn">Object</span><span class="p">.</span><span class="n">t</span><span class="o">)</span> <span class="n">option</span>
</code></pre></div>

<p>Attribute classes_: get value or raise Not_found if None.</p>
<div class="highlight"><pre><span></span><code><span class="k">val</span> <span class="n">classes_</span> <span class="o">:</span> <span class="n">t</span> <span class="o">-&gt;</span> <span class="o">[&gt;`</span><span class="nc">ArrayLike</span><span class="o">]</span> <span class="nn">Np</span><span class="p">.</span><span class="nn">Obj</span><span class="p">.</span><span class="n">t</span>
</code></pre></div>

<p>Attribute classes_: get value as an option.</p>
<div class="highlight"><pre><span></span><code><span class="k">val</span> <span class="n">classes_opt</span> <span class="o">:</span> <span class="n">t</span> <span class="o">-&gt;</span> <span class="o">([&gt;`</span><span class="nc">ArrayLike</span><span class="o">]</span> <span class="nn">Np</span><span class="p">.</span><span class="nn">Obj</span><span class="p">.</span><span class="n">t</span><span class="o">)</span> <span class="n">option</span>
</code></pre></div>

<p>Attribute n_classes_: get value or raise Not_found if None.</p>
<div class="highlight"><pre><span></span><code><span class="k">val</span> <span class="n">n_classes_</span> <span class="o">:</span> <span class="n">t</span> <span class="o">-&gt;</span> <span class="nn">Py</span><span class="p">.</span><span class="nn">Object</span><span class="p">.</span><span class="n">t</span>
</code></pre></div>

<p>Attribute n_classes_: get value as an option.</p>
<div class="highlight"><pre><span></span><code><span class="k">val</span> <span class="n">n_classes_opt</span> <span class="o">:</span> <span class="n">t</span> <span class="o">-&gt;</span> <span class="o">(</span><span class="nn">Py</span><span class="p">.</span><span class="nn">Object</span><span class="p">.</span><span class="n">t</span><span class="o">)</span> <span class="n">option</span>
</code></pre></div>

<p>Attribute n_features_: get value or raise Not_found if None.</p>
<div class="highlight"><pre><span></span><code><span class="k">val</span> <span class="n">n_features_</span> <span class="o">:</span> <span class="n">t</span> <span class="o">-&gt;</span> <span class="kt">int</span>
</code></pre></div>

<p>Attribute n_features_: get value as an option.</p>
<div class="highlight"><pre><span></span><code><span class="k">val</span> <span class="n">n_features_opt</span> <span class="o">:</span> <span class="n">t</span> <span class="o">-&gt;</span> <span class="o">(</span><span class="kt">int</span><span class="o">)</span> <span class="n">option</span>
</code></pre></div>

<p>Attribute n_outputs_: get value or raise Not_found if None.</p>
<div class="highlight"><pre><span></span><code><span class="k">val</span> <span class="n">n_outputs_</span> <span class="o">:</span> <span class="n">t</span> <span class="o">-&gt;</span> <span class="kt">int</span>
</code></pre></div>

<p>Attribute n_outputs_: get value as an option.</p>
<div class="highlight"><pre><span></span><code><span class="k">val</span> <span class="n">n_outputs_opt</span> <span class="o">:</span> <span class="n">t</span> <span class="o">-&gt;</span> <span class="o">(</span><span class="kt">int</span><span class="o">)</span> <span class="n">option</span>
</code></pre></div>

<p>Attribute feature_importances_: get value or raise Not_found if None.</p>
<div class="highlight"><pre><span></span><code><span class="k">val</span> <span class="n">feature_importances_</span> <span class="o">:</span> <span class="n">t</span> <span class="o">-&gt;</span> <span class="o">[&gt;`</span><span class="nc">ArrayLike</span><span class="o">]</span> <span class="nn">Np</span><span class="p">.</span><span class="nn">Obj</span><span class="p">.</span><span class="n">t</span>
</code></pre></div>

<p>Attribute feature_importances_: get value as an option.</p>
<div class="highlight"><pre><span></span><code><span class="k">val</span> <span class="n">feature_importances_opt</span> <span class="o">:</span> <span class="n">t</span> <span class="o">-&gt;</span> <span class="o">([&gt;`</span><span class="nc">ArrayLike</span><span class="o">]</span> <span class="nn">Np</span><span class="p">.</span><span class="nn">Obj</span><span class="p">.</span><span class="n">t</span><span class="o">)</span> <span class="n">option</span>
</code></pre></div>

<p>Attribute oob_score_: get value or raise Not_found if None.</p>
<div class="highlight"><pre><span></span><code><span class="k">val</span> <span class="n">oob_score_</span> <span class="o">:</span> <span class="n">t</span> <span class="o">-&gt;</span> <span class="kt">float</span>
</code></pre></div>

<p>Attribute oob_score_: get value as an option.</p>
<div class="highlight"><pre><span></span><code><span class="k">val</span> <span class="n">oob_score_opt</span> <span class="o">:</span> <span class="n">t</span> <span class="o">-&gt;</span> <span class="o">(</span><span class="kt">float</span><span class="o">)</span> <span class="n">option</span>
</code></pre></div>

<p>Attribute oob_decision_function_: get value or raise Not_found if None.</p>
<div class="highlight"><pre><span></span><code><span class="k">val</span> <span class="n">oob_decision_function_</span> <span class="o">:</span> <span class="n">t</span> <span class="o">-&gt;</span> <span class="o">[&gt;`</span><span class="nc">ArrayLike</span><span class="o">]</span> <span class="nn">Np</span><span class="p">.</span><span class="nn">Obj</span><span class="p">.</span><span class="n">t</span>
</code></pre></div>

<p>Attribute oob_decision_function_: get value as an option.</p>
<div class="highlight"><pre><span></span><code><span class="k">val</span> <span class="n">oob_decision_function_opt</span> <span class="o">:</span> <span class="n">t</span> <span class="o">-&gt;</span> <span class="o">([&gt;`</span><span class="nc">ArrayLike</span><span class="o">]</span> <span class="nn">Np</span><span class="p">.</span><span class="nn">Obj</span><span class="p">.</span><span class="n">t</span><span class="o">)</span> <span class="n">option</span>
</code></pre></div>

<p>Print the object to a human-readable representation.</p>
<div class="highlight"><pre><span></span><code><span class="k">val</span> <span class="n">to_string</span> <span class="o">:</span> <span class="n">t</span> <span class="o">-&gt;</span> <span class="kt">string</span>
</code></pre></div>

<p>Print the object to a human-readable representation.</p>
<div class="highlight"><pre><span></span><code><span class="k">val</span> <span class="n">show</span> <span class="o">:</span> <span class="n">t</span> <span class="o">-&gt;</span> <span class="kt">string</span>
</code></pre></div>

<p>Pretty-print the object to a formatter.</p>
<div class="highlight"><pre><span></span><code><span class="k">val</span> <span class="n">pp</span> <span class="o">:</span> <span class="nn">Format</span><span class="p">.</span><span class="n">formatter</span> <span class="o">-&gt;</span> <span class="n">t</span> <span class="o">-&gt;</span> <span class="kt">unit</span> <span class="o">[@@</span><span class="n">ocaml</span><span class="o">.</span><span class="n">toplevel_printer</span><span class="o">]</span>



<span class="k">module</span> <span class="nc">RandomForestRegressor</span> <span class="o">:</span> <span class="k">sig</span>
<span class="k">type</span> <span class="n">tag</span> <span class="o">=</span> <span class="o">[`</span><span class="nc">RandomForestRegressor</span><span class="o">]</span>
<span class="k">type</span> <span class="n">t</span> <span class="o">=</span> <span class="o">[`</span><span class="nc">BaseEnsemble</span> <span class="o">|</span> <span class="o">`</span><span class="nc">BaseEstimator</span> <span class="o">|</span> <span class="o">`</span><span class="nc">BaseForest</span> <span class="o">|</span> <span class="o">`</span><span class="nc">MetaEstimatorMixin</span> <span class="o">|</span> <span class="o">`</span><span class="nc">MultiOutputMixin</span> <span class="o">|</span> <span class="o">`</span><span class="nc">Object</span> <span class="o">|</span> <span class="o">`</span><span class="nc">RandomForestRegressor</span> <span class="o">|</span> <span class="o">`</span><span class="nc">RegressorMixin</span><span class="o">]</span> <span class="nn">Obj</span><span class="p">.</span><span class="n">t</span>
<span class="k">val</span> <span class="n">of_pyobject</span> <span class="o">:</span> <span class="nn">Py</span><span class="p">.</span><span class="nn">Object</span><span class="p">.</span><span class="n">t</span> <span class="o">-&gt;</span> <span class="n">t</span>
<span class="k">val</span> <span class="n">to_pyobject</span> <span class="o">:</span> <span class="o">[&gt;</span> <span class="n">tag</span><span class="o">]</span> <span class="nn">Obj</span><span class="p">.</span><span class="n">t</span> <span class="o">-&gt;</span> <span class="nn">Py</span><span class="p">.</span><span class="nn">Object</span><span class="p">.</span><span class="n">t</span>

<span class="k">val</span> <span class="n">as_regressor</span> <span class="o">:</span> <span class="n">t</span> <span class="o">-&gt;</span> <span class="o">[`</span><span class="nc">RegressorMixin</span><span class="o">]</span> <span class="nn">Obj</span><span class="p">.</span><span class="n">t</span>
<span class="k">val</span> <span class="n">as_multi_output</span> <span class="o">:</span> <span class="n">t</span> <span class="o">-&gt;</span> <span class="o">[`</span><span class="nc">MultiOutputMixin</span><span class="o">]</span> <span class="nn">Obj</span><span class="p">.</span><span class="n">t</span>
<span class="k">val</span> <span class="n">as_meta_estimator</span> <span class="o">:</span> <span class="n">t</span> <span class="o">-&gt;</span> <span class="o">[`</span><span class="nc">MetaEstimatorMixin</span><span class="o">]</span> <span class="nn">Obj</span><span class="p">.</span><span class="n">t</span>
<span class="k">val</span> <span class="n">as_estimator</span> <span class="o">:</span> <span class="n">t</span> <span class="o">-&gt;</span> <span class="o">[`</span><span class="nc">BaseEstimator</span><span class="o">]</span> <span class="nn">Obj</span><span class="p">.</span><span class="n">t</span>
<span class="k">val</span> <span class="n">as_ensemble</span> <span class="o">:</span> <span class="n">t</span> <span class="o">-&gt;</span> <span class="o">[`</span><span class="nc">BaseEnsemble</span><span class="o">]</span> <span class="nn">Obj</span><span class="p">.</span><span class="n">t</span>
<span class="k">val</span> <span class="n">as_forest</span> <span class="o">:</span> <span class="n">t</span> <span class="o">-&gt;</span> <span class="o">[`</span><span class="nc">BaseForest</span><span class="o">]</span> <span class="nn">Obj</span><span class="p">.</span><span class="n">t</span>
<span class="k">val</span> <span class="n">create</span> <span class="o">:</span> <span class="o">?</span><span class="n">n_estimators</span><span class="o">:</span><span class="kt">int</span> <span class="o">-&gt;</span> <span class="o">?</span><span class="n">criterion</span><span class="o">:</span><span class="kt">string</span> <span class="o">-&gt;</span> <span class="o">?</span><span class="n">max_depth</span><span class="o">:</span><span class="kt">int</span> <span class="o">-&gt;</span> <span class="o">?</span><span class="n">min_samples_split</span><span class="o">:[`</span><span class="nc">F</span> <span class="k">of</span> <span class="kt">float</span> <span class="o">|</span> <span class="o">`</span><span class="nc">I</span> <span class="k">of</span> <span class="kt">int</span><span class="o">]</span> <span class="o">-&gt;</span> <span class="o">?</span><span class="n">min_samples_leaf</span><span class="o">:[`</span><span class="nc">F</span> <span class="k">of</span> <span class="kt">float</span> <span class="o">|</span> <span class="o">`</span><span class="nc">I</span> <span class="k">of</span> <span class="kt">int</span><span class="o">]</span> <span class="o">-&gt;</span> <span class="o">?</span><span class="n">min_weight_fraction_leaf</span><span class="o">:</span><span class="kt">float</span> <span class="o">-&gt;</span> <span class="o">?</span><span class="n">max_features</span><span class="o">:[`</span><span class="nc">F</span> <span class="k">of</span> <span class="kt">float</span> <span class="o">|</span> <span class="o">`</span><span class="nc">S</span> <span class="k">of</span> <span class="kt">string</span> <span class="o">|</span> <span class="o">`</span><span class="nc">I</span> <span class="k">of</span> <span class="kt">int</span> <span class="o">|</span> <span class="o">`</span><span class="nc">None</span><span class="o">]</span> <span class="o">-&gt;</span> <span class="o">?</span><span class="n">max_leaf_nodes</span><span class="o">:</span><span class="kt">int</span> <span class="o">-&gt;</span> <span class="o">?</span><span class="n">min_impurity_decrease</span><span class="o">:</span><span class="kt">float</span> <span class="o">-&gt;</span> <span class="o">?</span><span class="n">min_impurity_split</span><span class="o">:</span><span class="kt">float</span> <span class="o">-&gt;</span> <span class="o">?</span><span class="n">bootstrap</span><span class="o">:</span><span class="kt">bool</span> <span class="o">-&gt;</span> <span class="o">?</span><span class="n">oob_score</span><span class="o">:</span><span class="kt">bool</span> <span class="o">-&gt;</span> <span class="o">?</span><span class="n">n_jobs</span><span class="o">:</span><span class="kt">int</span> <span class="o">-&gt;</span> <span class="o">?</span><span class="n">random_state</span><span class="o">:</span><span class="kt">int</span> <span class="o">-&gt;</span> <span class="o">?</span><span class="n">verbose</span><span class="o">:</span><span class="kt">int</span> <span class="o">-&gt;</span> <span class="o">?</span><span class="n">warm_start</span><span class="o">:</span><span class="kt">bool</span> <span class="o">-&gt;</span> <span class="o">?</span><span class="n">ccp_alpha</span><span class="o">:</span><span class="kt">float</span> <span class="o">-&gt;</span> <span class="o">?</span><span class="n">max_samples</span><span class="o">:[`</span><span class="nc">F</span> <span class="k">of</span> <span class="kt">float</span> <span class="o">|</span> <span class="o">`</span><span class="nc">I</span> <span class="k">of</span> <span class="kt">int</span><span class="o">]</span> <span class="o">-&gt;</span> <span class="kt">unit</span> <span class="o">-&gt;</span> <span class="n">t</span>
</code></pre></div>

<p>A random forest regressor.</p>
<p>A random forest is a meta estimator that fits a number of classifying
decision trees on various sub-samples of the dataset and uses averaging
to improve the predictive accuracy and control over-fitting.
The sub-sample size is always the same as the original
input sample size but the samples are drawn with replacement if
<code>bootstrap=True</code> (default).</p>
<p>Read more in the :ref:<code>User Guide &lt;forest&gt;</code>.</p>
<h2 id="parameters_94">Parameters<a class="headerlink" href="#parameters_94" title="Permanent link">&para;</a></h2>
<p>n_estimators : integer, optional (default=10)
The number of trees in the forest.</p>
<p>.. versionchanged:: 0.22
The default value of <code>n_estimators</code> changed from 10 to 100
in 0.22.</p>
<p>criterion : string, optional (default='mse')
The function to measure the quality of a split. Supported criteria
are 'mse' for the mean squared error, which is equal to variance
reduction as feature selection criterion, and 'mae' for the mean
absolute error.</p>
<p>.. versionadded:: 0.18
Mean Absolute Error (MAE) criterion.</p>
<p>max_depth : integer or None, optional (default=None)
The maximum depth of the tree. If None, then nodes are expanded until
all leaves are pure or until all leaves contain less than
min_samples_split samples.</p>
<p>min_samples_split : int, float, optional (default=2)
The minimum number of samples required to split an internal node:</p>
<ul>
<li>If int, then consider <code>min_samples_split</code> as the minimum number.</li>
<li>If float, then <code>min_samples_split</code> is a fraction and
<code>ceil(min_samples_split * n_samples)</code> are the minimum
number of samples for each split.</li>
</ul>
<p>.. versionchanged:: 0.18
Added float values for fractions.</p>
<p>min_samples_leaf : int, float, optional (default=1)
The minimum number of samples required to be at a leaf node.
A split point at any depth will only be considered if it leaves at
least <code>min_samples_leaf</code> training samples in each of the left and
right branches.  This may have the effect of smoothing the model,
especially in regression.</p>
<ul>
<li>If int, then consider <code>min_samples_leaf</code> as the minimum number.</li>
<li>If float, then <code>min_samples_leaf</code> is a fraction and
<code>ceil(min_samples_leaf * n_samples)</code> are the minimum
number of samples for each node.</li>
</ul>
<p>.. versionchanged:: 0.18
Added float values for fractions.</p>
<p>min_weight_fraction_leaf : float, optional (default=0.)
The minimum weighted fraction of the sum total of weights (of all
the input samples) required to be at a leaf node. Samples have
equal weight when sample_weight is not provided.</p>
<p>max_features : int, float, string or None, optional (default='auto')
The number of features to consider when looking for the best split:</p>
<ul>
<li>If int, then consider <code>max_features</code> features at each split.</li>
<li>If float, then <code>max_features</code> is a fraction and
<code>int(max_features * n_features)</code> features are considered at each
split.</li>
<li>If 'auto', then <code>max_features=n_features</code>.</li>
<li>If 'sqrt', then <code>max_features=sqrt(n_features)</code>.</li>
<li>If 'log2', then <code>max_features=log2(n_features)</code>.</li>
<li>If None, then <code>max_features=n_features</code>.</li>
</ul>
<p>Note: the search for a split does not stop until at least one
valid partition of the node samples is found, even if it requires to
effectively inspect more than <code>max_features</code> features.</p>
<p>max_leaf_nodes : int or None, optional (default=None)
Grow trees with <code>max_leaf_nodes</code> in best-first fashion.
Best nodes are defined as relative reduction in impurity.
If None then unlimited number of leaf nodes.</p>
<p>min_impurity_decrease : float, optional (default=0.)
A node will be split if this split induces a decrease of the impurity
greater than or equal to this value.</p>
<p>The weighted impurity decrease equation is the following::</p>
<p>N_t / N * (impurity - N_t_R / N_t * right_impurity
- N_t_L / N_t * left_impurity)</p>
<p>where <code>N</code> is the total number of samples, <code>N_t</code> is the number of
samples at the current node, <code>N_t_L</code> is the number of samples in the
left child, and <code>N_t_R</code> is the number of samples in the right child.</p>
<p><code>N</code>, <code>N_t</code>, <code>N_t_R</code> and <code>N_t_L</code> all refer to the weighted sum,
if <code>sample_weight</code> is passed.</p>
<p>.. versionadded:: 0.19</p>
<p>min_impurity_split : float, (default=1e-7)
Threshold for early stopping in tree growth. A node will split
if its impurity is above the threshold, otherwise it is a leaf.</p>
<p>.. deprecated:: 0.19
<code>min_impurity_split</code> has been deprecated in favor of
<code>min_impurity_decrease</code> in 0.19. The default value of
<code>min_impurity_split</code> will change from 1e-7 to 0 in 0.23 and it
will be removed in 0.25. Use <code>min_impurity_decrease</code> instead.</p>
<p>bootstrap : boolean, optional (default=True)
Whether bootstrap samples are used when building trees. If False, the
whole datset is used to build each tree.</p>
<p>oob_score : bool, optional (default=False)
whether to use out-of-bag samples to estimate
the R^2 on unseen data.</p>
<p>n_jobs : int or None, optional (default=None)
The number of jobs to run in parallel. :meth:<code>fit</code>, :meth:<code>predict</code>,
:meth:<code>decision_path</code> and :meth:<code>apply</code> are all parallelized over the
trees. <code>None</code> means 1 unless in a :obj:<code>joblib.parallel_backend</code>
context. <code>-1</code> means using all processors. See :term:<code>Glossary
&lt;n_jobs&gt;</code> for more details.</p>
<p>random_state : int, RandomState instance or None, optional (default=None)
Controls both the randomness of the bootstrapping of the samples used
when building trees (if <code>bootstrap=True</code>) and the sampling of the
features to consider when looking for the best split at each node
(if <code>max_features &lt; n_features</code>).
See :term:<code>Glossary &lt;random_state&gt;</code> for details.</p>
<p>verbose : int, optional (default=0)
Controls the verbosity when fitting and predicting.</p>
<p>warm_start : bool, optional (default=False)
When set to <code>True</code>, reuse the solution of the previous call to fit
and add more estimators to the ensemble, otherwise, just fit a whole
new forest. See :term:<code>the Glossary &lt;warm_start&gt;</code>.</p>
<p>ccp_alpha : non-negative float, optional (default=0.0)
Complexity parameter used for Minimal Cost-Complexity Pruning. The
subtree with the largest cost complexity that is smaller than
<code>ccp_alpha</code> will be chosen. By default, no pruning is performed. See
:ref:<code>minimal_cost_complexity_pruning</code> for details.</p>
<p>.. versionadded:: 0.22</p>
<p>max_samples : int or float, default=None
If bootstrap is True, the number of samples to draw from X
to train each base estimator.</p>
<ul>
<li>If None (default), then draw <code>X.shape[0]</code> samples.</li>
<li>If int, then draw <code>max_samples</code> samples.</li>
<li>If float, then draw <code>max_samples * X.shape[0]</code> samples. Thus,
<code>max_samples</code> should be in the interval <code>(0, 1)</code>.</li>
</ul>
<p>.. versionadded:: 0.22</p>
<h2 id="attributes_10">Attributes<a class="headerlink" href="#attributes_10" title="Permanent link">&para;</a></h2>
<p>base_estimator_ : DecisionTreeRegressor
The child estimator template used to create the collection of fitted
sub-estimators.</p>
<p>estimators_ : list of DecisionTreeRegressor
The collection of fitted sub-estimators.</p>
<p>feature_importances_ : ndarray of shape (n_features,)
The feature importances (the higher, the more important the feature).</p>
<p>n_features_ : int
The number of features when <code>fit</code> is performed.</p>
<p>n_outputs_ : int
The number of outputs when <code>fit</code> is performed.</p>
<p>oob_score_ : float
Score of the training dataset obtained using an out-of-bag estimate.
This attribute exists only when <code>oob_score</code> is True.</p>
<p>oob_prediction_ : ndarray of shape (n_samples,)
Prediction computed with out-of-bag estimate on the training set.
This attribute exists only when <code>oob_score</code> is True.</p>
<h2 id="examples_7">Examples<a class="headerlink" href="#examples_7" title="Permanent link">&para;</a></h2>
<blockquote>
<blockquote>
<blockquote>
<p>from sklearn.ensemble import RandomForestRegressor
from sklearn.datasets import make_regression</p>
<p>X, y = make_regression(n_features=4, n_informative=2,
...                        random_state=0, shuffle=False)
regr = RandomForestRegressor(max_depth=2, random_state=0)
regr.fit(X, y)
RandomForestRegressor(max_depth=2, random_state=0)
print(regr.feature_importances_)
[0.18146984 0.81473937 0.00145312 0.00233767]
print(regr.predict([[0, 0, 0, 0]]))
[-8.32987858]</p>
</blockquote>
</blockquote>
</blockquote>
<h2 id="notes_10">Notes<a class="headerlink" href="#notes_10" title="Permanent link">&para;</a></h2>
<p>The default values for the parameters controlling the size of the trees
(e.g. <code>max_depth</code>, <code>min_samples_leaf</code>, etc.) lead to fully grown and
unpruned trees which can potentially be very large on some data sets. To
reduce memory consumption, the complexity and size of the trees should be
controlled by setting those parameter values.</p>
<p>The features are always randomly permuted at each split. Therefore,
the best found split may vary, even with the same training data,
<code>max_features=n_features</code> and <code>bootstrap=False</code>, if the improvement
of the criterion is identical for several splits enumerated during the
search of the best split. To obtain a deterministic behaviour during
fitting, <code>random_state</code> has to be fixed.</p>
<p>The default value <code>max_features='auto'</code> uses <code>n_features</code>
rather than <code>n_features / 3</code>. The latter was originally suggested in
[1], whereas the former was more recently justified empirically in [2].</p>
<h2 id="references_10">References<a class="headerlink" href="#references_10" title="Permanent link">&para;</a></h2>
<p>.. [1] L. Breiman, 'Random Forests', Machine Learning, 45(1), 5-32, 2001.</p>
<p>.. [2] P. Geurts, D. Ernst., and L. Wehenkel, 'Extremely randomized
trees', Machine Learning, 63(1), 3-42, 2006.</p>
<h2 id="see-also_8">See Also<a class="headerlink" href="#see-also_8" title="Permanent link">&para;</a></h2>
<p>DecisionTreeRegressor, ExtraTreesRegressor</p>
<div class="highlight"><pre><span></span><code><span class="k">val</span> <span class="n">get_item</span> <span class="o">:</span> <span class="n">index</span><span class="o">:</span><span class="nn">Py</span><span class="p">.</span><span class="nn">Object</span><span class="p">.</span><span class="n">t</span> <span class="o">-&gt;</span> <span class="o">[&gt;</span> <span class="n">tag</span><span class="o">]</span> <span class="nn">Obj</span><span class="p">.</span><span class="n">t</span> <span class="o">-&gt;</span> <span class="nn">Py</span><span class="p">.</span><span class="nn">Object</span><span class="p">.</span><span class="n">t</span>
</code></pre></div>

<p>Return the index'th estimator in the ensemble.</p>
<div class="highlight"><pre><span></span><code><span class="k">val</span> <span class="n">iter</span> <span class="o">:</span> <span class="o">[&gt;</span> <span class="n">tag</span><span class="o">]</span> <span class="nn">Obj</span><span class="p">.</span><span class="n">t</span> <span class="o">-&gt;</span> <span class="nn">Dict</span><span class="p">.</span><span class="n">t</span> <span class="nn">Seq</span><span class="p">.</span><span class="n">t</span>
</code></pre></div>

<p>Return iterator over estimators in the ensemble.</p>
<div class="highlight"><pre><span></span><code><span class="k">val</span> <span class="n">apply</span> <span class="o">:</span> <span class="n">x</span><span class="o">:</span><span class="nn">Py</span><span class="p">.</span><span class="nn">Object</span><span class="p">.</span><span class="n">t</span> <span class="o">-&gt;</span> <span class="o">[&gt;</span> <span class="n">tag</span><span class="o">]</span> <span class="nn">Obj</span><span class="p">.</span><span class="n">t</span> <span class="o">-&gt;</span> <span class="o">[&gt;`</span><span class="nc">ArrayLike</span><span class="o">]</span> <span class="nn">Np</span><span class="p">.</span><span class="nn">Obj</span><span class="p">.</span><span class="n">t</span>
</code></pre></div>

<p>Apply trees in the forest to X, return leaf indices.</p>
<h2 id="parameters_95">Parameters<a class="headerlink" href="#parameters_95" title="Permanent link">&para;</a></h2>
<p>X : {array-like or sparse matrix} of shape (n_samples, n_features)
The input samples. Internally, its dtype will be converted to
<code>dtype=np.float32</code>. If a sparse matrix is provided, it will be
converted into a sparse <code>csr_matrix</code>.</p>
<h2 id="returns_78">Returns<a class="headerlink" href="#returns_78" title="Permanent link">&para;</a></h2>
<p>X_leaves : array_like, shape = [n_samples, n_estimators]
For each datapoint x in X and for each tree in the forest,
return the index of the leaf x ends up in.</p>
<div class="highlight"><pre><span></span><code><span class="k">val</span> <span class="n">decision_path</span> <span class="o">:</span> <span class="n">x</span><span class="o">:</span><span class="nn">Py</span><span class="p">.</span><span class="nn">Object</span><span class="p">.</span><span class="n">t</span> <span class="o">-&gt;</span> <span class="o">[&gt;</span> <span class="n">tag</span><span class="o">]</span> <span class="nn">Obj</span><span class="p">.</span><span class="n">t</span> <span class="o">-&gt;</span> <span class="o">(</span><span class="nn">Py</span><span class="p">.</span><span class="nn">Object</span><span class="p">.</span><span class="n">t</span> <span class="o">*</span> <span class="nn">Py</span><span class="p">.</span><span class="nn">Object</span><span class="p">.</span><span class="n">t</span><span class="o">)</span>
</code></pre></div>

<p>Return the decision path in the forest.</p>
<p>.. versionadded:: 0.18</p>
<h2 id="parameters_96">Parameters<a class="headerlink" href="#parameters_96" title="Permanent link">&para;</a></h2>
<p>X : {array-like or sparse matrix} of shape (n_samples, n_features)
The input samples. Internally, its dtype will be converted to
<code>dtype=np.float32</code>. If a sparse matrix is provided, it will be
converted into a sparse <code>csr_matrix</code>.</p>
<h2 id="returns_79">Returns<a class="headerlink" href="#returns_79" title="Permanent link">&para;</a></h2>
<p>indicator : sparse csr array, shape = [n_samples, n_nodes]
Return a node indicator matrix where non zero elements
indicates that the samples goes through the nodes.</p>
<p>n_nodes_ptr : array of size (n_estimators + 1, )
The columns from indicator[n_nodes_ptr[i]:n_nodes_ptr[i+1]]
gives the indicator value for the i-th estimator.</p>
<div class="highlight"><pre><span></span><code><span class="k">val</span> <span class="n">fit</span> <span class="o">:</span> <span class="o">?</span><span class="n">sample_weight</span><span class="o">:[&gt;`</span><span class="nc">ArrayLike</span><span class="o">]</span> <span class="nn">Np</span><span class="p">.</span><span class="nn">Obj</span><span class="p">.</span><span class="n">t</span> <span class="o">-&gt;</span> <span class="n">x</span><span class="o">:[&gt;`</span><span class="nc">ArrayLike</span><span class="o">]</span> <span class="nn">Np</span><span class="p">.</span><span class="nn">Obj</span><span class="p">.</span><span class="n">t</span> <span class="o">-&gt;</span> <span class="n">y</span><span class="o">:[&gt;`</span><span class="nc">ArrayLike</span><span class="o">]</span> <span class="nn">Np</span><span class="p">.</span><span class="nn">Obj</span><span class="p">.</span><span class="n">t</span> <span class="o">-&gt;</span> <span class="o">[&gt;</span> <span class="n">tag</span><span class="o">]</span> <span class="nn">Obj</span><span class="p">.</span><span class="n">t</span> <span class="o">-&gt;</span> <span class="n">t</span>
</code></pre></div>

<p>Build a forest of trees from the training set (X, y).</p>
<h2 id="parameters_97">Parameters<a class="headerlink" href="#parameters_97" title="Permanent link">&para;</a></h2>
<p>X : array-like or sparse matrix of shape (n_samples, n_features)
The training input samples. Internally, its dtype will be converted
to <code>dtype=np.float32</code>. If a sparse matrix is provided, it will be
converted into a sparse <code>csc_matrix</code>.</p>
<p>y : array-like of shape (n_samples,) or (n_samples, n_outputs)
The target values (class labels in classification, real numbers in
regression).</p>
<p>sample_weight : array-like of shape (n_samples,), default=None
Sample weights. If None, then samples are equally weighted. Splits
that would create child nodes with net zero or negative weight are
ignored while searching for a split in each node. In the case of
classification, splits are also ignored if they would result in any
single class carrying a negative weight in either child node.</p>
<h2 id="returns_80">Returns<a class="headerlink" href="#returns_80" title="Permanent link">&para;</a></h2>
<p>self : object</p>
<div class="highlight"><pre><span></span><code><span class="k">val</span> <span class="n">get_params</span> <span class="o">:</span> <span class="o">?</span><span class="n">deep</span><span class="o">:</span><span class="kt">bool</span> <span class="o">-&gt;</span> <span class="o">[&gt;</span> <span class="n">tag</span><span class="o">]</span> <span class="nn">Obj</span><span class="p">.</span><span class="n">t</span> <span class="o">-&gt;</span> <span class="nn">Dict</span><span class="p">.</span><span class="n">t</span>
</code></pre></div>

<p>Get parameters for this estimator.</p>
<h2 id="parameters_98">Parameters<a class="headerlink" href="#parameters_98" title="Permanent link">&para;</a></h2>
<p>deep : bool, default=True
If True, will return the parameters for this estimator and
contained subobjects that are estimators.</p>
<h2 id="returns_81">Returns<a class="headerlink" href="#returns_81" title="Permanent link">&para;</a></h2>
<p>params : mapping of string to any
Parameter names mapped to their values.</p>
<div class="highlight"><pre><span></span><code><span class="k">val</span> <span class="n">predict</span> <span class="o">:</span> <span class="n">x</span><span class="o">:[&gt;`</span><span class="nc">ArrayLike</span><span class="o">]</span> <span class="nn">Np</span><span class="p">.</span><span class="nn">Obj</span><span class="p">.</span><span class="n">t</span> <span class="o">-&gt;</span> <span class="o">[&gt;</span> <span class="n">tag</span><span class="o">]</span> <span class="nn">Obj</span><span class="p">.</span><span class="n">t</span> <span class="o">-&gt;</span> <span class="o">[&gt;`</span><span class="nc">ArrayLike</span><span class="o">]</span> <span class="nn">Np</span><span class="p">.</span><span class="nn">Obj</span><span class="p">.</span><span class="n">t</span>
</code></pre></div>

<p>Predict regression target for X.</p>
<p>The predicted regression target of an input sample is computed as the
mean predicted regression targets of the trees in the forest.</p>
<h2 id="parameters_99">Parameters<a class="headerlink" href="#parameters_99" title="Permanent link">&para;</a></h2>
<p>X : array-like or sparse matrix of shape (n_samples, n_features)
The input samples. Internally, its dtype will be converted to
<code>dtype=np.float32</code>. If a sparse matrix is provided, it will be
converted into a sparse <code>csr_matrix</code>.</p>
<h2 id="returns_82">Returns<a class="headerlink" href="#returns_82" title="Permanent link">&para;</a></h2>
<p>y : array-like of shape (n_samples,) or (n_samples, n_outputs)
The predicted values.</p>
<div class="highlight"><pre><span></span><code><span class="k">val</span> <span class="n">score</span> <span class="o">:</span> <span class="o">?</span><span class="n">sample_weight</span><span class="o">:[&gt;`</span><span class="nc">ArrayLike</span><span class="o">]</span> <span class="nn">Np</span><span class="p">.</span><span class="nn">Obj</span><span class="p">.</span><span class="n">t</span> <span class="o">-&gt;</span> <span class="n">x</span><span class="o">:[&gt;`</span><span class="nc">ArrayLike</span><span class="o">]</span> <span class="nn">Np</span><span class="p">.</span><span class="nn">Obj</span><span class="p">.</span><span class="n">t</span> <span class="o">-&gt;</span> <span class="n">y</span><span class="o">:[&gt;`</span><span class="nc">ArrayLike</span><span class="o">]</span> <span class="nn">Np</span><span class="p">.</span><span class="nn">Obj</span><span class="p">.</span><span class="n">t</span> <span class="o">-&gt;</span> <span class="o">[&gt;</span> <span class="n">tag</span><span class="o">]</span> <span class="nn">Obj</span><span class="p">.</span><span class="n">t</span> <span class="o">-&gt;</span> <span class="kt">float</span>
</code></pre></div>

<p>Return the coefficient of determination R^2 of the prediction.</p>
<p>The coefficient R^2 is defined as (1 - u/v), where u is the residual
sum of squares ((y_true - y_pred) <strong> 2).sum() and v is the total
sum of squares ((y_true - y_true.mean()) </strong> 2).sum().
The best possible score is 1.0 and it can be negative (because the
model can be arbitrarily worse). A constant model that always
predicts the expected value of y, disregarding the input features,
would get a R^2 score of 0.0.</p>
<h2 id="parameters_100">Parameters<a class="headerlink" href="#parameters_100" title="Permanent link">&para;</a></h2>
<p>X : array-like of shape (n_samples, n_features)
Test samples. For some estimators this may be a
precomputed kernel matrix or a list of generic objects instead,
shape = (n_samples, n_samples_fitted),
where n_samples_fitted is the number of
samples used in the fitting for the estimator.</p>
<p>y : array-like of shape (n_samples,) or (n_samples, n_outputs)
True values for X.</p>
<p>sample_weight : array-like of shape (n_samples,), default=None
Sample weights.</p>
<h2 id="returns_83">Returns<a class="headerlink" href="#returns_83" title="Permanent link">&para;</a></h2>
<p>score : float
R^2 of self.predict(X) wrt. y.</p>
<h2 id="notes_11">Notes<a class="headerlink" href="#notes_11" title="Permanent link">&para;</a></h2>
<p>The R2 score used when calling <code>score</code> on a regressor will use
<code>multioutput='uniform_average'</code> from version 0.23 to keep consistent
with :func:<code>~sklearn.metrics.r2_score</code>. This will influence the
<code>score</code> method of all the multioutput regressors (except for
:class:<code>~sklearn.multioutput.MultiOutputRegressor</code>). To specify the
default value manually and avoid the warning, please either call
:func:<code>~sklearn.metrics.r2_score</code> directly or make a custom scorer with
:func:<code>~sklearn.metrics.make_scorer</code> (the built-in scorer <code>'r2'</code> uses
<code>multioutput='uniform_average'</code>).</p>
<div class="highlight"><pre><span></span><code><span class="k">val</span> <span class="n">set_params</span> <span class="o">:</span> <span class="o">?</span><span class="n">params</span><span class="o">:(</span><span class="kt">string</span> <span class="o">*</span> <span class="nn">Py</span><span class="p">.</span><span class="nn">Object</span><span class="p">.</span><span class="n">t</span><span class="o">)</span> <span class="kt">list</span> <span class="o">-&gt;</span> <span class="o">[&gt;</span> <span class="n">tag</span><span class="o">]</span> <span class="nn">Obj</span><span class="p">.</span><span class="n">t</span> <span class="o">-&gt;</span> <span class="n">t</span>
</code></pre></div>

<p>Set the parameters of this estimator.</p>
<p>The method works on simple estimators as well as on nested objects
(such as pipelines). The latter have parameters of the form
<code>&lt;component&gt;__&lt;parameter&gt;</code> so that it's possible to update each
component of a nested object.</p>
<h2 id="parameters_101">Parameters<a class="headerlink" href="#parameters_101" title="Permanent link">&para;</a></h2>
<p>**params : dict
Estimator parameters.</p>
<h2 id="returns_84">Returns<a class="headerlink" href="#returns_84" title="Permanent link">&para;</a></h2>
<p>self : object
Estimator instance.</p>
<p>Attribute base_estimator_: get value or raise Not_found if None.</p>
<div class="highlight"><pre><span></span><code><span class="k">val</span> <span class="n">base_estimator_</span> <span class="o">:</span> <span class="n">t</span> <span class="o">-&gt;</span> <span class="nn">Py</span><span class="p">.</span><span class="nn">Object</span><span class="p">.</span><span class="n">t</span>
</code></pre></div>

<p>Attribute base_estimator_: get value as an option.</p>
<div class="highlight"><pre><span></span><code><span class="k">val</span> <span class="n">base_estimator_opt</span> <span class="o">:</span> <span class="n">t</span> <span class="o">-&gt;</span> <span class="o">(</span><span class="nn">Py</span><span class="p">.</span><span class="nn">Object</span><span class="p">.</span><span class="n">t</span><span class="o">)</span> <span class="n">option</span>
</code></pre></div>

<p>Attribute estimators_: get value or raise Not_found if None.</p>
<div class="highlight"><pre><span></span><code><span class="k">val</span> <span class="n">estimators_</span> <span class="o">:</span> <span class="n">t</span> <span class="o">-&gt;</span> <span class="nn">Py</span><span class="p">.</span><span class="nn">Object</span><span class="p">.</span><span class="n">t</span>
</code></pre></div>

<p>Attribute estimators_: get value as an option.</p>
<div class="highlight"><pre><span></span><code><span class="k">val</span> <span class="n">estimators_opt</span> <span class="o">:</span> <span class="n">t</span> <span class="o">-&gt;</span> <span class="o">(</span><span class="nn">Py</span><span class="p">.</span><span class="nn">Object</span><span class="p">.</span><span class="n">t</span><span class="o">)</span> <span class="n">option</span>
</code></pre></div>

<p>Attribute feature_importances_: get value or raise Not_found if None.</p>
<div class="highlight"><pre><span></span><code><span class="k">val</span> <span class="n">feature_importances_</span> <span class="o">:</span> <span class="n">t</span> <span class="o">-&gt;</span> <span class="o">[&gt;`</span><span class="nc">ArrayLike</span><span class="o">]</span> <span class="nn">Np</span><span class="p">.</span><span class="nn">Obj</span><span class="p">.</span><span class="n">t</span>
</code></pre></div>

<p>Attribute feature_importances_: get value as an option.</p>
<div class="highlight"><pre><span></span><code><span class="k">val</span> <span class="n">feature_importances_opt</span> <span class="o">:</span> <span class="n">t</span> <span class="o">-&gt;</span> <span class="o">([&gt;`</span><span class="nc">ArrayLike</span><span class="o">]</span> <span class="nn">Np</span><span class="p">.</span><span class="nn">Obj</span><span class="p">.</span><span class="n">t</span><span class="o">)</span> <span class="n">option</span>
</code></pre></div>

<p>Attribute n_features_: get value or raise Not_found if None.</p>
<div class="highlight"><pre><span></span><code><span class="k">val</span> <span class="n">n_features_</span> <span class="o">:</span> <span class="n">t</span> <span class="o">-&gt;</span> <span class="kt">int</span>
</code></pre></div>

<p>Attribute n_features_: get value as an option.</p>
<div class="highlight"><pre><span></span><code><span class="k">val</span> <span class="n">n_features_opt</span> <span class="o">:</span> <span class="n">t</span> <span class="o">-&gt;</span> <span class="o">(</span><span class="kt">int</span><span class="o">)</span> <span class="n">option</span>
</code></pre></div>

<p>Attribute n_outputs_: get value or raise Not_found if None.</p>
<div class="highlight"><pre><span></span><code><span class="k">val</span> <span class="n">n_outputs_</span> <span class="o">:</span> <span class="n">t</span> <span class="o">-&gt;</span> <span class="kt">int</span>
</code></pre></div>

<p>Attribute n_outputs_: get value as an option.</p>
<div class="highlight"><pre><span></span><code><span class="k">val</span> <span class="n">n_outputs_opt</span> <span class="o">:</span> <span class="n">t</span> <span class="o">-&gt;</span> <span class="o">(</span><span class="kt">int</span><span class="o">)</span> <span class="n">option</span>
</code></pre></div>

<p>Attribute oob_score_: get value or raise Not_found if None.</p>
<div class="highlight"><pre><span></span><code><span class="k">val</span> <span class="n">oob_score_</span> <span class="o">:</span> <span class="n">t</span> <span class="o">-&gt;</span> <span class="kt">float</span>
</code></pre></div>

<p>Attribute oob_score_: get value as an option.</p>
<div class="highlight"><pre><span></span><code><span class="k">val</span> <span class="n">oob_score_opt</span> <span class="o">:</span> <span class="n">t</span> <span class="o">-&gt;</span> <span class="o">(</span><span class="kt">float</span><span class="o">)</span> <span class="n">option</span>
</code></pre></div>

<p>Attribute oob_prediction_: get value or raise Not_found if None.</p>
<div class="highlight"><pre><span></span><code><span class="k">val</span> <span class="n">oob_prediction_</span> <span class="o">:</span> <span class="n">t</span> <span class="o">-&gt;</span> <span class="o">[&gt;`</span><span class="nc">ArrayLike</span><span class="o">]</span> <span class="nn">Np</span><span class="p">.</span><span class="nn">Obj</span><span class="p">.</span><span class="n">t</span>
</code></pre></div>

<p>Attribute oob_prediction_: get value as an option.</p>
<div class="highlight"><pre><span></span><code><span class="k">val</span> <span class="n">oob_prediction_opt</span> <span class="o">:</span> <span class="n">t</span> <span class="o">-&gt;</span> <span class="o">([&gt;`</span><span class="nc">ArrayLike</span><span class="o">]</span> <span class="nn">Np</span><span class="p">.</span><span class="nn">Obj</span><span class="p">.</span><span class="n">t</span><span class="o">)</span> <span class="n">option</span>
</code></pre></div>

<p>Print the object to a human-readable representation.</p>
<div class="highlight"><pre><span></span><code><span class="k">val</span> <span class="n">to_string</span> <span class="o">:</span> <span class="n">t</span> <span class="o">-&gt;</span> <span class="kt">string</span>
</code></pre></div>

<p>Print the object to a human-readable representation.</p>
<div class="highlight"><pre><span></span><code><span class="k">val</span> <span class="n">show</span> <span class="o">:</span> <span class="n">t</span> <span class="o">-&gt;</span> <span class="kt">string</span>
</code></pre></div>

<p>Pretty-print the object to a formatter.</p>
<div class="highlight"><pre><span></span><code><span class="k">val</span> <span class="n">pp</span> <span class="o">:</span> <span class="nn">Format</span><span class="p">.</span><span class="n">formatter</span> <span class="o">-&gt;</span> <span class="n">t</span> <span class="o">-&gt;</span> <span class="kt">unit</span> <span class="o">[@@</span><span class="n">ocaml</span><span class="o">.</span><span class="n">toplevel_printer</span><span class="o">]</span>



<span class="k">module</span> <span class="nc">RandomTreesEmbedding</span> <span class="o">:</span> <span class="k">sig</span>
<span class="k">type</span> <span class="n">tag</span> <span class="o">=</span> <span class="o">[`</span><span class="nc">RandomTreesEmbedding</span><span class="o">]</span>
<span class="k">type</span> <span class="n">t</span> <span class="o">=</span> <span class="o">[`</span><span class="nc">BaseEnsemble</span> <span class="o">|</span> <span class="o">`</span><span class="nc">BaseEstimator</span> <span class="o">|</span> <span class="o">`</span><span class="nc">BaseForest</span> <span class="o">|</span> <span class="o">`</span><span class="nc">MetaEstimatorMixin</span> <span class="o">|</span> <span class="o">`</span><span class="nc">MultiOutputMixin</span> <span class="o">|</span> <span class="o">`</span><span class="nc">Object</span> <span class="o">|</span> <span class="o">`</span><span class="nc">RandomTreesEmbedding</span><span class="o">]</span> <span class="nn">Obj</span><span class="p">.</span><span class="n">t</span>
<span class="k">val</span> <span class="n">of_pyobject</span> <span class="o">:</span> <span class="nn">Py</span><span class="p">.</span><span class="nn">Object</span><span class="p">.</span><span class="n">t</span> <span class="o">-&gt;</span> <span class="n">t</span>
<span class="k">val</span> <span class="n">to_pyobject</span> <span class="o">:</span> <span class="o">[&gt;</span> <span class="n">tag</span><span class="o">]</span> <span class="nn">Obj</span><span class="p">.</span><span class="n">t</span> <span class="o">-&gt;</span> <span class="nn">Py</span><span class="p">.</span><span class="nn">Object</span><span class="p">.</span><span class="n">t</span>

<span class="k">val</span> <span class="n">as_multi_output</span> <span class="o">:</span> <span class="n">t</span> <span class="o">-&gt;</span> <span class="o">[`</span><span class="nc">MultiOutputMixin</span><span class="o">]</span> <span class="nn">Obj</span><span class="p">.</span><span class="n">t</span>
<span class="k">val</span> <span class="n">as_meta_estimator</span> <span class="o">:</span> <span class="n">t</span> <span class="o">-&gt;</span> <span class="o">[`</span><span class="nc">MetaEstimatorMixin</span><span class="o">]</span> <span class="nn">Obj</span><span class="p">.</span><span class="n">t</span>
<span class="k">val</span> <span class="n">as_estimator</span> <span class="o">:</span> <span class="n">t</span> <span class="o">-&gt;</span> <span class="o">[`</span><span class="nc">BaseEstimator</span><span class="o">]</span> <span class="nn">Obj</span><span class="p">.</span><span class="n">t</span>
<span class="k">val</span> <span class="n">as_ensemble</span> <span class="o">:</span> <span class="n">t</span> <span class="o">-&gt;</span> <span class="o">[`</span><span class="nc">BaseEnsemble</span><span class="o">]</span> <span class="nn">Obj</span><span class="p">.</span><span class="n">t</span>
<span class="k">val</span> <span class="n">as_forest</span> <span class="o">:</span> <span class="n">t</span> <span class="o">-&gt;</span> <span class="o">[`</span><span class="nc">BaseForest</span><span class="o">]</span> <span class="nn">Obj</span><span class="p">.</span><span class="n">t</span>
<span class="k">val</span> <span class="n">create</span> <span class="o">:</span> <span class="o">?</span><span class="n">n_estimators</span><span class="o">:</span><span class="kt">int</span> <span class="o">-&gt;</span> <span class="o">?</span><span class="n">max_depth</span><span class="o">:</span><span class="kt">int</span> <span class="o">-&gt;</span> <span class="o">?</span><span class="n">min_samples_split</span><span class="o">:[`</span><span class="nc">F</span> <span class="k">of</span> <span class="kt">float</span> <span class="o">|</span> <span class="o">`</span><span class="nc">I</span> <span class="k">of</span> <span class="kt">int</span><span class="o">]</span> <span class="o">-&gt;</span> <span class="o">?</span><span class="n">min_samples_leaf</span><span class="o">:[`</span><span class="nc">F</span> <span class="k">of</span> <span class="kt">float</span> <span class="o">|</span> <span class="o">`</span><span class="nc">I</span> <span class="k">of</span> <span class="kt">int</span><span class="o">]</span> <span class="o">-&gt;</span> <span class="o">?</span><span class="n">min_weight_fraction_leaf</span><span class="o">:</span><span class="kt">float</span> <span class="o">-&gt;</span> <span class="o">?</span><span class="n">max_leaf_nodes</span><span class="o">:</span><span class="kt">int</span> <span class="o">-&gt;</span> <span class="o">?</span><span class="n">min_impurity_decrease</span><span class="o">:</span><span class="kt">float</span> <span class="o">-&gt;</span> <span class="o">?</span><span class="n">min_impurity_split</span><span class="o">:</span><span class="kt">float</span> <span class="o">-&gt;</span> <span class="o">?</span><span class="n">sparse_output</span><span class="o">:</span><span class="kt">bool</span> <span class="o">-&gt;</span> <span class="o">?</span><span class="n">n_jobs</span><span class="o">:</span><span class="kt">int</span> <span class="o">-&gt;</span> <span class="o">?</span><span class="n">random_state</span><span class="o">:</span><span class="kt">int</span> <span class="o">-&gt;</span> <span class="o">?</span><span class="n">verbose</span><span class="o">:</span><span class="kt">int</span> <span class="o">-&gt;</span> <span class="o">?</span><span class="n">warm_start</span><span class="o">:</span><span class="kt">bool</span> <span class="o">-&gt;</span> <span class="kt">unit</span> <span class="o">-&gt;</span> <span class="n">t</span>
</code></pre></div>

<p>An ensemble of totally random trees.</p>
<p>An unsupervised transformation of a dataset to a high-dimensional
sparse representation. A datapoint is coded according to which leaf of
each tree it is sorted into. Using a one-hot encoding of the leaves,
this leads to a binary coding with as many ones as there are trees in
the forest.</p>
<p>The dimensionality of the resulting representation is
<code>n_out &lt;= n_estimators * max_leaf_nodes</code>. If <code>max_leaf_nodes == None</code>,
the number of leaf nodes is at most <code>n_estimators * 2 ** max_depth</code>.</p>
<p>Read more in the :ref:<code>User Guide &lt;random_trees_embedding&gt;</code>.</p>
<h2 id="parameters_102">Parameters<a class="headerlink" href="#parameters_102" title="Permanent link">&para;</a></h2>
<p>n_estimators : integer, optional (default=10)
Number of trees in the forest.</p>
<p>.. versionchanged:: 0.22
The default value of <code>n_estimators</code> changed from 10 to 100
in 0.22.</p>
<p>max_depth : integer, optional (default=5)
The maximum depth of each tree. If None, then nodes are expanded until
all leaves are pure or until all leaves contain less than
min_samples_split samples.</p>
<p>min_samples_split : int, float, optional (default=2)
The minimum number of samples required to split an internal node:</p>
<ul>
<li>If int, then consider <code>min_samples_split</code> as the minimum number.</li>
<li>If float, then <code>min_samples_split</code> is a fraction and
<code>ceil(min_samples_split * n_samples)</code> is the minimum
number of samples for each split.</li>
</ul>
<p>.. versionchanged:: 0.18
Added float values for fractions.</p>
<p>min_samples_leaf : int, float, optional (default=1)
The minimum number of samples required to be at a leaf node.
A split point at any depth will only be considered if it leaves at
least <code>min_samples_leaf</code> training samples in each of the left and
right branches.  This may have the effect of smoothing the model,
especially in regression.</p>
<ul>
<li>If int, then consider <code>min_samples_leaf</code> as the minimum number.</li>
<li>If float, then <code>min_samples_leaf</code> is a fraction and
<code>ceil(min_samples_leaf * n_samples)</code> is the minimum
number of samples for each node.</li>
</ul>
<p>.. versionchanged:: 0.18
Added float values for fractions.</p>
<p>min_weight_fraction_leaf : float, optional (default=0.)
The minimum weighted fraction of the sum total of weights (of all
the input samples) required to be at a leaf node. Samples have
equal weight when sample_weight is not provided.</p>
<p>max_leaf_nodes : int or None, optional (default=None)
Grow trees with <code>max_leaf_nodes</code> in best-first fashion.
Best nodes are defined as relative reduction in impurity.
If None then unlimited number of leaf nodes.</p>
<p>min_impurity_decrease : float, optional (default=0.)
A node will be split if this split induces a decrease of the impurity
greater than or equal to this value.</p>
<p>The weighted impurity decrease equation is the following::</p>
<p>N_t / N * (impurity - N_t_R / N_t * right_impurity
- N_t_L / N_t * left_impurity)</p>
<p>where <code>N</code> is the total number of samples, <code>N_t</code> is the number of
samples at the current node, <code>N_t_L</code> is the number of samples in the
left child, and <code>N_t_R</code> is the number of samples in the right child.</p>
<p><code>N</code>, <code>N_t</code>, <code>N_t_R</code> and <code>N_t_L</code> all refer to the weighted sum,
if <code>sample_weight</code> is passed.</p>
<p>.. versionadded:: 0.19</p>
<p>min_impurity_split : float, (default=1e-7)
Threshold for early stopping in tree growth. A node will split
if its impurity is above the threshold, otherwise it is a leaf.</p>
<p>.. deprecated:: 0.19
<code>min_impurity_split</code> has been deprecated in favor of
<code>min_impurity_decrease</code> in 0.19. The default value of
<code>min_impurity_split</code> will change from 1e-7 to 0 in 0.23 and it
will be removed in 0.25. Use <code>min_impurity_decrease</code> instead.</p>
<p>sparse_output : bool, optional (default=True)
Whether or not to return a sparse CSR matrix, as default behavior,
or to return a dense array compatible with dense pipeline operators.</p>
<p>n_jobs : int or None, optional (default=None)
The number of jobs to run in parallel. :meth:<code>fit</code>, :meth:<code>transform</code>,
:meth:<code>decision_path</code> and :meth:<code>apply</code> are all parallelized over the
trees. <code>None</code> means 1 unless in a :obj:<code>joblib.parallel_backend</code>
context. <code>-1</code> means using all processors. See :term:<code>Glossary
&lt;n_jobs&gt;</code> for more details.</p>
<p>random_state : int, RandomState instance or None, optional (default=None)
Controls the generation of the random <code>y</code> used to fit the trees
and the draw of the splits for each feature at the trees' nodes.
See :term:<code>Glossary &lt;random_state&gt;</code> for details.</p>
<p>verbose : int, optional (default=0)
Controls the verbosity when fitting and predicting.</p>
<p>warm_start : bool, optional (default=False)
When set to <code>True</code>, reuse the solution of the previous call to fit
and add more estimators to the ensemble, otherwise, just fit a whole
new forest. See :term:<code>the Glossary &lt;warm_start&gt;</code>.</p>
<h2 id="attributes_11">Attributes<a class="headerlink" href="#attributes_11" title="Permanent link">&para;</a></h2>
<p>estimators_ : list of DecisionTreeClassifier
The collection of fitted sub-estimators.</p>
<h2 id="references_11">References<a class="headerlink" href="#references_11" title="Permanent link">&para;</a></h2>
<p>.. [1] P. Geurts, D. Ernst., and L. Wehenkel, 'Extremely randomized trees',
Machine Learning, 63(1), 3-42, 2006.
.. [2] Moosmann, F. and Triggs, B. and Jurie, F.  'Fast discriminative
visual codebooks using randomized clustering forests'
NIPS 2007</p>
<div class="highlight"><pre><span></span><code><span class="k">val</span> <span class="n">get_item</span> <span class="o">:</span> <span class="n">index</span><span class="o">:</span><span class="nn">Py</span><span class="p">.</span><span class="nn">Object</span><span class="p">.</span><span class="n">t</span> <span class="o">-&gt;</span> <span class="o">[&gt;</span> <span class="n">tag</span><span class="o">]</span> <span class="nn">Obj</span><span class="p">.</span><span class="n">t</span> <span class="o">-&gt;</span> <span class="nn">Py</span><span class="p">.</span><span class="nn">Object</span><span class="p">.</span><span class="n">t</span>
</code></pre></div>

<p>Return the index'th estimator in the ensemble.</p>
<div class="highlight"><pre><span></span><code><span class="k">val</span> <span class="n">iter</span> <span class="o">:</span> <span class="o">[&gt;</span> <span class="n">tag</span><span class="o">]</span> <span class="nn">Obj</span><span class="p">.</span><span class="n">t</span> <span class="o">-&gt;</span> <span class="nn">Dict</span><span class="p">.</span><span class="n">t</span> <span class="nn">Seq</span><span class="p">.</span><span class="n">t</span>
</code></pre></div>

<p>Return iterator over estimators in the ensemble.</p>
<div class="highlight"><pre><span></span><code><span class="k">val</span> <span class="n">apply</span> <span class="o">:</span> <span class="n">x</span><span class="o">:</span><span class="nn">Py</span><span class="p">.</span><span class="nn">Object</span><span class="p">.</span><span class="n">t</span> <span class="o">-&gt;</span> <span class="o">[&gt;</span> <span class="n">tag</span><span class="o">]</span> <span class="nn">Obj</span><span class="p">.</span><span class="n">t</span> <span class="o">-&gt;</span> <span class="o">[&gt;`</span><span class="nc">ArrayLike</span><span class="o">]</span> <span class="nn">Np</span><span class="p">.</span><span class="nn">Obj</span><span class="p">.</span><span class="n">t</span>
</code></pre></div>

<p>Apply trees in the forest to X, return leaf indices.</p>
<h2 id="parameters_103">Parameters<a class="headerlink" href="#parameters_103" title="Permanent link">&para;</a></h2>
<p>X : {array-like or sparse matrix} of shape (n_samples, n_features)
The input samples. Internally, its dtype will be converted to
<code>dtype=np.float32</code>. If a sparse matrix is provided, it will be
converted into a sparse <code>csr_matrix</code>.</p>
<h2 id="returns_85">Returns<a class="headerlink" href="#returns_85" title="Permanent link">&para;</a></h2>
<p>X_leaves : array_like, shape = [n_samples, n_estimators]
For each datapoint x in X and for each tree in the forest,
return the index of the leaf x ends up in.</p>
<div class="highlight"><pre><span></span><code><span class="k">val</span> <span class="n">decision_path</span> <span class="o">:</span> <span class="n">x</span><span class="o">:</span><span class="nn">Py</span><span class="p">.</span><span class="nn">Object</span><span class="p">.</span><span class="n">t</span> <span class="o">-&gt;</span> <span class="o">[&gt;</span> <span class="n">tag</span><span class="o">]</span> <span class="nn">Obj</span><span class="p">.</span><span class="n">t</span> <span class="o">-&gt;</span> <span class="o">(</span><span class="nn">Py</span><span class="p">.</span><span class="nn">Object</span><span class="p">.</span><span class="n">t</span> <span class="o">*</span> <span class="nn">Py</span><span class="p">.</span><span class="nn">Object</span><span class="p">.</span><span class="n">t</span><span class="o">)</span>
</code></pre></div>

<p>Return the decision path in the forest.</p>
<p>.. versionadded:: 0.18</p>
<h2 id="parameters_104">Parameters<a class="headerlink" href="#parameters_104" title="Permanent link">&para;</a></h2>
<p>X : {array-like or sparse matrix} of shape (n_samples, n_features)
The input samples. Internally, its dtype will be converted to
<code>dtype=np.float32</code>. If a sparse matrix is provided, it will be
converted into a sparse <code>csr_matrix</code>.</p>
<h2 id="returns_86">Returns<a class="headerlink" href="#returns_86" title="Permanent link">&para;</a></h2>
<p>indicator : sparse csr array, shape = [n_samples, n_nodes]
Return a node indicator matrix where non zero elements
indicates that the samples goes through the nodes.</p>
<p>n_nodes_ptr : array of size (n_estimators + 1, )
The columns from indicator[n_nodes_ptr[i]:n_nodes_ptr[i+1]]
gives the indicator value for the i-th estimator.</p>
<div class="highlight"><pre><span></span><code><span class="k">val</span> <span class="n">fit</span> <span class="o">:</span> <span class="o">?</span><span class="n">y</span><span class="o">:</span><span class="nn">Py</span><span class="p">.</span><span class="nn">Object</span><span class="p">.</span><span class="n">t</span> <span class="o">-&gt;</span> <span class="o">?</span><span class="n">sample_weight</span><span class="o">:[&gt;`</span><span class="nc">ArrayLike</span><span class="o">]</span> <span class="nn">Np</span><span class="p">.</span><span class="nn">Obj</span><span class="p">.</span><span class="n">t</span> <span class="o">-&gt;</span> <span class="n">x</span><span class="o">:[&gt;`</span><span class="nc">ArrayLike</span><span class="o">]</span> <span class="nn">Np</span><span class="p">.</span><span class="nn">Obj</span><span class="p">.</span><span class="n">t</span> <span class="o">-&gt;</span> <span class="o">[&gt;</span> <span class="n">tag</span><span class="o">]</span> <span class="nn">Obj</span><span class="p">.</span><span class="n">t</span> <span class="o">-&gt;</span> <span class="n">t</span>
</code></pre></div>

<p>Fit estimator.</p>
<h2 id="parameters_105">Parameters<a class="headerlink" href="#parameters_105" title="Permanent link">&para;</a></h2>
<p>X : array-like or sparse matrix, shape=(n_samples, n_features)
The input samples. Use <code>dtype=np.float32</code> for maximum
efficiency. Sparse matrices are also supported, use sparse
<code>csc_matrix</code> for maximum efficiency.</p>
<p>sample_weight : array-like of shape (n_samples,), default=None
Sample weights. If None, then samples are equally weighted. Splits
that would create child nodes with net zero or negative weight are
ignored while searching for a split in each node. In the case of
classification, splits are also ignored if they would result in any
single class carrying a negative weight in either child node.</p>
<h2 id="returns_87">Returns<a class="headerlink" href="#returns_87" title="Permanent link">&para;</a></h2>
<p>self : object</p>
<div class="highlight"><pre><span></span><code><span class="k">val</span> <span class="n">fit_transform</span> <span class="o">:</span> <span class="o">?</span><span class="n">y</span><span class="o">:</span><span class="nn">Py</span><span class="p">.</span><span class="nn">Object</span><span class="p">.</span><span class="n">t</span> <span class="o">-&gt;</span> <span class="o">?</span><span class="n">sample_weight</span><span class="o">:[&gt;`</span><span class="nc">ArrayLike</span><span class="o">]</span> <span class="nn">Np</span><span class="p">.</span><span class="nn">Obj</span><span class="p">.</span><span class="n">t</span> <span class="o">-&gt;</span> <span class="n">x</span><span class="o">:[&gt;`</span><span class="nc">ArrayLike</span><span class="o">]</span> <span class="nn">Np</span><span class="p">.</span><span class="nn">Obj</span><span class="p">.</span><span class="n">t</span> <span class="o">-&gt;</span> <span class="o">[&gt;</span> <span class="n">tag</span><span class="o">]</span> <span class="nn">Obj</span><span class="p">.</span><span class="n">t</span> <span class="o">-&gt;</span> <span class="o">[&gt;`</span><span class="nc">ArrayLike</span><span class="o">]</span> <span class="nn">Np</span><span class="p">.</span><span class="nn">Obj</span><span class="p">.</span><span class="n">t</span>
</code></pre></div>

<p>Fit estimator and transform dataset.</p>
<h2 id="parameters_106">Parameters<a class="headerlink" href="#parameters_106" title="Permanent link">&para;</a></h2>
<p>X : array-like or sparse matrix, shape=(n_samples, n_features)
Input data used to build forests. Use <code>dtype=np.float32</code> for
maximum efficiency.</p>
<p>sample_weight : array-like of shape (n_samples,), default=None
Sample weights. If None, then samples are equally weighted. Splits
that would create child nodes with net zero or negative weight are
ignored while searching for a split in each node. In the case of
classification, splits are also ignored if they would result in any
single class carrying a negative weight in either child node.</p>
<h2 id="returns_88">Returns<a class="headerlink" href="#returns_88" title="Permanent link">&para;</a></h2>
<p>X_transformed : sparse matrix, shape=(n_samples, n_out)
Transformed dataset.</p>
<div class="highlight"><pre><span></span><code><span class="k">val</span> <span class="n">get_params</span> <span class="o">:</span> <span class="o">?</span><span class="n">deep</span><span class="o">:</span><span class="kt">bool</span> <span class="o">-&gt;</span> <span class="o">[&gt;</span> <span class="n">tag</span><span class="o">]</span> <span class="nn">Obj</span><span class="p">.</span><span class="n">t</span> <span class="o">-&gt;</span> <span class="nn">Dict</span><span class="p">.</span><span class="n">t</span>
</code></pre></div>

<p>Get parameters for this estimator.</p>
<h2 id="parameters_107">Parameters<a class="headerlink" href="#parameters_107" title="Permanent link">&para;</a></h2>
<p>deep : bool, default=True
If True, will return the parameters for this estimator and
contained subobjects that are estimators.</p>
<h2 id="returns_89">Returns<a class="headerlink" href="#returns_89" title="Permanent link">&para;</a></h2>
<p>params : mapping of string to any
Parameter names mapped to their values.</p>
<div class="highlight"><pre><span></span><code><span class="k">val</span> <span class="n">set_params</span> <span class="o">:</span> <span class="o">?</span><span class="n">params</span><span class="o">:(</span><span class="kt">string</span> <span class="o">*</span> <span class="nn">Py</span><span class="p">.</span><span class="nn">Object</span><span class="p">.</span><span class="n">t</span><span class="o">)</span> <span class="kt">list</span> <span class="o">-&gt;</span> <span class="o">[&gt;</span> <span class="n">tag</span><span class="o">]</span> <span class="nn">Obj</span><span class="p">.</span><span class="n">t</span> <span class="o">-&gt;</span> <span class="n">t</span>
</code></pre></div>

<p>Set the parameters of this estimator.</p>
<p>The method works on simple estimators as well as on nested objects
(such as pipelines). The latter have parameters of the form
<code>&lt;component&gt;__&lt;parameter&gt;</code> so that it's possible to update each
component of a nested object.</p>
<h2 id="parameters_108">Parameters<a class="headerlink" href="#parameters_108" title="Permanent link">&para;</a></h2>
<p>**params : dict
Estimator parameters.</p>
<h2 id="returns_90">Returns<a class="headerlink" href="#returns_90" title="Permanent link">&para;</a></h2>
<p>self : object
Estimator instance.</p>
<div class="highlight"><pre><span></span><code><span class="k">val</span> <span class="n">transform</span> <span class="o">:</span> <span class="n">x</span><span class="o">:[&gt;`</span><span class="nc">ArrayLike</span><span class="o">]</span> <span class="nn">Np</span><span class="p">.</span><span class="nn">Obj</span><span class="p">.</span><span class="n">t</span> <span class="o">-&gt;</span> <span class="o">[&gt;</span> <span class="n">tag</span><span class="o">]</span> <span class="nn">Obj</span><span class="p">.</span><span class="n">t</span> <span class="o">-&gt;</span> <span class="o">[&gt;`</span><span class="nc">ArrayLike</span><span class="o">]</span> <span class="nn">Np</span><span class="p">.</span><span class="nn">Obj</span><span class="p">.</span><span class="n">t</span>
</code></pre></div>

<p>Transform dataset.</p>
<h2 id="parameters_109">Parameters<a class="headerlink" href="#parameters_109" title="Permanent link">&para;</a></h2>
<p>X : array-like or sparse matrix, shape=(n_samples, n_features)
Input data to be transformed. Use <code>dtype=np.float32</code> for maximum
efficiency. Sparse matrices are also supported, use sparse
<code>csr_matrix</code> for maximum efficiency.</p>
<h2 id="returns_91">Returns<a class="headerlink" href="#returns_91" title="Permanent link">&para;</a></h2>
<p>X_transformed : sparse matrix, shape=(n_samples, n_out)
Transformed dataset.</p>
<p>Attribute estimators_: get value or raise Not_found if None.</p>
<div class="highlight"><pre><span></span><code><span class="k">val</span> <span class="n">estimators_</span> <span class="o">:</span> <span class="n">t</span> <span class="o">-&gt;</span> <span class="nn">Py</span><span class="p">.</span><span class="nn">Object</span><span class="p">.</span><span class="n">t</span>
</code></pre></div>

<p>Attribute estimators_: get value as an option.</p>
<div class="highlight"><pre><span></span><code><span class="k">val</span> <span class="n">estimators_opt</span> <span class="o">:</span> <span class="n">t</span> <span class="o">-&gt;</span> <span class="o">(</span><span class="nn">Py</span><span class="p">.</span><span class="nn">Object</span><span class="p">.</span><span class="n">t</span><span class="o">)</span> <span class="n">option</span>
</code></pre></div>

<p>Print the object to a human-readable representation.</p>
<div class="highlight"><pre><span></span><code><span class="k">val</span> <span class="n">to_string</span> <span class="o">:</span> <span class="n">t</span> <span class="o">-&gt;</span> <span class="kt">string</span>
</code></pre></div>

<p>Print the object to a human-readable representation.</p>
<div class="highlight"><pre><span></span><code><span class="k">val</span> <span class="n">show</span> <span class="o">:</span> <span class="n">t</span> <span class="o">-&gt;</span> <span class="kt">string</span>
</code></pre></div>

<p>Pretty-print the object to a formatter.</p>
<div class="highlight"><pre><span></span><code><span class="k">val</span> <span class="n">pp</span> <span class="o">:</span> <span class="nn">Format</span><span class="p">.</span><span class="n">formatter</span> <span class="o">-&gt;</span> <span class="n">t</span> <span class="o">-&gt;</span> <span class="kt">unit</span> <span class="o">[@@</span><span class="n">ocaml</span><span class="o">.</span><span class="n">toplevel_printer</span><span class="o">]</span>



<span class="k">module</span> <span class="nc">StackingClassifier</span> <span class="o">:</span> <span class="k">sig</span>
<span class="k">type</span> <span class="n">tag</span> <span class="o">=</span> <span class="o">[`</span><span class="nc">StackingClassifier</span><span class="o">]</span>
<span class="k">type</span> <span class="n">t</span> <span class="o">=</span> <span class="o">[`</span><span class="nc">BaseEstimator</span> <span class="o">|</span> <span class="o">`</span><span class="nc">ClassifierMixin</span> <span class="o">|</span> <span class="o">`</span><span class="nc">MetaEstimatorMixin</span> <span class="o">|</span> <span class="o">`</span><span class="nc">Object</span> <span class="o">|</span> <span class="o">`</span><span class="nc">StackingClassifier</span> <span class="o">|</span> <span class="o">`</span><span class="nc">TransformerMixin</span><span class="o">]</span> <span class="nn">Obj</span><span class="p">.</span><span class="n">t</span>
<span class="k">val</span> <span class="n">of_pyobject</span> <span class="o">:</span> <span class="nn">Py</span><span class="p">.</span><span class="nn">Object</span><span class="p">.</span><span class="n">t</span> <span class="o">-&gt;</span> <span class="n">t</span>
<span class="k">val</span> <span class="n">to_pyobject</span> <span class="o">:</span> <span class="o">[&gt;</span> <span class="n">tag</span><span class="o">]</span> <span class="nn">Obj</span><span class="p">.</span><span class="n">t</span> <span class="o">-&gt;</span> <span class="nn">Py</span><span class="p">.</span><span class="nn">Object</span><span class="p">.</span><span class="n">t</span>

<span class="k">val</span> <span class="n">as_classifier</span> <span class="o">:</span> <span class="n">t</span> <span class="o">-&gt;</span> <span class="o">[`</span><span class="nc">ClassifierMixin</span><span class="o">]</span> <span class="nn">Obj</span><span class="p">.</span><span class="n">t</span>
<span class="k">val</span> <span class="n">as_transformer</span> <span class="o">:</span> <span class="n">t</span> <span class="o">-&gt;</span> <span class="o">[`</span><span class="nc">TransformerMixin</span><span class="o">]</span> <span class="nn">Obj</span><span class="p">.</span><span class="n">t</span>
<span class="k">val</span> <span class="n">as_estimator</span> <span class="o">:</span> <span class="n">t</span> <span class="o">-&gt;</span> <span class="o">[`</span><span class="nc">BaseEstimator</span><span class="o">]</span> <span class="nn">Obj</span><span class="p">.</span><span class="n">t</span>
<span class="k">val</span> <span class="n">as_meta_estimator</span> <span class="o">:</span> <span class="n">t</span> <span class="o">-&gt;</span> <span class="o">[`</span><span class="nc">MetaEstimatorMixin</span><span class="o">]</span> <span class="nn">Obj</span><span class="p">.</span><span class="n">t</span>
<span class="k">val</span> <span class="n">create</span> <span class="o">:</span> <span class="o">?</span><span class="n">final_estimator</span><span class="o">:[&gt;`</span><span class="nc">BaseEstimator</span><span class="o">]</span> <span class="nn">Np</span><span class="p">.</span><span class="nn">Obj</span><span class="p">.</span><span class="n">t</span> <span class="o">-&gt;</span> <span class="o">?</span><span class="n">cv</span><span class="o">:[`</span><span class="nc">Arr</span> <span class="k">of</span> <span class="o">[&gt;`</span><span class="nc">ArrayLike</span><span class="o">]</span> <span class="nn">Np</span><span class="p">.</span><span class="nn">Obj</span><span class="p">.</span><span class="n">t</span> <span class="o">|</span> <span class="o">`</span><span class="nc">BaseCrossValidator</span> <span class="k">of</span> <span class="o">[&gt;`</span><span class="nc">BaseCrossValidator</span><span class="o">]</span> <span class="nn">Np</span><span class="p">.</span><span class="nn">Obj</span><span class="p">.</span><span class="n">t</span> <span class="o">|</span> <span class="o">`</span><span class="nc">I</span> <span class="k">of</span> <span class="kt">int</span><span class="o">]</span> <span class="o">-&gt;</span> <span class="o">?</span><span class="n">stack_method</span><span class="o">:[`</span><span class="nc">Auto</span> <span class="o">|</span> <span class="o">`</span><span class="nc">Predict_proba</span> <span class="o">|</span> <span class="o">`</span><span class="nc">Decision_function</span> <span class="o">|</span> <span class="o">`</span><span class="nc">Predict</span><span class="o">]</span> <span class="o">-&gt;</span> <span class="o">?</span><span class="n">n_jobs</span><span class="o">:</span><span class="kt">int</span> <span class="o">-&gt;</span> <span class="o">?</span><span class="n">passthrough</span><span class="o">:</span><span class="kt">bool</span> <span class="o">-&gt;</span> <span class="o">?</span><span class="n">verbose</span><span class="o">:</span><span class="kt">int</span> <span class="o">-&gt;</span> <span class="n">estimators</span><span class="o">:(</span><span class="kt">string</span> <span class="o">*</span> <span class="o">[&gt;`</span><span class="nc">BaseEstimator</span><span class="o">]</span> <span class="nn">Np</span><span class="p">.</span><span class="nn">Obj</span><span class="p">.</span><span class="n">t</span><span class="o">)</span> <span class="kt">list</span> <span class="o">-&gt;</span> <span class="kt">unit</span> <span class="o">-&gt;</span> <span class="n">t</span>
</code></pre></div>

<p>Stack of estimators with a final classifier.</p>
<p>Stacked generalization consists in stacking the output of individual
estimator and use a classifier to compute the final prediction. Stacking
allows to use the strength of each individual estimator by using their
output as input of a final estimator.</p>
<p>Note that <code>estimators_</code> are fitted on the full <code>X</code> while <code>final_estimator_</code>
is trained using cross-validated predictions of the base estimators using
<code>cross_val_predict</code>.</p>
<p>.. versionadded:: 0.22</p>
<p>Read more in the :ref:<code>User Guide &lt;stacking&gt;</code>.</p>
<h2 id="parameters_110">Parameters<a class="headerlink" href="#parameters_110" title="Permanent link">&para;</a></h2>
<p>estimators : list of (str, estimator)
Base estimators which will be stacked together. Each element of the
list is defined as a tuple of string (i.e. name) and an estimator
instance. An estimator can be set to 'drop' using <code>set_params</code>.</p>
<p>final_estimator : estimator, default=None
A classifier which will be used to combine the base estimators.
The default classifier is a <code>LogisticRegression</code>.</p>
<p>cv : int, cross-validation generator or an iterable, default=None
Determines the cross-validation splitting strategy used in
<code>cross_val_predict</code> to train <code>final_estimator</code>. Possible inputs for
cv are:</p>
<ul>
<li>None, to use the default 5-fold cross validation,</li>
<li>integer, to specify the number of folds in a (Stratified) KFold,</li>
<li>An object to be used as a cross-validation generator,</li>
<li>An iterable yielding train, test splits.</li>
</ul>
<p>For integer/None inputs, if the estimator is a classifier and y is
either binary or multiclass, <code>StratifiedKFold</code> is used. In all other
cases, <code>KFold</code> is used.</p>
<p>Refer :ref:<code>User Guide &lt;cross_validation&gt;</code> for the various
cross-validation strategies that can be used here.</p>
<p>.. note::
A larger number of split will provide no benefits if the number
of training samples is large enough. Indeed, the training time
will increase. <code>cv</code> is not used for model evaluation but for
prediction.</p>
<p>stack_method : {'auto', 'predict_proba', 'decision_function', 'predict'},             default='auto'
Methods called for each base estimator. It can be:</p>
<ul>
<li>if 'auto', it will try to invoke, for each estimator,
<code>'predict_proba'</code>, <code>'decision_function'</code> or <code>'predict'</code> in that
order.</li>
<li>otherwise, one of <code>'predict_proba'</code>, <code>'decision_function'</code> or
<code>'predict'</code>. If the method is not implemented by the estimator, it
will raise an error.</li>
</ul>
<p>n_jobs : int, default=None
The number of jobs to run in parallel all <code>estimators</code> <code>fit</code>.
<code>None</code> means 1 unless in a <code>joblib.parallel_backend</code> context. -1 means
using all processors. See Glossary for more details.</p>
<p>passthrough : bool, default=False
When False, only the predictions of estimators will be used as
training data for <code>final_estimator</code>. When True, the
<code>final_estimator</code> is trained on the predictions as well as the
original training data.</p>
<h2 id="attributes_12">Attributes<a class="headerlink" href="#attributes_12" title="Permanent link">&para;</a></h2>
<p>estimators_ : list of estimators
The elements of the estimators parameter, having been fitted on the
training data. If an estimator has been set to <code>'drop'</code>, it
will not appear in <code>estimators_</code>.</p>
<p>named_estimators_ : Bunch
Attribute to access any fitted sub-estimators by name.</p>
<p>final_estimator_ : estimator
The classifier which predicts given the output of <code>estimators_</code>.</p>
<p>stack_method_ : list of str
The method used by each base estimator.</p>
<h2 id="notes_12">Notes<a class="headerlink" href="#notes_12" title="Permanent link">&para;</a></h2>
<p>When <code>predict_proba</code> is used by each estimator (i.e. most of the time for
<code>stack_method='auto'</code> or specifically for <code>stack_method='predict_proba'</code>),
The first column predicted by each estimator will be dropped in the case
of a binary classification problem. Indeed, both feature will be perfectly
collinear.</p>
<h2 id="references_12">References<a class="headerlink" href="#references_12" title="Permanent link">&para;</a></h2>
<p>.. [1] Wolpert, David H. 'Stacked generalization.' Neural networks 5.2
(1992): 241-259.</p>
<h2 id="examples_8">Examples<a class="headerlink" href="#examples_8" title="Permanent link">&para;</a></h2>
<blockquote>
<blockquote>
<blockquote>
<p>from sklearn.datasets import load_iris
from sklearn.ensemble import RandomForestClassifier
from sklearn.svm import LinearSVC
from sklearn.linear_model import LogisticRegression
from sklearn.preprocessing import StandardScaler
from sklearn.pipeline import make_pipeline
from sklearn.ensemble import StackingClassifier
X, y = load_iris(return_X_y=True)
estimators = [
...     ('rf', RandomForestClassifier(n_estimators=10, random_state=42)),
...     ('svr', make_pipeline(StandardScaler(),
...                           LinearSVC(random_state=42)))
... ]
clf = StackingClassifier(
...     estimators=estimators, final_estimator=LogisticRegression()
... )
from sklearn.model_selection import train_test_split
X_train, X_test, y_train, y_test = train_test_split(
...     X, y, stratify=y, random_state=42
... )
clf.fit(X_train, y_train).score(X_test, y_test)
0.9...</p>
</blockquote>
</blockquote>
</blockquote>
<div class="highlight"><pre><span></span><code><span class="k">val</span> <span class="n">decision_function</span> <span class="o">:</span> <span class="n">x</span><span class="o">:[&gt;`</span><span class="nc">ArrayLike</span><span class="o">]</span> <span class="nn">Np</span><span class="p">.</span><span class="nn">Obj</span><span class="p">.</span><span class="n">t</span> <span class="o">-&gt;</span> <span class="o">[&gt;</span> <span class="n">tag</span><span class="o">]</span> <span class="nn">Obj</span><span class="p">.</span><span class="n">t</span> <span class="o">-&gt;</span> <span class="o">[&gt;`</span><span class="nc">ArrayLike</span><span class="o">]</span> <span class="nn">Np</span><span class="p">.</span><span class="nn">Obj</span><span class="p">.</span><span class="n">t</span>
</code></pre></div>

<p>Predict decision function for samples in X using
<code>final_estimator_.decision_function</code>.</p>
<h2 id="parameters_111">Parameters<a class="headerlink" href="#parameters_111" title="Permanent link">&para;</a></h2>
<p>X : {array-like, sparse matrix} of shape (n_samples, n_features)
Training vectors, where n_samples is the number of samples and
n_features is the number of features.</p>
<h2 id="returns_92">Returns<a class="headerlink" href="#returns_92" title="Permanent link">&para;</a></h2>
<p>decisions : ndarray of shape (n_samples,), (n_samples, n_classes),             or (n_samples, n_classes * (n_classes-1) / 2)
The decision function computed the final estimator.</p>
<div class="highlight"><pre><span></span><code><span class="k">val</span> <span class="n">fit</span> <span class="o">:</span> <span class="o">?</span><span class="n">sample_weight</span><span class="o">:[&gt;`</span><span class="nc">ArrayLike</span><span class="o">]</span> <span class="nn">Np</span><span class="p">.</span><span class="nn">Obj</span><span class="p">.</span><span class="n">t</span> <span class="o">-&gt;</span> <span class="n">x</span><span class="o">:[&gt;`</span><span class="nc">ArrayLike</span><span class="o">]</span> <span class="nn">Np</span><span class="p">.</span><span class="nn">Obj</span><span class="p">.</span><span class="n">t</span> <span class="o">-&gt;</span> <span class="n">y</span><span class="o">:[&gt;`</span><span class="nc">ArrayLike</span><span class="o">]</span> <span class="nn">Np</span><span class="p">.</span><span class="nn">Obj</span><span class="p">.</span><span class="n">t</span> <span class="o">-&gt;</span> <span class="o">[&gt;</span> <span class="n">tag</span><span class="o">]</span> <span class="nn">Obj</span><span class="p">.</span><span class="n">t</span> <span class="o">-&gt;</span> <span class="n">t</span>
</code></pre></div>

<p>Fit the estimators.</p>
<h2 id="parameters_112">Parameters<a class="headerlink" href="#parameters_112" title="Permanent link">&para;</a></h2>
<p>X : {array-like, sparse matrix} of shape (n_samples, n_features)
Training vectors, where <code>n_samples</code> is the number of samples and
<code>n_features</code> is the number of features.</p>
<p>y : array-like of shape (n_samples,)
Target values.</p>
<p>sample_weight : array-like of shape (n_samples,) or None
Sample weights. If None, then samples are equally weighted.
Note that this is supported only if all underlying estimators
support sample weights.</p>
<h2 id="returns_93">Returns<a class="headerlink" href="#returns_93" title="Permanent link">&para;</a></h2>
<p>self : object</p>
<div class="highlight"><pre><span></span><code><span class="k">val</span> <span class="n">fit_transform</span> <span class="o">:</span> <span class="o">?</span><span class="n">y</span><span class="o">:[&gt;`</span><span class="nc">ArrayLike</span><span class="o">]</span> <span class="nn">Np</span><span class="p">.</span><span class="nn">Obj</span><span class="p">.</span><span class="n">t</span> <span class="o">-&gt;</span> <span class="o">?</span><span class="n">fit_params</span><span class="o">:(</span><span class="kt">string</span> <span class="o">*</span> <span class="nn">Py</span><span class="p">.</span><span class="nn">Object</span><span class="p">.</span><span class="n">t</span><span class="o">)</span> <span class="kt">list</span> <span class="o">-&gt;</span> <span class="n">x</span><span class="o">:[&gt;`</span><span class="nc">ArrayLike</span><span class="o">]</span> <span class="nn">Np</span><span class="p">.</span><span class="nn">Obj</span><span class="p">.</span><span class="n">t</span> <span class="o">-&gt;</span> <span class="o">[&gt;</span> <span class="n">tag</span><span class="o">]</span> <span class="nn">Obj</span><span class="p">.</span><span class="n">t</span> <span class="o">-&gt;</span> <span class="o">[&gt;`</span><span class="nc">ArrayLike</span><span class="o">]</span> <span class="nn">Np</span><span class="p">.</span><span class="nn">Obj</span><span class="p">.</span><span class="n">t</span>
</code></pre></div>

<p>Fit to data, then transform it.</p>
<p>Fits transformer to X and y with optional parameters fit_params
and returns a transformed version of X.</p>
<h2 id="parameters_113">Parameters<a class="headerlink" href="#parameters_113" title="Permanent link">&para;</a></h2>
<p>X : numpy array of shape [n_samples, n_features]
Training set.</p>
<p>y : numpy array of shape [n_samples]
Target values.</p>
<p>**fit_params : dict
Additional fit parameters.</p>
<h2 id="returns_94">Returns<a class="headerlink" href="#returns_94" title="Permanent link">&para;</a></h2>
<p>X_new : numpy array of shape [n_samples, n_features_new]
Transformed array.</p>
<div class="highlight"><pre><span></span><code><span class="k">val</span> <span class="n">get_params</span> <span class="o">:</span> <span class="o">?</span><span class="n">deep</span><span class="o">:</span><span class="kt">bool</span> <span class="o">-&gt;</span> <span class="o">[&gt;</span> <span class="n">tag</span><span class="o">]</span> <span class="nn">Obj</span><span class="p">.</span><span class="n">t</span> <span class="o">-&gt;</span> <span class="nn">Py</span><span class="p">.</span><span class="nn">Object</span><span class="p">.</span><span class="n">t</span>
</code></pre></div>

<p>Get the parameters of an estimator from the ensemble.</p>
<h2 id="parameters_114">Parameters<a class="headerlink" href="#parameters_114" title="Permanent link">&para;</a></h2>
<p>deep : bool
Setting it to True gets the various classifiers and the parameters
of the classifiers as well.</p>
<div class="highlight"><pre><span></span><code><span class="k">val</span> <span class="n">predict</span> <span class="o">:</span> <span class="o">?</span><span class="n">predict_params</span><span class="o">:(</span><span class="kt">string</span> <span class="o">*</span> <span class="nn">Py</span><span class="p">.</span><span class="nn">Object</span><span class="p">.</span><span class="n">t</span><span class="o">)</span> <span class="kt">list</span> <span class="o">-&gt;</span> <span class="n">x</span><span class="o">:[&gt;`</span><span class="nc">ArrayLike</span><span class="o">]</span> <span class="nn">Np</span><span class="p">.</span><span class="nn">Obj</span><span class="p">.</span><span class="n">t</span> <span class="o">-&gt;</span> <span class="o">[&gt;</span> <span class="n">tag</span><span class="o">]</span> <span class="nn">Obj</span><span class="p">.</span><span class="n">t</span> <span class="o">-&gt;</span> <span class="o">[&gt;`</span><span class="nc">ArrayLike</span><span class="o">]</span> <span class="nn">Np</span><span class="p">.</span><span class="nn">Obj</span><span class="p">.</span><span class="n">t</span>
</code></pre></div>

<p>Predict target for X.</p>
<h2 id="parameters_115">Parameters<a class="headerlink" href="#parameters_115" title="Permanent link">&para;</a></h2>
<p>X : {array-like, sparse matrix} of shape (n_samples, n_features)
Training vectors, where n_samples is the number of samples and
n_features is the number of features.</p>
<p>**predict_params : dict of str -&gt; obj
Parameters to the <code>predict</code> called by the <code>final_estimator</code>. Note
that this may be used to return uncertainties from some estimators
with <code>return_std</code> or <code>return_cov</code>. Be aware that it will only
accounts for uncertainty in the final estimator.</p>
<h2 id="returns_95">Returns<a class="headerlink" href="#returns_95" title="Permanent link">&para;</a></h2>
<p>y_pred : ndarray of shape (n_samples,) or (n_samples, n_output)
Predicted targets.</p>
<div class="highlight"><pre><span></span><code><span class="k">val</span> <span class="n">predict_proba</span> <span class="o">:</span> <span class="n">x</span><span class="o">:[&gt;`</span><span class="nc">ArrayLike</span><span class="o">]</span> <span class="nn">Np</span><span class="p">.</span><span class="nn">Obj</span><span class="p">.</span><span class="n">t</span> <span class="o">-&gt;</span> <span class="o">[&gt;</span> <span class="n">tag</span><span class="o">]</span> <span class="nn">Obj</span><span class="p">.</span><span class="n">t</span> <span class="o">-&gt;</span> <span class="o">[&gt;`</span><span class="nc">ArrayLike</span><span class="o">]</span> <span class="nn">Np</span><span class="p">.</span><span class="nn">Obj</span><span class="p">.</span><span class="n">t</span>
</code></pre></div>

<p>Predict class probabilities for X using
<code>final_estimator_.predict_proba</code>.</p>
<h2 id="parameters_116">Parameters<a class="headerlink" href="#parameters_116" title="Permanent link">&para;</a></h2>
<p>X : {array-like, sparse matrix} of shape (n_samples, n_features)
Training vectors, where n_samples is the number of samples and
n_features is the number of features.</p>
<h2 id="returns_96">Returns<a class="headerlink" href="#returns_96" title="Permanent link">&para;</a></h2>
<p>probabilities : ndarray of shape (n_samples, n_classes) or             list of ndarray of shape (n_output,)
The class probabilities of the input samples.</p>
<div class="highlight"><pre><span></span><code><span class="k">val</span> <span class="n">score</span> <span class="o">:</span> <span class="o">?</span><span class="n">sample_weight</span><span class="o">:[&gt;`</span><span class="nc">ArrayLike</span><span class="o">]</span> <span class="nn">Np</span><span class="p">.</span><span class="nn">Obj</span><span class="p">.</span><span class="n">t</span> <span class="o">-&gt;</span> <span class="n">x</span><span class="o">:[&gt;`</span><span class="nc">ArrayLike</span><span class="o">]</span> <span class="nn">Np</span><span class="p">.</span><span class="nn">Obj</span><span class="p">.</span><span class="n">t</span> <span class="o">-&gt;</span> <span class="n">y</span><span class="o">:[&gt;`</span><span class="nc">ArrayLike</span><span class="o">]</span> <span class="nn">Np</span><span class="p">.</span><span class="nn">Obj</span><span class="p">.</span><span class="n">t</span> <span class="o">-&gt;</span> <span class="o">[&gt;</span> <span class="n">tag</span><span class="o">]</span> <span class="nn">Obj</span><span class="p">.</span><span class="n">t</span> <span class="o">-&gt;</span> <span class="kt">float</span>
</code></pre></div>

<p>Return the mean accuracy on the given test data and labels.</p>
<p>In multi-label classification, this is the subset accuracy
which is a harsh metric since you require for each sample that
each label set be correctly predicted.</p>
<h2 id="parameters_117">Parameters<a class="headerlink" href="#parameters_117" title="Permanent link">&para;</a></h2>
<p>X : array-like of shape (n_samples, n_features)
Test samples.</p>
<p>y : array-like of shape (n_samples,) or (n_samples, n_outputs)
True labels for X.</p>
<p>sample_weight : array-like of shape (n_samples,), default=None
Sample weights.</p>
<h2 id="returns_97">Returns<a class="headerlink" href="#returns_97" title="Permanent link">&para;</a></h2>
<p>score : float
Mean accuracy of self.predict(X) wrt. y.</p>
<div class="highlight"><pre><span></span><code><span class="k">val</span> <span class="n">set_params</span> <span class="o">:</span> <span class="o">?</span><span class="n">params</span><span class="o">:(</span><span class="kt">string</span> <span class="o">*</span> <span class="nn">Py</span><span class="p">.</span><span class="nn">Object</span><span class="p">.</span><span class="n">t</span><span class="o">)</span> <span class="kt">list</span> <span class="o">-&gt;</span> <span class="o">[&gt;</span> <span class="n">tag</span><span class="o">]</span> <span class="nn">Obj</span><span class="p">.</span><span class="n">t</span> <span class="o">-&gt;</span> <span class="n">t</span>
</code></pre></div>

<p>Set the parameters of an estimator from the ensemble.</p>
<p>Valid parameter keys can be listed with <code>get_params()</code>.</p>
<h2 id="parameters_118">Parameters<a class="headerlink" href="#parameters_118" title="Permanent link">&para;</a></h2>
<p>**params : keyword arguments
Specific parameters using e.g.
<code>set_params(parameter_name=new_value)</code>. In addition, to setting the
parameters of the stacking estimator, the individual estimator of
the stacking estimators can also be set, or can be removed by
setting them to 'drop'.</p>
<div class="highlight"><pre><span></span><code><span class="k">val</span> <span class="n">transform</span> <span class="o">:</span> <span class="n">x</span><span class="o">:[&gt;`</span><span class="nc">ArrayLike</span><span class="o">]</span> <span class="nn">Np</span><span class="p">.</span><span class="nn">Obj</span><span class="p">.</span><span class="n">t</span> <span class="o">-&gt;</span> <span class="o">[&gt;</span> <span class="n">tag</span><span class="o">]</span> <span class="nn">Obj</span><span class="p">.</span><span class="n">t</span> <span class="o">-&gt;</span> <span class="o">[&gt;`</span><span class="nc">ArrayLike</span><span class="o">]</span> <span class="nn">Np</span><span class="p">.</span><span class="nn">Obj</span><span class="p">.</span><span class="n">t</span>
</code></pre></div>

<p>Return class labels or probabilities for X for each estimator.</p>
<h2 id="parameters_119">Parameters<a class="headerlink" href="#parameters_119" title="Permanent link">&para;</a></h2>
<p>X : {array-like, sparse matrix} of shape (n_samples, n_features)
Training vectors, where <code>n_samples</code> is the number of samples and
<code>n_features</code> is the number of features.</p>
<h2 id="returns_98">Returns<a class="headerlink" href="#returns_98" title="Permanent link">&para;</a></h2>
<p>y_preds : ndarray of shape (n_samples, n_estimators) or                 (n_samples, n_classes * n_estimators)
Prediction outputs for each estimator.</p>
<p>Attribute estimators_: get value or raise Not_found if None.</p>
<div class="highlight"><pre><span></span><code><span class="k">val</span> <span class="n">estimators_</span> <span class="o">:</span> <span class="n">t</span> <span class="o">-&gt;</span> <span class="o">[`</span><span class="nc">BaseEstimator</span><span class="o">|`</span><span class="nc">Object</span><span class="o">]</span> <span class="nn">Np</span><span class="p">.</span><span class="nn">Obj</span><span class="p">.</span><span class="n">t</span> <span class="kt">list</span>
</code></pre></div>

<p>Attribute estimators_: get value as an option.</p>
<div class="highlight"><pre><span></span><code><span class="k">val</span> <span class="n">estimators_opt</span> <span class="o">:</span> <span class="n">t</span> <span class="o">-&gt;</span> <span class="o">([`</span><span class="nc">BaseEstimator</span><span class="o">|`</span><span class="nc">Object</span><span class="o">]</span> <span class="nn">Np</span><span class="p">.</span><span class="nn">Obj</span><span class="p">.</span><span class="n">t</span> <span class="kt">list</span><span class="o">)</span> <span class="n">option</span>
</code></pre></div>

<p>Attribute named_estimators_: get value or raise Not_found if None.</p>
<div class="highlight"><pre><span></span><code><span class="k">val</span> <span class="n">named_estimators_</span> <span class="o">:</span> <span class="n">t</span> <span class="o">-&gt;</span> <span class="nn">Dict</span><span class="p">.</span><span class="n">t</span>
</code></pre></div>

<p>Attribute named_estimators_: get value as an option.</p>
<div class="highlight"><pre><span></span><code><span class="k">val</span> <span class="n">named_estimators_opt</span> <span class="o">:</span> <span class="n">t</span> <span class="o">-&gt;</span> <span class="o">(</span><span class="nn">Dict</span><span class="p">.</span><span class="n">t</span><span class="o">)</span> <span class="n">option</span>
</code></pre></div>

<p>Attribute final_estimator_: get value or raise Not_found if None.</p>
<div class="highlight"><pre><span></span><code><span class="k">val</span> <span class="n">final_estimator_</span> <span class="o">:</span> <span class="n">t</span> <span class="o">-&gt;</span> <span class="o">[`</span><span class="nc">BaseEstimator</span><span class="o">|`</span><span class="nc">Object</span><span class="o">]</span> <span class="nn">Np</span><span class="p">.</span><span class="nn">Obj</span><span class="p">.</span><span class="n">t</span>
</code></pre></div>

<p>Attribute final_estimator_: get value as an option.</p>
<div class="highlight"><pre><span></span><code><span class="k">val</span> <span class="n">final_estimator_opt</span> <span class="o">:</span> <span class="n">t</span> <span class="o">-&gt;</span> <span class="o">([`</span><span class="nc">BaseEstimator</span><span class="o">|`</span><span class="nc">Object</span><span class="o">]</span> <span class="nn">Np</span><span class="p">.</span><span class="nn">Obj</span><span class="p">.</span><span class="n">t</span><span class="o">)</span> <span class="n">option</span>
</code></pre></div>

<p>Attribute stack_method_: get value or raise Not_found if None.</p>
<div class="highlight"><pre><span></span><code><span class="k">val</span> <span class="n">stack_method_</span> <span class="o">:</span> <span class="n">t</span> <span class="o">-&gt;</span> <span class="kt">string</span> <span class="kt">list</span>
</code></pre></div>

<p>Attribute stack_method_: get value as an option.</p>
<div class="highlight"><pre><span></span><code><span class="k">val</span> <span class="n">stack_method_opt</span> <span class="o">:</span> <span class="n">t</span> <span class="o">-&gt;</span> <span class="o">(</span><span class="kt">string</span> <span class="kt">list</span><span class="o">)</span> <span class="n">option</span>
</code></pre></div>

<p>Print the object to a human-readable representation.</p>
<div class="highlight"><pre><span></span><code><span class="k">val</span> <span class="n">to_string</span> <span class="o">:</span> <span class="n">t</span> <span class="o">-&gt;</span> <span class="kt">string</span>
</code></pre></div>

<p>Print the object to a human-readable representation.</p>
<div class="highlight"><pre><span></span><code><span class="k">val</span> <span class="n">show</span> <span class="o">:</span> <span class="n">t</span> <span class="o">-&gt;</span> <span class="kt">string</span>
</code></pre></div>

<p>Pretty-print the object to a formatter.</p>
<div class="highlight"><pre><span></span><code><span class="k">val</span> <span class="n">pp</span> <span class="o">:</span> <span class="nn">Format</span><span class="p">.</span><span class="n">formatter</span> <span class="o">-&gt;</span> <span class="n">t</span> <span class="o">-&gt;</span> <span class="kt">unit</span> <span class="o">[@@</span><span class="n">ocaml</span><span class="o">.</span><span class="n">toplevel_printer</span><span class="o">]</span>



<span class="k">module</span> <span class="nc">StackingRegressor</span> <span class="o">:</span> <span class="k">sig</span>
<span class="k">type</span> <span class="n">tag</span> <span class="o">=</span> <span class="o">[`</span><span class="nc">StackingRegressor</span><span class="o">]</span>
<span class="k">type</span> <span class="n">t</span> <span class="o">=</span> <span class="o">[`</span><span class="nc">BaseEstimator</span> <span class="o">|</span> <span class="o">`</span><span class="nc">MetaEstimatorMixin</span> <span class="o">|</span> <span class="o">`</span><span class="nc">Object</span> <span class="o">|</span> <span class="o">`</span><span class="nc">RegressorMixin</span> <span class="o">|</span> <span class="o">`</span><span class="nc">StackingRegressor</span> <span class="o">|</span> <span class="o">`</span><span class="nc">TransformerMixin</span><span class="o">]</span> <span class="nn">Obj</span><span class="p">.</span><span class="n">t</span>
<span class="k">val</span> <span class="n">of_pyobject</span> <span class="o">:</span> <span class="nn">Py</span><span class="p">.</span><span class="nn">Object</span><span class="p">.</span><span class="n">t</span> <span class="o">-&gt;</span> <span class="n">t</span>
<span class="k">val</span> <span class="n">to_pyobject</span> <span class="o">:</span> <span class="o">[&gt;</span> <span class="n">tag</span><span class="o">]</span> <span class="nn">Obj</span><span class="p">.</span><span class="n">t</span> <span class="o">-&gt;</span> <span class="nn">Py</span><span class="p">.</span><span class="nn">Object</span><span class="p">.</span><span class="n">t</span>

<span class="k">val</span> <span class="n">as_regressor</span> <span class="o">:</span> <span class="n">t</span> <span class="o">-&gt;</span> <span class="o">[`</span><span class="nc">RegressorMixin</span><span class="o">]</span> <span class="nn">Obj</span><span class="p">.</span><span class="n">t</span>
<span class="k">val</span> <span class="n">as_transformer</span> <span class="o">:</span> <span class="n">t</span> <span class="o">-&gt;</span> <span class="o">[`</span><span class="nc">TransformerMixin</span><span class="o">]</span> <span class="nn">Obj</span><span class="p">.</span><span class="n">t</span>
<span class="k">val</span> <span class="n">as_estimator</span> <span class="o">:</span> <span class="n">t</span> <span class="o">-&gt;</span> <span class="o">[`</span><span class="nc">BaseEstimator</span><span class="o">]</span> <span class="nn">Obj</span><span class="p">.</span><span class="n">t</span>
<span class="k">val</span> <span class="n">as_meta_estimator</span> <span class="o">:</span> <span class="n">t</span> <span class="o">-&gt;</span> <span class="o">[`</span><span class="nc">MetaEstimatorMixin</span><span class="o">]</span> <span class="nn">Obj</span><span class="p">.</span><span class="n">t</span>
<span class="k">val</span> <span class="n">create</span> <span class="o">:</span> <span class="o">?</span><span class="n">final_estimator</span><span class="o">:[&gt;`</span><span class="nc">BaseEstimator</span><span class="o">]</span> <span class="nn">Np</span><span class="p">.</span><span class="nn">Obj</span><span class="p">.</span><span class="n">t</span> <span class="o">-&gt;</span> <span class="o">?</span><span class="n">cv</span><span class="o">:[`</span><span class="nc">Arr</span> <span class="k">of</span> <span class="o">[&gt;`</span><span class="nc">ArrayLike</span><span class="o">]</span> <span class="nn">Np</span><span class="p">.</span><span class="nn">Obj</span><span class="p">.</span><span class="n">t</span> <span class="o">|</span> <span class="o">`</span><span class="nc">BaseCrossValidator</span> <span class="k">of</span> <span class="o">[&gt;`</span><span class="nc">BaseCrossValidator</span><span class="o">]</span> <span class="nn">Np</span><span class="p">.</span><span class="nn">Obj</span><span class="p">.</span><span class="n">t</span> <span class="o">|</span> <span class="o">`</span><span class="nc">I</span> <span class="k">of</span> <span class="kt">int</span><span class="o">]</span> <span class="o">-&gt;</span> <span class="o">?</span><span class="n">n_jobs</span><span class="o">:</span><span class="kt">int</span> <span class="o">-&gt;</span> <span class="o">?</span><span class="n">passthrough</span><span class="o">:</span><span class="kt">bool</span> <span class="o">-&gt;</span> <span class="o">?</span><span class="n">verbose</span><span class="o">:</span><span class="kt">int</span> <span class="o">-&gt;</span> <span class="n">estimators</span><span class="o">:(</span><span class="kt">string</span> <span class="o">*</span> <span class="o">[&gt;`</span><span class="nc">BaseEstimator</span><span class="o">]</span> <span class="nn">Np</span><span class="p">.</span><span class="nn">Obj</span><span class="p">.</span><span class="n">t</span><span class="o">)</span> <span class="kt">list</span> <span class="o">-&gt;</span> <span class="kt">unit</span> <span class="o">-&gt;</span> <span class="n">t</span>
</code></pre></div>

<p>Stack of estimators with a final regressor.</p>
<p>Stacked generalization consists in stacking the output of individual
estimator and use a regressor to compute the final prediction. Stacking
allows to use the strength of each individual estimator by using their
output as input of a final estimator.</p>
<p>Note that <code>estimators_</code> are fitted on the full <code>X</code> while <code>final_estimator_</code>
is trained using cross-validated predictions of the base estimators using
<code>cross_val_predict</code>.</p>
<p>.. versionadded:: 0.22</p>
<p>Read more in the :ref:<code>User Guide &lt;stacking&gt;</code>.</p>
<h2 id="parameters_120">Parameters<a class="headerlink" href="#parameters_120" title="Permanent link">&para;</a></h2>
<p>estimators : list of (str, estimator)
Base estimators which will be stacked together. Each element of the
list is defined as a tuple of string (i.e. name) and an estimator
instance. An estimator can be set to 'drop' using <code>set_params</code>.</p>
<p>final_estimator : estimator, default=None
A regressor which will be used to combine the base estimators.
The default regressor is a <code>RidgeCV</code>.</p>
<p>cv : int, cross-validation generator or an iterable, default=None
Determines the cross-validation splitting strategy used in
<code>cross_val_predict</code> to train <code>final_estimator</code>. Possible inputs for
cv are:</p>
<ul>
<li>None, to use the default 5-fold cross validation,</li>
<li>integer, to specify the number of folds in a (Stratified) KFold,</li>
<li>An object to be used as a cross-validation generator,</li>
<li>An iterable yielding train, test splits.</li>
</ul>
<p>For integer/None inputs, if the estimator is a classifier and y is
either binary or multiclass, <code>StratifiedKFold</code> is used. In all other
cases, <code>KFold</code> is used.</p>
<p>Refer :ref:<code>User Guide &lt;cross_validation&gt;</code> for the various
cross-validation strategies that can be used here.</p>
<p>.. note::
A larger number of split will provide no benefits if the number
of training samples is large enough. Indeed, the training time
will increase. <code>cv</code> is not used for model evaluation but for
prediction.</p>
<p>n_jobs : int, default=None
The number of jobs to run in parallel for <code>fit</code> of all <code>estimators</code>.
<code>None</code> means 1 unless in a <code>joblib.parallel_backend</code> context. -1 means
using all processors. See Glossary for more details.</p>
<p>passthrough : bool, default=False
When False, only the predictions of estimators will be used as
training data for <code>final_estimator</code>. When True, the
<code>final_estimator</code> is trained on the predictions as well as the
original training data.</p>
<h2 id="attributes_13">Attributes<a class="headerlink" href="#attributes_13" title="Permanent link">&para;</a></h2>
<p>estimators_ : list of estimator
The elements of the estimators parameter, having been fitted on the
training data. If an estimator has been set to <code>'drop'</code>, it
will not appear in <code>estimators_</code>.</p>
<p>named_estimators_ : Bunch
Attribute to access any fitted sub-estimators by name.</p>
<p>final_estimator_ : estimator
The regressor to stacked the base estimators fitted.</p>
<h2 id="references_13">References<a class="headerlink" href="#references_13" title="Permanent link">&para;</a></h2>
<p>.. [1] Wolpert, David H. 'Stacked generalization.' Neural networks 5.2
(1992): 241-259.</p>
<h2 id="examples_9">Examples<a class="headerlink" href="#examples_9" title="Permanent link">&para;</a></h2>
<blockquote>
<blockquote>
<blockquote>
<p>from sklearn.datasets import load_diabetes
from sklearn.linear_model import RidgeCV
from sklearn.svm import LinearSVR
from sklearn.ensemble import RandomForestRegressor
from sklearn.ensemble import StackingRegressor
X, y = load_diabetes(return_X_y=True)
estimators = [
...     ('lr', RidgeCV()),
...     ('svr', LinearSVR(random_state=42))
... ]
reg = StackingRegressor(
...     estimators=estimators,
...     final_estimator=RandomForestRegressor(n_estimators=10,
...                                           random_state=42)
... )
from sklearn.model_selection import train_test_split
X_train, X_test, y_train, y_test = train_test_split(
...     X, y, random_state=42
... )
reg.fit(X_train, y_train).score(X_test, y_test)
0.3...</p>
</blockquote>
</blockquote>
</blockquote>
<div class="highlight"><pre><span></span><code><span class="k">val</span> <span class="n">fit</span> <span class="o">:</span> <span class="o">?</span><span class="n">sample_weight</span><span class="o">:[&gt;`</span><span class="nc">ArrayLike</span><span class="o">]</span> <span class="nn">Np</span><span class="p">.</span><span class="nn">Obj</span><span class="p">.</span><span class="n">t</span> <span class="o">-&gt;</span> <span class="n">x</span><span class="o">:[&gt;`</span><span class="nc">ArrayLike</span><span class="o">]</span> <span class="nn">Np</span><span class="p">.</span><span class="nn">Obj</span><span class="p">.</span><span class="n">t</span> <span class="o">-&gt;</span> <span class="n">y</span><span class="o">:[&gt;`</span><span class="nc">ArrayLike</span><span class="o">]</span> <span class="nn">Np</span><span class="p">.</span><span class="nn">Obj</span><span class="p">.</span><span class="n">t</span> <span class="o">-&gt;</span> <span class="o">[&gt;</span> <span class="n">tag</span><span class="o">]</span> <span class="nn">Obj</span><span class="p">.</span><span class="n">t</span> <span class="o">-&gt;</span> <span class="n">t</span>
</code></pre></div>

<p>Fit the estimators.</p>
<h2 id="parameters_121">Parameters<a class="headerlink" href="#parameters_121" title="Permanent link">&para;</a></h2>
<p>X : {array-like, sparse matrix} of shape (n_samples, n_features)
Training vectors, where n_samples is the number of samples and
n_features is the number of features.</p>
<p>y : array-like of shape (n_samples,)
Target values.</p>
<p>sample_weight : array-like of shape (n_samples,) or None
Sample weights. If None, then samples are equally weighted.
Note that this is supported only if all underlying estimators
support sample weights.</p>
<h2 id="returns_99">Returns<a class="headerlink" href="#returns_99" title="Permanent link">&para;</a></h2>
<p>self : object</p>
<div class="highlight"><pre><span></span><code><span class="k">val</span> <span class="n">fit_transform</span> <span class="o">:</span> <span class="o">?</span><span class="n">y</span><span class="o">:[&gt;`</span><span class="nc">ArrayLike</span><span class="o">]</span> <span class="nn">Np</span><span class="p">.</span><span class="nn">Obj</span><span class="p">.</span><span class="n">t</span> <span class="o">-&gt;</span> <span class="o">?</span><span class="n">fit_params</span><span class="o">:(</span><span class="kt">string</span> <span class="o">*</span> <span class="nn">Py</span><span class="p">.</span><span class="nn">Object</span><span class="p">.</span><span class="n">t</span><span class="o">)</span> <span class="kt">list</span> <span class="o">-&gt;</span> <span class="n">x</span><span class="o">:[&gt;`</span><span class="nc">ArrayLike</span><span class="o">]</span> <span class="nn">Np</span><span class="p">.</span><span class="nn">Obj</span><span class="p">.</span><span class="n">t</span> <span class="o">-&gt;</span> <span class="o">[&gt;</span> <span class="n">tag</span><span class="o">]</span> <span class="nn">Obj</span><span class="p">.</span><span class="n">t</span> <span class="o">-&gt;</span> <span class="o">[&gt;`</span><span class="nc">ArrayLike</span><span class="o">]</span> <span class="nn">Np</span><span class="p">.</span><span class="nn">Obj</span><span class="p">.</span><span class="n">t</span>
</code></pre></div>

<p>Fit to data, then transform it.</p>
<p>Fits transformer to X and y with optional parameters fit_params
and returns a transformed version of X.</p>
<h2 id="parameters_122">Parameters<a class="headerlink" href="#parameters_122" title="Permanent link">&para;</a></h2>
<p>X : numpy array of shape [n_samples, n_features]
Training set.</p>
<p>y : numpy array of shape [n_samples]
Target values.</p>
<p>**fit_params : dict
Additional fit parameters.</p>
<h2 id="returns_100">Returns<a class="headerlink" href="#returns_100" title="Permanent link">&para;</a></h2>
<p>X_new : numpy array of shape [n_samples, n_features_new]
Transformed array.</p>
<div class="highlight"><pre><span></span><code><span class="k">val</span> <span class="n">get_params</span> <span class="o">:</span> <span class="o">?</span><span class="n">deep</span><span class="o">:</span><span class="kt">bool</span> <span class="o">-&gt;</span> <span class="o">[&gt;</span> <span class="n">tag</span><span class="o">]</span> <span class="nn">Obj</span><span class="p">.</span><span class="n">t</span> <span class="o">-&gt;</span> <span class="nn">Py</span><span class="p">.</span><span class="nn">Object</span><span class="p">.</span><span class="n">t</span>
</code></pre></div>

<p>Get the parameters of an estimator from the ensemble.</p>
<h2 id="parameters_123">Parameters<a class="headerlink" href="#parameters_123" title="Permanent link">&para;</a></h2>
<p>deep : bool
Setting it to True gets the various classifiers and the parameters
of the classifiers as well.</p>
<div class="highlight"><pre><span></span><code><span class="k">val</span> <span class="n">predict</span> <span class="o">:</span> <span class="o">?</span><span class="n">predict_params</span><span class="o">:(</span><span class="kt">string</span> <span class="o">*</span> <span class="nn">Py</span><span class="p">.</span><span class="nn">Object</span><span class="p">.</span><span class="n">t</span><span class="o">)</span> <span class="kt">list</span> <span class="o">-&gt;</span> <span class="n">x</span><span class="o">:[&gt;`</span><span class="nc">ArrayLike</span><span class="o">]</span> <span class="nn">Np</span><span class="p">.</span><span class="nn">Obj</span><span class="p">.</span><span class="n">t</span> <span class="o">-&gt;</span> <span class="o">[&gt;</span> <span class="n">tag</span><span class="o">]</span> <span class="nn">Obj</span><span class="p">.</span><span class="n">t</span> <span class="o">-&gt;</span> <span class="o">[&gt;`</span><span class="nc">ArrayLike</span><span class="o">]</span> <span class="nn">Np</span><span class="p">.</span><span class="nn">Obj</span><span class="p">.</span><span class="n">t</span>
</code></pre></div>

<p>Predict target for X.</p>
<h2 id="parameters_124">Parameters<a class="headerlink" href="#parameters_124" title="Permanent link">&para;</a></h2>
<p>X : {array-like, sparse matrix} of shape (n_samples, n_features)
Training vectors, where n_samples is the number of samples and
n_features is the number of features.</p>
<p>**predict_params : dict of str -&gt; obj
Parameters to the <code>predict</code> called by the <code>final_estimator</code>. Note
that this may be used to return uncertainties from some estimators
with <code>return_std</code> or <code>return_cov</code>. Be aware that it will only
accounts for uncertainty in the final estimator.</p>
<h2 id="returns_101">Returns<a class="headerlink" href="#returns_101" title="Permanent link">&para;</a></h2>
<p>y_pred : ndarray of shape (n_samples,) or (n_samples, n_output)
Predicted targets.</p>
<div class="highlight"><pre><span></span><code><span class="k">val</span> <span class="n">score</span> <span class="o">:</span> <span class="o">?</span><span class="n">sample_weight</span><span class="o">:[&gt;`</span><span class="nc">ArrayLike</span><span class="o">]</span> <span class="nn">Np</span><span class="p">.</span><span class="nn">Obj</span><span class="p">.</span><span class="n">t</span> <span class="o">-&gt;</span> <span class="n">x</span><span class="o">:[&gt;`</span><span class="nc">ArrayLike</span><span class="o">]</span> <span class="nn">Np</span><span class="p">.</span><span class="nn">Obj</span><span class="p">.</span><span class="n">t</span> <span class="o">-&gt;</span> <span class="n">y</span><span class="o">:[&gt;`</span><span class="nc">ArrayLike</span><span class="o">]</span> <span class="nn">Np</span><span class="p">.</span><span class="nn">Obj</span><span class="p">.</span><span class="n">t</span> <span class="o">-&gt;</span> <span class="o">[&gt;</span> <span class="n">tag</span><span class="o">]</span> <span class="nn">Obj</span><span class="p">.</span><span class="n">t</span> <span class="o">-&gt;</span> <span class="kt">float</span>
</code></pre></div>

<p>Return the coefficient of determination R^2 of the prediction.</p>
<p>The coefficient R^2 is defined as (1 - u/v), where u is the residual
sum of squares ((y_true - y_pred) <strong> 2).sum() and v is the total
sum of squares ((y_true - y_true.mean()) </strong> 2).sum().
The best possible score is 1.0 and it can be negative (because the
model can be arbitrarily worse). A constant model that always
predicts the expected value of y, disregarding the input features,
would get a R^2 score of 0.0.</p>
<h2 id="parameters_125">Parameters<a class="headerlink" href="#parameters_125" title="Permanent link">&para;</a></h2>
<p>X : array-like of shape (n_samples, n_features)
Test samples. For some estimators this may be a
precomputed kernel matrix or a list of generic objects instead,
shape = (n_samples, n_samples_fitted),
where n_samples_fitted is the number of
samples used in the fitting for the estimator.</p>
<p>y : array-like of shape (n_samples,) or (n_samples, n_outputs)
True values for X.</p>
<p>sample_weight : array-like of shape (n_samples,), default=None
Sample weights.</p>
<h2 id="returns_102">Returns<a class="headerlink" href="#returns_102" title="Permanent link">&para;</a></h2>
<p>score : float
R^2 of self.predict(X) wrt. y.</p>
<h2 id="notes_13">Notes<a class="headerlink" href="#notes_13" title="Permanent link">&para;</a></h2>
<p>The R2 score used when calling <code>score</code> on a regressor will use
<code>multioutput='uniform_average'</code> from version 0.23 to keep consistent
with :func:<code>~sklearn.metrics.r2_score</code>. This will influence the
<code>score</code> method of all the multioutput regressors (except for
:class:<code>~sklearn.multioutput.MultiOutputRegressor</code>). To specify the
default value manually and avoid the warning, please either call
:func:<code>~sklearn.metrics.r2_score</code> directly or make a custom scorer with
:func:<code>~sklearn.metrics.make_scorer</code> (the built-in scorer <code>'r2'</code> uses
<code>multioutput='uniform_average'</code>).</p>
<div class="highlight"><pre><span></span><code><span class="k">val</span> <span class="n">set_params</span> <span class="o">:</span> <span class="o">?</span><span class="n">params</span><span class="o">:(</span><span class="kt">string</span> <span class="o">*</span> <span class="nn">Py</span><span class="p">.</span><span class="nn">Object</span><span class="p">.</span><span class="n">t</span><span class="o">)</span> <span class="kt">list</span> <span class="o">-&gt;</span> <span class="o">[&gt;</span> <span class="n">tag</span><span class="o">]</span> <span class="nn">Obj</span><span class="p">.</span><span class="n">t</span> <span class="o">-&gt;</span> <span class="n">t</span>
</code></pre></div>

<p>Set the parameters of an estimator from the ensemble.</p>
<p>Valid parameter keys can be listed with <code>get_params()</code>.</p>
<h2 id="parameters_126">Parameters<a class="headerlink" href="#parameters_126" title="Permanent link">&para;</a></h2>
<p>**params : keyword arguments
Specific parameters using e.g.
<code>set_params(parameter_name=new_value)</code>. In addition, to setting the
parameters of the stacking estimator, the individual estimator of
the stacking estimators can also be set, or can be removed by
setting them to 'drop'.</p>
<div class="highlight"><pre><span></span><code><span class="k">val</span> <span class="n">transform</span> <span class="o">:</span> <span class="n">x</span><span class="o">:[&gt;`</span><span class="nc">ArrayLike</span><span class="o">]</span> <span class="nn">Np</span><span class="p">.</span><span class="nn">Obj</span><span class="p">.</span><span class="n">t</span> <span class="o">-&gt;</span> <span class="o">[&gt;</span> <span class="n">tag</span><span class="o">]</span> <span class="nn">Obj</span><span class="p">.</span><span class="n">t</span> <span class="o">-&gt;</span> <span class="o">[&gt;`</span><span class="nc">ArrayLike</span><span class="o">]</span> <span class="nn">Np</span><span class="p">.</span><span class="nn">Obj</span><span class="p">.</span><span class="n">t</span>
</code></pre></div>

<p>Return the predictions for X for each estimator.</p>
<h2 id="parameters_127">Parameters<a class="headerlink" href="#parameters_127" title="Permanent link">&para;</a></h2>
<p>X : {array-like, sparse matrix} of shape (n_samples, n_features)
Training vectors, where <code>n_samples</code> is the number of samples and
<code>n_features</code> is the number of features.</p>
<h2 id="returns_103">Returns<a class="headerlink" href="#returns_103" title="Permanent link">&para;</a></h2>
<p>y_preds : ndarray of shape (n_samples, n_estimators)
Prediction outputs for each estimator.</p>
<p>Attribute estimators_: get value or raise Not_found if None.</p>
<div class="highlight"><pre><span></span><code><span class="k">val</span> <span class="n">estimators_</span> <span class="o">:</span> <span class="n">t</span> <span class="o">-&gt;</span> <span class="o">[`</span><span class="nc">BaseEstimator</span><span class="o">|`</span><span class="nc">Object</span><span class="o">]</span> <span class="nn">Np</span><span class="p">.</span><span class="nn">Obj</span><span class="p">.</span><span class="n">t</span> <span class="kt">list</span>
</code></pre></div>

<p>Attribute estimators_: get value as an option.</p>
<div class="highlight"><pre><span></span><code><span class="k">val</span> <span class="n">estimators_opt</span> <span class="o">:</span> <span class="n">t</span> <span class="o">-&gt;</span> <span class="o">([`</span><span class="nc">BaseEstimator</span><span class="o">|`</span><span class="nc">Object</span><span class="o">]</span> <span class="nn">Np</span><span class="p">.</span><span class="nn">Obj</span><span class="p">.</span><span class="n">t</span> <span class="kt">list</span><span class="o">)</span> <span class="n">option</span>
</code></pre></div>

<p>Attribute named_estimators_: get value or raise Not_found if None.</p>
<div class="highlight"><pre><span></span><code><span class="k">val</span> <span class="n">named_estimators_</span> <span class="o">:</span> <span class="n">t</span> <span class="o">-&gt;</span> <span class="nn">Dict</span><span class="p">.</span><span class="n">t</span>
</code></pre></div>

<p>Attribute named_estimators_: get value as an option.</p>
<div class="highlight"><pre><span></span><code><span class="k">val</span> <span class="n">named_estimators_opt</span> <span class="o">:</span> <span class="n">t</span> <span class="o">-&gt;</span> <span class="o">(</span><span class="nn">Dict</span><span class="p">.</span><span class="n">t</span><span class="o">)</span> <span class="n">option</span>
</code></pre></div>

<p>Attribute final_estimator_: get value or raise Not_found if None.</p>
<div class="highlight"><pre><span></span><code><span class="k">val</span> <span class="n">final_estimator_</span> <span class="o">:</span> <span class="n">t</span> <span class="o">-&gt;</span> <span class="o">[`</span><span class="nc">BaseEstimator</span><span class="o">|`</span><span class="nc">Object</span><span class="o">]</span> <span class="nn">Np</span><span class="p">.</span><span class="nn">Obj</span><span class="p">.</span><span class="n">t</span>
</code></pre></div>

<p>Attribute final_estimator_: get value as an option.</p>
<div class="highlight"><pre><span></span><code><span class="k">val</span> <span class="n">final_estimator_opt</span> <span class="o">:</span> <span class="n">t</span> <span class="o">-&gt;</span> <span class="o">([`</span><span class="nc">BaseEstimator</span><span class="o">|`</span><span class="nc">Object</span><span class="o">]</span> <span class="nn">Np</span><span class="p">.</span><span class="nn">Obj</span><span class="p">.</span><span class="n">t</span><span class="o">)</span> <span class="n">option</span>
</code></pre></div>

<p>Print the object to a human-readable representation.</p>
<div class="highlight"><pre><span></span><code><span class="k">val</span> <span class="n">to_string</span> <span class="o">:</span> <span class="n">t</span> <span class="o">-&gt;</span> <span class="kt">string</span>
</code></pre></div>

<p>Print the object to a human-readable representation.</p>
<div class="highlight"><pre><span></span><code><span class="k">val</span> <span class="n">show</span> <span class="o">:</span> <span class="n">t</span> <span class="o">-&gt;</span> <span class="kt">string</span>
</code></pre></div>

<p>Pretty-print the object to a formatter.</p>
<div class="highlight"><pre><span></span><code><span class="k">val</span> <span class="n">pp</span> <span class="o">:</span> <span class="nn">Format</span><span class="p">.</span><span class="n">formatter</span> <span class="o">-&gt;</span> <span class="n">t</span> <span class="o">-&gt;</span> <span class="kt">unit</span> <span class="o">[@@</span><span class="n">ocaml</span><span class="o">.</span><span class="n">toplevel_printer</span><span class="o">]</span>



<span class="k">module</span> <span class="nc">VotingClassifier</span> <span class="o">:</span> <span class="k">sig</span>
<span class="k">type</span> <span class="n">tag</span> <span class="o">=</span> <span class="o">[`</span><span class="nc">VotingClassifier</span><span class="o">]</span>
<span class="k">type</span> <span class="n">t</span> <span class="o">=</span> <span class="o">[`</span><span class="nc">BaseEstimator</span> <span class="o">|</span> <span class="o">`</span><span class="nc">ClassifierMixin</span> <span class="o">|</span> <span class="o">`</span><span class="nc">MetaEstimatorMixin</span> <span class="o">|</span> <span class="o">`</span><span class="nc">Object</span> <span class="o">|</span> <span class="o">`</span><span class="nc">TransformerMixin</span> <span class="o">|</span> <span class="o">`</span><span class="nc">VotingClassifier</span><span class="o">]</span> <span class="nn">Obj</span><span class="p">.</span><span class="n">t</span>
<span class="k">val</span> <span class="n">of_pyobject</span> <span class="o">:</span> <span class="nn">Py</span><span class="p">.</span><span class="nn">Object</span><span class="p">.</span><span class="n">t</span> <span class="o">-&gt;</span> <span class="n">t</span>
<span class="k">val</span> <span class="n">to_pyobject</span> <span class="o">:</span> <span class="o">[&gt;</span> <span class="n">tag</span><span class="o">]</span> <span class="nn">Obj</span><span class="p">.</span><span class="n">t</span> <span class="o">-&gt;</span> <span class="nn">Py</span><span class="p">.</span><span class="nn">Object</span><span class="p">.</span><span class="n">t</span>

<span class="k">val</span> <span class="n">as_classifier</span> <span class="o">:</span> <span class="n">t</span> <span class="o">-&gt;</span> <span class="o">[`</span><span class="nc">ClassifierMixin</span><span class="o">]</span> <span class="nn">Obj</span><span class="p">.</span><span class="n">t</span>
<span class="k">val</span> <span class="n">as_transformer</span> <span class="o">:</span> <span class="n">t</span> <span class="o">-&gt;</span> <span class="o">[`</span><span class="nc">TransformerMixin</span><span class="o">]</span> <span class="nn">Obj</span><span class="p">.</span><span class="n">t</span>
<span class="k">val</span> <span class="n">as_estimator</span> <span class="o">:</span> <span class="n">t</span> <span class="o">-&gt;</span> <span class="o">[`</span><span class="nc">BaseEstimator</span><span class="o">]</span> <span class="nn">Obj</span><span class="p">.</span><span class="n">t</span>
<span class="k">val</span> <span class="n">as_meta_estimator</span> <span class="o">:</span> <span class="n">t</span> <span class="o">-&gt;</span> <span class="o">[`</span><span class="nc">MetaEstimatorMixin</span><span class="o">]</span> <span class="nn">Obj</span><span class="p">.</span><span class="n">t</span>
<span class="k">val</span> <span class="n">create</span> <span class="o">:</span> <span class="o">?</span><span class="n">voting</span><span class="o">:[`</span><span class="nc">Hard</span> <span class="o">|</span> <span class="o">`</span><span class="nc">Soft</span><span class="o">]</span> <span class="o">-&gt;</span> <span class="o">?</span><span class="n">weights</span><span class="o">:[&gt;`</span><span class="nc">ArrayLike</span><span class="o">]</span> <span class="nn">Np</span><span class="p">.</span><span class="nn">Obj</span><span class="p">.</span><span class="n">t</span> <span class="o">-&gt;</span> <span class="o">?</span><span class="n">n_jobs</span><span class="o">:</span><span class="kt">int</span> <span class="o">-&gt;</span> <span class="o">?</span><span class="n">flatten_transform</span><span class="o">:</span><span class="kt">bool</span> <span class="o">-&gt;</span> <span class="n">estimators</span><span class="o">:(</span><span class="kt">string</span> <span class="o">*</span> <span class="o">[&gt;`</span><span class="nc">BaseEstimator</span><span class="o">]</span> <span class="nn">Np</span><span class="p">.</span><span class="nn">Obj</span><span class="p">.</span><span class="n">t</span><span class="o">)</span> <span class="kt">list</span> <span class="o">-&gt;</span> <span class="kt">unit</span> <span class="o">-&gt;</span> <span class="n">t</span>
</code></pre></div>

<p>Soft Voting/Majority Rule classifier for unfitted estimators.</p>
<p>.. versionadded:: 0.17</p>
<p>Read more in the :ref:<code>User Guide &lt;voting_classifier&gt;</code>.</p>
<h2 id="parameters_128">Parameters<a class="headerlink" href="#parameters_128" title="Permanent link">&para;</a></h2>
<p>estimators : list of (str, estimator) tuples
Invoking the <code>fit</code> method on the <code>VotingClassifier</code> will fit clones
of those original estimators that will be stored in the class attribute
<code>self.estimators_</code>. An estimator can be set to <code>'drop'</code>
using <code>set_params</code>.</p>
<p>.. deprecated:: 0.22
Using <code>None</code> to drop an estimator is deprecated in 0.22 and
support will be dropped in 0.24. Use the string <code>'drop'</code> instead.</p>
<p>voting : str, {'hard', 'soft'} (default='hard')
If 'hard', uses predicted class labels for majority rule voting.
Else if 'soft', predicts the class label based on the argmax of
the sums of the predicted probabilities, which is recommended for
an ensemble of well-calibrated classifiers.</p>
<p>weights : array-like, shape (n_classifiers,), optional (default=<code>None</code>)
Sequence of weights (<code>float</code> or <code>int</code>) to weight the occurrences of
predicted class labels (<code>hard</code> voting) or class probabilities
before averaging (<code>soft</code> voting). Uses uniform weights if <code>None</code>.</p>
<p>n_jobs : int or None, optional (default=None)
The number of jobs to run in parallel for <code>fit</code>.
<code>None</code> means 1 unless in a :obj:<code>joblib.parallel_backend</code> context.
<code>-1</code> means using all processors. See :term:<code>Glossary &lt;n_jobs&gt;</code>
for more details.</p>
<p>flatten_transform : bool, optional (default=True)
Affects shape of transform output only when voting='soft'
If voting='soft' and flatten_transform=True, transform method returns
matrix with shape (n_samples, n_classifiers * n_classes). If
flatten_transform=False, it returns
(n_classifiers, n_samples, n_classes).</p>
<h2 id="attributes_14">Attributes<a class="headerlink" href="#attributes_14" title="Permanent link">&para;</a></h2>
<p>estimators_ : list of classifiers
The collection of fitted sub-estimators as defined in <code>estimators</code>
that are not 'drop'.</p>
<p>named_estimators_ : Bunch object, a dictionary with attribute access
Attribute to access any fitted sub-estimators by name.</p>
<p>.. versionadded:: 0.20</p>
<p>classes_ : array-like, shape (n_predictions,)
The classes labels.</p>
<h2 id="see-also_9">See Also<a class="headerlink" href="#see-also_9" title="Permanent link">&para;</a></h2>
<p>VotingRegressor: Prediction voting regressor.</p>
<h2 id="examples_10">Examples<a class="headerlink" href="#examples_10" title="Permanent link">&para;</a></h2>
<blockquote>
<blockquote>
<blockquote>
<p>import numpy as np
from sklearn.linear_model import LogisticRegression
from sklearn.naive_bayes import GaussianNB
from sklearn.ensemble import RandomForestClassifier, VotingClassifier
clf1 = LogisticRegression(multi_class='multinomial', random_state=1)
clf2 = RandomForestClassifier(n_estimators=50, random_state=1)
clf3 = GaussianNB()
X = np.array([[-1, -1], [-2, -1], [-3, -2], [1, 1], [2, 1], [3, 2]])
y = np.array([1, 1, 1, 2, 2, 2])
eclf1 = VotingClassifier(estimators=[
...         ('lr', clf1), ('rf', clf2), ('gnb', clf3)], voting='hard')
eclf1 = eclf1.fit(X, y)
print(eclf1.predict(X))
[1 1 1 2 2 2]
np.array_equal(eclf1.named_estimators_.lr.predict(X),
...                eclf1.named_estimators_['lr'].predict(X))
True
eclf2 = VotingClassifier(estimators=[
...         ('lr', clf1), ('rf', clf2), ('gnb', clf3)],
...         voting='soft')
eclf2 = eclf2.fit(X, y)
print(eclf2.predict(X))
[1 1 1 2 2 2]
eclf3 = VotingClassifier(estimators=[
...        ('lr', clf1), ('rf', clf2), ('gnb', clf3)],
...        voting='soft', weights=[2,1,1],
...        flatten_transform=True)
eclf3 = eclf3.fit(X, y)
print(eclf3.predict(X))
[1 1 1 2 2 2]
print(eclf3.transform(X).shape)
(6, 6)</p>
</blockquote>
</blockquote>
</blockquote>
<div class="highlight"><pre><span></span><code><span class="k">val</span> <span class="n">fit</span> <span class="o">:</span> <span class="o">?</span><span class="n">sample_weight</span><span class="o">:[&gt;`</span><span class="nc">ArrayLike</span><span class="o">]</span> <span class="nn">Np</span><span class="p">.</span><span class="nn">Obj</span><span class="p">.</span><span class="n">t</span> <span class="o">-&gt;</span> <span class="n">x</span><span class="o">:[&gt;`</span><span class="nc">ArrayLike</span><span class="o">]</span> <span class="nn">Np</span><span class="p">.</span><span class="nn">Obj</span><span class="p">.</span><span class="n">t</span> <span class="o">-&gt;</span> <span class="n">y</span><span class="o">:[&gt;`</span><span class="nc">ArrayLike</span><span class="o">]</span> <span class="nn">Np</span><span class="p">.</span><span class="nn">Obj</span><span class="p">.</span><span class="n">t</span> <span class="o">-&gt;</span> <span class="o">[&gt;</span> <span class="n">tag</span><span class="o">]</span> <span class="nn">Obj</span><span class="p">.</span><span class="n">t</span> <span class="o">-&gt;</span> <span class="n">t</span>
</code></pre></div>

<p>Fit the estimators.</p>
<h2 id="parameters_129">Parameters<a class="headerlink" href="#parameters_129" title="Permanent link">&para;</a></h2>
<p>X : {array-like, sparse matrix}, shape (n_samples, n_features)
Training vectors, where n_samples is the number of samples and
n_features is the number of features.</p>
<p>y : array-like, shape (n_samples,)
Target values.</p>
<p>sample_weight : array-like, shape (n_samples,) or None
Sample weights. If None, then samples are equally weighted.
Note that this is supported only if all underlying estimators
support sample weights.</p>
<h2 id="returns_104">Returns<a class="headerlink" href="#returns_104" title="Permanent link">&para;</a></h2>
<p>self : object</p>
<div class="highlight"><pre><span></span><code><span class="k">val</span> <span class="n">fit_transform</span> <span class="o">:</span> <span class="o">?</span><span class="n">y</span><span class="o">:[&gt;`</span><span class="nc">ArrayLike</span><span class="o">]</span> <span class="nn">Np</span><span class="p">.</span><span class="nn">Obj</span><span class="p">.</span><span class="n">t</span> <span class="o">-&gt;</span> <span class="o">?</span><span class="n">fit_params</span><span class="o">:(</span><span class="kt">string</span> <span class="o">*</span> <span class="nn">Py</span><span class="p">.</span><span class="nn">Object</span><span class="p">.</span><span class="n">t</span><span class="o">)</span> <span class="kt">list</span> <span class="o">-&gt;</span> <span class="n">x</span><span class="o">:[&gt;`</span><span class="nc">ArrayLike</span><span class="o">]</span> <span class="nn">Np</span><span class="p">.</span><span class="nn">Obj</span><span class="p">.</span><span class="n">t</span> <span class="o">-&gt;</span> <span class="o">[&gt;</span> <span class="n">tag</span><span class="o">]</span> <span class="nn">Obj</span><span class="p">.</span><span class="n">t</span> <span class="o">-&gt;</span> <span class="o">[&gt;`</span><span class="nc">ArrayLike</span><span class="o">]</span> <span class="nn">Np</span><span class="p">.</span><span class="nn">Obj</span><span class="p">.</span><span class="n">t</span>
</code></pre></div>

<p>Fit to data, then transform it.</p>
<p>Fits transformer to X and y with optional parameters fit_params
and returns a transformed version of X.</p>
<h2 id="parameters_130">Parameters<a class="headerlink" href="#parameters_130" title="Permanent link">&para;</a></h2>
<p>X : numpy array of shape [n_samples, n_features]
Training set.</p>
<p>y : numpy array of shape [n_samples]
Target values.</p>
<p>**fit_params : dict
Additional fit parameters.</p>
<h2 id="returns_105">Returns<a class="headerlink" href="#returns_105" title="Permanent link">&para;</a></h2>
<p>X_new : numpy array of shape [n_samples, n_features_new]
Transformed array.</p>
<div class="highlight"><pre><span></span><code><span class="k">val</span> <span class="n">get_params</span> <span class="o">:</span> <span class="o">?</span><span class="n">deep</span><span class="o">:</span><span class="kt">bool</span> <span class="o">-&gt;</span> <span class="o">[&gt;</span> <span class="n">tag</span><span class="o">]</span> <span class="nn">Obj</span><span class="p">.</span><span class="n">t</span> <span class="o">-&gt;</span> <span class="nn">Py</span><span class="p">.</span><span class="nn">Object</span><span class="p">.</span><span class="n">t</span>
</code></pre></div>

<p>Get the parameters of an estimator from the ensemble.</p>
<h2 id="parameters_131">Parameters<a class="headerlink" href="#parameters_131" title="Permanent link">&para;</a></h2>
<p>deep : bool
Setting it to True gets the various classifiers and the parameters
of the classifiers as well.</p>
<div class="highlight"><pre><span></span><code><span class="k">val</span> <span class="n">predict</span> <span class="o">:</span> <span class="n">x</span><span class="o">:[&gt;`</span><span class="nc">ArrayLike</span><span class="o">]</span> <span class="nn">Np</span><span class="p">.</span><span class="nn">Obj</span><span class="p">.</span><span class="n">t</span> <span class="o">-&gt;</span> <span class="o">[&gt;</span> <span class="n">tag</span><span class="o">]</span> <span class="nn">Obj</span><span class="p">.</span><span class="n">t</span> <span class="o">-&gt;</span> <span class="o">[&gt;`</span><span class="nc">ArrayLike</span><span class="o">]</span> <span class="nn">Np</span><span class="p">.</span><span class="nn">Obj</span><span class="p">.</span><span class="n">t</span>
</code></pre></div>

<p>Predict class labels for X.</p>
<h2 id="parameters_132">Parameters<a class="headerlink" href="#parameters_132" title="Permanent link">&para;</a></h2>
<p>X : {array-like, sparse matrix}, shape (n_samples, n_features)
The input samples.</p>
<h2 id="returns_106">Returns<a class="headerlink" href="#returns_106" title="Permanent link">&para;</a></h2>
<p>maj : array-like, shape (n_samples,)
Predicted class labels.</p>
<div class="highlight"><pre><span></span><code><span class="k">val</span> <span class="n">score</span> <span class="o">:</span> <span class="o">?</span><span class="n">sample_weight</span><span class="o">:[&gt;`</span><span class="nc">ArrayLike</span><span class="o">]</span> <span class="nn">Np</span><span class="p">.</span><span class="nn">Obj</span><span class="p">.</span><span class="n">t</span> <span class="o">-&gt;</span> <span class="n">x</span><span class="o">:[&gt;`</span><span class="nc">ArrayLike</span><span class="o">]</span> <span class="nn">Np</span><span class="p">.</span><span class="nn">Obj</span><span class="p">.</span><span class="n">t</span> <span class="o">-&gt;</span> <span class="n">y</span><span class="o">:[&gt;`</span><span class="nc">ArrayLike</span><span class="o">]</span> <span class="nn">Np</span><span class="p">.</span><span class="nn">Obj</span><span class="p">.</span><span class="n">t</span> <span class="o">-&gt;</span> <span class="o">[&gt;</span> <span class="n">tag</span><span class="o">]</span> <span class="nn">Obj</span><span class="p">.</span><span class="n">t</span> <span class="o">-&gt;</span> <span class="kt">float</span>
</code></pre></div>

<p>Return the mean accuracy on the given test data and labels.</p>
<p>In multi-label classification, this is the subset accuracy
which is a harsh metric since you require for each sample that
each label set be correctly predicted.</p>
<h2 id="parameters_133">Parameters<a class="headerlink" href="#parameters_133" title="Permanent link">&para;</a></h2>
<p>X : array-like of shape (n_samples, n_features)
Test samples.</p>
<p>y : array-like of shape (n_samples,) or (n_samples, n_outputs)
True labels for X.</p>
<p>sample_weight : array-like of shape (n_samples,), default=None
Sample weights.</p>
<h2 id="returns_107">Returns<a class="headerlink" href="#returns_107" title="Permanent link">&para;</a></h2>
<p>score : float
Mean accuracy of self.predict(X) wrt. y.</p>
<div class="highlight"><pre><span></span><code><span class="k">val</span> <span class="n">set_params</span> <span class="o">:</span> <span class="o">?</span><span class="n">params</span><span class="o">:(</span><span class="kt">string</span> <span class="o">*</span> <span class="nn">Py</span><span class="p">.</span><span class="nn">Object</span><span class="p">.</span><span class="n">t</span><span class="o">)</span> <span class="kt">list</span> <span class="o">-&gt;</span> <span class="o">[&gt;</span> <span class="n">tag</span><span class="o">]</span> <span class="nn">Obj</span><span class="p">.</span><span class="n">t</span> <span class="o">-&gt;</span> <span class="n">t</span>
</code></pre></div>

<p>Set the parameters of an estimator from the ensemble.</p>
<p>Valid parameter keys can be listed with <code>get_params()</code>.</p>
<h2 id="parameters_134">Parameters<a class="headerlink" href="#parameters_134" title="Permanent link">&para;</a></h2>
<p>**params : keyword arguments
Specific parameters using e.g.
<code>set_params(parameter_name=new_value)</code>. In addition, to setting the
parameters of the stacking estimator, the individual estimator of
the stacking estimators can also be set, or can be removed by
setting them to 'drop'.</p>
<div class="highlight"><pre><span></span><code><span class="k">val</span> <span class="n">transform</span> <span class="o">:</span> <span class="n">x</span><span class="o">:[&gt;`</span><span class="nc">ArrayLike</span><span class="o">]</span> <span class="nn">Np</span><span class="p">.</span><span class="nn">Obj</span><span class="p">.</span><span class="n">t</span> <span class="o">-&gt;</span> <span class="o">[&gt;</span> <span class="n">tag</span><span class="o">]</span> <span class="nn">Obj</span><span class="p">.</span><span class="n">t</span> <span class="o">-&gt;</span> <span class="o">[&gt;`</span><span class="nc">ArrayLike</span><span class="o">]</span> <span class="nn">Np</span><span class="p">.</span><span class="nn">Obj</span><span class="p">.</span><span class="n">t</span>
</code></pre></div>

<p>Return class labels or probabilities for X for each estimator.</p>
<h2 id="parameters_135">Parameters<a class="headerlink" href="#parameters_135" title="Permanent link">&para;</a></h2>
<p>X : {array-like, sparse matrix}, shape (n_samples, n_features)
Training vectors, where n_samples is the number of samples and
n_features is the number of features.</p>
<h2 id="returns_108">Returns<a class="headerlink" href="#returns_108" title="Permanent link">&para;</a></h2>
<p>probabilities_or_labels
If <code>voting='soft'</code> and <code>flatten_transform=True</code>:
returns array-like of shape (n_classifiers, n_samples *
n_classes), being class probabilities calculated by each
classifier.
If <code>voting='soft' and</code>flatten_transform=False<code>:
array-like of shape (n_classifiers, n_samples, n_classes)
If</code>voting='hard'`:
array-like of shape (n_samples, n_classifiers), being
class labels predicted by each classifier.</p>
<p>Attribute estimators_: get value or raise Not_found if None.</p>
<div class="highlight"><pre><span></span><code><span class="k">val</span> <span class="n">estimators_</span> <span class="o">:</span> <span class="n">t</span> <span class="o">-&gt;</span> <span class="nn">Py</span><span class="p">.</span><span class="nn">Object</span><span class="p">.</span><span class="n">t</span>
</code></pre></div>

<p>Attribute estimators_: get value as an option.</p>
<div class="highlight"><pre><span></span><code><span class="k">val</span> <span class="n">estimators_opt</span> <span class="o">:</span> <span class="n">t</span> <span class="o">-&gt;</span> <span class="o">(</span><span class="nn">Py</span><span class="p">.</span><span class="nn">Object</span><span class="p">.</span><span class="n">t</span><span class="o">)</span> <span class="n">option</span>
</code></pre></div>

<p>Attribute named_estimators_: get value or raise Not_found if None.</p>
<div class="highlight"><pre><span></span><code><span class="k">val</span> <span class="n">named_estimators_</span> <span class="o">:</span> <span class="n">t</span> <span class="o">-&gt;</span> <span class="nn">Dict</span><span class="p">.</span><span class="n">t</span>
</code></pre></div>

<p>Attribute named_estimators_: get value as an option.</p>
<div class="highlight"><pre><span></span><code><span class="k">val</span> <span class="n">named_estimators_opt</span> <span class="o">:</span> <span class="n">t</span> <span class="o">-&gt;</span> <span class="o">(</span><span class="nn">Dict</span><span class="p">.</span><span class="n">t</span><span class="o">)</span> <span class="n">option</span>
</code></pre></div>

<p>Attribute classes_: get value or raise Not_found if None.</p>
<div class="highlight"><pre><span></span><code><span class="k">val</span> <span class="n">classes_</span> <span class="o">:</span> <span class="n">t</span> <span class="o">-&gt;</span> <span class="o">[&gt;`</span><span class="nc">ArrayLike</span><span class="o">]</span> <span class="nn">Np</span><span class="p">.</span><span class="nn">Obj</span><span class="p">.</span><span class="n">t</span>
</code></pre></div>

<p>Attribute classes_: get value as an option.</p>
<div class="highlight"><pre><span></span><code><span class="k">val</span> <span class="n">classes_opt</span> <span class="o">:</span> <span class="n">t</span> <span class="o">-&gt;</span> <span class="o">([&gt;`</span><span class="nc">ArrayLike</span><span class="o">]</span> <span class="nn">Np</span><span class="p">.</span><span class="nn">Obj</span><span class="p">.</span><span class="n">t</span><span class="o">)</span> <span class="n">option</span>
</code></pre></div>

<p>Print the object to a human-readable representation.</p>
<div class="highlight"><pre><span></span><code><span class="k">val</span> <span class="n">to_string</span> <span class="o">:</span> <span class="n">t</span> <span class="o">-&gt;</span> <span class="kt">string</span>
</code></pre></div>

<p>Print the object to a human-readable representation.</p>
<div class="highlight"><pre><span></span><code><span class="k">val</span> <span class="n">show</span> <span class="o">:</span> <span class="n">t</span> <span class="o">-&gt;</span> <span class="kt">string</span>
</code></pre></div>

<p>Pretty-print the object to a formatter.</p>
<div class="highlight"><pre><span></span><code><span class="k">val</span> <span class="n">pp</span> <span class="o">:</span> <span class="nn">Format</span><span class="p">.</span><span class="n">formatter</span> <span class="o">-&gt;</span> <span class="n">t</span> <span class="o">-&gt;</span> <span class="kt">unit</span> <span class="o">[@@</span><span class="n">ocaml</span><span class="o">.</span><span class="n">toplevel_printer</span><span class="o">]</span>



<span class="k">module</span> <span class="nc">VotingRegressor</span> <span class="o">:</span> <span class="k">sig</span>
<span class="k">type</span> <span class="n">tag</span> <span class="o">=</span> <span class="o">[`</span><span class="nc">VotingRegressor</span><span class="o">]</span>
<span class="k">type</span> <span class="n">t</span> <span class="o">=</span> <span class="o">[`</span><span class="nc">BaseEstimator</span> <span class="o">|</span> <span class="o">`</span><span class="nc">MetaEstimatorMixin</span> <span class="o">|</span> <span class="o">`</span><span class="nc">Object</span> <span class="o">|</span> <span class="o">`</span><span class="nc">RegressorMixin</span> <span class="o">|</span> <span class="o">`</span><span class="nc">TransformerMixin</span> <span class="o">|</span> <span class="o">`</span><span class="nc">VotingRegressor</span><span class="o">]</span> <span class="nn">Obj</span><span class="p">.</span><span class="n">t</span>
<span class="k">val</span> <span class="n">of_pyobject</span> <span class="o">:</span> <span class="nn">Py</span><span class="p">.</span><span class="nn">Object</span><span class="p">.</span><span class="n">t</span> <span class="o">-&gt;</span> <span class="n">t</span>
<span class="k">val</span> <span class="n">to_pyobject</span> <span class="o">:</span> <span class="o">[&gt;</span> <span class="n">tag</span><span class="o">]</span> <span class="nn">Obj</span><span class="p">.</span><span class="n">t</span> <span class="o">-&gt;</span> <span class="nn">Py</span><span class="p">.</span><span class="nn">Object</span><span class="p">.</span><span class="n">t</span>

<span class="k">val</span> <span class="n">as_regressor</span> <span class="o">:</span> <span class="n">t</span> <span class="o">-&gt;</span> <span class="o">[`</span><span class="nc">RegressorMixin</span><span class="o">]</span> <span class="nn">Obj</span><span class="p">.</span><span class="n">t</span>
<span class="k">val</span> <span class="n">as_transformer</span> <span class="o">:</span> <span class="n">t</span> <span class="o">-&gt;</span> <span class="o">[`</span><span class="nc">TransformerMixin</span><span class="o">]</span> <span class="nn">Obj</span><span class="p">.</span><span class="n">t</span>
<span class="k">val</span> <span class="n">as_estimator</span> <span class="o">:</span> <span class="n">t</span> <span class="o">-&gt;</span> <span class="o">[`</span><span class="nc">BaseEstimator</span><span class="o">]</span> <span class="nn">Obj</span><span class="p">.</span><span class="n">t</span>
<span class="k">val</span> <span class="n">as_meta_estimator</span> <span class="o">:</span> <span class="n">t</span> <span class="o">-&gt;</span> <span class="o">[`</span><span class="nc">MetaEstimatorMixin</span><span class="o">]</span> <span class="nn">Obj</span><span class="p">.</span><span class="n">t</span>
<span class="k">val</span> <span class="n">create</span> <span class="o">:</span> <span class="o">?</span><span class="n">weights</span><span class="o">:[&gt;`</span><span class="nc">ArrayLike</span><span class="o">]</span> <span class="nn">Np</span><span class="p">.</span><span class="nn">Obj</span><span class="p">.</span><span class="n">t</span> <span class="o">-&gt;</span> <span class="o">?</span><span class="n">n_jobs</span><span class="o">:</span><span class="kt">int</span> <span class="o">-&gt;</span> <span class="n">estimators</span><span class="o">:(</span><span class="kt">string</span> <span class="o">*</span> <span class="o">[&gt;`</span><span class="nc">BaseEstimator</span><span class="o">]</span> <span class="nn">Np</span><span class="p">.</span><span class="nn">Obj</span><span class="p">.</span><span class="n">t</span><span class="o">)</span> <span class="kt">list</span> <span class="o">-&gt;</span> <span class="kt">unit</span> <span class="o">-&gt;</span> <span class="n">t</span>
</code></pre></div>

<p>Prediction voting regressor for unfitted estimators.</p>
<p>.. versionadded:: 0.21</p>
<p>A voting regressor is an ensemble meta-estimator that fits base
regressors each on the whole dataset. It, then, averages the individual
predictions to form a final prediction.</p>
<p>Read more in the :ref:<code>User Guide &lt;voting_regressor&gt;</code>.</p>
<h2 id="parameters_136">Parameters<a class="headerlink" href="#parameters_136" title="Permanent link">&para;</a></h2>
<p>estimators : list of (str, estimator) tuples
Invoking the <code>fit</code> method on the <code>VotingRegressor</code> will fit clones
of those original estimators that will be stored in the class attribute
<code>self.estimators_</code>. An estimator can be set to <code>'drop'</code> using
<code>set_params</code>.</p>
<p>.. deprecated:: 0.22
Using <code>None</code> to drop an estimator is deprecated in 0.22 and
support will be dropped in 0.24. Use the string <code>'drop'</code> instead.</p>
<p>weights : array-like, shape (n_regressors,), optional (default=<code>None</code>)
Sequence of weights (<code>float</code> or <code>int</code>) to weight the occurrences of
predicted values before averaging. Uses uniform weights if <code>None</code>.</p>
<p>n_jobs : int or None, optional (default=None)
The number of jobs to run in parallel for <code>fit</code>.
<code>None</code> means 1 unless in a :obj:<code>joblib.parallel_backend</code> context.
<code>-1</code> means using all processors. See :term:<code>Glossary &lt;n_jobs&gt;</code>
for more details.</p>
<h2 id="attributes_15">Attributes<a class="headerlink" href="#attributes_15" title="Permanent link">&para;</a></h2>
<p>estimators_ : list of regressors
The collection of fitted sub-estimators as defined in <code>estimators</code>
that are not 'drop'.</p>
<p>named_estimators_ : Bunch object, a dictionary with attribute access
Attribute to access any fitted sub-estimators by name.</p>
<p>.. versionadded:: 0.20</p>
<h2 id="see-also_10">See Also<a class="headerlink" href="#see-also_10" title="Permanent link">&para;</a></h2>
<p>VotingClassifier: Soft Voting/Majority Rule classifier.</p>
<h2 id="examples_11">Examples<a class="headerlink" href="#examples_11" title="Permanent link">&para;</a></h2>
<blockquote>
<blockquote>
<blockquote>
<p>import numpy as np
from sklearn.linear_model import LinearRegression
from sklearn.ensemble import RandomForestRegressor
from sklearn.ensemble import VotingRegressor
r1 = LinearRegression()
r2 = RandomForestRegressor(n_estimators=10, random_state=1)
X = np.array([[1, 1], [2, 4], [3, 9], [4, 16], [5, 25], [6, 36]])
y = np.array([2, 6, 12, 20, 30, 42])
er = VotingRegressor([('lr', r1), ('rf', r2)])
print(er.fit(X, y).predict(X))
[ 3.3  5.7 11.8 19.7 28.  40.3]</p>
</blockquote>
</blockquote>
</blockquote>
<div class="highlight"><pre><span></span><code><span class="k">val</span> <span class="n">fit</span> <span class="o">:</span> <span class="o">?</span><span class="n">sample_weight</span><span class="o">:[&gt;`</span><span class="nc">ArrayLike</span><span class="o">]</span> <span class="nn">Np</span><span class="p">.</span><span class="nn">Obj</span><span class="p">.</span><span class="n">t</span> <span class="o">-&gt;</span> <span class="n">x</span><span class="o">:[&gt;`</span><span class="nc">ArrayLike</span><span class="o">]</span> <span class="nn">Np</span><span class="p">.</span><span class="nn">Obj</span><span class="p">.</span><span class="n">t</span> <span class="o">-&gt;</span> <span class="n">y</span><span class="o">:[&gt;`</span><span class="nc">ArrayLike</span><span class="o">]</span> <span class="nn">Np</span><span class="p">.</span><span class="nn">Obj</span><span class="p">.</span><span class="n">t</span> <span class="o">-&gt;</span> <span class="o">[&gt;</span> <span class="n">tag</span><span class="o">]</span> <span class="nn">Obj</span><span class="p">.</span><span class="n">t</span> <span class="o">-&gt;</span> <span class="n">t</span>
</code></pre></div>

<p>Fit the estimators.</p>
<h2 id="parameters_137">Parameters<a class="headerlink" href="#parameters_137" title="Permanent link">&para;</a></h2>
<p>X : {array-like, sparse matrix}, shape (n_samples, n_features)
Training vectors, where n_samples is the number of samples and
n_features is the number of features.</p>
<p>y : array-like, shape (n_samples,)
Target values.</p>
<p>sample_weight : array-like, shape (n_samples,) or None
Sample weights. If None, then samples are equally weighted.
Note that this is supported only if all underlying estimators
support sample weights.</p>
<h2 id="returns_109">Returns<a class="headerlink" href="#returns_109" title="Permanent link">&para;</a></h2>
<p>self : object
Fitted estimator.</p>
<div class="highlight"><pre><span></span><code><span class="k">val</span> <span class="n">fit_transform</span> <span class="o">:</span> <span class="o">?</span><span class="n">y</span><span class="o">:[&gt;`</span><span class="nc">ArrayLike</span><span class="o">]</span> <span class="nn">Np</span><span class="p">.</span><span class="nn">Obj</span><span class="p">.</span><span class="n">t</span> <span class="o">-&gt;</span> <span class="o">?</span><span class="n">fit_params</span><span class="o">:(</span><span class="kt">string</span> <span class="o">*</span> <span class="nn">Py</span><span class="p">.</span><span class="nn">Object</span><span class="p">.</span><span class="n">t</span><span class="o">)</span> <span class="kt">list</span> <span class="o">-&gt;</span> <span class="n">x</span><span class="o">:[&gt;`</span><span class="nc">ArrayLike</span><span class="o">]</span> <span class="nn">Np</span><span class="p">.</span><span class="nn">Obj</span><span class="p">.</span><span class="n">t</span> <span class="o">-&gt;</span> <span class="o">[&gt;</span> <span class="n">tag</span><span class="o">]</span> <span class="nn">Obj</span><span class="p">.</span><span class="n">t</span> <span class="o">-&gt;</span> <span class="o">[&gt;`</span><span class="nc">ArrayLike</span><span class="o">]</span> <span class="nn">Np</span><span class="p">.</span><span class="nn">Obj</span><span class="p">.</span><span class="n">t</span>
</code></pre></div>

<p>Fit to data, then transform it.</p>
<p>Fits transformer to X and y with optional parameters fit_params
and returns a transformed version of X.</p>
<h2 id="parameters_138">Parameters<a class="headerlink" href="#parameters_138" title="Permanent link">&para;</a></h2>
<p>X : numpy array of shape [n_samples, n_features]
Training set.</p>
<p>y : numpy array of shape [n_samples]
Target values.</p>
<p>**fit_params : dict
Additional fit parameters.</p>
<h2 id="returns_110">Returns<a class="headerlink" href="#returns_110" title="Permanent link">&para;</a></h2>
<p>X_new : numpy array of shape [n_samples, n_features_new]
Transformed array.</p>
<div class="highlight"><pre><span></span><code><span class="k">val</span> <span class="n">get_params</span> <span class="o">:</span> <span class="o">?</span><span class="n">deep</span><span class="o">:</span><span class="kt">bool</span> <span class="o">-&gt;</span> <span class="o">[&gt;</span> <span class="n">tag</span><span class="o">]</span> <span class="nn">Obj</span><span class="p">.</span><span class="n">t</span> <span class="o">-&gt;</span> <span class="nn">Py</span><span class="p">.</span><span class="nn">Object</span><span class="p">.</span><span class="n">t</span>
</code></pre></div>

<p>Get the parameters of an estimator from the ensemble.</p>
<h2 id="parameters_139">Parameters<a class="headerlink" href="#parameters_139" title="Permanent link">&para;</a></h2>
<p>deep : bool
Setting it to True gets the various classifiers and the parameters
of the classifiers as well.</p>
<div class="highlight"><pre><span></span><code><span class="k">val</span> <span class="n">predict</span> <span class="o">:</span> <span class="n">x</span><span class="o">:[&gt;`</span><span class="nc">ArrayLike</span><span class="o">]</span> <span class="nn">Np</span><span class="p">.</span><span class="nn">Obj</span><span class="p">.</span><span class="n">t</span> <span class="o">-&gt;</span> <span class="o">[&gt;</span> <span class="n">tag</span><span class="o">]</span> <span class="nn">Obj</span><span class="p">.</span><span class="n">t</span> <span class="o">-&gt;</span> <span class="o">[&gt;`</span><span class="nc">ArrayLike</span><span class="o">]</span> <span class="nn">Np</span><span class="p">.</span><span class="nn">Obj</span><span class="p">.</span><span class="n">t</span>
</code></pre></div>

<p>Predict regression target for X.</p>
<p>The predicted regression target of an input sample is computed as the
mean predicted regression targets of the estimators in the ensemble.</p>
<h2 id="parameters_140">Parameters<a class="headerlink" href="#parameters_140" title="Permanent link">&para;</a></h2>
<p>X : {array-like, sparse matrix} of shape (n_samples, n_features)
The input samples.</p>
<h2 id="returns_111">Returns<a class="headerlink" href="#returns_111" title="Permanent link">&para;</a></h2>
<p>y : array of shape (n_samples,)
The predicted values.</p>
<div class="highlight"><pre><span></span><code><span class="k">val</span> <span class="n">score</span> <span class="o">:</span> <span class="o">?</span><span class="n">sample_weight</span><span class="o">:[&gt;`</span><span class="nc">ArrayLike</span><span class="o">]</span> <span class="nn">Np</span><span class="p">.</span><span class="nn">Obj</span><span class="p">.</span><span class="n">t</span> <span class="o">-&gt;</span> <span class="n">x</span><span class="o">:[&gt;`</span><span class="nc">ArrayLike</span><span class="o">]</span> <span class="nn">Np</span><span class="p">.</span><span class="nn">Obj</span><span class="p">.</span><span class="n">t</span> <span class="o">-&gt;</span> <span class="n">y</span><span class="o">:[&gt;`</span><span class="nc">ArrayLike</span><span class="o">]</span> <span class="nn">Np</span><span class="p">.</span><span class="nn">Obj</span><span class="p">.</span><span class="n">t</span> <span class="o">-&gt;</span> <span class="o">[&gt;</span> <span class="n">tag</span><span class="o">]</span> <span class="nn">Obj</span><span class="p">.</span><span class="n">t</span> <span class="o">-&gt;</span> <span class="kt">float</span>
</code></pre></div>

<p>Return the coefficient of determination R^2 of the prediction.</p>
<p>The coefficient R^2 is defined as (1 - u/v), where u is the residual
sum of squares ((y_true - y_pred) <strong> 2).sum() and v is the total
sum of squares ((y_true - y_true.mean()) </strong> 2).sum().
The best possible score is 1.0 and it can be negative (because the
model can be arbitrarily worse). A constant model that always
predicts the expected value of y, disregarding the input features,
would get a R^2 score of 0.0.</p>
<h2 id="parameters_141">Parameters<a class="headerlink" href="#parameters_141" title="Permanent link">&para;</a></h2>
<p>X : array-like of shape (n_samples, n_features)
Test samples. For some estimators this may be a
precomputed kernel matrix or a list of generic objects instead,
shape = (n_samples, n_samples_fitted),
where n_samples_fitted is the number of
samples used in the fitting for the estimator.</p>
<p>y : array-like of shape (n_samples,) or (n_samples, n_outputs)
True values for X.</p>
<p>sample_weight : array-like of shape (n_samples,), default=None
Sample weights.</p>
<h2 id="returns_112">Returns<a class="headerlink" href="#returns_112" title="Permanent link">&para;</a></h2>
<p>score : float
R^2 of self.predict(X) wrt. y.</p>
<h2 id="notes_14">Notes<a class="headerlink" href="#notes_14" title="Permanent link">&para;</a></h2>
<p>The R2 score used when calling <code>score</code> on a regressor will use
<code>multioutput='uniform_average'</code> from version 0.23 to keep consistent
with :func:<code>~sklearn.metrics.r2_score</code>. This will influence the
<code>score</code> method of all the multioutput regressors (except for
:class:<code>~sklearn.multioutput.MultiOutputRegressor</code>). To specify the
default value manually and avoid the warning, please either call
:func:<code>~sklearn.metrics.r2_score</code> directly or make a custom scorer with
:func:<code>~sklearn.metrics.make_scorer</code> (the built-in scorer <code>'r2'</code> uses
<code>multioutput='uniform_average'</code>).</p>
<div class="highlight"><pre><span></span><code><span class="k">val</span> <span class="n">set_params</span> <span class="o">:</span> <span class="o">?</span><span class="n">params</span><span class="o">:(</span><span class="kt">string</span> <span class="o">*</span> <span class="nn">Py</span><span class="p">.</span><span class="nn">Object</span><span class="p">.</span><span class="n">t</span><span class="o">)</span> <span class="kt">list</span> <span class="o">-&gt;</span> <span class="o">[&gt;</span> <span class="n">tag</span><span class="o">]</span> <span class="nn">Obj</span><span class="p">.</span><span class="n">t</span> <span class="o">-&gt;</span> <span class="n">t</span>
</code></pre></div>

<p>Set the parameters of an estimator from the ensemble.</p>
<p>Valid parameter keys can be listed with <code>get_params()</code>.</p>
<h2 id="parameters_142">Parameters<a class="headerlink" href="#parameters_142" title="Permanent link">&para;</a></h2>
<p>**params : keyword arguments
Specific parameters using e.g.
<code>set_params(parameter_name=new_value)</code>. In addition, to setting the
parameters of the stacking estimator, the individual estimator of
the stacking estimators can also be set, or can be removed by
setting them to 'drop'.</p>
<div class="highlight"><pre><span></span><code><span class="k">val</span> <span class="n">transform</span> <span class="o">:</span> <span class="n">x</span><span class="o">:[&gt;`</span><span class="nc">ArrayLike</span><span class="o">]</span> <span class="nn">Np</span><span class="p">.</span><span class="nn">Obj</span><span class="p">.</span><span class="n">t</span> <span class="o">-&gt;</span> <span class="o">[&gt;</span> <span class="n">tag</span><span class="o">]</span> <span class="nn">Obj</span><span class="p">.</span><span class="n">t</span> <span class="o">-&gt;</span> <span class="o">[&gt;`</span><span class="nc">ArrayLike</span><span class="o">]</span> <span class="nn">Np</span><span class="p">.</span><span class="nn">Obj</span><span class="p">.</span><span class="n">t</span>
</code></pre></div>

<p>Return predictions for X for each estimator.</p>
<h2 id="parameters_143">Parameters<a class="headerlink" href="#parameters_143" title="Permanent link">&para;</a></h2>
<p>X : {array-like, sparse matrix}, shape (n_samples, n_features)
The input samples.</p>
<h2 id="returns_113">Returns<a class="headerlink" href="#returns_113" title="Permanent link">&para;</a></h2>
<p>predictions: array of shape (n_samples, n_classifiers)
Values predicted by each regressor.</p>
<p>Attribute estimators_: get value or raise Not_found if None.</p>
<div class="highlight"><pre><span></span><code><span class="k">val</span> <span class="n">estimators_</span> <span class="o">:</span> <span class="n">t</span> <span class="o">-&gt;</span> <span class="o">[`</span><span class="nc">Object</span><span class="o">|`</span><span class="nc">RegressorMixin</span><span class="o">]</span> <span class="nn">Np</span><span class="p">.</span><span class="nn">Obj</span><span class="p">.</span><span class="n">t</span> <span class="kt">list</span>
</code></pre></div>

<p>Attribute estimators_: get value as an option.</p>
<div class="highlight"><pre><span></span><code><span class="k">val</span> <span class="n">estimators_opt</span> <span class="o">:</span> <span class="n">t</span> <span class="o">-&gt;</span> <span class="o">([`</span><span class="nc">Object</span><span class="o">|`</span><span class="nc">RegressorMixin</span><span class="o">]</span> <span class="nn">Np</span><span class="p">.</span><span class="nn">Obj</span><span class="p">.</span><span class="n">t</span> <span class="kt">list</span><span class="o">)</span> <span class="n">option</span>
</code></pre></div>

<p>Attribute named_estimators_: get value or raise Not_found if None.</p>
<div class="highlight"><pre><span></span><code><span class="k">val</span> <span class="n">named_estimators_</span> <span class="o">:</span> <span class="n">t</span> <span class="o">-&gt;</span> <span class="nn">Dict</span><span class="p">.</span><span class="n">t</span>
</code></pre></div>

<p>Attribute named_estimators_: get value as an option.</p>
<div class="highlight"><pre><span></span><code><span class="k">val</span> <span class="n">named_estimators_opt</span> <span class="o">:</span> <span class="n">t</span> <span class="o">-&gt;</span> <span class="o">(</span><span class="nn">Dict</span><span class="p">.</span><span class="n">t</span><span class="o">)</span> <span class="n">option</span>
</code></pre></div>

<p>Print the object to a human-readable representation.</p>
<div class="highlight"><pre><span></span><code><span class="k">val</span> <span class="n">to_string</span> <span class="o">:</span> <span class="n">t</span> <span class="o">-&gt;</span> <span class="kt">string</span>
</code></pre></div>

<p>Print the object to a human-readable representation.</p>
<div class="highlight"><pre><span></span><code><span class="k">val</span> <span class="n">show</span> <span class="o">:</span> <span class="n">t</span> <span class="o">-&gt;</span> <span class="kt">string</span>
</code></pre></div>

<p>Pretty-print the object to a formatter.</p>
<div class="highlight"><pre><span></span><code><span class="k">val</span> <span class="n">pp</span> <span class="o">:</span> <span class="nn">Format</span><span class="p">.</span><span class="n">formatter</span> <span class="o">-&gt;</span> <span class="n">t</span> <span class="o">-&gt;</span> <span class="kt">unit</span> <span class="o">[@@</span><span class="n">ocaml</span><span class="o">.</span><span class="n">toplevel_printer</span><span class="o">]</span>



<span class="k">module</span> <span class="nc">Partial_dependence</span> <span class="o">:</span> <span class="k">sig</span>
</code></pre></div>

<p>Get an attribute of this module as a Py.Object.t.
This is useful to pass a Python function to another function.</p>
<div class="highlight"><pre><span></span><code><span class="k">val</span> <span class="n">get_py</span> <span class="o">:</span> <span class="kt">string</span> <span class="o">-&gt;</span> <span class="nn">Py</span><span class="p">.</span><span class="nn">Object</span><span class="p">.</span><span class="n">t</span>

<span class="k">module</span> <span class="nc">BaseGradientBoosting</span> <span class="o">:</span> <span class="k">sig</span>
<span class="k">type</span> <span class="n">tag</span> <span class="o">=</span> <span class="o">[`</span><span class="nc">BaseGradientBoosting</span><span class="o">]</span>
<span class="k">type</span> <span class="n">t</span> <span class="o">=</span> <span class="o">[`</span><span class="nc">BaseEnsemble</span> <span class="o">|</span> <span class="o">`</span><span class="nc">BaseEstimator</span> <span class="o">|</span> <span class="o">`</span><span class="nc">BaseGradientBoosting</span> <span class="o">|</span> <span class="o">`</span><span class="nc">MetaEstimatorMixin</span> <span class="o">|</span> <span class="o">`</span><span class="nc">Object</span><span class="o">]</span> <span class="nn">Obj</span><span class="p">.</span><span class="n">t</span>
<span class="k">val</span> <span class="n">of_pyobject</span> <span class="o">:</span> <span class="nn">Py</span><span class="p">.</span><span class="nn">Object</span><span class="p">.</span><span class="n">t</span> <span class="o">-&gt;</span> <span class="n">t</span>
<span class="k">val</span> <span class="n">to_pyobject</span> <span class="o">:</span> <span class="o">[&gt;</span> <span class="n">tag</span><span class="o">]</span> <span class="nn">Obj</span><span class="p">.</span><span class="n">t</span> <span class="o">-&gt;</span> <span class="nn">Py</span><span class="p">.</span><span class="nn">Object</span><span class="p">.</span><span class="n">t</span>

<span class="k">val</span> <span class="n">as_ensemble</span> <span class="o">:</span> <span class="n">t</span> <span class="o">-&gt;</span> <span class="o">[`</span><span class="nc">BaseEnsemble</span><span class="o">]</span> <span class="nn">Obj</span><span class="p">.</span><span class="n">t</span>
<span class="k">val</span> <span class="n">as_estimator</span> <span class="o">:</span> <span class="n">t</span> <span class="o">-&gt;</span> <span class="o">[`</span><span class="nc">BaseEstimator</span><span class="o">]</span> <span class="nn">Obj</span><span class="p">.</span><span class="n">t</span>
<span class="k">val</span> <span class="n">as_meta_estimator</span> <span class="o">:</span> <span class="n">t</span> <span class="o">-&gt;</span> <span class="o">[`</span><span class="nc">MetaEstimatorMixin</span><span class="o">]</span> <span class="nn">Obj</span><span class="p">.</span><span class="n">t</span>
<span class="k">val</span> <span class="n">get_item</span> <span class="o">:</span> <span class="n">index</span><span class="o">:</span><span class="nn">Py</span><span class="p">.</span><span class="nn">Object</span><span class="p">.</span><span class="n">t</span> <span class="o">-&gt;</span> <span class="o">[&gt;</span> <span class="n">tag</span><span class="o">]</span> <span class="nn">Obj</span><span class="p">.</span><span class="n">t</span> <span class="o">-&gt;</span> <span class="nn">Py</span><span class="p">.</span><span class="nn">Object</span><span class="p">.</span><span class="n">t</span>
</code></pre></div>

<p>Return the index'th estimator in the ensemble.</p>
<div class="highlight"><pre><span></span><code><span class="k">val</span> <span class="n">iter</span> <span class="o">:</span> <span class="o">[&gt;</span> <span class="n">tag</span><span class="o">]</span> <span class="nn">Obj</span><span class="p">.</span><span class="n">t</span> <span class="o">-&gt;</span> <span class="nn">Dict</span><span class="p">.</span><span class="n">t</span> <span class="nn">Seq</span><span class="p">.</span><span class="n">t</span>
</code></pre></div>

<p>Return iterator over estimators in the ensemble.</p>
<div class="highlight"><pre><span></span><code><span class="k">val</span> <span class="n">apply</span> <span class="o">:</span> <span class="n">x</span><span class="o">:[&gt;`</span><span class="nc">ArrayLike</span><span class="o">]</span> <span class="nn">Np</span><span class="p">.</span><span class="nn">Obj</span><span class="p">.</span><span class="n">t</span> <span class="o">-&gt;</span> <span class="o">[&gt;</span> <span class="n">tag</span><span class="o">]</span> <span class="nn">Obj</span><span class="p">.</span><span class="n">t</span> <span class="o">-&gt;</span> <span class="o">[&gt;`</span><span class="nc">ArrayLike</span><span class="o">]</span> <span class="nn">Np</span><span class="p">.</span><span class="nn">Obj</span><span class="p">.</span><span class="n">t</span>
</code></pre></div>

<p>Apply trees in the ensemble to X, return leaf indices.</p>
<p>.. versionadded:: 0.17</p>
<h2 id="parameters_144">Parameters<a class="headerlink" href="#parameters_144" title="Permanent link">&para;</a></h2>
<p>X : {array-like, sparse matrix}, shape (n_samples, n_features)
The input samples. Internally, its dtype will be converted to
<code>dtype=np.float32</code>. If a sparse matrix is provided, it will
be converted to a sparse <code>csr_matrix</code>.</p>
<h2 id="returns_114">Returns<a class="headerlink" href="#returns_114" title="Permanent link">&para;</a></h2>
<p>X_leaves : array-like, shape (n_samples, n_estimators, n_classes)
For each datapoint x in X and for each tree in the ensemble,
return the index of the leaf x ends up in each estimator.
In the case of binary classification n_classes is 1.</p>
<div class="highlight"><pre><span></span><code><span class="k">val</span> <span class="n">fit</span> <span class="o">:</span> <span class="o">?</span><span class="n">sample_weight</span><span class="o">:[&gt;`</span><span class="nc">ArrayLike</span><span class="o">]</span> <span class="nn">Np</span><span class="p">.</span><span class="nn">Obj</span><span class="p">.</span><span class="n">t</span> <span class="o">-&gt;</span> <span class="o">?</span><span class="n">monitor</span><span class="o">:</span><span class="nn">Py</span><span class="p">.</span><span class="nn">Object</span><span class="p">.</span><span class="n">t</span> <span class="o">-&gt;</span> <span class="n">x</span><span class="o">:[&gt;`</span><span class="nc">ArrayLike</span><span class="o">]</span> <span class="nn">Np</span><span class="p">.</span><span class="nn">Obj</span><span class="p">.</span><span class="n">t</span> <span class="o">-&gt;</span> <span class="n">y</span><span class="o">:[&gt;`</span><span class="nc">ArrayLike</span><span class="o">]</span> <span class="nn">Np</span><span class="p">.</span><span class="nn">Obj</span><span class="p">.</span><span class="n">t</span> <span class="o">-&gt;</span> <span class="o">[&gt;</span> <span class="n">tag</span><span class="o">]</span> <span class="nn">Obj</span><span class="p">.</span><span class="n">t</span> <span class="o">-&gt;</span> <span class="n">t</span>
</code></pre></div>

<p>Fit the gradient boosting model.</p>
<h2 id="parameters_145">Parameters<a class="headerlink" href="#parameters_145" title="Permanent link">&para;</a></h2>
<p>X : {array-like, sparse matrix}, shape (n_samples, n_features)
The input samples. Internally, it will be converted to
<code>dtype=np.float32</code> and if a sparse matrix is provided
to a sparse <code>csr_matrix</code>.</p>
<p>y : array-like, shape (n_samples,)
Target values (strings or integers in classification, real numbers
in regression)
For classification, labels must correspond to classes.</p>
<p>sample_weight : array-like, shape (n_samples,) or None
Sample weights. If None, then samples are equally weighted. Splits
that would create child nodes with net zero or negative weight are
ignored while searching for a split in each node. In the case of
classification, splits are also ignored if they would result in any
single class carrying a negative weight in either child node.</p>
<p>monitor : callable, optional
The monitor is called after each iteration with the current
iteration, a reference to the estimator and the local variables of
<code>_fit_stages</code> as keyword arguments <code>callable(i, self,
locals())</code>. If the callable returns <code>True</code> the fitting procedure
is stopped. The monitor can be used for various things such as
computing held-out estimates, early stopping, model introspect, and
snapshoting.</p>
<h2 id="returns_115">Returns<a class="headerlink" href="#returns_115" title="Permanent link">&para;</a></h2>
<p>self : object</p>
<div class="highlight"><pre><span></span><code><span class="k">val</span> <span class="n">get_params</span> <span class="o">:</span> <span class="o">?</span><span class="n">deep</span><span class="o">:</span><span class="kt">bool</span> <span class="o">-&gt;</span> <span class="o">[&gt;</span> <span class="n">tag</span><span class="o">]</span> <span class="nn">Obj</span><span class="p">.</span><span class="n">t</span> <span class="o">-&gt;</span> <span class="nn">Dict</span><span class="p">.</span><span class="n">t</span>
</code></pre></div>

<p>Get parameters for this estimator.</p>
<h2 id="parameters_146">Parameters<a class="headerlink" href="#parameters_146" title="Permanent link">&para;</a></h2>
<p>deep : bool, default=True
If True, will return the parameters for this estimator and
contained subobjects that are estimators.</p>
<h2 id="returns_116">Returns<a class="headerlink" href="#returns_116" title="Permanent link">&para;</a></h2>
<p>params : mapping of string to any
Parameter names mapped to their values.</p>
<div class="highlight"><pre><span></span><code><span class="k">val</span> <span class="n">set_params</span> <span class="o">:</span> <span class="o">?</span><span class="n">params</span><span class="o">:(</span><span class="kt">string</span> <span class="o">*</span> <span class="nn">Py</span><span class="p">.</span><span class="nn">Object</span><span class="p">.</span><span class="n">t</span><span class="o">)</span> <span class="kt">list</span> <span class="o">-&gt;</span> <span class="o">[&gt;</span> <span class="n">tag</span><span class="o">]</span> <span class="nn">Obj</span><span class="p">.</span><span class="n">t</span> <span class="o">-&gt;</span> <span class="n">t</span>
</code></pre></div>

<p>Set the parameters of this estimator.</p>
<p>The method works on simple estimators as well as on nested objects
(such as pipelines). The latter have parameters of the form
<code>&lt;component&gt;__&lt;parameter&gt;</code> so that it's possible to update each
component of a nested object.</p>
<h2 id="parameters_147">Parameters<a class="headerlink" href="#parameters_147" title="Permanent link">&para;</a></h2>
<p>**params : dict
Estimator parameters.</p>
<h2 id="returns_117">Returns<a class="headerlink" href="#returns_117" title="Permanent link">&para;</a></h2>
<p>self : object
Estimator instance.</p>
<p>Print the object to a human-readable representation.</p>
<div class="highlight"><pre><span></span><code><span class="k">val</span> <span class="n">to_string</span> <span class="o">:</span> <span class="n">t</span> <span class="o">-&gt;</span> <span class="kt">string</span>
</code></pre></div>

<p>Print the object to a human-readable representation.</p>
<div class="highlight"><pre><span></span><code><span class="k">val</span> <span class="n">show</span> <span class="o">:</span> <span class="n">t</span> <span class="o">-&gt;</span> <span class="kt">string</span>
</code></pre></div>

<p>Pretty-print the object to a formatter.</p>
<div class="highlight"><pre><span></span><code><span class="k">val</span> <span class="n">pp</span> <span class="o">:</span> <span class="nn">Format</span><span class="p">.</span><span class="n">formatter</span> <span class="o">-&gt;</span> <span class="n">t</span> <span class="o">-&gt;</span> <span class="kt">unit</span> <span class="o">[@@</span><span class="n">ocaml</span><span class="o">.</span><span class="n">toplevel_printer</span><span class="o">]</span>



<span class="k">module</span> <span class="nc">DTYPE</span> <span class="o">:</span> <span class="k">sig</span>
<span class="k">type</span> <span class="n">tag</span> <span class="o">=</span> <span class="o">[`</span><span class="nc">Float32</span><span class="o">]</span>
<span class="k">type</span> <span class="n">t</span> <span class="o">=</span> <span class="o">[`</span><span class="nc">Float32</span> <span class="o">|</span> <span class="o">`</span><span class="nc">Object</span><span class="o">]</span> <span class="nn">Obj</span><span class="p">.</span><span class="n">t</span>
<span class="k">val</span> <span class="n">of_pyobject</span> <span class="o">:</span> <span class="nn">Py</span><span class="p">.</span><span class="nn">Object</span><span class="p">.</span><span class="n">t</span> <span class="o">-&gt;</span> <span class="n">t</span>
<span class="k">val</span> <span class="n">to_pyobject</span> <span class="o">:</span> <span class="o">[&gt;</span> <span class="n">tag</span><span class="o">]</span> <span class="nn">Obj</span><span class="p">.</span><span class="n">t</span> <span class="o">-&gt;</span> <span class="nn">Py</span><span class="p">.</span><span class="nn">Object</span><span class="p">.</span><span class="n">t</span>

<span class="k">val</span> <span class="n">get_item</span> <span class="o">:</span> <span class="n">key</span><span class="o">:</span><span class="nn">Py</span><span class="p">.</span><span class="nn">Object</span><span class="p">.</span><span class="n">t</span> <span class="o">-&gt;</span> <span class="o">[&gt;</span> <span class="n">tag</span><span class="o">]</span> <span class="nn">Obj</span><span class="p">.</span><span class="n">t</span> <span class="o">-&gt;</span> <span class="nn">Py</span><span class="p">.</span><span class="nn">Object</span><span class="p">.</span><span class="n">t</span>
</code></pre></div>

<p>Return self[key].</p>
<div class="highlight"><pre><span></span><code><span class="k">val</span> <span class="n">newbyteorder</span> <span class="o">:</span> <span class="o">?</span><span class="n">new_order</span><span class="o">:</span><span class="kt">string</span> <span class="o">-&gt;</span> <span class="o">[&gt;</span> <span class="n">tag</span><span class="o">]</span> <span class="nn">Obj</span><span class="p">.</span><span class="n">t</span> <span class="o">-&gt;</span> <span class="nn">Np</span><span class="p">.</span><span class="nn">Dtype</span><span class="p">.</span><span class="n">t</span>
</code></pre></div>

<p>newbyteorder(new_order='S')</p>
<p>Return a new <code>dtype</code> with a different byte order.</p>
<p>Changes are also made in all fields and sub-arrays of the data type.</p>
<p>The <code>new_order</code> code can be any from the following:</p>
<ul>
<li>'S' - swap dtype from current to opposite endian</li>
<li>{'&lt;', 'L'} - little endian</li>
<li>{'&gt;', 'B'} - big endian</li>
<li>{'=', 'N'} - native order</li>
<li>{'|', 'I'} - ignore (no change to byte order)</li>
</ul>
<h2 id="parameters_148">Parameters<a class="headerlink" href="#parameters_148" title="Permanent link">&para;</a></h2>
<p>new_order : str, optional
Byte order to force; a value from the byte order specifications
above.  The default value ('S') results in swapping the current
byte order. The code does a case-insensitive check on the first
letter of <code>new_order</code> for the alternatives above.  For example,
any of 'B' or 'b' or 'biggish' are valid to specify big-endian.</p>
<h2 id="returns_118">Returns<a class="headerlink" href="#returns_118" title="Permanent link">&para;</a></h2>
<p>new_dtype : dtype
New <code>dtype</code> object with the given change to the byte order.</p>
<p>Print the object to a human-readable representation.</p>
<div class="highlight"><pre><span></span><code><span class="k">val</span> <span class="n">to_string</span> <span class="o">:</span> <span class="n">t</span> <span class="o">-&gt;</span> <span class="kt">string</span>
</code></pre></div>

<p>Print the object to a human-readable representation.</p>
<div class="highlight"><pre><span></span><code><span class="k">val</span> <span class="n">show</span> <span class="o">:</span> <span class="n">t</span> <span class="o">-&gt;</span> <span class="kt">string</span>
</code></pre></div>

<p>Pretty-print the object to a formatter.</p>
<div class="highlight"><pre><span></span><code><span class="k">val</span> <span class="n">pp</span> <span class="o">:</span> <span class="nn">Format</span><span class="p">.</span><span class="n">formatter</span> <span class="o">-&gt;</span> <span class="n">t</span> <span class="o">-&gt;</span> <span class="kt">unit</span> <span class="o">[@@</span><span class="n">ocaml</span><span class="o">.</span><span class="n">toplevel_printer</span><span class="o">]</span>



<span class="k">module</span> <span class="nc">Count</span> <span class="o">:</span> <span class="k">sig</span>
<span class="k">type</span> <span class="n">tag</span> <span class="o">=</span> <span class="o">[`</span><span class="nc">Count</span><span class="o">]</span>
<span class="k">type</span> <span class="n">t</span> <span class="o">=</span> <span class="o">[`</span><span class="nc">Count</span> <span class="o">|</span> <span class="o">`</span><span class="nc">Object</span><span class="o">]</span> <span class="nn">Obj</span><span class="p">.</span><span class="n">t</span>
<span class="k">val</span> <span class="n">of_pyobject</span> <span class="o">:</span> <span class="nn">Py</span><span class="p">.</span><span class="nn">Object</span><span class="p">.</span><span class="n">t</span> <span class="o">-&gt;</span> <span class="n">t</span>
<span class="k">val</span> <span class="n">to_pyobject</span> <span class="o">:</span> <span class="o">[&gt;</span> <span class="n">tag</span><span class="o">]</span> <span class="nn">Obj</span><span class="p">.</span><span class="n">t</span> <span class="o">-&gt;</span> <span class="nn">Py</span><span class="p">.</span><span class="nn">Object</span><span class="p">.</span><span class="n">t</span>

<span class="k">val</span> <span class="n">create</span> <span class="o">:</span> <span class="o">?</span><span class="n">start</span><span class="o">:</span><span class="nn">Py</span><span class="p">.</span><span class="nn">Object</span><span class="p">.</span><span class="n">t</span> <span class="o">-&gt;</span> <span class="o">?</span><span class="n">step</span><span class="o">:</span><span class="nn">Py</span><span class="p">.</span><span class="nn">Object</span><span class="p">.</span><span class="n">t</span> <span class="o">-&gt;</span> <span class="kt">unit</span> <span class="o">-&gt;</span> <span class="n">t</span>
</code></pre></div>

<p>Return a count object whose .<strong>next</strong>() method returns consecutive values.</p>
<p>Equivalent to:
def count(firstval=0, step=1):
x = firstval
while 1:
yield x
x += step</p>
<div class="highlight"><pre><span></span><code><span class="k">val</span> <span class="n">iter</span> <span class="o">:</span> <span class="o">[&gt;</span> <span class="n">tag</span><span class="o">]</span> <span class="nn">Obj</span><span class="p">.</span><span class="n">t</span> <span class="o">-&gt;</span> <span class="nn">Dict</span><span class="p">.</span><span class="n">t</span> <span class="nn">Seq</span><span class="p">.</span><span class="n">t</span>
</code></pre></div>

<p>Implement iter(self).</p>
<p>Print the object to a human-readable representation.</p>
<div class="highlight"><pre><span></span><code><span class="k">val</span> <span class="n">to_string</span> <span class="o">:</span> <span class="n">t</span> <span class="o">-&gt;</span> <span class="kt">string</span>
</code></pre></div>

<p>Print the object to a human-readable representation.</p>
<div class="highlight"><pre><span></span><code><span class="k">val</span> <span class="n">show</span> <span class="o">:</span> <span class="n">t</span> <span class="o">-&gt;</span> <span class="kt">string</span>
</code></pre></div>

<p>Pretty-print the object to a formatter.</p>
<div class="highlight"><pre><span></span><code><span class="k">val</span> <span class="n">pp</span> <span class="o">:</span> <span class="nn">Format</span><span class="p">.</span><span class="n">formatter</span> <span class="o">-&gt;</span> <span class="n">t</span> <span class="o">-&gt;</span> <span class="kt">unit</span> <span class="o">[@@</span><span class="n">ocaml</span><span class="o">.</span><span class="n">toplevel_printer</span><span class="o">]</span>



<span class="k">val</span> <span class="n">cartesian</span> <span class="o">:</span> <span class="o">?</span><span class="n">out</span><span class="o">:[&gt;`</span><span class="nc">ArrayLike</span><span class="o">]</span> <span class="nn">Np</span><span class="p">.</span><span class="nn">Obj</span><span class="p">.</span><span class="n">t</span> <span class="o">-&gt;</span> <span class="n">arrays</span><span class="o">:</span><span class="nn">Np</span><span class="p">.</span><span class="nn">Numpy</span><span class="p">.</span><span class="nn">Ndarray</span><span class="p">.</span><span class="nn">List</span><span class="p">.</span><span class="n">t</span> <span class="o">-&gt;</span> <span class="kt">unit</span> <span class="o">-&gt;</span> <span class="o">[&gt;`</span><span class="nc">ArrayLike</span><span class="o">]</span> <span class="nn">Np</span><span class="p">.</span><span class="nn">Obj</span><span class="p">.</span><span class="n">t</span>
</code></pre></div>

<p>Generate a cartesian product of input arrays.</p>
<h2 id="parameters_149">Parameters<a class="headerlink" href="#parameters_149" title="Permanent link">&para;</a></h2>
<p>arrays : list of array-like
1-D arrays to form the cartesian product of.
out : ndarray
Array to place the cartesian product in.</p>
<h2 id="returns_119">Returns<a class="headerlink" href="#returns_119" title="Permanent link">&para;</a></h2>
<p>out : ndarray
2-D array of shape (M, len(arrays)) containing cartesian products
formed of input arrays.</p>
<h2 id="examples_12">Examples<a class="headerlink" href="#examples_12" title="Permanent link">&para;</a></h2>
<blockquote>
<blockquote>
<blockquote>
<p>cartesian(([1, 2, 3], [4, 5], [6, 7]))
array([[1, 4, 6],
[1, 4, 7],
[1, 5, 6],
[1, 5, 7],
[2, 4, 6],
[2, 4, 7],
[2, 5, 6],
[2, 5, 7],
[3, 4, 6],
[3, 4, 7],
[3, 5, 6],
[3, 5, 7]])</p>
</blockquote>
</blockquote>
</blockquote>
<div class="highlight"><pre><span></span><code><span class="k">val</span> <span class="n">check_array</span> <span class="o">:</span> <span class="o">?</span><span class="n">accept_sparse</span><span class="o">:[`</span><span class="nc">StringList</span> <span class="k">of</span> <span class="kt">string</span> <span class="kt">list</span> <span class="o">|</span> <span class="o">`</span><span class="nc">S</span> <span class="k">of</span> <span class="kt">string</span> <span class="o">|</span> <span class="o">`</span><span class="nc">Bool</span> <span class="k">of</span> <span class="kt">bool</span><span class="o">]</span> <span class="o">-&gt;</span> <span class="o">?</span><span class="n">accept_large_sparse</span><span class="o">:</span><span class="kt">bool</span> <span class="o">-&gt;</span> <span class="o">?</span><span class="n">dtype</span><span class="o">:[`</span><span class="nc">S</span> <span class="k">of</span> <span class="kt">string</span> <span class="o">|</span> <span class="o">`</span><span class="nc">Dtype</span> <span class="k">of</span> <span class="nn">Np</span><span class="p">.</span><span class="nn">Dtype</span><span class="p">.</span><span class="n">t</span> <span class="o">|</span> <span class="o">`</span><span class="nc">Dtypes</span> <span class="k">of</span> <span class="nn">Np</span><span class="p">.</span><span class="nn">Dtype</span><span class="p">.</span><span class="n">t</span> <span class="kt">list</span> <span class="o">|</span> <span class="o">`</span><span class="nc">None</span><span class="o">]</span> <span class="o">-&gt;</span> <span class="o">?</span><span class="n">order</span><span class="o">:[`</span><span class="nc">F</span> <span class="o">|</span> <span class="o">`</span><span class="nc">C</span><span class="o">]</span> <span class="o">-&gt;</span> <span class="o">?</span><span class="n">copy</span><span class="o">:</span><span class="kt">bool</span> <span class="o">-&gt;</span> <span class="o">?</span><span class="n">force_all_finite</span><span class="o">:[`</span><span class="nc">Allow_nan</span> <span class="o">|</span> <span class="o">`</span><span class="nc">Bool</span> <span class="k">of</span> <span class="kt">bool</span><span class="o">]</span> <span class="o">-&gt;</span> <span class="o">?</span><span class="n">ensure_2d</span><span class="o">:</span><span class="kt">bool</span> <span class="o">-&gt;</span> <span class="o">?</span><span class="n">allow_nd</span><span class="o">:</span><span class="kt">bool</span> <span class="o">-&gt;</span> <span class="o">?</span><span class="n">ensure_min_samples</span><span class="o">:</span><span class="kt">int</span> <span class="o">-&gt;</span> <span class="o">?</span><span class="n">ensure_min_features</span><span class="o">:</span><span class="kt">int</span> <span class="o">-&gt;</span> <span class="o">?</span><span class="n">warn_on_dtype</span><span class="o">:</span><span class="kt">bool</span> <span class="o">-&gt;</span> <span class="o">?</span><span class="n">estimator</span><span class="o">:[&gt;`</span><span class="nc">BaseEstimator</span><span class="o">]</span> <span class="nn">Np</span><span class="p">.</span><span class="nn">Obj</span><span class="p">.</span><span class="n">t</span> <span class="o">-&gt;</span> <span class="kt">array</span><span class="o">:</span><span class="nn">Py</span><span class="p">.</span><span class="nn">Object</span><span class="p">.</span><span class="n">t</span> <span class="o">-&gt;</span> <span class="kt">unit</span> <span class="o">-&gt;</span> <span class="nn">Py</span><span class="p">.</span><span class="nn">Object</span><span class="p">.</span><span class="n">t</span>
</code></pre></div>

<p>Input validation on an array, list, sparse matrix or similar.</p>
<p>By default, the input is checked to be a non-empty 2D array containing
only finite values. If the dtype of the array is object, attempt
converting to float, raising on failure.</p>
<h2 id="parameters_150">Parameters<a class="headerlink" href="#parameters_150" title="Permanent link">&para;</a></h2>
<p>array : object
Input object to check / convert.</p>
<p>accept_sparse : string, boolean or list/tuple of strings (default=False)
String[s] representing allowed sparse matrix formats, such as 'csc',
'csr', etc. If the input is sparse but not in the allowed format,
it will be converted to the first listed format. True allows the input
to be any format. False means that a sparse matrix input will
raise an error.</p>
<p>accept_large_sparse : bool (default=True)
If a CSR, CSC, COO or BSR sparse matrix is supplied and accepted by
accept_sparse, accept_large_sparse=False will cause it to be accepted
only if its indices are stored with a 32-bit dtype.</p>
<p>.. versionadded:: 0.20</p>
<p>dtype : string, type, list of types or None (default='numeric')
Data type of result. If None, the dtype of the input is preserved.
If 'numeric', dtype is preserved unless array.dtype is object.
If dtype is a list of types, conversion on the first type is only
performed if the dtype of the input is not in the list.</p>
<p>order : 'F', 'C' or None (default=None)
Whether an array will be forced to be fortran or c-style.
When order is None (default), then if copy=False, nothing is ensured
about the memory layout of the output array; otherwise (copy=True)
the memory layout of the returned array is kept as close as possible
to the original array.</p>
<p>copy : boolean (default=False)
Whether a forced copy will be triggered. If copy=False, a copy might
be triggered by a conversion.</p>
<p>force_all_finite : boolean or 'allow-nan', (default=True)
Whether to raise an error on np.inf and np.nan in array. The
possibilities are:</p>
<ul>
<li>True: Force all values of array to be finite.</li>
<li>False: accept both np.inf and np.nan in array.</li>
<li>'allow-nan': accept only np.nan values in array. Values cannot
be infinite.</li>
</ul>
<p>For object dtyped data, only np.nan is checked and not np.inf.</p>
<p>.. versionadded:: 0.20
<code>force_all_finite</code> accepts the string <code>'allow-nan'</code>.</p>
<p>ensure_2d : boolean (default=True)
Whether to raise a value error if array is not 2D.</p>
<p>allow_nd : boolean (default=False)
Whether to allow array.ndim &gt; 2.</p>
<p>ensure_min_samples : int (default=1)
Make sure that the array has a minimum number of samples in its first
axis (rows for a 2D array). Setting to 0 disables this check.</p>
<p>ensure_min_features : int (default=1)
Make sure that the 2D array has some minimum number of features
(columns). The default value of 1 rejects empty datasets.
This check is only enforced when the input data has effectively 2
dimensions or is originally 1D and <code>ensure_2d</code> is True. Setting to 0
disables this check.</p>
<p>warn_on_dtype : boolean or None, optional (default=None)
Raise DataConversionWarning if the dtype of the input data structure
does not match the requested dtype, causing a memory copy.</p>
<p>.. deprecated:: 0.21
<code>warn_on_dtype</code> is deprecated in version 0.21 and will be
removed in 0.23.</p>
<p>estimator : str or estimator instance (default=None)
If passed, include the name of the estimator in warning messages.</p>
<h2 id="returns_120">Returns<a class="headerlink" href="#returns_120" title="Permanent link">&para;</a></h2>
<p>array_converted : object
The converted and validated array.</p>
<div class="highlight"><pre><span></span><code><span class="k">val</span> <span class="n">check_is_fitted</span> <span class="o">:</span> <span class="o">?</span><span class="n">attributes</span><span class="o">:[`</span><span class="nc">S</span> <span class="k">of</span> <span class="kt">string</span> <span class="o">|</span> <span class="o">`</span><span class="nc">Arr</span> <span class="k">of</span> <span class="o">[&gt;`</span><span class="nc">ArrayLike</span><span class="o">]</span> <span class="nn">Np</span><span class="p">.</span><span class="nn">Obj</span><span class="p">.</span><span class="n">t</span> <span class="o">|</span> <span class="o">`</span><span class="nc">StringList</span> <span class="k">of</span> <span class="kt">string</span> <span class="kt">list</span><span class="o">]</span> <span class="o">-&gt;</span> <span class="o">?</span><span class="n">msg</span><span class="o">:</span><span class="kt">string</span> <span class="o">-&gt;</span> <span class="o">?</span><span class="n">all_or_any</span><span class="o">:[`</span><span class="nc">Callable</span> <span class="k">of</span> <span class="nn">Py</span><span class="p">.</span><span class="nn">Object</span><span class="p">.</span><span class="n">t</span> <span class="o">|</span> <span class="o">`</span><span class="nc">PyObject</span> <span class="k">of</span> <span class="nn">Py</span><span class="p">.</span><span class="nn">Object</span><span class="p">.</span><span class="n">t</span><span class="o">]</span> <span class="o">-&gt;</span> <span class="n">estimator</span><span class="o">:[&gt;`</span><span class="nc">BaseEstimator</span><span class="o">]</span> <span class="nn">Np</span><span class="p">.</span><span class="nn">Obj</span><span class="p">.</span><span class="n">t</span> <span class="o">-&gt;</span> <span class="kt">unit</span> <span class="o">-&gt;</span> <span class="nn">Py</span><span class="p">.</span><span class="nn">Object</span><span class="p">.</span><span class="n">t</span>
</code></pre></div>

<p>Perform is_fitted validation for estimator.</p>
<p>Checks if the estimator is fitted by verifying the presence of
fitted attributes (ending with a trailing underscore) and otherwise
raises a NotFittedError with the given message.</p>
<p>This utility is meant to be used internally by estimators themselves,
typically in their own predict / transform methods.</p>
<h2 id="parameters_151">Parameters<a class="headerlink" href="#parameters_151" title="Permanent link">&para;</a></h2>
<p>estimator : estimator instance.
estimator instance for which the check is performed.</p>
<p>attributes : str, list or tuple of str, default=None
Attribute name(s) given as string or a list/tuple of strings
Eg.: <code>['coef_', 'estimator_', ...], 'coef_'</code></p>
<p>If <code>None</code>, <code>estimator</code> is considered fitted if there exist an
attribute that ends with a underscore and does not start with double
underscore.</p>
<p>msg : string
The default error message is, 'This %(name)s instance is not fitted
yet. Call 'fit' with appropriate arguments before using this
estimator.'</p>
<p>For custom messages if '%(name)s' is present in the message string,
it is substituted for the estimator name.</p>
<p>Eg. : 'Estimator, %(name)s, must be fitted before sparsifying'.</p>
<p>all_or_any : callable, {all, any}, default all
Specify whether all or any of the given attributes must exist.</p>
<h2 id="returns_121">Returns<a class="headerlink" href="#returns_121" title="Permanent link">&para;</a></h2>
<p>None</p>
<h2 id="raises_2">Raises<a class="headerlink" href="#raises_2" title="Permanent link">&para;</a></h2>
<p>NotFittedError
If the attributes are not found.</p>
<div class="highlight"><pre><span></span><code><span class="k">val</span> <span class="n">delayed</span> <span class="o">:</span> <span class="o">?</span><span class="n">check_pickle</span><span class="o">:</span><span class="nn">Py</span><span class="p">.</span><span class="nn">Object</span><span class="p">.</span><span class="n">t</span> <span class="o">-&gt;</span> <span class="n">function_</span><span class="o">:</span><span class="nn">Py</span><span class="p">.</span><span class="nn">Object</span><span class="p">.</span><span class="n">t</span> <span class="o">-&gt;</span> <span class="kt">unit</span> <span class="o">-&gt;</span> <span class="nn">Py</span><span class="p">.</span><span class="nn">Object</span><span class="p">.</span><span class="n">t</span>
</code></pre></div>

<p>Decorator used to capture the arguments of a function.</p>
<div class="highlight"><pre><span></span><code><span class="k">val</span> <span class="n">mquantiles</span> <span class="o">:</span> <span class="o">?</span><span class="n">prob</span><span class="o">:[&gt;`</span><span class="nc">ArrayLike</span><span class="o">]</span> <span class="nn">Np</span><span class="p">.</span><span class="nn">Obj</span><span class="p">.</span><span class="n">t</span> <span class="o">-&gt;</span> <span class="o">?</span><span class="n">alphap</span><span class="o">:</span><span class="kt">float</span> <span class="o">-&gt;</span> <span class="o">?</span><span class="n">betap</span><span class="o">:</span><span class="kt">float</span> <span class="o">-&gt;</span> <span class="o">?</span><span class="n">axis</span><span class="o">:</span><span class="kt">int</span> <span class="o">-&gt;</span> <span class="o">?</span><span class="n">limit</span><span class="o">:(</span><span class="kt">float</span> <span class="o">*</span> <span class="kt">float</span><span class="o">)</span> <span class="o">-&gt;</span> <span class="n">a</span><span class="o">:[&gt;`</span><span class="nc">ArrayLike</span><span class="o">]</span> <span class="nn">Np</span><span class="p">.</span><span class="nn">Obj</span><span class="p">.</span><span class="n">t</span> <span class="o">-&gt;</span> <span class="kt">unit</span> <span class="o">-&gt;</span> <span class="o">[&gt;`</span><span class="nc">ArrayLike</span><span class="o">]</span> <span class="nn">Np</span><span class="p">.</span><span class="nn">Obj</span><span class="p">.</span><span class="n">t</span>
</code></pre></div>

<p>Computes empirical quantiles for a data array.</p>
<p>Samples quantile are defined by <code>Q(p) = (1-gamma)*x[j] + gamma*x[j+1]</code>,
where <code>x[j]</code> is the j-th order statistic, and gamma is a function of
<code>j = floor(n*p + m)</code>, <code>m = alphap + p*(1 - alphap - betap)</code> and
<code>g = n*p + m - j</code>.</p>
<p>Reinterpreting the above equations to compare to <strong>R</strong> lead to the
equation: <code>p(k) = (k - alphap)/(n + 1 - alphap - betap)</code></p>
<p>Typical values of (alphap,betap) are:
- (0,1)    : <code>p(k) = k/n</code> : linear interpolation of cdf
( <strong>R</strong> type 4)
- (.5,.5)  : <code>p(k) = (k - 1/2.)/n</code> : piecewise linear function
( <strong>R</strong> type 5)
- (0,0)    : <code>p(k) = k/(n+1)</code> :
( <strong>R</strong> type 6)
- (1,1)    : <code>p(k) = (k-1)/(n-1)</code>: p(k) = mode[F(x[k])].
( <strong>R</strong> type 7, <strong>R</strong> default)
- (1/3,1/3): <code>p(k) = (k-1/3)/(n+1/3)</code>: Then p(k) ~ median[F(x[k])].
The resulting quantile estimates are approximately median-unbiased
regardless of the distribution of x.
( <strong>R</strong> type 8)
- (3/8,3/8): <code>p(k) = (k-3/8)/(n+1/4)</code>: Blom.
The resulting quantile estimates are approximately unbiased
if x is normally distributed
( <strong>R</strong> type 9)
- (.4,.4)  : approximately quantile unbiased (Cunnane)
- (.35,.35): APL, used with PWM</p>
<h2 id="parameters_152">Parameters<a class="headerlink" href="#parameters_152" title="Permanent link">&para;</a></h2>
<p>a : array_like
Input data, as a sequence or array of dimension at most 2.
prob : array_like, optional
List of quantiles to compute.
alphap : float, optional
Plotting positions parameter, default is 0.4.
betap : float, optional
Plotting positions parameter, default is 0.4.
axis : int, optional
Axis along which to perform the trimming.
If None (default), the input array is first flattened.
limit : tuple, optional
Tuple of (lower, upper) values.
Values of <code>a</code> outside this open interval are ignored.</p>
<h2 id="returns_122">Returns<a class="headerlink" href="#returns_122" title="Permanent link">&para;</a></h2>
<p>mquantiles : MaskedArray
An array containing the calculated quantiles.</p>
<h2 id="notes_15">Notes<a class="headerlink" href="#notes_15" title="Permanent link">&para;</a></h2>
<p>This formulation is very similar to <strong>R</strong> except the calculation of
<code>m</code> from <code>alphap</code> and <code>betap</code>, where in <strong>R</strong> <code>m</code> is defined
with each type.</p>
<h2 id="references_14">References<a class="headerlink" href="#references_14" title="Permanent link">&para;</a></h2>
<p>.. [1] <em>R</em> statistical software: https://www.r-project.org/
.. [2] <em>R</em> <code>quantile</code> function:
http://stat.ethz.ch/R-manual/R-devel/library/stats/html/quantile.html</p>
<h2 id="examples_13">Examples<a class="headerlink" href="#examples_13" title="Permanent link">&para;</a></h2>
<blockquote>
<blockquote>
<blockquote>
<p>from scipy.stats.mstats import mquantiles
a = np.array([6., 47., 49., 15., 42., 41., 7., 39., 43., 40., 36.])
mquantiles(a)
array([ 19.2,  40. ,  42.8])</p>
</blockquote>
</blockquote>
</blockquote>
<p>Using a 2D array, specifying axis and limit.</p>
<blockquote>
<blockquote>
<blockquote>
<p>data = np.array([[   6.,    7.,    1.],
...                  [  47.,   15.,    2.],
...                  [  49.,   36.,    3.],
...                  [  15.,   39.,    4.],
...                  [  42.,   40., -999.],
...                  [  41.,   41., -999.],
...                  [   7., -999., -999.],
...                  [  39., -999., -999.],
...                  [  43., -999., -999.],
...                  [  40., -999., -999.],
...                  [  36., -999., -999.]])
print(mquantiles(data, axis=0, limit=(0, 50)))
[[19.2  14.6   1.45]
[40.   37.5   2.5 ]
[42.8  40.05  3.55]]</p>
<p>data[:, 2] = -999.
print(mquantiles(data, axis=0, limit=(0, 50)))
[[19.200000000000003 14.6 --]
[40.0 37.5 --]
[42.800000000000004 40.05 --]]</p>
</blockquote>
</blockquote>
</blockquote>
<div class="highlight"><pre><span></span><code><span class="k">val</span> <span class="n">partial_dependence</span> <span class="o">:</span> <span class="o">?</span><span class="n">grid</span><span class="o">:[&gt;`</span><span class="nc">ArrayLike</span><span class="o">]</span> <span class="nn">Np</span><span class="p">.</span><span class="nn">Obj</span><span class="p">.</span><span class="n">t</span> <span class="o">-&gt;</span> <span class="o">?</span><span class="n">x</span><span class="o">:[&gt;`</span><span class="nc">ArrayLike</span><span class="o">]</span> <span class="nn">Np</span><span class="p">.</span><span class="nn">Obj</span><span class="p">.</span><span class="n">t</span> <span class="o">-&gt;</span> <span class="o">?</span><span class="n">percentiles</span><span class="o">:</span><span class="nn">Py</span><span class="p">.</span><span class="nn">Object</span><span class="p">.</span><span class="n">t</span> <span class="o">-&gt;</span> <span class="o">?</span><span class="n">grid_resolution</span><span class="o">:</span><span class="kt">int</span> <span class="o">-&gt;</span> <span class="n">gbrt</span><span class="o">:</span><span class="nn">Py</span><span class="p">.</span><span class="nn">Object</span><span class="p">.</span><span class="n">t</span> <span class="o">-&gt;</span> <span class="n">target_variables</span><span class="o">:[`</span><span class="nc">Arr</span> <span class="k">of</span> <span class="o">[&gt;`</span><span class="nc">ArrayLike</span><span class="o">]</span> <span class="nn">Np</span><span class="p">.</span><span class="nn">Obj</span><span class="p">.</span><span class="n">t</span> <span class="o">|</span> <span class="o">`</span><span class="nc">Dtype_int</span> <span class="k">of</span> <span class="nn">Py</span><span class="p">.</span><span class="nn">Object</span><span class="p">.</span><span class="n">t</span><span class="o">]</span> <span class="o">-&gt;</span> <span class="kt">unit</span> <span class="o">-&gt;</span> <span class="o">([&gt;`</span><span class="nc">ArrayLike</span><span class="o">]</span> <span class="nn">Np</span><span class="p">.</span><span class="nn">Obj</span><span class="p">.</span><span class="n">t</span> <span class="o">*</span> <span class="nn">Py</span><span class="p">.</span><span class="nn">Object</span><span class="p">.</span><span class="n">t</span> <span class="n">option</span><span class="o">)</span>
</code></pre></div>

<p>DEPRECATED: The function ensemble.partial_dependence has been deprecated in favour of inspection.partial_dependence in 0.21 and will be removed in 0.23.</p>
<p>Partial dependence of <code>target_variables</code>.</p>
<p>Partial dependence plots show the dependence between the joint values
of the <code>target_variables</code> and the function represented
by the <code>gbrt</code>.</p>
<p>Read more in the :ref:<code>User Guide &lt;partial_dependence&gt;</code>.</p>
<p>.. deprecated:: 0.21
This function was deprecated in version 0.21 in favor of
:func:<code>sklearn.inspection.partial_dependence</code> and will be
removed in 0.23.</p>
<h2 id="parameters_153">Parameters<a class="headerlink" href="#parameters_153" title="Permanent link">&para;</a></h2>
<p>gbrt : BaseGradientBoosting
A fitted gradient boosting model.</p>
<p>target_variables : array-like, dtype=int
The target features for which the partial dependency should be
computed (size should be smaller than 3 for visual renderings).</p>
<p>grid : array-like of shape (n_points, n_target_variables)
The grid of <code>target_variables</code> values for which the
partial dependency should be evaluated (either <code>grid</code> or <code>X</code>
must be specified).</p>
<p>X : array-like of shape (n_samples, n_features)
The data on which <code>gbrt</code> was trained. It is used to generate
a <code>grid</code> for the <code>target_variables</code>. The <code>grid</code> comprises
<code>grid_resolution</code> equally spaced points between the two
<code>percentiles</code>.</p>
<p>percentiles : (low, high), default=(0.05, 0.95)
The lower and upper percentile used create the extreme values
for the <code>grid</code>. Only if <code>X</code> is not None.</p>
<p>grid_resolution : int, default=100
The number of equally spaced points on the <code>grid</code>.</p>
<h2 id="returns_123">Returns<a class="headerlink" href="#returns_123" title="Permanent link">&para;</a></h2>
<p>pdp : array, shape=(n_classes, n_points)
The partial dependence function evaluated on the <code>grid</code>.
For regression and binary classification <code>n_classes==1</code>.</p>
<p>axes : seq of ndarray or None
The axes with which the grid has been created or None if
the grid has been given.</p>
<h2 id="examples_14">Examples<a class="headerlink" href="#examples_14" title="Permanent link">&para;</a></h2>
<blockquote>
<blockquote>
<blockquote>
<p>samples = [[0, 0, 2], [1, 0, 0]]
labels = [0, 1]
from sklearn.ensemble import GradientBoostingClassifier
gb = GradientBoostingClassifier(random_state=0).fit(samples, labels)
kwargs = dict(X=samples, percentiles=(0, 1), grid_resolution=2)
partial_dependence(gb, [0], **kwargs) # doctest: +SKIP
(array([[-4.52...,  4.52...]]), [array([ 0.,  1.])])</p>
</blockquote>
</blockquote>
</blockquote>
<div class="highlight"><pre><span></span><code><span class="k">val</span> <span class="n">plot_partial_dependence</span> <span class="o">:</span> <span class="o">?</span><span class="n">feature_names</span><span class="o">:</span><span class="nn">Py</span><span class="p">.</span><span class="nn">Object</span><span class="p">.</span><span class="n">t</span> <span class="o">-&gt;</span> <span class="o">?</span><span class="n">label</span><span class="o">:</span><span class="nn">Py</span><span class="p">.</span><span class="nn">Object</span><span class="p">.</span><span class="n">t</span> <span class="o">-&gt;</span> <span class="o">?</span><span class="n">n_cols</span><span class="o">:</span><span class="kt">int</span> <span class="o">-&gt;</span> <span class="o">?</span><span class="n">grid_resolution</span><span class="o">:</span><span class="kt">int</span> <span class="o">-&gt;</span> <span class="o">?</span><span class="n">percentiles</span><span class="o">:</span><span class="nn">Py</span><span class="p">.</span><span class="nn">Object</span><span class="p">.</span><span class="n">t</span> <span class="o">-&gt;</span> <span class="o">?</span><span class="n">n_jobs</span><span class="o">:</span><span class="kt">int</span> <span class="o">-&gt;</span> <span class="o">?</span><span class="n">verbose</span><span class="o">:</span><span class="kt">int</span> <span class="o">-&gt;</span> <span class="o">?</span><span class="n">ax</span><span class="o">:</span><span class="nn">Py</span><span class="p">.</span><span class="nn">Object</span><span class="p">.</span><span class="n">t</span> <span class="o">-&gt;</span> <span class="o">?</span><span class="n">line_kw</span><span class="o">:</span><span class="nn">Dict</span><span class="p">.</span><span class="n">t</span> <span class="o">-&gt;</span> <span class="o">?</span><span class="n">contour_kw</span><span class="o">:</span><span class="nn">Dict</span><span class="p">.</span><span class="n">t</span> <span class="o">-&gt;</span> <span class="o">?</span><span class="n">fig_kw</span><span class="o">:(</span><span class="kt">string</span> <span class="o">*</span> <span class="nn">Py</span><span class="p">.</span><span class="nn">Object</span><span class="p">.</span><span class="n">t</span><span class="o">)</span> <span class="kt">list</span> <span class="o">-&gt;</span> <span class="n">gbrt</span><span class="o">:</span><span class="nn">Py</span><span class="p">.</span><span class="nn">Object</span><span class="p">.</span><span class="n">t</span> <span class="o">-&gt;</span> <span class="n">x</span><span class="o">:[&gt;`</span><span class="nc">ArrayLike</span><span class="o">]</span> <span class="nn">Np</span><span class="p">.</span><span class="nn">Obj</span><span class="p">.</span><span class="n">t</span> <span class="o">-&gt;</span> <span class="n">features</span><span class="o">:</span><span class="nn">Py</span><span class="p">.</span><span class="nn">Object</span><span class="p">.</span><span class="n">t</span> <span class="o">-&gt;</span> <span class="kt">unit</span> <span class="o">-&gt;</span> <span class="o">(</span><span class="nn">Py</span><span class="p">.</span><span class="nn">Object</span><span class="p">.</span><span class="n">t</span> <span class="o">*</span> <span class="nn">Py</span><span class="p">.</span><span class="nn">Object</span><span class="p">.</span><span class="n">t</span><span class="o">)</span>
</code></pre></div>

<p>DEPRECATED: The function ensemble.plot_partial_dependence has been deprecated in favour of sklearn.inspection.plot_partial_dependence in  0.21 and will be removed in 0.23.</p>
<p>Partial dependence plots for <code>features</code>.</p>
<p>The <code>len(features)</code> plots are arranged in a grid with <code>n_cols</code>
columns. Two-way partial dependence plots are plotted as contour
plots.</p>
<p>Read more in the :ref:<code>User Guide &lt;partial_dependence&gt;</code>.</p>
<p>.. deprecated:: 0.21
This function was deprecated in version 0.21 in favor of
:func:<code>sklearn.inspection.plot_partial_dependence</code> and will be
removed in 0.23.</p>
<h2 id="parameters_154">Parameters<a class="headerlink" href="#parameters_154" title="Permanent link">&para;</a></h2>
<p>gbrt : BaseGradientBoosting
A fitted gradient boosting model.</p>
<p>X : array-like of shape (n_samples, n_features)
The data on which <code>gbrt</code> was trained.</p>
<p>features : seq of ints, strings, or tuples of ints or strings
If seq[i] is an int or a tuple with one int value, a one-way
PDP is created; if seq[i] is a tuple of two ints, a two-way
PDP is created.
If feature_names is specified and seq[i] is an int, seq[i]
must be &lt; len(feature_names).
If seq[i] is a string, feature_names must be specified, and
seq[i] must be in feature_names.</p>
<p>feature_names : seq of str
Name of each feature; feature_names[i] holds
the name of the feature with index i.</p>
<p>label : object
The class label for which the PDPs should be computed.
Only if gbrt is a multi-class model. Must be in <code>gbrt.classes_</code>.</p>
<p>n_cols : int
The number of columns in the grid plot (default: 3).</p>
<p>grid_resolution : int, default=100
The number of equally spaced points on the axes.</p>
<p>percentiles : (low, high), default=(0.05, 0.95)
The lower and upper percentile used to create the extreme values
for the PDP axes.</p>
<p>n_jobs : int or None, optional (default=None)
<code>None</code> means 1 unless in a :obj:<code>joblib.parallel_backend</code> context.
<code>-1</code> means using all processors. See :term:<code>Glossary &lt;n_jobs&gt;</code>
for more details.</p>
<p>verbose : int
Verbose output during PD computations. Defaults to 0.</p>
<p>ax : Matplotlib axis object, default None
An axis object onto which the plots will be drawn.</p>
<p>line_kw : dict
Dict with keywords passed to the <code>matplotlib.pyplot.plot</code> call.
For one-way partial dependence plots.</p>
<p>contour_kw : dict
Dict with keywords passed to the <code>matplotlib.pyplot.plot</code> call.
For two-way partial dependence plots.</p>
<p><code>**fig_kw</code> : dict
Dict with keywords passed to the figure() call.
Note that all keywords not recognized above will be automatically
included here.</p>
<h2 id="returns_124">Returns<a class="headerlink" href="#returns_124" title="Permanent link">&para;</a></h2>
<p>fig : figure
The Matplotlib Figure object.</p>
<p>axs : seq of Axis objects
A seq of Axis objects, one for each subplot.</p>
<h2 id="examples_15">Examples<a class="headerlink" href="#examples_15" title="Permanent link">&para;</a></h2>
<blockquote>
<blockquote>
<blockquote>
<p>from sklearn.datasets import make_friedman1
from sklearn.ensemble import GradientBoostingRegressor
X, y = make_friedman1()
clf = GradientBoostingRegressor(n_estimators=10).fit(X, y)
fig, axs = plot_partial_dependence(clf, X, [0, (0, 1)]) #doctest: +SKIP
...</p>
</blockquote>
</blockquote>
</blockquote>
                
              
              
                


              
            </article>
          </div>
        </div>
      </main>
      
        
<footer class="md-footer">
  
    <div class="md-footer-nav">
      <nav class="md-footer-nav__inner md-grid" aria-label="Footer">
        
          <a href="../Dummy/" title="Dummy" class="md-footer-nav__link md-footer-nav__link--prev" rel="prev">
            <div class="md-footer-nav__button md-icon">
              <svg xmlns="http://www.w3.org/2000/svg" viewBox="0 0 24 24"><path d="M20 11v2H8l5.5 5.5-1.42 1.42L4.16 12l7.92-7.92L13.5 5.5 8 11h12z"/></svg>
            </div>
            <div class="md-footer-nav__title">
              <div class="md-ellipsis">
                <span class="md-footer-nav__direction">
                  Previous
                </span>
                Dummy
              </div>
            </div>
          </a>
        
        
          <a href="../Exceptions/" title="Exceptions" class="md-footer-nav__link md-footer-nav__link--next" rel="next">
            <div class="md-footer-nav__title">
              <div class="md-ellipsis">
                <span class="md-footer-nav__direction">
                  Next
                </span>
                Exceptions
              </div>
            </div>
            <div class="md-footer-nav__button md-icon">
              <svg xmlns="http://www.w3.org/2000/svg" viewBox="0 0 24 24"><path d="M4 11v2h12l-5.5 5.5 1.42 1.42L19.84 12l-7.92-7.92L10.5 5.5 16 11H4z"/></svg>
            </div>
          </a>
        
      </nav>
    </div>
  
  <div class="md-footer-meta md-typeset">
    <div class="md-footer-meta__inner md-grid">
      <div class="md-footer-copyright">
        
        Made with
        <a href="https://squidfunk.github.io/mkdocs-material/" target="_blank" rel="noopener">
          Material for MkDocs
        </a>
      </div>
      
    </div>
  </div>
</footer>
      
    </div>
    
      <script src="../../assets/javascripts/vendor.d710d30a.min.js"></script>
      <script src="../../assets/javascripts/bundle.a45f732b.min.js"></script><script id="__lang" type="application/json">{"clipboard.copy": "Copy to clipboard", "clipboard.copied": "Copied to clipboard", "search.config.lang": "en", "search.config.pipeline": "trimmer, stopWordFilter", "search.config.separator": "[\\s\\-]+", "search.result.placeholder": "Type to start searching", "search.result.none": "No matching documents", "search.result.one": "1 matching document", "search.result.other": "# matching documents"}</script>
      
      <script>
        app = initialize({
          base: "../..",
          features: ["instant", "tabs"],
          search: Object.assign({
            worker: "../../assets/javascripts/worker/search.c03f0417.min.js"
          }, typeof search !== "undefined" && search)
        })
      </script>
      
        <script src="https://cdnjs.cloudflare.com/ajax/libs/mathjax/2.7.0/MathJax.js?config=TeX-MML-AM_CHTML"></script>
      
    
  </body>
</html>