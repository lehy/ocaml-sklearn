
<!doctype html>
<html lang="en" class="no-js">
  <head>
    
      <meta charset="utf-8">
      <meta name="viewport" content="width=device-width,initial-scale=1">
      
      
      
      
      <link rel="shortcut icon" href="../../assets/images/favicon.png">
      <meta name="generator" content="mkdocs-1.1.2, mkdocs-material-6.1.7">
    
    
      
        <title>Ensemble - OCaml scikit-learn interface</title>
      
    
    
      <link rel="stylesheet" href="../../assets/stylesheets/main.19753c6b.min.css">
      
        
        <link rel="stylesheet" href="../../assets/stylesheets/palette.196e0c26.min.css">
        
          
          
          <meta name="theme-color" content="#4051b5">
        
      
    
    
    
      
        
        <link href="https://fonts.gstatic.com" rel="preconnect" crossorigin>
        <link rel="stylesheet" href="https://fonts.googleapis.com/css?family=Roboto:300,400,400i,700%7CRoboto+Mono&display=fallback">
        <style>body,input{font-family:"Roboto",-apple-system,BlinkMacSystemFont,Helvetica,Arial,sans-serif}code,kbd,pre{font-family:"Roboto Mono",SFMono-Regular,Consolas,Menlo,monospace}</style>
      
    
    
    
    
      
    
    
  </head>
  
  
    
    
    
    
    
    <body dir="ltr" data-md-color-scheme="" data-md-color-primary="indigo" data-md-color-accent="indigo">
      
  
    <input class="md-toggle" data-md-toggle="drawer" type="checkbox" id="__drawer" autocomplete="off">
    <input class="md-toggle" data-md-toggle="search" type="checkbox" id="__search" autocomplete="off">
    <label class="md-overlay" for="__drawer"></label>
    <div data-md-component="skip">
      
        
        <a href="#adaboostclassifier" class="md-skip">
          Skip to content
        </a>
      
    </div>
    <div data-md-component="announce">
      
    </div>
    
      

<header class="md-header" data-md-component="header">
  <nav class="md-header-nav md-grid" aria-label="Header">
    <a href="../.." title="OCaml scikit-learn interface" class="md-header-nav__button md-logo" aria-label="OCaml scikit-learn interface">
      
  
  <svg xmlns="http://www.w3.org/2000/svg" viewBox="0 0 24 24"><path d="M12 8a3 3 0 003-3 3 3 0 00-3-3 3 3 0 00-3 3 3 3 0 003 3m0 3.54C9.64 9.35 6.5 8 3 8v11c3.5 0 6.64 1.35 9 3.54 2.36-2.19 5.5-3.54 9-3.54V8c-3.5 0-6.64 1.35-9 3.54z"/></svg>

    </a>
    <label class="md-header-nav__button md-icon" for="__drawer">
      <svg xmlns="http://www.w3.org/2000/svg" viewBox="0 0 24 24"><path d="M3 6h18v2H3V6m0 5h18v2H3v-2m0 5h18v2H3v-2z"/></svg>
    </label>
    <div class="md-header-nav__title" data-md-component="header-title">
      
        <div class="md-header-nav__ellipsis">
          <span class="md-header-nav__topic md-ellipsis">
            OCaml scikit-learn interface
          </span>
          <span class="md-header-nav__topic md-ellipsis">
            
              Ensemble
            
          </span>
        </div>
      
    </div>
    
      <label class="md-header-nav__button md-icon" for="__search">
        <svg xmlns="http://www.w3.org/2000/svg" viewBox="0 0 24 24"><path d="M9.5 3A6.5 6.5 0 0116 9.5c0 1.61-.59 3.09-1.56 4.23l.27.27h.79l5 5-1.5 1.5-5-5v-.79l-.27-.27A6.516 6.516 0 019.5 16 6.5 6.5 0 013 9.5 6.5 6.5 0 019.5 3m0 2C7 5 5 7 5 9.5S7 14 9.5 14 14 12 14 9.5 12 5 9.5 5z"/></svg>
      </label>
      
<div class="md-search" data-md-component="search" role="dialog">
  <label class="md-search__overlay" for="__search"></label>
  <div class="md-search__inner" role="search">
    <form class="md-search__form" name="search">
      <input type="text" class="md-search__input" name="query" aria-label="Search" placeholder="Search" autocapitalize="off" autocorrect="off" autocomplete="off" spellcheck="false" data-md-component="search-query" data-md-state="active" required>
      <label class="md-search__icon md-icon" for="__search">
        <svg xmlns="http://www.w3.org/2000/svg" viewBox="0 0 24 24"><path d="M9.5 3A6.5 6.5 0 0116 9.5c0 1.61-.59 3.09-1.56 4.23l.27.27h.79l5 5-1.5 1.5-5-5v-.79l-.27-.27A6.516 6.516 0 019.5 16 6.5 6.5 0 013 9.5 6.5 6.5 0 019.5 3m0 2C7 5 5 7 5 9.5S7 14 9.5 14 14 12 14 9.5 12 5 9.5 5z"/></svg>
        <svg xmlns="http://www.w3.org/2000/svg" viewBox="0 0 24 24"><path d="M20 11v2H8l5.5 5.5-1.42 1.42L4.16 12l7.92-7.92L13.5 5.5 8 11h12z"/></svg>
      </label>
      <button type="reset" class="md-search__icon md-icon" aria-label="Clear" data-md-component="search-reset" tabindex="-1">
        <svg xmlns="http://www.w3.org/2000/svg" viewBox="0 0 24 24"><path d="M19 6.41L17.59 5 12 10.59 6.41 5 5 6.41 10.59 12 5 17.59 6.41 19 12 13.41 17.59 19 19 17.59 13.41 12 19 6.41z"/></svg>
      </button>
    </form>
    <div class="md-search__output">
      <div class="md-search__scrollwrap" data-md-scrollfix>
        <div class="md-search-result" data-md-component="search-result">
          <div class="md-search-result__meta">
            Initializing search
          </div>
          <ol class="md-search-result__list"></ol>
        </div>
      </div>
    </div>
  </div>
</div>
    
    
      <div class="md-header-nav__source">
        
<a href="https://github.com/lehy/ocaml-sklearn/" title="Go to repository" class="md-source">
  <div class="md-source__icon md-icon">
    
    <svg xmlns="http://www.w3.org/2000/svg" viewBox="0 0 448 512"><path d="M439.55 236.05L244 40.45a28.87 28.87 0 00-40.81 0l-40.66 40.63 51.52 51.52c27.06-9.14 52.68 16.77 43.39 43.68l49.66 49.66c34.23-11.8 61.18 31 35.47 56.69-26.49 26.49-70.21-2.87-56-37.34L240.22 199v121.85c25.3 12.54 22.26 41.85 9.08 55a34.34 34.34 0 01-48.55 0c-17.57-17.6-11.07-46.91 11.25-56v-123c-20.8-8.51-24.6-30.74-18.64-45L142.57 101 8.45 235.14a28.86 28.86 0 000 40.81l195.61 195.6a28.86 28.86 0 0040.8 0l194.69-194.69a28.86 28.86 0 000-40.81z"/></svg>
  </div>
  <div class="md-source__repository">
    lehy/ocaml-sklearn
  </div>
</a>
      </div>
    
  </nav>
</header>
    
    <div class="md-container" data-md-component="container">
      
      
        
      
      <main class="md-main" data-md-component="main">
        <div class="md-main__inner md-grid">
          
            
              <div class="md-sidebar md-sidebar--primary" data-md-component="navigation">
                <div class="md-sidebar__scrollwrap">
                  <div class="md-sidebar__inner">
                    

<nav class="md-nav md-nav--primary" aria-label="Navigation" data-md-level="0">
  <label class="md-nav__title" for="__drawer">
    <a href="../.." title="OCaml scikit-learn interface" class="md-nav__button md-logo" aria-label="OCaml scikit-learn interface">
      
  
  <svg xmlns="http://www.w3.org/2000/svg" viewBox="0 0 24 24"><path d="M12 8a3 3 0 003-3 3 3 0 00-3-3 3 3 0 00-3 3 3 3 0 003 3m0 3.54C9.64 9.35 6.5 8 3 8v11c3.5 0 6.64 1.35 9 3.54 2.36-2.19 5.5-3.54 9-3.54V8c-3.5 0-6.64 1.35-9 3.54z"/></svg>

    </a>
    OCaml scikit-learn interface
  </label>
  
    <div class="md-nav__source">
      
<a href="https://github.com/lehy/ocaml-sklearn/" title="Go to repository" class="md-source">
  <div class="md-source__icon md-icon">
    
    <svg xmlns="http://www.w3.org/2000/svg" viewBox="0 0 448 512"><path d="M439.55 236.05L244 40.45a28.87 28.87 0 00-40.81 0l-40.66 40.63 51.52 51.52c27.06-9.14 52.68 16.77 43.39 43.68l49.66 49.66c34.23-11.8 61.18 31 35.47 56.69-26.49 26.49-70.21-2.87-56-37.34L240.22 199v121.85c25.3 12.54 22.26 41.85 9.08 55a34.34 34.34 0 01-48.55 0c-17.57-17.6-11.07-46.91 11.25-56v-123c-20.8-8.51-24.6-30.74-18.64-45L142.57 101 8.45 235.14a28.86 28.86 0 000 40.81l195.61 195.6a28.86 28.86 0 0040.8 0l194.69-194.69a28.86 28.86 0 000-40.81z"/></svg>
  </div>
  <div class="md-source__repository">
    lehy/ocaml-sklearn
  </div>
</a>
    </div>
  
  <ul class="md-nav__list" data-md-scrollfix>
    
      
      
      


  <li class="md-nav__item">
    <a href="../.." class="md-nav__link">
      Home
    </a>
  </li>

    
      
      
      


  <li class="md-nav__item md-nav__item--nested">
    
    <input class="md-nav__toggle md-toggle" data-md-toggle="nav-2" type="checkbox" id="nav-2" >
    <label class="md-nav__link" for="nav-2">
      Np
      <span class="md-nav__icon md-icon"></span>
    </label>
    <nav class="md-nav" aria-label="Np" data-md-level="1">
      <label class="md-nav__title" for="nav-2">
        <span class="md-nav__icon md-icon"></span>
        Np
      </label>
      <ul class="md-nav__list" data-md-scrollfix>
        
        
          
          
          


  <li class="md-nav__item">
    <a href="../../np/" class="md-nav__link">
      Numpy for OCaml
    </a>
  </li>

        
          
          
          


  <li class="md-nav__item">
    <a href="../../np/Numpy/" class="md-nav__link">
      Numpy
    </a>
  </li>

        
          
          
          


  <li class="md-nav__item">
    <a href="../../np/NumpyRaw/" class="md-nav__link">
      NumpyRaw
    </a>
  </li>

        
          
          
          


  <li class="md-nav__item">
    <a href="../../np/PyList/" class="md-nav__link">
      PyList
    </a>
  </li>

        
          
          
          


  <li class="md-nav__item">
    <a href="../../np/dtype/" class="md-nav__link">
      Dtype
    </a>
  </li>

        
          
          
          


  <li class="md-nav__item">
    <a href="../../np/obj/" class="md-nav__link">
      Obj
    </a>
  </li>

        
      </ul>
    </nav>
  </li>

    
      
      
      


  <li class="md-nav__item md-nav__item--nested">
    
    <input class="md-nav__toggle md-toggle" data-md-toggle="nav-3" type="checkbox" id="nav-3" >
    <label class="md-nav__link" for="nav-3">
      Scipy
      <span class="md-nav__icon md-icon"></span>
    </label>
    <nav class="md-nav" aria-label="Scipy" data-md-level="1">
      <label class="md-nav__title" for="nav-3">
        <span class="md-nav__icon md-icon"></span>
        Scipy
      </label>
      <ul class="md-nav__list" data-md-scrollfix>
        
        
          
          
          


  <li class="md-nav__item">
    <a href="../../scipy/" class="md-nav__link">
      SciPy library for OCaml
    </a>
  </li>

        
          
          
          


  <li class="md-nav__item">
    <a href="../../scipy/Cluster/" class="md-nav__link">
      Cluster
    </a>
  </li>

        
          
          
          


  <li class="md-nav__item">
    <a href="../../scipy/Conftest/" class="md-nav__link">
      Conftest
    </a>
  </li>

        
          
          
          


  <li class="md-nav__item">
    <a href="../../scipy/Constants/" class="md-nav__link">
      Constants
    </a>
  </li>

        
          
          
          


  <li class="md-nav__item">
    <a href="../../scipy/Fft/" class="md-nav__link">
      Fft
    </a>
  </li>

        
          
          
          


  <li class="md-nav__item">
    <a href="../../scipy/Fftpack/" class="md-nav__link">
      Fftpack
    </a>
  </li>

        
          
          
          


  <li class="md-nav__item">
    <a href="../../scipy/Integrate/" class="md-nav__link">
      Integrate
    </a>
  </li>

        
          
          
          


  <li class="md-nav__item">
    <a href="../../scipy/Interpolate/" class="md-nav__link">
      Interpolate
    </a>
  </li>

        
          
          
          


  <li class="md-nav__item">
    <a href="../../scipy/Io/" class="md-nav__link">
      Io
    </a>
  </li>

        
          
          
          


  <li class="md-nav__item">
    <a href="../../scipy/Linalg/" class="md-nav__link">
      Linalg
    </a>
  </li>

        
          
          
          


  <li class="md-nav__item">
    <a href="../../scipy/Misc/" class="md-nav__link">
      Misc
    </a>
  </li>

        
          
          
          


  <li class="md-nav__item">
    <a href="../../scipy/Ndimage/" class="md-nav__link">
      Ndimage
    </a>
  </li>

        
          
          
          


  <li class="md-nav__item">
    <a href="../../scipy/Odr/" class="md-nav__link">
      Odr
    </a>
  </li>

        
          
          
          


  <li class="md-nav__item">
    <a href="../../scipy/Optimize/" class="md-nav__link">
      Optimize
    </a>
  </li>

        
          
          
          


  <li class="md-nav__item">
    <a href="../../scipy/Setup/" class="md-nav__link">
      Setup
    </a>
  </li>

        
          
          
          


  <li class="md-nav__item">
    <a href="../../scipy/Signal/" class="md-nav__link">
      Signal
    </a>
  </li>

        
          
          
          


  <li class="md-nav__item">
    <a href="../../scipy/Sparse/" class="md-nav__link">
      Sparse
    </a>
  </li>

        
          
          
          


  <li class="md-nav__item">
    <a href="../../scipy/Spatial/" class="md-nav__link">
      Spatial
    </a>
  </li>

        
          
          
          


  <li class="md-nav__item">
    <a href="../../scipy/Special/" class="md-nav__link">
      Special
    </a>
  </li>

        
          
          
          


  <li class="md-nav__item">
    <a href="../../scipy/Stats/" class="md-nav__link">
      Stats
    </a>
  </li>

        
          
          
          


  <li class="md-nav__item">
    <a href="../../scipy/Version/" class="md-nav__link">
      Version
    </a>
  </li>

        
          
          
          


  <li class="md-nav__item">
    <a href="../../scipy/wrap_version/" class="md-nav__link">
      Wrap version
    </a>
  </li>

        
      </ul>
    </nav>
  </li>

    
      
      
      

  


  <li class="md-nav__item md-nav__item--active md-nav__item--nested">
    
    <input class="md-nav__toggle md-toggle" data-md-toggle="nav-4" type="checkbox" id="nav-4" checked>
    <label class="md-nav__link" for="nav-4">
      Sklearn
      <span class="md-nav__icon md-icon"></span>
    </label>
    <nav class="md-nav" aria-label="Sklearn" data-md-level="1">
      <label class="md-nav__title" for="nav-4">
        <span class="md-nav__icon md-icon"></span>
        Sklearn
      </label>
      <ul class="md-nav__list" data-md-scrollfix>
        
        
          
          
          


  <li class="md-nav__item">
    <a href="../Base/" class="md-nav__link">
      Base
    </a>
  </li>

        
          
          
          


  <li class="md-nav__item">
    <a href="../Calibration/" class="md-nav__link">
      Calibration
    </a>
  </li>

        
          
          
          


  <li class="md-nav__item">
    <a href="../Cluster/" class="md-nav__link">
      Cluster
    </a>
  </li>

        
          
          
          


  <li class="md-nav__item">
    <a href="../Compose/" class="md-nav__link">
      Compose
    </a>
  </li>

        
          
          
          


  <li class="md-nav__item">
    <a href="../Conftest/" class="md-nav__link">
      Conftest
    </a>
  </li>

        
          
          
          


  <li class="md-nav__item">
    <a href="../Covariance/" class="md-nav__link">
      Covariance
    </a>
  </li>

        
          
          
          


  <li class="md-nav__item">
    <a href="../Cross_decomposition/" class="md-nav__link">
      Cross decomposition
    </a>
  </li>

        
          
          
          


  <li class="md-nav__item">
    <a href="../Datasets/" class="md-nav__link">
      Datasets
    </a>
  </li>

        
          
          
          


  <li class="md-nav__item">
    <a href="../Decomposition/" class="md-nav__link">
      Decomposition
    </a>
  </li>

        
          
          
          


  <li class="md-nav__item">
    <a href="../Discriminant_analysis/" class="md-nav__link">
      Discriminant analysis
    </a>
  </li>

        
          
          
          


  <li class="md-nav__item">
    <a href="../Dummy/" class="md-nav__link">
      Dummy
    </a>
  </li>

        
          
          
          

  


  <li class="md-nav__item md-nav__item--active">
    
    <input class="md-nav__toggle md-toggle" data-md-toggle="toc" type="checkbox" id="__toc">
    
    
      <label class="md-nav__link md-nav__link--active" for="__toc">
        Ensemble
        <span class="md-nav__icon md-icon"></span>
      </label>
    
    <a href="./" class="md-nav__link md-nav__link--active">
      Ensemble
    </a>
    
      
<nav class="md-nav md-nav--secondary" aria-label="Table of contents">
  
  
  
    <label class="md-nav__title" for="__toc">
      <span class="md-nav__icon md-icon"></span>
      Table of contents
    </label>
    <ul class="md-nav__list" data-md-scrollfix>
      
        <li class="md-nav__item">
  <a href="#adaboostclassifier" class="md-nav__link">
    AdaBoostClassifier
  </a>
  
    <nav class="md-nav" aria-label="AdaBoostClassifier">
      <ul class="md-nav__list">
        
          <li class="md-nav__item">
  <a href="#create" class="md-nav__link">
    create
  </a>
  
</li>
        
          <li class="md-nav__item">
  <a href="#get_item" class="md-nav__link">
    get_item
  </a>
  
</li>
        
          <li class="md-nav__item">
  <a href="#iter" class="md-nav__link">
    iter
  </a>
  
</li>
        
          <li class="md-nav__item">
  <a href="#decision_function" class="md-nav__link">
    decision_function
  </a>
  
</li>
        
          <li class="md-nav__item">
  <a href="#fit" class="md-nav__link">
    fit
  </a>
  
</li>
        
          <li class="md-nav__item">
  <a href="#get_params" class="md-nav__link">
    get_params
  </a>
  
</li>
        
          <li class="md-nav__item">
  <a href="#predict" class="md-nav__link">
    predict
  </a>
  
</li>
        
          <li class="md-nav__item">
  <a href="#predict_log_proba" class="md-nav__link">
    predict_log_proba
  </a>
  
</li>
        
          <li class="md-nav__item">
  <a href="#predict_proba" class="md-nav__link">
    predict_proba
  </a>
  
</li>
        
          <li class="md-nav__item">
  <a href="#score" class="md-nav__link">
    score
  </a>
  
</li>
        
          <li class="md-nav__item">
  <a href="#set_params" class="md-nav__link">
    set_params
  </a>
  
</li>
        
          <li class="md-nav__item">
  <a href="#staged_decision_function" class="md-nav__link">
    staged_decision_function
  </a>
  
</li>
        
          <li class="md-nav__item">
  <a href="#staged_predict" class="md-nav__link">
    staged_predict
  </a>
  
</li>
        
          <li class="md-nav__item">
  <a href="#staged_predict_proba" class="md-nav__link">
    staged_predict_proba
  </a>
  
</li>
        
          <li class="md-nav__item">
  <a href="#staged_score" class="md-nav__link">
    staged_score
  </a>
  
</li>
        
          <li class="md-nav__item">
  <a href="#base_estimator_" class="md-nav__link">
    base_estimator_
  </a>
  
</li>
        
          <li class="md-nav__item">
  <a href="#estimators_" class="md-nav__link">
    estimators_
  </a>
  
</li>
        
          <li class="md-nav__item">
  <a href="#classes_" class="md-nav__link">
    classes_
  </a>
  
</li>
        
          <li class="md-nav__item">
  <a href="#n_classes_" class="md-nav__link">
    n_classes_
  </a>
  
</li>
        
          <li class="md-nav__item">
  <a href="#estimator_weights_" class="md-nav__link">
    estimator_weights_
  </a>
  
</li>
        
          <li class="md-nav__item">
  <a href="#estimator_errors_" class="md-nav__link">
    estimator_errors_
  </a>
  
</li>
        
          <li class="md-nav__item">
  <a href="#feature_importances_" class="md-nav__link">
    feature_importances_
  </a>
  
</li>
        
          <li class="md-nav__item">
  <a href="#warning" class="md-nav__link">
    warning
  </a>
  
</li>
        
          <li class="md-nav__item">
  <a href="#to_string" class="md-nav__link">
    to_string
  </a>
  
</li>
        
          <li class="md-nav__item">
  <a href="#show" class="md-nav__link">
    show
  </a>
  
</li>
        
          <li class="md-nav__item">
  <a href="#pp" class="md-nav__link">
    pp
  </a>
  
</li>
        
      </ul>
    </nav>
  
</li>
      
        <li class="md-nav__item">
  <a href="#adaboostregressor" class="md-nav__link">
    AdaBoostRegressor
  </a>
  
    <nav class="md-nav" aria-label="AdaBoostRegressor">
      <ul class="md-nav__list">
        
          <li class="md-nav__item">
  <a href="#create_1" class="md-nav__link">
    create
  </a>
  
</li>
        
          <li class="md-nav__item">
  <a href="#get_item_1" class="md-nav__link">
    get_item
  </a>
  
</li>
        
          <li class="md-nav__item">
  <a href="#iter_1" class="md-nav__link">
    iter
  </a>
  
</li>
        
          <li class="md-nav__item">
  <a href="#fit_1" class="md-nav__link">
    fit
  </a>
  
</li>
        
          <li class="md-nav__item">
  <a href="#get_params_1" class="md-nav__link">
    get_params
  </a>
  
</li>
        
          <li class="md-nav__item">
  <a href="#predict_1" class="md-nav__link">
    predict
  </a>
  
</li>
        
          <li class="md-nav__item">
  <a href="#score_1" class="md-nav__link">
    score
  </a>
  
</li>
        
          <li class="md-nav__item">
  <a href="#set_params_1" class="md-nav__link">
    set_params
  </a>
  
</li>
        
          <li class="md-nav__item">
  <a href="#staged_predict_1" class="md-nav__link">
    staged_predict
  </a>
  
</li>
        
          <li class="md-nav__item">
  <a href="#staged_score_1" class="md-nav__link">
    staged_score
  </a>
  
</li>
        
          <li class="md-nav__item">
  <a href="#base_estimator__1" class="md-nav__link">
    base_estimator_
  </a>
  
</li>
        
          <li class="md-nav__item">
  <a href="#estimators__1" class="md-nav__link">
    estimators_
  </a>
  
</li>
        
          <li class="md-nav__item">
  <a href="#estimator_weights__1" class="md-nav__link">
    estimator_weights_
  </a>
  
</li>
        
          <li class="md-nav__item">
  <a href="#estimator_errors__1" class="md-nav__link">
    estimator_errors_
  </a>
  
</li>
        
          <li class="md-nav__item">
  <a href="#feature_importances__1" class="md-nav__link">
    feature_importances_
  </a>
  
</li>
        
          <li class="md-nav__item">
  <a href="#warning_1" class="md-nav__link">
    warning
  </a>
  
</li>
        
          <li class="md-nav__item">
  <a href="#to_string_1" class="md-nav__link">
    to_string
  </a>
  
</li>
        
          <li class="md-nav__item">
  <a href="#show_1" class="md-nav__link">
    show
  </a>
  
</li>
        
          <li class="md-nav__item">
  <a href="#pp_1" class="md-nav__link">
    pp
  </a>
  
</li>
        
      </ul>
    </nav>
  
</li>
      
        <li class="md-nav__item">
  <a href="#baggingclassifier" class="md-nav__link">
    BaggingClassifier
  </a>
  
    <nav class="md-nav" aria-label="BaggingClassifier">
      <ul class="md-nav__list">
        
          <li class="md-nav__item">
  <a href="#create_2" class="md-nav__link">
    create
  </a>
  
</li>
        
          <li class="md-nav__item">
  <a href="#get_item_2" class="md-nav__link">
    get_item
  </a>
  
</li>
        
          <li class="md-nav__item">
  <a href="#iter_2" class="md-nav__link">
    iter
  </a>
  
</li>
        
          <li class="md-nav__item">
  <a href="#fit_2" class="md-nav__link">
    fit
  </a>
  
</li>
        
          <li class="md-nav__item">
  <a href="#get_params_2" class="md-nav__link">
    get_params
  </a>
  
</li>
        
          <li class="md-nav__item">
  <a href="#predict_2" class="md-nav__link">
    predict
  </a>
  
</li>
        
          <li class="md-nav__item">
  <a href="#predict_log_proba_1" class="md-nav__link">
    predict_log_proba
  </a>
  
</li>
        
          <li class="md-nav__item">
  <a href="#predict_proba_1" class="md-nav__link">
    predict_proba
  </a>
  
</li>
        
          <li class="md-nav__item">
  <a href="#score_2" class="md-nav__link">
    score
  </a>
  
</li>
        
          <li class="md-nav__item">
  <a href="#set_params_2" class="md-nav__link">
    set_params
  </a>
  
</li>
        
          <li class="md-nav__item">
  <a href="#base_estimator__2" class="md-nav__link">
    base_estimator_
  </a>
  
</li>
        
          <li class="md-nav__item">
  <a href="#n_features_" class="md-nav__link">
    n_features_
  </a>
  
</li>
        
          <li class="md-nav__item">
  <a href="#estimators__2" class="md-nav__link">
    estimators_
  </a>
  
</li>
        
          <li class="md-nav__item">
  <a href="#estimators_samples_" class="md-nav__link">
    estimators_samples_
  </a>
  
</li>
        
          <li class="md-nav__item">
  <a href="#estimators_features_" class="md-nav__link">
    estimators_features_
  </a>
  
</li>
        
          <li class="md-nav__item">
  <a href="#classes__1" class="md-nav__link">
    classes_
  </a>
  
</li>
        
          <li class="md-nav__item">
  <a href="#n_classes__1" class="md-nav__link">
    n_classes_
  </a>
  
</li>
        
          <li class="md-nav__item">
  <a href="#oob_score_" class="md-nav__link">
    oob_score_
  </a>
  
</li>
        
          <li class="md-nav__item">
  <a href="#oob_decision_function_" class="md-nav__link">
    oob_decision_function_
  </a>
  
</li>
        
          <li class="md-nav__item">
  <a href="#to_string_2" class="md-nav__link">
    to_string
  </a>
  
</li>
        
          <li class="md-nav__item">
  <a href="#show_2" class="md-nav__link">
    show
  </a>
  
</li>
        
          <li class="md-nav__item">
  <a href="#pp_2" class="md-nav__link">
    pp
  </a>
  
</li>
        
      </ul>
    </nav>
  
</li>
      
        <li class="md-nav__item">
  <a href="#baggingregressor" class="md-nav__link">
    BaggingRegressor
  </a>
  
    <nav class="md-nav" aria-label="BaggingRegressor">
      <ul class="md-nav__list">
        
          <li class="md-nav__item">
  <a href="#create_3" class="md-nav__link">
    create
  </a>
  
</li>
        
          <li class="md-nav__item">
  <a href="#get_item_3" class="md-nav__link">
    get_item
  </a>
  
</li>
        
          <li class="md-nav__item">
  <a href="#iter_3" class="md-nav__link">
    iter
  </a>
  
</li>
        
          <li class="md-nav__item">
  <a href="#fit_3" class="md-nav__link">
    fit
  </a>
  
</li>
        
          <li class="md-nav__item">
  <a href="#get_params_3" class="md-nav__link">
    get_params
  </a>
  
</li>
        
          <li class="md-nav__item">
  <a href="#predict_3" class="md-nav__link">
    predict
  </a>
  
</li>
        
          <li class="md-nav__item">
  <a href="#score_3" class="md-nav__link">
    score
  </a>
  
</li>
        
          <li class="md-nav__item">
  <a href="#set_params_3" class="md-nav__link">
    set_params
  </a>
  
</li>
        
          <li class="md-nav__item">
  <a href="#base_estimator__3" class="md-nav__link">
    base_estimator_
  </a>
  
</li>
        
          <li class="md-nav__item">
  <a href="#n_features__1" class="md-nav__link">
    n_features_
  </a>
  
</li>
        
          <li class="md-nav__item">
  <a href="#estimators__3" class="md-nav__link">
    estimators_
  </a>
  
</li>
        
          <li class="md-nav__item">
  <a href="#estimators_samples__1" class="md-nav__link">
    estimators_samples_
  </a>
  
</li>
        
          <li class="md-nav__item">
  <a href="#estimators_features__1" class="md-nav__link">
    estimators_features_
  </a>
  
</li>
        
          <li class="md-nav__item">
  <a href="#oob_score__1" class="md-nav__link">
    oob_score_
  </a>
  
</li>
        
          <li class="md-nav__item">
  <a href="#oob_prediction_" class="md-nav__link">
    oob_prediction_
  </a>
  
</li>
        
          <li class="md-nav__item">
  <a href="#to_string_3" class="md-nav__link">
    to_string
  </a>
  
</li>
        
          <li class="md-nav__item">
  <a href="#show_3" class="md-nav__link">
    show
  </a>
  
</li>
        
          <li class="md-nav__item">
  <a href="#pp_3" class="md-nav__link">
    pp
  </a>
  
</li>
        
      </ul>
    </nav>
  
</li>
      
        <li class="md-nav__item">
  <a href="#baseensemble" class="md-nav__link">
    BaseEnsemble
  </a>
  
    <nav class="md-nav" aria-label="BaseEnsemble">
      <ul class="md-nav__list">
        
          <li class="md-nav__item">
  <a href="#get_item_4" class="md-nav__link">
    get_item
  </a>
  
</li>
        
          <li class="md-nav__item">
  <a href="#iter_4" class="md-nav__link">
    iter
  </a>
  
</li>
        
          <li class="md-nav__item">
  <a href="#get_params_4" class="md-nav__link">
    get_params
  </a>
  
</li>
        
          <li class="md-nav__item">
  <a href="#set_params_4" class="md-nav__link">
    set_params
  </a>
  
</li>
        
          <li class="md-nav__item">
  <a href="#base_estimator__4" class="md-nav__link">
    base_estimator_
  </a>
  
</li>
        
          <li class="md-nav__item">
  <a href="#estimators__4" class="md-nav__link">
    estimators_
  </a>
  
</li>
        
          <li class="md-nav__item">
  <a href="#to_string_4" class="md-nav__link">
    to_string
  </a>
  
</li>
        
          <li class="md-nav__item">
  <a href="#show_4" class="md-nav__link">
    show
  </a>
  
</li>
        
          <li class="md-nav__item">
  <a href="#pp_4" class="md-nav__link">
    pp
  </a>
  
</li>
        
      </ul>
    </nav>
  
</li>
      
        <li class="md-nav__item">
  <a href="#extratreesclassifier" class="md-nav__link">
    ExtraTreesClassifier
  </a>
  
    <nav class="md-nav" aria-label="ExtraTreesClassifier">
      <ul class="md-nav__list">
        
          <li class="md-nav__item">
  <a href="#create_4" class="md-nav__link">
    create
  </a>
  
</li>
        
          <li class="md-nav__item">
  <a href="#get_item_5" class="md-nav__link">
    get_item
  </a>
  
</li>
        
          <li class="md-nav__item">
  <a href="#iter_5" class="md-nav__link">
    iter
  </a>
  
</li>
        
          <li class="md-nav__item">
  <a href="#apply" class="md-nav__link">
    apply
  </a>
  
</li>
        
          <li class="md-nav__item">
  <a href="#decision_path" class="md-nav__link">
    decision_path
  </a>
  
</li>
        
          <li class="md-nav__item">
  <a href="#fit_4" class="md-nav__link">
    fit
  </a>
  
</li>
        
          <li class="md-nav__item">
  <a href="#get_params_5" class="md-nav__link">
    get_params
  </a>
  
</li>
        
          <li class="md-nav__item">
  <a href="#predict_4" class="md-nav__link">
    predict
  </a>
  
</li>
        
          <li class="md-nav__item">
  <a href="#predict_log_proba_2" class="md-nav__link">
    predict_log_proba
  </a>
  
</li>
        
          <li class="md-nav__item">
  <a href="#predict_proba_2" class="md-nav__link">
    predict_proba
  </a>
  
</li>
        
          <li class="md-nav__item">
  <a href="#score_4" class="md-nav__link">
    score
  </a>
  
</li>
        
          <li class="md-nav__item">
  <a href="#set_params_5" class="md-nav__link">
    set_params
  </a>
  
</li>
        
          <li class="md-nav__item">
  <a href="#base_estimator__5" class="md-nav__link">
    base_estimator_
  </a>
  
</li>
        
          <li class="md-nav__item">
  <a href="#estimators__5" class="md-nav__link">
    estimators_
  </a>
  
</li>
        
          <li class="md-nav__item">
  <a href="#classes__2" class="md-nav__link">
    classes_
  </a>
  
</li>
        
          <li class="md-nav__item">
  <a href="#n_classes__2" class="md-nav__link">
    n_classes_
  </a>
  
</li>
        
          <li class="md-nav__item">
  <a href="#feature_importances__2" class="md-nav__link">
    feature_importances_
  </a>
  
</li>
        
          <li class="md-nav__item">
  <a href="#warning_2" class="md-nav__link">
    warning
  </a>
  
</li>
        
          <li class="md-nav__item">
  <a href="#n_features__2" class="md-nav__link">
    n_features_
  </a>
  
</li>
        
          <li class="md-nav__item">
  <a href="#n_outputs_" class="md-nav__link">
    n_outputs_
  </a>
  
</li>
        
          <li class="md-nav__item">
  <a href="#oob_score__2" class="md-nav__link">
    oob_score_
  </a>
  
</li>
        
          <li class="md-nav__item">
  <a href="#oob_decision_function__1" class="md-nav__link">
    oob_decision_function_
  </a>
  
</li>
        
          <li class="md-nav__item">
  <a href="#to_string_5" class="md-nav__link">
    to_string
  </a>
  
</li>
        
          <li class="md-nav__item">
  <a href="#show_5" class="md-nav__link">
    show
  </a>
  
</li>
        
          <li class="md-nav__item">
  <a href="#pp_5" class="md-nav__link">
    pp
  </a>
  
</li>
        
      </ul>
    </nav>
  
</li>
      
        <li class="md-nav__item">
  <a href="#extratreesregressor" class="md-nav__link">
    ExtraTreesRegressor
  </a>
  
    <nav class="md-nav" aria-label="ExtraTreesRegressor">
      <ul class="md-nav__list">
        
          <li class="md-nav__item">
  <a href="#create_5" class="md-nav__link">
    create
  </a>
  
</li>
        
          <li class="md-nav__item">
  <a href="#get_item_6" class="md-nav__link">
    get_item
  </a>
  
</li>
        
          <li class="md-nav__item">
  <a href="#iter_6" class="md-nav__link">
    iter
  </a>
  
</li>
        
          <li class="md-nav__item">
  <a href="#apply_1" class="md-nav__link">
    apply
  </a>
  
</li>
        
          <li class="md-nav__item">
  <a href="#decision_path_1" class="md-nav__link">
    decision_path
  </a>
  
</li>
        
          <li class="md-nav__item">
  <a href="#fit_5" class="md-nav__link">
    fit
  </a>
  
</li>
        
          <li class="md-nav__item">
  <a href="#get_params_6" class="md-nav__link">
    get_params
  </a>
  
</li>
        
          <li class="md-nav__item">
  <a href="#predict_5" class="md-nav__link">
    predict
  </a>
  
</li>
        
          <li class="md-nav__item">
  <a href="#score_5" class="md-nav__link">
    score
  </a>
  
</li>
        
          <li class="md-nav__item">
  <a href="#set_params_6" class="md-nav__link">
    set_params
  </a>
  
</li>
        
          <li class="md-nav__item">
  <a href="#base_estimator__6" class="md-nav__link">
    base_estimator_
  </a>
  
</li>
        
          <li class="md-nav__item">
  <a href="#estimators__6" class="md-nav__link">
    estimators_
  </a>
  
</li>
        
          <li class="md-nav__item">
  <a href="#feature_importances__3" class="md-nav__link">
    feature_importances_
  </a>
  
</li>
        
          <li class="md-nav__item">
  <a href="#warning_3" class="md-nav__link">
    warning
  </a>
  
</li>
        
          <li class="md-nav__item">
  <a href="#n_features__3" class="md-nav__link">
    n_features_
  </a>
  
</li>
        
          <li class="md-nav__item">
  <a href="#n_outputs__1" class="md-nav__link">
    n_outputs_
  </a>
  
</li>
        
          <li class="md-nav__item">
  <a href="#oob_score__3" class="md-nav__link">
    oob_score_
  </a>
  
</li>
        
          <li class="md-nav__item">
  <a href="#oob_prediction__1" class="md-nav__link">
    oob_prediction_
  </a>
  
</li>
        
          <li class="md-nav__item">
  <a href="#to_string_6" class="md-nav__link">
    to_string
  </a>
  
</li>
        
          <li class="md-nav__item">
  <a href="#show_6" class="md-nav__link">
    show
  </a>
  
</li>
        
          <li class="md-nav__item">
  <a href="#pp_6" class="md-nav__link">
    pp
  </a>
  
</li>
        
      </ul>
    </nav>
  
</li>
      
        <li class="md-nav__item">
  <a href="#gradientboostingclassifier" class="md-nav__link">
    GradientBoostingClassifier
  </a>
  
    <nav class="md-nav" aria-label="GradientBoostingClassifier">
      <ul class="md-nav__list">
        
          <li class="md-nav__item">
  <a href="#create_6" class="md-nav__link">
    create
  </a>
  
</li>
        
          <li class="md-nav__item">
  <a href="#get_item_7" class="md-nav__link">
    get_item
  </a>
  
</li>
        
          <li class="md-nav__item">
  <a href="#iter_7" class="md-nav__link">
    iter
  </a>
  
</li>
        
          <li class="md-nav__item">
  <a href="#apply_2" class="md-nav__link">
    apply
  </a>
  
</li>
        
          <li class="md-nav__item">
  <a href="#decision_function_1" class="md-nav__link">
    decision_function
  </a>
  
</li>
        
          <li class="md-nav__item">
  <a href="#fit_6" class="md-nav__link">
    fit
  </a>
  
</li>
        
          <li class="md-nav__item">
  <a href="#get_params_7" class="md-nav__link">
    get_params
  </a>
  
</li>
        
          <li class="md-nav__item">
  <a href="#predict_6" class="md-nav__link">
    predict
  </a>
  
</li>
        
          <li class="md-nav__item">
  <a href="#predict_log_proba_3" class="md-nav__link">
    predict_log_proba
  </a>
  
</li>
        
          <li class="md-nav__item">
  <a href="#predict_proba_3" class="md-nav__link">
    predict_proba
  </a>
  
</li>
        
          <li class="md-nav__item">
  <a href="#score_6" class="md-nav__link">
    score
  </a>
  
</li>
        
          <li class="md-nav__item">
  <a href="#set_params_7" class="md-nav__link">
    set_params
  </a>
  
</li>
        
          <li class="md-nav__item">
  <a href="#staged_decision_function_1" class="md-nav__link">
    staged_decision_function
  </a>
  
</li>
        
          <li class="md-nav__item">
  <a href="#staged_predict_2" class="md-nav__link">
    staged_predict
  </a>
  
</li>
        
          <li class="md-nav__item">
  <a href="#staged_predict_proba_1" class="md-nav__link">
    staged_predict_proba
  </a>
  
</li>
        
          <li class="md-nav__item">
  <a href="#n_estimators_" class="md-nav__link">
    n_estimators_
  </a>
  
</li>
        
          <li class="md-nav__item">
  <a href="#feature_importances__4" class="md-nav__link">
    feature_importances_
  </a>
  
</li>
        
          <li class="md-nav__item">
  <a href="#warning_4" class="md-nav__link">
    warning
  </a>
  
</li>
        
          <li class="md-nav__item">
  <a href="#oob_improvement_" class="md-nav__link">
    oob_improvement_
  </a>
  
</li>
        
          <li class="md-nav__item">
  <a href="#train_score_" class="md-nav__link">
    train_score_
  </a>
  
</li>
        
          <li class="md-nav__item">
  <a href="#loss_" class="md-nav__link">
    loss_
  </a>
  
</li>
        
          <li class="md-nav__item">
  <a href="#init_" class="md-nav__link">
    init_
  </a>
  
</li>
        
          <li class="md-nav__item">
  <a href="#estimators__7" class="md-nav__link">
    estimators_
  </a>
  
</li>
        
          <li class="md-nav__item">
  <a href="#classes__3" class="md-nav__link">
    classes_
  </a>
  
</li>
        
          <li class="md-nav__item">
  <a href="#n_features__4" class="md-nav__link">
    n_features_
  </a>
  
</li>
        
          <li class="md-nav__item">
  <a href="#n_classes__3" class="md-nav__link">
    n_classes_
  </a>
  
</li>
        
          <li class="md-nav__item">
  <a href="#max_features_" class="md-nav__link">
    max_features_
  </a>
  
</li>
        
          <li class="md-nav__item">
  <a href="#to_string_7" class="md-nav__link">
    to_string
  </a>
  
</li>
        
          <li class="md-nav__item">
  <a href="#show_7" class="md-nav__link">
    show
  </a>
  
</li>
        
          <li class="md-nav__item">
  <a href="#pp_7" class="md-nav__link">
    pp
  </a>
  
</li>
        
      </ul>
    </nav>
  
</li>
      
        <li class="md-nav__item">
  <a href="#gradientboostingregressor" class="md-nav__link">
    GradientBoostingRegressor
  </a>
  
    <nav class="md-nav" aria-label="GradientBoostingRegressor">
      <ul class="md-nav__list">
        
          <li class="md-nav__item">
  <a href="#create_7" class="md-nav__link">
    create
  </a>
  
</li>
        
          <li class="md-nav__item">
  <a href="#get_item_8" class="md-nav__link">
    get_item
  </a>
  
</li>
        
          <li class="md-nav__item">
  <a href="#iter_8" class="md-nav__link">
    iter
  </a>
  
</li>
        
          <li class="md-nav__item">
  <a href="#apply_3" class="md-nav__link">
    apply
  </a>
  
</li>
        
          <li class="md-nav__item">
  <a href="#fit_7" class="md-nav__link">
    fit
  </a>
  
</li>
        
          <li class="md-nav__item">
  <a href="#get_params_8" class="md-nav__link">
    get_params
  </a>
  
</li>
        
          <li class="md-nav__item">
  <a href="#predict_7" class="md-nav__link">
    predict
  </a>
  
</li>
        
          <li class="md-nav__item">
  <a href="#score_7" class="md-nav__link">
    score
  </a>
  
</li>
        
          <li class="md-nav__item">
  <a href="#set_params_8" class="md-nav__link">
    set_params
  </a>
  
</li>
        
          <li class="md-nav__item">
  <a href="#staged_predict_3" class="md-nav__link">
    staged_predict
  </a>
  
</li>
        
          <li class="md-nav__item">
  <a href="#feature_importances__5" class="md-nav__link">
    feature_importances_
  </a>
  
</li>
        
          <li class="md-nav__item">
  <a href="#warning_5" class="md-nav__link">
    warning
  </a>
  
</li>
        
          <li class="md-nav__item">
  <a href="#oob_improvement__1" class="md-nav__link">
    oob_improvement_
  </a>
  
</li>
        
          <li class="md-nav__item">
  <a href="#train_score__1" class="md-nav__link">
    train_score_
  </a>
  
</li>
        
          <li class="md-nav__item">
  <a href="#loss__1" class="md-nav__link">
    loss_
  </a>
  
</li>
        
          <li class="md-nav__item">
  <a href="#init__1" class="md-nav__link">
    init_
  </a>
  
</li>
        
          <li class="md-nav__item">
  <a href="#estimators__8" class="md-nav__link">
    estimators_
  </a>
  
</li>
        
          <li class="md-nav__item">
  <a href="#n_features__5" class="md-nav__link">
    n_features_
  </a>
  
</li>
        
          <li class="md-nav__item">
  <a href="#max_features__1" class="md-nav__link">
    max_features_
  </a>
  
</li>
        
          <li class="md-nav__item">
  <a href="#to_string_8" class="md-nav__link">
    to_string
  </a>
  
</li>
        
          <li class="md-nav__item">
  <a href="#show_8" class="md-nav__link">
    show
  </a>
  
</li>
        
          <li class="md-nav__item">
  <a href="#pp_8" class="md-nav__link">
    pp
  </a>
  
</li>
        
      </ul>
    </nav>
  
</li>
      
        <li class="md-nav__item">
  <a href="#isolationforest" class="md-nav__link">
    IsolationForest
  </a>
  
    <nav class="md-nav" aria-label="IsolationForest">
      <ul class="md-nav__list">
        
          <li class="md-nav__item">
  <a href="#create_8" class="md-nav__link">
    create
  </a>
  
</li>
        
          <li class="md-nav__item">
  <a href="#get_item_9" class="md-nav__link">
    get_item
  </a>
  
</li>
        
          <li class="md-nav__item">
  <a href="#iter_9" class="md-nav__link">
    iter
  </a>
  
</li>
        
          <li class="md-nav__item">
  <a href="#decision_function_2" class="md-nav__link">
    decision_function
  </a>
  
</li>
        
          <li class="md-nav__item">
  <a href="#fit_8" class="md-nav__link">
    fit
  </a>
  
</li>
        
          <li class="md-nav__item">
  <a href="#fit_predict" class="md-nav__link">
    fit_predict
  </a>
  
</li>
        
          <li class="md-nav__item">
  <a href="#get_params_9" class="md-nav__link">
    get_params
  </a>
  
</li>
        
          <li class="md-nav__item">
  <a href="#predict_8" class="md-nav__link">
    predict
  </a>
  
</li>
        
          <li class="md-nav__item">
  <a href="#score_samples" class="md-nav__link">
    score_samples
  </a>
  
</li>
        
          <li class="md-nav__item">
  <a href="#set_params_9" class="md-nav__link">
    set_params
  </a>
  
</li>
        
          <li class="md-nav__item">
  <a href="#estimators__9" class="md-nav__link">
    estimators_
  </a>
  
</li>
        
          <li class="md-nav__item">
  <a href="#estimators_samples__2" class="md-nav__link">
    estimators_samples_
  </a>
  
</li>
        
          <li class="md-nav__item">
  <a href="#max_samples_" class="md-nav__link">
    max_samples_
  </a>
  
</li>
        
          <li class="md-nav__item">
  <a href="#offset_" class="md-nav__link">
    offset_
  </a>
  
</li>
        
          <li class="md-nav__item">
  <a href="#estimators_features__2" class="md-nav__link">
    estimators_features_
  </a>
  
</li>
        
          <li class="md-nav__item">
  <a href="#to_string_9" class="md-nav__link">
    to_string
  </a>
  
</li>
        
          <li class="md-nav__item">
  <a href="#show_9" class="md-nav__link">
    show
  </a>
  
</li>
        
          <li class="md-nav__item">
  <a href="#pp_9" class="md-nav__link">
    pp
  </a>
  
</li>
        
      </ul>
    </nav>
  
</li>
      
        <li class="md-nav__item">
  <a href="#randomforestclassifier" class="md-nav__link">
    RandomForestClassifier
  </a>
  
    <nav class="md-nav" aria-label="RandomForestClassifier">
      <ul class="md-nav__list">
        
          <li class="md-nav__item">
  <a href="#create_9" class="md-nav__link">
    create
  </a>
  
</li>
        
          <li class="md-nav__item">
  <a href="#get_item_10" class="md-nav__link">
    get_item
  </a>
  
</li>
        
          <li class="md-nav__item">
  <a href="#iter_10" class="md-nav__link">
    iter
  </a>
  
</li>
        
          <li class="md-nav__item">
  <a href="#apply_4" class="md-nav__link">
    apply
  </a>
  
</li>
        
          <li class="md-nav__item">
  <a href="#decision_path_2" class="md-nav__link">
    decision_path
  </a>
  
</li>
        
          <li class="md-nav__item">
  <a href="#fit_9" class="md-nav__link">
    fit
  </a>
  
</li>
        
          <li class="md-nav__item">
  <a href="#get_params_10" class="md-nav__link">
    get_params
  </a>
  
</li>
        
          <li class="md-nav__item">
  <a href="#predict_9" class="md-nav__link">
    predict
  </a>
  
</li>
        
          <li class="md-nav__item">
  <a href="#predict_log_proba_4" class="md-nav__link">
    predict_log_proba
  </a>
  
</li>
        
          <li class="md-nav__item">
  <a href="#predict_proba_4" class="md-nav__link">
    predict_proba
  </a>
  
</li>
        
          <li class="md-nav__item">
  <a href="#score_8" class="md-nav__link">
    score
  </a>
  
</li>
        
          <li class="md-nav__item">
  <a href="#set_params_10" class="md-nav__link">
    set_params
  </a>
  
</li>
        
          <li class="md-nav__item">
  <a href="#base_estimator__7" class="md-nav__link">
    base_estimator_
  </a>
  
</li>
        
          <li class="md-nav__item">
  <a href="#estimators__10" class="md-nav__link">
    estimators_
  </a>
  
</li>
        
          <li class="md-nav__item">
  <a href="#classes__4" class="md-nav__link">
    classes_
  </a>
  
</li>
        
          <li class="md-nav__item">
  <a href="#n_classes__4" class="md-nav__link">
    n_classes_
  </a>
  
</li>
        
          <li class="md-nav__item">
  <a href="#n_features__6" class="md-nav__link">
    n_features_
  </a>
  
</li>
        
          <li class="md-nav__item">
  <a href="#n_outputs__2" class="md-nav__link">
    n_outputs_
  </a>
  
</li>
        
          <li class="md-nav__item">
  <a href="#feature_importances__6" class="md-nav__link">
    feature_importances_
  </a>
  
</li>
        
          <li class="md-nav__item">
  <a href="#warning_6" class="md-nav__link">
    warning
  </a>
  
</li>
        
          <li class="md-nav__item">
  <a href="#oob_score__4" class="md-nav__link">
    oob_score_
  </a>
  
</li>
        
          <li class="md-nav__item">
  <a href="#oob_decision_function__2" class="md-nav__link">
    oob_decision_function_
  </a>
  
</li>
        
          <li class="md-nav__item">
  <a href="#to_string_10" class="md-nav__link">
    to_string
  </a>
  
</li>
        
          <li class="md-nav__item">
  <a href="#show_10" class="md-nav__link">
    show
  </a>
  
</li>
        
          <li class="md-nav__item">
  <a href="#pp_10" class="md-nav__link">
    pp
  </a>
  
</li>
        
      </ul>
    </nav>
  
</li>
      
        <li class="md-nav__item">
  <a href="#randomforestregressor" class="md-nav__link">
    RandomForestRegressor
  </a>
  
    <nav class="md-nav" aria-label="RandomForestRegressor">
      <ul class="md-nav__list">
        
          <li class="md-nav__item">
  <a href="#create_10" class="md-nav__link">
    create
  </a>
  
</li>
        
          <li class="md-nav__item">
  <a href="#get_item_11" class="md-nav__link">
    get_item
  </a>
  
</li>
        
          <li class="md-nav__item">
  <a href="#iter_11" class="md-nav__link">
    iter
  </a>
  
</li>
        
          <li class="md-nav__item">
  <a href="#apply_5" class="md-nav__link">
    apply
  </a>
  
</li>
        
          <li class="md-nav__item">
  <a href="#decision_path_3" class="md-nav__link">
    decision_path
  </a>
  
</li>
        
          <li class="md-nav__item">
  <a href="#fit_10" class="md-nav__link">
    fit
  </a>
  
</li>
        
          <li class="md-nav__item">
  <a href="#get_params_11" class="md-nav__link">
    get_params
  </a>
  
</li>
        
          <li class="md-nav__item">
  <a href="#predict_10" class="md-nav__link">
    predict
  </a>
  
</li>
        
          <li class="md-nav__item">
  <a href="#score_9" class="md-nav__link">
    score
  </a>
  
</li>
        
          <li class="md-nav__item">
  <a href="#set_params_11" class="md-nav__link">
    set_params
  </a>
  
</li>
        
          <li class="md-nav__item">
  <a href="#base_estimator__8" class="md-nav__link">
    base_estimator_
  </a>
  
</li>
        
          <li class="md-nav__item">
  <a href="#estimators__11" class="md-nav__link">
    estimators_
  </a>
  
</li>
        
          <li class="md-nav__item">
  <a href="#feature_importances__7" class="md-nav__link">
    feature_importances_
  </a>
  
</li>
        
          <li class="md-nav__item">
  <a href="#warning_7" class="md-nav__link">
    warning
  </a>
  
</li>
        
          <li class="md-nav__item">
  <a href="#n_features__7" class="md-nav__link">
    n_features_
  </a>
  
</li>
        
          <li class="md-nav__item">
  <a href="#n_outputs__3" class="md-nav__link">
    n_outputs_
  </a>
  
</li>
        
          <li class="md-nav__item">
  <a href="#oob_score__5" class="md-nav__link">
    oob_score_
  </a>
  
</li>
        
          <li class="md-nav__item">
  <a href="#oob_prediction__2" class="md-nav__link">
    oob_prediction_
  </a>
  
</li>
        
          <li class="md-nav__item">
  <a href="#to_string_11" class="md-nav__link">
    to_string
  </a>
  
</li>
        
          <li class="md-nav__item">
  <a href="#show_11" class="md-nav__link">
    show
  </a>
  
</li>
        
          <li class="md-nav__item">
  <a href="#pp_11" class="md-nav__link">
    pp
  </a>
  
</li>
        
      </ul>
    </nav>
  
</li>
      
        <li class="md-nav__item">
  <a href="#randomtreesembedding" class="md-nav__link">
    RandomTreesEmbedding
  </a>
  
    <nav class="md-nav" aria-label="RandomTreesEmbedding">
      <ul class="md-nav__list">
        
          <li class="md-nav__item">
  <a href="#create_11" class="md-nav__link">
    create
  </a>
  
</li>
        
          <li class="md-nav__item">
  <a href="#get_item_12" class="md-nav__link">
    get_item
  </a>
  
</li>
        
          <li class="md-nav__item">
  <a href="#iter_12" class="md-nav__link">
    iter
  </a>
  
</li>
        
          <li class="md-nav__item">
  <a href="#apply_6" class="md-nav__link">
    apply
  </a>
  
</li>
        
          <li class="md-nav__item">
  <a href="#decision_path_4" class="md-nav__link">
    decision_path
  </a>
  
</li>
        
          <li class="md-nav__item">
  <a href="#fit_11" class="md-nav__link">
    fit
  </a>
  
</li>
        
          <li class="md-nav__item">
  <a href="#fit_transform" class="md-nav__link">
    fit_transform
  </a>
  
</li>
        
          <li class="md-nav__item">
  <a href="#get_params_12" class="md-nav__link">
    get_params
  </a>
  
</li>
        
          <li class="md-nav__item">
  <a href="#set_params_12" class="md-nav__link">
    set_params
  </a>
  
</li>
        
          <li class="md-nav__item">
  <a href="#transform" class="md-nav__link">
    transform
  </a>
  
</li>
        
          <li class="md-nav__item">
  <a href="#estimators__12" class="md-nav__link">
    estimators_
  </a>
  
</li>
        
          <li class="md-nav__item">
  <a href="#to_string_12" class="md-nav__link">
    to_string
  </a>
  
</li>
        
          <li class="md-nav__item">
  <a href="#show_12" class="md-nav__link">
    show
  </a>
  
</li>
        
          <li class="md-nav__item">
  <a href="#pp_12" class="md-nav__link">
    pp
  </a>
  
</li>
        
      </ul>
    </nav>
  
</li>
      
        <li class="md-nav__item">
  <a href="#stackingclassifier" class="md-nav__link">
    StackingClassifier
  </a>
  
    <nav class="md-nav" aria-label="StackingClassifier">
      <ul class="md-nav__list">
        
          <li class="md-nav__item">
  <a href="#create_12" class="md-nav__link">
    create
  </a>
  
</li>
        
          <li class="md-nav__item">
  <a href="#decision_function_3" class="md-nav__link">
    decision_function
  </a>
  
</li>
        
          <li class="md-nav__item">
  <a href="#fit_12" class="md-nav__link">
    fit
  </a>
  
</li>
        
          <li class="md-nav__item">
  <a href="#fit_transform_1" class="md-nav__link">
    fit_transform
  </a>
  
</li>
        
          <li class="md-nav__item">
  <a href="#get_params_13" class="md-nav__link">
    get_params
  </a>
  
</li>
        
          <li class="md-nav__item">
  <a href="#predict_11" class="md-nav__link">
    predict
  </a>
  
</li>
        
          <li class="md-nav__item">
  <a href="#predict_proba_5" class="md-nav__link">
    predict_proba
  </a>
  
</li>
        
          <li class="md-nav__item">
  <a href="#score_10" class="md-nav__link">
    score
  </a>
  
</li>
        
          <li class="md-nav__item">
  <a href="#set_params_13" class="md-nav__link">
    set_params
  </a>
  
</li>
        
          <li class="md-nav__item">
  <a href="#transform_1" class="md-nav__link">
    transform
  </a>
  
</li>
        
          <li class="md-nav__item">
  <a href="#classes__5" class="md-nav__link">
    classes_
  </a>
  
</li>
        
          <li class="md-nav__item">
  <a href="#estimators__13" class="md-nav__link">
    estimators_
  </a>
  
</li>
        
          <li class="md-nav__item">
  <a href="#named_estimators_" class="md-nav__link">
    named_estimators_
  </a>
  
</li>
        
          <li class="md-nav__item">
  <a href="#final_estimator_" class="md-nav__link">
    final_estimator_
  </a>
  
</li>
        
          <li class="md-nav__item">
  <a href="#stack_method_" class="md-nav__link">
    stack_method_
  </a>
  
</li>
        
          <li class="md-nav__item">
  <a href="#to_string_13" class="md-nav__link">
    to_string
  </a>
  
</li>
        
          <li class="md-nav__item">
  <a href="#show_13" class="md-nav__link">
    show
  </a>
  
</li>
        
          <li class="md-nav__item">
  <a href="#pp_13" class="md-nav__link">
    pp
  </a>
  
</li>
        
      </ul>
    </nav>
  
</li>
      
        <li class="md-nav__item">
  <a href="#stackingregressor" class="md-nav__link">
    StackingRegressor
  </a>
  
    <nav class="md-nav" aria-label="StackingRegressor">
      <ul class="md-nav__list">
        
          <li class="md-nav__item">
  <a href="#create_13" class="md-nav__link">
    create
  </a>
  
</li>
        
          <li class="md-nav__item">
  <a href="#fit_13" class="md-nav__link">
    fit
  </a>
  
</li>
        
          <li class="md-nav__item">
  <a href="#fit_transform_2" class="md-nav__link">
    fit_transform
  </a>
  
</li>
        
          <li class="md-nav__item">
  <a href="#get_params_14" class="md-nav__link">
    get_params
  </a>
  
</li>
        
          <li class="md-nav__item">
  <a href="#predict_12" class="md-nav__link">
    predict
  </a>
  
</li>
        
          <li class="md-nav__item">
  <a href="#score_11" class="md-nav__link">
    score
  </a>
  
</li>
        
          <li class="md-nav__item">
  <a href="#set_params_14" class="md-nav__link">
    set_params
  </a>
  
</li>
        
          <li class="md-nav__item">
  <a href="#transform_2" class="md-nav__link">
    transform
  </a>
  
</li>
        
          <li class="md-nav__item">
  <a href="#estimators__14" class="md-nav__link">
    estimators_
  </a>
  
</li>
        
          <li class="md-nav__item">
  <a href="#named_estimators__1" class="md-nav__link">
    named_estimators_
  </a>
  
</li>
        
          <li class="md-nav__item">
  <a href="#final_estimator__1" class="md-nav__link">
    final_estimator_
  </a>
  
</li>
        
          <li class="md-nav__item">
  <a href="#to_string_14" class="md-nav__link">
    to_string
  </a>
  
</li>
        
          <li class="md-nav__item">
  <a href="#show_14" class="md-nav__link">
    show
  </a>
  
</li>
        
          <li class="md-nav__item">
  <a href="#pp_14" class="md-nav__link">
    pp
  </a>
  
</li>
        
      </ul>
    </nav>
  
</li>
      
        <li class="md-nav__item">
  <a href="#votingclassifier" class="md-nav__link">
    VotingClassifier
  </a>
  
    <nav class="md-nav" aria-label="VotingClassifier">
      <ul class="md-nav__list">
        
          <li class="md-nav__item">
  <a href="#create_14" class="md-nav__link">
    create
  </a>
  
</li>
        
          <li class="md-nav__item">
  <a href="#fit_14" class="md-nav__link">
    fit
  </a>
  
</li>
        
          <li class="md-nav__item">
  <a href="#fit_transform_3" class="md-nav__link">
    fit_transform
  </a>
  
</li>
        
          <li class="md-nav__item">
  <a href="#get_params_15" class="md-nav__link">
    get_params
  </a>
  
</li>
        
          <li class="md-nav__item">
  <a href="#predict_13" class="md-nav__link">
    predict
  </a>
  
</li>
        
          <li class="md-nav__item">
  <a href="#score_12" class="md-nav__link">
    score
  </a>
  
</li>
        
          <li class="md-nav__item">
  <a href="#set_params_15" class="md-nav__link">
    set_params
  </a>
  
</li>
        
          <li class="md-nav__item">
  <a href="#transform_3" class="md-nav__link">
    transform
  </a>
  
</li>
        
          <li class="md-nav__item">
  <a href="#estimators__15" class="md-nav__link">
    estimators_
  </a>
  
</li>
        
          <li class="md-nav__item">
  <a href="#named_estimators__2" class="md-nav__link">
    named_estimators_
  </a>
  
</li>
        
          <li class="md-nav__item">
  <a href="#classes__6" class="md-nav__link">
    classes_
  </a>
  
</li>
        
          <li class="md-nav__item">
  <a href="#to_string_15" class="md-nav__link">
    to_string
  </a>
  
</li>
        
          <li class="md-nav__item">
  <a href="#show_15" class="md-nav__link">
    show
  </a>
  
</li>
        
          <li class="md-nav__item">
  <a href="#pp_15" class="md-nav__link">
    pp
  </a>
  
</li>
        
      </ul>
    </nav>
  
</li>
      
        <li class="md-nav__item">
  <a href="#votingregressor" class="md-nav__link">
    VotingRegressor
  </a>
  
    <nav class="md-nav" aria-label="VotingRegressor">
      <ul class="md-nav__list">
        
          <li class="md-nav__item">
  <a href="#create_15" class="md-nav__link">
    create
  </a>
  
</li>
        
          <li class="md-nav__item">
  <a href="#fit_15" class="md-nav__link">
    fit
  </a>
  
</li>
        
          <li class="md-nav__item">
  <a href="#fit_transform_4" class="md-nav__link">
    fit_transform
  </a>
  
</li>
        
          <li class="md-nav__item">
  <a href="#get_params_16" class="md-nav__link">
    get_params
  </a>
  
</li>
        
          <li class="md-nav__item">
  <a href="#predict_14" class="md-nav__link">
    predict
  </a>
  
</li>
        
          <li class="md-nav__item">
  <a href="#score_13" class="md-nav__link">
    score
  </a>
  
</li>
        
          <li class="md-nav__item">
  <a href="#set_params_16" class="md-nav__link">
    set_params
  </a>
  
</li>
        
          <li class="md-nav__item">
  <a href="#transform_4" class="md-nav__link">
    transform
  </a>
  
</li>
        
          <li class="md-nav__item">
  <a href="#estimators__16" class="md-nav__link">
    estimators_
  </a>
  
</li>
        
          <li class="md-nav__item">
  <a href="#named_estimators__3" class="md-nav__link">
    named_estimators_
  </a>
  
</li>
        
          <li class="md-nav__item">
  <a href="#to_string_16" class="md-nav__link">
    to_string
  </a>
  
</li>
        
          <li class="md-nav__item">
  <a href="#show_16" class="md-nav__link">
    show
  </a>
  
</li>
        
          <li class="md-nav__item">
  <a href="#pp_16" class="md-nav__link">
    pp
  </a>
  
</li>
        
      </ul>
    </nav>
  
</li>
      
    </ul>
  
</nav>
    
  </li>

        
          
          
          


  <li class="md-nav__item">
    <a href="../Exceptions/" class="md-nav__link">
      Exceptions
    </a>
  </li>

        
          
          
          


  <li class="md-nav__item">
    <a href="../Experimental/" class="md-nav__link">
      Experimental
    </a>
  </li>

        
          
          
          


  <li class="md-nav__item">
    <a href="../Externals/" class="md-nav__link">
      Externals
    </a>
  </li>

        
          
          
          


  <li class="md-nav__item">
    <a href="../Feature_extraction/" class="md-nav__link">
      Feature extraction
    </a>
  </li>

        
          
          
          


  <li class="md-nav__item">
    <a href="../Feature_selection/" class="md-nav__link">
      Feature selection
    </a>
  </li>

        
          
          
          


  <li class="md-nav__item">
    <a href="../Gaussian_process/" class="md-nav__link">
      Gaussian process
    </a>
  </li>

        
          
          
          


  <li class="md-nav__item">
    <a href="../Impute/" class="md-nav__link">
      Impute
    </a>
  </li>

        
          
          
          


  <li class="md-nav__item">
    <a href="../Inspection/" class="md-nav__link">
      Inspection
    </a>
  </li>

        
          
          
          


  <li class="md-nav__item">
    <a href="../Isotonic/" class="md-nav__link">
      Isotonic
    </a>
  </li>

        
          
          
          


  <li class="md-nav__item">
    <a href="../Kernel_approximation/" class="md-nav__link">
      Kernel approximation
    </a>
  </li>

        
          
          
          


  <li class="md-nav__item">
    <a href="../Kernel_ridge/" class="md-nav__link">
      Kernel ridge
    </a>
  </li>

        
          
          
          


  <li class="md-nav__item">
    <a href="../Linear_model/" class="md-nav__link">
      Linear model
    </a>
  </li>

        
          
          
          


  <li class="md-nav__item">
    <a href="../Manifold/" class="md-nav__link">
      Manifold
    </a>
  </li>

        
          
          
          


  <li class="md-nav__item">
    <a href="../Metrics/" class="md-nav__link">
      Metrics
    </a>
  </li>

        
          
          
          


  <li class="md-nav__item">
    <a href="../Mixture/" class="md-nav__link">
      Mixture
    </a>
  </li>

        
          
          
          


  <li class="md-nav__item">
    <a href="../Model_selection/" class="md-nav__link">
      Model selection
    </a>
  </li>

        
          
          
          


  <li class="md-nav__item">
    <a href="../Multiclass/" class="md-nav__link">
      Multiclass
    </a>
  </li>

        
          
          
          


  <li class="md-nav__item">
    <a href="../Multioutput/" class="md-nav__link">
      Multioutput
    </a>
  </li>

        
          
          
          


  <li class="md-nav__item">
    <a href="../Naive_bayes/" class="md-nav__link">
      Naive bayes
    </a>
  </li>

        
          
          
          


  <li class="md-nav__item">
    <a href="../Neighbors/" class="md-nav__link">
      Neighbors
    </a>
  </li>

        
          
          
          


  <li class="md-nav__item">
    <a href="../Neural_network/" class="md-nav__link">
      Neural network
    </a>
  </li>

        
          
          
          


  <li class="md-nav__item">
    <a href="../Pipeline/" class="md-nav__link">
      Pipeline
    </a>
  </li>

        
          
          
          


  <li class="md-nav__item">
    <a href="../Preprocessing/" class="md-nav__link">
      Preprocessing
    </a>
  </li>

        
          
          
          


  <li class="md-nav__item">
    <a href="../Random_projection/" class="md-nav__link">
      Random projection
    </a>
  </li>

        
          
          
          


  <li class="md-nav__item">
    <a href="../Semi_supervised/" class="md-nav__link">
      Semi supervised
    </a>
  </li>

        
          
          
          


  <li class="md-nav__item">
    <a href="../Setup/" class="md-nav__link">
      Setup
    </a>
  </li>

        
          
          
          


  <li class="md-nav__item">
    <a href="../Svm/" class="md-nav__link">
      Svm
    </a>
  </li>

        
          
          
          


  <li class="md-nav__item">
    <a href="../Tests/" class="md-nav__link">
      Tests
    </a>
  </li>

        
          
          
          


  <li class="md-nav__item">
    <a href="../Tree/" class="md-nav__link">
      Tree
    </a>
  </li>

        
          
          
          


  <li class="md-nav__item">
    <a href="../Utils/" class="md-nav__link">
      Utils
    </a>
  </li>

        
          
          
          


  <li class="md-nav__item">
    <a href="../arr/" class="md-nav__link">
      Arr
    </a>
  </li>

        
          
          
          


  <li class="md-nav__item">
    <a href="../dict/" class="md-nav__link">
      Dict
    </a>
  </li>

        
          
          
          


  <li class="md-nav__item">
    <a href="../wrap_version/" class="md-nav__link">
      Wrap version
    </a>
  </li>

        
      </ul>
    </nav>
  </li>

    
  </ul>
</nav>
                  </div>
                </div>
              </div>
            
            
              <div class="md-sidebar md-sidebar--secondary" data-md-component="toc">
                <div class="md-sidebar__scrollwrap">
                  <div class="md-sidebar__inner">
                    
<nav class="md-nav md-nav--secondary" aria-label="Table of contents">
  
  
  
    <label class="md-nav__title" for="__toc">
      <span class="md-nav__icon md-icon"></span>
      Table of contents
    </label>
    <ul class="md-nav__list" data-md-scrollfix>
      
        <li class="md-nav__item">
  <a href="#adaboostclassifier" class="md-nav__link">
    AdaBoostClassifier
  </a>
  
    <nav class="md-nav" aria-label="AdaBoostClassifier">
      <ul class="md-nav__list">
        
          <li class="md-nav__item">
  <a href="#create" class="md-nav__link">
    create
  </a>
  
</li>
        
          <li class="md-nav__item">
  <a href="#get_item" class="md-nav__link">
    get_item
  </a>
  
</li>
        
          <li class="md-nav__item">
  <a href="#iter" class="md-nav__link">
    iter
  </a>
  
</li>
        
          <li class="md-nav__item">
  <a href="#decision_function" class="md-nav__link">
    decision_function
  </a>
  
</li>
        
          <li class="md-nav__item">
  <a href="#fit" class="md-nav__link">
    fit
  </a>
  
</li>
        
          <li class="md-nav__item">
  <a href="#get_params" class="md-nav__link">
    get_params
  </a>
  
</li>
        
          <li class="md-nav__item">
  <a href="#predict" class="md-nav__link">
    predict
  </a>
  
</li>
        
          <li class="md-nav__item">
  <a href="#predict_log_proba" class="md-nav__link">
    predict_log_proba
  </a>
  
</li>
        
          <li class="md-nav__item">
  <a href="#predict_proba" class="md-nav__link">
    predict_proba
  </a>
  
</li>
        
          <li class="md-nav__item">
  <a href="#score" class="md-nav__link">
    score
  </a>
  
</li>
        
          <li class="md-nav__item">
  <a href="#set_params" class="md-nav__link">
    set_params
  </a>
  
</li>
        
          <li class="md-nav__item">
  <a href="#staged_decision_function" class="md-nav__link">
    staged_decision_function
  </a>
  
</li>
        
          <li class="md-nav__item">
  <a href="#staged_predict" class="md-nav__link">
    staged_predict
  </a>
  
</li>
        
          <li class="md-nav__item">
  <a href="#staged_predict_proba" class="md-nav__link">
    staged_predict_proba
  </a>
  
</li>
        
          <li class="md-nav__item">
  <a href="#staged_score" class="md-nav__link">
    staged_score
  </a>
  
</li>
        
          <li class="md-nav__item">
  <a href="#base_estimator_" class="md-nav__link">
    base_estimator_
  </a>
  
</li>
        
          <li class="md-nav__item">
  <a href="#estimators_" class="md-nav__link">
    estimators_
  </a>
  
</li>
        
          <li class="md-nav__item">
  <a href="#classes_" class="md-nav__link">
    classes_
  </a>
  
</li>
        
          <li class="md-nav__item">
  <a href="#n_classes_" class="md-nav__link">
    n_classes_
  </a>
  
</li>
        
          <li class="md-nav__item">
  <a href="#estimator_weights_" class="md-nav__link">
    estimator_weights_
  </a>
  
</li>
        
          <li class="md-nav__item">
  <a href="#estimator_errors_" class="md-nav__link">
    estimator_errors_
  </a>
  
</li>
        
          <li class="md-nav__item">
  <a href="#feature_importances_" class="md-nav__link">
    feature_importances_
  </a>
  
</li>
        
          <li class="md-nav__item">
  <a href="#warning" class="md-nav__link">
    warning
  </a>
  
</li>
        
          <li class="md-nav__item">
  <a href="#to_string" class="md-nav__link">
    to_string
  </a>
  
</li>
        
          <li class="md-nav__item">
  <a href="#show" class="md-nav__link">
    show
  </a>
  
</li>
        
          <li class="md-nav__item">
  <a href="#pp" class="md-nav__link">
    pp
  </a>
  
</li>
        
      </ul>
    </nav>
  
</li>
      
        <li class="md-nav__item">
  <a href="#adaboostregressor" class="md-nav__link">
    AdaBoostRegressor
  </a>
  
    <nav class="md-nav" aria-label="AdaBoostRegressor">
      <ul class="md-nav__list">
        
          <li class="md-nav__item">
  <a href="#create_1" class="md-nav__link">
    create
  </a>
  
</li>
        
          <li class="md-nav__item">
  <a href="#get_item_1" class="md-nav__link">
    get_item
  </a>
  
</li>
        
          <li class="md-nav__item">
  <a href="#iter_1" class="md-nav__link">
    iter
  </a>
  
</li>
        
          <li class="md-nav__item">
  <a href="#fit_1" class="md-nav__link">
    fit
  </a>
  
</li>
        
          <li class="md-nav__item">
  <a href="#get_params_1" class="md-nav__link">
    get_params
  </a>
  
</li>
        
          <li class="md-nav__item">
  <a href="#predict_1" class="md-nav__link">
    predict
  </a>
  
</li>
        
          <li class="md-nav__item">
  <a href="#score_1" class="md-nav__link">
    score
  </a>
  
</li>
        
          <li class="md-nav__item">
  <a href="#set_params_1" class="md-nav__link">
    set_params
  </a>
  
</li>
        
          <li class="md-nav__item">
  <a href="#staged_predict_1" class="md-nav__link">
    staged_predict
  </a>
  
</li>
        
          <li class="md-nav__item">
  <a href="#staged_score_1" class="md-nav__link">
    staged_score
  </a>
  
</li>
        
          <li class="md-nav__item">
  <a href="#base_estimator__1" class="md-nav__link">
    base_estimator_
  </a>
  
</li>
        
          <li class="md-nav__item">
  <a href="#estimators__1" class="md-nav__link">
    estimators_
  </a>
  
</li>
        
          <li class="md-nav__item">
  <a href="#estimator_weights__1" class="md-nav__link">
    estimator_weights_
  </a>
  
</li>
        
          <li class="md-nav__item">
  <a href="#estimator_errors__1" class="md-nav__link">
    estimator_errors_
  </a>
  
</li>
        
          <li class="md-nav__item">
  <a href="#feature_importances__1" class="md-nav__link">
    feature_importances_
  </a>
  
</li>
        
          <li class="md-nav__item">
  <a href="#warning_1" class="md-nav__link">
    warning
  </a>
  
</li>
        
          <li class="md-nav__item">
  <a href="#to_string_1" class="md-nav__link">
    to_string
  </a>
  
</li>
        
          <li class="md-nav__item">
  <a href="#show_1" class="md-nav__link">
    show
  </a>
  
</li>
        
          <li class="md-nav__item">
  <a href="#pp_1" class="md-nav__link">
    pp
  </a>
  
</li>
        
      </ul>
    </nav>
  
</li>
      
        <li class="md-nav__item">
  <a href="#baggingclassifier" class="md-nav__link">
    BaggingClassifier
  </a>
  
    <nav class="md-nav" aria-label="BaggingClassifier">
      <ul class="md-nav__list">
        
          <li class="md-nav__item">
  <a href="#create_2" class="md-nav__link">
    create
  </a>
  
</li>
        
          <li class="md-nav__item">
  <a href="#get_item_2" class="md-nav__link">
    get_item
  </a>
  
</li>
        
          <li class="md-nav__item">
  <a href="#iter_2" class="md-nav__link">
    iter
  </a>
  
</li>
        
          <li class="md-nav__item">
  <a href="#fit_2" class="md-nav__link">
    fit
  </a>
  
</li>
        
          <li class="md-nav__item">
  <a href="#get_params_2" class="md-nav__link">
    get_params
  </a>
  
</li>
        
          <li class="md-nav__item">
  <a href="#predict_2" class="md-nav__link">
    predict
  </a>
  
</li>
        
          <li class="md-nav__item">
  <a href="#predict_log_proba_1" class="md-nav__link">
    predict_log_proba
  </a>
  
</li>
        
          <li class="md-nav__item">
  <a href="#predict_proba_1" class="md-nav__link">
    predict_proba
  </a>
  
</li>
        
          <li class="md-nav__item">
  <a href="#score_2" class="md-nav__link">
    score
  </a>
  
</li>
        
          <li class="md-nav__item">
  <a href="#set_params_2" class="md-nav__link">
    set_params
  </a>
  
</li>
        
          <li class="md-nav__item">
  <a href="#base_estimator__2" class="md-nav__link">
    base_estimator_
  </a>
  
</li>
        
          <li class="md-nav__item">
  <a href="#n_features_" class="md-nav__link">
    n_features_
  </a>
  
</li>
        
          <li class="md-nav__item">
  <a href="#estimators__2" class="md-nav__link">
    estimators_
  </a>
  
</li>
        
          <li class="md-nav__item">
  <a href="#estimators_samples_" class="md-nav__link">
    estimators_samples_
  </a>
  
</li>
        
          <li class="md-nav__item">
  <a href="#estimators_features_" class="md-nav__link">
    estimators_features_
  </a>
  
</li>
        
          <li class="md-nav__item">
  <a href="#classes__1" class="md-nav__link">
    classes_
  </a>
  
</li>
        
          <li class="md-nav__item">
  <a href="#n_classes__1" class="md-nav__link">
    n_classes_
  </a>
  
</li>
        
          <li class="md-nav__item">
  <a href="#oob_score_" class="md-nav__link">
    oob_score_
  </a>
  
</li>
        
          <li class="md-nav__item">
  <a href="#oob_decision_function_" class="md-nav__link">
    oob_decision_function_
  </a>
  
</li>
        
          <li class="md-nav__item">
  <a href="#to_string_2" class="md-nav__link">
    to_string
  </a>
  
</li>
        
          <li class="md-nav__item">
  <a href="#show_2" class="md-nav__link">
    show
  </a>
  
</li>
        
          <li class="md-nav__item">
  <a href="#pp_2" class="md-nav__link">
    pp
  </a>
  
</li>
        
      </ul>
    </nav>
  
</li>
      
        <li class="md-nav__item">
  <a href="#baggingregressor" class="md-nav__link">
    BaggingRegressor
  </a>
  
    <nav class="md-nav" aria-label="BaggingRegressor">
      <ul class="md-nav__list">
        
          <li class="md-nav__item">
  <a href="#create_3" class="md-nav__link">
    create
  </a>
  
</li>
        
          <li class="md-nav__item">
  <a href="#get_item_3" class="md-nav__link">
    get_item
  </a>
  
</li>
        
          <li class="md-nav__item">
  <a href="#iter_3" class="md-nav__link">
    iter
  </a>
  
</li>
        
          <li class="md-nav__item">
  <a href="#fit_3" class="md-nav__link">
    fit
  </a>
  
</li>
        
          <li class="md-nav__item">
  <a href="#get_params_3" class="md-nav__link">
    get_params
  </a>
  
</li>
        
          <li class="md-nav__item">
  <a href="#predict_3" class="md-nav__link">
    predict
  </a>
  
</li>
        
          <li class="md-nav__item">
  <a href="#score_3" class="md-nav__link">
    score
  </a>
  
</li>
        
          <li class="md-nav__item">
  <a href="#set_params_3" class="md-nav__link">
    set_params
  </a>
  
</li>
        
          <li class="md-nav__item">
  <a href="#base_estimator__3" class="md-nav__link">
    base_estimator_
  </a>
  
</li>
        
          <li class="md-nav__item">
  <a href="#n_features__1" class="md-nav__link">
    n_features_
  </a>
  
</li>
        
          <li class="md-nav__item">
  <a href="#estimators__3" class="md-nav__link">
    estimators_
  </a>
  
</li>
        
          <li class="md-nav__item">
  <a href="#estimators_samples__1" class="md-nav__link">
    estimators_samples_
  </a>
  
</li>
        
          <li class="md-nav__item">
  <a href="#estimators_features__1" class="md-nav__link">
    estimators_features_
  </a>
  
</li>
        
          <li class="md-nav__item">
  <a href="#oob_score__1" class="md-nav__link">
    oob_score_
  </a>
  
</li>
        
          <li class="md-nav__item">
  <a href="#oob_prediction_" class="md-nav__link">
    oob_prediction_
  </a>
  
</li>
        
          <li class="md-nav__item">
  <a href="#to_string_3" class="md-nav__link">
    to_string
  </a>
  
</li>
        
          <li class="md-nav__item">
  <a href="#show_3" class="md-nav__link">
    show
  </a>
  
</li>
        
          <li class="md-nav__item">
  <a href="#pp_3" class="md-nav__link">
    pp
  </a>
  
</li>
        
      </ul>
    </nav>
  
</li>
      
        <li class="md-nav__item">
  <a href="#baseensemble" class="md-nav__link">
    BaseEnsemble
  </a>
  
    <nav class="md-nav" aria-label="BaseEnsemble">
      <ul class="md-nav__list">
        
          <li class="md-nav__item">
  <a href="#get_item_4" class="md-nav__link">
    get_item
  </a>
  
</li>
        
          <li class="md-nav__item">
  <a href="#iter_4" class="md-nav__link">
    iter
  </a>
  
</li>
        
          <li class="md-nav__item">
  <a href="#get_params_4" class="md-nav__link">
    get_params
  </a>
  
</li>
        
          <li class="md-nav__item">
  <a href="#set_params_4" class="md-nav__link">
    set_params
  </a>
  
</li>
        
          <li class="md-nav__item">
  <a href="#base_estimator__4" class="md-nav__link">
    base_estimator_
  </a>
  
</li>
        
          <li class="md-nav__item">
  <a href="#estimators__4" class="md-nav__link">
    estimators_
  </a>
  
</li>
        
          <li class="md-nav__item">
  <a href="#to_string_4" class="md-nav__link">
    to_string
  </a>
  
</li>
        
          <li class="md-nav__item">
  <a href="#show_4" class="md-nav__link">
    show
  </a>
  
</li>
        
          <li class="md-nav__item">
  <a href="#pp_4" class="md-nav__link">
    pp
  </a>
  
</li>
        
      </ul>
    </nav>
  
</li>
      
        <li class="md-nav__item">
  <a href="#extratreesclassifier" class="md-nav__link">
    ExtraTreesClassifier
  </a>
  
    <nav class="md-nav" aria-label="ExtraTreesClassifier">
      <ul class="md-nav__list">
        
          <li class="md-nav__item">
  <a href="#create_4" class="md-nav__link">
    create
  </a>
  
</li>
        
          <li class="md-nav__item">
  <a href="#get_item_5" class="md-nav__link">
    get_item
  </a>
  
</li>
        
          <li class="md-nav__item">
  <a href="#iter_5" class="md-nav__link">
    iter
  </a>
  
</li>
        
          <li class="md-nav__item">
  <a href="#apply" class="md-nav__link">
    apply
  </a>
  
</li>
        
          <li class="md-nav__item">
  <a href="#decision_path" class="md-nav__link">
    decision_path
  </a>
  
</li>
        
          <li class="md-nav__item">
  <a href="#fit_4" class="md-nav__link">
    fit
  </a>
  
</li>
        
          <li class="md-nav__item">
  <a href="#get_params_5" class="md-nav__link">
    get_params
  </a>
  
</li>
        
          <li class="md-nav__item">
  <a href="#predict_4" class="md-nav__link">
    predict
  </a>
  
</li>
        
          <li class="md-nav__item">
  <a href="#predict_log_proba_2" class="md-nav__link">
    predict_log_proba
  </a>
  
</li>
        
          <li class="md-nav__item">
  <a href="#predict_proba_2" class="md-nav__link">
    predict_proba
  </a>
  
</li>
        
          <li class="md-nav__item">
  <a href="#score_4" class="md-nav__link">
    score
  </a>
  
</li>
        
          <li class="md-nav__item">
  <a href="#set_params_5" class="md-nav__link">
    set_params
  </a>
  
</li>
        
          <li class="md-nav__item">
  <a href="#base_estimator__5" class="md-nav__link">
    base_estimator_
  </a>
  
</li>
        
          <li class="md-nav__item">
  <a href="#estimators__5" class="md-nav__link">
    estimators_
  </a>
  
</li>
        
          <li class="md-nav__item">
  <a href="#classes__2" class="md-nav__link">
    classes_
  </a>
  
</li>
        
          <li class="md-nav__item">
  <a href="#n_classes__2" class="md-nav__link">
    n_classes_
  </a>
  
</li>
        
          <li class="md-nav__item">
  <a href="#feature_importances__2" class="md-nav__link">
    feature_importances_
  </a>
  
</li>
        
          <li class="md-nav__item">
  <a href="#warning_2" class="md-nav__link">
    warning
  </a>
  
</li>
        
          <li class="md-nav__item">
  <a href="#n_features__2" class="md-nav__link">
    n_features_
  </a>
  
</li>
        
          <li class="md-nav__item">
  <a href="#n_outputs_" class="md-nav__link">
    n_outputs_
  </a>
  
</li>
        
          <li class="md-nav__item">
  <a href="#oob_score__2" class="md-nav__link">
    oob_score_
  </a>
  
</li>
        
          <li class="md-nav__item">
  <a href="#oob_decision_function__1" class="md-nav__link">
    oob_decision_function_
  </a>
  
</li>
        
          <li class="md-nav__item">
  <a href="#to_string_5" class="md-nav__link">
    to_string
  </a>
  
</li>
        
          <li class="md-nav__item">
  <a href="#show_5" class="md-nav__link">
    show
  </a>
  
</li>
        
          <li class="md-nav__item">
  <a href="#pp_5" class="md-nav__link">
    pp
  </a>
  
</li>
        
      </ul>
    </nav>
  
</li>
      
        <li class="md-nav__item">
  <a href="#extratreesregressor" class="md-nav__link">
    ExtraTreesRegressor
  </a>
  
    <nav class="md-nav" aria-label="ExtraTreesRegressor">
      <ul class="md-nav__list">
        
          <li class="md-nav__item">
  <a href="#create_5" class="md-nav__link">
    create
  </a>
  
</li>
        
          <li class="md-nav__item">
  <a href="#get_item_6" class="md-nav__link">
    get_item
  </a>
  
</li>
        
          <li class="md-nav__item">
  <a href="#iter_6" class="md-nav__link">
    iter
  </a>
  
</li>
        
          <li class="md-nav__item">
  <a href="#apply_1" class="md-nav__link">
    apply
  </a>
  
</li>
        
          <li class="md-nav__item">
  <a href="#decision_path_1" class="md-nav__link">
    decision_path
  </a>
  
</li>
        
          <li class="md-nav__item">
  <a href="#fit_5" class="md-nav__link">
    fit
  </a>
  
</li>
        
          <li class="md-nav__item">
  <a href="#get_params_6" class="md-nav__link">
    get_params
  </a>
  
</li>
        
          <li class="md-nav__item">
  <a href="#predict_5" class="md-nav__link">
    predict
  </a>
  
</li>
        
          <li class="md-nav__item">
  <a href="#score_5" class="md-nav__link">
    score
  </a>
  
</li>
        
          <li class="md-nav__item">
  <a href="#set_params_6" class="md-nav__link">
    set_params
  </a>
  
</li>
        
          <li class="md-nav__item">
  <a href="#base_estimator__6" class="md-nav__link">
    base_estimator_
  </a>
  
</li>
        
          <li class="md-nav__item">
  <a href="#estimators__6" class="md-nav__link">
    estimators_
  </a>
  
</li>
        
          <li class="md-nav__item">
  <a href="#feature_importances__3" class="md-nav__link">
    feature_importances_
  </a>
  
</li>
        
          <li class="md-nav__item">
  <a href="#warning_3" class="md-nav__link">
    warning
  </a>
  
</li>
        
          <li class="md-nav__item">
  <a href="#n_features__3" class="md-nav__link">
    n_features_
  </a>
  
</li>
        
          <li class="md-nav__item">
  <a href="#n_outputs__1" class="md-nav__link">
    n_outputs_
  </a>
  
</li>
        
          <li class="md-nav__item">
  <a href="#oob_score__3" class="md-nav__link">
    oob_score_
  </a>
  
</li>
        
          <li class="md-nav__item">
  <a href="#oob_prediction__1" class="md-nav__link">
    oob_prediction_
  </a>
  
</li>
        
          <li class="md-nav__item">
  <a href="#to_string_6" class="md-nav__link">
    to_string
  </a>
  
</li>
        
          <li class="md-nav__item">
  <a href="#show_6" class="md-nav__link">
    show
  </a>
  
</li>
        
          <li class="md-nav__item">
  <a href="#pp_6" class="md-nav__link">
    pp
  </a>
  
</li>
        
      </ul>
    </nav>
  
</li>
      
        <li class="md-nav__item">
  <a href="#gradientboostingclassifier" class="md-nav__link">
    GradientBoostingClassifier
  </a>
  
    <nav class="md-nav" aria-label="GradientBoostingClassifier">
      <ul class="md-nav__list">
        
          <li class="md-nav__item">
  <a href="#create_6" class="md-nav__link">
    create
  </a>
  
</li>
        
          <li class="md-nav__item">
  <a href="#get_item_7" class="md-nav__link">
    get_item
  </a>
  
</li>
        
          <li class="md-nav__item">
  <a href="#iter_7" class="md-nav__link">
    iter
  </a>
  
</li>
        
          <li class="md-nav__item">
  <a href="#apply_2" class="md-nav__link">
    apply
  </a>
  
</li>
        
          <li class="md-nav__item">
  <a href="#decision_function_1" class="md-nav__link">
    decision_function
  </a>
  
</li>
        
          <li class="md-nav__item">
  <a href="#fit_6" class="md-nav__link">
    fit
  </a>
  
</li>
        
          <li class="md-nav__item">
  <a href="#get_params_7" class="md-nav__link">
    get_params
  </a>
  
</li>
        
          <li class="md-nav__item">
  <a href="#predict_6" class="md-nav__link">
    predict
  </a>
  
</li>
        
          <li class="md-nav__item">
  <a href="#predict_log_proba_3" class="md-nav__link">
    predict_log_proba
  </a>
  
</li>
        
          <li class="md-nav__item">
  <a href="#predict_proba_3" class="md-nav__link">
    predict_proba
  </a>
  
</li>
        
          <li class="md-nav__item">
  <a href="#score_6" class="md-nav__link">
    score
  </a>
  
</li>
        
          <li class="md-nav__item">
  <a href="#set_params_7" class="md-nav__link">
    set_params
  </a>
  
</li>
        
          <li class="md-nav__item">
  <a href="#staged_decision_function_1" class="md-nav__link">
    staged_decision_function
  </a>
  
</li>
        
          <li class="md-nav__item">
  <a href="#staged_predict_2" class="md-nav__link">
    staged_predict
  </a>
  
</li>
        
          <li class="md-nav__item">
  <a href="#staged_predict_proba_1" class="md-nav__link">
    staged_predict_proba
  </a>
  
</li>
        
          <li class="md-nav__item">
  <a href="#n_estimators_" class="md-nav__link">
    n_estimators_
  </a>
  
</li>
        
          <li class="md-nav__item">
  <a href="#feature_importances__4" class="md-nav__link">
    feature_importances_
  </a>
  
</li>
        
          <li class="md-nav__item">
  <a href="#warning_4" class="md-nav__link">
    warning
  </a>
  
</li>
        
          <li class="md-nav__item">
  <a href="#oob_improvement_" class="md-nav__link">
    oob_improvement_
  </a>
  
</li>
        
          <li class="md-nav__item">
  <a href="#train_score_" class="md-nav__link">
    train_score_
  </a>
  
</li>
        
          <li class="md-nav__item">
  <a href="#loss_" class="md-nav__link">
    loss_
  </a>
  
</li>
        
          <li class="md-nav__item">
  <a href="#init_" class="md-nav__link">
    init_
  </a>
  
</li>
        
          <li class="md-nav__item">
  <a href="#estimators__7" class="md-nav__link">
    estimators_
  </a>
  
</li>
        
          <li class="md-nav__item">
  <a href="#classes__3" class="md-nav__link">
    classes_
  </a>
  
</li>
        
          <li class="md-nav__item">
  <a href="#n_features__4" class="md-nav__link">
    n_features_
  </a>
  
</li>
        
          <li class="md-nav__item">
  <a href="#n_classes__3" class="md-nav__link">
    n_classes_
  </a>
  
</li>
        
          <li class="md-nav__item">
  <a href="#max_features_" class="md-nav__link">
    max_features_
  </a>
  
</li>
        
          <li class="md-nav__item">
  <a href="#to_string_7" class="md-nav__link">
    to_string
  </a>
  
</li>
        
          <li class="md-nav__item">
  <a href="#show_7" class="md-nav__link">
    show
  </a>
  
</li>
        
          <li class="md-nav__item">
  <a href="#pp_7" class="md-nav__link">
    pp
  </a>
  
</li>
        
      </ul>
    </nav>
  
</li>
      
        <li class="md-nav__item">
  <a href="#gradientboostingregressor" class="md-nav__link">
    GradientBoostingRegressor
  </a>
  
    <nav class="md-nav" aria-label="GradientBoostingRegressor">
      <ul class="md-nav__list">
        
          <li class="md-nav__item">
  <a href="#create_7" class="md-nav__link">
    create
  </a>
  
</li>
        
          <li class="md-nav__item">
  <a href="#get_item_8" class="md-nav__link">
    get_item
  </a>
  
</li>
        
          <li class="md-nav__item">
  <a href="#iter_8" class="md-nav__link">
    iter
  </a>
  
</li>
        
          <li class="md-nav__item">
  <a href="#apply_3" class="md-nav__link">
    apply
  </a>
  
</li>
        
          <li class="md-nav__item">
  <a href="#fit_7" class="md-nav__link">
    fit
  </a>
  
</li>
        
          <li class="md-nav__item">
  <a href="#get_params_8" class="md-nav__link">
    get_params
  </a>
  
</li>
        
          <li class="md-nav__item">
  <a href="#predict_7" class="md-nav__link">
    predict
  </a>
  
</li>
        
          <li class="md-nav__item">
  <a href="#score_7" class="md-nav__link">
    score
  </a>
  
</li>
        
          <li class="md-nav__item">
  <a href="#set_params_8" class="md-nav__link">
    set_params
  </a>
  
</li>
        
          <li class="md-nav__item">
  <a href="#staged_predict_3" class="md-nav__link">
    staged_predict
  </a>
  
</li>
        
          <li class="md-nav__item">
  <a href="#feature_importances__5" class="md-nav__link">
    feature_importances_
  </a>
  
</li>
        
          <li class="md-nav__item">
  <a href="#warning_5" class="md-nav__link">
    warning
  </a>
  
</li>
        
          <li class="md-nav__item">
  <a href="#oob_improvement__1" class="md-nav__link">
    oob_improvement_
  </a>
  
</li>
        
          <li class="md-nav__item">
  <a href="#train_score__1" class="md-nav__link">
    train_score_
  </a>
  
</li>
        
          <li class="md-nav__item">
  <a href="#loss__1" class="md-nav__link">
    loss_
  </a>
  
</li>
        
          <li class="md-nav__item">
  <a href="#init__1" class="md-nav__link">
    init_
  </a>
  
</li>
        
          <li class="md-nav__item">
  <a href="#estimators__8" class="md-nav__link">
    estimators_
  </a>
  
</li>
        
          <li class="md-nav__item">
  <a href="#n_features__5" class="md-nav__link">
    n_features_
  </a>
  
</li>
        
          <li class="md-nav__item">
  <a href="#max_features__1" class="md-nav__link">
    max_features_
  </a>
  
</li>
        
          <li class="md-nav__item">
  <a href="#to_string_8" class="md-nav__link">
    to_string
  </a>
  
</li>
        
          <li class="md-nav__item">
  <a href="#show_8" class="md-nav__link">
    show
  </a>
  
</li>
        
          <li class="md-nav__item">
  <a href="#pp_8" class="md-nav__link">
    pp
  </a>
  
</li>
        
      </ul>
    </nav>
  
</li>
      
        <li class="md-nav__item">
  <a href="#isolationforest" class="md-nav__link">
    IsolationForest
  </a>
  
    <nav class="md-nav" aria-label="IsolationForest">
      <ul class="md-nav__list">
        
          <li class="md-nav__item">
  <a href="#create_8" class="md-nav__link">
    create
  </a>
  
</li>
        
          <li class="md-nav__item">
  <a href="#get_item_9" class="md-nav__link">
    get_item
  </a>
  
</li>
        
          <li class="md-nav__item">
  <a href="#iter_9" class="md-nav__link">
    iter
  </a>
  
</li>
        
          <li class="md-nav__item">
  <a href="#decision_function_2" class="md-nav__link">
    decision_function
  </a>
  
</li>
        
          <li class="md-nav__item">
  <a href="#fit_8" class="md-nav__link">
    fit
  </a>
  
</li>
        
          <li class="md-nav__item">
  <a href="#fit_predict" class="md-nav__link">
    fit_predict
  </a>
  
</li>
        
          <li class="md-nav__item">
  <a href="#get_params_9" class="md-nav__link">
    get_params
  </a>
  
</li>
        
          <li class="md-nav__item">
  <a href="#predict_8" class="md-nav__link">
    predict
  </a>
  
</li>
        
          <li class="md-nav__item">
  <a href="#score_samples" class="md-nav__link">
    score_samples
  </a>
  
</li>
        
          <li class="md-nav__item">
  <a href="#set_params_9" class="md-nav__link">
    set_params
  </a>
  
</li>
        
          <li class="md-nav__item">
  <a href="#estimators__9" class="md-nav__link">
    estimators_
  </a>
  
</li>
        
          <li class="md-nav__item">
  <a href="#estimators_samples__2" class="md-nav__link">
    estimators_samples_
  </a>
  
</li>
        
          <li class="md-nav__item">
  <a href="#max_samples_" class="md-nav__link">
    max_samples_
  </a>
  
</li>
        
          <li class="md-nav__item">
  <a href="#offset_" class="md-nav__link">
    offset_
  </a>
  
</li>
        
          <li class="md-nav__item">
  <a href="#estimators_features__2" class="md-nav__link">
    estimators_features_
  </a>
  
</li>
        
          <li class="md-nav__item">
  <a href="#to_string_9" class="md-nav__link">
    to_string
  </a>
  
</li>
        
          <li class="md-nav__item">
  <a href="#show_9" class="md-nav__link">
    show
  </a>
  
</li>
        
          <li class="md-nav__item">
  <a href="#pp_9" class="md-nav__link">
    pp
  </a>
  
</li>
        
      </ul>
    </nav>
  
</li>
      
        <li class="md-nav__item">
  <a href="#randomforestclassifier" class="md-nav__link">
    RandomForestClassifier
  </a>
  
    <nav class="md-nav" aria-label="RandomForestClassifier">
      <ul class="md-nav__list">
        
          <li class="md-nav__item">
  <a href="#create_9" class="md-nav__link">
    create
  </a>
  
</li>
        
          <li class="md-nav__item">
  <a href="#get_item_10" class="md-nav__link">
    get_item
  </a>
  
</li>
        
          <li class="md-nav__item">
  <a href="#iter_10" class="md-nav__link">
    iter
  </a>
  
</li>
        
          <li class="md-nav__item">
  <a href="#apply_4" class="md-nav__link">
    apply
  </a>
  
</li>
        
          <li class="md-nav__item">
  <a href="#decision_path_2" class="md-nav__link">
    decision_path
  </a>
  
</li>
        
          <li class="md-nav__item">
  <a href="#fit_9" class="md-nav__link">
    fit
  </a>
  
</li>
        
          <li class="md-nav__item">
  <a href="#get_params_10" class="md-nav__link">
    get_params
  </a>
  
</li>
        
          <li class="md-nav__item">
  <a href="#predict_9" class="md-nav__link">
    predict
  </a>
  
</li>
        
          <li class="md-nav__item">
  <a href="#predict_log_proba_4" class="md-nav__link">
    predict_log_proba
  </a>
  
</li>
        
          <li class="md-nav__item">
  <a href="#predict_proba_4" class="md-nav__link">
    predict_proba
  </a>
  
</li>
        
          <li class="md-nav__item">
  <a href="#score_8" class="md-nav__link">
    score
  </a>
  
</li>
        
          <li class="md-nav__item">
  <a href="#set_params_10" class="md-nav__link">
    set_params
  </a>
  
</li>
        
          <li class="md-nav__item">
  <a href="#base_estimator__7" class="md-nav__link">
    base_estimator_
  </a>
  
</li>
        
          <li class="md-nav__item">
  <a href="#estimators__10" class="md-nav__link">
    estimators_
  </a>
  
</li>
        
          <li class="md-nav__item">
  <a href="#classes__4" class="md-nav__link">
    classes_
  </a>
  
</li>
        
          <li class="md-nav__item">
  <a href="#n_classes__4" class="md-nav__link">
    n_classes_
  </a>
  
</li>
        
          <li class="md-nav__item">
  <a href="#n_features__6" class="md-nav__link">
    n_features_
  </a>
  
</li>
        
          <li class="md-nav__item">
  <a href="#n_outputs__2" class="md-nav__link">
    n_outputs_
  </a>
  
</li>
        
          <li class="md-nav__item">
  <a href="#feature_importances__6" class="md-nav__link">
    feature_importances_
  </a>
  
</li>
        
          <li class="md-nav__item">
  <a href="#warning_6" class="md-nav__link">
    warning
  </a>
  
</li>
        
          <li class="md-nav__item">
  <a href="#oob_score__4" class="md-nav__link">
    oob_score_
  </a>
  
</li>
        
          <li class="md-nav__item">
  <a href="#oob_decision_function__2" class="md-nav__link">
    oob_decision_function_
  </a>
  
</li>
        
          <li class="md-nav__item">
  <a href="#to_string_10" class="md-nav__link">
    to_string
  </a>
  
</li>
        
          <li class="md-nav__item">
  <a href="#show_10" class="md-nav__link">
    show
  </a>
  
</li>
        
          <li class="md-nav__item">
  <a href="#pp_10" class="md-nav__link">
    pp
  </a>
  
</li>
        
      </ul>
    </nav>
  
</li>
      
        <li class="md-nav__item">
  <a href="#randomforestregressor" class="md-nav__link">
    RandomForestRegressor
  </a>
  
    <nav class="md-nav" aria-label="RandomForestRegressor">
      <ul class="md-nav__list">
        
          <li class="md-nav__item">
  <a href="#create_10" class="md-nav__link">
    create
  </a>
  
</li>
        
          <li class="md-nav__item">
  <a href="#get_item_11" class="md-nav__link">
    get_item
  </a>
  
</li>
        
          <li class="md-nav__item">
  <a href="#iter_11" class="md-nav__link">
    iter
  </a>
  
</li>
        
          <li class="md-nav__item">
  <a href="#apply_5" class="md-nav__link">
    apply
  </a>
  
</li>
        
          <li class="md-nav__item">
  <a href="#decision_path_3" class="md-nav__link">
    decision_path
  </a>
  
</li>
        
          <li class="md-nav__item">
  <a href="#fit_10" class="md-nav__link">
    fit
  </a>
  
</li>
        
          <li class="md-nav__item">
  <a href="#get_params_11" class="md-nav__link">
    get_params
  </a>
  
</li>
        
          <li class="md-nav__item">
  <a href="#predict_10" class="md-nav__link">
    predict
  </a>
  
</li>
        
          <li class="md-nav__item">
  <a href="#score_9" class="md-nav__link">
    score
  </a>
  
</li>
        
          <li class="md-nav__item">
  <a href="#set_params_11" class="md-nav__link">
    set_params
  </a>
  
</li>
        
          <li class="md-nav__item">
  <a href="#base_estimator__8" class="md-nav__link">
    base_estimator_
  </a>
  
</li>
        
          <li class="md-nav__item">
  <a href="#estimators__11" class="md-nav__link">
    estimators_
  </a>
  
</li>
        
          <li class="md-nav__item">
  <a href="#feature_importances__7" class="md-nav__link">
    feature_importances_
  </a>
  
</li>
        
          <li class="md-nav__item">
  <a href="#warning_7" class="md-nav__link">
    warning
  </a>
  
</li>
        
          <li class="md-nav__item">
  <a href="#n_features__7" class="md-nav__link">
    n_features_
  </a>
  
</li>
        
          <li class="md-nav__item">
  <a href="#n_outputs__3" class="md-nav__link">
    n_outputs_
  </a>
  
</li>
        
          <li class="md-nav__item">
  <a href="#oob_score__5" class="md-nav__link">
    oob_score_
  </a>
  
</li>
        
          <li class="md-nav__item">
  <a href="#oob_prediction__2" class="md-nav__link">
    oob_prediction_
  </a>
  
</li>
        
          <li class="md-nav__item">
  <a href="#to_string_11" class="md-nav__link">
    to_string
  </a>
  
</li>
        
          <li class="md-nav__item">
  <a href="#show_11" class="md-nav__link">
    show
  </a>
  
</li>
        
          <li class="md-nav__item">
  <a href="#pp_11" class="md-nav__link">
    pp
  </a>
  
</li>
        
      </ul>
    </nav>
  
</li>
      
        <li class="md-nav__item">
  <a href="#randomtreesembedding" class="md-nav__link">
    RandomTreesEmbedding
  </a>
  
    <nav class="md-nav" aria-label="RandomTreesEmbedding">
      <ul class="md-nav__list">
        
          <li class="md-nav__item">
  <a href="#create_11" class="md-nav__link">
    create
  </a>
  
</li>
        
          <li class="md-nav__item">
  <a href="#get_item_12" class="md-nav__link">
    get_item
  </a>
  
</li>
        
          <li class="md-nav__item">
  <a href="#iter_12" class="md-nav__link">
    iter
  </a>
  
</li>
        
          <li class="md-nav__item">
  <a href="#apply_6" class="md-nav__link">
    apply
  </a>
  
</li>
        
          <li class="md-nav__item">
  <a href="#decision_path_4" class="md-nav__link">
    decision_path
  </a>
  
</li>
        
          <li class="md-nav__item">
  <a href="#fit_11" class="md-nav__link">
    fit
  </a>
  
</li>
        
          <li class="md-nav__item">
  <a href="#fit_transform" class="md-nav__link">
    fit_transform
  </a>
  
</li>
        
          <li class="md-nav__item">
  <a href="#get_params_12" class="md-nav__link">
    get_params
  </a>
  
</li>
        
          <li class="md-nav__item">
  <a href="#set_params_12" class="md-nav__link">
    set_params
  </a>
  
</li>
        
          <li class="md-nav__item">
  <a href="#transform" class="md-nav__link">
    transform
  </a>
  
</li>
        
          <li class="md-nav__item">
  <a href="#estimators__12" class="md-nav__link">
    estimators_
  </a>
  
</li>
        
          <li class="md-nav__item">
  <a href="#to_string_12" class="md-nav__link">
    to_string
  </a>
  
</li>
        
          <li class="md-nav__item">
  <a href="#show_12" class="md-nav__link">
    show
  </a>
  
</li>
        
          <li class="md-nav__item">
  <a href="#pp_12" class="md-nav__link">
    pp
  </a>
  
</li>
        
      </ul>
    </nav>
  
</li>
      
        <li class="md-nav__item">
  <a href="#stackingclassifier" class="md-nav__link">
    StackingClassifier
  </a>
  
    <nav class="md-nav" aria-label="StackingClassifier">
      <ul class="md-nav__list">
        
          <li class="md-nav__item">
  <a href="#create_12" class="md-nav__link">
    create
  </a>
  
</li>
        
          <li class="md-nav__item">
  <a href="#decision_function_3" class="md-nav__link">
    decision_function
  </a>
  
</li>
        
          <li class="md-nav__item">
  <a href="#fit_12" class="md-nav__link">
    fit
  </a>
  
</li>
        
          <li class="md-nav__item">
  <a href="#fit_transform_1" class="md-nav__link">
    fit_transform
  </a>
  
</li>
        
          <li class="md-nav__item">
  <a href="#get_params_13" class="md-nav__link">
    get_params
  </a>
  
</li>
        
          <li class="md-nav__item">
  <a href="#predict_11" class="md-nav__link">
    predict
  </a>
  
</li>
        
          <li class="md-nav__item">
  <a href="#predict_proba_5" class="md-nav__link">
    predict_proba
  </a>
  
</li>
        
          <li class="md-nav__item">
  <a href="#score_10" class="md-nav__link">
    score
  </a>
  
</li>
        
          <li class="md-nav__item">
  <a href="#set_params_13" class="md-nav__link">
    set_params
  </a>
  
</li>
        
          <li class="md-nav__item">
  <a href="#transform_1" class="md-nav__link">
    transform
  </a>
  
</li>
        
          <li class="md-nav__item">
  <a href="#classes__5" class="md-nav__link">
    classes_
  </a>
  
</li>
        
          <li class="md-nav__item">
  <a href="#estimators__13" class="md-nav__link">
    estimators_
  </a>
  
</li>
        
          <li class="md-nav__item">
  <a href="#named_estimators_" class="md-nav__link">
    named_estimators_
  </a>
  
</li>
        
          <li class="md-nav__item">
  <a href="#final_estimator_" class="md-nav__link">
    final_estimator_
  </a>
  
</li>
        
          <li class="md-nav__item">
  <a href="#stack_method_" class="md-nav__link">
    stack_method_
  </a>
  
</li>
        
          <li class="md-nav__item">
  <a href="#to_string_13" class="md-nav__link">
    to_string
  </a>
  
</li>
        
          <li class="md-nav__item">
  <a href="#show_13" class="md-nav__link">
    show
  </a>
  
</li>
        
          <li class="md-nav__item">
  <a href="#pp_13" class="md-nav__link">
    pp
  </a>
  
</li>
        
      </ul>
    </nav>
  
</li>
      
        <li class="md-nav__item">
  <a href="#stackingregressor" class="md-nav__link">
    StackingRegressor
  </a>
  
    <nav class="md-nav" aria-label="StackingRegressor">
      <ul class="md-nav__list">
        
          <li class="md-nav__item">
  <a href="#create_13" class="md-nav__link">
    create
  </a>
  
</li>
        
          <li class="md-nav__item">
  <a href="#fit_13" class="md-nav__link">
    fit
  </a>
  
</li>
        
          <li class="md-nav__item">
  <a href="#fit_transform_2" class="md-nav__link">
    fit_transform
  </a>
  
</li>
        
          <li class="md-nav__item">
  <a href="#get_params_14" class="md-nav__link">
    get_params
  </a>
  
</li>
        
          <li class="md-nav__item">
  <a href="#predict_12" class="md-nav__link">
    predict
  </a>
  
</li>
        
          <li class="md-nav__item">
  <a href="#score_11" class="md-nav__link">
    score
  </a>
  
</li>
        
          <li class="md-nav__item">
  <a href="#set_params_14" class="md-nav__link">
    set_params
  </a>
  
</li>
        
          <li class="md-nav__item">
  <a href="#transform_2" class="md-nav__link">
    transform
  </a>
  
</li>
        
          <li class="md-nav__item">
  <a href="#estimators__14" class="md-nav__link">
    estimators_
  </a>
  
</li>
        
          <li class="md-nav__item">
  <a href="#named_estimators__1" class="md-nav__link">
    named_estimators_
  </a>
  
</li>
        
          <li class="md-nav__item">
  <a href="#final_estimator__1" class="md-nav__link">
    final_estimator_
  </a>
  
</li>
        
          <li class="md-nav__item">
  <a href="#to_string_14" class="md-nav__link">
    to_string
  </a>
  
</li>
        
          <li class="md-nav__item">
  <a href="#show_14" class="md-nav__link">
    show
  </a>
  
</li>
        
          <li class="md-nav__item">
  <a href="#pp_14" class="md-nav__link">
    pp
  </a>
  
</li>
        
      </ul>
    </nav>
  
</li>
      
        <li class="md-nav__item">
  <a href="#votingclassifier" class="md-nav__link">
    VotingClassifier
  </a>
  
    <nav class="md-nav" aria-label="VotingClassifier">
      <ul class="md-nav__list">
        
          <li class="md-nav__item">
  <a href="#create_14" class="md-nav__link">
    create
  </a>
  
</li>
        
          <li class="md-nav__item">
  <a href="#fit_14" class="md-nav__link">
    fit
  </a>
  
</li>
        
          <li class="md-nav__item">
  <a href="#fit_transform_3" class="md-nav__link">
    fit_transform
  </a>
  
</li>
        
          <li class="md-nav__item">
  <a href="#get_params_15" class="md-nav__link">
    get_params
  </a>
  
</li>
        
          <li class="md-nav__item">
  <a href="#predict_13" class="md-nav__link">
    predict
  </a>
  
</li>
        
          <li class="md-nav__item">
  <a href="#score_12" class="md-nav__link">
    score
  </a>
  
</li>
        
          <li class="md-nav__item">
  <a href="#set_params_15" class="md-nav__link">
    set_params
  </a>
  
</li>
        
          <li class="md-nav__item">
  <a href="#transform_3" class="md-nav__link">
    transform
  </a>
  
</li>
        
          <li class="md-nav__item">
  <a href="#estimators__15" class="md-nav__link">
    estimators_
  </a>
  
</li>
        
          <li class="md-nav__item">
  <a href="#named_estimators__2" class="md-nav__link">
    named_estimators_
  </a>
  
</li>
        
          <li class="md-nav__item">
  <a href="#classes__6" class="md-nav__link">
    classes_
  </a>
  
</li>
        
          <li class="md-nav__item">
  <a href="#to_string_15" class="md-nav__link">
    to_string
  </a>
  
</li>
        
          <li class="md-nav__item">
  <a href="#show_15" class="md-nav__link">
    show
  </a>
  
</li>
        
          <li class="md-nav__item">
  <a href="#pp_15" class="md-nav__link">
    pp
  </a>
  
</li>
        
      </ul>
    </nav>
  
</li>
      
        <li class="md-nav__item">
  <a href="#votingregressor" class="md-nav__link">
    VotingRegressor
  </a>
  
    <nav class="md-nav" aria-label="VotingRegressor">
      <ul class="md-nav__list">
        
          <li class="md-nav__item">
  <a href="#create_15" class="md-nav__link">
    create
  </a>
  
</li>
        
          <li class="md-nav__item">
  <a href="#fit_15" class="md-nav__link">
    fit
  </a>
  
</li>
        
          <li class="md-nav__item">
  <a href="#fit_transform_4" class="md-nav__link">
    fit_transform
  </a>
  
</li>
        
          <li class="md-nav__item">
  <a href="#get_params_16" class="md-nav__link">
    get_params
  </a>
  
</li>
        
          <li class="md-nav__item">
  <a href="#predict_14" class="md-nav__link">
    predict
  </a>
  
</li>
        
          <li class="md-nav__item">
  <a href="#score_13" class="md-nav__link">
    score
  </a>
  
</li>
        
          <li class="md-nav__item">
  <a href="#set_params_16" class="md-nav__link">
    set_params
  </a>
  
</li>
        
          <li class="md-nav__item">
  <a href="#transform_4" class="md-nav__link">
    transform
  </a>
  
</li>
        
          <li class="md-nav__item">
  <a href="#estimators__16" class="md-nav__link">
    estimators_
  </a>
  
</li>
        
          <li class="md-nav__item">
  <a href="#named_estimators__3" class="md-nav__link">
    named_estimators_
  </a>
  
</li>
        
          <li class="md-nav__item">
  <a href="#to_string_16" class="md-nav__link">
    to_string
  </a>
  
</li>
        
          <li class="md-nav__item">
  <a href="#show_16" class="md-nav__link">
    show
  </a>
  
</li>
        
          <li class="md-nav__item">
  <a href="#pp_16" class="md-nav__link">
    pp
  </a>
  
</li>
        
      </ul>
    </nav>
  
</li>
      
    </ul>
  
</nav>
                  </div>
                </div>
              </div>
            
          
          <div class="md-content">
            <article class="md-content__inner md-typeset">
              
                
                  <a href="https://github.com/lehy/ocaml-sklearn/edit/master/docs/sklearn/Ensemble.md" title="Edit this page" class="md-content__button md-icon">
                    <svg xmlns="http://www.w3.org/2000/svg" viewBox="0 0 24 24"><path d="M20.71 7.04c.39-.39.39-1.04 0-1.41l-2.34-2.34c-.37-.39-1.02-.39-1.41 0l-1.84 1.83 3.75 3.75M3 17.25V21h3.75L17.81 9.93l-3.75-3.75L3 17.25z"/></svg>
                  </a>
                
                
                  <h1>Ensemble</h1>
                
                <h2 id="adaboostclassifier">AdaBoostClassifier<a class="headerlink" href="#adaboostclassifier" title="Permanent link">&para;</a></h2>
<p>Module <code>Sklearn.​Ensemble.​AdaBoostClassifier</code> wraps Python class <a href="https://scikit-learn.org/stable/modules/generated/sklearn.ensemble.AdaBoostClassifier.html"><code>sklearn.ensemble.AdaBoostClassifier</code></a>.</p>
<div class="highlight"><pre><span></span><code><span class="k">type</span> <span class="n">t</span>
</code></pre></div>

<h3 id="create">create<a class="headerlink" href="#create" title="Permanent link">&para;</a></h3>
<details class="note" open="open"><summary>constructor and attributes create</summary><div class="highlight"><pre><span></span><code><span class="k">val</span> <span class="n">create</span> <span class="o">:</span>
  <span class="o">?</span><span class="n">base_estimator</span><span class="o">:[&gt;`</span><span class="nc">BaseEstimator</span><span class="o">]</span> <span class="nn">Np</span><span class="p">.</span><span class="nn">Obj</span><span class="p">.</span><span class="n">t</span> <span class="o">-&gt;</span>
  <span class="o">?</span><span class="n">n_estimators</span><span class="o">:</span><span class="kt">int</span> <span class="o">-&gt;</span>
  <span class="o">?</span><span class="n">learning_rate</span><span class="o">:</span><span class="kt">float</span> <span class="o">-&gt;</span>
  <span class="o">?</span><span class="n">algorithm</span><span class="o">:[`</span><span class="nc">SAMME</span> <span class="o">|</span> <span class="o">`</span><span class="nc">SAMME_R</span><span class="o">]</span> <span class="o">-&gt;</span>
  <span class="o">?</span><span class="n">random_state</span><span class="o">:</span><span class="kt">int</span> <span class="o">-&gt;</span>
  <span class="kt">unit</span> <span class="o">-&gt;</span>
  <span class="n">t</span>
</code></pre></div>

<p>An AdaBoost classifier.</p>
<p>An AdaBoost [1] classifier is a meta-estimator that begins by fitting a
classifier on the original dataset and then fits additional copies of the
classifier on the same dataset but where the weights of incorrectly
classified instances are adjusted such that subsequent classifiers focus
more on difficult cases.</p>
<p>This class implements the algorithm known as AdaBoost-SAMME [2].</p>
<p>Read more in the :ref:<code>User Guide &lt;adaboost&gt;</code>.</p>
<p>.. versionadded:: 0.14</p>
<h4>Parameters</h4>
<ul>
<li>
<p><strong>base_estimator : object, default=None</strong>
    The base estimator from which the boosted ensemble is built.
    Support for sample weighting is required, as well as proper
    <code>classes_</code> and <code>n_classes_</code> attributes. If <code>None</code>, then
    the base estimator is <code>DecisionTreeClassifier(max_depth=1)</code>.</p>
</li>
<li>
<p><strong>n_estimators : int, default=50</strong>
    The maximum number of estimators at which boosting is terminated.
    In case of perfect fit, the learning procedure is stopped early.</p>
</li>
<li>
<p><strong>learning_rate : float, default=1.</strong>
    Learning rate shrinks the contribution of each classifier by
    <code>learning_rate</code>. There is a trade-off between <code>learning_rate</code> and
    <code>n_estimators</code>.</p>
</li>
<li>
<p><strong>algorithm : {'SAMME', 'SAMME.R'}, default='SAMME.R'</strong>
    If 'SAMME.R' then use the SAMME.R real boosting algorithm.
    <code>base_estimator</code> must support calculation of class probabilities.
    If 'SAMME' then use the SAMME discrete boosting algorithm.
    The SAMME.R algorithm typically converges faster than SAMME,
    achieving a lower test error with fewer boosting iterations.</p>
</li>
<li>
<p><strong>random_state : int or RandomState, default=None</strong>
    Controls the random seed given at each <code>base_estimator</code> at each
    boosting iteration.
    Thus, it is only used when <code>base_estimator</code> exposes a <code>random_state</code>.
    Pass an int for reproducible output across multiple function calls.</p>
</li>
<li>
<p><strong>See :term:<code>Glossary &lt;random_state&gt;</code>.</strong></p>
</li>
</ul>
<h4>Attributes</h4>
<ul>
<li>
<p><strong>base_estimator_ : estimator</strong>
    The base estimator from which the ensemble is grown.</p>
</li>
<li>
<p><strong>estimators_ : list of classifiers</strong>
    The collection of fitted sub-estimators.</p>
</li>
<li>
<p><strong>classes_ : ndarray of shape (n_classes,)</strong>
    The classes labels.</p>
</li>
<li>
<p><strong>n_classes_ : int</strong>
    The number of classes.</p>
</li>
<li>
<p><strong>estimator_weights_ : ndarray of floats</strong>
    Weights for each estimator in the boosted ensemble.</p>
</li>
<li>
<p><strong>estimator_errors_ : ndarray of floats</strong>
    Classification error for each estimator in the boosted
    ensemble.</p>
</li>
<li>
<p><strong>feature_importances_ : ndarray of shape (n_features,)</strong>
    The impurity-based feature importances if supported by the
    <code>base_estimator</code> (when based on decision trees).</p>
</li>
<li>
<p><strong>Warning: impurity-based feature importances can be misleading for</strong>
    high cardinality features (many unique values). See
    :func:<code>sklearn.inspection.permutation_importance</code> as an alternative.</p>
</li>
</ul>
<h4>See Also</h4>
<p>AdaBoostRegressor
    An AdaBoost regressor that begins by fitting a regressor on the
    original dataset and then fits additional copies of the regressor
    on the same dataset but where the weights of instances are
    adjusted according to the error of the current prediction.</p>
<p>GradientBoostingClassifier
    GB builds an additive model in a forward stage-wise fashion. Regression
    trees are fit on the negative gradient of the binomial or multinomial
    deviance loss function. Binary classification is a special case where
    only a single regression tree is induced.</p>
<p>sklearn.tree.DecisionTreeClassifier
    A non-parametric supervised learning method used for classification.
    Creates a model that predicts the value of a target variable by
    learning simple decision rules inferred from the data features.</p>
<h4>References</h4>
<p>.. [1] Y. Freund, R. Schapire, 'A Decision-Theoretic Generalization of
       on-Line Learning and an Application to Boosting', 1995.</p>
<p>.. [2] J. Zhu, H. Zou, S. Rosset, T. Hastie, 'Multi-class AdaBoost', 2009.</p>
<h4>Examples</h4>
<div class="highlight"><pre><span></span><code><span class="o">&gt;&gt;&gt;</span> <span class="kn">from</span> <span class="nn">sklearn.ensemble</span> <span class="kn">import</span> <span class="n">AdaBoostClassifier</span>
<span class="o">&gt;&gt;&gt;</span> <span class="kn">from</span> <span class="nn">sklearn.datasets</span> <span class="kn">import</span> <span class="n">make_classification</span>
<span class="o">&gt;&gt;&gt;</span> <span class="n">X</span><span class="p">,</span> <span class="n">y</span> <span class="o">=</span> <span class="n">make_classification</span><span class="p">(</span><span class="n">n_samples</span><span class="o">=</span><span class="mi">1000</span><span class="p">,</span> <span class="n">n_features</span><span class="o">=</span><span class="mi">4</span><span class="p">,</span>
<span class="o">...</span>                            <span class="n">n_informative</span><span class="o">=</span><span class="mi">2</span><span class="p">,</span> <span class="n">n_redundant</span><span class="o">=</span><span class="mi">0</span><span class="p">,</span>
<span class="o">...</span>                            <span class="n">random_state</span><span class="o">=</span><span class="mi">0</span><span class="p">,</span> <span class="n">shuffle</span><span class="o">=</span><span class="kc">False</span><span class="p">)</span>
<span class="o">&gt;&gt;&gt;</span> <span class="n">clf</span> <span class="o">=</span> <span class="n">AdaBoostClassifier</span><span class="p">(</span><span class="n">n_estimators</span><span class="o">=</span><span class="mi">100</span><span class="p">,</span> <span class="n">random_state</span><span class="o">=</span><span class="mi">0</span><span class="p">)</span>
<span class="o">&gt;&gt;&gt;</span> <span class="n">clf</span><span class="o">.</span><span class="n">fit</span><span class="p">(</span><span class="n">X</span><span class="p">,</span> <span class="n">y</span><span class="p">)</span>
<span class="n">AdaBoostClassifier</span><span class="p">(</span><span class="n">n_estimators</span><span class="o">=</span><span class="mi">100</span><span class="p">,</span> <span class="n">random_state</span><span class="o">=</span><span class="mi">0</span><span class="p">)</span>
<span class="o">&gt;&gt;&gt;</span> <span class="n">clf</span><span class="o">.</span><span class="n">predict</span><span class="p">([[</span><span class="mi">0</span><span class="p">,</span> <span class="mi">0</span><span class="p">,</span> <span class="mi">0</span><span class="p">,</span> <span class="mi">0</span><span class="p">]])</span>
<span class="n">array</span><span class="p">([</span><span class="mi">1</span><span class="p">])</span>
<span class="o">&gt;&gt;&gt;</span> <span class="n">clf</span><span class="o">.</span><span class="n">score</span><span class="p">(</span><span class="n">X</span><span class="p">,</span> <span class="n">y</span><span class="p">)</span>
<span class="mf">0.983</span><span class="o">...</span>
</code></pre></div>

</details>
<h3 id="get_item">get_item<a class="headerlink" href="#get_item" title="Permanent link">&para;</a></h3>
<details class="note" open="open"><summary>method get_item</summary><div class="highlight"><pre><span></span><code><span class="k">val</span> <span class="n">get_item</span> <span class="o">:</span>
  <span class="n">index</span><span class="o">:</span><span class="nn">Py</span><span class="p">.</span><span class="nn">Object</span><span class="p">.</span><span class="n">t</span> <span class="o">-&gt;</span>
  <span class="o">[&gt;</span> <span class="n">tag</span><span class="o">]</span> <span class="nn">Obj</span><span class="p">.</span><span class="n">t</span> <span class="o">-&gt;</span>
  <span class="nn">Py</span><span class="p">.</span><span class="nn">Object</span><span class="p">.</span><span class="n">t</span>
</code></pre></div>

<p>Return the index'th estimator in the ensemble.</p>
</details>
<h3 id="iter">iter<a class="headerlink" href="#iter" title="Permanent link">&para;</a></h3>
<details class="note" open="open"><summary>method iter</summary><div class="highlight"><pre><span></span><code><span class="k">val</span> <span class="n">iter</span> <span class="o">:</span>
  <span class="o">[&gt;</span> <span class="n">tag</span><span class="o">]</span> <span class="nn">Obj</span><span class="p">.</span><span class="n">t</span> <span class="o">-&gt;</span>
  <span class="nn">Dict</span><span class="p">.</span><span class="n">t</span> <span class="nn">Seq</span><span class="p">.</span><span class="n">t</span>
</code></pre></div>

<p>Return iterator over estimators in the ensemble.</p>
</details>
<h3 id="decision_function">decision_function<a class="headerlink" href="#decision_function" title="Permanent link">&para;</a></h3>
<details class="note" open="open"><summary>method decision_function</summary><div class="highlight"><pre><span></span><code><span class="k">val</span> <span class="n">decision_function</span> <span class="o">:</span>
  <span class="n">x</span><span class="o">:[&gt;`</span><span class="nc">ArrayLike</span><span class="o">]</span> <span class="nn">Np</span><span class="p">.</span><span class="nn">Obj</span><span class="p">.</span><span class="n">t</span> <span class="o">-&gt;</span>
  <span class="o">[&gt;</span> <span class="n">tag</span><span class="o">]</span> <span class="nn">Obj</span><span class="p">.</span><span class="n">t</span> <span class="o">-&gt;</span>
  <span class="o">[&gt;`</span><span class="nc">ArrayLike</span><span class="o">]</span> <span class="nn">Np</span><span class="p">.</span><span class="nn">Obj</span><span class="p">.</span><span class="n">t</span>
</code></pre></div>

<p>Compute the decision function of <code>X</code>.</p>
<h4>Parameters</h4>
<ul>
<li><strong>X : {array-like, sparse matrix} of shape (n_samples, n_features)</strong>
    The training input samples. Sparse matrix can be CSC, CSR, COO,
    DOK, or LIL. COO, DOK, and LIL are converted to CSR.</li>
</ul>
<h4>Returns</h4>
<ul>
<li><strong>score : ndarray of shape of (n_samples, k)</strong>
    The decision function of the input samples. The order of
    outputs is the same of that of the :term:<code>classes_</code> attribute.
    Binary classification is a special cases with <code>k == 1</code>,
    otherwise <code>k==n_classes</code>. For binary classification,
    values closer to -1 or 1 mean more like the first or second
    class in <code>classes_</code>, respectively.</li>
</ul>
</details>
<h3 id="fit">fit<a class="headerlink" href="#fit" title="Permanent link">&para;</a></h3>
<details class="note" open="open"><summary>method fit</summary><div class="highlight"><pre><span></span><code><span class="k">val</span> <span class="n">fit</span> <span class="o">:</span>
  <span class="o">?</span><span class="n">sample_weight</span><span class="o">:[&gt;`</span><span class="nc">ArrayLike</span><span class="o">]</span> <span class="nn">Np</span><span class="p">.</span><span class="nn">Obj</span><span class="p">.</span><span class="n">t</span> <span class="o">-&gt;</span>
  <span class="n">x</span><span class="o">:[&gt;`</span><span class="nc">ArrayLike</span><span class="o">]</span> <span class="nn">Np</span><span class="p">.</span><span class="nn">Obj</span><span class="p">.</span><span class="n">t</span> <span class="o">-&gt;</span>
  <span class="n">y</span><span class="o">:[&gt;`</span><span class="nc">ArrayLike</span><span class="o">]</span> <span class="nn">Np</span><span class="p">.</span><span class="nn">Obj</span><span class="p">.</span><span class="n">t</span> <span class="o">-&gt;</span>
  <span class="o">[&gt;</span> <span class="n">tag</span><span class="o">]</span> <span class="nn">Obj</span><span class="p">.</span><span class="n">t</span> <span class="o">-&gt;</span>
  <span class="n">t</span>
</code></pre></div>

<p>Build a boosted classifier from the training set (X, y).</p>
<h4>Parameters</h4>
<ul>
<li>
<p><strong>X : {array-like, sparse matrix} of shape (n_samples, n_features)</strong>
    The training input samples. Sparse matrix can be CSC, CSR, COO,
    DOK, or LIL. COO, DOK, and LIL are converted to CSR.</p>
</li>
<li>
<p><strong>y : array-like of shape (n_samples,)</strong>
    The target values (class labels).</p>
</li>
<li>
<p><strong>sample_weight : array-like of shape (n_samples,), default=None</strong>
    Sample weights. If None, the sample weights are initialized to
    <code>1 / n_samples</code>.</p>
</li>
</ul>
<h4>Returns</h4>
<ul>
<li><strong>self : object</strong>
    Fitted estimator.</li>
</ul>
</details>
<h3 id="get_params">get_params<a class="headerlink" href="#get_params" title="Permanent link">&para;</a></h3>
<details class="note" open="open"><summary>method get_params</summary><div class="highlight"><pre><span></span><code><span class="k">val</span> <span class="n">get_params</span> <span class="o">:</span>
  <span class="o">?</span><span class="n">deep</span><span class="o">:</span><span class="kt">bool</span> <span class="o">-&gt;</span>
  <span class="o">[&gt;</span> <span class="n">tag</span><span class="o">]</span> <span class="nn">Obj</span><span class="p">.</span><span class="n">t</span> <span class="o">-&gt;</span>
  <span class="nn">Dict</span><span class="p">.</span><span class="n">t</span>
</code></pre></div>

<p>Get parameters for this estimator.</p>
<h4>Parameters</h4>
<ul>
<li><strong>deep : bool, default=True</strong>
    If True, will return the parameters for this estimator and
    contained subobjects that are estimators.</li>
</ul>
<h4>Returns</h4>
<ul>
<li><strong>params : mapping of string to any</strong>
    Parameter names mapped to their values.</li>
</ul>
</details>
<h3 id="predict">predict<a class="headerlink" href="#predict" title="Permanent link">&para;</a></h3>
<details class="note" open="open"><summary>method predict</summary><div class="highlight"><pre><span></span><code><span class="k">val</span> <span class="n">predict</span> <span class="o">:</span>
  <span class="n">x</span><span class="o">:[&gt;`</span><span class="nc">ArrayLike</span><span class="o">]</span> <span class="nn">Np</span><span class="p">.</span><span class="nn">Obj</span><span class="p">.</span><span class="n">t</span> <span class="o">-&gt;</span>
  <span class="o">[&gt;</span> <span class="n">tag</span><span class="o">]</span> <span class="nn">Obj</span><span class="p">.</span><span class="n">t</span> <span class="o">-&gt;</span>
  <span class="o">[&gt;`</span><span class="nc">ArrayLike</span><span class="o">]</span> <span class="nn">Np</span><span class="p">.</span><span class="nn">Obj</span><span class="p">.</span><span class="n">t</span>
</code></pre></div>

<p>Predict classes for X.</p>
<p>The predicted class of an input sample is computed as the weighted mean
prediction of the classifiers in the ensemble.</p>
<h4>Parameters</h4>
<ul>
<li><strong>X : {array-like, sparse matrix} of shape (n_samples, n_features)</strong>
    The training input samples. Sparse matrix can be CSC, CSR, COO,
    DOK, or LIL. COO, DOK, and LIL are converted to CSR.</li>
</ul>
<h4>Returns</h4>
<ul>
<li><strong>y : ndarray of shape (n_samples,)</strong>
    The predicted classes.</li>
</ul>
</details>
<h3 id="predict_log_proba">predict_log_proba<a class="headerlink" href="#predict_log_proba" title="Permanent link">&para;</a></h3>
<details class="note" open="open"><summary>method predict_log_proba</summary><div class="highlight"><pre><span></span><code><span class="k">val</span> <span class="n">predict_log_proba</span> <span class="o">:</span>
  <span class="n">x</span><span class="o">:[&gt;`</span><span class="nc">ArrayLike</span><span class="o">]</span> <span class="nn">Np</span><span class="p">.</span><span class="nn">Obj</span><span class="p">.</span><span class="n">t</span> <span class="o">-&gt;</span>
  <span class="o">[&gt;</span> <span class="n">tag</span><span class="o">]</span> <span class="nn">Obj</span><span class="p">.</span><span class="n">t</span> <span class="o">-&gt;</span>
  <span class="o">[&gt;`</span><span class="nc">ArrayLike</span><span class="o">]</span> <span class="nn">Np</span><span class="p">.</span><span class="nn">Obj</span><span class="p">.</span><span class="n">t</span>
</code></pre></div>

<p>Predict class log-probabilities for X.</p>
<p>The predicted class log-probabilities of an input sample is computed as
the weighted mean predicted class log-probabilities of the classifiers
in the ensemble.</p>
<h4>Parameters</h4>
<ul>
<li><strong>X : {array-like, sparse matrix} of shape (n_samples, n_features)</strong>
    The training input samples. Sparse matrix can be CSC, CSR, COO,
    DOK, or LIL. COO, DOK, and LIL are converted to CSR.</li>
</ul>
<h4>Returns</h4>
<ul>
<li><strong>p : ndarray of shape (n_samples, n_classes)</strong>
    The class probabilities of the input samples. The order of
    outputs is the same of that of the :term:<code>classes_</code> attribute.</li>
</ul>
</details>
<h3 id="predict_proba">predict_proba<a class="headerlink" href="#predict_proba" title="Permanent link">&para;</a></h3>
<details class="note" open="open"><summary>method predict_proba</summary><div class="highlight"><pre><span></span><code><span class="k">val</span> <span class="n">predict_proba</span> <span class="o">:</span>
  <span class="n">x</span><span class="o">:[&gt;`</span><span class="nc">ArrayLike</span><span class="o">]</span> <span class="nn">Np</span><span class="p">.</span><span class="nn">Obj</span><span class="p">.</span><span class="n">t</span> <span class="o">-&gt;</span>
  <span class="o">[&gt;</span> <span class="n">tag</span><span class="o">]</span> <span class="nn">Obj</span><span class="p">.</span><span class="n">t</span> <span class="o">-&gt;</span>
  <span class="o">[&gt;`</span><span class="nc">ArrayLike</span><span class="o">]</span> <span class="nn">Np</span><span class="p">.</span><span class="nn">Obj</span><span class="p">.</span><span class="n">t</span>
</code></pre></div>

<p>Predict class probabilities for X.</p>
<p>The predicted class probabilities of an input sample is computed as
the weighted mean predicted class probabilities of the classifiers
in the ensemble.</p>
<h4>Parameters</h4>
<ul>
<li><strong>X : {array-like, sparse matrix} of shape (n_samples, n_features)</strong>
    The training input samples. Sparse matrix can be CSC, CSR, COO,
    DOK, or LIL. COO, DOK, and LIL are converted to CSR.</li>
</ul>
<h4>Returns</h4>
<ul>
<li><strong>p : ndarray of shape (n_samples, n_classes)</strong>
    The class probabilities of the input samples. The order of
    outputs is the same of that of the :term:<code>classes_</code> attribute.</li>
</ul>
</details>
<h3 id="score">score<a class="headerlink" href="#score" title="Permanent link">&para;</a></h3>
<details class="note" open="open"><summary>method score</summary><div class="highlight"><pre><span></span><code><span class="k">val</span> <span class="n">score</span> <span class="o">:</span>
  <span class="o">?</span><span class="n">sample_weight</span><span class="o">:[&gt;`</span><span class="nc">ArrayLike</span><span class="o">]</span> <span class="nn">Np</span><span class="p">.</span><span class="nn">Obj</span><span class="p">.</span><span class="n">t</span> <span class="o">-&gt;</span>
  <span class="n">x</span><span class="o">:[&gt;`</span><span class="nc">ArrayLike</span><span class="o">]</span> <span class="nn">Np</span><span class="p">.</span><span class="nn">Obj</span><span class="p">.</span><span class="n">t</span> <span class="o">-&gt;</span>
  <span class="n">y</span><span class="o">:[&gt;`</span><span class="nc">ArrayLike</span><span class="o">]</span> <span class="nn">Np</span><span class="p">.</span><span class="nn">Obj</span><span class="p">.</span><span class="n">t</span> <span class="o">-&gt;</span>
  <span class="o">[&gt;</span> <span class="n">tag</span><span class="o">]</span> <span class="nn">Obj</span><span class="p">.</span><span class="n">t</span> <span class="o">-&gt;</span>
  <span class="kt">float</span>
</code></pre></div>

<p>Return the mean accuracy on the given test data and labels.</p>
<p>In multi-label classification, this is the subset accuracy
which is a harsh metric since you require for each sample that
each label set be correctly predicted.</p>
<h4>Parameters</h4>
<ul>
<li>
<p><strong>X : array-like of shape (n_samples, n_features)</strong>
    Test samples.</p>
</li>
<li>
<p><strong>y : array-like of shape (n_samples,) or (n_samples, n_outputs)</strong>
    True labels for X.</p>
</li>
<li>
<p><strong>sample_weight : array-like of shape (n_samples,), default=None</strong>
    Sample weights.</p>
</li>
</ul>
<h4>Returns</h4>
<ul>
<li><strong>score : float</strong>
    Mean accuracy of self.predict(X) wrt. y.</li>
</ul>
</details>
<h3 id="set_params">set_params<a class="headerlink" href="#set_params" title="Permanent link">&para;</a></h3>
<details class="note" open="open"><summary>method set_params</summary><div class="highlight"><pre><span></span><code><span class="k">val</span> <span class="n">set_params</span> <span class="o">:</span>
  <span class="o">?</span><span class="n">params</span><span class="o">:(</span><span class="kt">string</span> <span class="o">*</span> <span class="nn">Py</span><span class="p">.</span><span class="nn">Object</span><span class="p">.</span><span class="n">t</span><span class="o">)</span> <span class="kt">list</span> <span class="o">-&gt;</span>
  <span class="o">[&gt;</span> <span class="n">tag</span><span class="o">]</span> <span class="nn">Obj</span><span class="p">.</span><span class="n">t</span> <span class="o">-&gt;</span>
  <span class="n">t</span>
</code></pre></div>

<p>Set the parameters of this estimator.</p>
<p>The method works on simple estimators as well as on nested objects
(such as pipelines). The latter have parameters of the form
<code>&lt;component&gt;__&lt;parameter&gt;</code> so that it's possible to update each
component of a nested object.</p>
<h4>Parameters</h4>
<ul>
<li><strong>**params : dict</strong>
    Estimator parameters.</li>
</ul>
<h4>Returns</h4>
<ul>
<li><strong>self : object</strong>
    Estimator instance.</li>
</ul>
</details>
<h3 id="staged_decision_function">staged_decision_function<a class="headerlink" href="#staged_decision_function" title="Permanent link">&para;</a></h3>
<details class="note" open="open"><summary>method staged_decision_function</summary><div class="highlight"><pre><span></span><code><span class="k">val</span> <span class="n">staged_decision_function</span> <span class="o">:</span>
  <span class="n">x</span><span class="o">:[&gt;`</span><span class="nc">ArrayLike</span><span class="o">]</span> <span class="nn">Np</span><span class="p">.</span><span class="nn">Obj</span><span class="p">.</span><span class="n">t</span> <span class="o">-&gt;</span>
  <span class="o">[&gt;</span> <span class="n">tag</span><span class="o">]</span> <span class="nn">Obj</span><span class="p">.</span><span class="n">t</span> <span class="o">-&gt;</span>
  <span class="o">[&gt;`</span><span class="nc">ArrayLike</span><span class="o">]</span> <span class="nn">Np</span><span class="p">.</span><span class="nn">Obj</span><span class="p">.</span><span class="n">t</span> <span class="nn">Seq</span><span class="p">.</span><span class="n">t</span>
</code></pre></div>

<p>Compute decision function of <code>X</code> for each boosting iteration.</p>
<p>This method allows monitoring (i.e. determine error on testing set)
after each boosting iteration.</p>
<h4>Parameters</h4>
<ul>
<li><strong>X : {array-like, sparse matrix} of shape (n_samples, n_features)</strong>
    The training input samples. Sparse matrix can be CSC, CSR, COO,
    DOK, or LIL. COO, DOK, and LIL are converted to CSR.</li>
</ul>
<h4>Yields</h4>
<ul>
<li><strong>score : generator of ndarray of shape (n_samples, k)</strong>
    The decision function of the input samples. The order of
    outputs is the same of that of the :term:<code>classes_</code> attribute.
    Binary classification is a special cases with <code>k == 1</code>,
    otherwise <code>k==n_classes</code>. For binary classification,
    values closer to -1 or 1 mean more like the first or second
    class in <code>classes_</code>, respectively.</li>
</ul>
</details>
<h3 id="staged_predict">staged_predict<a class="headerlink" href="#staged_predict" title="Permanent link">&para;</a></h3>
<details class="note" open="open"><summary>method staged_predict</summary><div class="highlight"><pre><span></span><code><span class="k">val</span> <span class="n">staged_predict</span> <span class="o">:</span>
  <span class="n">x</span><span class="o">:[&gt;`</span><span class="nc">ArrayLike</span><span class="o">]</span> <span class="nn">Np</span><span class="p">.</span><span class="nn">Obj</span><span class="p">.</span><span class="n">t</span> <span class="o">-&gt;</span>
  <span class="o">[&gt;</span> <span class="n">tag</span><span class="o">]</span> <span class="nn">Obj</span><span class="p">.</span><span class="n">t</span> <span class="o">-&gt;</span>
  <span class="o">[&gt;`</span><span class="nc">ArrayLike</span><span class="o">]</span> <span class="nn">Np</span><span class="p">.</span><span class="nn">Obj</span><span class="p">.</span><span class="n">t</span> <span class="nn">Seq</span><span class="p">.</span><span class="n">t</span>
</code></pre></div>

<p>Return staged predictions for X.</p>
<p>The predicted class of an input sample is computed as the weighted mean
prediction of the classifiers in the ensemble.</p>
<p>This generator method yields the ensemble prediction after each
iteration of boosting and therefore allows monitoring, such as to
determine the prediction on a test set after each boost.</p>
<h4>Parameters</h4>
<ul>
<li><strong>X : array-like of shape (n_samples, n_features)</strong>
    The input samples. Sparse matrix can be CSC, CSR, COO,
    DOK, or LIL. COO, DOK, and LIL are converted to CSR.</li>
</ul>
<h4>Yields</h4>
<ul>
<li><strong>y : generator of ndarray of shape (n_samples,)</strong>
    The predicted classes.</li>
</ul>
</details>
<h3 id="staged_predict_proba">staged_predict_proba<a class="headerlink" href="#staged_predict_proba" title="Permanent link">&para;</a></h3>
<details class="note" open="open"><summary>method staged_predict_proba</summary><div class="highlight"><pre><span></span><code><span class="k">val</span> <span class="n">staged_predict_proba</span> <span class="o">:</span>
  <span class="n">x</span><span class="o">:[&gt;`</span><span class="nc">ArrayLike</span><span class="o">]</span> <span class="nn">Np</span><span class="p">.</span><span class="nn">Obj</span><span class="p">.</span><span class="n">t</span> <span class="o">-&gt;</span>
  <span class="o">[&gt;</span> <span class="n">tag</span><span class="o">]</span> <span class="nn">Obj</span><span class="p">.</span><span class="n">t</span> <span class="o">-&gt;</span>
  <span class="o">[&gt;`</span><span class="nc">ArrayLike</span><span class="o">]</span> <span class="nn">Np</span><span class="p">.</span><span class="nn">Obj</span><span class="p">.</span><span class="n">t</span> <span class="nn">Seq</span><span class="p">.</span><span class="n">t</span>
</code></pre></div>

<p>Predict class probabilities for X.</p>
<p>The predicted class probabilities of an input sample is computed as
the weighted mean predicted class probabilities of the classifiers
in the ensemble.</p>
<p>This generator method yields the ensemble predicted class probabilities
after each iteration of boosting and therefore allows monitoring, such
as to determine the predicted class probabilities on a test set after
each boost.</p>
<h4>Parameters</h4>
<ul>
<li><strong>X : {array-like, sparse matrix} of shape (n_samples, n_features)</strong>
    The training input samples. Sparse matrix can be CSC, CSR, COO,
    DOK, or LIL. COO, DOK, and LIL are converted to CSR.</li>
</ul>
<h4>Yields</h4>
<ul>
<li><strong>p : generator of ndarray of shape (n_samples,)</strong>
    The class probabilities of the input samples. The order of
    outputs is the same of that of the :term:<code>classes_</code> attribute.</li>
</ul>
</details>
<h3 id="staged_score">staged_score<a class="headerlink" href="#staged_score" title="Permanent link">&para;</a></h3>
<details class="note" open="open"><summary>method staged_score</summary><div class="highlight"><pre><span></span><code><span class="k">val</span> <span class="n">staged_score</span> <span class="o">:</span>
  <span class="o">?</span><span class="n">sample_weight</span><span class="o">:[&gt;`</span><span class="nc">ArrayLike</span><span class="o">]</span> <span class="nn">Np</span><span class="p">.</span><span class="nn">Obj</span><span class="p">.</span><span class="n">t</span> <span class="o">-&gt;</span>
  <span class="n">x</span><span class="o">:[&gt;`</span><span class="nc">ArrayLike</span><span class="o">]</span> <span class="nn">Np</span><span class="p">.</span><span class="nn">Obj</span><span class="p">.</span><span class="n">t</span> <span class="o">-&gt;</span>
  <span class="n">y</span><span class="o">:[&gt;`</span><span class="nc">ArrayLike</span><span class="o">]</span> <span class="nn">Np</span><span class="p">.</span><span class="nn">Obj</span><span class="p">.</span><span class="n">t</span> <span class="o">-&gt;</span>
  <span class="o">[&gt;</span> <span class="n">tag</span><span class="o">]</span> <span class="nn">Obj</span><span class="p">.</span><span class="n">t</span> <span class="o">-&gt;</span>
  <span class="nn">Py</span><span class="p">.</span><span class="nn">Object</span><span class="p">.</span><span class="n">t</span>
</code></pre></div>

<p>Return staged scores for X, y.</p>
<p>This generator method yields the ensemble score after each iteration of
boosting and therefore allows monitoring, such as to determine the
score on a test set after each boost.</p>
<h4>Parameters</h4>
<ul>
<li>
<p><strong>X : {array-like, sparse matrix} of shape (n_samples, n_features)</strong>
    The training input samples. Sparse matrix can be CSC, CSR, COO,
    DOK, or LIL. COO, DOK, and LIL are converted to CSR.</p>
</li>
<li>
<p><strong>y : array-like of shape (n_samples,)</strong>
    Labels for X.</p>
</li>
<li>
<p><strong>sample_weight : array-like of shape (n_samples,), default=None</strong>
    Sample weights.</p>
</li>
</ul>
<h4>Yields</h4>
<ul>
<li><strong>z : float</strong></li>
</ul>
</details>
<h3 id="base_estimator_">base_estimator_<a class="headerlink" href="#base_estimator_" title="Permanent link">&para;</a></h3>
<details class="note" open="open"><summary>attribute base_estimator_</summary><div class="highlight"><pre><span></span><code><span class="k">val</span> <span class="n">base_estimator_</span> <span class="o">:</span> <span class="n">t</span> <span class="o">-&gt;</span> <span class="o">[`</span><span class="nc">BaseEstimator</span><span class="o">|`</span><span class="nc">Object</span><span class="o">]</span> <span class="nn">Np</span><span class="p">.</span><span class="nn">Obj</span><span class="p">.</span><span class="n">t</span>
<span class="k">val</span> <span class="n">base_estimator_opt</span> <span class="o">:</span> <span class="n">t</span> <span class="o">-&gt;</span> <span class="o">([`</span><span class="nc">BaseEstimator</span><span class="o">|`</span><span class="nc">Object</span><span class="o">]</span> <span class="nn">Np</span><span class="p">.</span><span class="nn">Obj</span><span class="p">.</span><span class="n">t</span><span class="o">)</span> <span class="n">option</span>
</code></pre></div>

<p>This attribute is documented in <code>create</code> above. The first version raises Not_found
if the attribute is None. The _opt version returns an option.</p>
</details>
<h3 id="estimators_">estimators_<a class="headerlink" href="#estimators_" title="Permanent link">&para;</a></h3>
<details class="note" open="open"><summary>attribute estimators_</summary><div class="highlight"><pre><span></span><code><span class="k">val</span> <span class="n">estimators_</span> <span class="o">:</span> <span class="n">t</span> <span class="o">-&gt;</span> <span class="nn">Py</span><span class="p">.</span><span class="nn">Object</span><span class="p">.</span><span class="n">t</span>
<span class="k">val</span> <span class="n">estimators_opt</span> <span class="o">:</span> <span class="n">t</span> <span class="o">-&gt;</span> <span class="o">(</span><span class="nn">Py</span><span class="p">.</span><span class="nn">Object</span><span class="p">.</span><span class="n">t</span><span class="o">)</span> <span class="n">option</span>
</code></pre></div>

<p>This attribute is documented in <code>create</code> above. The first version raises Not_found
if the attribute is None. The _opt version returns an option.</p>
</details>
<h3 id="classes_">classes_<a class="headerlink" href="#classes_" title="Permanent link">&para;</a></h3>
<details class="note" open="open"><summary>attribute classes_</summary><div class="highlight"><pre><span></span><code><span class="k">val</span> <span class="n">classes_</span> <span class="o">:</span> <span class="n">t</span> <span class="o">-&gt;</span> <span class="o">[&gt;`</span><span class="nc">ArrayLike</span><span class="o">]</span> <span class="nn">Np</span><span class="p">.</span><span class="nn">Obj</span><span class="p">.</span><span class="n">t</span>
<span class="k">val</span> <span class="n">classes_opt</span> <span class="o">:</span> <span class="n">t</span> <span class="o">-&gt;</span> <span class="o">([&gt;`</span><span class="nc">ArrayLike</span><span class="o">]</span> <span class="nn">Np</span><span class="p">.</span><span class="nn">Obj</span><span class="p">.</span><span class="n">t</span><span class="o">)</span> <span class="n">option</span>
</code></pre></div>

<p>This attribute is documented in <code>create</code> above. The first version raises Not_found
if the attribute is None. The _opt version returns an option.</p>
</details>
<h3 id="n_classes_">n_classes_<a class="headerlink" href="#n_classes_" title="Permanent link">&para;</a></h3>
<details class="note" open="open"><summary>attribute n_classes_</summary><div class="highlight"><pre><span></span><code><span class="k">val</span> <span class="n">n_classes_</span> <span class="o">:</span> <span class="n">t</span> <span class="o">-&gt;</span> <span class="kt">int</span>
<span class="k">val</span> <span class="n">n_classes_opt</span> <span class="o">:</span> <span class="n">t</span> <span class="o">-&gt;</span> <span class="o">(</span><span class="kt">int</span><span class="o">)</span> <span class="n">option</span>
</code></pre></div>

<p>This attribute is documented in <code>create</code> above. The first version raises Not_found
if the attribute is None. The _opt version returns an option.</p>
</details>
<h3 id="estimator_weights_">estimator_weights_<a class="headerlink" href="#estimator_weights_" title="Permanent link">&para;</a></h3>
<details class="note" open="open"><summary>attribute estimator_weights_</summary><div class="highlight"><pre><span></span><code><span class="k">val</span> <span class="n">estimator_weights_</span> <span class="o">:</span> <span class="n">t</span> <span class="o">-&gt;</span> <span class="o">[&gt;`</span><span class="nc">ArrayLike</span><span class="o">]</span> <span class="nn">Np</span><span class="p">.</span><span class="nn">Obj</span><span class="p">.</span><span class="n">t</span>
<span class="k">val</span> <span class="n">estimator_weights_opt</span> <span class="o">:</span> <span class="n">t</span> <span class="o">-&gt;</span> <span class="o">([&gt;`</span><span class="nc">ArrayLike</span><span class="o">]</span> <span class="nn">Np</span><span class="p">.</span><span class="nn">Obj</span><span class="p">.</span><span class="n">t</span><span class="o">)</span> <span class="n">option</span>
</code></pre></div>

<p>This attribute is documented in <code>create</code> above. The first version raises Not_found
if the attribute is None. The _opt version returns an option.</p>
</details>
<h3 id="estimator_errors_">estimator_errors_<a class="headerlink" href="#estimator_errors_" title="Permanent link">&para;</a></h3>
<details class="note" open="open"><summary>attribute estimator_errors_</summary><div class="highlight"><pre><span></span><code><span class="k">val</span> <span class="n">estimator_errors_</span> <span class="o">:</span> <span class="n">t</span> <span class="o">-&gt;</span> <span class="o">[&gt;`</span><span class="nc">ArrayLike</span><span class="o">]</span> <span class="nn">Np</span><span class="p">.</span><span class="nn">Obj</span><span class="p">.</span><span class="n">t</span>
<span class="k">val</span> <span class="n">estimator_errors_opt</span> <span class="o">:</span> <span class="n">t</span> <span class="o">-&gt;</span> <span class="o">([&gt;`</span><span class="nc">ArrayLike</span><span class="o">]</span> <span class="nn">Np</span><span class="p">.</span><span class="nn">Obj</span><span class="p">.</span><span class="n">t</span><span class="o">)</span> <span class="n">option</span>
</code></pre></div>

<p>This attribute is documented in <code>create</code> above. The first version raises Not_found
if the attribute is None. The _opt version returns an option.</p>
</details>
<h3 id="feature_importances_">feature_importances_<a class="headerlink" href="#feature_importances_" title="Permanent link">&para;</a></h3>
<details class="note" open="open"><summary>attribute feature_importances_</summary><div class="highlight"><pre><span></span><code><span class="k">val</span> <span class="n">feature_importances_</span> <span class="o">:</span> <span class="n">t</span> <span class="o">-&gt;</span> <span class="o">[&gt;`</span><span class="nc">ArrayLike</span><span class="o">]</span> <span class="nn">Np</span><span class="p">.</span><span class="nn">Obj</span><span class="p">.</span><span class="n">t</span>
<span class="k">val</span> <span class="n">feature_importances_opt</span> <span class="o">:</span> <span class="n">t</span> <span class="o">-&gt;</span> <span class="o">([&gt;`</span><span class="nc">ArrayLike</span><span class="o">]</span> <span class="nn">Np</span><span class="p">.</span><span class="nn">Obj</span><span class="p">.</span><span class="n">t</span><span class="o">)</span> <span class="n">option</span>
</code></pre></div>

<p>This attribute is documented in <code>create</code> above. The first version raises Not_found
if the attribute is None. The _opt version returns an option.</p>
</details>
<h3 id="warning">warning<a class="headerlink" href="#warning" title="Permanent link">&para;</a></h3>
<details class="note" open="open"><summary>attribute warning</summary><div class="highlight"><pre><span></span><code><span class="k">val</span> <span class="n">warning</span> <span class="o">:</span> <span class="n">t</span> <span class="o">-&gt;</span> <span class="nn">Py</span><span class="p">.</span><span class="nn">Object</span><span class="p">.</span><span class="n">t</span>
<span class="k">val</span> <span class="n">warning_opt</span> <span class="o">:</span> <span class="n">t</span> <span class="o">-&gt;</span> <span class="o">(</span><span class="nn">Py</span><span class="p">.</span><span class="nn">Object</span><span class="p">.</span><span class="n">t</span><span class="o">)</span> <span class="n">option</span>
</code></pre></div>

<p>This attribute is documented in <code>create</code> above. The first version raises Not_found
if the attribute is None. The _opt version returns an option.</p>
</details>
<h3 id="to_string">to_string<a class="headerlink" href="#to_string" title="Permanent link">&para;</a></h3>
<details class="note" open="open"><summary>method to_string</summary><div class="highlight"><pre><span></span><code><span class="k">val</span> <span class="n">to_string</span><span class="o">:</span> <span class="n">t</span> <span class="o">-&gt;</span> <span class="kt">string</span>
</code></pre></div>

<p>Print the object to a human-readable representation.</p>
</details>
<h3 id="show">show<a class="headerlink" href="#show" title="Permanent link">&para;</a></h3>
<details class="note" open="open"><summary>method show</summary><div class="highlight"><pre><span></span><code><span class="k">val</span> <span class="n">show</span><span class="o">:</span> <span class="n">t</span> <span class="o">-&gt;</span> <span class="kt">string</span>
</code></pre></div>

<p>Print the object to a human-readable representation.</p>
</details>
<h3 id="pp">pp<a class="headerlink" href="#pp" title="Permanent link">&para;</a></h3>
<details class="note" open="open"><summary>method pp</summary><div class="highlight"><pre><span></span><code><span class="k">val</span> <span class="n">pp</span><span class="o">:</span> <span class="nn">Format</span><span class="p">.</span><span class="n">formatter</span> <span class="o">-&gt;</span> <span class="n">t</span> <span class="o">-&gt;</span> <span class="kt">unit</span>
</code></pre></div>

<p>Pretty-print the object to a formatter.</p>
</details>
<h2 id="adaboostregressor">AdaBoostRegressor<a class="headerlink" href="#adaboostregressor" title="Permanent link">&para;</a></h2>
<p>Module <code>Sklearn.​Ensemble.​AdaBoostRegressor</code> wraps Python class <a href="https://scikit-learn.org/stable/modules/generated/sklearn.ensemble.AdaBoostRegressor.html"><code>sklearn.ensemble.AdaBoostRegressor</code></a>.</p>
<div class="highlight"><pre><span></span><code><span class="k">type</span> <span class="n">t</span>
</code></pre></div>

<h3 id="create_1">create<a class="headerlink" href="#create_1" title="Permanent link">&para;</a></h3>
<details class="note" open="open"><summary>constructor and attributes create</summary><div class="highlight"><pre><span></span><code><span class="k">val</span> <span class="n">create</span> <span class="o">:</span>
  <span class="o">?</span><span class="n">base_estimator</span><span class="o">:[&gt;`</span><span class="nc">BaseEstimator</span><span class="o">]</span> <span class="nn">Np</span><span class="p">.</span><span class="nn">Obj</span><span class="p">.</span><span class="n">t</span> <span class="o">-&gt;</span>
  <span class="o">?</span><span class="n">n_estimators</span><span class="o">:</span><span class="kt">int</span> <span class="o">-&gt;</span>
  <span class="o">?</span><span class="n">learning_rate</span><span class="o">:</span><span class="kt">float</span> <span class="o">-&gt;</span>
  <span class="o">?</span><span class="n">loss</span><span class="o">:[`</span><span class="nc">Linear</span> <span class="o">|</span> <span class="o">`</span><span class="nc">Square</span> <span class="o">|</span> <span class="o">`</span><span class="nc">Exponential</span><span class="o">]</span> <span class="o">-&gt;</span>
  <span class="o">?</span><span class="n">random_state</span><span class="o">:</span><span class="kt">int</span> <span class="o">-&gt;</span>
  <span class="kt">unit</span> <span class="o">-&gt;</span>
  <span class="n">t</span>
</code></pre></div>

<p>An AdaBoost regressor.</p>
<p>An AdaBoost [1] regressor is a meta-estimator that begins by fitting a
regressor on the original dataset and then fits additional copies of the
regressor on the same dataset but where the weights of instances are
adjusted according to the error of the current prediction. As such,
subsequent regressors focus more on difficult cases.</p>
<p>This class implements the algorithm known as AdaBoost.R2 [2].</p>
<p>Read more in the :ref:<code>User Guide &lt;adaboost&gt;</code>.</p>
<p>.. versionadded:: 0.14</p>
<h4>Parameters</h4>
<ul>
<li>
<p><strong>base_estimator : object, default=None</strong>
    The base estimator from which the boosted ensemble is built.
    If <code>None</code>, then the base estimator is
    <code>DecisionTreeRegressor(max_depth=3)</code>.</p>
</li>
<li>
<p><strong>n_estimators : int, default=50</strong>
    The maximum number of estimators at which boosting is terminated.
    In case of perfect fit, the learning procedure is stopped early.</p>
</li>
<li>
<p><strong>learning_rate : float, default=1.</strong>
    Learning rate shrinks the contribution of each regressor by
    <code>learning_rate</code>. There is a trade-off between <code>learning_rate</code> and
    <code>n_estimators</code>.</p>
</li>
<li>
<p><strong>loss : {'linear', 'square', 'exponential'}, default='linear'</strong>
    The loss function to use when updating the weights after each
    boosting iteration.</p>
</li>
<li>
<p><strong>random_state : int or RandomState, default=None</strong>
    Controls the random seed given at each <code>base_estimator</code> at each
    boosting iteration.
    Thus, it is only used when <code>base_estimator</code> exposes a <code>random_state</code>.
    In addition, it controls the bootstrap of the weights used to train the
    <code>base_estimator</code> at each boosting iteration.
    Pass an int for reproducible output across multiple function calls.</p>
</li>
<li>
<p><strong>See :term:<code>Glossary &lt;random_state&gt;</code>.</strong></p>
</li>
</ul>
<h4>Attributes</h4>
<ul>
<li>
<p><strong>base_estimator_ : estimator</strong>
    The base estimator from which the ensemble is grown.</p>
</li>
<li>
<p><strong>estimators_ : list of classifiers</strong>
    The collection of fitted sub-estimators.</p>
</li>
<li>
<p><strong>estimator_weights_ : ndarray of floats</strong>
    Weights for each estimator in the boosted ensemble.</p>
</li>
<li>
<p><strong>estimator_errors_ : ndarray of floats</strong>
    Regression error for each estimator in the boosted ensemble.</p>
</li>
<li>
<p><strong>feature_importances_ : ndarray of shape (n_features,)</strong>
    The impurity-based feature importances if supported by the
    <code>base_estimator</code> (when based on decision trees).</p>
</li>
<li>
<p><strong>Warning: impurity-based feature importances can be misleading for</strong>
    high cardinality features (many unique values). See
    :func:<code>sklearn.inspection.permutation_importance</code> as an alternative.</p>
</li>
</ul>
<h4>Examples</h4>
<div class="highlight"><pre><span></span><code><span class="o">&gt;&gt;&gt;</span> <span class="kn">from</span> <span class="nn">sklearn.ensemble</span> <span class="kn">import</span> <span class="n">AdaBoostRegressor</span>
<span class="o">&gt;&gt;&gt;</span> <span class="kn">from</span> <span class="nn">sklearn.datasets</span> <span class="kn">import</span> <span class="n">make_regression</span>
<span class="o">&gt;&gt;&gt;</span> <span class="n">X</span><span class="p">,</span> <span class="n">y</span> <span class="o">=</span> <span class="n">make_regression</span><span class="p">(</span><span class="n">n_features</span><span class="o">=</span><span class="mi">4</span><span class="p">,</span> <span class="n">n_informative</span><span class="o">=</span><span class="mi">2</span><span class="p">,</span>
<span class="o">...</span>                        <span class="n">random_state</span><span class="o">=</span><span class="mi">0</span><span class="p">,</span> <span class="n">shuffle</span><span class="o">=</span><span class="kc">False</span><span class="p">)</span>
<span class="o">&gt;&gt;&gt;</span> <span class="n">regr</span> <span class="o">=</span> <span class="n">AdaBoostRegressor</span><span class="p">(</span><span class="n">random_state</span><span class="o">=</span><span class="mi">0</span><span class="p">,</span> <span class="n">n_estimators</span><span class="o">=</span><span class="mi">100</span><span class="p">)</span>
<span class="o">&gt;&gt;&gt;</span> <span class="n">regr</span><span class="o">.</span><span class="n">fit</span><span class="p">(</span><span class="n">X</span><span class="p">,</span> <span class="n">y</span><span class="p">)</span>
<span class="n">AdaBoostRegressor</span><span class="p">(</span><span class="n">n_estimators</span><span class="o">=</span><span class="mi">100</span><span class="p">,</span> <span class="n">random_state</span><span class="o">=</span><span class="mi">0</span><span class="p">)</span>
<span class="o">&gt;&gt;&gt;</span> <span class="n">regr</span><span class="o">.</span><span class="n">predict</span><span class="p">([[</span><span class="mi">0</span><span class="p">,</span> <span class="mi">0</span><span class="p">,</span> <span class="mi">0</span><span class="p">,</span> <span class="mi">0</span><span class="p">]])</span>
<span class="n">array</span><span class="p">([</span><span class="mf">4.7972</span><span class="o">...</span><span class="p">])</span>
<span class="o">&gt;&gt;&gt;</span> <span class="n">regr</span><span class="o">.</span><span class="n">score</span><span class="p">(</span><span class="n">X</span><span class="p">,</span> <span class="n">y</span><span class="p">)</span>
<span class="mf">0.9771</span><span class="o">...</span>
</code></pre></div>

<h4>See also</h4>
<p>AdaBoostClassifier, GradientBoostingRegressor,
sklearn.tree.DecisionTreeRegressor</p>
<h4>References</h4>
<p>.. [1] Y. Freund, R. Schapire, 'A Decision-Theoretic Generalization of
       on-Line Learning and an Application to Boosting', 1995.</p>
<p>.. [2] H. Drucker, 'Improving Regressors using Boosting Techniques', 1997.</p>
</details>
<h3 id="get_item_1">get_item<a class="headerlink" href="#get_item_1" title="Permanent link">&para;</a></h3>
<details class="note" open="open"><summary>method get_item</summary><div class="highlight"><pre><span></span><code><span class="k">val</span> <span class="n">get_item</span> <span class="o">:</span>
  <span class="n">index</span><span class="o">:</span><span class="nn">Py</span><span class="p">.</span><span class="nn">Object</span><span class="p">.</span><span class="n">t</span> <span class="o">-&gt;</span>
  <span class="o">[&gt;</span> <span class="n">tag</span><span class="o">]</span> <span class="nn">Obj</span><span class="p">.</span><span class="n">t</span> <span class="o">-&gt;</span>
  <span class="nn">Py</span><span class="p">.</span><span class="nn">Object</span><span class="p">.</span><span class="n">t</span>
</code></pre></div>

<p>Return the index'th estimator in the ensemble.</p>
</details>
<h3 id="iter_1">iter<a class="headerlink" href="#iter_1" title="Permanent link">&para;</a></h3>
<details class="note" open="open"><summary>method iter</summary><div class="highlight"><pre><span></span><code><span class="k">val</span> <span class="n">iter</span> <span class="o">:</span>
  <span class="o">[&gt;</span> <span class="n">tag</span><span class="o">]</span> <span class="nn">Obj</span><span class="p">.</span><span class="n">t</span> <span class="o">-&gt;</span>
  <span class="nn">Dict</span><span class="p">.</span><span class="n">t</span> <span class="nn">Seq</span><span class="p">.</span><span class="n">t</span>
</code></pre></div>

<p>Return iterator over estimators in the ensemble.</p>
</details>
<h3 id="fit_1">fit<a class="headerlink" href="#fit_1" title="Permanent link">&para;</a></h3>
<details class="note" open="open"><summary>method fit</summary><div class="highlight"><pre><span></span><code><span class="k">val</span> <span class="n">fit</span> <span class="o">:</span>
  <span class="o">?</span><span class="n">sample_weight</span><span class="o">:[&gt;`</span><span class="nc">ArrayLike</span><span class="o">]</span> <span class="nn">Np</span><span class="p">.</span><span class="nn">Obj</span><span class="p">.</span><span class="n">t</span> <span class="o">-&gt;</span>
  <span class="n">x</span><span class="o">:[&gt;`</span><span class="nc">ArrayLike</span><span class="o">]</span> <span class="nn">Np</span><span class="p">.</span><span class="nn">Obj</span><span class="p">.</span><span class="n">t</span> <span class="o">-&gt;</span>
  <span class="n">y</span><span class="o">:[&gt;`</span><span class="nc">ArrayLike</span><span class="o">]</span> <span class="nn">Np</span><span class="p">.</span><span class="nn">Obj</span><span class="p">.</span><span class="n">t</span> <span class="o">-&gt;</span>
  <span class="o">[&gt;</span> <span class="n">tag</span><span class="o">]</span> <span class="nn">Obj</span><span class="p">.</span><span class="n">t</span> <span class="o">-&gt;</span>
  <span class="n">t</span>
</code></pre></div>

<p>Build a boosted regressor from the training set (X, y).</p>
<h4>Parameters</h4>
<ul>
<li>
<p><strong>X : {array-like, sparse matrix} of shape (n_samples, n_features)</strong>
    The training input samples. Sparse matrix can be CSC, CSR, COO,
    DOK, or LIL. COO, DOK, and LIL are converted to CSR.</p>
</li>
<li>
<p><strong>y : array-like of shape (n_samples,)</strong>
    The target values (real numbers).</p>
</li>
<li>
<p><strong>sample_weight : array-like of shape (n_samples,), default=None</strong>
    Sample weights. If None, the sample weights are initialized to
    1 / n_samples.</p>
</li>
</ul>
<h4>Returns</h4>
<ul>
<li><strong>self : object</strong></li>
</ul>
</details>
<h3 id="get_params_1">get_params<a class="headerlink" href="#get_params_1" title="Permanent link">&para;</a></h3>
<details class="note" open="open"><summary>method get_params</summary><div class="highlight"><pre><span></span><code><span class="k">val</span> <span class="n">get_params</span> <span class="o">:</span>
  <span class="o">?</span><span class="n">deep</span><span class="o">:</span><span class="kt">bool</span> <span class="o">-&gt;</span>
  <span class="o">[&gt;</span> <span class="n">tag</span><span class="o">]</span> <span class="nn">Obj</span><span class="p">.</span><span class="n">t</span> <span class="o">-&gt;</span>
  <span class="nn">Dict</span><span class="p">.</span><span class="n">t</span>
</code></pre></div>

<p>Get parameters for this estimator.</p>
<h4>Parameters</h4>
<ul>
<li><strong>deep : bool, default=True</strong>
    If True, will return the parameters for this estimator and
    contained subobjects that are estimators.</li>
</ul>
<h4>Returns</h4>
<ul>
<li><strong>params : mapping of string to any</strong>
    Parameter names mapped to their values.</li>
</ul>
</details>
<h3 id="predict_1">predict<a class="headerlink" href="#predict_1" title="Permanent link">&para;</a></h3>
<details class="note" open="open"><summary>method predict</summary><div class="highlight"><pre><span></span><code><span class="k">val</span> <span class="n">predict</span> <span class="o">:</span>
  <span class="n">x</span><span class="o">:[&gt;`</span><span class="nc">ArrayLike</span><span class="o">]</span> <span class="nn">Np</span><span class="p">.</span><span class="nn">Obj</span><span class="p">.</span><span class="n">t</span> <span class="o">-&gt;</span>
  <span class="o">[&gt;</span> <span class="n">tag</span><span class="o">]</span> <span class="nn">Obj</span><span class="p">.</span><span class="n">t</span> <span class="o">-&gt;</span>
  <span class="o">[&gt;`</span><span class="nc">ArrayLike</span><span class="o">]</span> <span class="nn">Np</span><span class="p">.</span><span class="nn">Obj</span><span class="p">.</span><span class="n">t</span>
</code></pre></div>

<p>Predict regression value for X.</p>
<p>The predicted regression value of an input sample is computed
as the weighted median prediction of the classifiers in the ensemble.</p>
<h4>Parameters</h4>
<ul>
<li><strong>X : {array-like, sparse matrix} of shape (n_samples, n_features)</strong>
    The training input samples. Sparse matrix can be CSC, CSR, COO,
    DOK, or LIL. COO, DOK, and LIL are converted to CSR.</li>
</ul>
<h4>Returns</h4>
<ul>
<li><strong>y : ndarray of shape (n_samples,)</strong>
    The predicted regression values.</li>
</ul>
</details>
<h3 id="score_1">score<a class="headerlink" href="#score_1" title="Permanent link">&para;</a></h3>
<details class="note" open="open"><summary>method score</summary><div class="highlight"><pre><span></span><code><span class="k">val</span> <span class="n">score</span> <span class="o">:</span>
  <span class="o">?</span><span class="n">sample_weight</span><span class="o">:[&gt;`</span><span class="nc">ArrayLike</span><span class="o">]</span> <span class="nn">Np</span><span class="p">.</span><span class="nn">Obj</span><span class="p">.</span><span class="n">t</span> <span class="o">-&gt;</span>
  <span class="n">x</span><span class="o">:[&gt;`</span><span class="nc">ArrayLike</span><span class="o">]</span> <span class="nn">Np</span><span class="p">.</span><span class="nn">Obj</span><span class="p">.</span><span class="n">t</span> <span class="o">-&gt;</span>
  <span class="n">y</span><span class="o">:[&gt;`</span><span class="nc">ArrayLike</span><span class="o">]</span> <span class="nn">Np</span><span class="p">.</span><span class="nn">Obj</span><span class="p">.</span><span class="n">t</span> <span class="o">-&gt;</span>
  <span class="o">[&gt;</span> <span class="n">tag</span><span class="o">]</span> <span class="nn">Obj</span><span class="p">.</span><span class="n">t</span> <span class="o">-&gt;</span>
  <span class="kt">float</span>
</code></pre></div>

<p>Return the coefficient of determination R^2 of the prediction.</p>
<p>The coefficient R^2 is defined as (1 - u/v), where u is the residual
sum of squares ((y_true - y_pred) <strong> 2).sum() and v is the total
sum of squares ((y_true - y_true.mean()) </strong> 2).sum().
The best possible score is 1.0 and it can be negative (because the
model can be arbitrarily worse). A constant model that always
predicts the expected value of y, disregarding the input features,
would get a R^2 score of 0.0.</p>
<h4>Parameters</h4>
<ul>
<li>
<p><strong>X : array-like of shape (n_samples, n_features)</strong>
    Test samples. For some estimators this may be a
    precomputed kernel matrix or a list of generic objects instead,
    shape = (n_samples, n_samples_fitted),
    where n_samples_fitted is the number of
    samples used in the fitting for the estimator.</p>
</li>
<li>
<p><strong>y : array-like of shape (n_samples,) or (n_samples, n_outputs)</strong>
    True values for X.</p>
</li>
<li>
<p><strong>sample_weight : array-like of shape (n_samples,), default=None</strong>
    Sample weights.</p>
</li>
</ul>
<h4>Returns</h4>
<ul>
<li><strong>score : float</strong>
    R^2 of self.predict(X) wrt. y.</li>
</ul>
<h4>Notes</h4>
<p>The R2 score used when calling <code>score</code> on a regressor uses
<code>multioutput='uniform_average'</code> from version 0.23 to keep consistent
with default value of :func:<code>~sklearn.metrics.r2_score</code>.
This influences the <code>score</code> method of all the multioutput
regressors (except for
:class:<code>~sklearn.multioutput.MultiOutputRegressor</code>).</p>
</details>
<h3 id="set_params_1">set_params<a class="headerlink" href="#set_params_1" title="Permanent link">&para;</a></h3>
<details class="note" open="open"><summary>method set_params</summary><div class="highlight"><pre><span></span><code><span class="k">val</span> <span class="n">set_params</span> <span class="o">:</span>
  <span class="o">?</span><span class="n">params</span><span class="o">:(</span><span class="kt">string</span> <span class="o">*</span> <span class="nn">Py</span><span class="p">.</span><span class="nn">Object</span><span class="p">.</span><span class="n">t</span><span class="o">)</span> <span class="kt">list</span> <span class="o">-&gt;</span>
  <span class="o">[&gt;</span> <span class="n">tag</span><span class="o">]</span> <span class="nn">Obj</span><span class="p">.</span><span class="n">t</span> <span class="o">-&gt;</span>
  <span class="n">t</span>
</code></pre></div>

<p>Set the parameters of this estimator.</p>
<p>The method works on simple estimators as well as on nested objects
(such as pipelines). The latter have parameters of the form
<code>&lt;component&gt;__&lt;parameter&gt;</code> so that it's possible to update each
component of a nested object.</p>
<h4>Parameters</h4>
<ul>
<li><strong>**params : dict</strong>
    Estimator parameters.</li>
</ul>
<h4>Returns</h4>
<ul>
<li><strong>self : object</strong>
    Estimator instance.</li>
</ul>
</details>
<h3 id="staged_predict_1">staged_predict<a class="headerlink" href="#staged_predict_1" title="Permanent link">&para;</a></h3>
<details class="note" open="open"><summary>method staged_predict</summary><div class="highlight"><pre><span></span><code><span class="k">val</span> <span class="n">staged_predict</span> <span class="o">:</span>
  <span class="n">x</span><span class="o">:[&gt;`</span><span class="nc">ArrayLike</span><span class="o">]</span> <span class="nn">Np</span><span class="p">.</span><span class="nn">Obj</span><span class="p">.</span><span class="n">t</span> <span class="o">-&gt;</span>
  <span class="o">[&gt;</span> <span class="n">tag</span><span class="o">]</span> <span class="nn">Obj</span><span class="p">.</span><span class="n">t</span> <span class="o">-&gt;</span>
  <span class="o">[&gt;`</span><span class="nc">ArrayLike</span><span class="o">]</span> <span class="nn">Np</span><span class="p">.</span><span class="nn">Obj</span><span class="p">.</span><span class="n">t</span> <span class="nn">Seq</span><span class="p">.</span><span class="n">t</span>
</code></pre></div>

<p>Return staged predictions for X.</p>
<p>The predicted regression value of an input sample is computed
as the weighted median prediction of the classifiers in the ensemble.</p>
<p>This generator method yields the ensemble prediction after each
iteration of boosting and therefore allows monitoring, such as to
determine the prediction on a test set after each boost.</p>
<h4>Parameters</h4>
<ul>
<li><strong>X : {array-like, sparse matrix} of shape (n_samples, n_features)</strong>
    The training input samples.</li>
</ul>
<h4>Yields</h4>
<ul>
<li><strong>y : generator of ndarray of shape (n_samples,)</strong>
    The predicted regression values.</li>
</ul>
</details>
<h3 id="staged_score_1">staged_score<a class="headerlink" href="#staged_score_1" title="Permanent link">&para;</a></h3>
<details class="note" open="open"><summary>method staged_score</summary><div class="highlight"><pre><span></span><code><span class="k">val</span> <span class="n">staged_score</span> <span class="o">:</span>
  <span class="o">?</span><span class="n">sample_weight</span><span class="o">:[&gt;`</span><span class="nc">ArrayLike</span><span class="o">]</span> <span class="nn">Np</span><span class="p">.</span><span class="nn">Obj</span><span class="p">.</span><span class="n">t</span> <span class="o">-&gt;</span>
  <span class="n">x</span><span class="o">:[&gt;`</span><span class="nc">ArrayLike</span><span class="o">]</span> <span class="nn">Np</span><span class="p">.</span><span class="nn">Obj</span><span class="p">.</span><span class="n">t</span> <span class="o">-&gt;</span>
  <span class="n">y</span><span class="o">:[&gt;`</span><span class="nc">ArrayLike</span><span class="o">]</span> <span class="nn">Np</span><span class="p">.</span><span class="nn">Obj</span><span class="p">.</span><span class="n">t</span> <span class="o">-&gt;</span>
  <span class="o">[&gt;</span> <span class="n">tag</span><span class="o">]</span> <span class="nn">Obj</span><span class="p">.</span><span class="n">t</span> <span class="o">-&gt;</span>
  <span class="nn">Py</span><span class="p">.</span><span class="nn">Object</span><span class="p">.</span><span class="n">t</span>
</code></pre></div>

<p>Return staged scores for X, y.</p>
<p>This generator method yields the ensemble score after each iteration of
boosting and therefore allows monitoring, such as to determine the
score on a test set after each boost.</p>
<h4>Parameters</h4>
<ul>
<li>
<p><strong>X : {array-like, sparse matrix} of shape (n_samples, n_features)</strong>
    The training input samples. Sparse matrix can be CSC, CSR, COO,
    DOK, or LIL. COO, DOK, and LIL are converted to CSR.</p>
</li>
<li>
<p><strong>y : array-like of shape (n_samples,)</strong>
    Labels for X.</p>
</li>
<li>
<p><strong>sample_weight : array-like of shape (n_samples,), default=None</strong>
    Sample weights.</p>
</li>
</ul>
<h4>Yields</h4>
<ul>
<li><strong>z : float</strong></li>
</ul>
</details>
<h3 id="base_estimator__1">base_estimator_<a class="headerlink" href="#base_estimator__1" title="Permanent link">&para;</a></h3>
<details class="note" open="open"><summary>attribute base_estimator_</summary><div class="highlight"><pre><span></span><code><span class="k">val</span> <span class="n">base_estimator_</span> <span class="o">:</span> <span class="n">t</span> <span class="o">-&gt;</span> <span class="o">[`</span><span class="nc">BaseEstimator</span><span class="o">|`</span><span class="nc">Object</span><span class="o">]</span> <span class="nn">Np</span><span class="p">.</span><span class="nn">Obj</span><span class="p">.</span><span class="n">t</span>
<span class="k">val</span> <span class="n">base_estimator_opt</span> <span class="o">:</span> <span class="n">t</span> <span class="o">-&gt;</span> <span class="o">([`</span><span class="nc">BaseEstimator</span><span class="o">|`</span><span class="nc">Object</span><span class="o">]</span> <span class="nn">Np</span><span class="p">.</span><span class="nn">Obj</span><span class="p">.</span><span class="n">t</span><span class="o">)</span> <span class="n">option</span>
</code></pre></div>

<p>This attribute is documented in <code>create</code> above. The first version raises Not_found
if the attribute is None. The _opt version returns an option.</p>
</details>
<h3 id="estimators__1">estimators_<a class="headerlink" href="#estimators__1" title="Permanent link">&para;</a></h3>
<details class="note" open="open"><summary>attribute estimators_</summary><div class="highlight"><pre><span></span><code><span class="k">val</span> <span class="n">estimators_</span> <span class="o">:</span> <span class="n">t</span> <span class="o">-&gt;</span> <span class="nn">Py</span><span class="p">.</span><span class="nn">Object</span><span class="p">.</span><span class="n">t</span>
<span class="k">val</span> <span class="n">estimators_opt</span> <span class="o">:</span> <span class="n">t</span> <span class="o">-&gt;</span> <span class="o">(</span><span class="nn">Py</span><span class="p">.</span><span class="nn">Object</span><span class="p">.</span><span class="n">t</span><span class="o">)</span> <span class="n">option</span>
</code></pre></div>

<p>This attribute is documented in <code>create</code> above. The first version raises Not_found
if the attribute is None. The _opt version returns an option.</p>
</details>
<h3 id="estimator_weights__1">estimator_weights_<a class="headerlink" href="#estimator_weights__1" title="Permanent link">&para;</a></h3>
<details class="note" open="open"><summary>attribute estimator_weights_</summary><div class="highlight"><pre><span></span><code><span class="k">val</span> <span class="n">estimator_weights_</span> <span class="o">:</span> <span class="n">t</span> <span class="o">-&gt;</span> <span class="o">[&gt;`</span><span class="nc">ArrayLike</span><span class="o">]</span> <span class="nn">Np</span><span class="p">.</span><span class="nn">Obj</span><span class="p">.</span><span class="n">t</span>
<span class="k">val</span> <span class="n">estimator_weights_opt</span> <span class="o">:</span> <span class="n">t</span> <span class="o">-&gt;</span> <span class="o">([&gt;`</span><span class="nc">ArrayLike</span><span class="o">]</span> <span class="nn">Np</span><span class="p">.</span><span class="nn">Obj</span><span class="p">.</span><span class="n">t</span><span class="o">)</span> <span class="n">option</span>
</code></pre></div>

<p>This attribute is documented in <code>create</code> above. The first version raises Not_found
if the attribute is None. The _opt version returns an option.</p>
</details>
<h3 id="estimator_errors__1">estimator_errors_<a class="headerlink" href="#estimator_errors__1" title="Permanent link">&para;</a></h3>
<details class="note" open="open"><summary>attribute estimator_errors_</summary><div class="highlight"><pre><span></span><code><span class="k">val</span> <span class="n">estimator_errors_</span> <span class="o">:</span> <span class="n">t</span> <span class="o">-&gt;</span> <span class="o">[&gt;`</span><span class="nc">ArrayLike</span><span class="o">]</span> <span class="nn">Np</span><span class="p">.</span><span class="nn">Obj</span><span class="p">.</span><span class="n">t</span>
<span class="k">val</span> <span class="n">estimator_errors_opt</span> <span class="o">:</span> <span class="n">t</span> <span class="o">-&gt;</span> <span class="o">([&gt;`</span><span class="nc">ArrayLike</span><span class="o">]</span> <span class="nn">Np</span><span class="p">.</span><span class="nn">Obj</span><span class="p">.</span><span class="n">t</span><span class="o">)</span> <span class="n">option</span>
</code></pre></div>

<p>This attribute is documented in <code>create</code> above. The first version raises Not_found
if the attribute is None. The _opt version returns an option.</p>
</details>
<h3 id="feature_importances__1">feature_importances_<a class="headerlink" href="#feature_importances__1" title="Permanent link">&para;</a></h3>
<details class="note" open="open"><summary>attribute feature_importances_</summary><div class="highlight"><pre><span></span><code><span class="k">val</span> <span class="n">feature_importances_</span> <span class="o">:</span> <span class="n">t</span> <span class="o">-&gt;</span> <span class="o">[&gt;`</span><span class="nc">ArrayLike</span><span class="o">]</span> <span class="nn">Np</span><span class="p">.</span><span class="nn">Obj</span><span class="p">.</span><span class="n">t</span>
<span class="k">val</span> <span class="n">feature_importances_opt</span> <span class="o">:</span> <span class="n">t</span> <span class="o">-&gt;</span> <span class="o">([&gt;`</span><span class="nc">ArrayLike</span><span class="o">]</span> <span class="nn">Np</span><span class="p">.</span><span class="nn">Obj</span><span class="p">.</span><span class="n">t</span><span class="o">)</span> <span class="n">option</span>
</code></pre></div>

<p>This attribute is documented in <code>create</code> above. The first version raises Not_found
if the attribute is None. The _opt version returns an option.</p>
</details>
<h3 id="warning_1">warning<a class="headerlink" href="#warning_1" title="Permanent link">&para;</a></h3>
<details class="note" open="open"><summary>attribute warning</summary><div class="highlight"><pre><span></span><code><span class="k">val</span> <span class="n">warning</span> <span class="o">:</span> <span class="n">t</span> <span class="o">-&gt;</span> <span class="nn">Py</span><span class="p">.</span><span class="nn">Object</span><span class="p">.</span><span class="n">t</span>
<span class="k">val</span> <span class="n">warning_opt</span> <span class="o">:</span> <span class="n">t</span> <span class="o">-&gt;</span> <span class="o">(</span><span class="nn">Py</span><span class="p">.</span><span class="nn">Object</span><span class="p">.</span><span class="n">t</span><span class="o">)</span> <span class="n">option</span>
</code></pre></div>

<p>This attribute is documented in <code>create</code> above. The first version raises Not_found
if the attribute is None. The _opt version returns an option.</p>
</details>
<h3 id="to_string_1">to_string<a class="headerlink" href="#to_string_1" title="Permanent link">&para;</a></h3>
<details class="note" open="open"><summary>method to_string</summary><div class="highlight"><pre><span></span><code><span class="k">val</span> <span class="n">to_string</span><span class="o">:</span> <span class="n">t</span> <span class="o">-&gt;</span> <span class="kt">string</span>
</code></pre></div>

<p>Print the object to a human-readable representation.</p>
</details>
<h3 id="show_1">show<a class="headerlink" href="#show_1" title="Permanent link">&para;</a></h3>
<details class="note" open="open"><summary>method show</summary><div class="highlight"><pre><span></span><code><span class="k">val</span> <span class="n">show</span><span class="o">:</span> <span class="n">t</span> <span class="o">-&gt;</span> <span class="kt">string</span>
</code></pre></div>

<p>Print the object to a human-readable representation.</p>
</details>
<h3 id="pp_1">pp<a class="headerlink" href="#pp_1" title="Permanent link">&para;</a></h3>
<details class="note" open="open"><summary>method pp</summary><div class="highlight"><pre><span></span><code><span class="k">val</span> <span class="n">pp</span><span class="o">:</span> <span class="nn">Format</span><span class="p">.</span><span class="n">formatter</span> <span class="o">-&gt;</span> <span class="n">t</span> <span class="o">-&gt;</span> <span class="kt">unit</span>
</code></pre></div>

<p>Pretty-print the object to a formatter.</p>
</details>
<h2 id="baggingclassifier">BaggingClassifier<a class="headerlink" href="#baggingclassifier" title="Permanent link">&para;</a></h2>
<p>Module <code>Sklearn.​Ensemble.​BaggingClassifier</code> wraps Python class <a href="https://scikit-learn.org/stable/modules/generated/sklearn.ensemble.BaggingClassifier.html"><code>sklearn.ensemble.BaggingClassifier</code></a>.</p>
<div class="highlight"><pre><span></span><code><span class="k">type</span> <span class="n">t</span>
</code></pre></div>

<h3 id="create_2">create<a class="headerlink" href="#create_2" title="Permanent link">&para;</a></h3>
<details class="note" open="open"><summary>constructor and attributes create</summary><div class="highlight"><pre><span></span><code><span class="k">val</span> <span class="n">create</span> <span class="o">:</span>
  <span class="o">?</span><span class="n">base_estimator</span><span class="o">:[&gt;`</span><span class="nc">BaseEstimator</span><span class="o">]</span> <span class="nn">Np</span><span class="p">.</span><span class="nn">Obj</span><span class="p">.</span><span class="n">t</span> <span class="o">-&gt;</span>
  <span class="o">?</span><span class="n">n_estimators</span><span class="o">:</span><span class="kt">int</span> <span class="o">-&gt;</span>
  <span class="o">?</span><span class="n">max_samples</span><span class="o">:[`</span><span class="nc">F</span> <span class="k">of</span> <span class="kt">float</span> <span class="o">|</span> <span class="o">`</span><span class="nc">I</span> <span class="k">of</span> <span class="kt">int</span><span class="o">]</span> <span class="o">-&gt;</span>
  <span class="o">?</span><span class="n">max_features</span><span class="o">:[`</span><span class="nc">F</span> <span class="k">of</span> <span class="kt">float</span> <span class="o">|</span> <span class="o">`</span><span class="nc">I</span> <span class="k">of</span> <span class="kt">int</span><span class="o">]</span> <span class="o">-&gt;</span>
  <span class="o">?</span><span class="n">bootstrap</span><span class="o">:</span><span class="kt">bool</span> <span class="o">-&gt;</span>
  <span class="o">?</span><span class="n">bootstrap_features</span><span class="o">:</span><span class="kt">bool</span> <span class="o">-&gt;</span>
  <span class="o">?</span><span class="n">oob_score</span><span class="o">:</span><span class="kt">bool</span> <span class="o">-&gt;</span>
  <span class="o">?</span><span class="n">warm_start</span><span class="o">:</span><span class="kt">bool</span> <span class="o">-&gt;</span>
  <span class="o">?</span><span class="n">n_jobs</span><span class="o">:</span><span class="kt">int</span> <span class="o">-&gt;</span>
  <span class="o">?</span><span class="n">random_state</span><span class="o">:</span><span class="kt">int</span> <span class="o">-&gt;</span>
  <span class="o">?</span><span class="n">verbose</span><span class="o">:</span><span class="kt">int</span> <span class="o">-&gt;</span>
  <span class="kt">unit</span> <span class="o">-&gt;</span>
  <span class="n">t</span>
</code></pre></div>

<p>A Bagging classifier.</p>
<p>A Bagging classifier is an ensemble meta-estimator that fits base
classifiers each on random subsets of the original dataset and then
aggregate their individual predictions (either by voting or by averaging)
to form a final prediction. Such a meta-estimator can typically be used as
a way to reduce the variance of a black-box estimator (e.g., a decision
tree), by introducing randomization into its construction procedure and
then making an ensemble out of it.</p>
<p>This algorithm encompasses several works from the literature. When random
subsets of the dataset are drawn as random subsets of the samples, then
this algorithm is known as Pasting [1]<em>. If samples are drawn with
replacement, then the method is known as Bagging [2]</em>. When random subsets
of the dataset are drawn as random subsets of the features, then the method
is known as Random Subspaces [3]<em>. Finally, when base estimators are built
on subsets of both samples and features, then the method is known as
Random Patches [4]</em>.</p>
<p>Read more in the :ref:<code>User Guide &lt;bagging&gt;</code>.</p>
<p>.. versionadded:: 0.15</p>
<h4>Parameters</h4>
<ul>
<li>
<p><strong>base_estimator : object, default=None</strong>
    The base estimator to fit on random subsets of the dataset.
    If None, then the base estimator is a decision tree.</p>
</li>
<li>
<p><strong>n_estimators : int, default=10</strong>
    The number of base estimators in the ensemble.</p>
</li>
<li>
<p><strong>max_samples : int or float, default=1.0</strong>
    The number of samples to draw from X to train each base estimator (with
    replacement by default, see <code>bootstrap</code> for more details).</p>
<ul>
<li>If int, then draw <code>max_samples</code> samples.</li>
<li>If float, then draw <code>max_samples * X.shape[0]</code> samples.</li>
</ul>
</li>
<li>
<p><strong>max_features : int or float, default=1.0</strong>
    The number of features to draw from X to train each base estimator (
    without replacement by default, see <code>bootstrap_features</code> for more
    details).</p>
<ul>
<li>If int, then draw <code>max_features</code> features.</li>
<li>If float, then draw <code>max_features * X.shape[1]</code> features.</li>
</ul>
</li>
<li>
<p><strong>bootstrap : bool, default=True</strong>
    Whether samples are drawn with replacement. If False, sampling
    without replacement is performed.</p>
</li>
<li>
<p><strong>bootstrap_features : bool, default=False</strong>
    Whether features are drawn with replacement.</p>
</li>
<li>
<p><strong>oob_score : bool, default=False</strong>
    Whether to use out-of-bag samples to estimate
    the generalization error.</p>
</li>
<li>
<p><strong>warm_start : bool, default=False</strong>
    When set to True, reuse the solution of the previous call to fit
    and add more estimators to the ensemble, otherwise, just fit
    a whole new ensemble. See :term:<code>the Glossary &lt;warm_start&gt;</code>.</p>
<p>.. versionadded:: 0.17
   <em>warm_start</em> constructor parameter.</p>
</li>
<li>
<p><strong>n_jobs : int, default=None</strong>
    The number of jobs to run in parallel for both :meth:<code>fit</code> and
    :meth:<code>predict</code>. <code>None</code> means 1 unless in a
    :obj:<code>joblib.parallel_backend</code> context. <code>-1</code> means using all
    processors. See :term:<code>Glossary &lt;n_jobs&gt;</code> for more details.</p>
</li>
<li>
<p><strong>random_state : int or RandomState, default=None</strong>
    Controls the random resampling of the original dataset
    (sample wise and feature wise).
    If the base estimator accepts a <code>random_state</code> attribute, a different
    seed is generated for each instance in the ensemble.
    Pass an int for reproducible output across multiple function calls.</p>
</li>
<li>
<p><strong>See :term:<code>Glossary &lt;random_state&gt;</code>.</strong></p>
</li>
<li>
<p><strong>verbose : int, default=0</strong>
    Controls the verbosity when fitting and predicting.</p>
</li>
</ul>
<h4>Attributes</h4>
<ul>
<li>
<p><strong>base_estimator_ : estimator</strong>
    The base estimator from which the ensemble is grown.</p>
</li>
<li>
<p><strong>n_features_ : int</strong>
    The number of features when :meth:<code>fit</code> is performed.</p>
</li>
<li>
<p><strong>estimators_ : list of estimators</strong>
    The collection of fitted base estimators.</p>
</li>
<li>
<p><strong>estimators_samples_ : list of arrays</strong>
    The subset of drawn samples (i.e., the in-bag samples) for each base
    estimator. Each subset is defined by an array of the indices selected.</p>
</li>
<li>
<p><strong>estimators_features_ : list of arrays</strong>
    The subset of drawn features for each base estimator.</p>
</li>
<li>
<p><strong>classes_ : ndarray of shape (n_classes,)</strong>
    The classes labels.</p>
</li>
<li>
<p><strong>n_classes_ : int or list</strong>
    The number of classes.</p>
</li>
<li>
<p><strong>oob_score_ : float</strong>
    Score of the training dataset obtained using an out-of-bag estimate.
    This attribute exists only when <code>oob_score</code> is True.</p>
</li>
<li>
<p><strong>oob_decision_function_ : ndarray of shape (n_samples, n_classes)</strong>
    Decision function computed with out-of-bag estimate on the training
    set. If n_estimators is small it might be possible that a data point
    was never left out during the bootstrap. In this case,
    <code>oob_decision_function_</code> might contain NaN. This attribute exists
    only when <code>oob_score</code> is True.</p>
</li>
</ul>
<h4>Examples</h4>
<div class="highlight"><pre><span></span><code><span class="o">&gt;&gt;&gt;</span> <span class="kn">from</span> <span class="nn">sklearn.svm</span> <span class="kn">import</span> <span class="n">SVC</span>
<span class="o">&gt;&gt;&gt;</span> <span class="kn">from</span> <span class="nn">sklearn.ensemble</span> <span class="kn">import</span> <span class="n">BaggingClassifier</span>
<span class="o">&gt;&gt;&gt;</span> <span class="kn">from</span> <span class="nn">sklearn.datasets</span> <span class="kn">import</span> <span class="n">make_classification</span>
<span class="o">&gt;&gt;&gt;</span> <span class="n">X</span><span class="p">,</span> <span class="n">y</span> <span class="o">=</span> <span class="n">make_classification</span><span class="p">(</span><span class="n">n_samples</span><span class="o">=</span><span class="mi">100</span><span class="p">,</span> <span class="n">n_features</span><span class="o">=</span><span class="mi">4</span><span class="p">,</span>
<span class="o">...</span>                            <span class="n">n_informative</span><span class="o">=</span><span class="mi">2</span><span class="p">,</span> <span class="n">n_redundant</span><span class="o">=</span><span class="mi">0</span><span class="p">,</span>
<span class="o">...</span>                            <span class="n">random_state</span><span class="o">=</span><span class="mi">0</span><span class="p">,</span> <span class="n">shuffle</span><span class="o">=</span><span class="kc">False</span><span class="p">)</span>
<span class="o">&gt;&gt;&gt;</span> <span class="n">clf</span> <span class="o">=</span> <span class="n">BaggingClassifier</span><span class="p">(</span><span class="n">base_estimator</span><span class="o">=</span><span class="n">SVC</span><span class="p">(),</span>
<span class="o">...</span>                         <span class="n">n_estimators</span><span class="o">=</span><span class="mi">10</span><span class="p">,</span> <span class="n">random_state</span><span class="o">=</span><span class="mi">0</span><span class="p">)</span><span class="o">.</span><span class="n">fit</span><span class="p">(</span><span class="n">X</span><span class="p">,</span> <span class="n">y</span><span class="p">)</span>
<span class="o">&gt;&gt;&gt;</span> <span class="n">clf</span><span class="o">.</span><span class="n">predict</span><span class="p">([[</span><span class="mi">0</span><span class="p">,</span> <span class="mi">0</span><span class="p">,</span> <span class="mi">0</span><span class="p">,</span> <span class="mi">0</span><span class="p">]])</span>
<span class="n">array</span><span class="p">([</span><span class="mi">1</span><span class="p">])</span>
</code></pre></div>

<h4>References</h4>
<p>.. [1] L. Breiman, 'Pasting small votes for classification in large
       databases and on-line', Machine Learning, 36(1), 85-103, 1999.</p>
<p>.. [2] L. Breiman, 'Bagging predictors', Machine Learning, 24(2), 123-140,
       1996.</p>
<p>.. [3] T. Ho, 'The random subspace method for constructing decision
       forests', Pattern Analysis and Machine Intelligence, 20(8), 832-844,
       1998.</p>
<p>.. [4] G. Louppe and P. Geurts, 'Ensembles on Random Patches', Machine
       Learning and Knowledge Discovery in Databases, 346-361, 2012.</p>
</details>
<h3 id="get_item_2">get_item<a class="headerlink" href="#get_item_2" title="Permanent link">&para;</a></h3>
<details class="note" open="open"><summary>method get_item</summary><div class="highlight"><pre><span></span><code><span class="k">val</span> <span class="n">get_item</span> <span class="o">:</span>
  <span class="n">index</span><span class="o">:</span><span class="nn">Py</span><span class="p">.</span><span class="nn">Object</span><span class="p">.</span><span class="n">t</span> <span class="o">-&gt;</span>
  <span class="o">[&gt;</span> <span class="n">tag</span><span class="o">]</span> <span class="nn">Obj</span><span class="p">.</span><span class="n">t</span> <span class="o">-&gt;</span>
  <span class="nn">Py</span><span class="p">.</span><span class="nn">Object</span><span class="p">.</span><span class="n">t</span>
</code></pre></div>

<p>Return the index'th estimator in the ensemble.</p>
</details>
<h3 id="iter_2">iter<a class="headerlink" href="#iter_2" title="Permanent link">&para;</a></h3>
<details class="note" open="open"><summary>method iter</summary><div class="highlight"><pre><span></span><code><span class="k">val</span> <span class="n">iter</span> <span class="o">:</span>
  <span class="o">[&gt;</span> <span class="n">tag</span><span class="o">]</span> <span class="nn">Obj</span><span class="p">.</span><span class="n">t</span> <span class="o">-&gt;</span>
  <span class="nn">Dict</span><span class="p">.</span><span class="n">t</span> <span class="nn">Seq</span><span class="p">.</span><span class="n">t</span>
</code></pre></div>

<p>Return iterator over estimators in the ensemble.</p>
</details>
<h3 id="fit_2">fit<a class="headerlink" href="#fit_2" title="Permanent link">&para;</a></h3>
<details class="note" open="open"><summary>method fit</summary><div class="highlight"><pre><span></span><code><span class="k">val</span> <span class="n">fit</span> <span class="o">:</span>
  <span class="o">?</span><span class="n">sample_weight</span><span class="o">:[&gt;`</span><span class="nc">ArrayLike</span><span class="o">]</span> <span class="nn">Np</span><span class="p">.</span><span class="nn">Obj</span><span class="p">.</span><span class="n">t</span> <span class="o">-&gt;</span>
  <span class="n">x</span><span class="o">:[&gt;`</span><span class="nc">ArrayLike</span><span class="o">]</span> <span class="nn">Np</span><span class="p">.</span><span class="nn">Obj</span><span class="p">.</span><span class="n">t</span> <span class="o">-&gt;</span>
  <span class="n">y</span><span class="o">:[&gt;`</span><span class="nc">ArrayLike</span><span class="o">]</span> <span class="nn">Np</span><span class="p">.</span><span class="nn">Obj</span><span class="p">.</span><span class="n">t</span> <span class="o">-&gt;</span>
  <span class="o">[&gt;</span> <span class="n">tag</span><span class="o">]</span> <span class="nn">Obj</span><span class="p">.</span><span class="n">t</span> <span class="o">-&gt;</span>
  <span class="n">t</span>
</code></pre></div>

<p>Build a Bagging ensemble of estimators from the training
   set (X, y).</p>
<h4>Parameters</h4>
<ul>
<li>
<p><strong>X : {array-like, sparse matrix} of shape (n_samples, n_features)</strong>
    The training input samples. Sparse matrices are accepted only if
    they are supported by the base estimator.</p>
</li>
<li>
<p><strong>y : array-like of shape (n_samples,)</strong>
    The target values (class labels in classification, real numbers in
    regression).</p>
</li>
<li>
<p><strong>sample_weight : array-like of shape (n_samples,), default=None</strong>
    Sample weights. If None, then samples are equally weighted.
    Note that this is supported only if the base estimator supports
    sample weighting.</p>
</li>
</ul>
<h4>Returns</h4>
<ul>
<li><strong>self : object</strong></li>
</ul>
</details>
<h3 id="get_params_2">get_params<a class="headerlink" href="#get_params_2" title="Permanent link">&para;</a></h3>
<details class="note" open="open"><summary>method get_params</summary><div class="highlight"><pre><span></span><code><span class="k">val</span> <span class="n">get_params</span> <span class="o">:</span>
  <span class="o">?</span><span class="n">deep</span><span class="o">:</span><span class="kt">bool</span> <span class="o">-&gt;</span>
  <span class="o">[&gt;</span> <span class="n">tag</span><span class="o">]</span> <span class="nn">Obj</span><span class="p">.</span><span class="n">t</span> <span class="o">-&gt;</span>
  <span class="nn">Dict</span><span class="p">.</span><span class="n">t</span>
</code></pre></div>

<p>Get parameters for this estimator.</p>
<h4>Parameters</h4>
<ul>
<li><strong>deep : bool, default=True</strong>
    If True, will return the parameters for this estimator and
    contained subobjects that are estimators.</li>
</ul>
<h4>Returns</h4>
<ul>
<li><strong>params : mapping of string to any</strong>
    Parameter names mapped to their values.</li>
</ul>
</details>
<h3 id="predict_2">predict<a class="headerlink" href="#predict_2" title="Permanent link">&para;</a></h3>
<details class="note" open="open"><summary>method predict</summary><div class="highlight"><pre><span></span><code><span class="k">val</span> <span class="n">predict</span> <span class="o">:</span>
  <span class="n">x</span><span class="o">:[&gt;`</span><span class="nc">ArrayLike</span><span class="o">]</span> <span class="nn">Np</span><span class="p">.</span><span class="nn">Obj</span><span class="p">.</span><span class="n">t</span> <span class="o">-&gt;</span>
  <span class="o">[&gt;</span> <span class="n">tag</span><span class="o">]</span> <span class="nn">Obj</span><span class="p">.</span><span class="n">t</span> <span class="o">-&gt;</span>
  <span class="o">[&gt;`</span><span class="nc">ArrayLike</span><span class="o">]</span> <span class="nn">Np</span><span class="p">.</span><span class="nn">Obj</span><span class="p">.</span><span class="n">t</span>
</code></pre></div>

<p>Predict class for X.</p>
<p>The predicted class of an input sample is computed as the class with
the highest mean predicted probability. If base estimators do not
implement a <code>predict_proba</code> method, then it resorts to voting.</p>
<h4>Parameters</h4>
<ul>
<li><strong>X : {array-like, sparse matrix} of shape (n_samples, n_features)</strong>
    The training input samples. Sparse matrices are accepted only if
    they are supported by the base estimator.</li>
</ul>
<h4>Returns</h4>
<ul>
<li><strong>y : ndarray of shape (n_samples,)</strong>
    The predicted classes.</li>
</ul>
</details>
<h3 id="predict_log_proba_1">predict_log_proba<a class="headerlink" href="#predict_log_proba_1" title="Permanent link">&para;</a></h3>
<details class="note" open="open"><summary>method predict_log_proba</summary><div class="highlight"><pre><span></span><code><span class="k">val</span> <span class="n">predict_log_proba</span> <span class="o">:</span>
  <span class="n">x</span><span class="o">:[&gt;`</span><span class="nc">ArrayLike</span><span class="o">]</span> <span class="nn">Np</span><span class="p">.</span><span class="nn">Obj</span><span class="p">.</span><span class="n">t</span> <span class="o">-&gt;</span>
  <span class="o">[&gt;</span> <span class="n">tag</span><span class="o">]</span> <span class="nn">Obj</span><span class="p">.</span><span class="n">t</span> <span class="o">-&gt;</span>
  <span class="o">[&gt;`</span><span class="nc">ArrayLike</span><span class="o">]</span> <span class="nn">Np</span><span class="p">.</span><span class="nn">Obj</span><span class="p">.</span><span class="n">t</span>
</code></pre></div>

<p>Predict class log-probabilities for X.</p>
<p>The predicted class log-probabilities of an input sample is computed as
the log of the mean predicted class probabilities of the base
estimators in the ensemble.</p>
<h4>Parameters</h4>
<ul>
<li><strong>X : {array-like, sparse matrix} of shape (n_samples, n_features)</strong>
    The training input samples. Sparse matrices are accepted only if
    they are supported by the base estimator.</li>
</ul>
<h4>Returns</h4>
<ul>
<li><strong>p : ndarray of shape (n_samples, n_classes)</strong>
    The class log-probabilities of the input samples. The order of the
    classes corresponds to that in the attribute :term:<code>classes_</code>.</li>
</ul>
</details>
<h3 id="predict_proba_1">predict_proba<a class="headerlink" href="#predict_proba_1" title="Permanent link">&para;</a></h3>
<details class="note" open="open"><summary>method predict_proba</summary><div class="highlight"><pre><span></span><code><span class="k">val</span> <span class="n">predict_proba</span> <span class="o">:</span>
  <span class="n">x</span><span class="o">:[&gt;`</span><span class="nc">ArrayLike</span><span class="o">]</span> <span class="nn">Np</span><span class="p">.</span><span class="nn">Obj</span><span class="p">.</span><span class="n">t</span> <span class="o">-&gt;</span>
  <span class="o">[&gt;</span> <span class="n">tag</span><span class="o">]</span> <span class="nn">Obj</span><span class="p">.</span><span class="n">t</span> <span class="o">-&gt;</span>
  <span class="o">[&gt;`</span><span class="nc">ArrayLike</span><span class="o">]</span> <span class="nn">Np</span><span class="p">.</span><span class="nn">Obj</span><span class="p">.</span><span class="n">t</span>
</code></pre></div>

<p>Predict class probabilities for X.</p>
<p>The predicted class probabilities of an input sample is computed as
the mean predicted class probabilities of the base estimators in the
ensemble. If base estimators do not implement a <code>predict_proba</code>
method, then it resorts to voting and the predicted class probabilities
of an input sample represents the proportion of estimators predicting
each class.</p>
<h4>Parameters</h4>
<ul>
<li><strong>X : {array-like, sparse matrix} of shape (n_samples, n_features)</strong>
    The training input samples. Sparse matrices are accepted only if
    they are supported by the base estimator.</li>
</ul>
<h4>Returns</h4>
<ul>
<li><strong>p : ndarray of shape (n_samples, n_classes)</strong>
    The class probabilities of the input samples. The order of the
    classes corresponds to that in the attribute :term:<code>classes_</code>.</li>
</ul>
</details>
<h3 id="score_2">score<a class="headerlink" href="#score_2" title="Permanent link">&para;</a></h3>
<details class="note" open="open"><summary>method score</summary><div class="highlight"><pre><span></span><code><span class="k">val</span> <span class="n">score</span> <span class="o">:</span>
  <span class="o">?</span><span class="n">sample_weight</span><span class="o">:[&gt;`</span><span class="nc">ArrayLike</span><span class="o">]</span> <span class="nn">Np</span><span class="p">.</span><span class="nn">Obj</span><span class="p">.</span><span class="n">t</span> <span class="o">-&gt;</span>
  <span class="n">x</span><span class="o">:[&gt;`</span><span class="nc">ArrayLike</span><span class="o">]</span> <span class="nn">Np</span><span class="p">.</span><span class="nn">Obj</span><span class="p">.</span><span class="n">t</span> <span class="o">-&gt;</span>
  <span class="n">y</span><span class="o">:[&gt;`</span><span class="nc">ArrayLike</span><span class="o">]</span> <span class="nn">Np</span><span class="p">.</span><span class="nn">Obj</span><span class="p">.</span><span class="n">t</span> <span class="o">-&gt;</span>
  <span class="o">[&gt;</span> <span class="n">tag</span><span class="o">]</span> <span class="nn">Obj</span><span class="p">.</span><span class="n">t</span> <span class="o">-&gt;</span>
  <span class="kt">float</span>
</code></pre></div>

<p>Return the mean accuracy on the given test data and labels.</p>
<p>In multi-label classification, this is the subset accuracy
which is a harsh metric since you require for each sample that
each label set be correctly predicted.</p>
<h4>Parameters</h4>
<ul>
<li>
<p><strong>X : array-like of shape (n_samples, n_features)</strong>
    Test samples.</p>
</li>
<li>
<p><strong>y : array-like of shape (n_samples,) or (n_samples, n_outputs)</strong>
    True labels for X.</p>
</li>
<li>
<p><strong>sample_weight : array-like of shape (n_samples,), default=None</strong>
    Sample weights.</p>
</li>
</ul>
<h4>Returns</h4>
<ul>
<li><strong>score : float</strong>
    Mean accuracy of self.predict(X) wrt. y.</li>
</ul>
</details>
<h3 id="set_params_2">set_params<a class="headerlink" href="#set_params_2" title="Permanent link">&para;</a></h3>
<details class="note" open="open"><summary>method set_params</summary><div class="highlight"><pre><span></span><code><span class="k">val</span> <span class="n">set_params</span> <span class="o">:</span>
  <span class="o">?</span><span class="n">params</span><span class="o">:(</span><span class="kt">string</span> <span class="o">*</span> <span class="nn">Py</span><span class="p">.</span><span class="nn">Object</span><span class="p">.</span><span class="n">t</span><span class="o">)</span> <span class="kt">list</span> <span class="o">-&gt;</span>
  <span class="o">[&gt;</span> <span class="n">tag</span><span class="o">]</span> <span class="nn">Obj</span><span class="p">.</span><span class="n">t</span> <span class="o">-&gt;</span>
  <span class="n">t</span>
</code></pre></div>

<p>Set the parameters of this estimator.</p>
<p>The method works on simple estimators as well as on nested objects
(such as pipelines). The latter have parameters of the form
<code>&lt;component&gt;__&lt;parameter&gt;</code> so that it's possible to update each
component of a nested object.</p>
<h4>Parameters</h4>
<ul>
<li><strong>**params : dict</strong>
    Estimator parameters.</li>
</ul>
<h4>Returns</h4>
<ul>
<li><strong>self : object</strong>
    Estimator instance.</li>
</ul>
</details>
<h3 id="base_estimator__2">base_estimator_<a class="headerlink" href="#base_estimator__2" title="Permanent link">&para;</a></h3>
<details class="note" open="open"><summary>attribute base_estimator_</summary><div class="highlight"><pre><span></span><code><span class="k">val</span> <span class="n">base_estimator_</span> <span class="o">:</span> <span class="n">t</span> <span class="o">-&gt;</span> <span class="o">[`</span><span class="nc">BaseEstimator</span><span class="o">|`</span><span class="nc">Object</span><span class="o">]</span> <span class="nn">Np</span><span class="p">.</span><span class="nn">Obj</span><span class="p">.</span><span class="n">t</span>
<span class="k">val</span> <span class="n">base_estimator_opt</span> <span class="o">:</span> <span class="n">t</span> <span class="o">-&gt;</span> <span class="o">([`</span><span class="nc">BaseEstimator</span><span class="o">|`</span><span class="nc">Object</span><span class="o">]</span> <span class="nn">Np</span><span class="p">.</span><span class="nn">Obj</span><span class="p">.</span><span class="n">t</span><span class="o">)</span> <span class="n">option</span>
</code></pre></div>

<p>This attribute is documented in <code>create</code> above. The first version raises Not_found
if the attribute is None. The _opt version returns an option.</p>
</details>
<h3 id="n_features_">n_features_<a class="headerlink" href="#n_features_" title="Permanent link">&para;</a></h3>
<details class="note" open="open"><summary>attribute n_features_</summary><div class="highlight"><pre><span></span><code><span class="k">val</span> <span class="n">n_features_</span> <span class="o">:</span> <span class="n">t</span> <span class="o">-&gt;</span> <span class="kt">int</span>
<span class="k">val</span> <span class="n">n_features_opt</span> <span class="o">:</span> <span class="n">t</span> <span class="o">-&gt;</span> <span class="o">(</span><span class="kt">int</span><span class="o">)</span> <span class="n">option</span>
</code></pre></div>

<p>This attribute is documented in <code>create</code> above. The first version raises Not_found
if the attribute is None. The _opt version returns an option.</p>
</details>
<h3 id="estimators__2">estimators_<a class="headerlink" href="#estimators__2" title="Permanent link">&para;</a></h3>
<details class="note" open="open"><summary>attribute estimators_</summary><div class="highlight"><pre><span></span><code><span class="k">val</span> <span class="n">estimators_</span> <span class="o">:</span> <span class="n">t</span> <span class="o">-&gt;</span> <span class="o">[`</span><span class="nc">BaseEstimator</span><span class="o">|`</span><span class="nc">Object</span><span class="o">]</span> <span class="nn">Np</span><span class="p">.</span><span class="nn">Obj</span><span class="p">.</span><span class="n">t</span> <span class="kt">list</span>
<span class="k">val</span> <span class="n">estimators_opt</span> <span class="o">:</span> <span class="n">t</span> <span class="o">-&gt;</span> <span class="o">([`</span><span class="nc">BaseEstimator</span><span class="o">|`</span><span class="nc">Object</span><span class="o">]</span> <span class="nn">Np</span><span class="p">.</span><span class="nn">Obj</span><span class="p">.</span><span class="n">t</span> <span class="kt">list</span><span class="o">)</span> <span class="n">option</span>
</code></pre></div>

<p>This attribute is documented in <code>create</code> above. The first version raises Not_found
if the attribute is None. The _opt version returns an option.</p>
</details>
<h3 id="estimators_samples_">estimators_samples_<a class="headerlink" href="#estimators_samples_" title="Permanent link">&para;</a></h3>
<details class="note" open="open"><summary>attribute estimators_samples_</summary><div class="highlight"><pre><span></span><code><span class="k">val</span> <span class="n">estimators_samples_</span> <span class="o">:</span> <span class="n">t</span> <span class="o">-&gt;</span> <span class="nn">Np</span><span class="p">.</span><span class="nn">Numpy</span><span class="p">.</span><span class="nn">Ndarray</span><span class="p">.</span><span class="nn">List</span><span class="p">.</span><span class="n">t</span>
<span class="k">val</span> <span class="n">estimators_samples_opt</span> <span class="o">:</span> <span class="n">t</span> <span class="o">-&gt;</span> <span class="o">(</span><span class="nn">Np</span><span class="p">.</span><span class="nn">Numpy</span><span class="p">.</span><span class="nn">Ndarray</span><span class="p">.</span><span class="nn">List</span><span class="p">.</span><span class="n">t</span><span class="o">)</span> <span class="n">option</span>
</code></pre></div>

<p>This attribute is documented in <code>create</code> above. The first version raises Not_found
if the attribute is None. The _opt version returns an option.</p>
</details>
<h3 id="estimators_features_">estimators_features_<a class="headerlink" href="#estimators_features_" title="Permanent link">&para;</a></h3>
<details class="note" open="open"><summary>attribute estimators_features_</summary><div class="highlight"><pre><span></span><code><span class="k">val</span> <span class="n">estimators_features_</span> <span class="o">:</span> <span class="n">t</span> <span class="o">-&gt;</span> <span class="nn">Np</span><span class="p">.</span><span class="nn">Numpy</span><span class="p">.</span><span class="nn">Ndarray</span><span class="p">.</span><span class="nn">List</span><span class="p">.</span><span class="n">t</span>
<span class="k">val</span> <span class="n">estimators_features_opt</span> <span class="o">:</span> <span class="n">t</span> <span class="o">-&gt;</span> <span class="o">(</span><span class="nn">Np</span><span class="p">.</span><span class="nn">Numpy</span><span class="p">.</span><span class="nn">Ndarray</span><span class="p">.</span><span class="nn">List</span><span class="p">.</span><span class="n">t</span><span class="o">)</span> <span class="n">option</span>
</code></pre></div>

<p>This attribute is documented in <code>create</code> above. The first version raises Not_found
if the attribute is None. The _opt version returns an option.</p>
</details>
<h3 id="classes__1">classes_<a class="headerlink" href="#classes__1" title="Permanent link">&para;</a></h3>
<details class="note" open="open"><summary>attribute classes_</summary><div class="highlight"><pre><span></span><code><span class="k">val</span> <span class="n">classes_</span> <span class="o">:</span> <span class="n">t</span> <span class="o">-&gt;</span> <span class="o">[&gt;`</span><span class="nc">ArrayLike</span><span class="o">]</span> <span class="nn">Np</span><span class="p">.</span><span class="nn">Obj</span><span class="p">.</span><span class="n">t</span>
<span class="k">val</span> <span class="n">classes_opt</span> <span class="o">:</span> <span class="n">t</span> <span class="o">-&gt;</span> <span class="o">([&gt;`</span><span class="nc">ArrayLike</span><span class="o">]</span> <span class="nn">Np</span><span class="p">.</span><span class="nn">Obj</span><span class="p">.</span><span class="n">t</span><span class="o">)</span> <span class="n">option</span>
</code></pre></div>

<p>This attribute is documented in <code>create</code> above. The first version raises Not_found
if the attribute is None. The _opt version returns an option.</p>
</details>
<h3 id="n_classes__1">n_classes_<a class="headerlink" href="#n_classes__1" title="Permanent link">&para;</a></h3>
<details class="note" open="open"><summary>attribute n_classes_</summary><div class="highlight"><pre><span></span><code><span class="k">val</span> <span class="n">n_classes_</span> <span class="o">:</span> <span class="n">t</span> <span class="o">-&gt;</span> <span class="nn">Py</span><span class="p">.</span><span class="nn">Object</span><span class="p">.</span><span class="n">t</span>
<span class="k">val</span> <span class="n">n_classes_opt</span> <span class="o">:</span> <span class="n">t</span> <span class="o">-&gt;</span> <span class="o">(</span><span class="nn">Py</span><span class="p">.</span><span class="nn">Object</span><span class="p">.</span><span class="n">t</span><span class="o">)</span> <span class="n">option</span>
</code></pre></div>

<p>This attribute is documented in <code>create</code> above. The first version raises Not_found
if the attribute is None. The _opt version returns an option.</p>
</details>
<h3 id="oob_score_">oob_score_<a class="headerlink" href="#oob_score_" title="Permanent link">&para;</a></h3>
<details class="note" open="open"><summary>attribute oob_score_</summary><div class="highlight"><pre><span></span><code><span class="k">val</span> <span class="n">oob_score_</span> <span class="o">:</span> <span class="n">t</span> <span class="o">-&gt;</span> <span class="kt">float</span>
<span class="k">val</span> <span class="n">oob_score_opt</span> <span class="o">:</span> <span class="n">t</span> <span class="o">-&gt;</span> <span class="o">(</span><span class="kt">float</span><span class="o">)</span> <span class="n">option</span>
</code></pre></div>

<p>This attribute is documented in <code>create</code> above. The first version raises Not_found
if the attribute is None. The _opt version returns an option.</p>
</details>
<h3 id="oob_decision_function_">oob_decision_function_<a class="headerlink" href="#oob_decision_function_" title="Permanent link">&para;</a></h3>
<details class="note" open="open"><summary>attribute oob_decision_function_</summary><div class="highlight"><pre><span></span><code><span class="k">val</span> <span class="n">oob_decision_function_</span> <span class="o">:</span> <span class="n">t</span> <span class="o">-&gt;</span> <span class="o">[&gt;`</span><span class="nc">ArrayLike</span><span class="o">]</span> <span class="nn">Np</span><span class="p">.</span><span class="nn">Obj</span><span class="p">.</span><span class="n">t</span>
<span class="k">val</span> <span class="n">oob_decision_function_opt</span> <span class="o">:</span> <span class="n">t</span> <span class="o">-&gt;</span> <span class="o">([&gt;`</span><span class="nc">ArrayLike</span><span class="o">]</span> <span class="nn">Np</span><span class="p">.</span><span class="nn">Obj</span><span class="p">.</span><span class="n">t</span><span class="o">)</span> <span class="n">option</span>
</code></pre></div>

<p>This attribute is documented in <code>create</code> above. The first version raises Not_found
if the attribute is None. The _opt version returns an option.</p>
</details>
<h3 id="to_string_2">to_string<a class="headerlink" href="#to_string_2" title="Permanent link">&para;</a></h3>
<details class="note" open="open"><summary>method to_string</summary><div class="highlight"><pre><span></span><code><span class="k">val</span> <span class="n">to_string</span><span class="o">:</span> <span class="n">t</span> <span class="o">-&gt;</span> <span class="kt">string</span>
</code></pre></div>

<p>Print the object to a human-readable representation.</p>
</details>
<h3 id="show_2">show<a class="headerlink" href="#show_2" title="Permanent link">&para;</a></h3>
<details class="note" open="open"><summary>method show</summary><div class="highlight"><pre><span></span><code><span class="k">val</span> <span class="n">show</span><span class="o">:</span> <span class="n">t</span> <span class="o">-&gt;</span> <span class="kt">string</span>
</code></pre></div>

<p>Print the object to a human-readable representation.</p>
</details>
<h3 id="pp_2">pp<a class="headerlink" href="#pp_2" title="Permanent link">&para;</a></h3>
<details class="note" open="open"><summary>method pp</summary><div class="highlight"><pre><span></span><code><span class="k">val</span> <span class="n">pp</span><span class="o">:</span> <span class="nn">Format</span><span class="p">.</span><span class="n">formatter</span> <span class="o">-&gt;</span> <span class="n">t</span> <span class="o">-&gt;</span> <span class="kt">unit</span>
</code></pre></div>

<p>Pretty-print the object to a formatter.</p>
</details>
<h2 id="baggingregressor">BaggingRegressor<a class="headerlink" href="#baggingregressor" title="Permanent link">&para;</a></h2>
<p>Module <code>Sklearn.​Ensemble.​BaggingRegressor</code> wraps Python class <a href="https://scikit-learn.org/stable/modules/generated/sklearn.ensemble.BaggingRegressor.html"><code>sklearn.ensemble.BaggingRegressor</code></a>.</p>
<div class="highlight"><pre><span></span><code><span class="k">type</span> <span class="n">t</span>
</code></pre></div>

<h3 id="create_3">create<a class="headerlink" href="#create_3" title="Permanent link">&para;</a></h3>
<details class="note" open="open"><summary>constructor and attributes create</summary><div class="highlight"><pre><span></span><code><span class="k">val</span> <span class="n">create</span> <span class="o">:</span>
  <span class="o">?</span><span class="n">base_estimator</span><span class="o">:[&gt;`</span><span class="nc">BaseEstimator</span><span class="o">]</span> <span class="nn">Np</span><span class="p">.</span><span class="nn">Obj</span><span class="p">.</span><span class="n">t</span> <span class="o">-&gt;</span>
  <span class="o">?</span><span class="n">n_estimators</span><span class="o">:</span><span class="kt">int</span> <span class="o">-&gt;</span>
  <span class="o">?</span><span class="n">max_samples</span><span class="o">:[`</span><span class="nc">F</span> <span class="k">of</span> <span class="kt">float</span> <span class="o">|</span> <span class="o">`</span><span class="nc">I</span> <span class="k">of</span> <span class="kt">int</span><span class="o">]</span> <span class="o">-&gt;</span>
  <span class="o">?</span><span class="n">max_features</span><span class="o">:[`</span><span class="nc">F</span> <span class="k">of</span> <span class="kt">float</span> <span class="o">|</span> <span class="o">`</span><span class="nc">I</span> <span class="k">of</span> <span class="kt">int</span><span class="o">]</span> <span class="o">-&gt;</span>
  <span class="o">?</span><span class="n">bootstrap</span><span class="o">:</span><span class="kt">bool</span> <span class="o">-&gt;</span>
  <span class="o">?</span><span class="n">bootstrap_features</span><span class="o">:</span><span class="kt">bool</span> <span class="o">-&gt;</span>
  <span class="o">?</span><span class="n">oob_score</span><span class="o">:</span><span class="kt">bool</span> <span class="o">-&gt;</span>
  <span class="o">?</span><span class="n">warm_start</span><span class="o">:</span><span class="kt">bool</span> <span class="o">-&gt;</span>
  <span class="o">?</span><span class="n">n_jobs</span><span class="o">:</span><span class="kt">int</span> <span class="o">-&gt;</span>
  <span class="o">?</span><span class="n">random_state</span><span class="o">:</span><span class="kt">int</span> <span class="o">-&gt;</span>
  <span class="o">?</span><span class="n">verbose</span><span class="o">:</span><span class="kt">int</span> <span class="o">-&gt;</span>
  <span class="kt">unit</span> <span class="o">-&gt;</span>
  <span class="n">t</span>
</code></pre></div>

<p>A Bagging regressor.</p>
<p>A Bagging regressor is an ensemble meta-estimator that fits base
regressors each on random subsets of the original dataset and then
aggregate their individual predictions (either by voting or by averaging)
to form a final prediction. Such a meta-estimator can typically be used as
a way to reduce the variance of a black-box estimator (e.g., a decision
tree), by introducing randomization into its construction procedure and
then making an ensemble out of it.</p>
<p>This algorithm encompasses several works from the literature. When random
subsets of the dataset are drawn as random subsets of the samples, then
this algorithm is known as Pasting [1]<em>. If samples are drawn with
replacement, then the method is known as Bagging [2]</em>. When random subsets
of the dataset are drawn as random subsets of the features, then the method
is known as Random Subspaces [3]<em>. Finally, when base estimators are built
on subsets of both samples and features, then the method is known as
Random Patches [4]</em>.</p>
<p>Read more in the :ref:<code>User Guide &lt;bagging&gt;</code>.</p>
<p>.. versionadded:: 0.15</p>
<h4>Parameters</h4>
<ul>
<li>
<p><strong>base_estimator : object, default=None</strong>
    The base estimator to fit on random subsets of the dataset.
    If None, then the base estimator is a decision tree.</p>
</li>
<li>
<p><strong>n_estimators : int, default=10</strong>
    The number of base estimators in the ensemble.</p>
</li>
<li>
<p><strong>max_samples : int or float, default=1.0</strong>
    The number of samples to draw from X to train each base estimator (with
    replacement by default, see <code>bootstrap</code> for more details).</p>
<ul>
<li>If int, then draw <code>max_samples</code> samples.</li>
<li>If float, then draw <code>max_samples * X.shape[0]</code> samples.</li>
</ul>
</li>
<li>
<p><strong>max_features : int or float, default=1.0</strong>
    The number of features to draw from X to train each base estimator (
    without replacement by default, see <code>bootstrap_features</code> for more
    details).</p>
<ul>
<li>If int, then draw <code>max_features</code> features.</li>
<li>If float, then draw <code>max_features * X.shape[1]</code> features.</li>
</ul>
</li>
<li>
<p><strong>bootstrap : bool, default=True</strong>
    Whether samples are drawn with replacement. If False, sampling
    without replacement is performed.</p>
</li>
<li>
<p><strong>bootstrap_features : bool, default=False</strong>
    Whether features are drawn with replacement.</p>
</li>
<li>
<p><strong>oob_score : bool, default=False</strong>
    Whether to use out-of-bag samples to estimate
    the generalization error.</p>
</li>
<li>
<p><strong>warm_start : bool, default=False</strong>
    When set to True, reuse the solution of the previous call to fit
    and add more estimators to the ensemble, otherwise, just fit
    a whole new ensemble. See :term:<code>the Glossary &lt;warm_start&gt;</code>.</p>
</li>
<li>
<p><strong>n_jobs : int, default=None</strong>
    The number of jobs to run in parallel for both :meth:<code>fit</code> and
    :meth:<code>predict</code>. <code>None</code> means 1 unless in a
    :obj:<code>joblib.parallel_backend</code> context. <code>-1</code> means using all
    processors. See :term:<code>Glossary &lt;n_jobs&gt;</code> for more details.</p>
</li>
<li>
<p><strong>random_state : int or RandomState, default=None</strong>
    Controls the random resampling of the original dataset
    (sample wise and feature wise).
    If the base estimator accepts a <code>random_state</code> attribute, a different
    seed is generated for each instance in the ensemble.
    Pass an int for reproducible output across multiple function calls.</p>
</li>
<li>
<p><strong>See :term:<code>Glossary &lt;random_state&gt;</code>.</strong></p>
</li>
<li>
<p><strong>verbose : int, default=0</strong>
    Controls the verbosity when fitting and predicting.</p>
</li>
</ul>
<h4>Attributes</h4>
<ul>
<li>
<p><strong>base_estimator_ : estimator</strong>
    The base estimator from which the ensemble is grown.</p>
</li>
<li>
<p><strong>n_features_ : int</strong>
    The number of features when :meth:<code>fit</code> is performed.</p>
</li>
<li>
<p><strong>estimators_ : list of estimators</strong>
    The collection of fitted sub-estimators.</p>
</li>
<li>
<p><strong>estimators_samples_ : list of arrays</strong>
    The subset of drawn samples (i.e., the in-bag samples) for each base
    estimator. Each subset is defined by an array of the indices selected.</p>
</li>
<li>
<p><strong>estimators_features_ : list of arrays</strong>
    The subset of drawn features for each base estimator.</p>
</li>
<li>
<p><strong>oob_score_ : float</strong>
    Score of the training dataset obtained using an out-of-bag estimate.
    This attribute exists only when <code>oob_score</code> is True.</p>
</li>
<li>
<p><strong>oob_prediction_ : ndarray of shape (n_samples,)</strong>
    Prediction computed with out-of-bag estimate on the training
    set. If n_estimators is small it might be possible that a data point
    was never left out during the bootstrap. In this case,
    <code>oob_prediction_</code> might contain NaN. This attribute exists only
    when <code>oob_score</code> is True.</p>
</li>
</ul>
<h4>Examples</h4>
<div class="highlight"><pre><span></span><code><span class="o">&gt;&gt;&gt;</span> <span class="kn">from</span> <span class="nn">sklearn.svm</span> <span class="kn">import</span> <span class="n">SVR</span>
<span class="o">&gt;&gt;&gt;</span> <span class="kn">from</span> <span class="nn">sklearn.ensemble</span> <span class="kn">import</span> <span class="n">BaggingRegressor</span>
<span class="o">&gt;&gt;&gt;</span> <span class="kn">from</span> <span class="nn">sklearn.datasets</span> <span class="kn">import</span> <span class="n">make_regression</span>
<span class="o">&gt;&gt;&gt;</span> <span class="n">X</span><span class="p">,</span> <span class="n">y</span> <span class="o">=</span> <span class="n">make_regression</span><span class="p">(</span><span class="n">n_samples</span><span class="o">=</span><span class="mi">100</span><span class="p">,</span> <span class="n">n_features</span><span class="o">=</span><span class="mi">4</span><span class="p">,</span>
<span class="o">...</span>                        <span class="n">n_informative</span><span class="o">=</span><span class="mi">2</span><span class="p">,</span> <span class="n">n_targets</span><span class="o">=</span><span class="mi">1</span><span class="p">,</span>
<span class="o">...</span>                        <span class="n">random_state</span><span class="o">=</span><span class="mi">0</span><span class="p">,</span> <span class="n">shuffle</span><span class="o">=</span><span class="kc">False</span><span class="p">)</span>
<span class="o">&gt;&gt;&gt;</span> <span class="n">regr</span> <span class="o">=</span> <span class="n">BaggingRegressor</span><span class="p">(</span><span class="n">base_estimator</span><span class="o">=</span><span class="n">SVR</span><span class="p">(),</span>
<span class="o">...</span>                         <span class="n">n_estimators</span><span class="o">=</span><span class="mi">10</span><span class="p">,</span> <span class="n">random_state</span><span class="o">=</span><span class="mi">0</span><span class="p">)</span><span class="o">.</span><span class="n">fit</span><span class="p">(</span><span class="n">X</span><span class="p">,</span> <span class="n">y</span><span class="p">)</span>
<span class="o">&gt;&gt;&gt;</span> <span class="n">regr</span><span class="o">.</span><span class="n">predict</span><span class="p">([[</span><span class="mi">0</span><span class="p">,</span> <span class="mi">0</span><span class="p">,</span> <span class="mi">0</span><span class="p">,</span> <span class="mi">0</span><span class="p">]])</span>
<span class="n">array</span><span class="p">([</span><span class="o">-</span><span class="mf">2.8720</span><span class="o">...</span><span class="p">])</span>
</code></pre></div>

<h4>References</h4>
<p>.. [1] L. Breiman, 'Pasting small votes for classification in large
       databases and on-line', Machine Learning, 36(1), 85-103, 1999.</p>
<p>.. [2] L. Breiman, 'Bagging predictors', Machine Learning, 24(2), 123-140,
       1996.</p>
<p>.. [3] T. Ho, 'The random subspace method for constructing decision
       forests', Pattern Analysis and Machine Intelligence, 20(8), 832-844,
       1998.</p>
<p>.. [4] G. Louppe and P. Geurts, 'Ensembles on Random Patches', Machine
       Learning and Knowledge Discovery in Databases, 346-361, 2012.</p>
</details>
<h3 id="get_item_3">get_item<a class="headerlink" href="#get_item_3" title="Permanent link">&para;</a></h3>
<details class="note" open="open"><summary>method get_item</summary><div class="highlight"><pre><span></span><code><span class="k">val</span> <span class="n">get_item</span> <span class="o">:</span>
  <span class="n">index</span><span class="o">:</span><span class="nn">Py</span><span class="p">.</span><span class="nn">Object</span><span class="p">.</span><span class="n">t</span> <span class="o">-&gt;</span>
  <span class="o">[&gt;</span> <span class="n">tag</span><span class="o">]</span> <span class="nn">Obj</span><span class="p">.</span><span class="n">t</span> <span class="o">-&gt;</span>
  <span class="nn">Py</span><span class="p">.</span><span class="nn">Object</span><span class="p">.</span><span class="n">t</span>
</code></pre></div>

<p>Return the index'th estimator in the ensemble.</p>
</details>
<h3 id="iter_3">iter<a class="headerlink" href="#iter_3" title="Permanent link">&para;</a></h3>
<details class="note" open="open"><summary>method iter</summary><div class="highlight"><pre><span></span><code><span class="k">val</span> <span class="n">iter</span> <span class="o">:</span>
  <span class="o">[&gt;</span> <span class="n">tag</span><span class="o">]</span> <span class="nn">Obj</span><span class="p">.</span><span class="n">t</span> <span class="o">-&gt;</span>
  <span class="nn">Dict</span><span class="p">.</span><span class="n">t</span> <span class="nn">Seq</span><span class="p">.</span><span class="n">t</span>
</code></pre></div>

<p>Return iterator over estimators in the ensemble.</p>
</details>
<h3 id="fit_3">fit<a class="headerlink" href="#fit_3" title="Permanent link">&para;</a></h3>
<details class="note" open="open"><summary>method fit</summary><div class="highlight"><pre><span></span><code><span class="k">val</span> <span class="n">fit</span> <span class="o">:</span>
  <span class="o">?</span><span class="n">sample_weight</span><span class="o">:[&gt;`</span><span class="nc">ArrayLike</span><span class="o">]</span> <span class="nn">Np</span><span class="p">.</span><span class="nn">Obj</span><span class="p">.</span><span class="n">t</span> <span class="o">-&gt;</span>
  <span class="n">x</span><span class="o">:[&gt;`</span><span class="nc">ArrayLike</span><span class="o">]</span> <span class="nn">Np</span><span class="p">.</span><span class="nn">Obj</span><span class="p">.</span><span class="n">t</span> <span class="o">-&gt;</span>
  <span class="n">y</span><span class="o">:[&gt;`</span><span class="nc">ArrayLike</span><span class="o">]</span> <span class="nn">Np</span><span class="p">.</span><span class="nn">Obj</span><span class="p">.</span><span class="n">t</span> <span class="o">-&gt;</span>
  <span class="o">[&gt;</span> <span class="n">tag</span><span class="o">]</span> <span class="nn">Obj</span><span class="p">.</span><span class="n">t</span> <span class="o">-&gt;</span>
  <span class="n">t</span>
</code></pre></div>

<p>Build a Bagging ensemble of estimators from the training
   set (X, y).</p>
<h4>Parameters</h4>
<ul>
<li>
<p><strong>X : {array-like, sparse matrix} of shape (n_samples, n_features)</strong>
    The training input samples. Sparse matrices are accepted only if
    they are supported by the base estimator.</p>
</li>
<li>
<p><strong>y : array-like of shape (n_samples,)</strong>
    The target values (class labels in classification, real numbers in
    regression).</p>
</li>
<li>
<p><strong>sample_weight : array-like of shape (n_samples,), default=None</strong>
    Sample weights. If None, then samples are equally weighted.
    Note that this is supported only if the base estimator supports
    sample weighting.</p>
</li>
</ul>
<h4>Returns</h4>
<ul>
<li><strong>self : object</strong></li>
</ul>
</details>
<h3 id="get_params_3">get_params<a class="headerlink" href="#get_params_3" title="Permanent link">&para;</a></h3>
<details class="note" open="open"><summary>method get_params</summary><div class="highlight"><pre><span></span><code><span class="k">val</span> <span class="n">get_params</span> <span class="o">:</span>
  <span class="o">?</span><span class="n">deep</span><span class="o">:</span><span class="kt">bool</span> <span class="o">-&gt;</span>
  <span class="o">[&gt;</span> <span class="n">tag</span><span class="o">]</span> <span class="nn">Obj</span><span class="p">.</span><span class="n">t</span> <span class="o">-&gt;</span>
  <span class="nn">Dict</span><span class="p">.</span><span class="n">t</span>
</code></pre></div>

<p>Get parameters for this estimator.</p>
<h4>Parameters</h4>
<ul>
<li><strong>deep : bool, default=True</strong>
    If True, will return the parameters for this estimator and
    contained subobjects that are estimators.</li>
</ul>
<h4>Returns</h4>
<ul>
<li><strong>params : mapping of string to any</strong>
    Parameter names mapped to their values.</li>
</ul>
</details>
<h3 id="predict_3">predict<a class="headerlink" href="#predict_3" title="Permanent link">&para;</a></h3>
<details class="note" open="open"><summary>method predict</summary><div class="highlight"><pre><span></span><code><span class="k">val</span> <span class="n">predict</span> <span class="o">:</span>
  <span class="n">x</span><span class="o">:[&gt;`</span><span class="nc">ArrayLike</span><span class="o">]</span> <span class="nn">Np</span><span class="p">.</span><span class="nn">Obj</span><span class="p">.</span><span class="n">t</span> <span class="o">-&gt;</span>
  <span class="o">[&gt;</span> <span class="n">tag</span><span class="o">]</span> <span class="nn">Obj</span><span class="p">.</span><span class="n">t</span> <span class="o">-&gt;</span>
  <span class="o">[&gt;`</span><span class="nc">ArrayLike</span><span class="o">]</span> <span class="nn">Np</span><span class="p">.</span><span class="nn">Obj</span><span class="p">.</span><span class="n">t</span>
</code></pre></div>

<p>Predict regression target for X.</p>
<p>The predicted regression target of an input sample is computed as the
mean predicted regression targets of the estimators in the ensemble.</p>
<h4>Parameters</h4>
<ul>
<li><strong>X : {array-like, sparse matrix} of shape (n_samples, n_features)</strong>
    The training input samples. Sparse matrices are accepted only if
    they are supported by the base estimator.</li>
</ul>
<h4>Returns</h4>
<ul>
<li><strong>y : ndarray of shape (n_samples,)</strong>
    The predicted values.</li>
</ul>
</details>
<h3 id="score_3">score<a class="headerlink" href="#score_3" title="Permanent link">&para;</a></h3>
<details class="note" open="open"><summary>method score</summary><div class="highlight"><pre><span></span><code><span class="k">val</span> <span class="n">score</span> <span class="o">:</span>
  <span class="o">?</span><span class="n">sample_weight</span><span class="o">:[&gt;`</span><span class="nc">ArrayLike</span><span class="o">]</span> <span class="nn">Np</span><span class="p">.</span><span class="nn">Obj</span><span class="p">.</span><span class="n">t</span> <span class="o">-&gt;</span>
  <span class="n">x</span><span class="o">:[&gt;`</span><span class="nc">ArrayLike</span><span class="o">]</span> <span class="nn">Np</span><span class="p">.</span><span class="nn">Obj</span><span class="p">.</span><span class="n">t</span> <span class="o">-&gt;</span>
  <span class="n">y</span><span class="o">:[&gt;`</span><span class="nc">ArrayLike</span><span class="o">]</span> <span class="nn">Np</span><span class="p">.</span><span class="nn">Obj</span><span class="p">.</span><span class="n">t</span> <span class="o">-&gt;</span>
  <span class="o">[&gt;</span> <span class="n">tag</span><span class="o">]</span> <span class="nn">Obj</span><span class="p">.</span><span class="n">t</span> <span class="o">-&gt;</span>
  <span class="kt">float</span>
</code></pre></div>

<p>Return the coefficient of determination R^2 of the prediction.</p>
<p>The coefficient R^2 is defined as (1 - u/v), where u is the residual
sum of squares ((y_true - y_pred) <strong> 2).sum() and v is the total
sum of squares ((y_true - y_true.mean()) </strong> 2).sum().
The best possible score is 1.0 and it can be negative (because the
model can be arbitrarily worse). A constant model that always
predicts the expected value of y, disregarding the input features,
would get a R^2 score of 0.0.</p>
<h4>Parameters</h4>
<ul>
<li>
<p><strong>X : array-like of shape (n_samples, n_features)</strong>
    Test samples. For some estimators this may be a
    precomputed kernel matrix or a list of generic objects instead,
    shape = (n_samples, n_samples_fitted),
    where n_samples_fitted is the number of
    samples used in the fitting for the estimator.</p>
</li>
<li>
<p><strong>y : array-like of shape (n_samples,) or (n_samples, n_outputs)</strong>
    True values for X.</p>
</li>
<li>
<p><strong>sample_weight : array-like of shape (n_samples,), default=None</strong>
    Sample weights.</p>
</li>
</ul>
<h4>Returns</h4>
<ul>
<li><strong>score : float</strong>
    R^2 of self.predict(X) wrt. y.</li>
</ul>
<h4>Notes</h4>
<p>The R2 score used when calling <code>score</code> on a regressor uses
<code>multioutput='uniform_average'</code> from version 0.23 to keep consistent
with default value of :func:<code>~sklearn.metrics.r2_score</code>.
This influences the <code>score</code> method of all the multioutput
regressors (except for
:class:<code>~sklearn.multioutput.MultiOutputRegressor</code>).</p>
</details>
<h3 id="set_params_3">set_params<a class="headerlink" href="#set_params_3" title="Permanent link">&para;</a></h3>
<details class="note" open="open"><summary>method set_params</summary><div class="highlight"><pre><span></span><code><span class="k">val</span> <span class="n">set_params</span> <span class="o">:</span>
  <span class="o">?</span><span class="n">params</span><span class="o">:(</span><span class="kt">string</span> <span class="o">*</span> <span class="nn">Py</span><span class="p">.</span><span class="nn">Object</span><span class="p">.</span><span class="n">t</span><span class="o">)</span> <span class="kt">list</span> <span class="o">-&gt;</span>
  <span class="o">[&gt;</span> <span class="n">tag</span><span class="o">]</span> <span class="nn">Obj</span><span class="p">.</span><span class="n">t</span> <span class="o">-&gt;</span>
  <span class="n">t</span>
</code></pre></div>

<p>Set the parameters of this estimator.</p>
<p>The method works on simple estimators as well as on nested objects
(such as pipelines). The latter have parameters of the form
<code>&lt;component&gt;__&lt;parameter&gt;</code> so that it's possible to update each
component of a nested object.</p>
<h4>Parameters</h4>
<ul>
<li><strong>**params : dict</strong>
    Estimator parameters.</li>
</ul>
<h4>Returns</h4>
<ul>
<li><strong>self : object</strong>
    Estimator instance.</li>
</ul>
</details>
<h3 id="base_estimator__3">base_estimator_<a class="headerlink" href="#base_estimator__3" title="Permanent link">&para;</a></h3>
<details class="note" open="open"><summary>attribute base_estimator_</summary><div class="highlight"><pre><span></span><code><span class="k">val</span> <span class="n">base_estimator_</span> <span class="o">:</span> <span class="n">t</span> <span class="o">-&gt;</span> <span class="o">[`</span><span class="nc">BaseEstimator</span><span class="o">|`</span><span class="nc">Object</span><span class="o">]</span> <span class="nn">Np</span><span class="p">.</span><span class="nn">Obj</span><span class="p">.</span><span class="n">t</span>
<span class="k">val</span> <span class="n">base_estimator_opt</span> <span class="o">:</span> <span class="n">t</span> <span class="o">-&gt;</span> <span class="o">([`</span><span class="nc">BaseEstimator</span><span class="o">|`</span><span class="nc">Object</span><span class="o">]</span> <span class="nn">Np</span><span class="p">.</span><span class="nn">Obj</span><span class="p">.</span><span class="n">t</span><span class="o">)</span> <span class="n">option</span>
</code></pre></div>

<p>This attribute is documented in <code>create</code> above. The first version raises Not_found
if the attribute is None. The _opt version returns an option.</p>
</details>
<h3 id="n_features__1">n_features_<a class="headerlink" href="#n_features__1" title="Permanent link">&para;</a></h3>
<details class="note" open="open"><summary>attribute n_features_</summary><div class="highlight"><pre><span></span><code><span class="k">val</span> <span class="n">n_features_</span> <span class="o">:</span> <span class="n">t</span> <span class="o">-&gt;</span> <span class="kt">int</span>
<span class="k">val</span> <span class="n">n_features_opt</span> <span class="o">:</span> <span class="n">t</span> <span class="o">-&gt;</span> <span class="o">(</span><span class="kt">int</span><span class="o">)</span> <span class="n">option</span>
</code></pre></div>

<p>This attribute is documented in <code>create</code> above. The first version raises Not_found
if the attribute is None. The _opt version returns an option.</p>
</details>
<h3 id="estimators__3">estimators_<a class="headerlink" href="#estimators__3" title="Permanent link">&para;</a></h3>
<details class="note" open="open"><summary>attribute estimators_</summary><div class="highlight"><pre><span></span><code><span class="k">val</span> <span class="n">estimators_</span> <span class="o">:</span> <span class="n">t</span> <span class="o">-&gt;</span> <span class="o">[`</span><span class="nc">BaseEstimator</span><span class="o">|`</span><span class="nc">Object</span><span class="o">]</span> <span class="nn">Np</span><span class="p">.</span><span class="nn">Obj</span><span class="p">.</span><span class="n">t</span> <span class="kt">list</span>
<span class="k">val</span> <span class="n">estimators_opt</span> <span class="o">:</span> <span class="n">t</span> <span class="o">-&gt;</span> <span class="o">([`</span><span class="nc">BaseEstimator</span><span class="o">|`</span><span class="nc">Object</span><span class="o">]</span> <span class="nn">Np</span><span class="p">.</span><span class="nn">Obj</span><span class="p">.</span><span class="n">t</span> <span class="kt">list</span><span class="o">)</span> <span class="n">option</span>
</code></pre></div>

<p>This attribute is documented in <code>create</code> above. The first version raises Not_found
if the attribute is None. The _opt version returns an option.</p>
</details>
<h3 id="estimators_samples__1">estimators_samples_<a class="headerlink" href="#estimators_samples__1" title="Permanent link">&para;</a></h3>
<details class="note" open="open"><summary>attribute estimators_samples_</summary><div class="highlight"><pre><span></span><code><span class="k">val</span> <span class="n">estimators_samples_</span> <span class="o">:</span> <span class="n">t</span> <span class="o">-&gt;</span> <span class="nn">Np</span><span class="p">.</span><span class="nn">Numpy</span><span class="p">.</span><span class="nn">Ndarray</span><span class="p">.</span><span class="nn">List</span><span class="p">.</span><span class="n">t</span>
<span class="k">val</span> <span class="n">estimators_samples_opt</span> <span class="o">:</span> <span class="n">t</span> <span class="o">-&gt;</span> <span class="o">(</span><span class="nn">Np</span><span class="p">.</span><span class="nn">Numpy</span><span class="p">.</span><span class="nn">Ndarray</span><span class="p">.</span><span class="nn">List</span><span class="p">.</span><span class="n">t</span><span class="o">)</span> <span class="n">option</span>
</code></pre></div>

<p>This attribute is documented in <code>create</code> above. The first version raises Not_found
if the attribute is None. The _opt version returns an option.</p>
</details>
<h3 id="estimators_features__1">estimators_features_<a class="headerlink" href="#estimators_features__1" title="Permanent link">&para;</a></h3>
<details class="note" open="open"><summary>attribute estimators_features_</summary><div class="highlight"><pre><span></span><code><span class="k">val</span> <span class="n">estimators_features_</span> <span class="o">:</span> <span class="n">t</span> <span class="o">-&gt;</span> <span class="nn">Np</span><span class="p">.</span><span class="nn">Numpy</span><span class="p">.</span><span class="nn">Ndarray</span><span class="p">.</span><span class="nn">List</span><span class="p">.</span><span class="n">t</span>
<span class="k">val</span> <span class="n">estimators_features_opt</span> <span class="o">:</span> <span class="n">t</span> <span class="o">-&gt;</span> <span class="o">(</span><span class="nn">Np</span><span class="p">.</span><span class="nn">Numpy</span><span class="p">.</span><span class="nn">Ndarray</span><span class="p">.</span><span class="nn">List</span><span class="p">.</span><span class="n">t</span><span class="o">)</span> <span class="n">option</span>
</code></pre></div>

<p>This attribute is documented in <code>create</code> above. The first version raises Not_found
if the attribute is None. The _opt version returns an option.</p>
</details>
<h3 id="oob_score__1">oob_score_<a class="headerlink" href="#oob_score__1" title="Permanent link">&para;</a></h3>
<details class="note" open="open"><summary>attribute oob_score_</summary><div class="highlight"><pre><span></span><code><span class="k">val</span> <span class="n">oob_score_</span> <span class="o">:</span> <span class="n">t</span> <span class="o">-&gt;</span> <span class="kt">float</span>
<span class="k">val</span> <span class="n">oob_score_opt</span> <span class="o">:</span> <span class="n">t</span> <span class="o">-&gt;</span> <span class="o">(</span><span class="kt">float</span><span class="o">)</span> <span class="n">option</span>
</code></pre></div>

<p>This attribute is documented in <code>create</code> above. The first version raises Not_found
if the attribute is None. The _opt version returns an option.</p>
</details>
<h3 id="oob_prediction_">oob_prediction_<a class="headerlink" href="#oob_prediction_" title="Permanent link">&para;</a></h3>
<details class="note" open="open"><summary>attribute oob_prediction_</summary><div class="highlight"><pre><span></span><code><span class="k">val</span> <span class="n">oob_prediction_</span> <span class="o">:</span> <span class="n">t</span> <span class="o">-&gt;</span> <span class="o">[&gt;`</span><span class="nc">ArrayLike</span><span class="o">]</span> <span class="nn">Np</span><span class="p">.</span><span class="nn">Obj</span><span class="p">.</span><span class="n">t</span>
<span class="k">val</span> <span class="n">oob_prediction_opt</span> <span class="o">:</span> <span class="n">t</span> <span class="o">-&gt;</span> <span class="o">([&gt;`</span><span class="nc">ArrayLike</span><span class="o">]</span> <span class="nn">Np</span><span class="p">.</span><span class="nn">Obj</span><span class="p">.</span><span class="n">t</span><span class="o">)</span> <span class="n">option</span>
</code></pre></div>

<p>This attribute is documented in <code>create</code> above. The first version raises Not_found
if the attribute is None. The _opt version returns an option.</p>
</details>
<h3 id="to_string_3">to_string<a class="headerlink" href="#to_string_3" title="Permanent link">&para;</a></h3>
<details class="note" open="open"><summary>method to_string</summary><div class="highlight"><pre><span></span><code><span class="k">val</span> <span class="n">to_string</span><span class="o">:</span> <span class="n">t</span> <span class="o">-&gt;</span> <span class="kt">string</span>
</code></pre></div>

<p>Print the object to a human-readable representation.</p>
</details>
<h3 id="show_3">show<a class="headerlink" href="#show_3" title="Permanent link">&para;</a></h3>
<details class="note" open="open"><summary>method show</summary><div class="highlight"><pre><span></span><code><span class="k">val</span> <span class="n">show</span><span class="o">:</span> <span class="n">t</span> <span class="o">-&gt;</span> <span class="kt">string</span>
</code></pre></div>

<p>Print the object to a human-readable representation.</p>
</details>
<h3 id="pp_3">pp<a class="headerlink" href="#pp_3" title="Permanent link">&para;</a></h3>
<details class="note" open="open"><summary>method pp</summary><div class="highlight"><pre><span></span><code><span class="k">val</span> <span class="n">pp</span><span class="o">:</span> <span class="nn">Format</span><span class="p">.</span><span class="n">formatter</span> <span class="o">-&gt;</span> <span class="n">t</span> <span class="o">-&gt;</span> <span class="kt">unit</span>
</code></pre></div>

<p>Pretty-print the object to a formatter.</p>
</details>
<h2 id="baseensemble">BaseEnsemble<a class="headerlink" href="#baseensemble" title="Permanent link">&para;</a></h2>
<p>Module <code>Sklearn.​Ensemble.​BaseEnsemble</code> wraps Python class <a href="https://scikit-learn.org/stable/modules/generated/sklearn.ensemble.BaseEnsemble.html"><code>sklearn.ensemble.BaseEnsemble</code></a>.</p>
<div class="highlight"><pre><span></span><code><span class="k">type</span> <span class="n">t</span>
</code></pre></div>

<h3 id="get_item_4">get_item<a class="headerlink" href="#get_item_4" title="Permanent link">&para;</a></h3>
<details class="note" open="open"><summary>method get_item</summary><div class="highlight"><pre><span></span><code><span class="k">val</span> <span class="n">get_item</span> <span class="o">:</span>
  <span class="n">index</span><span class="o">:</span><span class="nn">Py</span><span class="p">.</span><span class="nn">Object</span><span class="p">.</span><span class="n">t</span> <span class="o">-&gt;</span>
  <span class="o">[&gt;</span> <span class="n">tag</span><span class="o">]</span> <span class="nn">Obj</span><span class="p">.</span><span class="n">t</span> <span class="o">-&gt;</span>
  <span class="nn">Py</span><span class="p">.</span><span class="nn">Object</span><span class="p">.</span><span class="n">t</span>
</code></pre></div>

<p>Return the index'th estimator in the ensemble.</p>
</details>
<h3 id="iter_4">iter<a class="headerlink" href="#iter_4" title="Permanent link">&para;</a></h3>
<details class="note" open="open"><summary>method iter</summary><div class="highlight"><pre><span></span><code><span class="k">val</span> <span class="n">iter</span> <span class="o">:</span>
  <span class="o">[&gt;</span> <span class="n">tag</span><span class="o">]</span> <span class="nn">Obj</span><span class="p">.</span><span class="n">t</span> <span class="o">-&gt;</span>
  <span class="nn">Dict</span><span class="p">.</span><span class="n">t</span> <span class="nn">Seq</span><span class="p">.</span><span class="n">t</span>
</code></pre></div>

<p>Return iterator over estimators in the ensemble.</p>
</details>
<h3 id="get_params_4">get_params<a class="headerlink" href="#get_params_4" title="Permanent link">&para;</a></h3>
<details class="note" open="open"><summary>method get_params</summary><div class="highlight"><pre><span></span><code><span class="k">val</span> <span class="n">get_params</span> <span class="o">:</span>
  <span class="o">?</span><span class="n">deep</span><span class="o">:</span><span class="kt">bool</span> <span class="o">-&gt;</span>
  <span class="o">[&gt;</span> <span class="n">tag</span><span class="o">]</span> <span class="nn">Obj</span><span class="p">.</span><span class="n">t</span> <span class="o">-&gt;</span>
  <span class="nn">Dict</span><span class="p">.</span><span class="n">t</span>
</code></pre></div>

<p>Get parameters for this estimator.</p>
<h4>Parameters</h4>
<ul>
<li><strong>deep : bool, default=True</strong>
    If True, will return the parameters for this estimator and
    contained subobjects that are estimators.</li>
</ul>
<h4>Returns</h4>
<ul>
<li><strong>params : mapping of string to any</strong>
    Parameter names mapped to their values.</li>
</ul>
</details>
<h3 id="set_params_4">set_params<a class="headerlink" href="#set_params_4" title="Permanent link">&para;</a></h3>
<details class="note" open="open"><summary>method set_params</summary><div class="highlight"><pre><span></span><code><span class="k">val</span> <span class="n">set_params</span> <span class="o">:</span>
  <span class="o">?</span><span class="n">params</span><span class="o">:(</span><span class="kt">string</span> <span class="o">*</span> <span class="nn">Py</span><span class="p">.</span><span class="nn">Object</span><span class="p">.</span><span class="n">t</span><span class="o">)</span> <span class="kt">list</span> <span class="o">-&gt;</span>
  <span class="o">[&gt;</span> <span class="n">tag</span><span class="o">]</span> <span class="nn">Obj</span><span class="p">.</span><span class="n">t</span> <span class="o">-&gt;</span>
  <span class="n">t</span>
</code></pre></div>

<p>Set the parameters of this estimator.</p>
<p>The method works on simple estimators as well as on nested objects
(such as pipelines). The latter have parameters of the form
<code>&lt;component&gt;__&lt;parameter&gt;</code> so that it's possible to update each
component of a nested object.</p>
<h4>Parameters</h4>
<ul>
<li><strong>**params : dict</strong>
    Estimator parameters.</li>
</ul>
<h4>Returns</h4>
<ul>
<li><strong>self : object</strong>
    Estimator instance.</li>
</ul>
</details>
<h3 id="base_estimator__4">base_estimator_<a class="headerlink" href="#base_estimator__4" title="Permanent link">&para;</a></h3>
<details class="note" open="open"><summary>attribute base_estimator_</summary><div class="highlight"><pre><span></span><code><span class="k">val</span> <span class="n">base_estimator_</span> <span class="o">:</span> <span class="n">t</span> <span class="o">-&gt;</span> <span class="o">[`</span><span class="nc">BaseEstimator</span><span class="o">|`</span><span class="nc">Object</span><span class="o">]</span> <span class="nn">Np</span><span class="p">.</span><span class="nn">Obj</span><span class="p">.</span><span class="n">t</span>
<span class="k">val</span> <span class="n">base_estimator_opt</span> <span class="o">:</span> <span class="n">t</span> <span class="o">-&gt;</span> <span class="o">([`</span><span class="nc">BaseEstimator</span><span class="o">|`</span><span class="nc">Object</span><span class="o">]</span> <span class="nn">Np</span><span class="p">.</span><span class="nn">Obj</span><span class="p">.</span><span class="n">t</span><span class="o">)</span> <span class="n">option</span>
</code></pre></div>

<p>This attribute is documented in <code>create</code> above. The first version raises Not_found
if the attribute is None. The _opt version returns an option.</p>
</details>
<h3 id="estimators__4">estimators_<a class="headerlink" href="#estimators__4" title="Permanent link">&para;</a></h3>
<details class="note" open="open"><summary>attribute estimators_</summary><div class="highlight"><pre><span></span><code><span class="k">val</span> <span class="n">estimators_</span> <span class="o">:</span> <span class="n">t</span> <span class="o">-&gt;</span> <span class="o">[`</span><span class="nc">BaseEstimator</span><span class="o">|`</span><span class="nc">Object</span><span class="o">]</span> <span class="nn">Np</span><span class="p">.</span><span class="nn">Obj</span><span class="p">.</span><span class="n">t</span> <span class="kt">list</span>
<span class="k">val</span> <span class="n">estimators_opt</span> <span class="o">:</span> <span class="n">t</span> <span class="o">-&gt;</span> <span class="o">([`</span><span class="nc">BaseEstimator</span><span class="o">|`</span><span class="nc">Object</span><span class="o">]</span> <span class="nn">Np</span><span class="p">.</span><span class="nn">Obj</span><span class="p">.</span><span class="n">t</span> <span class="kt">list</span><span class="o">)</span> <span class="n">option</span>
</code></pre></div>

<p>This attribute is documented in <code>create</code> above. The first version raises Not_found
if the attribute is None. The _opt version returns an option.</p>
</details>
<h3 id="to_string_4">to_string<a class="headerlink" href="#to_string_4" title="Permanent link">&para;</a></h3>
<details class="note" open="open"><summary>method to_string</summary><div class="highlight"><pre><span></span><code><span class="k">val</span> <span class="n">to_string</span><span class="o">:</span> <span class="n">t</span> <span class="o">-&gt;</span> <span class="kt">string</span>
</code></pre></div>

<p>Print the object to a human-readable representation.</p>
</details>
<h3 id="show_4">show<a class="headerlink" href="#show_4" title="Permanent link">&para;</a></h3>
<details class="note" open="open"><summary>method show</summary><div class="highlight"><pre><span></span><code><span class="k">val</span> <span class="n">show</span><span class="o">:</span> <span class="n">t</span> <span class="o">-&gt;</span> <span class="kt">string</span>
</code></pre></div>

<p>Print the object to a human-readable representation.</p>
</details>
<h3 id="pp_4">pp<a class="headerlink" href="#pp_4" title="Permanent link">&para;</a></h3>
<details class="note" open="open"><summary>method pp</summary><div class="highlight"><pre><span></span><code><span class="k">val</span> <span class="n">pp</span><span class="o">:</span> <span class="nn">Format</span><span class="p">.</span><span class="n">formatter</span> <span class="o">-&gt;</span> <span class="n">t</span> <span class="o">-&gt;</span> <span class="kt">unit</span>
</code></pre></div>

<p>Pretty-print the object to a formatter.</p>
</details>
<h2 id="extratreesclassifier">ExtraTreesClassifier<a class="headerlink" href="#extratreesclassifier" title="Permanent link">&para;</a></h2>
<p>Module <code>Sklearn.​Ensemble.​ExtraTreesClassifier</code> wraps Python class <a href="https://scikit-learn.org/stable/modules/generated/sklearn.ensemble.ExtraTreesClassifier.html"><code>sklearn.ensemble.ExtraTreesClassifier</code></a>.</p>
<div class="highlight"><pre><span></span><code><span class="k">type</span> <span class="n">t</span>
</code></pre></div>

<h3 id="create_4">create<a class="headerlink" href="#create_4" title="Permanent link">&para;</a></h3>
<details class="note" open="open"><summary>constructor and attributes create</summary><div class="highlight"><pre><span></span><code><span class="k">val</span> <span class="n">create</span> <span class="o">:</span>
  <span class="o">?</span><span class="n">n_estimators</span><span class="o">:</span><span class="kt">int</span> <span class="o">-&gt;</span>
  <span class="o">?</span><span class="n">criterion</span><span class="o">:[`</span><span class="nc">Gini</span> <span class="o">|</span> <span class="o">`</span><span class="nc">Entropy</span><span class="o">]</span> <span class="o">-&gt;</span>
  <span class="o">?</span><span class="n">max_depth</span><span class="o">:</span><span class="kt">int</span> <span class="o">-&gt;</span>
  <span class="o">?</span><span class="n">min_samples_split</span><span class="o">:[`</span><span class="nc">F</span> <span class="k">of</span> <span class="kt">float</span> <span class="o">|</span> <span class="o">`</span><span class="nc">I</span> <span class="k">of</span> <span class="kt">int</span><span class="o">]</span> <span class="o">-&gt;</span>
  <span class="o">?</span><span class="n">min_samples_leaf</span><span class="o">:[`</span><span class="nc">F</span> <span class="k">of</span> <span class="kt">float</span> <span class="o">|</span> <span class="o">`</span><span class="nc">I</span> <span class="k">of</span> <span class="kt">int</span><span class="o">]</span> <span class="o">-&gt;</span>
  <span class="o">?</span><span class="n">min_weight_fraction_leaf</span><span class="o">:</span><span class="kt">float</span> <span class="o">-&gt;</span>
  <span class="o">?</span><span class="n">max_features</span><span class="o">:[`</span><span class="nc">I</span> <span class="k">of</span> <span class="kt">int</span> <span class="o">|</span> <span class="o">`</span><span class="nc">Sqrt</span> <span class="o">|</span> <span class="o">`</span><span class="nc">Auto</span> <span class="o">|</span> <span class="o">`</span><span class="nc">F</span> <span class="k">of</span> <span class="kt">float</span> <span class="o">|</span> <span class="o">`</span><span class="nc">Log2</span><span class="o">]</span> <span class="o">-&gt;</span>
  <span class="o">?</span><span class="n">max_leaf_nodes</span><span class="o">:</span><span class="kt">int</span> <span class="o">-&gt;</span>
  <span class="o">?</span><span class="n">min_impurity_decrease</span><span class="o">:</span><span class="kt">float</span> <span class="o">-&gt;</span>
  <span class="o">?</span><span class="n">min_impurity_split</span><span class="o">:</span><span class="kt">float</span> <span class="o">-&gt;</span>
  <span class="o">?</span><span class="n">bootstrap</span><span class="o">:</span><span class="kt">bool</span> <span class="o">-&gt;</span>
  <span class="o">?</span><span class="n">oob_score</span><span class="o">:</span><span class="kt">bool</span> <span class="o">-&gt;</span>
  <span class="o">?</span><span class="n">n_jobs</span><span class="o">:</span><span class="kt">int</span> <span class="o">-&gt;</span>
  <span class="o">?</span><span class="n">random_state</span><span class="o">:</span><span class="kt">int</span> <span class="o">-&gt;</span>
  <span class="o">?</span><span class="n">verbose</span><span class="o">:</span><span class="kt">int</span> <span class="o">-&gt;</span>
  <span class="o">?</span><span class="n">warm_start</span><span class="o">:</span><span class="kt">bool</span> <span class="o">-&gt;</span>
  <span class="o">?</span><span class="n">class_weight</span><span class="o">:[`</span><span class="nc">Balanced</span> <span class="o">|</span> <span class="o">`</span><span class="nc">DictIntToFloat</span> <span class="k">of</span> <span class="o">(</span><span class="kt">int</span> <span class="o">*</span> <span class="kt">float</span><span class="o">)</span> <span class="kt">list</span> <span class="o">|</span> <span class="o">`</span><span class="nc">Balanced_subsample</span> <span class="o">|</span> <span class="o">`</span><span class="nc">List_of_dicts</span> <span class="k">of</span> <span class="nn">Py</span><span class="p">.</span><span class="nn">Object</span><span class="p">.</span><span class="n">t</span><span class="o">]</span> <span class="o">-&gt;</span>
  <span class="o">?</span><span class="n">ccp_alpha</span><span class="o">:</span><span class="kt">float</span> <span class="o">-&gt;</span>
  <span class="o">?</span><span class="n">max_samples</span><span class="o">:[`</span><span class="nc">F</span> <span class="k">of</span> <span class="kt">float</span> <span class="o">|</span> <span class="o">`</span><span class="nc">I</span> <span class="k">of</span> <span class="kt">int</span><span class="o">]</span> <span class="o">-&gt;</span>
  <span class="kt">unit</span> <span class="o">-&gt;</span>
  <span class="n">t</span>
</code></pre></div>

<p>An extra-trees classifier.</p>
<p>This class implements a meta estimator that fits a number of
randomized decision trees (a.k.a. extra-trees) on various sub-samples
of the dataset and uses averaging to improve the predictive accuracy
and control over-fitting.</p>
<p>Read more in the :ref:<code>User Guide &lt;forest&gt;</code>.</p>
<h4>Parameters</h4>
<ul>
<li>
<p><strong>n_estimators : int, default=100</strong>
    The number of trees in the forest.</p>
<p>.. versionchanged:: 0.22
   The default value of <code>n_estimators</code> changed from 10 to 100
   in 0.22.</p>
</li>
<li>
<p><strong>criterion : {'gini', 'entropy'}, default='gini'</strong>
    The function to measure the quality of a split. Supported criteria are
    'gini' for the Gini impurity and 'entropy' for the information gain.</p>
</li>
<li>
<p><strong>max_depth : int, default=None</strong>
    The maximum depth of the tree. If None, then nodes are expanded until
    all leaves are pure or until all leaves contain less than
    min_samples_split samples.</p>
</li>
<li>
<p><strong>min_samples_split : int or float, default=2</strong>
    The minimum number of samples required to split an internal node:</p>
<ul>
<li>If int, then consider <code>min_samples_split</code> as the minimum number.</li>
<li>If float, then <code>min_samples_split</code> is a fraction and
  <code>ceil(min_samples_split * n_samples)</code> are the minimum
  number of samples for each split.</li>
</ul>
<p>.. versionchanged:: 0.18
   Added float values for fractions.</p>
</li>
<li>
<p><strong>min_samples_leaf : int or float, default=1</strong>
    The minimum number of samples required to be at a leaf node.
    A split point at any depth will only be considered if it leaves at
    least <code>min_samples_leaf</code> training samples in each of the left and
    right branches.  This may have the effect of smoothing the model,
    especially in regression.</p>
<ul>
<li>If int, then consider <code>min_samples_leaf</code> as the minimum number.</li>
<li>If float, then <code>min_samples_leaf</code> is a fraction and
  <code>ceil(min_samples_leaf * n_samples)</code> are the minimum
  number of samples for each node.</li>
</ul>
<p>.. versionchanged:: 0.18
   Added float values for fractions.</p>
</li>
<li>
<p><strong>min_weight_fraction_leaf : float, default=0.0</strong>
    The minimum weighted fraction of the sum total of weights (of all
    the input samples) required to be at a leaf node. Samples have
    equal weight when sample_weight is not provided.</p>
</li>
<li>
<p><strong>max_features : {'auto', 'sqrt', 'log2'}, int or float, default='auto'</strong>
    The number of features to consider when looking for the best split:</p>
<ul>
<li>If int, then consider <code>max_features</code> features at each split.</li>
<li>If float, then <code>max_features</code> is a fraction and
  <code>int(max_features * n_features)</code> features are considered at each
  split.</li>
<li>If 'auto', then <code>max_features=sqrt(n_features)</code>.</li>
<li>If 'sqrt', then <code>max_features=sqrt(n_features)</code>.</li>
<li>If 'log2', then <code>max_features=log2(n_features)</code>.</li>
<li>If None, then <code>max_features=n_features</code>.</li>
</ul>
</li>
<li>
<p><strong>Note: the search for a split does not stop until at least one</strong>
    valid partition of the node samples is found, even if it requires to
    effectively inspect more than <code>max_features</code> features.</p>
</li>
<li>
<p><strong>max_leaf_nodes : int, default=None</strong>
    Grow trees with <code>max_leaf_nodes</code> in best-first fashion.
    Best nodes are defined as relative reduction in impurity.
    If None then unlimited number of leaf nodes.</p>
</li>
<li>
<p><strong>min_impurity_decrease : float, default=0.0</strong>
    A node will be split if this split induces a decrease of the impurity
    greater than or equal to this value.</p>
<p>The weighted impurity decrease equation is the following::</p>
<div class="codehilite"><pre><span></span><code>N_t / N * (impurity - N_t_R / N_t * right_impurity
                    - N_t_L / N_t * left_impurity)
</code></pre></div>


<p>where <code>N</code> is the total number of samples, <code>N_t</code> is the number of
samples at the current node, <code>N_t_L</code> is the number of samples in the
left child, and <code>N_t_R</code> is the number of samples in the right child.</p>
<p><code>N</code>, <code>N_t</code>, <code>N_t_R</code> and <code>N_t_L</code> all refer to the weighted sum,
if <code>sample_weight</code> is passed.</p>
<p>.. versionadded:: 0.19</p>
</li>
<li>
<p><strong>min_impurity_split : float, default=None</strong>
    Threshold for early stopping in tree growth. A node will split
    if its impurity is above the threshold, otherwise it is a leaf.</p>
<p>.. deprecated:: 0.19
   <code>min_impurity_split</code> has been deprecated in favor of
   <code>min_impurity_decrease</code> in 0.19. The default value of
   <code>min_impurity_split</code> has changed from 1e-7 to 0 in 0.23 and it
   will be removed in 0.25. Use <code>min_impurity_decrease</code> instead.</p>
</li>
<li>
<p><strong>bootstrap : bool, default=False</strong>
    Whether bootstrap samples are used when building trees. If False, the
    whole dataset is used to build each tree.</p>
</li>
<li>
<p><strong>oob_score : bool, default=False</strong>
    Whether to use out-of-bag samples to estimate
    the generalization accuracy.</p>
</li>
<li>
<p><strong>n_jobs : int, default=None</strong>
    The number of jobs to run in parallel. :meth:<code>fit</code>, :meth:<code>predict</code>,
    :meth:<code>decision_path</code> and :meth:<code>apply</code> are all parallelized over the
    trees. <code>None</code> means 1 unless in a :obj:<code>joblib.parallel_backend</code>
    context. <code>-1</code> means using all processors. See :term:<code>Glossary
    &lt;n_jobs&gt;</code> for more details.</p>
</li>
<li>
<p><strong>random_state : int, RandomState, default=None</strong>
    Controls 3 sources of randomness:</p>
<ul>
<li>the bootstrapping of the samples used when building trees
  (if <code>bootstrap=True</code>)</li>
<li>the sampling of the features to consider when looking for the best
  split at each node (if <code>max_features &lt; n_features</code>)</li>
<li>the draw of the splits for each of the <code>max_features</code></li>
</ul>
</li>
<li>
<p><strong>See :term:<code>Glossary &lt;random_state&gt;</code> for details.</strong></p>
</li>
<li>
<p><strong>verbose : int, default=0</strong>
    Controls the verbosity when fitting and predicting.</p>
</li>
<li>
<p><strong>warm_start : bool, default=False</strong>
    When set to <code>True</code>, reuse the solution of the previous call to fit
    and add more estimators to the ensemble, otherwise, just fit a whole
    new forest. See :term:<code>the Glossary &lt;warm_start&gt;</code>.</p>
</li>
<li>
<p><strong>class_weight : {'balanced', 'balanced_subsample'}, dict or list of dicts,             default=None</strong>
    Weights associated with classes in the form <code>{class_label: weight}</code>.
    If not given, all classes are supposed to have weight one. For
    multi-output problems, a list of dicts can be provided in the same
    order as the columns of y.</p>
<p>Note that for multioutput (including multilabel) weights should be
defined for each class of every column in its own dict. For example,
for four-class multilabel classification weights should be
[{0: 1, 1: 1}, {0: 1, 1: 5}, {0: 1, 1: 1}, {0: 1, 1: 1}] instead of
[{1:1}, {2:5}, {3:1}, {4:1}].</p>
<p>The 'balanced' mode uses the values of y to automatically adjust
weights inversely proportional to class frequencies in the input data
as <code>n_samples / (n_classes * np.bincount(y))</code></p>
<p>The 'balanced_subsample' mode is the same as 'balanced' except that
weights are computed based on the bootstrap sample for every tree
grown.</p>
<p>For multi-output, the weights of each column of y will be multiplied.</p>
<p>Note that these weights will be multiplied with sample_weight (passed
through the fit method) if sample_weight is specified.</p>
</li>
<li>
<p><strong>ccp_alpha : non-negative float, default=0.0</strong>
    Complexity parameter used for Minimal Cost-Complexity Pruning. The
    subtree with the largest cost complexity that is smaller than
    <code>ccp_alpha</code> will be chosen. By default, no pruning is performed. See
    :ref:<code>minimal_cost_complexity_pruning</code> for details.</p>
<p>.. versionadded:: 0.22</p>
</li>
<li>
<p><strong>max_samples : int or float, default=None</strong>
    If bootstrap is True, the number of samples to draw from X
    to train each base estimator.</p>
<ul>
<li>If None (default), then draw <code>X.shape[0]</code> samples.</li>
<li>If int, then draw <code>max_samples</code> samples.</li>
<li>If float, then draw <code>max_samples * X.shape[0]</code> samples. Thus,
  <code>max_samples</code> should be in the interval <code>(0, 1)</code>.</li>
</ul>
<p>.. versionadded:: 0.22</p>
</li>
</ul>
<h4>Attributes</h4>
<ul>
<li>
<p><strong>base_estimator_ : ExtraTreesClassifier</strong>
    The child estimator template used to create the collection of fitted
    sub-estimators.</p>
</li>
<li>
<p><strong>estimators_ : list of DecisionTreeClassifier</strong>
    The collection of fitted sub-estimators.</p>
</li>
<li>
<p><strong>classes_ : ndarray of shape (n_classes,) or a list of such arrays</strong>
    The classes labels (single output problem), or a list of arrays of
    class labels (multi-output problem).</p>
</li>
<li>
<p><strong>n_classes_ : int or list</strong>
    The number of classes (single output problem), or a list containing the
    number of classes for each output (multi-output problem).</p>
</li>
<li>
<p><strong>feature_importances_ : ndarray of shape (n_features,)</strong>
    The impurity-based feature importances.
    The higher, the more important the feature.
    The importance of a feature is computed as the (normalized)
    total reduction of the criterion brought by that feature.  It is also
    known as the Gini importance.</p>
</li>
<li>
<p><strong>Warning: impurity-based feature importances can be misleading for</strong>
    high cardinality features (many unique values). See
    :func:<code>sklearn.inspection.permutation_importance</code> as an alternative.</p>
</li>
<li>
<p><strong>n_features_ : int</strong>
    The number of features when <code>fit</code> is performed.</p>
</li>
<li>
<p><strong>n_outputs_ : int</strong>
    The number of outputs when <code>fit</code> is performed.</p>
</li>
<li>
<p><strong>oob_score_ : float</strong>
    Score of the training dataset obtained using an out-of-bag estimate.
    This attribute exists only when <code>oob_score</code> is True.</p>
</li>
<li>
<p><strong>oob_decision_function_ : ndarray of shape (n_samples, n_classes)</strong>
    Decision function computed with out-of-bag estimate on the training
    set. If n_estimators is small it might be possible that a data point
    was never left out during the bootstrap. In this case,
    <code>oob_decision_function_</code> might contain NaN. This attribute exists
    only when <code>oob_score</code> is True.</p>
</li>
</ul>
<h4>See Also</h4>
<ul>
<li>
<p><strong>sklearn.tree.ExtraTreeClassifier : Base classifier for this ensemble.</strong></p>
</li>
<li>
<p><strong>RandomForestClassifier : Ensemble Classifier based on trees with optimal</strong>
    splits.</p>
</li>
</ul>
<h4>Notes</h4>
<p>The default values for the parameters controlling the size of the trees
(e.g. <code>max_depth</code>, <code>min_samples_leaf</code>, etc.) lead to fully grown and
unpruned trees which can potentially be very large on some data sets. To
reduce memory consumption, the complexity and size of the trees should be
controlled by setting those parameter values.</p>
<h4>References</h4>
<p>.. [1] P. Geurts, D. Ernst., and L. Wehenkel, 'Extremely randomized
       trees', Machine Learning, 63(1), 3-42, 2006.</p>
<h4>Examples</h4>
<div class="highlight"><pre><span></span><code><span class="o">&gt;&gt;&gt;</span> <span class="kn">from</span> <span class="nn">sklearn.ensemble</span> <span class="kn">import</span> <span class="n">ExtraTreesClassifier</span>
<span class="o">&gt;&gt;&gt;</span> <span class="kn">from</span> <span class="nn">sklearn.datasets</span> <span class="kn">import</span> <span class="n">make_classification</span>
<span class="o">&gt;&gt;&gt;</span> <span class="n">X</span><span class="p">,</span> <span class="n">y</span> <span class="o">=</span> <span class="n">make_classification</span><span class="p">(</span><span class="n">n_features</span><span class="o">=</span><span class="mi">4</span><span class="p">,</span> <span class="n">random_state</span><span class="o">=</span><span class="mi">0</span><span class="p">)</span>
<span class="o">&gt;&gt;&gt;</span> <span class="n">clf</span> <span class="o">=</span> <span class="n">ExtraTreesClassifier</span><span class="p">(</span><span class="n">n_estimators</span><span class="o">=</span><span class="mi">100</span><span class="p">,</span> <span class="n">random_state</span><span class="o">=</span><span class="mi">0</span><span class="p">)</span>
<span class="o">&gt;&gt;&gt;</span> <span class="n">clf</span><span class="o">.</span><span class="n">fit</span><span class="p">(</span><span class="n">X</span><span class="p">,</span> <span class="n">y</span><span class="p">)</span>
<span class="n">ExtraTreesClassifier</span><span class="p">(</span><span class="n">random_state</span><span class="o">=</span><span class="mi">0</span><span class="p">)</span>
<span class="o">&gt;&gt;&gt;</span> <span class="n">clf</span><span class="o">.</span><span class="n">predict</span><span class="p">([[</span><span class="mi">0</span><span class="p">,</span> <span class="mi">0</span><span class="p">,</span> <span class="mi">0</span><span class="p">,</span> <span class="mi">0</span><span class="p">]])</span>
<span class="n">array</span><span class="p">([</span><span class="mi">1</span><span class="p">])</span>
</code></pre></div>

</details>
<h3 id="get_item_5">get_item<a class="headerlink" href="#get_item_5" title="Permanent link">&para;</a></h3>
<details class="note" open="open"><summary>method get_item</summary><div class="highlight"><pre><span></span><code><span class="k">val</span> <span class="n">get_item</span> <span class="o">:</span>
  <span class="n">index</span><span class="o">:</span><span class="nn">Py</span><span class="p">.</span><span class="nn">Object</span><span class="p">.</span><span class="n">t</span> <span class="o">-&gt;</span>
  <span class="o">[&gt;</span> <span class="n">tag</span><span class="o">]</span> <span class="nn">Obj</span><span class="p">.</span><span class="n">t</span> <span class="o">-&gt;</span>
  <span class="nn">Py</span><span class="p">.</span><span class="nn">Object</span><span class="p">.</span><span class="n">t</span>
</code></pre></div>

<p>Return the index'th estimator in the ensemble.</p>
</details>
<h3 id="iter_5">iter<a class="headerlink" href="#iter_5" title="Permanent link">&para;</a></h3>
<details class="note" open="open"><summary>method iter</summary><div class="highlight"><pre><span></span><code><span class="k">val</span> <span class="n">iter</span> <span class="o">:</span>
  <span class="o">[&gt;</span> <span class="n">tag</span><span class="o">]</span> <span class="nn">Obj</span><span class="p">.</span><span class="n">t</span> <span class="o">-&gt;</span>
  <span class="nn">Dict</span><span class="p">.</span><span class="n">t</span> <span class="nn">Seq</span><span class="p">.</span><span class="n">t</span>
</code></pre></div>

<p>Return iterator over estimators in the ensemble.</p>
</details>
<h3 id="apply">apply<a class="headerlink" href="#apply" title="Permanent link">&para;</a></h3>
<details class="note" open="open"><summary>method apply</summary><div class="highlight"><pre><span></span><code><span class="k">val</span> <span class="n">apply</span> <span class="o">:</span>
  <span class="n">x</span><span class="o">:[&gt;`</span><span class="nc">ArrayLike</span><span class="o">]</span> <span class="nn">Np</span><span class="p">.</span><span class="nn">Obj</span><span class="p">.</span><span class="n">t</span> <span class="o">-&gt;</span>
  <span class="o">[&gt;</span> <span class="n">tag</span><span class="o">]</span> <span class="nn">Obj</span><span class="p">.</span><span class="n">t</span> <span class="o">-&gt;</span>
  <span class="o">[&gt;`</span><span class="nc">ArrayLike</span><span class="o">]</span> <span class="nn">Np</span><span class="p">.</span><span class="nn">Obj</span><span class="p">.</span><span class="n">t</span>
</code></pre></div>

<p>Apply trees in the forest to X, return leaf indices.</p>
<h4>Parameters</h4>
<ul>
<li><strong>X : {array-like, sparse matrix} of shape (n_samples, n_features)</strong>
    The input samples. Internally, its dtype will be converted to
    <code>dtype=np.float32</code>. If a sparse matrix is provided, it will be
    converted into a sparse <code>csr_matrix</code>.</li>
</ul>
<h4>Returns</h4>
<ul>
<li><strong>X_leaves : ndarray of shape (n_samples, n_estimators)</strong>
    For each datapoint x in X and for each tree in the forest,
    return the index of the leaf x ends up in.</li>
</ul>
</details>
<h3 id="decision_path">decision_path<a class="headerlink" href="#decision_path" title="Permanent link">&para;</a></h3>
<details class="note" open="open"><summary>method decision_path</summary><div class="highlight"><pre><span></span><code><span class="k">val</span> <span class="n">decision_path</span> <span class="o">:</span>
  <span class="n">x</span><span class="o">:[&gt;`</span><span class="nc">ArrayLike</span><span class="o">]</span> <span class="nn">Np</span><span class="p">.</span><span class="nn">Obj</span><span class="p">.</span><span class="n">t</span> <span class="o">-&gt;</span>
  <span class="o">[&gt;</span> <span class="n">tag</span><span class="o">]</span> <span class="nn">Obj</span><span class="p">.</span><span class="n">t</span> <span class="o">-&gt;</span>
  <span class="o">([`</span><span class="nc">ArrayLike</span><span class="o">|`</span><span class="nc">Object</span><span class="o">|`</span><span class="nc">Spmatrix</span><span class="o">]</span> <span class="nn">Np</span><span class="p">.</span><span class="nn">Obj</span><span class="p">.</span><span class="n">t</span> <span class="o">*</span> <span class="o">[&gt;`</span><span class="nc">ArrayLike</span><span class="o">]</span> <span class="nn">Np</span><span class="p">.</span><span class="nn">Obj</span><span class="p">.</span><span class="n">t</span><span class="o">)</span>
</code></pre></div>

<p>Return the decision path in the forest.</p>
<p>.. versionadded:: 0.18</p>
<h4>Parameters</h4>
<ul>
<li><strong>X : {array-like, sparse matrix} of shape (n_samples, n_features)</strong>
    The input samples. Internally, its dtype will be converted to
    <code>dtype=np.float32</code>. If a sparse matrix is provided, it will be
    converted into a sparse <code>csr_matrix</code>.</li>
</ul>
<h4>Returns</h4>
<ul>
<li>
<p><strong>indicator : sparse matrix of shape (n_samples, n_nodes)</strong>
    Return a node indicator matrix where non zero elements indicates
    that the samples goes through the nodes. The matrix is of CSR
    format.</p>
</li>
<li>
<p><strong>n_nodes_ptr : ndarray of shape (n_estimators + 1,)</strong>
    The columns from indicator[n_nodes_ptr[i]:n_nodes_ptr[i+1]]
    gives the indicator value for the i-th estimator.</p>
</li>
</ul>
</details>
<h3 id="fit_4">fit<a class="headerlink" href="#fit_4" title="Permanent link">&para;</a></h3>
<details class="note" open="open"><summary>method fit</summary><div class="highlight"><pre><span></span><code><span class="k">val</span> <span class="n">fit</span> <span class="o">:</span>
  <span class="o">?</span><span class="n">sample_weight</span><span class="o">:[&gt;`</span><span class="nc">ArrayLike</span><span class="o">]</span> <span class="nn">Np</span><span class="p">.</span><span class="nn">Obj</span><span class="p">.</span><span class="n">t</span> <span class="o">-&gt;</span>
  <span class="n">x</span><span class="o">:[&gt;`</span><span class="nc">ArrayLike</span><span class="o">]</span> <span class="nn">Np</span><span class="p">.</span><span class="nn">Obj</span><span class="p">.</span><span class="n">t</span> <span class="o">-&gt;</span>
  <span class="n">y</span><span class="o">:[&gt;`</span><span class="nc">ArrayLike</span><span class="o">]</span> <span class="nn">Np</span><span class="p">.</span><span class="nn">Obj</span><span class="p">.</span><span class="n">t</span> <span class="o">-&gt;</span>
  <span class="o">[&gt;</span> <span class="n">tag</span><span class="o">]</span> <span class="nn">Obj</span><span class="p">.</span><span class="n">t</span> <span class="o">-&gt;</span>
  <span class="n">t</span>
</code></pre></div>

<p>Build a forest of trees from the training set (X, y).</p>
<h4>Parameters</h4>
<ul>
<li>
<p><strong>X : {array-like, sparse matrix} of shape (n_samples, n_features)</strong>
    The training input samples. Internally, its dtype will be converted
    to <code>dtype=np.float32</code>. If a sparse matrix is provided, it will be
    converted into a sparse <code>csc_matrix</code>.</p>
</li>
<li>
<p><strong>y : array-like of shape (n_samples,) or (n_samples, n_outputs)</strong>
    The target values (class labels in classification, real numbers in
    regression).</p>
</li>
<li>
<p><strong>sample_weight : array-like of shape (n_samples,), default=None</strong>
    Sample weights. If None, then samples are equally weighted. Splits
    that would create child nodes with net zero or negative weight are
    ignored while searching for a split in each node. In the case of
    classification, splits are also ignored if they would result in any
    single class carrying a negative weight in either child node.</p>
</li>
</ul>
<h4>Returns</h4>
<ul>
<li><strong>self : object</strong></li>
</ul>
</details>
<h3 id="get_params_5">get_params<a class="headerlink" href="#get_params_5" title="Permanent link">&para;</a></h3>
<details class="note" open="open"><summary>method get_params</summary><div class="highlight"><pre><span></span><code><span class="k">val</span> <span class="n">get_params</span> <span class="o">:</span>
  <span class="o">?</span><span class="n">deep</span><span class="o">:</span><span class="kt">bool</span> <span class="o">-&gt;</span>
  <span class="o">[&gt;</span> <span class="n">tag</span><span class="o">]</span> <span class="nn">Obj</span><span class="p">.</span><span class="n">t</span> <span class="o">-&gt;</span>
  <span class="nn">Dict</span><span class="p">.</span><span class="n">t</span>
</code></pre></div>

<p>Get parameters for this estimator.</p>
<h4>Parameters</h4>
<ul>
<li><strong>deep : bool, default=True</strong>
    If True, will return the parameters for this estimator and
    contained subobjects that are estimators.</li>
</ul>
<h4>Returns</h4>
<ul>
<li><strong>params : mapping of string to any</strong>
    Parameter names mapped to their values.</li>
</ul>
</details>
<h3 id="predict_4">predict<a class="headerlink" href="#predict_4" title="Permanent link">&para;</a></h3>
<details class="note" open="open"><summary>method predict</summary><div class="highlight"><pre><span></span><code><span class="k">val</span> <span class="n">predict</span> <span class="o">:</span>
  <span class="n">x</span><span class="o">:[&gt;`</span><span class="nc">ArrayLike</span><span class="o">]</span> <span class="nn">Np</span><span class="p">.</span><span class="nn">Obj</span><span class="p">.</span><span class="n">t</span> <span class="o">-&gt;</span>
  <span class="o">[&gt;</span> <span class="n">tag</span><span class="o">]</span> <span class="nn">Obj</span><span class="p">.</span><span class="n">t</span> <span class="o">-&gt;</span>
  <span class="o">[&gt;`</span><span class="nc">ArrayLike</span><span class="o">]</span> <span class="nn">Np</span><span class="p">.</span><span class="nn">Obj</span><span class="p">.</span><span class="n">t</span>
</code></pre></div>

<p>Predict class for X.</p>
<p>The predicted class of an input sample is a vote by the trees in
the forest, weighted by their probability estimates. That is,
the predicted class is the one with highest mean probability
estimate across the trees.</p>
<h4>Parameters</h4>
<ul>
<li><strong>X : {array-like, sparse matrix} of shape (n_samples, n_features)</strong>
    The input samples. Internally, its dtype will be converted to
    <code>dtype=np.float32</code>. If a sparse matrix is provided, it will be
    converted into a sparse <code>csr_matrix</code>.</li>
</ul>
<h4>Returns</h4>
<ul>
<li><strong>y : ndarray of shape (n_samples,) or (n_samples, n_outputs)</strong>
    The predicted classes.</li>
</ul>
</details>
<h3 id="predict_log_proba_2">predict_log_proba<a class="headerlink" href="#predict_log_proba_2" title="Permanent link">&para;</a></h3>
<details class="note" open="open"><summary>method predict_log_proba</summary><div class="highlight"><pre><span></span><code><span class="k">val</span> <span class="n">predict_log_proba</span> <span class="o">:</span>
  <span class="n">x</span><span class="o">:[&gt;`</span><span class="nc">ArrayLike</span><span class="o">]</span> <span class="nn">Np</span><span class="p">.</span><span class="nn">Obj</span><span class="p">.</span><span class="n">t</span> <span class="o">-&gt;</span>
  <span class="o">[&gt;</span> <span class="n">tag</span><span class="o">]</span> <span class="nn">Obj</span><span class="p">.</span><span class="n">t</span> <span class="o">-&gt;</span>
  <span class="nn">Py</span><span class="p">.</span><span class="nn">Object</span><span class="p">.</span><span class="n">t</span>
</code></pre></div>

<p>Predict class log-probabilities for X.</p>
<p>The predicted class log-probabilities of an input sample is computed as
the log of the mean predicted class probabilities of the trees in the
forest.</p>
<h4>Parameters</h4>
<ul>
<li><strong>X : {array-like, sparse matrix} of shape (n_samples, n_features)</strong>
    The input samples. Internally, its dtype will be converted to
    <code>dtype=np.float32</code>. If a sparse matrix is provided, it will be
    converted into a sparse <code>csr_matrix</code>.</li>
</ul>
<h4>Returns</h4>
<ul>
<li><strong>p : ndarray of shape (n_samples, n_classes), or a list of n_outputs</strong>
    such arrays if n_outputs &gt; 1.
    The class probabilities of the input samples. The order of the
    classes corresponds to that in the attribute :term:<code>classes_</code>.</li>
</ul>
</details>
<h3 id="predict_proba_2">predict_proba<a class="headerlink" href="#predict_proba_2" title="Permanent link">&para;</a></h3>
<details class="note" open="open"><summary>method predict_proba</summary><div class="highlight"><pre><span></span><code><span class="k">val</span> <span class="n">predict_proba</span> <span class="o">:</span>
  <span class="n">x</span><span class="o">:[&gt;`</span><span class="nc">ArrayLike</span><span class="o">]</span> <span class="nn">Np</span><span class="p">.</span><span class="nn">Obj</span><span class="p">.</span><span class="n">t</span> <span class="o">-&gt;</span>
  <span class="o">[&gt;</span> <span class="n">tag</span><span class="o">]</span> <span class="nn">Obj</span><span class="p">.</span><span class="n">t</span> <span class="o">-&gt;</span>
  <span class="o">[&gt;`</span><span class="nc">ArrayLike</span><span class="o">]</span> <span class="nn">Np</span><span class="p">.</span><span class="nn">Obj</span><span class="p">.</span><span class="n">t</span>
</code></pre></div>

<p>Predict class probabilities for X.</p>
<p>The predicted class probabilities of an input sample are computed as
the mean predicted class probabilities of the trees in the forest.
The class probability of a single tree is the fraction of samples of
the same class in a leaf.</p>
<h4>Parameters</h4>
<ul>
<li><strong>X : {array-like, sparse matrix} of shape (n_samples, n_features)</strong>
    The input samples. Internally, its dtype will be converted to
    <code>dtype=np.float32</code>. If a sparse matrix is provided, it will be
    converted into a sparse <code>csr_matrix</code>.</li>
</ul>
<h4>Returns</h4>
<ul>
<li><strong>p : ndarray of shape (n_samples, n_classes), or a list of n_outputs</strong>
    such arrays if n_outputs &gt; 1.
    The class probabilities of the input samples. The order of the
    classes corresponds to that in the attribute :term:<code>classes_</code>.</li>
</ul>
</details>
<h3 id="score_4">score<a class="headerlink" href="#score_4" title="Permanent link">&para;</a></h3>
<details class="note" open="open"><summary>method score</summary><div class="highlight"><pre><span></span><code><span class="k">val</span> <span class="n">score</span> <span class="o">:</span>
  <span class="o">?</span><span class="n">sample_weight</span><span class="o">:[&gt;`</span><span class="nc">ArrayLike</span><span class="o">]</span> <span class="nn">Np</span><span class="p">.</span><span class="nn">Obj</span><span class="p">.</span><span class="n">t</span> <span class="o">-&gt;</span>
  <span class="n">x</span><span class="o">:[&gt;`</span><span class="nc">ArrayLike</span><span class="o">]</span> <span class="nn">Np</span><span class="p">.</span><span class="nn">Obj</span><span class="p">.</span><span class="n">t</span> <span class="o">-&gt;</span>
  <span class="n">y</span><span class="o">:[&gt;`</span><span class="nc">ArrayLike</span><span class="o">]</span> <span class="nn">Np</span><span class="p">.</span><span class="nn">Obj</span><span class="p">.</span><span class="n">t</span> <span class="o">-&gt;</span>
  <span class="o">[&gt;</span> <span class="n">tag</span><span class="o">]</span> <span class="nn">Obj</span><span class="p">.</span><span class="n">t</span> <span class="o">-&gt;</span>
  <span class="kt">float</span>
</code></pre></div>

<p>Return the mean accuracy on the given test data and labels.</p>
<p>In multi-label classification, this is the subset accuracy
which is a harsh metric since you require for each sample that
each label set be correctly predicted.</p>
<h4>Parameters</h4>
<ul>
<li>
<p><strong>X : array-like of shape (n_samples, n_features)</strong>
    Test samples.</p>
</li>
<li>
<p><strong>y : array-like of shape (n_samples,) or (n_samples, n_outputs)</strong>
    True labels for X.</p>
</li>
<li>
<p><strong>sample_weight : array-like of shape (n_samples,), default=None</strong>
    Sample weights.</p>
</li>
</ul>
<h4>Returns</h4>
<ul>
<li><strong>score : float</strong>
    Mean accuracy of self.predict(X) wrt. y.</li>
</ul>
</details>
<h3 id="set_params_5">set_params<a class="headerlink" href="#set_params_5" title="Permanent link">&para;</a></h3>
<details class="note" open="open"><summary>method set_params</summary><div class="highlight"><pre><span></span><code><span class="k">val</span> <span class="n">set_params</span> <span class="o">:</span>
  <span class="o">?</span><span class="n">params</span><span class="o">:(</span><span class="kt">string</span> <span class="o">*</span> <span class="nn">Py</span><span class="p">.</span><span class="nn">Object</span><span class="p">.</span><span class="n">t</span><span class="o">)</span> <span class="kt">list</span> <span class="o">-&gt;</span>
  <span class="o">[&gt;</span> <span class="n">tag</span><span class="o">]</span> <span class="nn">Obj</span><span class="p">.</span><span class="n">t</span> <span class="o">-&gt;</span>
  <span class="n">t</span>
</code></pre></div>

<p>Set the parameters of this estimator.</p>
<p>The method works on simple estimators as well as on nested objects
(such as pipelines). The latter have parameters of the form
<code>&lt;component&gt;__&lt;parameter&gt;</code> so that it's possible to update each
component of a nested object.</p>
<h4>Parameters</h4>
<ul>
<li><strong>**params : dict</strong>
    Estimator parameters.</li>
</ul>
<h4>Returns</h4>
<ul>
<li><strong>self : object</strong>
    Estimator instance.</li>
</ul>
</details>
<h3 id="base_estimator__5">base_estimator_<a class="headerlink" href="#base_estimator__5" title="Permanent link">&para;</a></h3>
<details class="note" open="open"><summary>attribute base_estimator_</summary><div class="highlight"><pre><span></span><code><span class="k">val</span> <span class="n">base_estimator_</span> <span class="o">:</span> <span class="n">t</span> <span class="o">-&gt;</span> <span class="nn">Py</span><span class="p">.</span><span class="nn">Object</span><span class="p">.</span><span class="n">t</span>
<span class="k">val</span> <span class="n">base_estimator_opt</span> <span class="o">:</span> <span class="n">t</span> <span class="o">-&gt;</span> <span class="o">(</span><span class="nn">Py</span><span class="p">.</span><span class="nn">Object</span><span class="p">.</span><span class="n">t</span><span class="o">)</span> <span class="n">option</span>
</code></pre></div>

<p>This attribute is documented in <code>create</code> above. The first version raises Not_found
if the attribute is None. The _opt version returns an option.</p>
</details>
<h3 id="estimators__5">estimators_<a class="headerlink" href="#estimators__5" title="Permanent link">&para;</a></h3>
<details class="note" open="open"><summary>attribute estimators_</summary><div class="highlight"><pre><span></span><code><span class="k">val</span> <span class="n">estimators_</span> <span class="o">:</span> <span class="n">t</span> <span class="o">-&gt;</span> <span class="nn">Py</span><span class="p">.</span><span class="nn">Object</span><span class="p">.</span><span class="n">t</span>
<span class="k">val</span> <span class="n">estimators_opt</span> <span class="o">:</span> <span class="n">t</span> <span class="o">-&gt;</span> <span class="o">(</span><span class="nn">Py</span><span class="p">.</span><span class="nn">Object</span><span class="p">.</span><span class="n">t</span><span class="o">)</span> <span class="n">option</span>
</code></pre></div>

<p>This attribute is documented in <code>create</code> above. The first version raises Not_found
if the attribute is None. The _opt version returns an option.</p>
</details>
<h3 id="classes__2">classes_<a class="headerlink" href="#classes__2" title="Permanent link">&para;</a></h3>
<details class="note" open="open"><summary>attribute classes_</summary><div class="highlight"><pre><span></span><code><span class="k">val</span> <span class="n">classes_</span> <span class="o">:</span> <span class="n">t</span> <span class="o">-&gt;</span> <span class="o">[&gt;`</span><span class="nc">ArrayLike</span><span class="o">]</span> <span class="nn">Np</span><span class="p">.</span><span class="nn">Obj</span><span class="p">.</span><span class="n">t</span>
<span class="k">val</span> <span class="n">classes_opt</span> <span class="o">:</span> <span class="n">t</span> <span class="o">-&gt;</span> <span class="o">([&gt;`</span><span class="nc">ArrayLike</span><span class="o">]</span> <span class="nn">Np</span><span class="p">.</span><span class="nn">Obj</span><span class="p">.</span><span class="n">t</span><span class="o">)</span> <span class="n">option</span>
</code></pre></div>

<p>This attribute is documented in <code>create</code> above. The first version raises Not_found
if the attribute is None. The _opt version returns an option.</p>
</details>
<h3 id="n_classes__2">n_classes_<a class="headerlink" href="#n_classes__2" title="Permanent link">&para;</a></h3>
<details class="note" open="open"><summary>attribute n_classes_</summary><div class="highlight"><pre><span></span><code><span class="k">val</span> <span class="n">n_classes_</span> <span class="o">:</span> <span class="n">t</span> <span class="o">-&gt;</span> <span class="nn">Py</span><span class="p">.</span><span class="nn">Object</span><span class="p">.</span><span class="n">t</span>
<span class="k">val</span> <span class="n">n_classes_opt</span> <span class="o">:</span> <span class="n">t</span> <span class="o">-&gt;</span> <span class="o">(</span><span class="nn">Py</span><span class="p">.</span><span class="nn">Object</span><span class="p">.</span><span class="n">t</span><span class="o">)</span> <span class="n">option</span>
</code></pre></div>

<p>This attribute is documented in <code>create</code> above. The first version raises Not_found
if the attribute is None. The _opt version returns an option.</p>
</details>
<h3 id="feature_importances__2">feature_importances_<a class="headerlink" href="#feature_importances__2" title="Permanent link">&para;</a></h3>
<details class="note" open="open"><summary>attribute feature_importances_</summary><div class="highlight"><pre><span></span><code><span class="k">val</span> <span class="n">feature_importances_</span> <span class="o">:</span> <span class="n">t</span> <span class="o">-&gt;</span> <span class="o">[&gt;`</span><span class="nc">ArrayLike</span><span class="o">]</span> <span class="nn">Np</span><span class="p">.</span><span class="nn">Obj</span><span class="p">.</span><span class="n">t</span>
<span class="k">val</span> <span class="n">feature_importances_opt</span> <span class="o">:</span> <span class="n">t</span> <span class="o">-&gt;</span> <span class="o">([&gt;`</span><span class="nc">ArrayLike</span><span class="o">]</span> <span class="nn">Np</span><span class="p">.</span><span class="nn">Obj</span><span class="p">.</span><span class="n">t</span><span class="o">)</span> <span class="n">option</span>
</code></pre></div>

<p>This attribute is documented in <code>create</code> above. The first version raises Not_found
if the attribute is None. The _opt version returns an option.</p>
</details>
<h3 id="warning_2">warning<a class="headerlink" href="#warning_2" title="Permanent link">&para;</a></h3>
<details class="note" open="open"><summary>attribute warning</summary><div class="highlight"><pre><span></span><code><span class="k">val</span> <span class="n">warning</span> <span class="o">:</span> <span class="n">t</span> <span class="o">-&gt;</span> <span class="nn">Py</span><span class="p">.</span><span class="nn">Object</span><span class="p">.</span><span class="n">t</span>
<span class="k">val</span> <span class="n">warning_opt</span> <span class="o">:</span> <span class="n">t</span> <span class="o">-&gt;</span> <span class="o">(</span><span class="nn">Py</span><span class="p">.</span><span class="nn">Object</span><span class="p">.</span><span class="n">t</span><span class="o">)</span> <span class="n">option</span>
</code></pre></div>

<p>This attribute is documented in <code>create</code> above. The first version raises Not_found
if the attribute is None. The _opt version returns an option.</p>
</details>
<h3 id="n_features__2">n_features_<a class="headerlink" href="#n_features__2" title="Permanent link">&para;</a></h3>
<details class="note" open="open"><summary>attribute n_features_</summary><div class="highlight"><pre><span></span><code><span class="k">val</span> <span class="n">n_features_</span> <span class="o">:</span> <span class="n">t</span> <span class="o">-&gt;</span> <span class="kt">int</span>
<span class="k">val</span> <span class="n">n_features_opt</span> <span class="o">:</span> <span class="n">t</span> <span class="o">-&gt;</span> <span class="o">(</span><span class="kt">int</span><span class="o">)</span> <span class="n">option</span>
</code></pre></div>

<p>This attribute is documented in <code>create</code> above. The first version raises Not_found
if the attribute is None. The _opt version returns an option.</p>
</details>
<h3 id="n_outputs_">n_outputs_<a class="headerlink" href="#n_outputs_" title="Permanent link">&para;</a></h3>
<details class="note" open="open"><summary>attribute n_outputs_</summary><div class="highlight"><pre><span></span><code><span class="k">val</span> <span class="n">n_outputs_</span> <span class="o">:</span> <span class="n">t</span> <span class="o">-&gt;</span> <span class="kt">int</span>
<span class="k">val</span> <span class="n">n_outputs_opt</span> <span class="o">:</span> <span class="n">t</span> <span class="o">-&gt;</span> <span class="o">(</span><span class="kt">int</span><span class="o">)</span> <span class="n">option</span>
</code></pre></div>

<p>This attribute is documented in <code>create</code> above. The first version raises Not_found
if the attribute is None. The _opt version returns an option.</p>
</details>
<h3 id="oob_score__2">oob_score_<a class="headerlink" href="#oob_score__2" title="Permanent link">&para;</a></h3>
<details class="note" open="open"><summary>attribute oob_score_</summary><div class="highlight"><pre><span></span><code><span class="k">val</span> <span class="n">oob_score_</span> <span class="o">:</span> <span class="n">t</span> <span class="o">-&gt;</span> <span class="kt">float</span>
<span class="k">val</span> <span class="n">oob_score_opt</span> <span class="o">:</span> <span class="n">t</span> <span class="o">-&gt;</span> <span class="o">(</span><span class="kt">float</span><span class="o">)</span> <span class="n">option</span>
</code></pre></div>

<p>This attribute is documented in <code>create</code> above. The first version raises Not_found
if the attribute is None. The _opt version returns an option.</p>
</details>
<h3 id="oob_decision_function__1">oob_decision_function_<a class="headerlink" href="#oob_decision_function__1" title="Permanent link">&para;</a></h3>
<details class="note" open="open"><summary>attribute oob_decision_function_</summary><div class="highlight"><pre><span></span><code><span class="k">val</span> <span class="n">oob_decision_function_</span> <span class="o">:</span> <span class="n">t</span> <span class="o">-&gt;</span> <span class="o">[&gt;`</span><span class="nc">ArrayLike</span><span class="o">]</span> <span class="nn">Np</span><span class="p">.</span><span class="nn">Obj</span><span class="p">.</span><span class="n">t</span>
<span class="k">val</span> <span class="n">oob_decision_function_opt</span> <span class="o">:</span> <span class="n">t</span> <span class="o">-&gt;</span> <span class="o">([&gt;`</span><span class="nc">ArrayLike</span><span class="o">]</span> <span class="nn">Np</span><span class="p">.</span><span class="nn">Obj</span><span class="p">.</span><span class="n">t</span><span class="o">)</span> <span class="n">option</span>
</code></pre></div>

<p>This attribute is documented in <code>create</code> above. The first version raises Not_found
if the attribute is None. The _opt version returns an option.</p>
</details>
<h3 id="to_string_5">to_string<a class="headerlink" href="#to_string_5" title="Permanent link">&para;</a></h3>
<details class="note" open="open"><summary>method to_string</summary><div class="highlight"><pre><span></span><code><span class="k">val</span> <span class="n">to_string</span><span class="o">:</span> <span class="n">t</span> <span class="o">-&gt;</span> <span class="kt">string</span>
</code></pre></div>

<p>Print the object to a human-readable representation.</p>
</details>
<h3 id="show_5">show<a class="headerlink" href="#show_5" title="Permanent link">&para;</a></h3>
<details class="note" open="open"><summary>method show</summary><div class="highlight"><pre><span></span><code><span class="k">val</span> <span class="n">show</span><span class="o">:</span> <span class="n">t</span> <span class="o">-&gt;</span> <span class="kt">string</span>
</code></pre></div>

<p>Print the object to a human-readable representation.</p>
</details>
<h3 id="pp_5">pp<a class="headerlink" href="#pp_5" title="Permanent link">&para;</a></h3>
<details class="note" open="open"><summary>method pp</summary><div class="highlight"><pre><span></span><code><span class="k">val</span> <span class="n">pp</span><span class="o">:</span> <span class="nn">Format</span><span class="p">.</span><span class="n">formatter</span> <span class="o">-&gt;</span> <span class="n">t</span> <span class="o">-&gt;</span> <span class="kt">unit</span>
</code></pre></div>

<p>Pretty-print the object to a formatter.</p>
</details>
<h2 id="extratreesregressor">ExtraTreesRegressor<a class="headerlink" href="#extratreesregressor" title="Permanent link">&para;</a></h2>
<p>Module <code>Sklearn.​Ensemble.​ExtraTreesRegressor</code> wraps Python class <a href="https://scikit-learn.org/stable/modules/generated/sklearn.ensemble.ExtraTreesRegressor.html"><code>sklearn.ensemble.ExtraTreesRegressor</code></a>.</p>
<div class="highlight"><pre><span></span><code><span class="k">type</span> <span class="n">t</span>
</code></pre></div>

<h3 id="create_5">create<a class="headerlink" href="#create_5" title="Permanent link">&para;</a></h3>
<details class="note" open="open"><summary>constructor and attributes create</summary><div class="highlight"><pre><span></span><code><span class="k">val</span> <span class="n">create</span> <span class="o">:</span>
  <span class="o">?</span><span class="n">n_estimators</span><span class="o">:</span><span class="kt">int</span> <span class="o">-&gt;</span>
  <span class="o">?</span><span class="n">criterion</span><span class="o">:[`</span><span class="nc">Mse</span> <span class="o">|</span> <span class="o">`</span><span class="nc">Mae</span><span class="o">]</span> <span class="o">-&gt;</span>
  <span class="o">?</span><span class="n">max_depth</span><span class="o">:</span><span class="kt">int</span> <span class="o">-&gt;</span>
  <span class="o">?</span><span class="n">min_samples_split</span><span class="o">:[`</span><span class="nc">F</span> <span class="k">of</span> <span class="kt">float</span> <span class="o">|</span> <span class="o">`</span><span class="nc">I</span> <span class="k">of</span> <span class="kt">int</span><span class="o">]</span> <span class="o">-&gt;</span>
  <span class="o">?</span><span class="n">min_samples_leaf</span><span class="o">:[`</span><span class="nc">F</span> <span class="k">of</span> <span class="kt">float</span> <span class="o">|</span> <span class="o">`</span><span class="nc">I</span> <span class="k">of</span> <span class="kt">int</span><span class="o">]</span> <span class="o">-&gt;</span>
  <span class="o">?</span><span class="n">min_weight_fraction_leaf</span><span class="o">:</span><span class="kt">float</span> <span class="o">-&gt;</span>
  <span class="o">?</span><span class="n">max_features</span><span class="o">:[`</span><span class="nc">PyObject</span> <span class="k">of</span> <span class="nn">Py</span><span class="p">.</span><span class="nn">Object</span><span class="p">.</span><span class="n">t</span> <span class="o">|</span> <span class="o">`</span><span class="nc">Sqrt</span> <span class="o">|</span> <span class="o">`</span><span class="nc">F</span> <span class="k">of</span> <span class="kt">float</span><span class="o">]</span> <span class="o">-&gt;</span>
  <span class="o">?</span><span class="n">max_leaf_nodes</span><span class="o">:</span><span class="kt">int</span> <span class="o">-&gt;</span>
  <span class="o">?</span><span class="n">min_impurity_decrease</span><span class="o">:</span><span class="kt">float</span> <span class="o">-&gt;</span>
  <span class="o">?</span><span class="n">min_impurity_split</span><span class="o">:</span><span class="kt">float</span> <span class="o">-&gt;</span>
  <span class="o">?</span><span class="n">bootstrap</span><span class="o">:</span><span class="kt">bool</span> <span class="o">-&gt;</span>
  <span class="o">?</span><span class="n">oob_score</span><span class="o">:</span><span class="kt">bool</span> <span class="o">-&gt;</span>
  <span class="o">?</span><span class="n">n_jobs</span><span class="o">:</span><span class="kt">int</span> <span class="o">-&gt;</span>
  <span class="o">?</span><span class="n">random_state</span><span class="o">:</span><span class="kt">int</span> <span class="o">-&gt;</span>
  <span class="o">?</span><span class="n">verbose</span><span class="o">:</span><span class="kt">int</span> <span class="o">-&gt;</span>
  <span class="o">?</span><span class="n">warm_start</span><span class="o">:</span><span class="kt">bool</span> <span class="o">-&gt;</span>
  <span class="o">?</span><span class="n">ccp_alpha</span><span class="o">:</span><span class="kt">float</span> <span class="o">-&gt;</span>
  <span class="o">?</span><span class="n">max_samples</span><span class="o">:[`</span><span class="nc">F</span> <span class="k">of</span> <span class="kt">float</span> <span class="o">|</span> <span class="o">`</span><span class="nc">I</span> <span class="k">of</span> <span class="kt">int</span><span class="o">]</span> <span class="o">-&gt;</span>
  <span class="kt">unit</span> <span class="o">-&gt;</span>
  <span class="n">t</span>
</code></pre></div>

<p>An extra-trees regressor.</p>
<p>This class implements a meta estimator that fits a number of
randomized decision trees (a.k.a. extra-trees) on various sub-samples
of the dataset and uses averaging to improve the predictive accuracy
and control over-fitting.</p>
<p>Read more in the :ref:<code>User Guide &lt;forest&gt;</code>.</p>
<h4>Parameters</h4>
<ul>
<li>
<p><strong>n_estimators : int, default=100</strong>
    The number of trees in the forest.</p>
<p>.. versionchanged:: 0.22
   The default value of <code>n_estimators</code> changed from 10 to 100
   in 0.22.</p>
</li>
<li>
<p><strong>criterion : {'mse', 'mae'}, default='mse'</strong>
    The function to measure the quality of a split. Supported criteria
    are 'mse' for the mean squared error, which is equal to variance
    reduction as feature selection criterion, and 'mae' for the mean
    absolute error.</p>
<p>.. versionadded:: 0.18
   Mean Absolute Error (MAE) criterion.</p>
</li>
<li>
<p><strong>max_depth : int, default=None</strong>
    The maximum depth of the tree. If None, then nodes are expanded until
    all leaves are pure or until all leaves contain less than
    min_samples_split samples.</p>
</li>
<li>
<p><strong>min_samples_split : int or float, default=2</strong>
    The minimum number of samples required to split an internal node:</p>
<ul>
<li>If int, then consider <code>min_samples_split</code> as the minimum number.</li>
<li>If float, then <code>min_samples_split</code> is a fraction and
  <code>ceil(min_samples_split * n_samples)</code> are the minimum
  number of samples for each split.</li>
</ul>
<p>.. versionchanged:: 0.18
   Added float values for fractions.</p>
</li>
<li>
<p><strong>min_samples_leaf : int or float, default=1</strong>
    The minimum number of samples required to be at a leaf node.
    A split point at any depth will only be considered if it leaves at
    least <code>min_samples_leaf</code> training samples in each of the left and
    right branches.  This may have the effect of smoothing the model,
    especially in regression.</p>
<ul>
<li>If int, then consider <code>min_samples_leaf</code> as the minimum number.</li>
<li>If float, then <code>min_samples_leaf</code> is a fraction and
  <code>ceil(min_samples_leaf * n_samples)</code> are the minimum
  number of samples for each node.</li>
</ul>
<p>.. versionchanged:: 0.18
   Added float values for fractions.</p>
</li>
<li>
<p><strong>min_weight_fraction_leaf : float, default=0.0</strong>
    The minimum weighted fraction of the sum total of weights (of all
    the input samples) required to be at a leaf node. Samples have
    equal weight when sample_weight is not provided.</p>
</li>
<li>
<p><strong>max_features : {'auto', 'sqrt', 'log2'} int or float, default='auto'</strong>
    The number of features to consider when looking for the best split:</p>
<ul>
<li>If int, then consider <code>max_features</code> features at each split.</li>
<li>If float, then <code>max_features</code> is a fraction and
  <code>int(max_features * n_features)</code> features are considered at each
  split.</li>
<li>If 'auto', then <code>max_features=n_features</code>.</li>
<li>If 'sqrt', then <code>max_features=sqrt(n_features)</code>.</li>
<li>If 'log2', then <code>max_features=log2(n_features)</code>.</li>
<li>If None, then <code>max_features=n_features</code>.</li>
</ul>
</li>
<li>
<p><strong>Note: the search for a split does not stop until at least one</strong>
    valid partition of the node samples is found, even if it requires to
    effectively inspect more than <code>max_features</code> features.</p>
</li>
<li>
<p><strong>max_leaf_nodes : int, default=None</strong>
    Grow trees with <code>max_leaf_nodes</code> in best-first fashion.
    Best nodes are defined as relative reduction in impurity.
    If None then unlimited number of leaf nodes.</p>
</li>
<li>
<p><strong>min_impurity_decrease : float, default=0.0</strong>
    A node will be split if this split induces a decrease of the impurity
    greater than or equal to this value.</p>
<p>The weighted impurity decrease equation is the following::</p>
<div class="codehilite"><pre><span></span><code>N_t / N * (impurity - N_t_R / N_t * right_impurity
                    - N_t_L / N_t * left_impurity)
</code></pre></div>


<p>where <code>N</code> is the total number of samples, <code>N_t</code> is the number of
samples at the current node, <code>N_t_L</code> is the number of samples in the
left child, and <code>N_t_R</code> is the number of samples in the right child.</p>
<p><code>N</code>, <code>N_t</code>, <code>N_t_R</code> and <code>N_t_L</code> all refer to the weighted sum,
if <code>sample_weight</code> is passed.</p>
<p>.. versionadded:: 0.19</p>
</li>
<li>
<p><strong>min_impurity_split : float, default=None</strong>
    Threshold for early stopping in tree growth. A node will split
    if its impurity is above the threshold, otherwise it is a leaf.</p>
<p>.. deprecated:: 0.19
   <code>min_impurity_split</code> has been deprecated in favor of
   <code>min_impurity_decrease</code> in 0.19. The default value of
   <code>min_impurity_split</code> has changed from 1e-7 to 0 in 0.23 and it
   will be removed in 0.25. Use <code>min_impurity_decrease</code> instead.</p>
</li>
<li>
<p><strong>bootstrap : bool, default=False</strong>
    Whether bootstrap samples are used when building trees. If False, the
    whole dataset is used to build each tree.</p>
</li>
<li>
<p><strong>oob_score : bool, default=False</strong>
    Whether to use out-of-bag samples to estimate the R^2 on unseen data.</p>
</li>
<li>
<p><strong>n_jobs : int, default=None</strong>
    The number of jobs to run in parallel. :meth:<code>fit</code>, :meth:<code>predict</code>,
    :meth:<code>decision_path</code> and :meth:<code>apply</code> are all parallelized over the
    trees. <code>None</code> means 1 unless in a :obj:<code>joblib.parallel_backend</code>
    context. <code>-1</code> means using all processors. See :term:<code>Glossary
    &lt;n_jobs&gt;</code> for more details.</p>
</li>
<li>
<p><strong>random_state : int or RandomState, default=None</strong>
    Controls 3 sources of randomness:</p>
<ul>
<li>the bootstrapping of the samples used when building trees
  (if <code>bootstrap=True</code>)</li>
<li>the sampling of the features to consider when looking for the best
  split at each node (if <code>max_features &lt; n_features</code>)</li>
<li>the draw of the splits for each of the <code>max_features</code></li>
</ul>
</li>
<li>
<p><strong>See :term:<code>Glossary &lt;random_state&gt;</code> for details.</strong></p>
</li>
<li>
<p><strong>verbose : int, default=0</strong>
    Controls the verbosity when fitting and predicting.</p>
</li>
<li>
<p><strong>warm_start : bool, default=False</strong>
    When set to <code>True</code>, reuse the solution of the previous call to fit
    and add more estimators to the ensemble, otherwise, just fit a whole
    new forest. See :term:<code>the Glossary &lt;warm_start&gt;</code>.</p>
</li>
<li>
<p><strong>ccp_alpha : non-negative float, default=0.0</strong>
    Complexity parameter used for Minimal Cost-Complexity Pruning. The
    subtree with the largest cost complexity that is smaller than
    <code>ccp_alpha</code> will be chosen. By default, no pruning is performed. See
    :ref:<code>minimal_cost_complexity_pruning</code> for details.</p>
<p>.. versionadded:: 0.22</p>
</li>
<li>
<p><strong>max_samples : int or float, default=None</strong>
    If bootstrap is True, the number of samples to draw from X
    to train each base estimator.</p>
<ul>
<li>If None (default), then draw <code>X.shape[0]</code> samples.</li>
<li>If int, then draw <code>max_samples</code> samples.</li>
<li>If float, then draw <code>max_samples * X.shape[0]</code> samples. Thus,
  <code>max_samples</code> should be in the interval <code>(0, 1)</code>.</li>
</ul>
<p>.. versionadded:: 0.22</p>
</li>
</ul>
<h4>Attributes</h4>
<ul>
<li>
<p><strong>base_estimator_ : ExtraTreeRegressor</strong>
    The child estimator template used to create the collection of fitted
    sub-estimators.</p>
</li>
<li>
<p><strong>estimators_ : list of DecisionTreeRegressor</strong>
    The collection of fitted sub-estimators.</p>
</li>
<li>
<p><strong>feature_importances_ : ndarray of shape (n_features,)</strong>
    The impurity-based feature importances.
    The higher, the more important the feature.
    The importance of a feature is computed as the (normalized)
    total reduction of the criterion brought by that feature.  It is also
    known as the Gini importance.</p>
</li>
<li>
<p><strong>Warning: impurity-based feature importances can be misleading for</strong>
    high cardinality features (many unique values). See
    :func:<code>sklearn.inspection.permutation_importance</code> as an alternative.</p>
</li>
<li>
<p><strong>n_features_ : int</strong>
    The number of features.</p>
</li>
<li>
<p><strong>n_outputs_ : int</strong>
    The number of outputs.</p>
</li>
<li>
<p><strong>oob_score_ : float</strong>
    Score of the training dataset obtained using an out-of-bag estimate.
    This attribute exists only when <code>oob_score</code> is True.</p>
</li>
<li>
<p><strong>oob_prediction_ : ndarray of shape (n_samples,)</strong>
    Prediction computed with out-of-bag estimate on the training set.
    This attribute exists only when <code>oob_score</code> is True.</p>
</li>
</ul>
<h4>See Also</h4>
<ul>
<li>
<p><strong>sklearn.tree.ExtraTreeRegressor: Base estimator for this ensemble.</strong></p>
</li>
<li>
<p><strong>RandomForestRegressor: Ensemble regressor using trees with optimal splits.</strong></p>
</li>
</ul>
<h4>Notes</h4>
<p>The default values for the parameters controlling the size of the trees
(e.g. <code>max_depth</code>, <code>min_samples_leaf</code>, etc.) lead to fully grown and
unpruned trees which can potentially be very large on some data sets. To
reduce memory consumption, the complexity and size of the trees should be
controlled by setting those parameter values.</p>
<h4>References</h4>
<p>.. [1] P. Geurts, D. Ernst., and L. Wehenkel, 'Extremely randomized trees',
       Machine Learning, 63(1), 3-42, 2006.</p>
<h4>Examples</h4>
<div class="highlight"><pre><span></span><code><span class="o">&gt;&gt;&gt;</span> <span class="kn">from</span> <span class="nn">sklearn.datasets</span> <span class="kn">import</span> <span class="n">load_diabetes</span>
<span class="o">&gt;&gt;&gt;</span> <span class="kn">from</span> <span class="nn">sklearn.model_selection</span> <span class="kn">import</span> <span class="n">train_test_split</span>
<span class="o">&gt;&gt;&gt;</span> <span class="kn">from</span> <span class="nn">sklearn.ensemble</span> <span class="kn">import</span> <span class="n">ExtraTreesRegressor</span>
<span class="o">&gt;&gt;&gt;</span> <span class="n">X</span><span class="p">,</span> <span class="n">y</span> <span class="o">=</span> <span class="n">load_diabetes</span><span class="p">(</span><span class="n">return_X_y</span><span class="o">=</span><span class="kc">True</span><span class="p">)</span>
<span class="o">&gt;&gt;&gt;</span> <span class="n">X_train</span><span class="p">,</span> <span class="n">X_test</span><span class="p">,</span> <span class="n">y_train</span><span class="p">,</span> <span class="n">y_test</span> <span class="o">=</span> <span class="n">train_test_split</span><span class="p">(</span>
<span class="o">...</span>     <span class="n">X</span><span class="p">,</span> <span class="n">y</span><span class="p">,</span> <span class="n">random_state</span><span class="o">=</span><span class="mi">0</span><span class="p">)</span>
<span class="o">&gt;&gt;&gt;</span> <span class="n">reg</span> <span class="o">=</span> <span class="n">ExtraTreesRegressor</span><span class="p">(</span><span class="n">n_estimators</span><span class="o">=</span><span class="mi">100</span><span class="p">,</span> <span class="n">random_state</span><span class="o">=</span><span class="mi">0</span><span class="p">)</span><span class="o">.</span><span class="n">fit</span><span class="p">(</span>
<span class="o">...</span>    <span class="n">X_train</span><span class="p">,</span> <span class="n">y_train</span><span class="p">)</span>
<span class="o">&gt;&gt;&gt;</span> <span class="n">reg</span><span class="o">.</span><span class="n">score</span><span class="p">(</span><span class="n">X_test</span><span class="p">,</span> <span class="n">y_test</span><span class="p">)</span>
<span class="mf">0.2708</span><span class="o">...</span>
</code></pre></div>

</details>
<h3 id="get_item_6">get_item<a class="headerlink" href="#get_item_6" title="Permanent link">&para;</a></h3>
<details class="note" open="open"><summary>method get_item</summary><div class="highlight"><pre><span></span><code><span class="k">val</span> <span class="n">get_item</span> <span class="o">:</span>
  <span class="n">index</span><span class="o">:</span><span class="nn">Py</span><span class="p">.</span><span class="nn">Object</span><span class="p">.</span><span class="n">t</span> <span class="o">-&gt;</span>
  <span class="o">[&gt;</span> <span class="n">tag</span><span class="o">]</span> <span class="nn">Obj</span><span class="p">.</span><span class="n">t</span> <span class="o">-&gt;</span>
  <span class="nn">Py</span><span class="p">.</span><span class="nn">Object</span><span class="p">.</span><span class="n">t</span>
</code></pre></div>

<p>Return the index'th estimator in the ensemble.</p>
</details>
<h3 id="iter_6">iter<a class="headerlink" href="#iter_6" title="Permanent link">&para;</a></h3>
<details class="note" open="open"><summary>method iter</summary><div class="highlight"><pre><span></span><code><span class="k">val</span> <span class="n">iter</span> <span class="o">:</span>
  <span class="o">[&gt;</span> <span class="n">tag</span><span class="o">]</span> <span class="nn">Obj</span><span class="p">.</span><span class="n">t</span> <span class="o">-&gt;</span>
  <span class="nn">Dict</span><span class="p">.</span><span class="n">t</span> <span class="nn">Seq</span><span class="p">.</span><span class="n">t</span>
</code></pre></div>

<p>Return iterator over estimators in the ensemble.</p>
</details>
<h3 id="apply_1">apply<a class="headerlink" href="#apply_1" title="Permanent link">&para;</a></h3>
<details class="note" open="open"><summary>method apply</summary><div class="highlight"><pre><span></span><code><span class="k">val</span> <span class="n">apply</span> <span class="o">:</span>
  <span class="n">x</span><span class="o">:[&gt;`</span><span class="nc">ArrayLike</span><span class="o">]</span> <span class="nn">Np</span><span class="p">.</span><span class="nn">Obj</span><span class="p">.</span><span class="n">t</span> <span class="o">-&gt;</span>
  <span class="o">[&gt;</span> <span class="n">tag</span><span class="o">]</span> <span class="nn">Obj</span><span class="p">.</span><span class="n">t</span> <span class="o">-&gt;</span>
  <span class="o">[&gt;`</span><span class="nc">ArrayLike</span><span class="o">]</span> <span class="nn">Np</span><span class="p">.</span><span class="nn">Obj</span><span class="p">.</span><span class="n">t</span>
</code></pre></div>

<p>Apply trees in the forest to X, return leaf indices.</p>
<h4>Parameters</h4>
<ul>
<li><strong>X : {array-like, sparse matrix} of shape (n_samples, n_features)</strong>
    The input samples. Internally, its dtype will be converted to
    <code>dtype=np.float32</code>. If a sparse matrix is provided, it will be
    converted into a sparse <code>csr_matrix</code>.</li>
</ul>
<h4>Returns</h4>
<ul>
<li><strong>X_leaves : ndarray of shape (n_samples, n_estimators)</strong>
    For each datapoint x in X and for each tree in the forest,
    return the index of the leaf x ends up in.</li>
</ul>
</details>
<h3 id="decision_path_1">decision_path<a class="headerlink" href="#decision_path_1" title="Permanent link">&para;</a></h3>
<details class="note" open="open"><summary>method decision_path</summary><div class="highlight"><pre><span></span><code><span class="k">val</span> <span class="n">decision_path</span> <span class="o">:</span>
  <span class="n">x</span><span class="o">:[&gt;`</span><span class="nc">ArrayLike</span><span class="o">]</span> <span class="nn">Np</span><span class="p">.</span><span class="nn">Obj</span><span class="p">.</span><span class="n">t</span> <span class="o">-&gt;</span>
  <span class="o">[&gt;</span> <span class="n">tag</span><span class="o">]</span> <span class="nn">Obj</span><span class="p">.</span><span class="n">t</span> <span class="o">-&gt;</span>
  <span class="o">([`</span><span class="nc">ArrayLike</span><span class="o">|`</span><span class="nc">Object</span><span class="o">|`</span><span class="nc">Spmatrix</span><span class="o">]</span> <span class="nn">Np</span><span class="p">.</span><span class="nn">Obj</span><span class="p">.</span><span class="n">t</span> <span class="o">*</span> <span class="o">[&gt;`</span><span class="nc">ArrayLike</span><span class="o">]</span> <span class="nn">Np</span><span class="p">.</span><span class="nn">Obj</span><span class="p">.</span><span class="n">t</span><span class="o">)</span>
</code></pre></div>

<p>Return the decision path in the forest.</p>
<p>.. versionadded:: 0.18</p>
<h4>Parameters</h4>
<ul>
<li><strong>X : {array-like, sparse matrix} of shape (n_samples, n_features)</strong>
    The input samples. Internally, its dtype will be converted to
    <code>dtype=np.float32</code>. If a sparse matrix is provided, it will be
    converted into a sparse <code>csr_matrix</code>.</li>
</ul>
<h4>Returns</h4>
<ul>
<li>
<p><strong>indicator : sparse matrix of shape (n_samples, n_nodes)</strong>
    Return a node indicator matrix where non zero elements indicates
    that the samples goes through the nodes. The matrix is of CSR
    format.</p>
</li>
<li>
<p><strong>n_nodes_ptr : ndarray of shape (n_estimators + 1,)</strong>
    The columns from indicator[n_nodes_ptr[i]:n_nodes_ptr[i+1]]
    gives the indicator value for the i-th estimator.</p>
</li>
</ul>
</details>
<h3 id="fit_5">fit<a class="headerlink" href="#fit_5" title="Permanent link">&para;</a></h3>
<details class="note" open="open"><summary>method fit</summary><div class="highlight"><pre><span></span><code><span class="k">val</span> <span class="n">fit</span> <span class="o">:</span>
  <span class="o">?</span><span class="n">sample_weight</span><span class="o">:[&gt;`</span><span class="nc">ArrayLike</span><span class="o">]</span> <span class="nn">Np</span><span class="p">.</span><span class="nn">Obj</span><span class="p">.</span><span class="n">t</span> <span class="o">-&gt;</span>
  <span class="n">x</span><span class="o">:[&gt;`</span><span class="nc">ArrayLike</span><span class="o">]</span> <span class="nn">Np</span><span class="p">.</span><span class="nn">Obj</span><span class="p">.</span><span class="n">t</span> <span class="o">-&gt;</span>
  <span class="n">y</span><span class="o">:[&gt;`</span><span class="nc">ArrayLike</span><span class="o">]</span> <span class="nn">Np</span><span class="p">.</span><span class="nn">Obj</span><span class="p">.</span><span class="n">t</span> <span class="o">-&gt;</span>
  <span class="o">[&gt;</span> <span class="n">tag</span><span class="o">]</span> <span class="nn">Obj</span><span class="p">.</span><span class="n">t</span> <span class="o">-&gt;</span>
  <span class="n">t</span>
</code></pre></div>

<p>Build a forest of trees from the training set (X, y).</p>
<h4>Parameters</h4>
<ul>
<li>
<p><strong>X : {array-like, sparse matrix} of shape (n_samples, n_features)</strong>
    The training input samples. Internally, its dtype will be converted
    to <code>dtype=np.float32</code>. If a sparse matrix is provided, it will be
    converted into a sparse <code>csc_matrix</code>.</p>
</li>
<li>
<p><strong>y : array-like of shape (n_samples,) or (n_samples, n_outputs)</strong>
    The target values (class labels in classification, real numbers in
    regression).</p>
</li>
<li>
<p><strong>sample_weight : array-like of shape (n_samples,), default=None</strong>
    Sample weights. If None, then samples are equally weighted. Splits
    that would create child nodes with net zero or negative weight are
    ignored while searching for a split in each node. In the case of
    classification, splits are also ignored if they would result in any
    single class carrying a negative weight in either child node.</p>
</li>
</ul>
<h4>Returns</h4>
<ul>
<li><strong>self : object</strong></li>
</ul>
</details>
<h3 id="get_params_6">get_params<a class="headerlink" href="#get_params_6" title="Permanent link">&para;</a></h3>
<details class="note" open="open"><summary>method get_params</summary><div class="highlight"><pre><span></span><code><span class="k">val</span> <span class="n">get_params</span> <span class="o">:</span>
  <span class="o">?</span><span class="n">deep</span><span class="o">:</span><span class="kt">bool</span> <span class="o">-&gt;</span>
  <span class="o">[&gt;</span> <span class="n">tag</span><span class="o">]</span> <span class="nn">Obj</span><span class="p">.</span><span class="n">t</span> <span class="o">-&gt;</span>
  <span class="nn">Dict</span><span class="p">.</span><span class="n">t</span>
</code></pre></div>

<p>Get parameters for this estimator.</p>
<h4>Parameters</h4>
<ul>
<li><strong>deep : bool, default=True</strong>
    If True, will return the parameters for this estimator and
    contained subobjects that are estimators.</li>
</ul>
<h4>Returns</h4>
<ul>
<li><strong>params : mapping of string to any</strong>
    Parameter names mapped to their values.</li>
</ul>
</details>
<h3 id="predict_5">predict<a class="headerlink" href="#predict_5" title="Permanent link">&para;</a></h3>
<details class="note" open="open"><summary>method predict</summary><div class="highlight"><pre><span></span><code><span class="k">val</span> <span class="n">predict</span> <span class="o">:</span>
  <span class="n">x</span><span class="o">:[&gt;`</span><span class="nc">ArrayLike</span><span class="o">]</span> <span class="nn">Np</span><span class="p">.</span><span class="nn">Obj</span><span class="p">.</span><span class="n">t</span> <span class="o">-&gt;</span>
  <span class="o">[&gt;</span> <span class="n">tag</span><span class="o">]</span> <span class="nn">Obj</span><span class="p">.</span><span class="n">t</span> <span class="o">-&gt;</span>
  <span class="o">[&gt;`</span><span class="nc">ArrayLike</span><span class="o">]</span> <span class="nn">Np</span><span class="p">.</span><span class="nn">Obj</span><span class="p">.</span><span class="n">t</span>
</code></pre></div>

<p>Predict regression target for X.</p>
<p>The predicted regression target of an input sample is computed as the
mean predicted regression targets of the trees in the forest.</p>
<h4>Parameters</h4>
<ul>
<li><strong>X : {array-like, sparse matrix} of shape (n_samples, n_features)</strong>
    The input samples. Internally, its dtype will be converted to
    <code>dtype=np.float32</code>. If a sparse matrix is provided, it will be
    converted into a sparse <code>csr_matrix</code>.</li>
</ul>
<h4>Returns</h4>
<ul>
<li><strong>y : ndarray of shape (n_samples,) or (n_samples, n_outputs)</strong>
    The predicted values.</li>
</ul>
</details>
<h3 id="score_5">score<a class="headerlink" href="#score_5" title="Permanent link">&para;</a></h3>
<details class="note" open="open"><summary>method score</summary><div class="highlight"><pre><span></span><code><span class="k">val</span> <span class="n">score</span> <span class="o">:</span>
  <span class="o">?</span><span class="n">sample_weight</span><span class="o">:[&gt;`</span><span class="nc">ArrayLike</span><span class="o">]</span> <span class="nn">Np</span><span class="p">.</span><span class="nn">Obj</span><span class="p">.</span><span class="n">t</span> <span class="o">-&gt;</span>
  <span class="n">x</span><span class="o">:[&gt;`</span><span class="nc">ArrayLike</span><span class="o">]</span> <span class="nn">Np</span><span class="p">.</span><span class="nn">Obj</span><span class="p">.</span><span class="n">t</span> <span class="o">-&gt;</span>
  <span class="n">y</span><span class="o">:[&gt;`</span><span class="nc">ArrayLike</span><span class="o">]</span> <span class="nn">Np</span><span class="p">.</span><span class="nn">Obj</span><span class="p">.</span><span class="n">t</span> <span class="o">-&gt;</span>
  <span class="o">[&gt;</span> <span class="n">tag</span><span class="o">]</span> <span class="nn">Obj</span><span class="p">.</span><span class="n">t</span> <span class="o">-&gt;</span>
  <span class="kt">float</span>
</code></pre></div>

<p>Return the coefficient of determination R^2 of the prediction.</p>
<p>The coefficient R^2 is defined as (1 - u/v), where u is the residual
sum of squares ((y_true - y_pred) <strong> 2).sum() and v is the total
sum of squares ((y_true - y_true.mean()) </strong> 2).sum().
The best possible score is 1.0 and it can be negative (because the
model can be arbitrarily worse). A constant model that always
predicts the expected value of y, disregarding the input features,
would get a R^2 score of 0.0.</p>
<h4>Parameters</h4>
<ul>
<li>
<p><strong>X : array-like of shape (n_samples, n_features)</strong>
    Test samples. For some estimators this may be a
    precomputed kernel matrix or a list of generic objects instead,
    shape = (n_samples, n_samples_fitted),
    where n_samples_fitted is the number of
    samples used in the fitting for the estimator.</p>
</li>
<li>
<p><strong>y : array-like of shape (n_samples,) or (n_samples, n_outputs)</strong>
    True values for X.</p>
</li>
<li>
<p><strong>sample_weight : array-like of shape (n_samples,), default=None</strong>
    Sample weights.</p>
</li>
</ul>
<h4>Returns</h4>
<ul>
<li><strong>score : float</strong>
    R^2 of self.predict(X) wrt. y.</li>
</ul>
<h4>Notes</h4>
<p>The R2 score used when calling <code>score</code> on a regressor uses
<code>multioutput='uniform_average'</code> from version 0.23 to keep consistent
with default value of :func:<code>~sklearn.metrics.r2_score</code>.
This influences the <code>score</code> method of all the multioutput
regressors (except for
:class:<code>~sklearn.multioutput.MultiOutputRegressor</code>).</p>
</details>
<h3 id="set_params_6">set_params<a class="headerlink" href="#set_params_6" title="Permanent link">&para;</a></h3>
<details class="note" open="open"><summary>method set_params</summary><div class="highlight"><pre><span></span><code><span class="k">val</span> <span class="n">set_params</span> <span class="o">:</span>
  <span class="o">?</span><span class="n">params</span><span class="o">:(</span><span class="kt">string</span> <span class="o">*</span> <span class="nn">Py</span><span class="p">.</span><span class="nn">Object</span><span class="p">.</span><span class="n">t</span><span class="o">)</span> <span class="kt">list</span> <span class="o">-&gt;</span>
  <span class="o">[&gt;</span> <span class="n">tag</span><span class="o">]</span> <span class="nn">Obj</span><span class="p">.</span><span class="n">t</span> <span class="o">-&gt;</span>
  <span class="n">t</span>
</code></pre></div>

<p>Set the parameters of this estimator.</p>
<p>The method works on simple estimators as well as on nested objects
(such as pipelines). The latter have parameters of the form
<code>&lt;component&gt;__&lt;parameter&gt;</code> so that it's possible to update each
component of a nested object.</p>
<h4>Parameters</h4>
<ul>
<li><strong>**params : dict</strong>
    Estimator parameters.</li>
</ul>
<h4>Returns</h4>
<ul>
<li><strong>self : object</strong>
    Estimator instance.</li>
</ul>
</details>
<h3 id="base_estimator__6">base_estimator_<a class="headerlink" href="#base_estimator__6" title="Permanent link">&para;</a></h3>
<details class="note" open="open"><summary>attribute base_estimator_</summary><div class="highlight"><pre><span></span><code><span class="k">val</span> <span class="n">base_estimator_</span> <span class="o">:</span> <span class="n">t</span> <span class="o">-&gt;</span> <span class="nn">Py</span><span class="p">.</span><span class="nn">Object</span><span class="p">.</span><span class="n">t</span>
<span class="k">val</span> <span class="n">base_estimator_opt</span> <span class="o">:</span> <span class="n">t</span> <span class="o">-&gt;</span> <span class="o">(</span><span class="nn">Py</span><span class="p">.</span><span class="nn">Object</span><span class="p">.</span><span class="n">t</span><span class="o">)</span> <span class="n">option</span>
</code></pre></div>

<p>This attribute is documented in <code>create</code> above. The first version raises Not_found
if the attribute is None. The _opt version returns an option.</p>
</details>
<h3 id="estimators__6">estimators_<a class="headerlink" href="#estimators__6" title="Permanent link">&para;</a></h3>
<details class="note" open="open"><summary>attribute estimators_</summary><div class="highlight"><pre><span></span><code><span class="k">val</span> <span class="n">estimators_</span> <span class="o">:</span> <span class="n">t</span> <span class="o">-&gt;</span> <span class="nn">Py</span><span class="p">.</span><span class="nn">Object</span><span class="p">.</span><span class="n">t</span>
<span class="k">val</span> <span class="n">estimators_opt</span> <span class="o">:</span> <span class="n">t</span> <span class="o">-&gt;</span> <span class="o">(</span><span class="nn">Py</span><span class="p">.</span><span class="nn">Object</span><span class="p">.</span><span class="n">t</span><span class="o">)</span> <span class="n">option</span>
</code></pre></div>

<p>This attribute is documented in <code>create</code> above. The first version raises Not_found
if the attribute is None. The _opt version returns an option.</p>
</details>
<h3 id="feature_importances__3">feature_importances_<a class="headerlink" href="#feature_importances__3" title="Permanent link">&para;</a></h3>
<details class="note" open="open"><summary>attribute feature_importances_</summary><div class="highlight"><pre><span></span><code><span class="k">val</span> <span class="n">feature_importances_</span> <span class="o">:</span> <span class="n">t</span> <span class="o">-&gt;</span> <span class="o">[&gt;`</span><span class="nc">ArrayLike</span><span class="o">]</span> <span class="nn">Np</span><span class="p">.</span><span class="nn">Obj</span><span class="p">.</span><span class="n">t</span>
<span class="k">val</span> <span class="n">feature_importances_opt</span> <span class="o">:</span> <span class="n">t</span> <span class="o">-&gt;</span> <span class="o">([&gt;`</span><span class="nc">ArrayLike</span><span class="o">]</span> <span class="nn">Np</span><span class="p">.</span><span class="nn">Obj</span><span class="p">.</span><span class="n">t</span><span class="o">)</span> <span class="n">option</span>
</code></pre></div>

<p>This attribute is documented in <code>create</code> above. The first version raises Not_found
if the attribute is None. The _opt version returns an option.</p>
</details>
<h3 id="warning_3">warning<a class="headerlink" href="#warning_3" title="Permanent link">&para;</a></h3>
<details class="note" open="open"><summary>attribute warning</summary><div class="highlight"><pre><span></span><code><span class="k">val</span> <span class="n">warning</span> <span class="o">:</span> <span class="n">t</span> <span class="o">-&gt;</span> <span class="nn">Py</span><span class="p">.</span><span class="nn">Object</span><span class="p">.</span><span class="n">t</span>
<span class="k">val</span> <span class="n">warning_opt</span> <span class="o">:</span> <span class="n">t</span> <span class="o">-&gt;</span> <span class="o">(</span><span class="nn">Py</span><span class="p">.</span><span class="nn">Object</span><span class="p">.</span><span class="n">t</span><span class="o">)</span> <span class="n">option</span>
</code></pre></div>

<p>This attribute is documented in <code>create</code> above. The first version raises Not_found
if the attribute is None. The _opt version returns an option.</p>
</details>
<h3 id="n_features__3">n_features_<a class="headerlink" href="#n_features__3" title="Permanent link">&para;</a></h3>
<details class="note" open="open"><summary>attribute n_features_</summary><div class="highlight"><pre><span></span><code><span class="k">val</span> <span class="n">n_features_</span> <span class="o">:</span> <span class="n">t</span> <span class="o">-&gt;</span> <span class="kt">int</span>
<span class="k">val</span> <span class="n">n_features_opt</span> <span class="o">:</span> <span class="n">t</span> <span class="o">-&gt;</span> <span class="o">(</span><span class="kt">int</span><span class="o">)</span> <span class="n">option</span>
</code></pre></div>

<p>This attribute is documented in <code>create</code> above. The first version raises Not_found
if the attribute is None. The _opt version returns an option.</p>
</details>
<h3 id="n_outputs__1">n_outputs_<a class="headerlink" href="#n_outputs__1" title="Permanent link">&para;</a></h3>
<details class="note" open="open"><summary>attribute n_outputs_</summary><div class="highlight"><pre><span></span><code><span class="k">val</span> <span class="n">n_outputs_</span> <span class="o">:</span> <span class="n">t</span> <span class="o">-&gt;</span> <span class="kt">int</span>
<span class="k">val</span> <span class="n">n_outputs_opt</span> <span class="o">:</span> <span class="n">t</span> <span class="o">-&gt;</span> <span class="o">(</span><span class="kt">int</span><span class="o">)</span> <span class="n">option</span>
</code></pre></div>

<p>This attribute is documented in <code>create</code> above. The first version raises Not_found
if the attribute is None. The _opt version returns an option.</p>
</details>
<h3 id="oob_score__3">oob_score_<a class="headerlink" href="#oob_score__3" title="Permanent link">&para;</a></h3>
<details class="note" open="open"><summary>attribute oob_score_</summary><div class="highlight"><pre><span></span><code><span class="k">val</span> <span class="n">oob_score_</span> <span class="o">:</span> <span class="n">t</span> <span class="o">-&gt;</span> <span class="kt">float</span>
<span class="k">val</span> <span class="n">oob_score_opt</span> <span class="o">:</span> <span class="n">t</span> <span class="o">-&gt;</span> <span class="o">(</span><span class="kt">float</span><span class="o">)</span> <span class="n">option</span>
</code></pre></div>

<p>This attribute is documented in <code>create</code> above. The first version raises Not_found
if the attribute is None. The _opt version returns an option.</p>
</details>
<h3 id="oob_prediction__1">oob_prediction_<a class="headerlink" href="#oob_prediction__1" title="Permanent link">&para;</a></h3>
<details class="note" open="open"><summary>attribute oob_prediction_</summary><div class="highlight"><pre><span></span><code><span class="k">val</span> <span class="n">oob_prediction_</span> <span class="o">:</span> <span class="n">t</span> <span class="o">-&gt;</span> <span class="o">[&gt;`</span><span class="nc">ArrayLike</span><span class="o">]</span> <span class="nn">Np</span><span class="p">.</span><span class="nn">Obj</span><span class="p">.</span><span class="n">t</span>
<span class="k">val</span> <span class="n">oob_prediction_opt</span> <span class="o">:</span> <span class="n">t</span> <span class="o">-&gt;</span> <span class="o">([&gt;`</span><span class="nc">ArrayLike</span><span class="o">]</span> <span class="nn">Np</span><span class="p">.</span><span class="nn">Obj</span><span class="p">.</span><span class="n">t</span><span class="o">)</span> <span class="n">option</span>
</code></pre></div>

<p>This attribute is documented in <code>create</code> above. The first version raises Not_found
if the attribute is None. The _opt version returns an option.</p>
</details>
<h3 id="to_string_6">to_string<a class="headerlink" href="#to_string_6" title="Permanent link">&para;</a></h3>
<details class="note" open="open"><summary>method to_string</summary><div class="highlight"><pre><span></span><code><span class="k">val</span> <span class="n">to_string</span><span class="o">:</span> <span class="n">t</span> <span class="o">-&gt;</span> <span class="kt">string</span>
</code></pre></div>

<p>Print the object to a human-readable representation.</p>
</details>
<h3 id="show_6">show<a class="headerlink" href="#show_6" title="Permanent link">&para;</a></h3>
<details class="note" open="open"><summary>method show</summary><div class="highlight"><pre><span></span><code><span class="k">val</span> <span class="n">show</span><span class="o">:</span> <span class="n">t</span> <span class="o">-&gt;</span> <span class="kt">string</span>
</code></pre></div>

<p>Print the object to a human-readable representation.</p>
</details>
<h3 id="pp_6">pp<a class="headerlink" href="#pp_6" title="Permanent link">&para;</a></h3>
<details class="note" open="open"><summary>method pp</summary><div class="highlight"><pre><span></span><code><span class="k">val</span> <span class="n">pp</span><span class="o">:</span> <span class="nn">Format</span><span class="p">.</span><span class="n">formatter</span> <span class="o">-&gt;</span> <span class="n">t</span> <span class="o">-&gt;</span> <span class="kt">unit</span>
</code></pre></div>

<p>Pretty-print the object to a formatter.</p>
</details>
<h2 id="gradientboostingclassifier">GradientBoostingClassifier<a class="headerlink" href="#gradientboostingclassifier" title="Permanent link">&para;</a></h2>
<p>Module <code>Sklearn.​Ensemble.​GradientBoostingClassifier</code> wraps Python class <a href="https://scikit-learn.org/stable/modules/generated/sklearn.ensemble.GradientBoostingClassifier.html"><code>sklearn.ensemble.GradientBoostingClassifier</code></a>.</p>
<div class="highlight"><pre><span></span><code><span class="k">type</span> <span class="n">t</span>
</code></pre></div>

<h3 id="create_6">create<a class="headerlink" href="#create_6" title="Permanent link">&para;</a></h3>
<details class="note" open="open"><summary>constructor and attributes create</summary><div class="highlight"><pre><span></span><code><span class="k">val</span> <span class="n">create</span> <span class="o">:</span>
  <span class="o">?</span><span class="n">loss</span><span class="o">:[`</span><span class="nc">Deviance</span> <span class="o">|</span> <span class="o">`</span><span class="nc">Exponential</span><span class="o">]</span> <span class="o">-&gt;</span>
  <span class="o">?</span><span class="n">learning_rate</span><span class="o">:</span><span class="kt">float</span> <span class="o">-&gt;</span>
  <span class="o">?</span><span class="n">n_estimators</span><span class="o">:</span><span class="kt">int</span> <span class="o">-&gt;</span>
  <span class="o">?</span><span class="n">subsample</span><span class="o">:</span><span class="kt">float</span> <span class="o">-&gt;</span>
  <span class="o">?</span><span class="n">criterion</span><span class="o">:[`</span><span class="nc">Friedman_mse</span> <span class="o">|</span> <span class="o">`</span><span class="nc">Mse</span> <span class="o">|</span> <span class="o">`</span><span class="nc">Mae</span><span class="o">]</span> <span class="o">-&gt;</span>
  <span class="o">?</span><span class="n">min_samples_split</span><span class="o">:[`</span><span class="nc">F</span> <span class="k">of</span> <span class="kt">float</span> <span class="o">|</span> <span class="o">`</span><span class="nc">I</span> <span class="k">of</span> <span class="kt">int</span><span class="o">]</span> <span class="o">-&gt;</span>
  <span class="o">?</span><span class="n">min_samples_leaf</span><span class="o">:[`</span><span class="nc">F</span> <span class="k">of</span> <span class="kt">float</span> <span class="o">|</span> <span class="o">`</span><span class="nc">I</span> <span class="k">of</span> <span class="kt">int</span><span class="o">]</span> <span class="o">-&gt;</span>
  <span class="o">?</span><span class="n">min_weight_fraction_leaf</span><span class="o">:</span><span class="kt">float</span> <span class="o">-&gt;</span>
  <span class="o">?</span><span class="n">max_depth</span><span class="o">:</span><span class="kt">int</span> <span class="o">-&gt;</span>
  <span class="o">?</span><span class="n">min_impurity_decrease</span><span class="o">:</span><span class="kt">float</span> <span class="o">-&gt;</span>
  <span class="o">?</span><span class="n">min_impurity_split</span><span class="o">:</span><span class="kt">float</span> <span class="o">-&gt;</span>
  <span class="o">?</span><span class="n">init</span><span class="o">:[`</span><span class="nc">Zero</span> <span class="o">|</span> <span class="o">`</span><span class="nc">BaseEstimator</span> <span class="k">of</span> <span class="o">[&gt;`</span><span class="nc">BaseEstimator</span><span class="o">]</span> <span class="nn">Np</span><span class="p">.</span><span class="nn">Obj</span><span class="p">.</span><span class="n">t</span><span class="o">]</span> <span class="o">-&gt;</span>
  <span class="o">?</span><span class="n">random_state</span><span class="o">:</span><span class="kt">int</span> <span class="o">-&gt;</span>
  <span class="o">?</span><span class="n">max_features</span><span class="o">:[`</span><span class="nc">I</span> <span class="k">of</span> <span class="kt">int</span> <span class="o">|</span> <span class="o">`</span><span class="nc">Sqrt</span> <span class="o">|</span> <span class="o">`</span><span class="nc">Auto</span> <span class="o">|</span> <span class="o">`</span><span class="nc">F</span> <span class="k">of</span> <span class="kt">float</span> <span class="o">|</span> <span class="o">`</span><span class="nc">Log2</span><span class="o">]</span> <span class="o">-&gt;</span>
  <span class="o">?</span><span class="n">verbose</span><span class="o">:</span><span class="kt">int</span> <span class="o">-&gt;</span>
  <span class="o">?</span><span class="n">max_leaf_nodes</span><span class="o">:</span><span class="kt">int</span> <span class="o">-&gt;</span>
  <span class="o">?</span><span class="n">warm_start</span><span class="o">:</span><span class="kt">bool</span> <span class="o">-&gt;</span>
  <span class="o">?</span><span class="n">presort</span><span class="o">:</span><span class="nn">Py</span><span class="p">.</span><span class="nn">Object</span><span class="p">.</span><span class="n">t</span> <span class="o">-&gt;</span>
  <span class="o">?</span><span class="n">validation_fraction</span><span class="o">:</span><span class="kt">float</span> <span class="o">-&gt;</span>
  <span class="o">?</span><span class="n">n_iter_no_change</span><span class="o">:</span><span class="kt">int</span> <span class="o">-&gt;</span>
  <span class="o">?</span><span class="n">tol</span><span class="o">:</span><span class="kt">float</span> <span class="o">-&gt;</span>
  <span class="o">?</span><span class="n">ccp_alpha</span><span class="o">:</span><span class="kt">float</span> <span class="o">-&gt;</span>
  <span class="kt">unit</span> <span class="o">-&gt;</span>
  <span class="n">t</span>
</code></pre></div>

<p>Gradient Boosting for classification.</p>
<p>GB builds an additive model in a
forward stage-wise fashion; it allows for the optimization of
arbitrary differentiable loss functions. In each stage <code>n_classes_</code>
regression trees are fit on the negative gradient of the
binomial or multinomial deviance loss function. Binary classification
is a special case where only a single regression tree is induced.</p>
<p>Read more in the :ref:<code>User Guide &lt;gradient_boosting&gt;</code>.</p>
<h4>Parameters</h4>
<ul>
<li>
<p><strong>loss : {'deviance', 'exponential'}, default='deviance'</strong>
    loss function to be optimized. 'deviance' refers to
    deviance (= logistic regression) for classification
    with probabilistic outputs. For loss 'exponential' gradient
    boosting recovers the AdaBoost algorithm.</p>
</li>
<li>
<p><strong>learning_rate : float, default=0.1</strong>
    learning rate shrinks the contribution of each tree by <code>learning_rate</code>.
    There is a trade-off between learning_rate and n_estimators.</p>
</li>
<li>
<p><strong>n_estimators : int, default=100</strong>
    The number of boosting stages to perform. Gradient boosting
    is fairly robust to over-fitting so a large number usually
    results in better performance.</p>
</li>
<li>
<p><strong>subsample : float, default=1.0</strong>
    The fraction of samples to be used for fitting the individual base
    learners. If smaller than 1.0 this results in Stochastic Gradient
    Boosting. <code>subsample</code> interacts with the parameter <code>n_estimators</code>.
    Choosing <code>subsample &lt; 1.0</code> leads to a reduction of variance
    and an increase in bias.</p>
</li>
<li>
<p><strong>criterion : {'friedman_mse', 'mse', 'mae'}, default='friedman_mse'</strong>
    The function to measure the quality of a split. Supported criteria
    are 'friedman_mse' for the mean squared error with improvement
    score by Friedman, 'mse' for mean squared error, and 'mae' for
    the mean absolute error. The default value of 'friedman_mse' is
    generally the best as it can provide a better approximation in
    some cases.</p>
<p>.. versionadded:: 0.18</p>
</li>
<li>
<p><strong>min_samples_split : int or float, default=2</strong>
    The minimum number of samples required to split an internal node:</p>
<ul>
<li>If int, then consider <code>min_samples_split</code> as the minimum number.</li>
<li>If float, then <code>min_samples_split</code> is a fraction and
  <code>ceil(min_samples_split * n_samples)</code> are the minimum
  number of samples for each split.</li>
</ul>
<p>.. versionchanged:: 0.18
   Added float values for fractions.</p>
</li>
<li>
<p><strong>min_samples_leaf : int or float, default=1</strong>
    The minimum number of samples required to be at a leaf node.
    A split point at any depth will only be considered if it leaves at
    least <code>min_samples_leaf</code> training samples in each of the left and
    right branches.  This may have the effect of smoothing the model,
    especially in regression.</p>
<ul>
<li>If int, then consider <code>min_samples_leaf</code> as the minimum number.</li>
<li>If float, then <code>min_samples_leaf</code> is a fraction and
  <code>ceil(min_samples_leaf * n_samples)</code> are the minimum
  number of samples for each node.</li>
</ul>
<p>.. versionchanged:: 0.18
   Added float values for fractions.</p>
</li>
<li>
<p><strong>min_weight_fraction_leaf : float, default=0.0</strong>
    The minimum weighted fraction of the sum total of weights (of all
    the input samples) required to be at a leaf node. Samples have
    equal weight when sample_weight is not provided.</p>
</li>
<li>
<p><strong>max_depth : int, default=3</strong>
    maximum depth of the individual regression estimators. The maximum
    depth limits the number of nodes in the tree. Tune this parameter
    for best performance; the best value depends on the interaction
    of the input variables.</p>
</li>
<li>
<p><strong>min_impurity_decrease : float, default=0.0</strong>
    A node will be split if this split induces a decrease of the impurity
    greater than or equal to this value.</p>
<p>The weighted impurity decrease equation is the following::</p>
<div class="codehilite"><pre><span></span><code>N_t / N * (impurity - N_t_R / N_t * right_impurity
                    - N_t_L / N_t * left_impurity)
</code></pre></div>


<p>where <code>N</code> is the total number of samples, <code>N_t</code> is the number of
samples at the current node, <code>N_t_L</code> is the number of samples in the
left child, and <code>N_t_R</code> is the number of samples in the right child.</p>
<p><code>N</code>, <code>N_t</code>, <code>N_t_R</code> and <code>N_t_L</code> all refer to the weighted sum,
if <code>sample_weight</code> is passed.</p>
<p>.. versionadded:: 0.19</p>
</li>
<li>
<p><strong>min_impurity_split : float, default=None</strong>
    Threshold for early stopping in tree growth. A node will split
    if its impurity is above the threshold, otherwise it is a leaf.</p>
<p>.. deprecated:: 0.19
   <code>min_impurity_split</code> has been deprecated in favor of
   <code>min_impurity_decrease</code> in 0.19. The default value of
   <code>min_impurity_split</code> has changed from 1e-7 to 0 in 0.23 and it
   will be removed in 0.25. Use <code>min_impurity_decrease</code> instead.</p>
</li>
<li>
<p><strong>init : estimator or 'zero', default=None</strong>
    An estimator object that is used to compute the initial predictions.
    <code>init</code> has to provide :meth:<code>fit</code> and :meth:<code>predict_proba</code>. If
    'zero', the initial raw predictions are set to zero. By default, a
    <code>DummyEstimator</code> predicting the classes priors is used.</p>
</li>
<li>
<p><strong>random_state : int or RandomState, default=None</strong>
    Controls the random seed given to each Tree estimator at each
    boosting iteration.
    In addition, it controls the random permutation of the features at
    each split (see Notes for more details).
    It also controls the random spliting of the training data to obtain a
    validation set if <code>n_iter_no_change</code> is not None.
    Pass an int for reproducible output across multiple function calls.</p>
</li>
<li>
<p><strong>See :term:<code>Glossary &lt;random_state&gt;</code>.</strong></p>
</li>
<li>
<p><strong>max_features : {'auto', 'sqrt', 'log2'}, int or float, default=None</strong>
    The number of features to consider when looking for the best split:</p>
<ul>
<li>If int, then consider <code>max_features</code> features at each split.</li>
<li>If float, then <code>max_features</code> is a fraction and
  <code>int(max_features * n_features)</code> features are considered at each
  split.</li>
<li>If 'auto', then <code>max_features=sqrt(n_features)</code>.</li>
<li>If 'sqrt', then <code>max_features=sqrt(n_features)</code>.</li>
<li>If 'log2', then <code>max_features=log2(n_features)</code>.</li>
<li>If None, then <code>max_features=n_features</code>.</li>
</ul>
<p>Choosing <code>max_features &lt; n_features</code> leads to a reduction of variance
and an increase in bias.</p>
</li>
<li>
<p><strong>Note: the search for a split does not stop until at least one</strong>
    valid partition of the node samples is found, even if it requires to
    effectively inspect more than <code>max_features</code> features.</p>
</li>
<li>
<p><strong>verbose : int, default=0</strong>
    Enable verbose output. If 1 then it prints progress and performance
    once in a while (the more trees the lower the frequency). If greater
    than 1 then it prints progress and performance for every tree.</p>
</li>
<li>
<p><strong>max_leaf_nodes : int, default=None</strong>
    Grow trees with <code>max_leaf_nodes</code> in best-first fashion.
    Best nodes are defined as relative reduction in impurity.
    If None then unlimited number of leaf nodes.</p>
</li>
<li>
<p><strong>warm_start : bool, default=False</strong>
    When set to <code>True</code>, reuse the solution of the previous call to fit
    and add more estimators to the ensemble, otherwise, just erase the
    previous solution. See :term:<code>the Glossary &lt;warm_start&gt;</code>.</p>
</li>
<li>
<p><strong>presort : deprecated, default='deprecated'</strong>
    This parameter is deprecated and will be removed in v0.24.</p>
<p>.. deprecated :: 0.22</p>
</li>
<li>
<p><strong>validation_fraction : float, default=0.1</strong>
    The proportion of training data to set aside as validation set for
    early stopping. Must be between 0 and 1.
    Only used if <code>n_iter_no_change</code> is set to an integer.</p>
<p>.. versionadded:: 0.20</p>
</li>
<li>
<p><strong>n_iter_no_change : int, default=None</strong>
    <code>n_iter_no_change</code> is used to decide if early stopping will be used
    to terminate training when validation score is not improving. By
    default it is set to None to disable early stopping. If set to a
    number, it will set aside <code>validation_fraction</code> size of the training
    data as validation and terminate training when validation score is not
    improving in all of the previous <code>n_iter_no_change</code> numbers of
    iterations. The split is stratified.</p>
<p>.. versionadded:: 0.20</p>
</li>
<li>
<p><strong>tol : float, default=1e-4</strong>
    Tolerance for the early stopping. When the loss is not improving
    by at least tol for <code>n_iter_no_change</code> iterations (if set to a
    number), the training stops.</p>
<p>.. versionadded:: 0.20</p>
</li>
<li>
<p><strong>ccp_alpha : non-negative float, default=0.0</strong>
    Complexity parameter used for Minimal Cost-Complexity Pruning. The
    subtree with the largest cost complexity that is smaller than
    <code>ccp_alpha</code> will be chosen. By default, no pruning is performed. See
    :ref:<code>minimal_cost_complexity_pruning</code> for details.</p>
<p>.. versionadded:: 0.22</p>
</li>
</ul>
<h4>Attributes</h4>
<ul>
<li>
<p><strong>n_estimators_ : int</strong>
    The number of estimators as selected by early stopping (if
    <code>n_iter_no_change</code> is specified). Otherwise it is set to
    <code>n_estimators</code>.</p>
<p>.. versionadded:: 0.20</p>
</li>
<li>
<p><strong>feature_importances_ : ndarray of shape (n_features,)</strong>
    The impurity-based feature importances.
    The higher, the more important the feature.
    The importance of a feature is computed as the (normalized)
    total reduction of the criterion brought by that feature.  It is also
    known as the Gini importance.</p>
</li>
<li>
<p><strong>Warning: impurity-based feature importances can be misleading for</strong>
    high cardinality features (many unique values). See
    :func:<code>sklearn.inspection.permutation_importance</code> as an alternative.</p>
</li>
<li>
<p><strong>oob_improvement_ : ndarray of shape (n_estimators,)</strong>
    The improvement in loss (= deviance) on the out-of-bag samples
    relative to the previous iteration.
    <code>oob_improvement_[0]</code> is the improvement in
    loss of the first stage over the <code>init</code> estimator.
    Only available if <code>subsample &lt; 1.0</code></p>
</li>
<li>
<p><strong>train_score_ : ndarray of shape (n_estimators,)</strong>
    The i-th score <code>train_score_[i]</code> is the deviance (= loss) of the
    model at iteration <code>i</code> on the in-bag sample.
    If <code>subsample == 1</code> this is the deviance on the training data.</p>
</li>
<li>
<p><strong>loss_ : LossFunction</strong>
    The concrete <code>LossFunction</code> object.</p>
</li>
<li>
<p><strong>init_ : estimator</strong>
    The estimator that provides the initial predictions.
    Set via the <code>init</code> argument or <code>loss.init_estimator</code>.</p>
</li>
<li>
<p><strong>estimators_ : ndarray of DecisionTreeRegressor of shape (n_estimators, <code>loss_.K</code>)</strong>
    The collection of fitted sub-estimators. <code>loss_.K</code> is 1 for binary
    classification, otherwise n_classes.</p>
</li>
<li>
<p><strong>classes_ : ndarray of shape (n_classes,)</strong>
    The classes labels.</p>
</li>
<li>
<p><strong>n_features_ : int</strong>
    The number of data features.</p>
</li>
<li>
<p><strong>n_classes_ : int</strong>
    The number of classes.</p>
</li>
<li>
<p><strong>max_features_ : int</strong>
    The inferred value of max_features.</p>
</li>
</ul>
<h4>Notes</h4>
<p>The features are always randomly permuted at each split. Therefore,
the best found split may vary, even with the same training data and
<code>max_features=n_features</code>, if the improvement of the criterion is
identical for several splits enumerated during the search of the best
split. To obtain a deterministic behaviour during fitting,
<code>random_state</code> has to be fixed.</p>
<h4>Examples</h4>
<div class="highlight"><pre><span></span><code><span class="o">&gt;&gt;&gt;</span> <span class="kn">from</span> <span class="nn">sklearn.datasets</span> <span class="kn">import</span> <span class="n">make_classification</span>
<span class="o">&gt;&gt;&gt;</span> <span class="kn">from</span> <span class="nn">sklearn.ensemble</span> <span class="kn">import</span> <span class="n">GradientBoostingClassifier</span>
<span class="o">&gt;&gt;&gt;</span> <span class="kn">from</span> <span class="nn">sklearn.model_selection</span> <span class="kn">import</span> <span class="n">train_test_split</span>
<span class="o">&gt;&gt;&gt;</span> <span class="n">X</span><span class="p">,</span> <span class="n">y</span> <span class="o">=</span> <span class="n">make_classification</span><span class="p">(</span><span class="n">random_state</span><span class="o">=</span><span class="mi">0</span><span class="p">)</span>
<span class="o">&gt;&gt;&gt;</span> <span class="n">X_train</span><span class="p">,</span> <span class="n">X_test</span><span class="p">,</span> <span class="n">y_train</span><span class="p">,</span> <span class="n">y_test</span> <span class="o">=</span> <span class="n">train_test_split</span><span class="p">(</span>
<span class="o">...</span>     <span class="n">X</span><span class="p">,</span> <span class="n">y</span><span class="p">,</span> <span class="n">random_state</span><span class="o">=</span><span class="mi">0</span><span class="p">)</span>
<span class="o">&gt;&gt;&gt;</span> <span class="n">clf</span> <span class="o">=</span> <span class="n">GradientBoostingClassifier</span><span class="p">(</span><span class="n">random_state</span><span class="o">=</span><span class="mi">0</span><span class="p">)</span>
<span class="o">&gt;&gt;&gt;</span> <span class="n">clf</span><span class="o">.</span><span class="n">fit</span><span class="p">(</span><span class="n">X_train</span><span class="p">,</span> <span class="n">y_train</span><span class="p">)</span>
<span class="n">GradientBoostingClassifier</span><span class="p">(</span><span class="n">random_state</span><span class="o">=</span><span class="mi">0</span><span class="p">)</span>
<span class="o">&gt;&gt;&gt;</span> <span class="n">clf</span><span class="o">.</span><span class="n">predict</span><span class="p">(</span><span class="n">X_test</span><span class="p">[:</span><span class="mi">2</span><span class="p">])</span>
<span class="n">array</span><span class="p">([</span><span class="mi">1</span><span class="p">,</span> <span class="mi">0</span><span class="p">])</span>
<span class="o">&gt;&gt;&gt;</span> <span class="n">clf</span><span class="o">.</span><span class="n">score</span><span class="p">(</span><span class="n">X_test</span><span class="p">,</span> <span class="n">y_test</span><span class="p">)</span>
<span class="mf">0.88</span>
</code></pre></div>

<h4>See also</h4>
<p>sklearn.ensemble.HistGradientBoostingClassifier,
sklearn.tree.DecisionTreeClassifier, RandomForestClassifier
AdaBoostClassifier</p>
<h4>References</h4>
<p>J. Friedman, Greedy Function Approximation: A Gradient Boosting
Machine, The Annals of Statistics, Vol. 29, No. 5, 2001.</p>
<p>J. Friedman, Stochastic Gradient Boosting, 1999</p>
<p>T. Hastie, R. Tibshirani and J. Friedman.
Elements of Statistical Learning Ed. 2, Springer, 2009.</p>
</details>
<h3 id="get_item_7">get_item<a class="headerlink" href="#get_item_7" title="Permanent link">&para;</a></h3>
<details class="note" open="open"><summary>method get_item</summary><div class="highlight"><pre><span></span><code><span class="k">val</span> <span class="n">get_item</span> <span class="o">:</span>
  <span class="n">index</span><span class="o">:</span><span class="nn">Py</span><span class="p">.</span><span class="nn">Object</span><span class="p">.</span><span class="n">t</span> <span class="o">-&gt;</span>
  <span class="o">[&gt;</span> <span class="n">tag</span><span class="o">]</span> <span class="nn">Obj</span><span class="p">.</span><span class="n">t</span> <span class="o">-&gt;</span>
  <span class="nn">Py</span><span class="p">.</span><span class="nn">Object</span><span class="p">.</span><span class="n">t</span>
</code></pre></div>

<p>Return the index'th estimator in the ensemble.</p>
</details>
<h3 id="iter_7">iter<a class="headerlink" href="#iter_7" title="Permanent link">&para;</a></h3>
<details class="note" open="open"><summary>method iter</summary><div class="highlight"><pre><span></span><code><span class="k">val</span> <span class="n">iter</span> <span class="o">:</span>
  <span class="o">[&gt;</span> <span class="n">tag</span><span class="o">]</span> <span class="nn">Obj</span><span class="p">.</span><span class="n">t</span> <span class="o">-&gt;</span>
  <span class="nn">Dict</span><span class="p">.</span><span class="n">t</span> <span class="nn">Seq</span><span class="p">.</span><span class="n">t</span>
</code></pre></div>

<p>Return iterator over estimators in the ensemble.</p>
</details>
<h3 id="apply_2">apply<a class="headerlink" href="#apply_2" title="Permanent link">&para;</a></h3>
<details class="note" open="open"><summary>method apply</summary><div class="highlight"><pre><span></span><code><span class="k">val</span> <span class="n">apply</span> <span class="o">:</span>
  <span class="n">x</span><span class="o">:[&gt;`</span><span class="nc">ArrayLike</span><span class="o">]</span> <span class="nn">Np</span><span class="p">.</span><span class="nn">Obj</span><span class="p">.</span><span class="n">t</span> <span class="o">-&gt;</span>
  <span class="o">[&gt;</span> <span class="n">tag</span><span class="o">]</span> <span class="nn">Obj</span><span class="p">.</span><span class="n">t</span> <span class="o">-&gt;</span>
  <span class="o">[&gt;`</span><span class="nc">ArrayLike</span><span class="o">]</span> <span class="nn">Np</span><span class="p">.</span><span class="nn">Obj</span><span class="p">.</span><span class="n">t</span>
</code></pre></div>

<p>Apply trees in the ensemble to X, return leaf indices.</p>
<p>.. versionadded:: 0.17</p>
<h4>Parameters</h4>
<ul>
<li><strong>X : {array-like, sparse matrix} of shape (n_samples, n_features)</strong>
    The input samples. Internally, its dtype will be converted to
    <code>dtype=np.float32</code>. If a sparse matrix is provided, it will
    be converted to a sparse <code>csr_matrix</code>.</li>
</ul>
<h4>Returns</h4>
<ul>
<li><strong>X_leaves : array-like of shape (n_samples, n_estimators, n_classes)</strong>
    For each datapoint x in X and for each tree in the ensemble,
    return the index of the leaf x ends up in each estimator.
    In the case of binary classification n_classes is 1.</li>
</ul>
</details>
<h3 id="decision_function_1">decision_function<a class="headerlink" href="#decision_function_1" title="Permanent link">&para;</a></h3>
<details class="note" open="open"><summary>method decision_function</summary><div class="highlight"><pre><span></span><code><span class="k">val</span> <span class="n">decision_function</span> <span class="o">:</span>
  <span class="n">x</span><span class="o">:[&gt;`</span><span class="nc">ArrayLike</span><span class="o">]</span> <span class="nn">Np</span><span class="p">.</span><span class="nn">Obj</span><span class="p">.</span><span class="n">t</span> <span class="o">-&gt;</span>
  <span class="o">[&gt;</span> <span class="n">tag</span><span class="o">]</span> <span class="nn">Obj</span><span class="p">.</span><span class="n">t</span> <span class="o">-&gt;</span>
  <span class="o">[&gt;`</span><span class="nc">ArrayLike</span><span class="o">]</span> <span class="nn">Np</span><span class="p">.</span><span class="nn">Obj</span><span class="p">.</span><span class="n">t</span>
</code></pre></div>

<p>Compute the decision function of <code>X</code>.</p>
<h4>Parameters</h4>
<ul>
<li><strong>X : {array-like, sparse matrix} of shape (n_samples, n_features)</strong>
    The input samples. Internally, it will be converted to
    <code>dtype=np.float32</code> and if a sparse matrix is provided
    to a sparse <code>csr_matrix</code>.</li>
</ul>
<h4>Returns</h4>
<ul>
<li><strong>score : ndarray of shape (n_samples, n_classes) or (n_samples,)</strong>
    The decision function of the input samples, which corresponds to
    the raw values predicted from the trees of the ensemble . The
    order of the classes corresponds to that in the attribute
    :term:<code>classes_</code>. Regression and binary classification produce an
    array of shape [n_samples].</li>
</ul>
</details>
<h3 id="fit_6">fit<a class="headerlink" href="#fit_6" title="Permanent link">&para;</a></h3>
<details class="note" open="open"><summary>method fit</summary><div class="highlight"><pre><span></span><code><span class="k">val</span> <span class="n">fit</span> <span class="o">:</span>
  <span class="o">?</span><span class="n">sample_weight</span><span class="o">:[&gt;`</span><span class="nc">ArrayLike</span><span class="o">]</span> <span class="nn">Np</span><span class="p">.</span><span class="nn">Obj</span><span class="p">.</span><span class="n">t</span> <span class="o">-&gt;</span>
  <span class="o">?</span><span class="n">monitor</span><span class="o">:</span><span class="nn">Py</span><span class="p">.</span><span class="nn">Object</span><span class="p">.</span><span class="n">t</span> <span class="o">-&gt;</span>
  <span class="n">x</span><span class="o">:[&gt;`</span><span class="nc">ArrayLike</span><span class="o">]</span> <span class="nn">Np</span><span class="p">.</span><span class="nn">Obj</span><span class="p">.</span><span class="n">t</span> <span class="o">-&gt;</span>
  <span class="n">y</span><span class="o">:[&gt;`</span><span class="nc">ArrayLike</span><span class="o">]</span> <span class="nn">Np</span><span class="p">.</span><span class="nn">Obj</span><span class="p">.</span><span class="n">t</span> <span class="o">-&gt;</span>
  <span class="o">[&gt;</span> <span class="n">tag</span><span class="o">]</span> <span class="nn">Obj</span><span class="p">.</span><span class="n">t</span> <span class="o">-&gt;</span>
  <span class="n">t</span>
</code></pre></div>

<p>Fit the gradient boosting model.</p>
<h4>Parameters</h4>
<ul>
<li>
<p><strong>X : {array-like, sparse matrix} of shape (n_samples, n_features)</strong>
    The input samples. Internally, it will be converted to
    <code>dtype=np.float32</code> and if a sparse matrix is provided
    to a sparse <code>csr_matrix</code>.</p>
</li>
<li>
<p><strong>y : array-like of shape (n_samples,)</strong>
    Target values (strings or integers in classification, real numbers
    in regression)
    For classification, labels must correspond to classes.</p>
</li>
<li>
<p><strong>sample_weight : array-like of shape (n_samples,), default=None</strong>
    Sample weights. If None, then samples are equally weighted. Splits
    that would create child nodes with net zero or negative weight are
    ignored while searching for a split in each node. In the case of
    classification, splits are also ignored if they would result in any
    single class carrying a negative weight in either child node.</p>
</li>
<li>
<p><strong>monitor : callable, default=None</strong>
    The monitor is called after each iteration with the current
    iteration, a reference to the estimator and the local variables of
    <code>_fit_stages</code> as keyword arguments <code>callable(i, self,
    locals())</code>. If the callable returns <code>True</code> the fitting procedure
    is stopped. The monitor can be used for various things such as
    computing held-out estimates, early stopping, model introspect, and
    snapshoting.</p>
</li>
</ul>
<h4>Returns</h4>
<ul>
<li><strong>self : object</strong></li>
</ul>
</details>
<h3 id="get_params_7">get_params<a class="headerlink" href="#get_params_7" title="Permanent link">&para;</a></h3>
<details class="note" open="open"><summary>method get_params</summary><div class="highlight"><pre><span></span><code><span class="k">val</span> <span class="n">get_params</span> <span class="o">:</span>
  <span class="o">?</span><span class="n">deep</span><span class="o">:</span><span class="kt">bool</span> <span class="o">-&gt;</span>
  <span class="o">[&gt;</span> <span class="n">tag</span><span class="o">]</span> <span class="nn">Obj</span><span class="p">.</span><span class="n">t</span> <span class="o">-&gt;</span>
  <span class="nn">Dict</span><span class="p">.</span><span class="n">t</span>
</code></pre></div>

<p>Get parameters for this estimator.</p>
<h4>Parameters</h4>
<ul>
<li><strong>deep : bool, default=True</strong>
    If True, will return the parameters for this estimator and
    contained subobjects that are estimators.</li>
</ul>
<h4>Returns</h4>
<ul>
<li><strong>params : mapping of string to any</strong>
    Parameter names mapped to their values.</li>
</ul>
</details>
<h3 id="predict_6">predict<a class="headerlink" href="#predict_6" title="Permanent link">&para;</a></h3>
<details class="note" open="open"><summary>method predict</summary><div class="highlight"><pre><span></span><code><span class="k">val</span> <span class="n">predict</span> <span class="o">:</span>
  <span class="n">x</span><span class="o">:[&gt;`</span><span class="nc">ArrayLike</span><span class="o">]</span> <span class="nn">Np</span><span class="p">.</span><span class="nn">Obj</span><span class="p">.</span><span class="n">t</span> <span class="o">-&gt;</span>
  <span class="o">[&gt;</span> <span class="n">tag</span><span class="o">]</span> <span class="nn">Obj</span><span class="p">.</span><span class="n">t</span> <span class="o">-&gt;</span>
  <span class="o">[&gt;`</span><span class="nc">ArrayLike</span><span class="o">]</span> <span class="nn">Np</span><span class="p">.</span><span class="nn">Obj</span><span class="p">.</span><span class="n">t</span>
</code></pre></div>

<p>Predict class for X.</p>
<h4>Parameters</h4>
<ul>
<li><strong>X : {array-like, sparse matrix} of shape (n_samples, n_features)</strong>
    The input samples. Internally, it will be converted to
    <code>dtype=np.float32</code> and if a sparse matrix is provided
    to a sparse <code>csr_matrix</code>.</li>
</ul>
<h4>Returns</h4>
<ul>
<li><strong>y : ndarray of shape (n_samples,)</strong>
    The predicted values.</li>
</ul>
</details>
<h3 id="predict_log_proba_3">predict_log_proba<a class="headerlink" href="#predict_log_proba_3" title="Permanent link">&para;</a></h3>
<details class="note" open="open"><summary>method predict_log_proba</summary><div class="highlight"><pre><span></span><code><span class="k">val</span> <span class="n">predict_log_proba</span> <span class="o">:</span>
  <span class="n">x</span><span class="o">:[&gt;`</span><span class="nc">ArrayLike</span><span class="o">]</span> <span class="nn">Np</span><span class="p">.</span><span class="nn">Obj</span><span class="p">.</span><span class="n">t</span> <span class="o">-&gt;</span>
  <span class="o">[&gt;</span> <span class="n">tag</span><span class="o">]</span> <span class="nn">Obj</span><span class="p">.</span><span class="n">t</span> <span class="o">-&gt;</span>
  <span class="o">[&gt;`</span><span class="nc">ArrayLike</span><span class="o">]</span> <span class="nn">Np</span><span class="p">.</span><span class="nn">Obj</span><span class="p">.</span><span class="n">t</span>
</code></pre></div>

<p>Predict class log-probabilities for X.</p>
<h4>Parameters</h4>
<ul>
<li><strong>X : {array-like, sparse matrix} of shape (n_samples, n_features)</strong>
    The input samples. Internally, it will be converted to
    <code>dtype=np.float32</code> and if a sparse matrix is provided
    to a sparse <code>csr_matrix</code>.</li>
</ul>
<h4>Raises</h4>
<p>AttributeError
    If the <code>loss</code> does not support probabilities.</p>
<h4>Returns</h4>
<ul>
<li><strong>p : ndarray of shape (n_samples, n_classes)</strong>
    The class log-probabilities of the input samples. The order of the
    classes corresponds to that in the attribute :term:<code>classes_</code>.</li>
</ul>
</details>
<h3 id="predict_proba_3">predict_proba<a class="headerlink" href="#predict_proba_3" title="Permanent link">&para;</a></h3>
<details class="note" open="open"><summary>method predict_proba</summary><div class="highlight"><pre><span></span><code><span class="k">val</span> <span class="n">predict_proba</span> <span class="o">:</span>
  <span class="n">x</span><span class="o">:[&gt;`</span><span class="nc">ArrayLike</span><span class="o">]</span> <span class="nn">Np</span><span class="p">.</span><span class="nn">Obj</span><span class="p">.</span><span class="n">t</span> <span class="o">-&gt;</span>
  <span class="o">[&gt;</span> <span class="n">tag</span><span class="o">]</span> <span class="nn">Obj</span><span class="p">.</span><span class="n">t</span> <span class="o">-&gt;</span>
  <span class="o">[&gt;`</span><span class="nc">ArrayLike</span><span class="o">]</span> <span class="nn">Np</span><span class="p">.</span><span class="nn">Obj</span><span class="p">.</span><span class="n">t</span>
</code></pre></div>

<p>Predict class probabilities for X.</p>
<h4>Parameters</h4>
<ul>
<li><strong>X : {array-like, sparse matrix} of shape (n_samples, n_features)</strong>
    The input samples. Internally, it will be converted to
    <code>dtype=np.float32</code> and if a sparse matrix is provided
    to a sparse <code>csr_matrix</code>.</li>
</ul>
<h4>Raises</h4>
<p>AttributeError
    If the <code>loss</code> does not support probabilities.</p>
<h4>Returns</h4>
<ul>
<li><strong>p : ndarray of shape (n_samples, n_classes)</strong>
    The class probabilities of the input samples. The order of the
    classes corresponds to that in the attribute :term:<code>classes_</code>.</li>
</ul>
</details>
<h3 id="score_6">score<a class="headerlink" href="#score_6" title="Permanent link">&para;</a></h3>
<details class="note" open="open"><summary>method score</summary><div class="highlight"><pre><span></span><code><span class="k">val</span> <span class="n">score</span> <span class="o">:</span>
  <span class="o">?</span><span class="n">sample_weight</span><span class="o">:[&gt;`</span><span class="nc">ArrayLike</span><span class="o">]</span> <span class="nn">Np</span><span class="p">.</span><span class="nn">Obj</span><span class="p">.</span><span class="n">t</span> <span class="o">-&gt;</span>
  <span class="n">x</span><span class="o">:[&gt;`</span><span class="nc">ArrayLike</span><span class="o">]</span> <span class="nn">Np</span><span class="p">.</span><span class="nn">Obj</span><span class="p">.</span><span class="n">t</span> <span class="o">-&gt;</span>
  <span class="n">y</span><span class="o">:[&gt;`</span><span class="nc">ArrayLike</span><span class="o">]</span> <span class="nn">Np</span><span class="p">.</span><span class="nn">Obj</span><span class="p">.</span><span class="n">t</span> <span class="o">-&gt;</span>
  <span class="o">[&gt;</span> <span class="n">tag</span><span class="o">]</span> <span class="nn">Obj</span><span class="p">.</span><span class="n">t</span> <span class="o">-&gt;</span>
  <span class="kt">float</span>
</code></pre></div>

<p>Return the mean accuracy on the given test data and labels.</p>
<p>In multi-label classification, this is the subset accuracy
which is a harsh metric since you require for each sample that
each label set be correctly predicted.</p>
<h4>Parameters</h4>
<ul>
<li>
<p><strong>X : array-like of shape (n_samples, n_features)</strong>
    Test samples.</p>
</li>
<li>
<p><strong>y : array-like of shape (n_samples,) or (n_samples, n_outputs)</strong>
    True labels for X.</p>
</li>
<li>
<p><strong>sample_weight : array-like of shape (n_samples,), default=None</strong>
    Sample weights.</p>
</li>
</ul>
<h4>Returns</h4>
<ul>
<li><strong>score : float</strong>
    Mean accuracy of self.predict(X) wrt. y.</li>
</ul>
</details>
<h3 id="set_params_7">set_params<a class="headerlink" href="#set_params_7" title="Permanent link">&para;</a></h3>
<details class="note" open="open"><summary>method set_params</summary><div class="highlight"><pre><span></span><code><span class="k">val</span> <span class="n">set_params</span> <span class="o">:</span>
  <span class="o">?</span><span class="n">params</span><span class="o">:(</span><span class="kt">string</span> <span class="o">*</span> <span class="nn">Py</span><span class="p">.</span><span class="nn">Object</span><span class="p">.</span><span class="n">t</span><span class="o">)</span> <span class="kt">list</span> <span class="o">-&gt;</span>
  <span class="o">[&gt;</span> <span class="n">tag</span><span class="o">]</span> <span class="nn">Obj</span><span class="p">.</span><span class="n">t</span> <span class="o">-&gt;</span>
  <span class="n">t</span>
</code></pre></div>

<p>Set the parameters of this estimator.</p>
<p>The method works on simple estimators as well as on nested objects
(such as pipelines). The latter have parameters of the form
<code>&lt;component&gt;__&lt;parameter&gt;</code> so that it's possible to update each
component of a nested object.</p>
<h4>Parameters</h4>
<ul>
<li><strong>**params : dict</strong>
    Estimator parameters.</li>
</ul>
<h4>Returns</h4>
<ul>
<li><strong>self : object</strong>
    Estimator instance.</li>
</ul>
</details>
<h3 id="staged_decision_function_1">staged_decision_function<a class="headerlink" href="#staged_decision_function_1" title="Permanent link">&para;</a></h3>
<details class="note" open="open"><summary>method staged_decision_function</summary><div class="highlight"><pre><span></span><code><span class="k">val</span> <span class="n">staged_decision_function</span> <span class="o">:</span>
  <span class="n">x</span><span class="o">:[&gt;`</span><span class="nc">ArrayLike</span><span class="o">]</span> <span class="nn">Np</span><span class="p">.</span><span class="nn">Obj</span><span class="p">.</span><span class="n">t</span> <span class="o">-&gt;</span>
  <span class="o">[&gt;</span> <span class="n">tag</span><span class="o">]</span> <span class="nn">Obj</span><span class="p">.</span><span class="n">t</span> <span class="o">-&gt;</span>
  <span class="o">[&gt;`</span><span class="nc">ArrayLike</span><span class="o">]</span> <span class="nn">Np</span><span class="p">.</span><span class="nn">Obj</span><span class="p">.</span><span class="n">t</span> <span class="nn">Seq</span><span class="p">.</span><span class="n">t</span>
</code></pre></div>

<p>Compute decision function of <code>X</code> for each iteration.</p>
<p>This method allows monitoring (i.e. determine error on testing set)
after each stage.</p>
<h4>Parameters</h4>
<ul>
<li><strong>X : {array-like, sparse matrix} of shape (n_samples, n_features)</strong>
    The input samples. Internally, it will be converted to
    <code>dtype=np.float32</code> and if a sparse matrix is provided
    to a sparse <code>csr_matrix</code>.</li>
</ul>
<h4>Returns</h4>
<ul>
<li><strong>score : generator of ndarray of shape (n_samples, k)</strong>
    The decision function of the input samples, which corresponds to
    the raw values predicted from the trees of the ensemble . The
    classes corresponds to that in the attribute :term:<code>classes_</code>.
    Regression and binary classification are special cases with
    <code>k == 1</code>, otherwise <code>k==n_classes</code>.</li>
</ul>
</details>
<h3 id="staged_predict_2">staged_predict<a class="headerlink" href="#staged_predict_2" title="Permanent link">&para;</a></h3>
<details class="note" open="open"><summary>method staged_predict</summary><div class="highlight"><pre><span></span><code><span class="k">val</span> <span class="n">staged_predict</span> <span class="o">:</span>
  <span class="n">x</span><span class="o">:[&gt;`</span><span class="nc">ArrayLike</span><span class="o">]</span> <span class="nn">Np</span><span class="p">.</span><span class="nn">Obj</span><span class="p">.</span><span class="n">t</span> <span class="o">-&gt;</span>
  <span class="o">[&gt;</span> <span class="n">tag</span><span class="o">]</span> <span class="nn">Obj</span><span class="p">.</span><span class="n">t</span> <span class="o">-&gt;</span>
  <span class="o">[&gt;`</span><span class="nc">ArrayLike</span><span class="o">]</span> <span class="nn">Np</span><span class="p">.</span><span class="nn">Obj</span><span class="p">.</span><span class="n">t</span> <span class="nn">Seq</span><span class="p">.</span><span class="n">t</span>
</code></pre></div>

<p>Predict class at each stage for X.</p>
<p>This method allows monitoring (i.e. determine error on testing set)
after each stage.</p>
<h4>Parameters</h4>
<ul>
<li><strong>X : {array-like, sparse matrix} of shape (n_samples, n_features)</strong>
    The input samples. Internally, it will be converted to
    <code>dtype=np.float32</code> and if a sparse matrix is provided
    to a sparse <code>csr_matrix</code>.</li>
</ul>
<h4>Returns</h4>
<ul>
<li><strong>y : generator of ndarray of shape (n_samples,)</strong>
    The predicted value of the input samples.</li>
</ul>
</details>
<h3 id="staged_predict_proba_1">staged_predict_proba<a class="headerlink" href="#staged_predict_proba_1" title="Permanent link">&para;</a></h3>
<details class="note" open="open"><summary>method staged_predict_proba</summary><div class="highlight"><pre><span></span><code><span class="k">val</span> <span class="n">staged_predict_proba</span> <span class="o">:</span>
  <span class="n">x</span><span class="o">:[&gt;`</span><span class="nc">ArrayLike</span><span class="o">]</span> <span class="nn">Np</span><span class="p">.</span><span class="nn">Obj</span><span class="p">.</span><span class="n">t</span> <span class="o">-&gt;</span>
  <span class="o">[&gt;</span> <span class="n">tag</span><span class="o">]</span> <span class="nn">Obj</span><span class="p">.</span><span class="n">t</span> <span class="o">-&gt;</span>
  <span class="o">[&gt;`</span><span class="nc">ArrayLike</span><span class="o">]</span> <span class="nn">Np</span><span class="p">.</span><span class="nn">Obj</span><span class="p">.</span><span class="n">t</span> <span class="nn">Seq</span><span class="p">.</span><span class="n">t</span>
</code></pre></div>

<p>Predict class probabilities at each stage for X.</p>
<p>This method allows monitoring (i.e. determine error on testing set)
after each stage.</p>
<h4>Parameters</h4>
<ul>
<li><strong>X : {array-like, sparse matrix} of shape (n_samples, n_features)</strong>
    The input samples. Internally, it will be converted to
    <code>dtype=np.float32</code> and if a sparse matrix is provided
    to a sparse <code>csr_matrix</code>.</li>
</ul>
<h4>Returns</h4>
<ul>
<li><strong>y : generator of ndarray of shape (n_samples,)</strong>
    The predicted value of the input samples.</li>
</ul>
</details>
<h3 id="n_estimators_">n_estimators_<a class="headerlink" href="#n_estimators_" title="Permanent link">&para;</a></h3>
<details class="note" open="open"><summary>attribute n_estimators_</summary><div class="highlight"><pre><span></span><code><span class="k">val</span> <span class="n">n_estimators_</span> <span class="o">:</span> <span class="n">t</span> <span class="o">-&gt;</span> <span class="kt">int</span>
<span class="k">val</span> <span class="n">n_estimators_opt</span> <span class="o">:</span> <span class="n">t</span> <span class="o">-&gt;</span> <span class="o">(</span><span class="kt">int</span><span class="o">)</span> <span class="n">option</span>
</code></pre></div>

<p>This attribute is documented in <code>create</code> above. The first version raises Not_found
if the attribute is None. The _opt version returns an option.</p>
</details>
<h3 id="feature_importances__4">feature_importances_<a class="headerlink" href="#feature_importances__4" title="Permanent link">&para;</a></h3>
<details class="note" open="open"><summary>attribute feature_importances_</summary><div class="highlight"><pre><span></span><code><span class="k">val</span> <span class="n">feature_importances_</span> <span class="o">:</span> <span class="n">t</span> <span class="o">-&gt;</span> <span class="o">[&gt;`</span><span class="nc">ArrayLike</span><span class="o">]</span> <span class="nn">Np</span><span class="p">.</span><span class="nn">Obj</span><span class="p">.</span><span class="n">t</span>
<span class="k">val</span> <span class="n">feature_importances_opt</span> <span class="o">:</span> <span class="n">t</span> <span class="o">-&gt;</span> <span class="o">([&gt;`</span><span class="nc">ArrayLike</span><span class="o">]</span> <span class="nn">Np</span><span class="p">.</span><span class="nn">Obj</span><span class="p">.</span><span class="n">t</span><span class="o">)</span> <span class="n">option</span>
</code></pre></div>

<p>This attribute is documented in <code>create</code> above. The first version raises Not_found
if the attribute is None. The _opt version returns an option.</p>
</details>
<h3 id="warning_4">warning<a class="headerlink" href="#warning_4" title="Permanent link">&para;</a></h3>
<details class="note" open="open"><summary>attribute warning</summary><div class="highlight"><pre><span></span><code><span class="k">val</span> <span class="n">warning</span> <span class="o">:</span> <span class="n">t</span> <span class="o">-&gt;</span> <span class="nn">Py</span><span class="p">.</span><span class="nn">Object</span><span class="p">.</span><span class="n">t</span>
<span class="k">val</span> <span class="n">warning_opt</span> <span class="o">:</span> <span class="n">t</span> <span class="o">-&gt;</span> <span class="o">(</span><span class="nn">Py</span><span class="p">.</span><span class="nn">Object</span><span class="p">.</span><span class="n">t</span><span class="o">)</span> <span class="n">option</span>
</code></pre></div>

<p>This attribute is documented in <code>create</code> above. The first version raises Not_found
if the attribute is None. The _opt version returns an option.</p>
</details>
<h3 id="oob_improvement_">oob_improvement_<a class="headerlink" href="#oob_improvement_" title="Permanent link">&para;</a></h3>
<details class="note" open="open"><summary>attribute oob_improvement_</summary><div class="highlight"><pre><span></span><code><span class="k">val</span> <span class="n">oob_improvement_</span> <span class="o">:</span> <span class="n">t</span> <span class="o">-&gt;</span> <span class="o">[&gt;`</span><span class="nc">ArrayLike</span><span class="o">]</span> <span class="nn">Np</span><span class="p">.</span><span class="nn">Obj</span><span class="p">.</span><span class="n">t</span>
<span class="k">val</span> <span class="n">oob_improvement_opt</span> <span class="o">:</span> <span class="n">t</span> <span class="o">-&gt;</span> <span class="o">([&gt;`</span><span class="nc">ArrayLike</span><span class="o">]</span> <span class="nn">Np</span><span class="p">.</span><span class="nn">Obj</span><span class="p">.</span><span class="n">t</span><span class="o">)</span> <span class="n">option</span>
</code></pre></div>

<p>This attribute is documented in <code>create</code> above. The first version raises Not_found
if the attribute is None. The _opt version returns an option.</p>
</details>
<h3 id="train_score_">train_score_<a class="headerlink" href="#train_score_" title="Permanent link">&para;</a></h3>
<details class="note" open="open"><summary>attribute train_score_</summary><div class="highlight"><pre><span></span><code><span class="k">val</span> <span class="n">train_score_</span> <span class="o">:</span> <span class="n">t</span> <span class="o">-&gt;</span> <span class="o">[&gt;`</span><span class="nc">ArrayLike</span><span class="o">]</span> <span class="nn">Np</span><span class="p">.</span><span class="nn">Obj</span><span class="p">.</span><span class="n">t</span>
<span class="k">val</span> <span class="n">train_score_opt</span> <span class="o">:</span> <span class="n">t</span> <span class="o">-&gt;</span> <span class="o">([&gt;`</span><span class="nc">ArrayLike</span><span class="o">]</span> <span class="nn">Np</span><span class="p">.</span><span class="nn">Obj</span><span class="p">.</span><span class="n">t</span><span class="o">)</span> <span class="n">option</span>
</code></pre></div>

<p>This attribute is documented in <code>create</code> above. The first version raises Not_found
if the attribute is None. The _opt version returns an option.</p>
</details>
<h3 id="loss_">loss_<a class="headerlink" href="#loss_" title="Permanent link">&para;</a></h3>
<details class="note" open="open"><summary>attribute loss_</summary><div class="highlight"><pre><span></span><code><span class="k">val</span> <span class="n">loss_</span> <span class="o">:</span> <span class="n">t</span> <span class="o">-&gt;</span> <span class="nn">Np</span><span class="p">.</span><span class="nn">NumpyRaw</span><span class="p">.</span><span class="nn">Ndarray</span><span class="p">.</span><span class="n">t</span> <span class="o">-&gt;</span> <span class="nn">Np</span><span class="p">.</span><span class="nn">NumpyRaw</span><span class="p">.</span><span class="nn">Ndarray</span><span class="p">.</span><span class="n">t</span> <span class="o">-&gt;</span> <span class="kt">float</span>
<span class="k">val</span> <span class="n">loss_opt</span> <span class="o">:</span> <span class="n">t</span> <span class="o">-&gt;</span> <span class="o">(</span><span class="nn">Np</span><span class="p">.</span><span class="nn">NumpyRaw</span><span class="p">.</span><span class="nn">Ndarray</span><span class="p">.</span><span class="n">t</span> <span class="o">-&gt;</span> <span class="nn">Np</span><span class="p">.</span><span class="nn">NumpyRaw</span><span class="p">.</span><span class="nn">Ndarray</span><span class="p">.</span><span class="n">t</span> <span class="o">-&gt;</span> <span class="kt">float</span><span class="o">)</span> <span class="n">option</span>
</code></pre></div>

<p>This attribute is documented in <code>create</code> above. The first version raises Not_found
if the attribute is None. The _opt version returns an option.</p>
</details>
<h3 id="init_">init_<a class="headerlink" href="#init_" title="Permanent link">&para;</a></h3>
<details class="note" open="open"><summary>attribute init_</summary><div class="highlight"><pre><span></span><code><span class="k">val</span> <span class="n">init_</span> <span class="o">:</span> <span class="n">t</span> <span class="o">-&gt;</span> <span class="o">[`</span><span class="nc">BaseEstimator</span><span class="o">|`</span><span class="nc">Object</span><span class="o">]</span> <span class="nn">Np</span><span class="p">.</span><span class="nn">Obj</span><span class="p">.</span><span class="n">t</span>
<span class="k">val</span> <span class="n">init_opt</span> <span class="o">:</span> <span class="n">t</span> <span class="o">-&gt;</span> <span class="o">([`</span><span class="nc">BaseEstimator</span><span class="o">|`</span><span class="nc">Object</span><span class="o">]</span> <span class="nn">Np</span><span class="p">.</span><span class="nn">Obj</span><span class="p">.</span><span class="n">t</span><span class="o">)</span> <span class="n">option</span>
</code></pre></div>

<p>This attribute is documented in <code>create</code> above. The first version raises Not_found
if the attribute is None. The _opt version returns an option.</p>
</details>
<h3 id="estimators__7">estimators_<a class="headerlink" href="#estimators__7" title="Permanent link">&para;</a></h3>
<details class="note" open="open"><summary>attribute estimators_</summary><div class="highlight"><pre><span></span><code><span class="k">val</span> <span class="n">estimators_</span> <span class="o">:</span> <span class="n">t</span> <span class="o">-&gt;</span> <span class="nn">Py</span><span class="p">.</span><span class="nn">Object</span><span class="p">.</span><span class="n">t</span>
<span class="k">val</span> <span class="n">estimators_opt</span> <span class="o">:</span> <span class="n">t</span> <span class="o">-&gt;</span> <span class="o">(</span><span class="nn">Py</span><span class="p">.</span><span class="nn">Object</span><span class="p">.</span><span class="n">t</span><span class="o">)</span> <span class="n">option</span>
</code></pre></div>

<p>This attribute is documented in <code>create</code> above. The first version raises Not_found
if the attribute is None. The _opt version returns an option.</p>
</details>
<h3 id="classes__3">classes_<a class="headerlink" href="#classes__3" title="Permanent link">&para;</a></h3>
<details class="note" open="open"><summary>attribute classes_</summary><div class="highlight"><pre><span></span><code><span class="k">val</span> <span class="n">classes_</span> <span class="o">:</span> <span class="n">t</span> <span class="o">-&gt;</span> <span class="o">[&gt;`</span><span class="nc">ArrayLike</span><span class="o">]</span> <span class="nn">Np</span><span class="p">.</span><span class="nn">Obj</span><span class="p">.</span><span class="n">t</span>
<span class="k">val</span> <span class="n">classes_opt</span> <span class="o">:</span> <span class="n">t</span> <span class="o">-&gt;</span> <span class="o">([&gt;`</span><span class="nc">ArrayLike</span><span class="o">]</span> <span class="nn">Np</span><span class="p">.</span><span class="nn">Obj</span><span class="p">.</span><span class="n">t</span><span class="o">)</span> <span class="n">option</span>
</code></pre></div>

<p>This attribute is documented in <code>create</code> above. The first version raises Not_found
if the attribute is None. The _opt version returns an option.</p>
</details>
<h3 id="n_features__4">n_features_<a class="headerlink" href="#n_features__4" title="Permanent link">&para;</a></h3>
<details class="note" open="open"><summary>attribute n_features_</summary><div class="highlight"><pre><span></span><code><span class="k">val</span> <span class="n">n_features_</span> <span class="o">:</span> <span class="n">t</span> <span class="o">-&gt;</span> <span class="kt">int</span>
<span class="k">val</span> <span class="n">n_features_opt</span> <span class="o">:</span> <span class="n">t</span> <span class="o">-&gt;</span> <span class="o">(</span><span class="kt">int</span><span class="o">)</span> <span class="n">option</span>
</code></pre></div>

<p>This attribute is documented in <code>create</code> above. The first version raises Not_found
if the attribute is None. The _opt version returns an option.</p>
</details>
<h3 id="n_classes__3">n_classes_<a class="headerlink" href="#n_classes__3" title="Permanent link">&para;</a></h3>
<details class="note" open="open"><summary>attribute n_classes_</summary><div class="highlight"><pre><span></span><code><span class="k">val</span> <span class="n">n_classes_</span> <span class="o">:</span> <span class="n">t</span> <span class="o">-&gt;</span> <span class="kt">int</span>
<span class="k">val</span> <span class="n">n_classes_opt</span> <span class="o">:</span> <span class="n">t</span> <span class="o">-&gt;</span> <span class="o">(</span><span class="kt">int</span><span class="o">)</span> <span class="n">option</span>
</code></pre></div>

<p>This attribute is documented in <code>create</code> above. The first version raises Not_found
if the attribute is None. The _opt version returns an option.</p>
</details>
<h3 id="max_features_">max_features_<a class="headerlink" href="#max_features_" title="Permanent link">&para;</a></h3>
<details class="note" open="open"><summary>attribute max_features_</summary><div class="highlight"><pre><span></span><code><span class="k">val</span> <span class="n">max_features_</span> <span class="o">:</span> <span class="n">t</span> <span class="o">-&gt;</span> <span class="kt">int</span>
<span class="k">val</span> <span class="n">max_features_opt</span> <span class="o">:</span> <span class="n">t</span> <span class="o">-&gt;</span> <span class="o">(</span><span class="kt">int</span><span class="o">)</span> <span class="n">option</span>
</code></pre></div>

<p>This attribute is documented in <code>create</code> above. The first version raises Not_found
if the attribute is None. The _opt version returns an option.</p>
</details>
<h3 id="to_string_7">to_string<a class="headerlink" href="#to_string_7" title="Permanent link">&para;</a></h3>
<details class="note" open="open"><summary>method to_string</summary><div class="highlight"><pre><span></span><code><span class="k">val</span> <span class="n">to_string</span><span class="o">:</span> <span class="n">t</span> <span class="o">-&gt;</span> <span class="kt">string</span>
</code></pre></div>

<p>Print the object to a human-readable representation.</p>
</details>
<h3 id="show_7">show<a class="headerlink" href="#show_7" title="Permanent link">&para;</a></h3>
<details class="note" open="open"><summary>method show</summary><div class="highlight"><pre><span></span><code><span class="k">val</span> <span class="n">show</span><span class="o">:</span> <span class="n">t</span> <span class="o">-&gt;</span> <span class="kt">string</span>
</code></pre></div>

<p>Print the object to a human-readable representation.</p>
</details>
<h3 id="pp_7">pp<a class="headerlink" href="#pp_7" title="Permanent link">&para;</a></h3>
<details class="note" open="open"><summary>method pp</summary><div class="highlight"><pre><span></span><code><span class="k">val</span> <span class="n">pp</span><span class="o">:</span> <span class="nn">Format</span><span class="p">.</span><span class="n">formatter</span> <span class="o">-&gt;</span> <span class="n">t</span> <span class="o">-&gt;</span> <span class="kt">unit</span>
</code></pre></div>

<p>Pretty-print the object to a formatter.</p>
</details>
<h2 id="gradientboostingregressor">GradientBoostingRegressor<a class="headerlink" href="#gradientboostingregressor" title="Permanent link">&para;</a></h2>
<p>Module <code>Sklearn.​Ensemble.​GradientBoostingRegressor</code> wraps Python class <a href="https://scikit-learn.org/stable/modules/generated/sklearn.ensemble.GradientBoostingRegressor.html"><code>sklearn.ensemble.GradientBoostingRegressor</code></a>.</p>
<div class="highlight"><pre><span></span><code><span class="k">type</span> <span class="n">t</span>
</code></pre></div>

<h3 id="create_7">create<a class="headerlink" href="#create_7" title="Permanent link">&para;</a></h3>
<details class="note" open="open"><summary>constructor and attributes create</summary><div class="highlight"><pre><span></span><code><span class="k">val</span> <span class="n">create</span> <span class="o">:</span>
  <span class="o">?</span><span class="n">loss</span><span class="o">:[`</span><span class="nc">Ls</span> <span class="o">|</span> <span class="o">`</span><span class="nc">Lad</span> <span class="o">|</span> <span class="o">`</span><span class="nc">Huber</span> <span class="o">|</span> <span class="o">`</span><span class="nc">Quantile</span><span class="o">]</span> <span class="o">-&gt;</span>
  <span class="o">?</span><span class="n">learning_rate</span><span class="o">:</span><span class="kt">float</span> <span class="o">-&gt;</span>
  <span class="o">?</span><span class="n">n_estimators</span><span class="o">:</span><span class="kt">int</span> <span class="o">-&gt;</span>
  <span class="o">?</span><span class="n">subsample</span><span class="o">:</span><span class="kt">float</span> <span class="o">-&gt;</span>
  <span class="o">?</span><span class="n">criterion</span><span class="o">:[`</span><span class="nc">Friedman_mse</span> <span class="o">|</span> <span class="o">`</span><span class="nc">Mse</span> <span class="o">|</span> <span class="o">`</span><span class="nc">Mae</span><span class="o">]</span> <span class="o">-&gt;</span>
  <span class="o">?</span><span class="n">min_samples_split</span><span class="o">:[`</span><span class="nc">F</span> <span class="k">of</span> <span class="kt">float</span> <span class="o">|</span> <span class="o">`</span><span class="nc">I</span> <span class="k">of</span> <span class="kt">int</span><span class="o">]</span> <span class="o">-&gt;</span>
  <span class="o">?</span><span class="n">min_samples_leaf</span><span class="o">:[`</span><span class="nc">F</span> <span class="k">of</span> <span class="kt">float</span> <span class="o">|</span> <span class="o">`</span><span class="nc">I</span> <span class="k">of</span> <span class="kt">int</span><span class="o">]</span> <span class="o">-&gt;</span>
  <span class="o">?</span><span class="n">min_weight_fraction_leaf</span><span class="o">:</span><span class="kt">float</span> <span class="o">-&gt;</span>
  <span class="o">?</span><span class="n">max_depth</span><span class="o">:</span><span class="kt">int</span> <span class="o">-&gt;</span>
  <span class="o">?</span><span class="n">min_impurity_decrease</span><span class="o">:</span><span class="kt">float</span> <span class="o">-&gt;</span>
  <span class="o">?</span><span class="n">min_impurity_split</span><span class="o">:</span><span class="kt">float</span> <span class="o">-&gt;</span>
  <span class="o">?</span><span class="n">init</span><span class="o">:[`</span><span class="nc">Zero</span> <span class="o">|</span> <span class="o">`</span><span class="nc">BaseEstimator</span> <span class="k">of</span> <span class="o">[&gt;`</span><span class="nc">BaseEstimator</span><span class="o">]</span> <span class="nn">Np</span><span class="p">.</span><span class="nn">Obj</span><span class="p">.</span><span class="n">t</span><span class="o">]</span> <span class="o">-&gt;</span>
  <span class="o">?</span><span class="n">random_state</span><span class="o">:</span><span class="kt">int</span> <span class="o">-&gt;</span>
  <span class="o">?</span><span class="n">max_features</span><span class="o">:[`</span><span class="nc">I</span> <span class="k">of</span> <span class="kt">int</span> <span class="o">|</span> <span class="o">`</span><span class="nc">Sqrt</span> <span class="o">|</span> <span class="o">`</span><span class="nc">Auto</span> <span class="o">|</span> <span class="o">`</span><span class="nc">F</span> <span class="k">of</span> <span class="kt">float</span> <span class="o">|</span> <span class="o">`</span><span class="nc">Log2</span><span class="o">]</span> <span class="o">-&gt;</span>
  <span class="o">?</span><span class="n">alpha</span><span class="o">:</span><span class="kt">float</span> <span class="o">-&gt;</span>
  <span class="o">?</span><span class="n">verbose</span><span class="o">:</span><span class="kt">int</span> <span class="o">-&gt;</span>
  <span class="o">?</span><span class="n">max_leaf_nodes</span><span class="o">:</span><span class="kt">int</span> <span class="o">-&gt;</span>
  <span class="o">?</span><span class="n">warm_start</span><span class="o">:</span><span class="kt">bool</span> <span class="o">-&gt;</span>
  <span class="o">?</span><span class="n">presort</span><span class="o">:</span><span class="nn">Py</span><span class="p">.</span><span class="nn">Object</span><span class="p">.</span><span class="n">t</span> <span class="o">-&gt;</span>
  <span class="o">?</span><span class="n">validation_fraction</span><span class="o">:</span><span class="kt">float</span> <span class="o">-&gt;</span>
  <span class="o">?</span><span class="n">n_iter_no_change</span><span class="o">:</span><span class="kt">int</span> <span class="o">-&gt;</span>
  <span class="o">?</span><span class="n">tol</span><span class="o">:</span><span class="kt">float</span> <span class="o">-&gt;</span>
  <span class="o">?</span><span class="n">ccp_alpha</span><span class="o">:</span><span class="kt">float</span> <span class="o">-&gt;</span>
  <span class="kt">unit</span> <span class="o">-&gt;</span>
  <span class="n">t</span>
</code></pre></div>

<p>Gradient Boosting for regression.</p>
<p>GB builds an additive model in a forward stage-wise fashion;
it allows for the optimization of arbitrary differentiable loss functions.
In each stage a regression tree is fit on the negative gradient of the
given loss function.</p>
<p>Read more in the :ref:<code>User Guide &lt;gradient_boosting&gt;</code>.</p>
<h4>Parameters</h4>
<ul>
<li>
<p><strong>loss : {'ls', 'lad', 'huber', 'quantile'}, default='ls'</strong>
    loss function to be optimized. 'ls' refers to least squares
    regression. 'lad' (least absolute deviation) is a highly robust
    loss function solely based on order information of the input
    variables. 'huber' is a combination of the two. 'quantile'
    allows quantile regression (use <code>alpha</code> to specify the quantile).</p>
</li>
<li>
<p><strong>learning_rate : float, default=0.1</strong>
    learning rate shrinks the contribution of each tree by <code>learning_rate</code>.
    There is a trade-off between learning_rate and n_estimators.</p>
</li>
<li>
<p><strong>n_estimators : int, default=100</strong>
    The number of boosting stages to perform. Gradient boosting
    is fairly robust to over-fitting so a large number usually
    results in better performance.</p>
</li>
<li>
<p><strong>subsample : float, default=1.0</strong>
    The fraction of samples to be used for fitting the individual base
    learners. If smaller than 1.0 this results in Stochastic Gradient
    Boosting. <code>subsample</code> interacts with the parameter <code>n_estimators</code>.
    Choosing <code>subsample &lt; 1.0</code> leads to a reduction of variance
    and an increase in bias.</p>
</li>
<li>
<p><strong>criterion : {'friedman_mse', 'mse', 'mae'}, default='friedman_mse'</strong>
    The function to measure the quality of a split. Supported criteria
    are 'friedman_mse' for the mean squared error with improvement
    score by Friedman, 'mse' for mean squared error, and 'mae' for
    the mean absolute error. The default value of 'friedman_mse' is
    generally the best as it can provide a better approximation in
    some cases.</p>
<p>.. versionadded:: 0.18</p>
</li>
<li>
<p><strong>min_samples_split : int or float, default=2</strong>
    The minimum number of samples required to split an internal node:</p>
<ul>
<li>If int, then consider <code>min_samples_split</code> as the minimum number.</li>
<li>If float, then <code>min_samples_split</code> is a fraction and
  <code>ceil(min_samples_split * n_samples)</code> are the minimum
  number of samples for each split.</li>
</ul>
<p>.. versionchanged:: 0.18
   Added float values for fractions.</p>
</li>
<li>
<p><strong>min_samples_leaf : int or float, default=1</strong>
    The minimum number of samples required to be at a leaf node.
    A split point at any depth will only be considered if it leaves at
    least <code>min_samples_leaf</code> training samples in each of the left and
    right branches.  This may have the effect of smoothing the model,
    especially in regression.</p>
<ul>
<li>If int, then consider <code>min_samples_leaf</code> as the minimum number.</li>
<li>If float, then <code>min_samples_leaf</code> is a fraction and
  <code>ceil(min_samples_leaf * n_samples)</code> are the minimum
  number of samples for each node.</li>
</ul>
<p>.. versionchanged:: 0.18
   Added float values for fractions.</p>
</li>
<li>
<p><strong>min_weight_fraction_leaf : float, default=0.0</strong>
    The minimum weighted fraction of the sum total of weights (of all
    the input samples) required to be at a leaf node. Samples have
    equal weight when sample_weight is not provided.</p>
</li>
<li>
<p><strong>max_depth : int, default=3</strong>
    maximum depth of the individual regression estimators. The maximum
    depth limits the number of nodes in the tree. Tune this parameter
    for best performance; the best value depends on the interaction
    of the input variables.</p>
</li>
<li>
<p><strong>min_impurity_decrease : float, default=0.0</strong>
    A node will be split if this split induces a decrease of the impurity
    greater than or equal to this value.</p>
<p>The weighted impurity decrease equation is the following::</p>
<div class="codehilite"><pre><span></span><code>N_t / N * (impurity - N_t_R / N_t * right_impurity
                    - N_t_L / N_t * left_impurity)
</code></pre></div>


<p>where <code>N</code> is the total number of samples, <code>N_t</code> is the number of
samples at the current node, <code>N_t_L</code> is the number of samples in the
left child, and <code>N_t_R</code> is the number of samples in the right child.</p>
<p><code>N</code>, <code>N_t</code>, <code>N_t_R</code> and <code>N_t_L</code> all refer to the weighted sum,
if <code>sample_weight</code> is passed.</p>
<p>.. versionadded:: 0.19</p>
</li>
<li>
<p><strong>min_impurity_split : float, default=None</strong>
    Threshold for early stopping in tree growth. A node will split
    if its impurity is above the threshold, otherwise it is a leaf.</p>
<p>.. deprecated:: 0.19
   <code>min_impurity_split</code> has been deprecated in favor of
   <code>min_impurity_decrease</code> in 0.19. The default value of
   <code>min_impurity_split</code> has changed from 1e-7 to 0 in 0.23 and it
   will be removed in 0.25. Use <code>min_impurity_decrease</code> instead.</p>
</li>
<li>
<p><strong>init : estimator or 'zero', default=None</strong>
    An estimator object that is used to compute the initial predictions.
    <code>init</code> has to provide :term:<code>fit</code> and :term:<code>predict</code>. If 'zero', the
    initial raw predictions are set to zero. By default a
    <code>DummyEstimator</code> is used, predicting either the average target value
    (for loss='ls'), or a quantile for the other losses.</p>
</li>
<li>
<p><strong>random_state : int or RandomState, default=None</strong>
    Controls the random seed given to each Tree estimator at each
    boosting iteration.
    In addition, it controls the random permutation of the features at
    each split (see Notes for more details).
    It also controls the random spliting of the training data to obtain a
    validation set if <code>n_iter_no_change</code> is not None.
    Pass an int for reproducible output across multiple function calls.</p>
</li>
<li>
<p><strong>See :term:<code>Glossary &lt;random_state&gt;</code>.</strong></p>
</li>
<li>
<p><strong>max_features : {'auto', 'sqrt', 'log2'}, int or float, default=None</strong>
    The number of features to consider when looking for the best split:</p>
<ul>
<li>If int, then consider <code>max_features</code> features at each split.</li>
<li>If float, then <code>max_features</code> is a fraction and
  <code>int(max_features * n_features)</code> features are considered at each
  split.</li>
<li>If 'auto', then <code>max_features=n_features</code>.</li>
<li>If 'sqrt', then <code>max_features=sqrt(n_features)</code>.</li>
<li>If 'log2', then <code>max_features=log2(n_features)</code>.</li>
<li>If None, then <code>max_features=n_features</code>.</li>
</ul>
<p>Choosing <code>max_features &lt; n_features</code> leads to a reduction of variance
and an increase in bias.</p>
</li>
<li>
<p><strong>Note: the search for a split does not stop until at least one</strong>
    valid partition of the node samples is found, even if it requires to
    effectively inspect more than <code>max_features</code> features.</p>
</li>
<li>
<p><strong>alpha : float, default=0.9</strong>
    The alpha-quantile of the huber loss function and the quantile
    loss function. Only if <code>loss='huber'</code> or <code>loss='quantile'</code>.</p>
</li>
<li>
<p><strong>verbose : int, default=0</strong>
    Enable verbose output. If 1 then it prints progress and performance
    once in a while (the more trees the lower the frequency). If greater
    than 1 then it prints progress and performance for every tree.</p>
</li>
<li>
<p><strong>max_leaf_nodes : int, default=None</strong>
    Grow trees with <code>max_leaf_nodes</code> in best-first fashion.
    Best nodes are defined as relative reduction in impurity.
    If None then unlimited number of leaf nodes.</p>
</li>
<li>
<p><strong>warm_start : bool, default=False</strong>
    When set to <code>True</code>, reuse the solution of the previous call to fit
    and add more estimators to the ensemble, otherwise, just erase the
    previous solution. See :term:<code>the Glossary &lt;warm_start&gt;</code>.</p>
</li>
<li>
<p><strong>presort : deprecated, default='deprecated'</strong>
    This parameter is deprecated and will be removed in v0.24.</p>
<p>.. deprecated :: 0.22</p>
</li>
<li>
<p><strong>validation_fraction : float, default=0.1</strong>
    The proportion of training data to set aside as validation set for
    early stopping. Must be between 0 and 1.
    Only used if <code>n_iter_no_change</code> is set to an integer.</p>
<p>.. versionadded:: 0.20</p>
</li>
<li>
<p><strong>n_iter_no_change : int, default=None</strong>
    <code>n_iter_no_change</code> is used to decide if early stopping will be used
    to terminate training when validation score is not improving. By
    default it is set to None to disable early stopping. If set to a
    number, it will set aside <code>validation_fraction</code> size of the training
    data as validation and terminate training when validation score is not
    improving in all of the previous <code>n_iter_no_change</code> numbers of
    iterations.</p>
<p>.. versionadded:: 0.20</p>
</li>
<li>
<p><strong>tol : float, default=1e-4</strong>
    Tolerance for the early stopping. When the loss is not improving
    by at least tol for <code>n_iter_no_change</code> iterations (if set to a
    number), the training stops.</p>
<p>.. versionadded:: 0.20</p>
</li>
<li>
<p><strong>ccp_alpha : non-negative float, default=0.0</strong>
    Complexity parameter used for Minimal Cost-Complexity Pruning. The
    subtree with the largest cost complexity that is smaller than
    <code>ccp_alpha</code> will be chosen. By default, no pruning is performed. See
    :ref:<code>minimal_cost_complexity_pruning</code> for details.</p>
<p>.. versionadded:: 0.22</p>
</li>
</ul>
<h4>Attributes</h4>
<ul>
<li>
<p><strong>feature_importances_ : ndarray of shape (n_features,)</strong>
    The impurity-based feature importances.
    The higher, the more important the feature.
    The importance of a feature is computed as the (normalized)
    total reduction of the criterion brought by that feature.  It is also
    known as the Gini importance.</p>
</li>
<li>
<p><strong>Warning: impurity-based feature importances can be misleading for</strong>
    high cardinality features (many unique values). See
    :func:<code>sklearn.inspection.permutation_importance</code> as an alternative.</p>
</li>
<li>
<p><strong>oob_improvement_ : ndarray of shape (n_estimators,)</strong>
    The improvement in loss (= deviance) on the out-of-bag samples
    relative to the previous iteration.
    <code>oob_improvement_[0]</code> is the improvement in
    loss of the first stage over the <code>init</code> estimator.
    Only available if <code>subsample &lt; 1.0</code></p>
</li>
<li>
<p><strong>train_score_ : ndarray of shape (n_estimators,)</strong>
    The i-th score <code>train_score_[i]</code> is the deviance (= loss) of the
    model at iteration <code>i</code> on the in-bag sample.
    If <code>subsample == 1</code> this is the deviance on the training data.</p>
</li>
<li>
<p><strong>loss_ : LossFunction</strong>
    The concrete <code>LossFunction</code> object.</p>
</li>
<li>
<p><strong>init_ : estimator</strong>
    The estimator that provides the initial predictions.
    Set via the <code>init</code> argument or <code>loss.init_estimator</code>.</p>
</li>
<li>
<p><strong>estimators_ : ndarray of DecisionTreeRegressor of shape (n_estimators, 1)</strong>
    The collection of fitted sub-estimators.</p>
</li>
<li>
<p><strong>n_features_ : int</strong>
    The number of data features.</p>
</li>
<li>
<p><strong>max_features_ : int</strong>
    The inferred value of max_features.</p>
</li>
</ul>
<h4>Notes</h4>
<p>The features are always randomly permuted at each split. Therefore,
the best found split may vary, even with the same training data and
<code>max_features=n_features</code>, if the improvement of the criterion is
identical for several splits enumerated during the search of the best
split. To obtain a deterministic behaviour during fitting,
<code>random_state</code> has to be fixed.</p>
<h4>Examples</h4>
<div class="highlight"><pre><span></span><code><span class="o">&gt;&gt;&gt;</span> <span class="kn">from</span> <span class="nn">sklearn.datasets</span> <span class="kn">import</span> <span class="n">make_regression</span>
<span class="o">&gt;&gt;&gt;</span> <span class="kn">from</span> <span class="nn">sklearn.ensemble</span> <span class="kn">import</span> <span class="n">GradientBoostingRegressor</span>
<span class="o">&gt;&gt;&gt;</span> <span class="kn">from</span> <span class="nn">sklearn.model_selection</span> <span class="kn">import</span> <span class="n">train_test_split</span>
<span class="o">&gt;&gt;&gt;</span> <span class="n">X</span><span class="p">,</span> <span class="n">y</span> <span class="o">=</span> <span class="n">make_regression</span><span class="p">(</span><span class="n">random_state</span><span class="o">=</span><span class="mi">0</span><span class="p">)</span>
<span class="o">&gt;&gt;&gt;</span> <span class="n">X_train</span><span class="p">,</span> <span class="n">X_test</span><span class="p">,</span> <span class="n">y_train</span><span class="p">,</span> <span class="n">y_test</span> <span class="o">=</span> <span class="n">train_test_split</span><span class="p">(</span>
<span class="o">...</span>     <span class="n">X</span><span class="p">,</span> <span class="n">y</span><span class="p">,</span> <span class="n">random_state</span><span class="o">=</span><span class="mi">0</span><span class="p">)</span>
<span class="o">&gt;&gt;&gt;</span> <span class="n">reg</span> <span class="o">=</span> <span class="n">GradientBoostingRegressor</span><span class="p">(</span><span class="n">random_state</span><span class="o">=</span><span class="mi">0</span><span class="p">)</span>
<span class="o">&gt;&gt;&gt;</span> <span class="n">reg</span><span class="o">.</span><span class="n">fit</span><span class="p">(</span><span class="n">X_train</span><span class="p">,</span> <span class="n">y_train</span><span class="p">)</span>
<span class="n">GradientBoostingRegressor</span><span class="p">(</span><span class="n">random_state</span><span class="o">=</span><span class="mi">0</span><span class="p">)</span>
<span class="o">&gt;&gt;&gt;</span> <span class="n">reg</span><span class="o">.</span><span class="n">predict</span><span class="p">(</span><span class="n">X_test</span><span class="p">[</span><span class="mi">1</span><span class="p">:</span><span class="mi">2</span><span class="p">])</span>
<span class="n">array</span><span class="p">([</span><span class="o">-</span><span class="mf">61.</span><span class="o">..</span><span class="p">])</span>
<span class="o">&gt;&gt;&gt;</span> <span class="n">reg</span><span class="o">.</span><span class="n">score</span><span class="p">(</span><span class="n">X_test</span><span class="p">,</span> <span class="n">y_test</span><span class="p">)</span>
<span class="mf">0.4</span><span class="o">...</span>
</code></pre></div>

<h4>See also</h4>
<p>sklearn.ensemble.HistGradientBoostingRegressor,
sklearn.tree.DecisionTreeRegressor, RandomForestRegressor</p>
<h4>References</h4>
<p>J. Friedman, Greedy Function Approximation: A Gradient Boosting
Machine, The Annals of Statistics, Vol. 29, No. 5, 2001.</p>
<p>J. Friedman, Stochastic Gradient Boosting, 1999</p>
<p>T. Hastie, R. Tibshirani and J. Friedman.
Elements of Statistical Learning Ed. 2, Springer, 2009.</p>
</details>
<h3 id="get_item_8">get_item<a class="headerlink" href="#get_item_8" title="Permanent link">&para;</a></h3>
<details class="note" open="open"><summary>method get_item</summary><div class="highlight"><pre><span></span><code><span class="k">val</span> <span class="n">get_item</span> <span class="o">:</span>
  <span class="n">index</span><span class="o">:</span><span class="nn">Py</span><span class="p">.</span><span class="nn">Object</span><span class="p">.</span><span class="n">t</span> <span class="o">-&gt;</span>
  <span class="o">[&gt;</span> <span class="n">tag</span><span class="o">]</span> <span class="nn">Obj</span><span class="p">.</span><span class="n">t</span> <span class="o">-&gt;</span>
  <span class="nn">Py</span><span class="p">.</span><span class="nn">Object</span><span class="p">.</span><span class="n">t</span>
</code></pre></div>

<p>Return the index'th estimator in the ensemble.</p>
</details>
<h3 id="iter_8">iter<a class="headerlink" href="#iter_8" title="Permanent link">&para;</a></h3>
<details class="note" open="open"><summary>method iter</summary><div class="highlight"><pre><span></span><code><span class="k">val</span> <span class="n">iter</span> <span class="o">:</span>
  <span class="o">[&gt;</span> <span class="n">tag</span><span class="o">]</span> <span class="nn">Obj</span><span class="p">.</span><span class="n">t</span> <span class="o">-&gt;</span>
  <span class="nn">Dict</span><span class="p">.</span><span class="n">t</span> <span class="nn">Seq</span><span class="p">.</span><span class="n">t</span>
</code></pre></div>

<p>Return iterator over estimators in the ensemble.</p>
</details>
<h3 id="apply_3">apply<a class="headerlink" href="#apply_3" title="Permanent link">&para;</a></h3>
<details class="note" open="open"><summary>method apply</summary><div class="highlight"><pre><span></span><code><span class="k">val</span> <span class="n">apply</span> <span class="o">:</span>
  <span class="n">x</span><span class="o">:[&gt;`</span><span class="nc">ArrayLike</span><span class="o">]</span> <span class="nn">Np</span><span class="p">.</span><span class="nn">Obj</span><span class="p">.</span><span class="n">t</span> <span class="o">-&gt;</span>
  <span class="o">[&gt;</span> <span class="n">tag</span><span class="o">]</span> <span class="nn">Obj</span><span class="p">.</span><span class="n">t</span> <span class="o">-&gt;</span>
  <span class="o">[&gt;`</span><span class="nc">ArrayLike</span><span class="o">]</span> <span class="nn">Np</span><span class="p">.</span><span class="nn">Obj</span><span class="p">.</span><span class="n">t</span>
</code></pre></div>

<p>Apply trees in the ensemble to X, return leaf indices.</p>
<p>.. versionadded:: 0.17</p>
<h4>Parameters</h4>
<ul>
<li><strong>X : {array-like, sparse matrix} of shape (n_samples, n_features)</strong>
    The input samples. Internally, its dtype will be converted to
    <code>dtype=np.float32</code>. If a sparse matrix is provided, it will
    be converted to a sparse <code>csr_matrix</code>.</li>
</ul>
<h4>Returns</h4>
<ul>
<li><strong>X_leaves : array-like of shape (n_samples, n_estimators)</strong>
    For each datapoint x in X and for each tree in the ensemble,
    return the index of the leaf x ends up in each estimator.</li>
</ul>
</details>
<h3 id="fit_7">fit<a class="headerlink" href="#fit_7" title="Permanent link">&para;</a></h3>
<details class="note" open="open"><summary>method fit</summary><div class="highlight"><pre><span></span><code><span class="k">val</span> <span class="n">fit</span> <span class="o">:</span>
  <span class="o">?</span><span class="n">sample_weight</span><span class="o">:[&gt;`</span><span class="nc">ArrayLike</span><span class="o">]</span> <span class="nn">Np</span><span class="p">.</span><span class="nn">Obj</span><span class="p">.</span><span class="n">t</span> <span class="o">-&gt;</span>
  <span class="o">?</span><span class="n">monitor</span><span class="o">:</span><span class="nn">Py</span><span class="p">.</span><span class="nn">Object</span><span class="p">.</span><span class="n">t</span> <span class="o">-&gt;</span>
  <span class="n">x</span><span class="o">:[&gt;`</span><span class="nc">ArrayLike</span><span class="o">]</span> <span class="nn">Np</span><span class="p">.</span><span class="nn">Obj</span><span class="p">.</span><span class="n">t</span> <span class="o">-&gt;</span>
  <span class="n">y</span><span class="o">:[&gt;`</span><span class="nc">ArrayLike</span><span class="o">]</span> <span class="nn">Np</span><span class="p">.</span><span class="nn">Obj</span><span class="p">.</span><span class="n">t</span> <span class="o">-&gt;</span>
  <span class="o">[&gt;</span> <span class="n">tag</span><span class="o">]</span> <span class="nn">Obj</span><span class="p">.</span><span class="n">t</span> <span class="o">-&gt;</span>
  <span class="n">t</span>
</code></pre></div>

<p>Fit the gradient boosting model.</p>
<h4>Parameters</h4>
<ul>
<li>
<p><strong>X : {array-like, sparse matrix} of shape (n_samples, n_features)</strong>
    The input samples. Internally, it will be converted to
    <code>dtype=np.float32</code> and if a sparse matrix is provided
    to a sparse <code>csr_matrix</code>.</p>
</li>
<li>
<p><strong>y : array-like of shape (n_samples,)</strong>
    Target values (strings or integers in classification, real numbers
    in regression)
    For classification, labels must correspond to classes.</p>
</li>
<li>
<p><strong>sample_weight : array-like of shape (n_samples,), default=None</strong>
    Sample weights. If None, then samples are equally weighted. Splits
    that would create child nodes with net zero or negative weight are
    ignored while searching for a split in each node. In the case of
    classification, splits are also ignored if they would result in any
    single class carrying a negative weight in either child node.</p>
</li>
<li>
<p><strong>monitor : callable, default=None</strong>
    The monitor is called after each iteration with the current
    iteration, a reference to the estimator and the local variables of
    <code>_fit_stages</code> as keyword arguments <code>callable(i, self,
    locals())</code>. If the callable returns <code>True</code> the fitting procedure
    is stopped. The monitor can be used for various things such as
    computing held-out estimates, early stopping, model introspect, and
    snapshoting.</p>
</li>
</ul>
<h4>Returns</h4>
<ul>
<li><strong>self : object</strong></li>
</ul>
</details>
<h3 id="get_params_8">get_params<a class="headerlink" href="#get_params_8" title="Permanent link">&para;</a></h3>
<details class="note" open="open"><summary>method get_params</summary><div class="highlight"><pre><span></span><code><span class="k">val</span> <span class="n">get_params</span> <span class="o">:</span>
  <span class="o">?</span><span class="n">deep</span><span class="o">:</span><span class="kt">bool</span> <span class="o">-&gt;</span>
  <span class="o">[&gt;</span> <span class="n">tag</span><span class="o">]</span> <span class="nn">Obj</span><span class="p">.</span><span class="n">t</span> <span class="o">-&gt;</span>
  <span class="nn">Dict</span><span class="p">.</span><span class="n">t</span>
</code></pre></div>

<p>Get parameters for this estimator.</p>
<h4>Parameters</h4>
<ul>
<li><strong>deep : bool, default=True</strong>
    If True, will return the parameters for this estimator and
    contained subobjects that are estimators.</li>
</ul>
<h4>Returns</h4>
<ul>
<li><strong>params : mapping of string to any</strong>
    Parameter names mapped to their values.</li>
</ul>
</details>
<h3 id="predict_7">predict<a class="headerlink" href="#predict_7" title="Permanent link">&para;</a></h3>
<details class="note" open="open"><summary>method predict</summary><div class="highlight"><pre><span></span><code><span class="k">val</span> <span class="n">predict</span> <span class="o">:</span>
  <span class="n">x</span><span class="o">:[&gt;`</span><span class="nc">ArrayLike</span><span class="o">]</span> <span class="nn">Np</span><span class="p">.</span><span class="nn">Obj</span><span class="p">.</span><span class="n">t</span> <span class="o">-&gt;</span>
  <span class="o">[&gt;</span> <span class="n">tag</span><span class="o">]</span> <span class="nn">Obj</span><span class="p">.</span><span class="n">t</span> <span class="o">-&gt;</span>
  <span class="o">[&gt;`</span><span class="nc">ArrayLike</span><span class="o">]</span> <span class="nn">Np</span><span class="p">.</span><span class="nn">Obj</span><span class="p">.</span><span class="n">t</span>
</code></pre></div>

<p>Predict regression target for X.</p>
<h4>Parameters</h4>
<ul>
<li><strong>X : {array-like, sparse matrix} of shape (n_samples, n_features)</strong>
    The input samples. Internally, it will be converted to
    <code>dtype=np.float32</code> and if a sparse matrix is provided
    to a sparse <code>csr_matrix</code>.</li>
</ul>
<h4>Returns</h4>
<ul>
<li><strong>y : ndarray of shape (n_samples,)</strong>
    The predicted values.</li>
</ul>
</details>
<h3 id="score_7">score<a class="headerlink" href="#score_7" title="Permanent link">&para;</a></h3>
<details class="note" open="open"><summary>method score</summary><div class="highlight"><pre><span></span><code><span class="k">val</span> <span class="n">score</span> <span class="o">:</span>
  <span class="o">?</span><span class="n">sample_weight</span><span class="o">:[&gt;`</span><span class="nc">ArrayLike</span><span class="o">]</span> <span class="nn">Np</span><span class="p">.</span><span class="nn">Obj</span><span class="p">.</span><span class="n">t</span> <span class="o">-&gt;</span>
  <span class="n">x</span><span class="o">:[&gt;`</span><span class="nc">ArrayLike</span><span class="o">]</span> <span class="nn">Np</span><span class="p">.</span><span class="nn">Obj</span><span class="p">.</span><span class="n">t</span> <span class="o">-&gt;</span>
  <span class="n">y</span><span class="o">:[&gt;`</span><span class="nc">ArrayLike</span><span class="o">]</span> <span class="nn">Np</span><span class="p">.</span><span class="nn">Obj</span><span class="p">.</span><span class="n">t</span> <span class="o">-&gt;</span>
  <span class="o">[&gt;</span> <span class="n">tag</span><span class="o">]</span> <span class="nn">Obj</span><span class="p">.</span><span class="n">t</span> <span class="o">-&gt;</span>
  <span class="kt">float</span>
</code></pre></div>

<p>Return the coefficient of determination R^2 of the prediction.</p>
<p>The coefficient R^2 is defined as (1 - u/v), where u is the residual
sum of squares ((y_true - y_pred) <strong> 2).sum() and v is the total
sum of squares ((y_true - y_true.mean()) </strong> 2).sum().
The best possible score is 1.0 and it can be negative (because the
model can be arbitrarily worse). A constant model that always
predicts the expected value of y, disregarding the input features,
would get a R^2 score of 0.0.</p>
<h4>Parameters</h4>
<ul>
<li>
<p><strong>X : array-like of shape (n_samples, n_features)</strong>
    Test samples. For some estimators this may be a
    precomputed kernel matrix or a list of generic objects instead,
    shape = (n_samples, n_samples_fitted),
    where n_samples_fitted is the number of
    samples used in the fitting for the estimator.</p>
</li>
<li>
<p><strong>y : array-like of shape (n_samples,) or (n_samples, n_outputs)</strong>
    True values for X.</p>
</li>
<li>
<p><strong>sample_weight : array-like of shape (n_samples,), default=None</strong>
    Sample weights.</p>
</li>
</ul>
<h4>Returns</h4>
<ul>
<li><strong>score : float</strong>
    R^2 of self.predict(X) wrt. y.</li>
</ul>
<h4>Notes</h4>
<p>The R2 score used when calling <code>score</code> on a regressor uses
<code>multioutput='uniform_average'</code> from version 0.23 to keep consistent
with default value of :func:<code>~sklearn.metrics.r2_score</code>.
This influences the <code>score</code> method of all the multioutput
regressors (except for
:class:<code>~sklearn.multioutput.MultiOutputRegressor</code>).</p>
</details>
<h3 id="set_params_8">set_params<a class="headerlink" href="#set_params_8" title="Permanent link">&para;</a></h3>
<details class="note" open="open"><summary>method set_params</summary><div class="highlight"><pre><span></span><code><span class="k">val</span> <span class="n">set_params</span> <span class="o">:</span>
  <span class="o">?</span><span class="n">params</span><span class="o">:(</span><span class="kt">string</span> <span class="o">*</span> <span class="nn">Py</span><span class="p">.</span><span class="nn">Object</span><span class="p">.</span><span class="n">t</span><span class="o">)</span> <span class="kt">list</span> <span class="o">-&gt;</span>
  <span class="o">[&gt;</span> <span class="n">tag</span><span class="o">]</span> <span class="nn">Obj</span><span class="p">.</span><span class="n">t</span> <span class="o">-&gt;</span>
  <span class="n">t</span>
</code></pre></div>

<p>Set the parameters of this estimator.</p>
<p>The method works on simple estimators as well as on nested objects
(such as pipelines). The latter have parameters of the form
<code>&lt;component&gt;__&lt;parameter&gt;</code> so that it's possible to update each
component of a nested object.</p>
<h4>Parameters</h4>
<ul>
<li><strong>**params : dict</strong>
    Estimator parameters.</li>
</ul>
<h4>Returns</h4>
<ul>
<li><strong>self : object</strong>
    Estimator instance.</li>
</ul>
</details>
<h3 id="staged_predict_3">staged_predict<a class="headerlink" href="#staged_predict_3" title="Permanent link">&para;</a></h3>
<details class="note" open="open"><summary>method staged_predict</summary><div class="highlight"><pre><span></span><code><span class="k">val</span> <span class="n">staged_predict</span> <span class="o">:</span>
  <span class="n">x</span><span class="o">:[&gt;`</span><span class="nc">ArrayLike</span><span class="o">]</span> <span class="nn">Np</span><span class="p">.</span><span class="nn">Obj</span><span class="p">.</span><span class="n">t</span> <span class="o">-&gt;</span>
  <span class="o">[&gt;</span> <span class="n">tag</span><span class="o">]</span> <span class="nn">Obj</span><span class="p">.</span><span class="n">t</span> <span class="o">-&gt;</span>
  <span class="o">[&gt;`</span><span class="nc">ArrayLike</span><span class="o">]</span> <span class="nn">Np</span><span class="p">.</span><span class="nn">Obj</span><span class="p">.</span><span class="n">t</span> <span class="nn">Seq</span><span class="p">.</span><span class="n">t</span>
</code></pre></div>

<p>Predict regression target at each stage for X.</p>
<p>This method allows monitoring (i.e. determine error on testing set)
after each stage.</p>
<h4>Parameters</h4>
<ul>
<li><strong>X : {array-like, sparse matrix} of shape (n_samples, n_features)</strong>
    The input samples. Internally, it will be converted to
    <code>dtype=np.float32</code> and if a sparse matrix is provided
    to a sparse <code>csr_matrix</code>.</li>
</ul>
<h4>Returns</h4>
<ul>
<li><strong>y : generator of ndarray of shape (n_samples,)</strong>
    The predicted value of the input samples.</li>
</ul>
</details>
<h3 id="feature_importances__5">feature_importances_<a class="headerlink" href="#feature_importances__5" title="Permanent link">&para;</a></h3>
<details class="note" open="open"><summary>attribute feature_importances_</summary><div class="highlight"><pre><span></span><code><span class="k">val</span> <span class="n">feature_importances_</span> <span class="o">:</span> <span class="n">t</span> <span class="o">-&gt;</span> <span class="o">[&gt;`</span><span class="nc">ArrayLike</span><span class="o">]</span> <span class="nn">Np</span><span class="p">.</span><span class="nn">Obj</span><span class="p">.</span><span class="n">t</span>
<span class="k">val</span> <span class="n">feature_importances_opt</span> <span class="o">:</span> <span class="n">t</span> <span class="o">-&gt;</span> <span class="o">([&gt;`</span><span class="nc">ArrayLike</span><span class="o">]</span> <span class="nn">Np</span><span class="p">.</span><span class="nn">Obj</span><span class="p">.</span><span class="n">t</span><span class="o">)</span> <span class="n">option</span>
</code></pre></div>

<p>This attribute is documented in <code>create</code> above. The first version raises Not_found
if the attribute is None. The _opt version returns an option.</p>
</details>
<h3 id="warning_5">warning<a class="headerlink" href="#warning_5" title="Permanent link">&para;</a></h3>
<details class="note" open="open"><summary>attribute warning</summary><div class="highlight"><pre><span></span><code><span class="k">val</span> <span class="n">warning</span> <span class="o">:</span> <span class="n">t</span> <span class="o">-&gt;</span> <span class="nn">Py</span><span class="p">.</span><span class="nn">Object</span><span class="p">.</span><span class="n">t</span>
<span class="k">val</span> <span class="n">warning_opt</span> <span class="o">:</span> <span class="n">t</span> <span class="o">-&gt;</span> <span class="o">(</span><span class="nn">Py</span><span class="p">.</span><span class="nn">Object</span><span class="p">.</span><span class="n">t</span><span class="o">)</span> <span class="n">option</span>
</code></pre></div>

<p>This attribute is documented in <code>create</code> above. The first version raises Not_found
if the attribute is None. The _opt version returns an option.</p>
</details>
<h3 id="oob_improvement__1">oob_improvement_<a class="headerlink" href="#oob_improvement__1" title="Permanent link">&para;</a></h3>
<details class="note" open="open"><summary>attribute oob_improvement_</summary><div class="highlight"><pre><span></span><code><span class="k">val</span> <span class="n">oob_improvement_</span> <span class="o">:</span> <span class="n">t</span> <span class="o">-&gt;</span> <span class="o">[&gt;`</span><span class="nc">ArrayLike</span><span class="o">]</span> <span class="nn">Np</span><span class="p">.</span><span class="nn">Obj</span><span class="p">.</span><span class="n">t</span>
<span class="k">val</span> <span class="n">oob_improvement_opt</span> <span class="o">:</span> <span class="n">t</span> <span class="o">-&gt;</span> <span class="o">([&gt;`</span><span class="nc">ArrayLike</span><span class="o">]</span> <span class="nn">Np</span><span class="p">.</span><span class="nn">Obj</span><span class="p">.</span><span class="n">t</span><span class="o">)</span> <span class="n">option</span>
</code></pre></div>

<p>This attribute is documented in <code>create</code> above. The first version raises Not_found
if the attribute is None. The _opt version returns an option.</p>
</details>
<h3 id="train_score__1">train_score_<a class="headerlink" href="#train_score__1" title="Permanent link">&para;</a></h3>
<details class="note" open="open"><summary>attribute train_score_</summary><div class="highlight"><pre><span></span><code><span class="k">val</span> <span class="n">train_score_</span> <span class="o">:</span> <span class="n">t</span> <span class="o">-&gt;</span> <span class="o">[&gt;`</span><span class="nc">ArrayLike</span><span class="o">]</span> <span class="nn">Np</span><span class="p">.</span><span class="nn">Obj</span><span class="p">.</span><span class="n">t</span>
<span class="k">val</span> <span class="n">train_score_opt</span> <span class="o">:</span> <span class="n">t</span> <span class="o">-&gt;</span> <span class="o">([&gt;`</span><span class="nc">ArrayLike</span><span class="o">]</span> <span class="nn">Np</span><span class="p">.</span><span class="nn">Obj</span><span class="p">.</span><span class="n">t</span><span class="o">)</span> <span class="n">option</span>
</code></pre></div>

<p>This attribute is documented in <code>create</code> above. The first version raises Not_found
if the attribute is None. The _opt version returns an option.</p>
</details>
<h3 id="loss__1">loss_<a class="headerlink" href="#loss__1" title="Permanent link">&para;</a></h3>
<details class="note" open="open"><summary>attribute loss_</summary><div class="highlight"><pre><span></span><code><span class="k">val</span> <span class="n">loss_</span> <span class="o">:</span> <span class="n">t</span> <span class="o">-&gt;</span> <span class="nn">Np</span><span class="p">.</span><span class="nn">NumpyRaw</span><span class="p">.</span><span class="nn">Ndarray</span><span class="p">.</span><span class="n">t</span> <span class="o">-&gt;</span> <span class="nn">Np</span><span class="p">.</span><span class="nn">NumpyRaw</span><span class="p">.</span><span class="nn">Ndarray</span><span class="p">.</span><span class="n">t</span> <span class="o">-&gt;</span> <span class="kt">float</span>
<span class="k">val</span> <span class="n">loss_opt</span> <span class="o">:</span> <span class="n">t</span> <span class="o">-&gt;</span> <span class="o">(</span><span class="nn">Np</span><span class="p">.</span><span class="nn">NumpyRaw</span><span class="p">.</span><span class="nn">Ndarray</span><span class="p">.</span><span class="n">t</span> <span class="o">-&gt;</span> <span class="nn">Np</span><span class="p">.</span><span class="nn">NumpyRaw</span><span class="p">.</span><span class="nn">Ndarray</span><span class="p">.</span><span class="n">t</span> <span class="o">-&gt;</span> <span class="kt">float</span><span class="o">)</span> <span class="n">option</span>
</code></pre></div>

<p>This attribute is documented in <code>create</code> above. The first version raises Not_found
if the attribute is None. The _opt version returns an option.</p>
</details>
<h3 id="init__1">init_<a class="headerlink" href="#init__1" title="Permanent link">&para;</a></h3>
<details class="note" open="open"><summary>attribute init_</summary><div class="highlight"><pre><span></span><code><span class="k">val</span> <span class="n">init_</span> <span class="o">:</span> <span class="n">t</span> <span class="o">-&gt;</span> <span class="o">[`</span><span class="nc">BaseEstimator</span><span class="o">|`</span><span class="nc">Object</span><span class="o">]</span> <span class="nn">Np</span><span class="p">.</span><span class="nn">Obj</span><span class="p">.</span><span class="n">t</span>
<span class="k">val</span> <span class="n">init_opt</span> <span class="o">:</span> <span class="n">t</span> <span class="o">-&gt;</span> <span class="o">([`</span><span class="nc">BaseEstimator</span><span class="o">|`</span><span class="nc">Object</span><span class="o">]</span> <span class="nn">Np</span><span class="p">.</span><span class="nn">Obj</span><span class="p">.</span><span class="n">t</span><span class="o">)</span> <span class="n">option</span>
</code></pre></div>

<p>This attribute is documented in <code>create</code> above. The first version raises Not_found
if the attribute is None. The _opt version returns an option.</p>
</details>
<h3 id="estimators__8">estimators_<a class="headerlink" href="#estimators__8" title="Permanent link">&para;</a></h3>
<details class="note" open="open"><summary>attribute estimators_</summary><div class="highlight"><pre><span></span><code><span class="k">val</span> <span class="n">estimators_</span> <span class="o">:</span> <span class="n">t</span> <span class="o">-&gt;</span> <span class="nn">Py</span><span class="p">.</span><span class="nn">Object</span><span class="p">.</span><span class="n">t</span>
<span class="k">val</span> <span class="n">estimators_opt</span> <span class="o">:</span> <span class="n">t</span> <span class="o">-&gt;</span> <span class="o">(</span><span class="nn">Py</span><span class="p">.</span><span class="nn">Object</span><span class="p">.</span><span class="n">t</span><span class="o">)</span> <span class="n">option</span>
</code></pre></div>

<p>This attribute is documented in <code>create</code> above. The first version raises Not_found
if the attribute is None. The _opt version returns an option.</p>
</details>
<h3 id="n_features__5">n_features_<a class="headerlink" href="#n_features__5" title="Permanent link">&para;</a></h3>
<details class="note" open="open"><summary>attribute n_features_</summary><div class="highlight"><pre><span></span><code><span class="k">val</span> <span class="n">n_features_</span> <span class="o">:</span> <span class="n">t</span> <span class="o">-&gt;</span> <span class="kt">int</span>
<span class="k">val</span> <span class="n">n_features_opt</span> <span class="o">:</span> <span class="n">t</span> <span class="o">-&gt;</span> <span class="o">(</span><span class="kt">int</span><span class="o">)</span> <span class="n">option</span>
</code></pre></div>

<p>This attribute is documented in <code>create</code> above. The first version raises Not_found
if the attribute is None. The _opt version returns an option.</p>
</details>
<h3 id="max_features__1">max_features_<a class="headerlink" href="#max_features__1" title="Permanent link">&para;</a></h3>
<details class="note" open="open"><summary>attribute max_features_</summary><div class="highlight"><pre><span></span><code><span class="k">val</span> <span class="n">max_features_</span> <span class="o">:</span> <span class="n">t</span> <span class="o">-&gt;</span> <span class="kt">int</span>
<span class="k">val</span> <span class="n">max_features_opt</span> <span class="o">:</span> <span class="n">t</span> <span class="o">-&gt;</span> <span class="o">(</span><span class="kt">int</span><span class="o">)</span> <span class="n">option</span>
</code></pre></div>

<p>This attribute is documented in <code>create</code> above. The first version raises Not_found
if the attribute is None. The _opt version returns an option.</p>
</details>
<h3 id="to_string_8">to_string<a class="headerlink" href="#to_string_8" title="Permanent link">&para;</a></h3>
<details class="note" open="open"><summary>method to_string</summary><div class="highlight"><pre><span></span><code><span class="k">val</span> <span class="n">to_string</span><span class="o">:</span> <span class="n">t</span> <span class="o">-&gt;</span> <span class="kt">string</span>
</code></pre></div>

<p>Print the object to a human-readable representation.</p>
</details>
<h3 id="show_8">show<a class="headerlink" href="#show_8" title="Permanent link">&para;</a></h3>
<details class="note" open="open"><summary>method show</summary><div class="highlight"><pre><span></span><code><span class="k">val</span> <span class="n">show</span><span class="o">:</span> <span class="n">t</span> <span class="o">-&gt;</span> <span class="kt">string</span>
</code></pre></div>

<p>Print the object to a human-readable representation.</p>
</details>
<h3 id="pp_8">pp<a class="headerlink" href="#pp_8" title="Permanent link">&para;</a></h3>
<details class="note" open="open"><summary>method pp</summary><div class="highlight"><pre><span></span><code><span class="k">val</span> <span class="n">pp</span><span class="o">:</span> <span class="nn">Format</span><span class="p">.</span><span class="n">formatter</span> <span class="o">-&gt;</span> <span class="n">t</span> <span class="o">-&gt;</span> <span class="kt">unit</span>
</code></pre></div>

<p>Pretty-print the object to a formatter.</p>
</details>
<h2 id="isolationforest">IsolationForest<a class="headerlink" href="#isolationforest" title="Permanent link">&para;</a></h2>
<p>Module <code>Sklearn.​Ensemble.​IsolationForest</code> wraps Python class <a href="https://scikit-learn.org/stable/modules/generated/sklearn.ensemble.IsolationForest.html"><code>sklearn.ensemble.IsolationForest</code></a>.</p>
<div class="highlight"><pre><span></span><code><span class="k">type</span> <span class="n">t</span>
</code></pre></div>

<h3 id="create_8">create<a class="headerlink" href="#create_8" title="Permanent link">&para;</a></h3>
<details class="note" open="open"><summary>constructor and attributes create</summary><div class="highlight"><pre><span></span><code><span class="k">val</span> <span class="n">create</span> <span class="o">:</span>
  <span class="o">?</span><span class="n">n_estimators</span><span class="o">:</span><span class="kt">int</span> <span class="o">-&gt;</span>
  <span class="o">?</span><span class="n">max_samples</span><span class="o">:[`</span><span class="nc">I</span> <span class="k">of</span> <span class="kt">int</span> <span class="o">|</span> <span class="o">`</span><span class="nc">F</span> <span class="k">of</span> <span class="kt">float</span> <span class="o">|</span> <span class="o">`</span><span class="nc">Auto</span><span class="o">]</span> <span class="o">-&gt;</span>
  <span class="o">?</span><span class="n">contamination</span><span class="o">:[`</span><span class="nc">F</span> <span class="k">of</span> <span class="kt">float</span> <span class="o">|</span> <span class="o">`</span><span class="nc">Auto</span><span class="o">]</span> <span class="o">-&gt;</span>
  <span class="o">?</span><span class="n">max_features</span><span class="o">:[`</span><span class="nc">F</span> <span class="k">of</span> <span class="kt">float</span> <span class="o">|</span> <span class="o">`</span><span class="nc">I</span> <span class="k">of</span> <span class="kt">int</span><span class="o">]</span> <span class="o">-&gt;</span>
  <span class="o">?</span><span class="n">bootstrap</span><span class="o">:</span><span class="kt">bool</span> <span class="o">-&gt;</span>
  <span class="o">?</span><span class="n">n_jobs</span><span class="o">:</span><span class="kt">int</span> <span class="o">-&gt;</span>
  <span class="o">?</span><span class="n">behaviour</span><span class="o">:</span><span class="kt">string</span> <span class="o">-&gt;</span>
  <span class="o">?</span><span class="n">random_state</span><span class="o">:</span><span class="kt">int</span> <span class="o">-&gt;</span>
  <span class="o">?</span><span class="n">verbose</span><span class="o">:</span><span class="kt">int</span> <span class="o">-&gt;</span>
  <span class="o">?</span><span class="n">warm_start</span><span class="o">:</span><span class="kt">bool</span> <span class="o">-&gt;</span>
  <span class="kt">unit</span> <span class="o">-&gt;</span>
  <span class="n">t</span>
</code></pre></div>

<p>Isolation Forest Algorithm.</p>
<p>Return the anomaly score of each sample using the IsolationForest algorithm</p>
<p>The IsolationForest 'isolates' observations by randomly selecting a feature
and then randomly selecting a split value between the maximum and minimum
values of the selected feature.</p>
<p>Since recursive partitioning can be represented by a tree structure, the
number of splittings required to isolate a sample is equivalent to the path
length from the root node to the terminating node.</p>
<p>This path length, averaged over a forest of such random trees, is a
measure of normality and our decision function.</p>
<p>Random partitioning produces noticeably shorter paths for anomalies.
Hence, when a forest of random trees collectively produce shorter path
lengths for particular samples, they are highly likely to be anomalies.</p>
<p>Read more in the :ref:<code>User Guide &lt;isolation_forest&gt;</code>.</p>
<p>.. versionadded:: 0.18</p>
<h4>Parameters</h4>
<ul>
<li>
<p><strong>n_estimators : int, default=100</strong>
    The number of base estimators in the ensemble.</p>
</li>
<li>
<p><strong>max_samples : 'auto', int or float, default='auto'</strong>
    The number of samples to draw from X to train each base estimator.
        - If int, then draw <code>max_samples</code> samples.
        - If float, then draw <code>max_samples * X.shape[0]</code> samples.
        - If 'auto', then <code>max_samples=min(256, n_samples)</code>.</p>
<p>If max_samples is larger than the number of samples provided,
all samples will be used for all trees (no sampling).</p>
</li>
<li>
<p><strong>contamination : 'auto' or float, default='auto'</strong>
    The amount of contamination of the data set, i.e. the proportion
    of outliers in the data set. Used when fitting to define the threshold
    on the scores of the samples.</p>
<div class="codehilite"><pre><span></span><code>- If &#39;auto&#39;, the threshold is determined as in the
  original paper.
- If float, the contamination should be in the range [0, 0.5].
</code></pre></div>


<p>.. versionchanged:: 0.22
   The default value of <code>contamination</code> changed from 0.1
   to <code>'auto'</code>.</p>
</li>
<li>
<p><strong>max_features : int or float, default=1.0</strong>
    The number of features to draw from X to train each base estimator.</p>
<div class="codehilite"><pre><span></span><code>- If int, then draw `max_features` features.
- If float, then draw `max_features * X.shape[1]` features.
</code></pre></div>


</li>
<li>
<p><strong>bootstrap : bool, default=False</strong>
    If True, individual trees are fit on random subsets of the training
    data sampled with replacement. If False, sampling without replacement
    is performed.</p>
</li>
<li>
<p><strong>n_jobs : int, default=None</strong>
    The number of jobs to run in parallel for both :meth:<code>fit</code> and
    :meth:<code>predict</code>. <code>None</code> means 1 unless in a
    :obj:<code>joblib.parallel_backend</code> context. <code>-1</code> means using all
    processors. See :term:<code>Glossary &lt;n_jobs&gt;</code> for more details.</p>
</li>
<li>
<p><strong>behaviour : str, default='deprecated'</strong>
    This parameter has no effect, is deprecated, and will be removed.</p>
<p>.. versionadded:: 0.20
   <code>behaviour</code> is added in 0.20 for back-compatibility purpose.</p>
<p>.. deprecated:: 0.20
   <code>behaviour='old'</code> is deprecated in 0.20 and will not be possible
   in 0.22.</p>
<p>.. deprecated:: 0.22
   <code>behaviour</code> parameter is deprecated in 0.22 and removed in
   0.24.</p>
</li>
<li>
<p><strong>random_state : int or RandomState, default=None</strong>
    Controls the pseudo-randomness of the selection of the feature
    and split values for each branching step and each tree in the forest.</p>
<p>Pass an int for reproducible results across multiple function calls.</p>
</li>
<li>
<p><strong>See :term:<code>Glossary &lt;random_state&gt;</code>.</strong></p>
</li>
<li>
<p><strong>verbose : int, default=0</strong>
    Controls the verbosity of the tree building process.</p>
</li>
<li>
<p><strong>warm_start : bool, default=False</strong>
    When set to <code>True</code>, reuse the solution of the previous call to fit
    and add more estimators to the ensemble, otherwise, just fit a whole
    new forest. See :term:<code>the Glossary &lt;warm_start&gt;</code>.</p>
<p>.. versionadded:: 0.21</p>
</li>
</ul>
<h4>Attributes</h4>
<ul>
<li>
<p><strong>estimators_ : list of DecisionTreeClassifier</strong>
    The collection of fitted sub-estimators.</p>
</li>
<li>
<p><strong>estimators_samples_ : list of arrays</strong>
    The subset of drawn samples (i.e., the in-bag samples) for each base
    estimator.</p>
</li>
<li>
<p><strong>max_samples_ : int</strong>
    The actual number of samples.</p>
</li>
<li>
<p><strong>offset_ : float</strong>
    Offset used to define the decision function from the raw scores. We
    have the relation: <code>decision_function = score_samples - offset_</code>.
    <code>offset_</code> is defined as follows. When the contamination parameter is
    set to 'auto', the offset is equal to -0.5 as the scores of inliers are
    close to 0 and the scores of outliers are close to -1. When a
    contamination parameter different than 'auto' is provided, the offset
    is defined in such a way we obtain the expected number of outliers
    (samples with decision function &lt; 0) in training.</p>
<p>.. versionadded:: 0.20</p>
</li>
<li>
<p><strong>estimators_features_ : list of arrays</strong>
    The subset of drawn features for each base estimator.</p>
</li>
</ul>
<h4>Notes</h4>
<p>The implementation is based on an ensemble of ExtraTreeRegressor. The
maximum depth of each tree is set to <code>ceil(log_2(n))</code> where
:math:<code>n</code> is the number of samples used to build the tree
(see (Liu et al., 2008) for more details).</p>
<h4>References</h4>
<p>.. [1] Liu, Fei Tony, Ting, Kai Ming and Zhou, Zhi-Hua. 'Isolation forest.'
       Data Mining, 2008. ICDM'08. Eighth IEEE International Conference on.
.. [2] Liu, Fei Tony, Ting, Kai Ming and Zhou, Zhi-Hua. 'Isolation-based
       anomaly detection.' ACM Transactions on Knowledge Discovery from
       Data (TKDD) 6.1 (2012): 3.</p>
<h4>See Also</h4>
<ul>
<li>
<p><strong>sklearn.covariance.EllipticEnvelope : An object for detecting outliers in a</strong>
    Gaussian distributed dataset.</p>
</li>
<li>
<p><strong>sklearn.svm.OneClassSVM : Unsupervised Outlier Detection.</strong>
    Estimate the support of a high-dimensional distribution.
    The implementation is based on libsvm.</p>
</li>
<li>
<p><strong>sklearn.neighbors.LocalOutlierFactor : Unsupervised Outlier Detection</strong>
    using Local Outlier Factor (LOF).</p>
</li>
</ul>
<h4>Examples</h4>
<div class="highlight"><pre><span></span><code><span class="o">&gt;&gt;&gt;</span> <span class="kn">from</span> <span class="nn">sklearn.ensemble</span> <span class="kn">import</span> <span class="n">IsolationForest</span>
<span class="o">&gt;&gt;&gt;</span> <span class="n">X</span> <span class="o">=</span> <span class="p">[[</span><span class="o">-</span><span class="mf">1.1</span><span class="p">],</span> <span class="p">[</span><span class="mf">0.3</span><span class="p">],</span> <span class="p">[</span><span class="mf">0.5</span><span class="p">],</span> <span class="p">[</span><span class="mi">100</span><span class="p">]]</span>
<span class="o">&gt;&gt;&gt;</span> <span class="n">clf</span> <span class="o">=</span> <span class="n">IsolationForest</span><span class="p">(</span><span class="n">random_state</span><span class="o">=</span><span class="mi">0</span><span class="p">)</span><span class="o">.</span><span class="n">fit</span><span class="p">(</span><span class="n">X</span><span class="p">)</span>
<span class="o">&gt;&gt;&gt;</span> <span class="n">clf</span><span class="o">.</span><span class="n">predict</span><span class="p">([[</span><span class="mf">0.1</span><span class="p">],</span> <span class="p">[</span><span class="mi">0</span><span class="p">],</span> <span class="p">[</span><span class="mi">90</span><span class="p">]])</span>
<span class="n">array</span><span class="p">([</span> <span class="mi">1</span><span class="p">,</span>  <span class="mi">1</span><span class="p">,</span> <span class="o">-</span><span class="mi">1</span><span class="p">])</span>
</code></pre></div>

</details>
<h3 id="get_item_9">get_item<a class="headerlink" href="#get_item_9" title="Permanent link">&para;</a></h3>
<details class="note" open="open"><summary>method get_item</summary><div class="highlight"><pre><span></span><code><span class="k">val</span> <span class="n">get_item</span> <span class="o">:</span>
  <span class="n">index</span><span class="o">:</span><span class="nn">Py</span><span class="p">.</span><span class="nn">Object</span><span class="p">.</span><span class="n">t</span> <span class="o">-&gt;</span>
  <span class="o">[&gt;</span> <span class="n">tag</span><span class="o">]</span> <span class="nn">Obj</span><span class="p">.</span><span class="n">t</span> <span class="o">-&gt;</span>
  <span class="nn">Py</span><span class="p">.</span><span class="nn">Object</span><span class="p">.</span><span class="n">t</span>
</code></pre></div>

<p>Return the index'th estimator in the ensemble.</p>
</details>
<h3 id="iter_9">iter<a class="headerlink" href="#iter_9" title="Permanent link">&para;</a></h3>
<details class="note" open="open"><summary>method iter</summary><div class="highlight"><pre><span></span><code><span class="k">val</span> <span class="n">iter</span> <span class="o">:</span>
  <span class="o">[&gt;</span> <span class="n">tag</span><span class="o">]</span> <span class="nn">Obj</span><span class="p">.</span><span class="n">t</span> <span class="o">-&gt;</span>
  <span class="nn">Dict</span><span class="p">.</span><span class="n">t</span> <span class="nn">Seq</span><span class="p">.</span><span class="n">t</span>
</code></pre></div>

<p>Return iterator over estimators in the ensemble.</p>
</details>
<h3 id="decision_function_2">decision_function<a class="headerlink" href="#decision_function_2" title="Permanent link">&para;</a></h3>
<details class="note" open="open"><summary>method decision_function</summary><div class="highlight"><pre><span></span><code><span class="k">val</span> <span class="n">decision_function</span> <span class="o">:</span>
  <span class="n">x</span><span class="o">:[&gt;`</span><span class="nc">ArrayLike</span><span class="o">]</span> <span class="nn">Np</span><span class="p">.</span><span class="nn">Obj</span><span class="p">.</span><span class="n">t</span> <span class="o">-&gt;</span>
  <span class="o">[&gt;</span> <span class="n">tag</span><span class="o">]</span> <span class="nn">Obj</span><span class="p">.</span><span class="n">t</span> <span class="o">-&gt;</span>
  <span class="o">[&gt;`</span><span class="nc">ArrayLike</span><span class="o">]</span> <span class="nn">Np</span><span class="p">.</span><span class="nn">Obj</span><span class="p">.</span><span class="n">t</span>
</code></pre></div>

<p>Average anomaly score of X of the base classifiers.</p>
<p>The anomaly score of an input sample is computed as
the mean anomaly score of the trees in the forest.</p>
<p>The measure of normality of an observation given a tree is the depth
of the leaf containing this observation, which is equivalent to
the number of splittings required to isolate this point. In case of
several observations n_left in the leaf, the average path length of
a n_left samples isolation tree is added.</p>
<h4>Parameters</h4>
<ul>
<li><strong>X : {array-like, sparse matrix} of shape (n_samples, n_features)</strong>
    The input samples. Internally, it will be converted to
    <code>dtype=np.float32</code> and if a sparse matrix is provided
    to a sparse <code>csr_matrix</code>.</li>
</ul>
<h4>Returns</h4>
<ul>
<li><strong>scores : ndarray of shape (n_samples,)</strong>
    The anomaly score of the input samples.
    The lower, the more abnormal. Negative scores represent outliers,
    positive scores represent inliers.</li>
</ul>
</details>
<h3 id="fit_8">fit<a class="headerlink" href="#fit_8" title="Permanent link">&para;</a></h3>
<details class="note" open="open"><summary>method fit</summary><div class="highlight"><pre><span></span><code><span class="k">val</span> <span class="n">fit</span> <span class="o">:</span>
  <span class="o">?</span><span class="n">y</span><span class="o">:</span><span class="nn">Py</span><span class="p">.</span><span class="nn">Object</span><span class="p">.</span><span class="n">t</span> <span class="o">-&gt;</span>
  <span class="o">?</span><span class="n">sample_weight</span><span class="o">:[&gt;`</span><span class="nc">ArrayLike</span><span class="o">]</span> <span class="nn">Np</span><span class="p">.</span><span class="nn">Obj</span><span class="p">.</span><span class="n">t</span> <span class="o">-&gt;</span>
  <span class="n">x</span><span class="o">:[&gt;`</span><span class="nc">ArrayLike</span><span class="o">]</span> <span class="nn">Np</span><span class="p">.</span><span class="nn">Obj</span><span class="p">.</span><span class="n">t</span> <span class="o">-&gt;</span>
  <span class="o">[&gt;</span> <span class="n">tag</span><span class="o">]</span> <span class="nn">Obj</span><span class="p">.</span><span class="n">t</span> <span class="o">-&gt;</span>
  <span class="n">t</span>
</code></pre></div>

<p>Fit estimator.</p>
<h4>Parameters</h4>
<ul>
<li>
<p><strong>X : {array-like, sparse matrix} of shape (n_samples, n_features)</strong>
    The input samples. Use <code>dtype=np.float32</code> for maximum
    efficiency. Sparse matrices are also supported, use sparse
    <code>csc_matrix</code> for maximum efficiency.</p>
</li>
<li>
<p><strong>y : Ignored</strong>
    Not used, present for API consistency by convention.</p>
</li>
<li>
<p><strong>sample_weight : array-like of shape (n_samples,), default=None</strong>
    Sample weights. If None, then samples are equally weighted.</p>
</li>
</ul>
<h4>Returns</h4>
<ul>
<li><strong>self : object</strong>
    Fitted estimator.</li>
</ul>
</details>
<h3 id="fit_predict">fit_predict<a class="headerlink" href="#fit_predict" title="Permanent link">&para;</a></h3>
<details class="note" open="open"><summary>method fit_predict</summary><div class="highlight"><pre><span></span><code><span class="k">val</span> <span class="n">fit_predict</span> <span class="o">:</span>
  <span class="o">?</span><span class="n">y</span><span class="o">:</span><span class="nn">Py</span><span class="p">.</span><span class="nn">Object</span><span class="p">.</span><span class="n">t</span> <span class="o">-&gt;</span>
  <span class="n">x</span><span class="o">:[&gt;`</span><span class="nc">ArrayLike</span><span class="o">]</span> <span class="nn">Np</span><span class="p">.</span><span class="nn">Obj</span><span class="p">.</span><span class="n">t</span> <span class="o">-&gt;</span>
  <span class="o">[&gt;</span> <span class="n">tag</span><span class="o">]</span> <span class="nn">Obj</span><span class="p">.</span><span class="n">t</span> <span class="o">-&gt;</span>
  <span class="o">[&gt;`</span><span class="nc">ArrayLike</span><span class="o">]</span> <span class="nn">Np</span><span class="p">.</span><span class="nn">Obj</span><span class="p">.</span><span class="n">t</span>
</code></pre></div>

<p>Perform fit on X and returns labels for X.</p>
<p>Returns -1 for outliers and 1 for inliers.</p>
<h4>Parameters</h4>
<ul>
<li>
<p><strong>X : {array-like, sparse matrix, dataframe} of shape             (n_samples, n_features)</strong></p>
</li>
<li>
<p><strong>y : Ignored</strong>
    Not used, present for API consistency by convention.</p>
</li>
</ul>
<h4>Returns</h4>
<ul>
<li><strong>y : ndarray of shape (n_samples,)</strong>
    1 for inliers, -1 for outliers.</li>
</ul>
</details>
<h3 id="get_params_9">get_params<a class="headerlink" href="#get_params_9" title="Permanent link">&para;</a></h3>
<details class="note" open="open"><summary>method get_params</summary><div class="highlight"><pre><span></span><code><span class="k">val</span> <span class="n">get_params</span> <span class="o">:</span>
  <span class="o">?</span><span class="n">deep</span><span class="o">:</span><span class="kt">bool</span> <span class="o">-&gt;</span>
  <span class="o">[&gt;</span> <span class="n">tag</span><span class="o">]</span> <span class="nn">Obj</span><span class="p">.</span><span class="n">t</span> <span class="o">-&gt;</span>
  <span class="nn">Dict</span><span class="p">.</span><span class="n">t</span>
</code></pre></div>

<p>Get parameters for this estimator.</p>
<h4>Parameters</h4>
<ul>
<li><strong>deep : bool, default=True</strong>
    If True, will return the parameters for this estimator and
    contained subobjects that are estimators.</li>
</ul>
<h4>Returns</h4>
<ul>
<li><strong>params : mapping of string to any</strong>
    Parameter names mapped to their values.</li>
</ul>
</details>
<h3 id="predict_8">predict<a class="headerlink" href="#predict_8" title="Permanent link">&para;</a></h3>
<details class="note" open="open"><summary>method predict</summary><div class="highlight"><pre><span></span><code><span class="k">val</span> <span class="n">predict</span> <span class="o">:</span>
  <span class="n">x</span><span class="o">:[&gt;`</span><span class="nc">ArrayLike</span><span class="o">]</span> <span class="nn">Np</span><span class="p">.</span><span class="nn">Obj</span><span class="p">.</span><span class="n">t</span> <span class="o">-&gt;</span>
  <span class="o">[&gt;</span> <span class="n">tag</span><span class="o">]</span> <span class="nn">Obj</span><span class="p">.</span><span class="n">t</span> <span class="o">-&gt;</span>
  <span class="o">[&gt;`</span><span class="nc">ArrayLike</span><span class="o">]</span> <span class="nn">Np</span><span class="p">.</span><span class="nn">Obj</span><span class="p">.</span><span class="n">t</span>
</code></pre></div>

<p>Predict if a particular sample is an outlier or not.</p>
<h4>Parameters</h4>
<ul>
<li><strong>X : {array-like, sparse matrix} of shape (n_samples, n_features)</strong>
    The input samples. Internally, it will be converted to
    <code>dtype=np.float32</code> and if a sparse matrix is provided
    to a sparse <code>csr_matrix</code>.</li>
</ul>
<h4>Returns</h4>
<ul>
<li><strong>is_inlier : ndarray of shape (n_samples,)</strong>
    For each observation, tells whether or not (+1 or -1) it should
    be considered as an inlier according to the fitted model.</li>
</ul>
</details>
<h3 id="score_samples">score_samples<a class="headerlink" href="#score_samples" title="Permanent link">&para;</a></h3>
<details class="note" open="open"><summary>method score_samples</summary><div class="highlight"><pre><span></span><code><span class="k">val</span> <span class="n">score_samples</span> <span class="o">:</span>
  <span class="n">x</span><span class="o">:[&gt;`</span><span class="nc">ArrayLike</span><span class="o">]</span> <span class="nn">Np</span><span class="p">.</span><span class="nn">Obj</span><span class="p">.</span><span class="n">t</span> <span class="o">-&gt;</span>
  <span class="o">[&gt;</span> <span class="n">tag</span><span class="o">]</span> <span class="nn">Obj</span><span class="p">.</span><span class="n">t</span> <span class="o">-&gt;</span>
  <span class="o">[&gt;`</span><span class="nc">ArrayLike</span><span class="o">]</span> <span class="nn">Np</span><span class="p">.</span><span class="nn">Obj</span><span class="p">.</span><span class="n">t</span>
</code></pre></div>

<p>Opposite of the anomaly score defined in the original paper.</p>
<p>The anomaly score of an input sample is computed as
the mean anomaly score of the trees in the forest.</p>
<p>The measure of normality of an observation given a tree is the depth
of the leaf containing this observation, which is equivalent to
the number of splittings required to isolate this point. In case of
several observations n_left in the leaf, the average path length of
a n_left samples isolation tree is added.</p>
<h4>Parameters</h4>
<ul>
<li><strong>X : {array-like, sparse matrix} of shape (n_samples, n_features)</strong>
    The input samples.</li>
</ul>
<h4>Returns</h4>
<ul>
<li><strong>scores : ndarray of shape (n_samples,)</strong>
    The anomaly score of the input samples.
    The lower, the more abnormal.</li>
</ul>
</details>
<h3 id="set_params_9">set_params<a class="headerlink" href="#set_params_9" title="Permanent link">&para;</a></h3>
<details class="note" open="open"><summary>method set_params</summary><div class="highlight"><pre><span></span><code><span class="k">val</span> <span class="n">set_params</span> <span class="o">:</span>
  <span class="o">?</span><span class="n">params</span><span class="o">:(</span><span class="kt">string</span> <span class="o">*</span> <span class="nn">Py</span><span class="p">.</span><span class="nn">Object</span><span class="p">.</span><span class="n">t</span><span class="o">)</span> <span class="kt">list</span> <span class="o">-&gt;</span>
  <span class="o">[&gt;</span> <span class="n">tag</span><span class="o">]</span> <span class="nn">Obj</span><span class="p">.</span><span class="n">t</span> <span class="o">-&gt;</span>
  <span class="n">t</span>
</code></pre></div>

<p>Set the parameters of this estimator.</p>
<p>The method works on simple estimators as well as on nested objects
(such as pipelines). The latter have parameters of the form
<code>&lt;component&gt;__&lt;parameter&gt;</code> so that it's possible to update each
component of a nested object.</p>
<h4>Parameters</h4>
<ul>
<li><strong>**params : dict</strong>
    Estimator parameters.</li>
</ul>
<h4>Returns</h4>
<ul>
<li><strong>self : object</strong>
    Estimator instance.</li>
</ul>
</details>
<h3 id="estimators__9">estimators_<a class="headerlink" href="#estimators__9" title="Permanent link">&para;</a></h3>
<details class="note" open="open"><summary>attribute estimators_</summary><div class="highlight"><pre><span></span><code><span class="k">val</span> <span class="n">estimators_</span> <span class="o">:</span> <span class="n">t</span> <span class="o">-&gt;</span> <span class="nn">Py</span><span class="p">.</span><span class="nn">Object</span><span class="p">.</span><span class="n">t</span>
<span class="k">val</span> <span class="n">estimators_opt</span> <span class="o">:</span> <span class="n">t</span> <span class="o">-&gt;</span> <span class="o">(</span><span class="nn">Py</span><span class="p">.</span><span class="nn">Object</span><span class="p">.</span><span class="n">t</span><span class="o">)</span> <span class="n">option</span>
</code></pre></div>

<p>This attribute is documented in <code>create</code> above. The first version raises Not_found
if the attribute is None. The _opt version returns an option.</p>
</details>
<h3 id="estimators_samples__2">estimators_samples_<a class="headerlink" href="#estimators_samples__2" title="Permanent link">&para;</a></h3>
<details class="note" open="open"><summary>attribute estimators_samples_</summary><div class="highlight"><pre><span></span><code><span class="k">val</span> <span class="n">estimators_samples_</span> <span class="o">:</span> <span class="n">t</span> <span class="o">-&gt;</span> <span class="nn">Np</span><span class="p">.</span><span class="nn">Numpy</span><span class="p">.</span><span class="nn">Ndarray</span><span class="p">.</span><span class="nn">List</span><span class="p">.</span><span class="n">t</span>
<span class="k">val</span> <span class="n">estimators_samples_opt</span> <span class="o">:</span> <span class="n">t</span> <span class="o">-&gt;</span> <span class="o">(</span><span class="nn">Np</span><span class="p">.</span><span class="nn">Numpy</span><span class="p">.</span><span class="nn">Ndarray</span><span class="p">.</span><span class="nn">List</span><span class="p">.</span><span class="n">t</span><span class="o">)</span> <span class="n">option</span>
</code></pre></div>

<p>This attribute is documented in <code>create</code> above. The first version raises Not_found
if the attribute is None. The _opt version returns an option.</p>
</details>
<h3 id="max_samples_">max_samples_<a class="headerlink" href="#max_samples_" title="Permanent link">&para;</a></h3>
<details class="note" open="open"><summary>attribute max_samples_</summary><div class="highlight"><pre><span></span><code><span class="k">val</span> <span class="n">max_samples_</span> <span class="o">:</span> <span class="n">t</span> <span class="o">-&gt;</span> <span class="kt">int</span>
<span class="k">val</span> <span class="n">max_samples_opt</span> <span class="o">:</span> <span class="n">t</span> <span class="o">-&gt;</span> <span class="o">(</span><span class="kt">int</span><span class="o">)</span> <span class="n">option</span>
</code></pre></div>

<p>This attribute is documented in <code>create</code> above. The first version raises Not_found
if the attribute is None. The _opt version returns an option.</p>
</details>
<h3 id="offset_">offset_<a class="headerlink" href="#offset_" title="Permanent link">&para;</a></h3>
<details class="note" open="open"><summary>attribute offset_</summary><div class="highlight"><pre><span></span><code><span class="k">val</span> <span class="n">offset_</span> <span class="o">:</span> <span class="n">t</span> <span class="o">-&gt;</span> <span class="kt">float</span>
<span class="k">val</span> <span class="n">offset_opt</span> <span class="o">:</span> <span class="n">t</span> <span class="o">-&gt;</span> <span class="o">(</span><span class="kt">float</span><span class="o">)</span> <span class="n">option</span>
</code></pre></div>

<p>This attribute is documented in <code>create</code> above. The first version raises Not_found
if the attribute is None. The _opt version returns an option.</p>
</details>
<h3 id="estimators_features__2">estimators_features_<a class="headerlink" href="#estimators_features__2" title="Permanent link">&para;</a></h3>
<details class="note" open="open"><summary>attribute estimators_features_</summary><div class="highlight"><pre><span></span><code><span class="k">val</span> <span class="n">estimators_features_</span> <span class="o">:</span> <span class="n">t</span> <span class="o">-&gt;</span> <span class="nn">Np</span><span class="p">.</span><span class="nn">Numpy</span><span class="p">.</span><span class="nn">Ndarray</span><span class="p">.</span><span class="nn">List</span><span class="p">.</span><span class="n">t</span>
<span class="k">val</span> <span class="n">estimators_features_opt</span> <span class="o">:</span> <span class="n">t</span> <span class="o">-&gt;</span> <span class="o">(</span><span class="nn">Np</span><span class="p">.</span><span class="nn">Numpy</span><span class="p">.</span><span class="nn">Ndarray</span><span class="p">.</span><span class="nn">List</span><span class="p">.</span><span class="n">t</span><span class="o">)</span> <span class="n">option</span>
</code></pre></div>

<p>This attribute is documented in <code>create</code> above. The first version raises Not_found
if the attribute is None. The _opt version returns an option.</p>
</details>
<h3 id="to_string_9">to_string<a class="headerlink" href="#to_string_9" title="Permanent link">&para;</a></h3>
<details class="note" open="open"><summary>method to_string</summary><div class="highlight"><pre><span></span><code><span class="k">val</span> <span class="n">to_string</span><span class="o">:</span> <span class="n">t</span> <span class="o">-&gt;</span> <span class="kt">string</span>
</code></pre></div>

<p>Print the object to a human-readable representation.</p>
</details>
<h3 id="show_9">show<a class="headerlink" href="#show_9" title="Permanent link">&para;</a></h3>
<details class="note" open="open"><summary>method show</summary><div class="highlight"><pre><span></span><code><span class="k">val</span> <span class="n">show</span><span class="o">:</span> <span class="n">t</span> <span class="o">-&gt;</span> <span class="kt">string</span>
</code></pre></div>

<p>Print the object to a human-readable representation.</p>
</details>
<h3 id="pp_9">pp<a class="headerlink" href="#pp_9" title="Permanent link">&para;</a></h3>
<details class="note" open="open"><summary>method pp</summary><div class="highlight"><pre><span></span><code><span class="k">val</span> <span class="n">pp</span><span class="o">:</span> <span class="nn">Format</span><span class="p">.</span><span class="n">formatter</span> <span class="o">-&gt;</span> <span class="n">t</span> <span class="o">-&gt;</span> <span class="kt">unit</span>
</code></pre></div>

<p>Pretty-print the object to a formatter.</p>
</details>
<h2 id="randomforestclassifier">RandomForestClassifier<a class="headerlink" href="#randomforestclassifier" title="Permanent link">&para;</a></h2>
<p>Module <code>Sklearn.​Ensemble.​RandomForestClassifier</code> wraps Python class <a href="https://scikit-learn.org/stable/modules/generated/sklearn.ensemble.RandomForestClassifier.html"><code>sklearn.ensemble.RandomForestClassifier</code></a>.</p>
<div class="highlight"><pre><span></span><code><span class="k">type</span> <span class="n">t</span>
</code></pre></div>

<h3 id="create_9">create<a class="headerlink" href="#create_9" title="Permanent link">&para;</a></h3>
<details class="note" open="open"><summary>constructor and attributes create</summary><div class="highlight"><pre><span></span><code><span class="k">val</span> <span class="n">create</span> <span class="o">:</span>
  <span class="o">?</span><span class="n">n_estimators</span><span class="o">:</span><span class="kt">int</span> <span class="o">-&gt;</span>
  <span class="o">?</span><span class="n">criterion</span><span class="o">:[`</span><span class="nc">Gini</span> <span class="o">|</span> <span class="o">`</span><span class="nc">Entropy</span><span class="o">]</span> <span class="o">-&gt;</span>
  <span class="o">?</span><span class="n">max_depth</span><span class="o">:</span><span class="kt">int</span> <span class="o">-&gt;</span>
  <span class="o">?</span><span class="n">min_samples_split</span><span class="o">:[`</span><span class="nc">F</span> <span class="k">of</span> <span class="kt">float</span> <span class="o">|</span> <span class="o">`</span><span class="nc">I</span> <span class="k">of</span> <span class="kt">int</span><span class="o">]</span> <span class="o">-&gt;</span>
  <span class="o">?</span><span class="n">min_samples_leaf</span><span class="o">:[`</span><span class="nc">F</span> <span class="k">of</span> <span class="kt">float</span> <span class="o">|</span> <span class="o">`</span><span class="nc">I</span> <span class="k">of</span> <span class="kt">int</span><span class="o">]</span> <span class="o">-&gt;</span>
  <span class="o">?</span><span class="n">min_weight_fraction_leaf</span><span class="o">:</span><span class="kt">float</span> <span class="o">-&gt;</span>
  <span class="o">?</span><span class="n">max_features</span><span class="o">:[`</span><span class="nc">I</span> <span class="k">of</span> <span class="kt">int</span> <span class="o">|</span> <span class="o">`</span><span class="nc">Sqrt</span> <span class="o">|</span> <span class="o">`</span><span class="nc">Auto</span> <span class="o">|</span> <span class="o">`</span><span class="nc">F</span> <span class="k">of</span> <span class="kt">float</span> <span class="o">|</span> <span class="o">`</span><span class="nc">Log2</span><span class="o">]</span> <span class="o">-&gt;</span>
  <span class="o">?</span><span class="n">max_leaf_nodes</span><span class="o">:</span><span class="kt">int</span> <span class="o">-&gt;</span>
  <span class="o">?</span><span class="n">min_impurity_decrease</span><span class="o">:</span><span class="kt">float</span> <span class="o">-&gt;</span>
  <span class="o">?</span><span class="n">min_impurity_split</span><span class="o">:</span><span class="kt">float</span> <span class="o">-&gt;</span>
  <span class="o">?</span><span class="n">bootstrap</span><span class="o">:</span><span class="kt">bool</span> <span class="o">-&gt;</span>
  <span class="o">?</span><span class="n">oob_score</span><span class="o">:</span><span class="kt">bool</span> <span class="o">-&gt;</span>
  <span class="o">?</span><span class="n">n_jobs</span><span class="o">:</span><span class="kt">int</span> <span class="o">-&gt;</span>
  <span class="o">?</span><span class="n">random_state</span><span class="o">:</span><span class="kt">int</span> <span class="o">-&gt;</span>
  <span class="o">?</span><span class="n">verbose</span><span class="o">:</span><span class="kt">int</span> <span class="o">-&gt;</span>
  <span class="o">?</span><span class="n">warm_start</span><span class="o">:</span><span class="kt">bool</span> <span class="o">-&gt;</span>
  <span class="o">?</span><span class="n">class_weight</span><span class="o">:[`</span><span class="nc">Balanced</span> <span class="o">|</span> <span class="o">`</span><span class="nc">DictIntToFloat</span> <span class="k">of</span> <span class="o">(</span><span class="kt">int</span> <span class="o">*</span> <span class="kt">float</span><span class="o">)</span> <span class="kt">list</span> <span class="o">|</span> <span class="o">`</span><span class="nc">Balanced_subsample</span> <span class="o">|</span> <span class="o">`</span><span class="nc">List_of_dicts</span> <span class="k">of</span> <span class="nn">Py</span><span class="p">.</span><span class="nn">Object</span><span class="p">.</span><span class="n">t</span><span class="o">]</span> <span class="o">-&gt;</span>
  <span class="o">?</span><span class="n">ccp_alpha</span><span class="o">:</span><span class="kt">float</span> <span class="o">-&gt;</span>
  <span class="o">?</span><span class="n">max_samples</span><span class="o">:[`</span><span class="nc">F</span> <span class="k">of</span> <span class="kt">float</span> <span class="o">|</span> <span class="o">`</span><span class="nc">I</span> <span class="k">of</span> <span class="kt">int</span><span class="o">]</span> <span class="o">-&gt;</span>
  <span class="kt">unit</span> <span class="o">-&gt;</span>
  <span class="n">t</span>
</code></pre></div>

<p>A random forest classifier.</p>
<p>A random forest is a meta estimator that fits a number of decision tree
classifiers on various sub-samples of the dataset and uses averaging to
improve the predictive accuracy and control over-fitting.
The sub-sample size is controlled with the <code>max_samples</code> parameter if
<code>bootstrap=True</code> (default), otherwise the whole dataset is used to build
each tree.</p>
<p>Read more in the :ref:<code>User Guide &lt;forest&gt;</code>.</p>
<h4>Parameters</h4>
<ul>
<li>
<p><strong>n_estimators : int, default=100</strong>
    The number of trees in the forest.</p>
<p>.. versionchanged:: 0.22
   The default value of <code>n_estimators</code> changed from 10 to 100
   in 0.22.</p>
</li>
<li>
<p><strong>criterion : {'gini', 'entropy'}, default='gini'</strong>
    The function to measure the quality of a split. Supported criteria are
    'gini' for the Gini impurity and 'entropy' for the information gain.</p>
</li>
<li>
<p><strong>Note: this parameter is tree-specific.</strong></p>
</li>
<li>
<p><strong>max_depth : int, default=None</strong>
    The maximum depth of the tree. If None, then nodes are expanded until
    all leaves are pure or until all leaves contain less than
    min_samples_split samples.</p>
</li>
<li>
<p><strong>min_samples_split : int or float, default=2</strong>
    The minimum number of samples required to split an internal node:</p>
<ul>
<li>If int, then consider <code>min_samples_split</code> as the minimum number.</li>
<li>If float, then <code>min_samples_split</code> is a fraction and
  <code>ceil(min_samples_split * n_samples)</code> are the minimum
  number of samples for each split.</li>
</ul>
<p>.. versionchanged:: 0.18
   Added float values for fractions.</p>
</li>
<li>
<p><strong>min_samples_leaf : int or float, default=1</strong>
    The minimum number of samples required to be at a leaf node.
    A split point at any depth will only be considered if it leaves at
    least <code>min_samples_leaf</code> training samples in each of the left and
    right branches.  This may have the effect of smoothing the model,
    especially in regression.</p>
<ul>
<li>If int, then consider <code>min_samples_leaf</code> as the minimum number.</li>
<li>If float, then <code>min_samples_leaf</code> is a fraction and
  <code>ceil(min_samples_leaf * n_samples)</code> are the minimum
  number of samples for each node.</li>
</ul>
<p>.. versionchanged:: 0.18
   Added float values for fractions.</p>
</li>
<li>
<p><strong>min_weight_fraction_leaf : float, default=0.0</strong>
    The minimum weighted fraction of the sum total of weights (of all
    the input samples) required to be at a leaf node. Samples have
    equal weight when sample_weight is not provided.</p>
</li>
<li>
<p><strong>max_features : {'auto', 'sqrt', 'log2'}, int or float, default='auto'</strong>
    The number of features to consider when looking for the best split:</p>
<ul>
<li>If int, then consider <code>max_features</code> features at each split.</li>
<li>If float, then <code>max_features</code> is a fraction and
  <code>int(max_features * n_features)</code> features are considered at each
  split.</li>
<li>If 'auto', then <code>max_features=sqrt(n_features)</code>.</li>
<li>If 'sqrt', then <code>max_features=sqrt(n_features)</code> (same as 'auto').</li>
<li>If 'log2', then <code>max_features=log2(n_features)</code>.</li>
<li>If None, then <code>max_features=n_features</code>.</li>
</ul>
</li>
<li>
<p><strong>Note: the search for a split does not stop until at least one</strong>
    valid partition of the node samples is found, even if it requires to
    effectively inspect more than <code>max_features</code> features.</p>
</li>
<li>
<p><strong>max_leaf_nodes : int, default=None</strong>
    Grow trees with <code>max_leaf_nodes</code> in best-first fashion.
    Best nodes are defined as relative reduction in impurity.
    If None then unlimited number of leaf nodes.</p>
</li>
<li>
<p><strong>min_impurity_decrease : float, default=0.0</strong>
    A node will be split if this split induces a decrease of the impurity
    greater than or equal to this value.</p>
<p>The weighted impurity decrease equation is the following::</p>
<div class="codehilite"><pre><span></span><code>N_t / N * (impurity - N_t_R / N_t * right_impurity
                    - N_t_L / N_t * left_impurity)
</code></pre></div>


<p>where <code>N</code> is the total number of samples, <code>N_t</code> is the number of
samples at the current node, <code>N_t_L</code> is the number of samples in the
left child, and <code>N_t_R</code> is the number of samples in the right child.</p>
<p><code>N</code>, <code>N_t</code>, <code>N_t_R</code> and <code>N_t_L</code> all refer to the weighted sum,
if <code>sample_weight</code> is passed.</p>
<p>.. versionadded:: 0.19</p>
</li>
<li>
<p><strong>min_impurity_split : float, default=None</strong>
    Threshold for early stopping in tree growth. A node will split
    if its impurity is above the threshold, otherwise it is a leaf.</p>
<p>.. deprecated:: 0.19
   <code>min_impurity_split</code> has been deprecated in favor of
   <code>min_impurity_decrease</code> in 0.19. The default value of
   <code>min_impurity_split</code> has changed from 1e-7 to 0 in 0.23 and it
   will be removed in 0.25. Use <code>min_impurity_decrease</code> instead.</p>
</li>
<li>
<p><strong>bootstrap : bool, default=True</strong>
    Whether bootstrap samples are used when building trees. If False, the
    whole dataset is used to build each tree.</p>
</li>
<li>
<p><strong>oob_score : bool, default=False</strong>
    Whether to use out-of-bag samples to estimate
    the generalization accuracy.</p>
</li>
<li>
<p><strong>n_jobs : int, default=None</strong>
    The number of jobs to run in parallel. :meth:<code>fit</code>, :meth:<code>predict</code>,
    :meth:<code>decision_path</code> and :meth:<code>apply</code> are all parallelized over the
    trees. <code>None</code> means 1 unless in a :obj:<code>joblib.parallel_backend</code>
    context. <code>-1</code> means using all processors. See :term:<code>Glossary
    &lt;n_jobs&gt;</code> for more details.</p>
</li>
<li>
<p><strong>random_state : int or RandomState, default=None</strong>
    Controls both the randomness of the bootstrapping of the samples used
    when building trees (if <code>bootstrap=True</code>) and the sampling of the
    features to consider when looking for the best split at each node
    (if <code>max_features &lt; n_features</code>).</p>
</li>
<li>
<p><strong>See :term:<code>Glossary &lt;random_state&gt;</code> for details.</strong></p>
</li>
<li>
<p><strong>verbose : int, default=0</strong>
    Controls the verbosity when fitting and predicting.</p>
</li>
<li>
<p><strong>warm_start : bool, default=False</strong>
    When set to <code>True</code>, reuse the solution of the previous call to fit
    and add more estimators to the ensemble, otherwise, just fit a whole
    new forest. See :term:<code>the Glossary &lt;warm_start&gt;</code>.</p>
</li>
<li>
<p><strong>class_weight : {'balanced', 'balanced_subsample'}, dict or list of dicts,             default=None</strong>
    Weights associated with classes in the form <code>{class_label: weight}</code>.
    If not given, all classes are supposed to have weight one. For
    multi-output problems, a list of dicts can be provided in the same
    order as the columns of y.</p>
<p>Note that for multioutput (including multilabel) weights should be
defined for each class of every column in its own dict. For example,
for four-class multilabel classification weights should be
[{0: 1, 1: 1}, {0: 1, 1: 5}, {0: 1, 1: 1}, {0: 1, 1: 1}] instead of
[{1:1}, {2:5}, {3:1}, {4:1}].</p>
<p>The 'balanced' mode uses the values of y to automatically adjust
weights inversely proportional to class frequencies in the input data
as <code>n_samples / (n_classes * np.bincount(y))</code></p>
<p>The 'balanced_subsample' mode is the same as 'balanced' except that
weights are computed based on the bootstrap sample for every tree
grown.</p>
<p>For multi-output, the weights of each column of y will be multiplied.</p>
<p>Note that these weights will be multiplied with sample_weight (passed
through the fit method) if sample_weight is specified.</p>
</li>
<li>
<p><strong>ccp_alpha : non-negative float, default=0.0</strong>
    Complexity parameter used for Minimal Cost-Complexity Pruning. The
    subtree with the largest cost complexity that is smaller than
    <code>ccp_alpha</code> will be chosen. By default, no pruning is performed. See
    :ref:<code>minimal_cost_complexity_pruning</code> for details.</p>
<p>.. versionadded:: 0.22</p>
</li>
<li>
<p><strong>max_samples : int or float, default=None</strong>
    If bootstrap is True, the number of samples to draw from X
    to train each base estimator.</p>
<ul>
<li>If None (default), then draw <code>X.shape[0]</code> samples.</li>
<li>If int, then draw <code>max_samples</code> samples.</li>
<li>If float, then draw <code>max_samples * X.shape[0]</code> samples. Thus,
  <code>max_samples</code> should be in the interval <code>(0, 1)</code>.</li>
</ul>
<p>.. versionadded:: 0.22</p>
</li>
</ul>
<h4>Attributes</h4>
<ul>
<li>
<p><strong>base_estimator_ : DecisionTreeClassifier</strong>
    The child estimator template used to create the collection of fitted
    sub-estimators.</p>
</li>
<li>
<p><strong>estimators_ : list of DecisionTreeClassifier</strong>
    The collection of fitted sub-estimators.</p>
</li>
<li>
<p><strong>classes_ : ndarray of shape (n_classes,) or a list of such arrays</strong>
    The classes labels (single output problem), or a list of arrays of
    class labels (multi-output problem).</p>
</li>
<li>
<p><strong>n_classes_ : int or list</strong>
    The number of classes (single output problem), or a list containing the
    number of classes for each output (multi-output problem).</p>
</li>
<li>
<p><strong>n_features_ : int</strong>
    The number of features when <code>fit</code> is performed.</p>
</li>
<li>
<p><strong>n_outputs_ : int</strong>
    The number of outputs when <code>fit</code> is performed.</p>
</li>
<li>
<p><strong>feature_importances_ : ndarray of shape (n_features,)</strong>
    The impurity-based feature importances.
    The higher, the more important the feature.
    The importance of a feature is computed as the (normalized)
    total reduction of the criterion brought by that feature.  It is also
    known as the Gini importance.</p>
</li>
<li>
<p><strong>Warning: impurity-based feature importances can be misleading for</strong>
    high cardinality features (many unique values). See
    :func:<code>sklearn.inspection.permutation_importance</code> as an alternative.</p>
</li>
<li>
<p><strong>oob_score_ : float</strong>
    Score of the training dataset obtained using an out-of-bag estimate.
    This attribute exists only when <code>oob_score</code> is True.</p>
</li>
<li>
<p><strong>oob_decision_function_ : ndarray of shape (n_samples, n_classes)</strong>
    Decision function computed with out-of-bag estimate on the training
    set. If n_estimators is small it might be possible that a data point
    was never left out during the bootstrap. In this case,
    <code>oob_decision_function_</code> might contain NaN. This attribute exists
    only when <code>oob_score</code> is True.</p>
</li>
</ul>
<h4>See Also</h4>
<p>DecisionTreeClassifier, ExtraTreesClassifier</p>
<h4>Notes</h4>
<p>The default values for the parameters controlling the size of the trees
(e.g. <code>max_depth</code>, <code>min_samples_leaf</code>, etc.) lead to fully grown and
unpruned trees which can potentially be very large on some data sets. To
reduce memory consumption, the complexity and size of the trees should be
controlled by setting those parameter values.</p>
<p>The features are always randomly permuted at each split. Therefore,
the best found split may vary, even with the same training data,
<code>max_features=n_features</code> and <code>bootstrap=False</code>, if the improvement
of the criterion is identical for several splits enumerated during the
search of the best split. To obtain a deterministic behaviour during
fitting, <code>random_state</code> has to be fixed.</p>
<h4>References</h4>
<p>.. [1] L. Breiman, 'Random Forests', Machine Learning, 45(1), 5-32, 2001.</p>
<h4>Examples</h4>
<div class="highlight"><pre><span></span><code><span class="o">&gt;&gt;&gt;</span> <span class="kn">from</span> <span class="nn">sklearn.ensemble</span> <span class="kn">import</span> <span class="n">RandomForestClassifier</span>
<span class="o">&gt;&gt;&gt;</span> <span class="kn">from</span> <span class="nn">sklearn.datasets</span> <span class="kn">import</span> <span class="n">make_classification</span>
<span class="o">&gt;&gt;&gt;</span> <span class="n">X</span><span class="p">,</span> <span class="n">y</span> <span class="o">=</span> <span class="n">make_classification</span><span class="p">(</span><span class="n">n_samples</span><span class="o">=</span><span class="mi">1000</span><span class="p">,</span> <span class="n">n_features</span><span class="o">=</span><span class="mi">4</span><span class="p">,</span>
<span class="o">...</span>                            <span class="n">n_informative</span><span class="o">=</span><span class="mi">2</span><span class="p">,</span> <span class="n">n_redundant</span><span class="o">=</span><span class="mi">0</span><span class="p">,</span>
<span class="o">...</span>                            <span class="n">random_state</span><span class="o">=</span><span class="mi">0</span><span class="p">,</span> <span class="n">shuffle</span><span class="o">=</span><span class="kc">False</span><span class="p">)</span>
<span class="o">&gt;&gt;&gt;</span> <span class="n">clf</span> <span class="o">=</span> <span class="n">RandomForestClassifier</span><span class="p">(</span><span class="n">max_depth</span><span class="o">=</span><span class="mi">2</span><span class="p">,</span> <span class="n">random_state</span><span class="o">=</span><span class="mi">0</span><span class="p">)</span>
<span class="o">&gt;&gt;&gt;</span> <span class="n">clf</span><span class="o">.</span><span class="n">fit</span><span class="p">(</span><span class="n">X</span><span class="p">,</span> <span class="n">y</span><span class="p">)</span>
<span class="n">RandomForestClassifier</span><span class="p">(</span><span class="o">...</span><span class="p">)</span>
<span class="o">&gt;&gt;&gt;</span> <span class="nb">print</span><span class="p">(</span><span class="n">clf</span><span class="o">.</span><span class="n">predict</span><span class="p">([[</span><span class="mi">0</span><span class="p">,</span> <span class="mi">0</span><span class="p">,</span> <span class="mi">0</span><span class="p">,</span> <span class="mi">0</span><span class="p">]]))</span>
<span class="p">[</span><span class="mi">1</span><span class="p">]</span>
</code></pre></div>

</details>
<h3 id="get_item_10">get_item<a class="headerlink" href="#get_item_10" title="Permanent link">&para;</a></h3>
<details class="note" open="open"><summary>method get_item</summary><div class="highlight"><pre><span></span><code><span class="k">val</span> <span class="n">get_item</span> <span class="o">:</span>
  <span class="n">index</span><span class="o">:</span><span class="nn">Py</span><span class="p">.</span><span class="nn">Object</span><span class="p">.</span><span class="n">t</span> <span class="o">-&gt;</span>
  <span class="o">[&gt;</span> <span class="n">tag</span><span class="o">]</span> <span class="nn">Obj</span><span class="p">.</span><span class="n">t</span> <span class="o">-&gt;</span>
  <span class="nn">Py</span><span class="p">.</span><span class="nn">Object</span><span class="p">.</span><span class="n">t</span>
</code></pre></div>

<p>Return the index'th estimator in the ensemble.</p>
</details>
<h3 id="iter_10">iter<a class="headerlink" href="#iter_10" title="Permanent link">&para;</a></h3>
<details class="note" open="open"><summary>method iter</summary><div class="highlight"><pre><span></span><code><span class="k">val</span> <span class="n">iter</span> <span class="o">:</span>
  <span class="o">[&gt;</span> <span class="n">tag</span><span class="o">]</span> <span class="nn">Obj</span><span class="p">.</span><span class="n">t</span> <span class="o">-&gt;</span>
  <span class="nn">Dict</span><span class="p">.</span><span class="n">t</span> <span class="nn">Seq</span><span class="p">.</span><span class="n">t</span>
</code></pre></div>

<p>Return iterator over estimators in the ensemble.</p>
</details>
<h3 id="apply_4">apply<a class="headerlink" href="#apply_4" title="Permanent link">&para;</a></h3>
<details class="note" open="open"><summary>method apply</summary><div class="highlight"><pre><span></span><code><span class="k">val</span> <span class="n">apply</span> <span class="o">:</span>
  <span class="n">x</span><span class="o">:[&gt;`</span><span class="nc">ArrayLike</span><span class="o">]</span> <span class="nn">Np</span><span class="p">.</span><span class="nn">Obj</span><span class="p">.</span><span class="n">t</span> <span class="o">-&gt;</span>
  <span class="o">[&gt;</span> <span class="n">tag</span><span class="o">]</span> <span class="nn">Obj</span><span class="p">.</span><span class="n">t</span> <span class="o">-&gt;</span>
  <span class="o">[&gt;`</span><span class="nc">ArrayLike</span><span class="o">]</span> <span class="nn">Np</span><span class="p">.</span><span class="nn">Obj</span><span class="p">.</span><span class="n">t</span>
</code></pre></div>

<p>Apply trees in the forest to X, return leaf indices.</p>
<h4>Parameters</h4>
<ul>
<li><strong>X : {array-like, sparse matrix} of shape (n_samples, n_features)</strong>
    The input samples. Internally, its dtype will be converted to
    <code>dtype=np.float32</code>. If a sparse matrix is provided, it will be
    converted into a sparse <code>csr_matrix</code>.</li>
</ul>
<h4>Returns</h4>
<ul>
<li><strong>X_leaves : ndarray of shape (n_samples, n_estimators)</strong>
    For each datapoint x in X and for each tree in the forest,
    return the index of the leaf x ends up in.</li>
</ul>
</details>
<h3 id="decision_path_2">decision_path<a class="headerlink" href="#decision_path_2" title="Permanent link">&para;</a></h3>
<details class="note" open="open"><summary>method decision_path</summary><div class="highlight"><pre><span></span><code><span class="k">val</span> <span class="n">decision_path</span> <span class="o">:</span>
  <span class="n">x</span><span class="o">:[&gt;`</span><span class="nc">ArrayLike</span><span class="o">]</span> <span class="nn">Np</span><span class="p">.</span><span class="nn">Obj</span><span class="p">.</span><span class="n">t</span> <span class="o">-&gt;</span>
  <span class="o">[&gt;</span> <span class="n">tag</span><span class="o">]</span> <span class="nn">Obj</span><span class="p">.</span><span class="n">t</span> <span class="o">-&gt;</span>
  <span class="o">([`</span><span class="nc">ArrayLike</span><span class="o">|`</span><span class="nc">Object</span><span class="o">|`</span><span class="nc">Spmatrix</span><span class="o">]</span> <span class="nn">Np</span><span class="p">.</span><span class="nn">Obj</span><span class="p">.</span><span class="n">t</span> <span class="o">*</span> <span class="o">[&gt;`</span><span class="nc">ArrayLike</span><span class="o">]</span> <span class="nn">Np</span><span class="p">.</span><span class="nn">Obj</span><span class="p">.</span><span class="n">t</span><span class="o">)</span>
</code></pre></div>

<p>Return the decision path in the forest.</p>
<p>.. versionadded:: 0.18</p>
<h4>Parameters</h4>
<ul>
<li><strong>X : {array-like, sparse matrix} of shape (n_samples, n_features)</strong>
    The input samples. Internally, its dtype will be converted to
    <code>dtype=np.float32</code>. If a sparse matrix is provided, it will be
    converted into a sparse <code>csr_matrix</code>.</li>
</ul>
<h4>Returns</h4>
<ul>
<li>
<p><strong>indicator : sparse matrix of shape (n_samples, n_nodes)</strong>
    Return a node indicator matrix where non zero elements indicates
    that the samples goes through the nodes. The matrix is of CSR
    format.</p>
</li>
<li>
<p><strong>n_nodes_ptr : ndarray of shape (n_estimators + 1,)</strong>
    The columns from indicator[n_nodes_ptr[i]:n_nodes_ptr[i+1]]
    gives the indicator value for the i-th estimator.</p>
</li>
</ul>
</details>
<h3 id="fit_9">fit<a class="headerlink" href="#fit_9" title="Permanent link">&para;</a></h3>
<details class="note" open="open"><summary>method fit</summary><div class="highlight"><pre><span></span><code><span class="k">val</span> <span class="n">fit</span> <span class="o">:</span>
  <span class="o">?</span><span class="n">sample_weight</span><span class="o">:[&gt;`</span><span class="nc">ArrayLike</span><span class="o">]</span> <span class="nn">Np</span><span class="p">.</span><span class="nn">Obj</span><span class="p">.</span><span class="n">t</span> <span class="o">-&gt;</span>
  <span class="n">x</span><span class="o">:[&gt;`</span><span class="nc">ArrayLike</span><span class="o">]</span> <span class="nn">Np</span><span class="p">.</span><span class="nn">Obj</span><span class="p">.</span><span class="n">t</span> <span class="o">-&gt;</span>
  <span class="n">y</span><span class="o">:[&gt;`</span><span class="nc">ArrayLike</span><span class="o">]</span> <span class="nn">Np</span><span class="p">.</span><span class="nn">Obj</span><span class="p">.</span><span class="n">t</span> <span class="o">-&gt;</span>
  <span class="o">[&gt;</span> <span class="n">tag</span><span class="o">]</span> <span class="nn">Obj</span><span class="p">.</span><span class="n">t</span> <span class="o">-&gt;</span>
  <span class="n">t</span>
</code></pre></div>

<p>Build a forest of trees from the training set (X, y).</p>
<h4>Parameters</h4>
<ul>
<li>
<p><strong>X : {array-like, sparse matrix} of shape (n_samples, n_features)</strong>
    The training input samples. Internally, its dtype will be converted
    to <code>dtype=np.float32</code>. If a sparse matrix is provided, it will be
    converted into a sparse <code>csc_matrix</code>.</p>
</li>
<li>
<p><strong>y : array-like of shape (n_samples,) or (n_samples, n_outputs)</strong>
    The target values (class labels in classification, real numbers in
    regression).</p>
</li>
<li>
<p><strong>sample_weight : array-like of shape (n_samples,), default=None</strong>
    Sample weights. If None, then samples are equally weighted. Splits
    that would create child nodes with net zero or negative weight are
    ignored while searching for a split in each node. In the case of
    classification, splits are also ignored if they would result in any
    single class carrying a negative weight in either child node.</p>
</li>
</ul>
<h4>Returns</h4>
<ul>
<li><strong>self : object</strong></li>
</ul>
</details>
<h3 id="get_params_10">get_params<a class="headerlink" href="#get_params_10" title="Permanent link">&para;</a></h3>
<details class="note" open="open"><summary>method get_params</summary><div class="highlight"><pre><span></span><code><span class="k">val</span> <span class="n">get_params</span> <span class="o">:</span>
  <span class="o">?</span><span class="n">deep</span><span class="o">:</span><span class="kt">bool</span> <span class="o">-&gt;</span>
  <span class="o">[&gt;</span> <span class="n">tag</span><span class="o">]</span> <span class="nn">Obj</span><span class="p">.</span><span class="n">t</span> <span class="o">-&gt;</span>
  <span class="nn">Dict</span><span class="p">.</span><span class="n">t</span>
</code></pre></div>

<p>Get parameters for this estimator.</p>
<h4>Parameters</h4>
<ul>
<li><strong>deep : bool, default=True</strong>
    If True, will return the parameters for this estimator and
    contained subobjects that are estimators.</li>
</ul>
<h4>Returns</h4>
<ul>
<li><strong>params : mapping of string to any</strong>
    Parameter names mapped to their values.</li>
</ul>
</details>
<h3 id="predict_9">predict<a class="headerlink" href="#predict_9" title="Permanent link">&para;</a></h3>
<details class="note" open="open"><summary>method predict</summary><div class="highlight"><pre><span></span><code><span class="k">val</span> <span class="n">predict</span> <span class="o">:</span>
  <span class="n">x</span><span class="o">:[&gt;`</span><span class="nc">ArrayLike</span><span class="o">]</span> <span class="nn">Np</span><span class="p">.</span><span class="nn">Obj</span><span class="p">.</span><span class="n">t</span> <span class="o">-&gt;</span>
  <span class="o">[&gt;</span> <span class="n">tag</span><span class="o">]</span> <span class="nn">Obj</span><span class="p">.</span><span class="n">t</span> <span class="o">-&gt;</span>
  <span class="o">[&gt;`</span><span class="nc">ArrayLike</span><span class="o">]</span> <span class="nn">Np</span><span class="p">.</span><span class="nn">Obj</span><span class="p">.</span><span class="n">t</span>
</code></pre></div>

<p>Predict class for X.</p>
<p>The predicted class of an input sample is a vote by the trees in
the forest, weighted by their probability estimates. That is,
the predicted class is the one with highest mean probability
estimate across the trees.</p>
<h4>Parameters</h4>
<ul>
<li><strong>X : {array-like, sparse matrix} of shape (n_samples, n_features)</strong>
    The input samples. Internally, its dtype will be converted to
    <code>dtype=np.float32</code>. If a sparse matrix is provided, it will be
    converted into a sparse <code>csr_matrix</code>.</li>
</ul>
<h4>Returns</h4>
<ul>
<li><strong>y : ndarray of shape (n_samples,) or (n_samples, n_outputs)</strong>
    The predicted classes.</li>
</ul>
</details>
<h3 id="predict_log_proba_4">predict_log_proba<a class="headerlink" href="#predict_log_proba_4" title="Permanent link">&para;</a></h3>
<details class="note" open="open"><summary>method predict_log_proba</summary><div class="highlight"><pre><span></span><code><span class="k">val</span> <span class="n">predict_log_proba</span> <span class="o">:</span>
  <span class="n">x</span><span class="o">:[&gt;`</span><span class="nc">ArrayLike</span><span class="o">]</span> <span class="nn">Np</span><span class="p">.</span><span class="nn">Obj</span><span class="p">.</span><span class="n">t</span> <span class="o">-&gt;</span>
  <span class="o">[&gt;</span> <span class="n">tag</span><span class="o">]</span> <span class="nn">Obj</span><span class="p">.</span><span class="n">t</span> <span class="o">-&gt;</span>
  <span class="nn">Py</span><span class="p">.</span><span class="nn">Object</span><span class="p">.</span><span class="n">t</span>
</code></pre></div>

<p>Predict class log-probabilities for X.</p>
<p>The predicted class log-probabilities of an input sample is computed as
the log of the mean predicted class probabilities of the trees in the
forest.</p>
<h4>Parameters</h4>
<ul>
<li><strong>X : {array-like, sparse matrix} of shape (n_samples, n_features)</strong>
    The input samples. Internally, its dtype will be converted to
    <code>dtype=np.float32</code>. If a sparse matrix is provided, it will be
    converted into a sparse <code>csr_matrix</code>.</li>
</ul>
<h4>Returns</h4>
<ul>
<li><strong>p : ndarray of shape (n_samples, n_classes), or a list of n_outputs</strong>
    such arrays if n_outputs &gt; 1.
    The class probabilities of the input samples. The order of the
    classes corresponds to that in the attribute :term:<code>classes_</code>.</li>
</ul>
</details>
<h3 id="predict_proba_4">predict_proba<a class="headerlink" href="#predict_proba_4" title="Permanent link">&para;</a></h3>
<details class="note" open="open"><summary>method predict_proba</summary><div class="highlight"><pre><span></span><code><span class="k">val</span> <span class="n">predict_proba</span> <span class="o">:</span>
  <span class="n">x</span><span class="o">:[&gt;`</span><span class="nc">ArrayLike</span><span class="o">]</span> <span class="nn">Np</span><span class="p">.</span><span class="nn">Obj</span><span class="p">.</span><span class="n">t</span> <span class="o">-&gt;</span>
  <span class="o">[&gt;</span> <span class="n">tag</span><span class="o">]</span> <span class="nn">Obj</span><span class="p">.</span><span class="n">t</span> <span class="o">-&gt;</span>
  <span class="o">[&gt;`</span><span class="nc">ArrayLike</span><span class="o">]</span> <span class="nn">Np</span><span class="p">.</span><span class="nn">Obj</span><span class="p">.</span><span class="n">t</span>
</code></pre></div>

<p>Predict class probabilities for X.</p>
<p>The predicted class probabilities of an input sample are computed as
the mean predicted class probabilities of the trees in the forest.
The class probability of a single tree is the fraction of samples of
the same class in a leaf.</p>
<h4>Parameters</h4>
<ul>
<li><strong>X : {array-like, sparse matrix} of shape (n_samples, n_features)</strong>
    The input samples. Internally, its dtype will be converted to
    <code>dtype=np.float32</code>. If a sparse matrix is provided, it will be
    converted into a sparse <code>csr_matrix</code>.</li>
</ul>
<h4>Returns</h4>
<ul>
<li><strong>p : ndarray of shape (n_samples, n_classes), or a list of n_outputs</strong>
    such arrays if n_outputs &gt; 1.
    The class probabilities of the input samples. The order of the
    classes corresponds to that in the attribute :term:<code>classes_</code>.</li>
</ul>
</details>
<h3 id="score_8">score<a class="headerlink" href="#score_8" title="Permanent link">&para;</a></h3>
<details class="note" open="open"><summary>method score</summary><div class="highlight"><pre><span></span><code><span class="k">val</span> <span class="n">score</span> <span class="o">:</span>
  <span class="o">?</span><span class="n">sample_weight</span><span class="o">:[&gt;`</span><span class="nc">ArrayLike</span><span class="o">]</span> <span class="nn">Np</span><span class="p">.</span><span class="nn">Obj</span><span class="p">.</span><span class="n">t</span> <span class="o">-&gt;</span>
  <span class="n">x</span><span class="o">:[&gt;`</span><span class="nc">ArrayLike</span><span class="o">]</span> <span class="nn">Np</span><span class="p">.</span><span class="nn">Obj</span><span class="p">.</span><span class="n">t</span> <span class="o">-&gt;</span>
  <span class="n">y</span><span class="o">:[&gt;`</span><span class="nc">ArrayLike</span><span class="o">]</span> <span class="nn">Np</span><span class="p">.</span><span class="nn">Obj</span><span class="p">.</span><span class="n">t</span> <span class="o">-&gt;</span>
  <span class="o">[&gt;</span> <span class="n">tag</span><span class="o">]</span> <span class="nn">Obj</span><span class="p">.</span><span class="n">t</span> <span class="o">-&gt;</span>
  <span class="kt">float</span>
</code></pre></div>

<p>Return the mean accuracy on the given test data and labels.</p>
<p>In multi-label classification, this is the subset accuracy
which is a harsh metric since you require for each sample that
each label set be correctly predicted.</p>
<h4>Parameters</h4>
<ul>
<li>
<p><strong>X : array-like of shape (n_samples, n_features)</strong>
    Test samples.</p>
</li>
<li>
<p><strong>y : array-like of shape (n_samples,) or (n_samples, n_outputs)</strong>
    True labels for X.</p>
</li>
<li>
<p><strong>sample_weight : array-like of shape (n_samples,), default=None</strong>
    Sample weights.</p>
</li>
</ul>
<h4>Returns</h4>
<ul>
<li><strong>score : float</strong>
    Mean accuracy of self.predict(X) wrt. y.</li>
</ul>
</details>
<h3 id="set_params_10">set_params<a class="headerlink" href="#set_params_10" title="Permanent link">&para;</a></h3>
<details class="note" open="open"><summary>method set_params</summary><div class="highlight"><pre><span></span><code><span class="k">val</span> <span class="n">set_params</span> <span class="o">:</span>
  <span class="o">?</span><span class="n">params</span><span class="o">:(</span><span class="kt">string</span> <span class="o">*</span> <span class="nn">Py</span><span class="p">.</span><span class="nn">Object</span><span class="p">.</span><span class="n">t</span><span class="o">)</span> <span class="kt">list</span> <span class="o">-&gt;</span>
  <span class="o">[&gt;</span> <span class="n">tag</span><span class="o">]</span> <span class="nn">Obj</span><span class="p">.</span><span class="n">t</span> <span class="o">-&gt;</span>
  <span class="n">t</span>
</code></pre></div>

<p>Set the parameters of this estimator.</p>
<p>The method works on simple estimators as well as on nested objects
(such as pipelines). The latter have parameters of the form
<code>&lt;component&gt;__&lt;parameter&gt;</code> so that it's possible to update each
component of a nested object.</p>
<h4>Parameters</h4>
<ul>
<li><strong>**params : dict</strong>
    Estimator parameters.</li>
</ul>
<h4>Returns</h4>
<ul>
<li><strong>self : object</strong>
    Estimator instance.</li>
</ul>
</details>
<h3 id="base_estimator__7">base_estimator_<a class="headerlink" href="#base_estimator__7" title="Permanent link">&para;</a></h3>
<details class="note" open="open"><summary>attribute base_estimator_</summary><div class="highlight"><pre><span></span><code><span class="k">val</span> <span class="n">base_estimator_</span> <span class="o">:</span> <span class="n">t</span> <span class="o">-&gt;</span> <span class="nn">Py</span><span class="p">.</span><span class="nn">Object</span><span class="p">.</span><span class="n">t</span>
<span class="k">val</span> <span class="n">base_estimator_opt</span> <span class="o">:</span> <span class="n">t</span> <span class="o">-&gt;</span> <span class="o">(</span><span class="nn">Py</span><span class="p">.</span><span class="nn">Object</span><span class="p">.</span><span class="n">t</span><span class="o">)</span> <span class="n">option</span>
</code></pre></div>

<p>This attribute is documented in <code>create</code> above. The first version raises Not_found
if the attribute is None. The _opt version returns an option.</p>
</details>
<h3 id="estimators__10">estimators_<a class="headerlink" href="#estimators__10" title="Permanent link">&para;</a></h3>
<details class="note" open="open"><summary>attribute estimators_</summary><div class="highlight"><pre><span></span><code><span class="k">val</span> <span class="n">estimators_</span> <span class="o">:</span> <span class="n">t</span> <span class="o">-&gt;</span> <span class="nn">Py</span><span class="p">.</span><span class="nn">Object</span><span class="p">.</span><span class="n">t</span>
<span class="k">val</span> <span class="n">estimators_opt</span> <span class="o">:</span> <span class="n">t</span> <span class="o">-&gt;</span> <span class="o">(</span><span class="nn">Py</span><span class="p">.</span><span class="nn">Object</span><span class="p">.</span><span class="n">t</span><span class="o">)</span> <span class="n">option</span>
</code></pre></div>

<p>This attribute is documented in <code>create</code> above. The first version raises Not_found
if the attribute is None. The _opt version returns an option.</p>
</details>
<h3 id="classes__4">classes_<a class="headerlink" href="#classes__4" title="Permanent link">&para;</a></h3>
<details class="note" open="open"><summary>attribute classes_</summary><div class="highlight"><pre><span></span><code><span class="k">val</span> <span class="n">classes_</span> <span class="o">:</span> <span class="n">t</span> <span class="o">-&gt;</span> <span class="o">[&gt;`</span><span class="nc">ArrayLike</span><span class="o">]</span> <span class="nn">Np</span><span class="p">.</span><span class="nn">Obj</span><span class="p">.</span><span class="n">t</span>
<span class="k">val</span> <span class="n">classes_opt</span> <span class="o">:</span> <span class="n">t</span> <span class="o">-&gt;</span> <span class="o">([&gt;`</span><span class="nc">ArrayLike</span><span class="o">]</span> <span class="nn">Np</span><span class="p">.</span><span class="nn">Obj</span><span class="p">.</span><span class="n">t</span><span class="o">)</span> <span class="n">option</span>
</code></pre></div>

<p>This attribute is documented in <code>create</code> above. The first version raises Not_found
if the attribute is None. The _opt version returns an option.</p>
</details>
<h3 id="n_classes__4">n_classes_<a class="headerlink" href="#n_classes__4" title="Permanent link">&para;</a></h3>
<details class="note" open="open"><summary>attribute n_classes_</summary><div class="highlight"><pre><span></span><code><span class="k">val</span> <span class="n">n_classes_</span> <span class="o">:</span> <span class="n">t</span> <span class="o">-&gt;</span> <span class="nn">Py</span><span class="p">.</span><span class="nn">Object</span><span class="p">.</span><span class="n">t</span>
<span class="k">val</span> <span class="n">n_classes_opt</span> <span class="o">:</span> <span class="n">t</span> <span class="o">-&gt;</span> <span class="o">(</span><span class="nn">Py</span><span class="p">.</span><span class="nn">Object</span><span class="p">.</span><span class="n">t</span><span class="o">)</span> <span class="n">option</span>
</code></pre></div>

<p>This attribute is documented in <code>create</code> above. The first version raises Not_found
if the attribute is None. The _opt version returns an option.</p>
</details>
<h3 id="n_features__6">n_features_<a class="headerlink" href="#n_features__6" title="Permanent link">&para;</a></h3>
<details class="note" open="open"><summary>attribute n_features_</summary><div class="highlight"><pre><span></span><code><span class="k">val</span> <span class="n">n_features_</span> <span class="o">:</span> <span class="n">t</span> <span class="o">-&gt;</span> <span class="kt">int</span>
<span class="k">val</span> <span class="n">n_features_opt</span> <span class="o">:</span> <span class="n">t</span> <span class="o">-&gt;</span> <span class="o">(</span><span class="kt">int</span><span class="o">)</span> <span class="n">option</span>
</code></pre></div>

<p>This attribute is documented in <code>create</code> above. The first version raises Not_found
if the attribute is None. The _opt version returns an option.</p>
</details>
<h3 id="n_outputs__2">n_outputs_<a class="headerlink" href="#n_outputs__2" title="Permanent link">&para;</a></h3>
<details class="note" open="open"><summary>attribute n_outputs_</summary><div class="highlight"><pre><span></span><code><span class="k">val</span> <span class="n">n_outputs_</span> <span class="o">:</span> <span class="n">t</span> <span class="o">-&gt;</span> <span class="kt">int</span>
<span class="k">val</span> <span class="n">n_outputs_opt</span> <span class="o">:</span> <span class="n">t</span> <span class="o">-&gt;</span> <span class="o">(</span><span class="kt">int</span><span class="o">)</span> <span class="n">option</span>
</code></pre></div>

<p>This attribute is documented in <code>create</code> above. The first version raises Not_found
if the attribute is None. The _opt version returns an option.</p>
</details>
<h3 id="feature_importances__6">feature_importances_<a class="headerlink" href="#feature_importances__6" title="Permanent link">&para;</a></h3>
<details class="note" open="open"><summary>attribute feature_importances_</summary><div class="highlight"><pre><span></span><code><span class="k">val</span> <span class="n">feature_importances_</span> <span class="o">:</span> <span class="n">t</span> <span class="o">-&gt;</span> <span class="o">[&gt;`</span><span class="nc">ArrayLike</span><span class="o">]</span> <span class="nn">Np</span><span class="p">.</span><span class="nn">Obj</span><span class="p">.</span><span class="n">t</span>
<span class="k">val</span> <span class="n">feature_importances_opt</span> <span class="o">:</span> <span class="n">t</span> <span class="o">-&gt;</span> <span class="o">([&gt;`</span><span class="nc">ArrayLike</span><span class="o">]</span> <span class="nn">Np</span><span class="p">.</span><span class="nn">Obj</span><span class="p">.</span><span class="n">t</span><span class="o">)</span> <span class="n">option</span>
</code></pre></div>

<p>This attribute is documented in <code>create</code> above. The first version raises Not_found
if the attribute is None. The _opt version returns an option.</p>
</details>
<h3 id="warning_6">warning<a class="headerlink" href="#warning_6" title="Permanent link">&para;</a></h3>
<details class="note" open="open"><summary>attribute warning</summary><div class="highlight"><pre><span></span><code><span class="k">val</span> <span class="n">warning</span> <span class="o">:</span> <span class="n">t</span> <span class="o">-&gt;</span> <span class="nn">Py</span><span class="p">.</span><span class="nn">Object</span><span class="p">.</span><span class="n">t</span>
<span class="k">val</span> <span class="n">warning_opt</span> <span class="o">:</span> <span class="n">t</span> <span class="o">-&gt;</span> <span class="o">(</span><span class="nn">Py</span><span class="p">.</span><span class="nn">Object</span><span class="p">.</span><span class="n">t</span><span class="o">)</span> <span class="n">option</span>
</code></pre></div>

<p>This attribute is documented in <code>create</code> above. The first version raises Not_found
if the attribute is None. The _opt version returns an option.</p>
</details>
<h3 id="oob_score__4">oob_score_<a class="headerlink" href="#oob_score__4" title="Permanent link">&para;</a></h3>
<details class="note" open="open"><summary>attribute oob_score_</summary><div class="highlight"><pre><span></span><code><span class="k">val</span> <span class="n">oob_score_</span> <span class="o">:</span> <span class="n">t</span> <span class="o">-&gt;</span> <span class="kt">float</span>
<span class="k">val</span> <span class="n">oob_score_opt</span> <span class="o">:</span> <span class="n">t</span> <span class="o">-&gt;</span> <span class="o">(</span><span class="kt">float</span><span class="o">)</span> <span class="n">option</span>
</code></pre></div>

<p>This attribute is documented in <code>create</code> above. The first version raises Not_found
if the attribute is None. The _opt version returns an option.</p>
</details>
<h3 id="oob_decision_function__2">oob_decision_function_<a class="headerlink" href="#oob_decision_function__2" title="Permanent link">&para;</a></h3>
<details class="note" open="open"><summary>attribute oob_decision_function_</summary><div class="highlight"><pre><span></span><code><span class="k">val</span> <span class="n">oob_decision_function_</span> <span class="o">:</span> <span class="n">t</span> <span class="o">-&gt;</span> <span class="o">[&gt;`</span><span class="nc">ArrayLike</span><span class="o">]</span> <span class="nn">Np</span><span class="p">.</span><span class="nn">Obj</span><span class="p">.</span><span class="n">t</span>
<span class="k">val</span> <span class="n">oob_decision_function_opt</span> <span class="o">:</span> <span class="n">t</span> <span class="o">-&gt;</span> <span class="o">([&gt;`</span><span class="nc">ArrayLike</span><span class="o">]</span> <span class="nn">Np</span><span class="p">.</span><span class="nn">Obj</span><span class="p">.</span><span class="n">t</span><span class="o">)</span> <span class="n">option</span>
</code></pre></div>

<p>This attribute is documented in <code>create</code> above. The first version raises Not_found
if the attribute is None. The _opt version returns an option.</p>
</details>
<h3 id="to_string_10">to_string<a class="headerlink" href="#to_string_10" title="Permanent link">&para;</a></h3>
<details class="note" open="open"><summary>method to_string</summary><div class="highlight"><pre><span></span><code><span class="k">val</span> <span class="n">to_string</span><span class="o">:</span> <span class="n">t</span> <span class="o">-&gt;</span> <span class="kt">string</span>
</code></pre></div>

<p>Print the object to a human-readable representation.</p>
</details>
<h3 id="show_10">show<a class="headerlink" href="#show_10" title="Permanent link">&para;</a></h3>
<details class="note" open="open"><summary>method show</summary><div class="highlight"><pre><span></span><code><span class="k">val</span> <span class="n">show</span><span class="o">:</span> <span class="n">t</span> <span class="o">-&gt;</span> <span class="kt">string</span>
</code></pre></div>

<p>Print the object to a human-readable representation.</p>
</details>
<h3 id="pp_10">pp<a class="headerlink" href="#pp_10" title="Permanent link">&para;</a></h3>
<details class="note" open="open"><summary>method pp</summary><div class="highlight"><pre><span></span><code><span class="k">val</span> <span class="n">pp</span><span class="o">:</span> <span class="nn">Format</span><span class="p">.</span><span class="n">formatter</span> <span class="o">-&gt;</span> <span class="n">t</span> <span class="o">-&gt;</span> <span class="kt">unit</span>
</code></pre></div>

<p>Pretty-print the object to a formatter.</p>
</details>
<h2 id="randomforestregressor">RandomForestRegressor<a class="headerlink" href="#randomforestregressor" title="Permanent link">&para;</a></h2>
<p>Module <code>Sklearn.​Ensemble.​RandomForestRegressor</code> wraps Python class <a href="https://scikit-learn.org/stable/modules/generated/sklearn.ensemble.RandomForestRegressor.html"><code>sklearn.ensemble.RandomForestRegressor</code></a>.</p>
<div class="highlight"><pre><span></span><code><span class="k">type</span> <span class="n">t</span>
</code></pre></div>

<h3 id="create_10">create<a class="headerlink" href="#create_10" title="Permanent link">&para;</a></h3>
<details class="note" open="open"><summary>constructor and attributes create</summary><div class="highlight"><pre><span></span><code><span class="k">val</span> <span class="n">create</span> <span class="o">:</span>
  <span class="o">?</span><span class="n">n_estimators</span><span class="o">:</span><span class="kt">int</span> <span class="o">-&gt;</span>
  <span class="o">?</span><span class="n">criterion</span><span class="o">:[`</span><span class="nc">Mse</span> <span class="o">|</span> <span class="o">`</span><span class="nc">Mae</span><span class="o">]</span> <span class="o">-&gt;</span>
  <span class="o">?</span><span class="n">max_depth</span><span class="o">:</span><span class="kt">int</span> <span class="o">-&gt;</span>
  <span class="o">?</span><span class="n">min_samples_split</span><span class="o">:[`</span><span class="nc">F</span> <span class="k">of</span> <span class="kt">float</span> <span class="o">|</span> <span class="o">`</span><span class="nc">I</span> <span class="k">of</span> <span class="kt">int</span><span class="o">]</span> <span class="o">-&gt;</span>
  <span class="o">?</span><span class="n">min_samples_leaf</span><span class="o">:[`</span><span class="nc">F</span> <span class="k">of</span> <span class="kt">float</span> <span class="o">|</span> <span class="o">`</span><span class="nc">I</span> <span class="k">of</span> <span class="kt">int</span><span class="o">]</span> <span class="o">-&gt;</span>
  <span class="o">?</span><span class="n">min_weight_fraction_leaf</span><span class="o">:</span><span class="kt">float</span> <span class="o">-&gt;</span>
  <span class="o">?</span><span class="n">max_features</span><span class="o">:[`</span><span class="nc">I</span> <span class="k">of</span> <span class="kt">int</span> <span class="o">|</span> <span class="o">`</span><span class="nc">Sqrt</span> <span class="o">|</span> <span class="o">`</span><span class="nc">Auto</span> <span class="o">|</span> <span class="o">`</span><span class="nc">F</span> <span class="k">of</span> <span class="kt">float</span> <span class="o">|</span> <span class="o">`</span><span class="nc">Log2</span><span class="o">]</span> <span class="o">-&gt;</span>
  <span class="o">?</span><span class="n">max_leaf_nodes</span><span class="o">:</span><span class="kt">int</span> <span class="o">-&gt;</span>
  <span class="o">?</span><span class="n">min_impurity_decrease</span><span class="o">:</span><span class="kt">float</span> <span class="o">-&gt;</span>
  <span class="o">?</span><span class="n">min_impurity_split</span><span class="o">:</span><span class="kt">float</span> <span class="o">-&gt;</span>
  <span class="o">?</span><span class="n">bootstrap</span><span class="o">:</span><span class="kt">bool</span> <span class="o">-&gt;</span>
  <span class="o">?</span><span class="n">oob_score</span><span class="o">:</span><span class="kt">bool</span> <span class="o">-&gt;</span>
  <span class="o">?</span><span class="n">n_jobs</span><span class="o">:</span><span class="kt">int</span> <span class="o">-&gt;</span>
  <span class="o">?</span><span class="n">random_state</span><span class="o">:</span><span class="kt">int</span> <span class="o">-&gt;</span>
  <span class="o">?</span><span class="n">verbose</span><span class="o">:</span><span class="kt">int</span> <span class="o">-&gt;</span>
  <span class="o">?</span><span class="n">warm_start</span><span class="o">:</span><span class="kt">bool</span> <span class="o">-&gt;</span>
  <span class="o">?</span><span class="n">ccp_alpha</span><span class="o">:</span><span class="kt">float</span> <span class="o">-&gt;</span>
  <span class="o">?</span><span class="n">max_samples</span><span class="o">:[`</span><span class="nc">F</span> <span class="k">of</span> <span class="kt">float</span> <span class="o">|</span> <span class="o">`</span><span class="nc">I</span> <span class="k">of</span> <span class="kt">int</span><span class="o">]</span> <span class="o">-&gt;</span>
  <span class="kt">unit</span> <span class="o">-&gt;</span>
  <span class="n">t</span>
</code></pre></div>

<p>A random forest regressor.</p>
<p>A random forest is a meta estimator that fits a number of classifying
decision trees on various sub-samples of the dataset and uses averaging
to improve the predictive accuracy and control over-fitting.
The sub-sample size is controlled with the <code>max_samples</code> parameter if
<code>bootstrap=True</code> (default), otherwise the whole dataset is used to build
each tree.</p>
<p>Read more in the :ref:<code>User Guide &lt;forest&gt;</code>.</p>
<h4>Parameters</h4>
<ul>
<li>
<p><strong>n_estimators : int, default=100</strong>
    The number of trees in the forest.</p>
<p>.. versionchanged:: 0.22
   The default value of <code>n_estimators</code> changed from 10 to 100
   in 0.22.</p>
</li>
<li>
<p><strong>criterion : {'mse', 'mae'}, default='mse'</strong>
    The function to measure the quality of a split. Supported criteria
    are 'mse' for the mean squared error, which is equal to variance
    reduction as feature selection criterion, and 'mae' for the mean
    absolute error.</p>
<p>.. versionadded:: 0.18
   Mean Absolute Error (MAE) criterion.</p>
</li>
<li>
<p><strong>max_depth : int, default=None</strong>
    The maximum depth of the tree. If None, then nodes are expanded until
    all leaves are pure or until all leaves contain less than
    min_samples_split samples.</p>
</li>
<li>
<p><strong>min_samples_split : int or float, default=2</strong>
    The minimum number of samples required to split an internal node:</p>
<ul>
<li>If int, then consider <code>min_samples_split</code> as the minimum number.</li>
<li>If float, then <code>min_samples_split</code> is a fraction and
  <code>ceil(min_samples_split * n_samples)</code> are the minimum
  number of samples for each split.</li>
</ul>
<p>.. versionchanged:: 0.18
   Added float values for fractions.</p>
</li>
<li>
<p><strong>min_samples_leaf : int or float, default=1</strong>
    The minimum number of samples required to be at a leaf node.
    A split point at any depth will only be considered if it leaves at
    least <code>min_samples_leaf</code> training samples in each of the left and
    right branches.  This may have the effect of smoothing the model,
    especially in regression.</p>
<ul>
<li>If int, then consider <code>min_samples_leaf</code> as the minimum number.</li>
<li>If float, then <code>min_samples_leaf</code> is a fraction and
  <code>ceil(min_samples_leaf * n_samples)</code> are the minimum
  number of samples for each node.</li>
</ul>
<p>.. versionchanged:: 0.18
   Added float values for fractions.</p>
</li>
<li>
<p><strong>min_weight_fraction_leaf : float, default=0.0</strong>
    The minimum weighted fraction of the sum total of weights (of all
    the input samples) required to be at a leaf node. Samples have
    equal weight when sample_weight is not provided.</p>
</li>
<li>
<p><strong>max_features : {'auto', 'sqrt', 'log2'}, int or float, default='auto'</strong>
    The number of features to consider when looking for the best split:</p>
<ul>
<li>If int, then consider <code>max_features</code> features at each split.</li>
<li>If float, then <code>max_features</code> is a fraction and
  <code>int(max_features * n_features)</code> features are considered at each
  split.</li>
<li>If 'auto', then <code>max_features=n_features</code>.</li>
<li>If 'sqrt', then <code>max_features=sqrt(n_features)</code>.</li>
<li>If 'log2', then <code>max_features=log2(n_features)</code>.</li>
<li>If None, then <code>max_features=n_features</code>.</li>
</ul>
</li>
<li>
<p><strong>Note: the search for a split does not stop until at least one</strong>
    valid partition of the node samples is found, even if it requires to
    effectively inspect more than <code>max_features</code> features.</p>
</li>
<li>
<p><strong>max_leaf_nodes : int, default=None</strong>
    Grow trees with <code>max_leaf_nodes</code> in best-first fashion.
    Best nodes are defined as relative reduction in impurity.
    If None then unlimited number of leaf nodes.</p>
</li>
<li>
<p><strong>min_impurity_decrease : float, default=0.0</strong>
    A node will be split if this split induces a decrease of the impurity
    greater than or equal to this value.</p>
<p>The weighted impurity decrease equation is the following::</p>
<div class="codehilite"><pre><span></span><code>N_t / N * (impurity - N_t_R / N_t * right_impurity
                    - N_t_L / N_t * left_impurity)
</code></pre></div>


<p>where <code>N</code> is the total number of samples, <code>N_t</code> is the number of
samples at the current node, <code>N_t_L</code> is the number of samples in the
left child, and <code>N_t_R</code> is the number of samples in the right child.</p>
<p><code>N</code>, <code>N_t</code>, <code>N_t_R</code> and <code>N_t_L</code> all refer to the weighted sum,
if <code>sample_weight</code> is passed.</p>
<p>.. versionadded:: 0.19</p>
</li>
<li>
<p><strong>min_impurity_split : float, default=None</strong>
    Threshold for early stopping in tree growth. A node will split
    if its impurity is above the threshold, otherwise it is a leaf.</p>
<p>.. deprecated:: 0.19
   <code>min_impurity_split</code> has been deprecated in favor of
   <code>min_impurity_decrease</code> in 0.19. The default value of
   <code>min_impurity_split</code> has changed from 1e-7 to 0 in 0.23 and it
   will be removed in 0.25. Use <code>min_impurity_decrease</code> instead.</p>
</li>
<li>
<p><strong>bootstrap : bool, default=True</strong>
    Whether bootstrap samples are used when building trees. If False, the
    whole dataset is used to build each tree.</p>
</li>
<li>
<p><strong>oob_score : bool, default=False</strong>
    whether to use out-of-bag samples to estimate
    the R^2 on unseen data.</p>
</li>
<li>
<p><strong>n_jobs : int, default=None</strong>
    The number of jobs to run in parallel. :meth:<code>fit</code>, :meth:<code>predict</code>,
    :meth:<code>decision_path</code> and :meth:<code>apply</code> are all parallelized over the
    trees. <code>None</code> means 1 unless in a :obj:<code>joblib.parallel_backend</code>
    context. <code>-1</code> means using all processors. See :term:<code>Glossary
    &lt;n_jobs&gt;</code> for more details.</p>
</li>
<li>
<p><strong>random_state : int or RandomState, default=None</strong>
    Controls both the randomness of the bootstrapping of the samples used
    when building trees (if <code>bootstrap=True</code>) and the sampling of the
    features to consider when looking for the best split at each node
    (if <code>max_features &lt; n_features</code>).</p>
</li>
<li>
<p><strong>See :term:<code>Glossary &lt;random_state&gt;</code> for details.</strong></p>
</li>
<li>
<p><strong>verbose : int, default=0</strong>
    Controls the verbosity when fitting and predicting.</p>
</li>
<li>
<p><strong>warm_start : bool, default=False</strong>
    When set to <code>True</code>, reuse the solution of the previous call to fit
    and add more estimators to the ensemble, otherwise, just fit a whole
    new forest. See :term:<code>the Glossary &lt;warm_start&gt;</code>.</p>
</li>
<li>
<p><strong>ccp_alpha : non-negative float, default=0.0</strong>
    Complexity parameter used for Minimal Cost-Complexity Pruning. The
    subtree with the largest cost complexity that is smaller than
    <code>ccp_alpha</code> will be chosen. By default, no pruning is performed. See
    :ref:<code>minimal_cost_complexity_pruning</code> for details.</p>
<p>.. versionadded:: 0.22</p>
</li>
<li>
<p><strong>max_samples : int or float, default=None</strong>
    If bootstrap is True, the number of samples to draw from X
    to train each base estimator.</p>
<ul>
<li>If None (default), then draw <code>X.shape[0]</code> samples.</li>
<li>If int, then draw <code>max_samples</code> samples.</li>
<li>If float, then draw <code>max_samples * X.shape[0]</code> samples. Thus,
  <code>max_samples</code> should be in the interval <code>(0, 1)</code>.</li>
</ul>
<p>.. versionadded:: 0.22</p>
</li>
</ul>
<h4>Attributes</h4>
<ul>
<li>
<p><strong>base_estimator_ : DecisionTreeRegressor</strong>
    The child estimator template used to create the collection of fitted
    sub-estimators.</p>
</li>
<li>
<p><strong>estimators_ : list of DecisionTreeRegressor</strong>
    The collection of fitted sub-estimators.</p>
</li>
<li>
<p><strong>feature_importances_ : ndarray of shape (n_features,)</strong>
    The impurity-based feature importances.
    The higher, the more important the feature.
    The importance of a feature is computed as the (normalized)
    total reduction of the criterion brought by that feature.  It is also
    known as the Gini importance.</p>
</li>
<li>
<p><strong>Warning: impurity-based feature importances can be misleading for</strong>
    high cardinality features (many unique values). See
    :func:<code>sklearn.inspection.permutation_importance</code> as an alternative.</p>
</li>
<li>
<p><strong>n_features_ : int</strong>
    The number of features when <code>fit</code> is performed.</p>
</li>
<li>
<p><strong>n_outputs_ : int</strong>
    The number of outputs when <code>fit</code> is performed.</p>
</li>
<li>
<p><strong>oob_score_ : float</strong>
    Score of the training dataset obtained using an out-of-bag estimate.
    This attribute exists only when <code>oob_score</code> is True.</p>
</li>
<li>
<p><strong>oob_prediction_ : ndarray of shape (n_samples,)</strong>
    Prediction computed with out-of-bag estimate on the training set.
    This attribute exists only when <code>oob_score</code> is True.</p>
</li>
</ul>
<h4>See Also</h4>
<p>DecisionTreeRegressor, ExtraTreesRegressor</p>
<h4>Notes</h4>
<p>The default values for the parameters controlling the size of the trees
(e.g. <code>max_depth</code>, <code>min_samples_leaf</code>, etc.) lead to fully grown and
unpruned trees which can potentially be very large on some data sets. To
reduce memory consumption, the complexity and size of the trees should be
controlled by setting those parameter values.</p>
<p>The features are always randomly permuted at each split. Therefore,
the best found split may vary, even with the same training data,
<code>max_features=n_features</code> and <code>bootstrap=False</code>, if the improvement
of the criterion is identical for several splits enumerated during the
search of the best split. To obtain a deterministic behaviour during
fitting, <code>random_state</code> has to be fixed.</p>
<p>The default value <code>max_features='auto'</code> uses <code>n_features</code>
rather than <code>n_features / 3</code>. The latter was originally suggested in
[1], whereas the former was more recently justified empirically in [2].</p>
<h4>References</h4>
<p>.. [1] L. Breiman, 'Random Forests', Machine Learning, 45(1), 5-32, 2001.</p>
<p>.. [2] P. Geurts, D. Ernst., and L. Wehenkel, 'Extremely randomized
       trees', Machine Learning, 63(1), 3-42, 2006.</p>
<h4>Examples</h4>
<div class="highlight"><pre><span></span><code><span class="o">&gt;&gt;&gt;</span> <span class="kn">from</span> <span class="nn">sklearn.ensemble</span> <span class="kn">import</span> <span class="n">RandomForestRegressor</span>
<span class="o">&gt;&gt;&gt;</span> <span class="kn">from</span> <span class="nn">sklearn.datasets</span> <span class="kn">import</span> <span class="n">make_regression</span>
<span class="o">&gt;&gt;&gt;</span> <span class="n">X</span><span class="p">,</span> <span class="n">y</span> <span class="o">=</span> <span class="n">make_regression</span><span class="p">(</span><span class="n">n_features</span><span class="o">=</span><span class="mi">4</span><span class="p">,</span> <span class="n">n_informative</span><span class="o">=</span><span class="mi">2</span><span class="p">,</span>
<span class="o">...</span>                        <span class="n">random_state</span><span class="o">=</span><span class="mi">0</span><span class="p">,</span> <span class="n">shuffle</span><span class="o">=</span><span class="kc">False</span><span class="p">)</span>
<span class="o">&gt;&gt;&gt;</span> <span class="n">regr</span> <span class="o">=</span> <span class="n">RandomForestRegressor</span><span class="p">(</span><span class="n">max_depth</span><span class="o">=</span><span class="mi">2</span><span class="p">,</span> <span class="n">random_state</span><span class="o">=</span><span class="mi">0</span><span class="p">)</span>
<span class="o">&gt;&gt;&gt;</span> <span class="n">regr</span><span class="o">.</span><span class="n">fit</span><span class="p">(</span><span class="n">X</span><span class="p">,</span> <span class="n">y</span><span class="p">)</span>
<span class="n">RandomForestRegressor</span><span class="p">(</span><span class="o">...</span><span class="p">)</span>
<span class="o">&gt;&gt;&gt;</span> <span class="nb">print</span><span class="p">(</span><span class="n">regr</span><span class="o">.</span><span class="n">predict</span><span class="p">([[</span><span class="mi">0</span><span class="p">,</span> <span class="mi">0</span><span class="p">,</span> <span class="mi">0</span><span class="p">,</span> <span class="mi">0</span><span class="p">]]))</span>
<span class="p">[</span><span class="o">-</span><span class="mf">8.32987858</span><span class="p">]</span>
</code></pre></div>

</details>
<h3 id="get_item_11">get_item<a class="headerlink" href="#get_item_11" title="Permanent link">&para;</a></h3>
<details class="note" open="open"><summary>method get_item</summary><div class="highlight"><pre><span></span><code><span class="k">val</span> <span class="n">get_item</span> <span class="o">:</span>
  <span class="n">index</span><span class="o">:</span><span class="nn">Py</span><span class="p">.</span><span class="nn">Object</span><span class="p">.</span><span class="n">t</span> <span class="o">-&gt;</span>
  <span class="o">[&gt;</span> <span class="n">tag</span><span class="o">]</span> <span class="nn">Obj</span><span class="p">.</span><span class="n">t</span> <span class="o">-&gt;</span>
  <span class="nn">Py</span><span class="p">.</span><span class="nn">Object</span><span class="p">.</span><span class="n">t</span>
</code></pre></div>

<p>Return the index'th estimator in the ensemble.</p>
</details>
<h3 id="iter_11">iter<a class="headerlink" href="#iter_11" title="Permanent link">&para;</a></h3>
<details class="note" open="open"><summary>method iter</summary><div class="highlight"><pre><span></span><code><span class="k">val</span> <span class="n">iter</span> <span class="o">:</span>
  <span class="o">[&gt;</span> <span class="n">tag</span><span class="o">]</span> <span class="nn">Obj</span><span class="p">.</span><span class="n">t</span> <span class="o">-&gt;</span>
  <span class="nn">Dict</span><span class="p">.</span><span class="n">t</span> <span class="nn">Seq</span><span class="p">.</span><span class="n">t</span>
</code></pre></div>

<p>Return iterator over estimators in the ensemble.</p>
</details>
<h3 id="apply_5">apply<a class="headerlink" href="#apply_5" title="Permanent link">&para;</a></h3>
<details class="note" open="open"><summary>method apply</summary><div class="highlight"><pre><span></span><code><span class="k">val</span> <span class="n">apply</span> <span class="o">:</span>
  <span class="n">x</span><span class="o">:[&gt;`</span><span class="nc">ArrayLike</span><span class="o">]</span> <span class="nn">Np</span><span class="p">.</span><span class="nn">Obj</span><span class="p">.</span><span class="n">t</span> <span class="o">-&gt;</span>
  <span class="o">[&gt;</span> <span class="n">tag</span><span class="o">]</span> <span class="nn">Obj</span><span class="p">.</span><span class="n">t</span> <span class="o">-&gt;</span>
  <span class="o">[&gt;`</span><span class="nc">ArrayLike</span><span class="o">]</span> <span class="nn">Np</span><span class="p">.</span><span class="nn">Obj</span><span class="p">.</span><span class="n">t</span>
</code></pre></div>

<p>Apply trees in the forest to X, return leaf indices.</p>
<h4>Parameters</h4>
<ul>
<li><strong>X : {array-like, sparse matrix} of shape (n_samples, n_features)</strong>
    The input samples. Internally, its dtype will be converted to
    <code>dtype=np.float32</code>. If a sparse matrix is provided, it will be
    converted into a sparse <code>csr_matrix</code>.</li>
</ul>
<h4>Returns</h4>
<ul>
<li><strong>X_leaves : ndarray of shape (n_samples, n_estimators)</strong>
    For each datapoint x in X and for each tree in the forest,
    return the index of the leaf x ends up in.</li>
</ul>
</details>
<h3 id="decision_path_3">decision_path<a class="headerlink" href="#decision_path_3" title="Permanent link">&para;</a></h3>
<details class="note" open="open"><summary>method decision_path</summary><div class="highlight"><pre><span></span><code><span class="k">val</span> <span class="n">decision_path</span> <span class="o">:</span>
  <span class="n">x</span><span class="o">:[&gt;`</span><span class="nc">ArrayLike</span><span class="o">]</span> <span class="nn">Np</span><span class="p">.</span><span class="nn">Obj</span><span class="p">.</span><span class="n">t</span> <span class="o">-&gt;</span>
  <span class="o">[&gt;</span> <span class="n">tag</span><span class="o">]</span> <span class="nn">Obj</span><span class="p">.</span><span class="n">t</span> <span class="o">-&gt;</span>
  <span class="o">([`</span><span class="nc">ArrayLike</span><span class="o">|`</span><span class="nc">Object</span><span class="o">|`</span><span class="nc">Spmatrix</span><span class="o">]</span> <span class="nn">Np</span><span class="p">.</span><span class="nn">Obj</span><span class="p">.</span><span class="n">t</span> <span class="o">*</span> <span class="o">[&gt;`</span><span class="nc">ArrayLike</span><span class="o">]</span> <span class="nn">Np</span><span class="p">.</span><span class="nn">Obj</span><span class="p">.</span><span class="n">t</span><span class="o">)</span>
</code></pre></div>

<p>Return the decision path in the forest.</p>
<p>.. versionadded:: 0.18</p>
<h4>Parameters</h4>
<ul>
<li><strong>X : {array-like, sparse matrix} of shape (n_samples, n_features)</strong>
    The input samples. Internally, its dtype will be converted to
    <code>dtype=np.float32</code>. If a sparse matrix is provided, it will be
    converted into a sparse <code>csr_matrix</code>.</li>
</ul>
<h4>Returns</h4>
<ul>
<li>
<p><strong>indicator : sparse matrix of shape (n_samples, n_nodes)</strong>
    Return a node indicator matrix where non zero elements indicates
    that the samples goes through the nodes. The matrix is of CSR
    format.</p>
</li>
<li>
<p><strong>n_nodes_ptr : ndarray of shape (n_estimators + 1,)</strong>
    The columns from indicator[n_nodes_ptr[i]:n_nodes_ptr[i+1]]
    gives the indicator value for the i-th estimator.</p>
</li>
</ul>
</details>
<h3 id="fit_10">fit<a class="headerlink" href="#fit_10" title="Permanent link">&para;</a></h3>
<details class="note" open="open"><summary>method fit</summary><div class="highlight"><pre><span></span><code><span class="k">val</span> <span class="n">fit</span> <span class="o">:</span>
  <span class="o">?</span><span class="n">sample_weight</span><span class="o">:[&gt;`</span><span class="nc">ArrayLike</span><span class="o">]</span> <span class="nn">Np</span><span class="p">.</span><span class="nn">Obj</span><span class="p">.</span><span class="n">t</span> <span class="o">-&gt;</span>
  <span class="n">x</span><span class="o">:[&gt;`</span><span class="nc">ArrayLike</span><span class="o">]</span> <span class="nn">Np</span><span class="p">.</span><span class="nn">Obj</span><span class="p">.</span><span class="n">t</span> <span class="o">-&gt;</span>
  <span class="n">y</span><span class="o">:[&gt;`</span><span class="nc">ArrayLike</span><span class="o">]</span> <span class="nn">Np</span><span class="p">.</span><span class="nn">Obj</span><span class="p">.</span><span class="n">t</span> <span class="o">-&gt;</span>
  <span class="o">[&gt;</span> <span class="n">tag</span><span class="o">]</span> <span class="nn">Obj</span><span class="p">.</span><span class="n">t</span> <span class="o">-&gt;</span>
  <span class="n">t</span>
</code></pre></div>

<p>Build a forest of trees from the training set (X, y).</p>
<h4>Parameters</h4>
<ul>
<li>
<p><strong>X : {array-like, sparse matrix} of shape (n_samples, n_features)</strong>
    The training input samples. Internally, its dtype will be converted
    to <code>dtype=np.float32</code>. If a sparse matrix is provided, it will be
    converted into a sparse <code>csc_matrix</code>.</p>
</li>
<li>
<p><strong>y : array-like of shape (n_samples,) or (n_samples, n_outputs)</strong>
    The target values (class labels in classification, real numbers in
    regression).</p>
</li>
<li>
<p><strong>sample_weight : array-like of shape (n_samples,), default=None</strong>
    Sample weights. If None, then samples are equally weighted. Splits
    that would create child nodes with net zero or negative weight are
    ignored while searching for a split in each node. In the case of
    classification, splits are also ignored if they would result in any
    single class carrying a negative weight in either child node.</p>
</li>
</ul>
<h4>Returns</h4>
<ul>
<li><strong>self : object</strong></li>
</ul>
</details>
<h3 id="get_params_11">get_params<a class="headerlink" href="#get_params_11" title="Permanent link">&para;</a></h3>
<details class="note" open="open"><summary>method get_params</summary><div class="highlight"><pre><span></span><code><span class="k">val</span> <span class="n">get_params</span> <span class="o">:</span>
  <span class="o">?</span><span class="n">deep</span><span class="o">:</span><span class="kt">bool</span> <span class="o">-&gt;</span>
  <span class="o">[&gt;</span> <span class="n">tag</span><span class="o">]</span> <span class="nn">Obj</span><span class="p">.</span><span class="n">t</span> <span class="o">-&gt;</span>
  <span class="nn">Dict</span><span class="p">.</span><span class="n">t</span>
</code></pre></div>

<p>Get parameters for this estimator.</p>
<h4>Parameters</h4>
<ul>
<li><strong>deep : bool, default=True</strong>
    If True, will return the parameters for this estimator and
    contained subobjects that are estimators.</li>
</ul>
<h4>Returns</h4>
<ul>
<li><strong>params : mapping of string to any</strong>
    Parameter names mapped to their values.</li>
</ul>
</details>
<h3 id="predict_10">predict<a class="headerlink" href="#predict_10" title="Permanent link">&para;</a></h3>
<details class="note" open="open"><summary>method predict</summary><div class="highlight"><pre><span></span><code><span class="k">val</span> <span class="n">predict</span> <span class="o">:</span>
  <span class="n">x</span><span class="o">:[&gt;`</span><span class="nc">ArrayLike</span><span class="o">]</span> <span class="nn">Np</span><span class="p">.</span><span class="nn">Obj</span><span class="p">.</span><span class="n">t</span> <span class="o">-&gt;</span>
  <span class="o">[&gt;</span> <span class="n">tag</span><span class="o">]</span> <span class="nn">Obj</span><span class="p">.</span><span class="n">t</span> <span class="o">-&gt;</span>
  <span class="o">[&gt;`</span><span class="nc">ArrayLike</span><span class="o">]</span> <span class="nn">Np</span><span class="p">.</span><span class="nn">Obj</span><span class="p">.</span><span class="n">t</span>
</code></pre></div>

<p>Predict regression target for X.</p>
<p>The predicted regression target of an input sample is computed as the
mean predicted regression targets of the trees in the forest.</p>
<h4>Parameters</h4>
<ul>
<li><strong>X : {array-like, sparse matrix} of shape (n_samples, n_features)</strong>
    The input samples. Internally, its dtype will be converted to
    <code>dtype=np.float32</code>. If a sparse matrix is provided, it will be
    converted into a sparse <code>csr_matrix</code>.</li>
</ul>
<h4>Returns</h4>
<ul>
<li><strong>y : ndarray of shape (n_samples,) or (n_samples, n_outputs)</strong>
    The predicted values.</li>
</ul>
</details>
<h3 id="score_9">score<a class="headerlink" href="#score_9" title="Permanent link">&para;</a></h3>
<details class="note" open="open"><summary>method score</summary><div class="highlight"><pre><span></span><code><span class="k">val</span> <span class="n">score</span> <span class="o">:</span>
  <span class="o">?</span><span class="n">sample_weight</span><span class="o">:[&gt;`</span><span class="nc">ArrayLike</span><span class="o">]</span> <span class="nn">Np</span><span class="p">.</span><span class="nn">Obj</span><span class="p">.</span><span class="n">t</span> <span class="o">-&gt;</span>
  <span class="n">x</span><span class="o">:[&gt;`</span><span class="nc">ArrayLike</span><span class="o">]</span> <span class="nn">Np</span><span class="p">.</span><span class="nn">Obj</span><span class="p">.</span><span class="n">t</span> <span class="o">-&gt;</span>
  <span class="n">y</span><span class="o">:[&gt;`</span><span class="nc">ArrayLike</span><span class="o">]</span> <span class="nn">Np</span><span class="p">.</span><span class="nn">Obj</span><span class="p">.</span><span class="n">t</span> <span class="o">-&gt;</span>
  <span class="o">[&gt;</span> <span class="n">tag</span><span class="o">]</span> <span class="nn">Obj</span><span class="p">.</span><span class="n">t</span> <span class="o">-&gt;</span>
  <span class="kt">float</span>
</code></pre></div>

<p>Return the coefficient of determination R^2 of the prediction.</p>
<p>The coefficient R^2 is defined as (1 - u/v), where u is the residual
sum of squares ((y_true - y_pred) <strong> 2).sum() and v is the total
sum of squares ((y_true - y_true.mean()) </strong> 2).sum().
The best possible score is 1.0 and it can be negative (because the
model can be arbitrarily worse). A constant model that always
predicts the expected value of y, disregarding the input features,
would get a R^2 score of 0.0.</p>
<h4>Parameters</h4>
<ul>
<li>
<p><strong>X : array-like of shape (n_samples, n_features)</strong>
    Test samples. For some estimators this may be a
    precomputed kernel matrix or a list of generic objects instead,
    shape = (n_samples, n_samples_fitted),
    where n_samples_fitted is the number of
    samples used in the fitting for the estimator.</p>
</li>
<li>
<p><strong>y : array-like of shape (n_samples,) or (n_samples, n_outputs)</strong>
    True values for X.</p>
</li>
<li>
<p><strong>sample_weight : array-like of shape (n_samples,), default=None</strong>
    Sample weights.</p>
</li>
</ul>
<h4>Returns</h4>
<ul>
<li><strong>score : float</strong>
    R^2 of self.predict(X) wrt. y.</li>
</ul>
<h4>Notes</h4>
<p>The R2 score used when calling <code>score</code> on a regressor uses
<code>multioutput='uniform_average'</code> from version 0.23 to keep consistent
with default value of :func:<code>~sklearn.metrics.r2_score</code>.
This influences the <code>score</code> method of all the multioutput
regressors (except for
:class:<code>~sklearn.multioutput.MultiOutputRegressor</code>).</p>
</details>
<h3 id="set_params_11">set_params<a class="headerlink" href="#set_params_11" title="Permanent link">&para;</a></h3>
<details class="note" open="open"><summary>method set_params</summary><div class="highlight"><pre><span></span><code><span class="k">val</span> <span class="n">set_params</span> <span class="o">:</span>
  <span class="o">?</span><span class="n">params</span><span class="o">:(</span><span class="kt">string</span> <span class="o">*</span> <span class="nn">Py</span><span class="p">.</span><span class="nn">Object</span><span class="p">.</span><span class="n">t</span><span class="o">)</span> <span class="kt">list</span> <span class="o">-&gt;</span>
  <span class="o">[&gt;</span> <span class="n">tag</span><span class="o">]</span> <span class="nn">Obj</span><span class="p">.</span><span class="n">t</span> <span class="o">-&gt;</span>
  <span class="n">t</span>
</code></pre></div>

<p>Set the parameters of this estimator.</p>
<p>The method works on simple estimators as well as on nested objects
(such as pipelines). The latter have parameters of the form
<code>&lt;component&gt;__&lt;parameter&gt;</code> so that it's possible to update each
component of a nested object.</p>
<h4>Parameters</h4>
<ul>
<li><strong>**params : dict</strong>
    Estimator parameters.</li>
</ul>
<h4>Returns</h4>
<ul>
<li><strong>self : object</strong>
    Estimator instance.</li>
</ul>
</details>
<h3 id="base_estimator__8">base_estimator_<a class="headerlink" href="#base_estimator__8" title="Permanent link">&para;</a></h3>
<details class="note" open="open"><summary>attribute base_estimator_</summary><div class="highlight"><pre><span></span><code><span class="k">val</span> <span class="n">base_estimator_</span> <span class="o">:</span> <span class="n">t</span> <span class="o">-&gt;</span> <span class="nn">Py</span><span class="p">.</span><span class="nn">Object</span><span class="p">.</span><span class="n">t</span>
<span class="k">val</span> <span class="n">base_estimator_opt</span> <span class="o">:</span> <span class="n">t</span> <span class="o">-&gt;</span> <span class="o">(</span><span class="nn">Py</span><span class="p">.</span><span class="nn">Object</span><span class="p">.</span><span class="n">t</span><span class="o">)</span> <span class="n">option</span>
</code></pre></div>

<p>This attribute is documented in <code>create</code> above. The first version raises Not_found
if the attribute is None. The _opt version returns an option.</p>
</details>
<h3 id="estimators__11">estimators_<a class="headerlink" href="#estimators__11" title="Permanent link">&para;</a></h3>
<details class="note" open="open"><summary>attribute estimators_</summary><div class="highlight"><pre><span></span><code><span class="k">val</span> <span class="n">estimators_</span> <span class="o">:</span> <span class="n">t</span> <span class="o">-&gt;</span> <span class="nn">Py</span><span class="p">.</span><span class="nn">Object</span><span class="p">.</span><span class="n">t</span>
<span class="k">val</span> <span class="n">estimators_opt</span> <span class="o">:</span> <span class="n">t</span> <span class="o">-&gt;</span> <span class="o">(</span><span class="nn">Py</span><span class="p">.</span><span class="nn">Object</span><span class="p">.</span><span class="n">t</span><span class="o">)</span> <span class="n">option</span>
</code></pre></div>

<p>This attribute is documented in <code>create</code> above. The first version raises Not_found
if the attribute is None. The _opt version returns an option.</p>
</details>
<h3 id="feature_importances__7">feature_importances_<a class="headerlink" href="#feature_importances__7" title="Permanent link">&para;</a></h3>
<details class="note" open="open"><summary>attribute feature_importances_</summary><div class="highlight"><pre><span></span><code><span class="k">val</span> <span class="n">feature_importances_</span> <span class="o">:</span> <span class="n">t</span> <span class="o">-&gt;</span> <span class="o">[&gt;`</span><span class="nc">ArrayLike</span><span class="o">]</span> <span class="nn">Np</span><span class="p">.</span><span class="nn">Obj</span><span class="p">.</span><span class="n">t</span>
<span class="k">val</span> <span class="n">feature_importances_opt</span> <span class="o">:</span> <span class="n">t</span> <span class="o">-&gt;</span> <span class="o">([&gt;`</span><span class="nc">ArrayLike</span><span class="o">]</span> <span class="nn">Np</span><span class="p">.</span><span class="nn">Obj</span><span class="p">.</span><span class="n">t</span><span class="o">)</span> <span class="n">option</span>
</code></pre></div>

<p>This attribute is documented in <code>create</code> above. The first version raises Not_found
if the attribute is None. The _opt version returns an option.</p>
</details>
<h3 id="warning_7">warning<a class="headerlink" href="#warning_7" title="Permanent link">&para;</a></h3>
<details class="note" open="open"><summary>attribute warning</summary><div class="highlight"><pre><span></span><code><span class="k">val</span> <span class="n">warning</span> <span class="o">:</span> <span class="n">t</span> <span class="o">-&gt;</span> <span class="nn">Py</span><span class="p">.</span><span class="nn">Object</span><span class="p">.</span><span class="n">t</span>
<span class="k">val</span> <span class="n">warning_opt</span> <span class="o">:</span> <span class="n">t</span> <span class="o">-&gt;</span> <span class="o">(</span><span class="nn">Py</span><span class="p">.</span><span class="nn">Object</span><span class="p">.</span><span class="n">t</span><span class="o">)</span> <span class="n">option</span>
</code></pre></div>

<p>This attribute is documented in <code>create</code> above. The first version raises Not_found
if the attribute is None. The _opt version returns an option.</p>
</details>
<h3 id="n_features__7">n_features_<a class="headerlink" href="#n_features__7" title="Permanent link">&para;</a></h3>
<details class="note" open="open"><summary>attribute n_features_</summary><div class="highlight"><pre><span></span><code><span class="k">val</span> <span class="n">n_features_</span> <span class="o">:</span> <span class="n">t</span> <span class="o">-&gt;</span> <span class="kt">int</span>
<span class="k">val</span> <span class="n">n_features_opt</span> <span class="o">:</span> <span class="n">t</span> <span class="o">-&gt;</span> <span class="o">(</span><span class="kt">int</span><span class="o">)</span> <span class="n">option</span>
</code></pre></div>

<p>This attribute is documented in <code>create</code> above. The first version raises Not_found
if the attribute is None. The _opt version returns an option.</p>
</details>
<h3 id="n_outputs__3">n_outputs_<a class="headerlink" href="#n_outputs__3" title="Permanent link">&para;</a></h3>
<details class="note" open="open"><summary>attribute n_outputs_</summary><div class="highlight"><pre><span></span><code><span class="k">val</span> <span class="n">n_outputs_</span> <span class="o">:</span> <span class="n">t</span> <span class="o">-&gt;</span> <span class="kt">int</span>
<span class="k">val</span> <span class="n">n_outputs_opt</span> <span class="o">:</span> <span class="n">t</span> <span class="o">-&gt;</span> <span class="o">(</span><span class="kt">int</span><span class="o">)</span> <span class="n">option</span>
</code></pre></div>

<p>This attribute is documented in <code>create</code> above. The first version raises Not_found
if the attribute is None. The _opt version returns an option.</p>
</details>
<h3 id="oob_score__5">oob_score_<a class="headerlink" href="#oob_score__5" title="Permanent link">&para;</a></h3>
<details class="note" open="open"><summary>attribute oob_score_</summary><div class="highlight"><pre><span></span><code><span class="k">val</span> <span class="n">oob_score_</span> <span class="o">:</span> <span class="n">t</span> <span class="o">-&gt;</span> <span class="kt">float</span>
<span class="k">val</span> <span class="n">oob_score_opt</span> <span class="o">:</span> <span class="n">t</span> <span class="o">-&gt;</span> <span class="o">(</span><span class="kt">float</span><span class="o">)</span> <span class="n">option</span>
</code></pre></div>

<p>This attribute is documented in <code>create</code> above. The first version raises Not_found
if the attribute is None. The _opt version returns an option.</p>
</details>
<h3 id="oob_prediction__2">oob_prediction_<a class="headerlink" href="#oob_prediction__2" title="Permanent link">&para;</a></h3>
<details class="note" open="open"><summary>attribute oob_prediction_</summary><div class="highlight"><pre><span></span><code><span class="k">val</span> <span class="n">oob_prediction_</span> <span class="o">:</span> <span class="n">t</span> <span class="o">-&gt;</span> <span class="o">[&gt;`</span><span class="nc">ArrayLike</span><span class="o">]</span> <span class="nn">Np</span><span class="p">.</span><span class="nn">Obj</span><span class="p">.</span><span class="n">t</span>
<span class="k">val</span> <span class="n">oob_prediction_opt</span> <span class="o">:</span> <span class="n">t</span> <span class="o">-&gt;</span> <span class="o">([&gt;`</span><span class="nc">ArrayLike</span><span class="o">]</span> <span class="nn">Np</span><span class="p">.</span><span class="nn">Obj</span><span class="p">.</span><span class="n">t</span><span class="o">)</span> <span class="n">option</span>
</code></pre></div>

<p>This attribute is documented in <code>create</code> above. The first version raises Not_found
if the attribute is None. The _opt version returns an option.</p>
</details>
<h3 id="to_string_11">to_string<a class="headerlink" href="#to_string_11" title="Permanent link">&para;</a></h3>
<details class="note" open="open"><summary>method to_string</summary><div class="highlight"><pre><span></span><code><span class="k">val</span> <span class="n">to_string</span><span class="o">:</span> <span class="n">t</span> <span class="o">-&gt;</span> <span class="kt">string</span>
</code></pre></div>

<p>Print the object to a human-readable representation.</p>
</details>
<h3 id="show_11">show<a class="headerlink" href="#show_11" title="Permanent link">&para;</a></h3>
<details class="note" open="open"><summary>method show</summary><div class="highlight"><pre><span></span><code><span class="k">val</span> <span class="n">show</span><span class="o">:</span> <span class="n">t</span> <span class="o">-&gt;</span> <span class="kt">string</span>
</code></pre></div>

<p>Print the object to a human-readable representation.</p>
</details>
<h3 id="pp_11">pp<a class="headerlink" href="#pp_11" title="Permanent link">&para;</a></h3>
<details class="note" open="open"><summary>method pp</summary><div class="highlight"><pre><span></span><code><span class="k">val</span> <span class="n">pp</span><span class="o">:</span> <span class="nn">Format</span><span class="p">.</span><span class="n">formatter</span> <span class="o">-&gt;</span> <span class="n">t</span> <span class="o">-&gt;</span> <span class="kt">unit</span>
</code></pre></div>

<p>Pretty-print the object to a formatter.</p>
</details>
<h2 id="randomtreesembedding">RandomTreesEmbedding<a class="headerlink" href="#randomtreesembedding" title="Permanent link">&para;</a></h2>
<p>Module <code>Sklearn.​Ensemble.​RandomTreesEmbedding</code> wraps Python class <a href="https://scikit-learn.org/stable/modules/generated/sklearn.ensemble.RandomTreesEmbedding.html"><code>sklearn.ensemble.RandomTreesEmbedding</code></a>.</p>
<div class="highlight"><pre><span></span><code><span class="k">type</span> <span class="n">t</span>
</code></pre></div>

<h3 id="create_11">create<a class="headerlink" href="#create_11" title="Permanent link">&para;</a></h3>
<details class="note" open="open"><summary>constructor and attributes create</summary><div class="highlight"><pre><span></span><code><span class="k">val</span> <span class="n">create</span> <span class="o">:</span>
  <span class="o">?</span><span class="n">n_estimators</span><span class="o">:</span><span class="kt">int</span> <span class="o">-&gt;</span>
  <span class="o">?</span><span class="n">max_depth</span><span class="o">:</span><span class="kt">int</span> <span class="o">-&gt;</span>
  <span class="o">?</span><span class="n">min_samples_split</span><span class="o">:[`</span><span class="nc">F</span> <span class="k">of</span> <span class="kt">float</span> <span class="o">|</span> <span class="o">`</span><span class="nc">I</span> <span class="k">of</span> <span class="kt">int</span><span class="o">]</span> <span class="o">-&gt;</span>
  <span class="o">?</span><span class="n">min_samples_leaf</span><span class="o">:[`</span><span class="nc">F</span> <span class="k">of</span> <span class="kt">float</span> <span class="o">|</span> <span class="o">`</span><span class="nc">I</span> <span class="k">of</span> <span class="kt">int</span><span class="o">]</span> <span class="o">-&gt;</span>
  <span class="o">?</span><span class="n">min_weight_fraction_leaf</span><span class="o">:</span><span class="kt">float</span> <span class="o">-&gt;</span>
  <span class="o">?</span><span class="n">max_leaf_nodes</span><span class="o">:</span><span class="kt">int</span> <span class="o">-&gt;</span>
  <span class="o">?</span><span class="n">min_impurity_decrease</span><span class="o">:</span><span class="kt">float</span> <span class="o">-&gt;</span>
  <span class="o">?</span><span class="n">min_impurity_split</span><span class="o">:</span><span class="kt">float</span> <span class="o">-&gt;</span>
  <span class="o">?</span><span class="n">sparse_output</span><span class="o">:</span><span class="kt">bool</span> <span class="o">-&gt;</span>
  <span class="o">?</span><span class="n">n_jobs</span><span class="o">:</span><span class="kt">int</span> <span class="o">-&gt;</span>
  <span class="o">?</span><span class="n">random_state</span><span class="o">:</span><span class="kt">int</span> <span class="o">-&gt;</span>
  <span class="o">?</span><span class="n">verbose</span><span class="o">:</span><span class="kt">int</span> <span class="o">-&gt;</span>
  <span class="o">?</span><span class="n">warm_start</span><span class="o">:</span><span class="kt">bool</span> <span class="o">-&gt;</span>
  <span class="kt">unit</span> <span class="o">-&gt;</span>
  <span class="n">t</span>
</code></pre></div>

<p>An ensemble of totally random trees.</p>
<p>An unsupervised transformation of a dataset to a high-dimensional
sparse representation. A datapoint is coded according to which leaf of
each tree it is sorted into. Using a one-hot encoding of the leaves,
this leads to a binary coding with as many ones as there are trees in
the forest.</p>
<p>The dimensionality of the resulting representation is
<code>n_out &lt;= n_estimators * max_leaf_nodes</code>. If <code>max_leaf_nodes == None</code>,
the number of leaf nodes is at most <code>n_estimators * 2 ** max_depth</code>.</p>
<p>Read more in the :ref:<code>User Guide &lt;random_trees_embedding&gt;</code>.</p>
<h4>Parameters</h4>
<ul>
<li>
<p><strong>n_estimators : int, default=100</strong>
    Number of trees in the forest.</p>
<p>.. versionchanged:: 0.22
   The default value of <code>n_estimators</code> changed from 10 to 100
   in 0.22.</p>
</li>
<li>
<p><strong>max_depth : int, default=5</strong>
    The maximum depth of each tree. If None, then nodes are expanded until
    all leaves are pure or until all leaves contain less than
    min_samples_split samples.</p>
</li>
<li>
<p><strong>min_samples_split : int or float, default=2</strong>
    The minimum number of samples required to split an internal node:</p>
<ul>
<li>If int, then consider <code>min_samples_split</code> as the minimum number.</li>
<li>If float, then <code>min_samples_split</code> is a fraction and
  <code>ceil(min_samples_split * n_samples)</code> is the minimum
  number of samples for each split.</li>
</ul>
<p>.. versionchanged:: 0.18
   Added float values for fractions.</p>
</li>
<li>
<p><strong>min_samples_leaf : int or float, default=1</strong>
    The minimum number of samples required to be at a leaf node.
    A split point at any depth will only be considered if it leaves at
    least <code>min_samples_leaf</code> training samples in each of the left and
    right branches.  This may have the effect of smoothing the model,
    especially in regression.</p>
<ul>
<li>If int, then consider <code>min_samples_leaf</code> as the minimum number.</li>
<li>If float, then <code>min_samples_leaf</code> is a fraction and
  <code>ceil(min_samples_leaf * n_samples)</code> is the minimum
  number of samples for each node.</li>
</ul>
<p>.. versionchanged:: 0.18
   Added float values for fractions.</p>
</li>
<li>
<p><strong>min_weight_fraction_leaf : float, default=0.0</strong>
    The minimum weighted fraction of the sum total of weights (of all
    the input samples) required to be at a leaf node. Samples have
    equal weight when sample_weight is not provided.</p>
</li>
<li>
<p><strong>max_leaf_nodes : int, default=None</strong>
    Grow trees with <code>max_leaf_nodes</code> in best-first fashion.
    Best nodes are defined as relative reduction in impurity.
    If None then unlimited number of leaf nodes.</p>
</li>
<li>
<p><strong>min_impurity_decrease : float, default=0.0</strong>
    A node will be split if this split induces a decrease of the impurity
    greater than or equal to this value.</p>
<p>The weighted impurity decrease equation is the following::</p>
<div class="codehilite"><pre><span></span><code>N_t / N * (impurity - N_t_R / N_t * right_impurity
                    - N_t_L / N_t * left_impurity)
</code></pre></div>


<p>where <code>N</code> is the total number of samples, <code>N_t</code> is the number of
samples at the current node, <code>N_t_L</code> is the number of samples in the
left child, and <code>N_t_R</code> is the number of samples in the right child.</p>
<p><code>N</code>, <code>N_t</code>, <code>N_t_R</code> and <code>N_t_L</code> all refer to the weighted sum,
if <code>sample_weight</code> is passed.</p>
<p>.. versionadded:: 0.19</p>
</li>
<li>
<p><strong>min_impurity_split : float, default=None</strong>
    Threshold for early stopping in tree growth. A node will split
    if its impurity is above the threshold, otherwise it is a leaf.</p>
<p>.. deprecated:: 0.19
   <code>min_impurity_split</code> has been deprecated in favor of
   <code>min_impurity_decrease</code> in 0.19. The default value of
   <code>min_impurity_split</code> has changed from 1e-7 to 0 in 0.23 and it
   will be removed in 0.25. Use <code>min_impurity_decrease</code> instead.</p>
</li>
<li>
<p><strong>sparse_output : bool, default=True</strong>
    Whether or not to return a sparse CSR matrix, as default behavior,
    or to return a dense array compatible with dense pipeline operators.</p>
</li>
<li>
<p><strong>n_jobs : int, default=None</strong>
    The number of jobs to run in parallel. :meth:<code>fit</code>, :meth:<code>transform</code>,
    :meth:<code>decision_path</code> and :meth:<code>apply</code> are all parallelized over the
    trees. <code>None</code> means 1 unless in a :obj:<code>joblib.parallel_backend</code>
    context. <code>-1</code> means using all processors. See :term:<code>Glossary
    &lt;n_jobs&gt;</code> for more details.</p>
</li>
<li>
<p><strong>random_state : int or RandomState, default=None</strong>
    Controls the generation of the random <code>y</code> used to fit the trees
    and the draw of the splits for each feature at the trees' nodes.</p>
</li>
<li>
<p><strong>See :term:<code>Glossary &lt;random_state&gt;</code> for details.</strong></p>
</li>
<li>
<p><strong>verbose : int, default=0</strong>
    Controls the verbosity when fitting and predicting.</p>
</li>
<li>
<p><strong>warm_start : bool, default=False</strong>
    When set to <code>True</code>, reuse the solution of the previous call to fit
    and add more estimators to the ensemble, otherwise, just fit a whole
    new forest. See :term:<code>the Glossary &lt;warm_start&gt;</code>.</p>
</li>
</ul>
<h4>Attributes</h4>
<ul>
<li><strong>estimators_ : list of DecisionTreeClassifier</strong>
    The collection of fitted sub-estimators.</li>
</ul>
<h4>References</h4>
<p>.. [1] P. Geurts, D. Ernst., and L. Wehenkel, 'Extremely randomized trees',
       Machine Learning, 63(1), 3-42, 2006.
.. [2] Moosmann, F. and Triggs, B. and Jurie, F.  'Fast discriminative
       visual codebooks using randomized clustering forests'
       NIPS 2007</p>
<h4>Examples</h4>
<div class="highlight"><pre><span></span><code><span class="o">&gt;&gt;&gt;</span> <span class="kn">from</span> <span class="nn">sklearn.ensemble</span> <span class="kn">import</span> <span class="n">RandomTreesEmbedding</span>
<span class="o">&gt;&gt;&gt;</span> <span class="n">X</span> <span class="o">=</span> <span class="p">[[</span><span class="mi">0</span><span class="p">,</span><span class="mi">0</span><span class="p">],</span> <span class="p">[</span><span class="mi">1</span><span class="p">,</span><span class="mi">0</span><span class="p">],</span> <span class="p">[</span><span class="mi">0</span><span class="p">,</span><span class="mi">1</span><span class="p">],</span> <span class="p">[</span><span class="o">-</span><span class="mi">1</span><span class="p">,</span><span class="mi">0</span><span class="p">],</span> <span class="p">[</span><span class="mi">0</span><span class="p">,</span><span class="o">-</span><span class="mi">1</span><span class="p">]]</span>
<span class="o">&gt;&gt;&gt;</span> <span class="n">random_trees</span> <span class="o">=</span> <span class="n">RandomTreesEmbedding</span><span class="p">(</span>
<span class="o">...</span>    <span class="n">n_estimators</span><span class="o">=</span><span class="mi">5</span><span class="p">,</span> <span class="n">random_state</span><span class="o">=</span><span class="mi">0</span><span class="p">,</span> <span class="n">max_depth</span><span class="o">=</span><span class="mi">1</span><span class="p">)</span><span class="o">.</span><span class="n">fit</span><span class="p">(</span><span class="n">X</span><span class="p">)</span>
<span class="o">&gt;&gt;&gt;</span> <span class="n">X_sparse_embedding</span> <span class="o">=</span> <span class="n">random_trees</span><span class="o">.</span><span class="n">transform</span><span class="p">(</span><span class="n">X</span><span class="p">)</span>
<span class="o">&gt;&gt;&gt;</span> <span class="n">X_sparse_embedding</span><span class="o">.</span><span class="n">toarray</span><span class="p">()</span>
<span class="n">array</span><span class="p">([[</span><span class="mf">0.</span><span class="p">,</span> <span class="mf">1.</span><span class="p">,</span> <span class="mf">1.</span><span class="p">,</span> <span class="mf">0.</span><span class="p">,</span> <span class="mf">1.</span><span class="p">,</span> <span class="mf">0.</span><span class="p">,</span> <span class="mf">0.</span><span class="p">,</span> <span class="mf">1.</span><span class="p">,</span> <span class="mf">1.</span><span class="p">,</span> <span class="mf">0.</span><span class="p">],</span>
       <span class="p">[</span><span class="mf">0.</span><span class="p">,</span> <span class="mf">1.</span><span class="p">,</span> <span class="mf">1.</span><span class="p">,</span> <span class="mf">0.</span><span class="p">,</span> <span class="mf">1.</span><span class="p">,</span> <span class="mf">0.</span><span class="p">,</span> <span class="mf">0.</span><span class="p">,</span> <span class="mf">1.</span><span class="p">,</span> <span class="mf">1.</span><span class="p">,</span> <span class="mf">0.</span><span class="p">],</span>
       <span class="p">[</span><span class="mf">0.</span><span class="p">,</span> <span class="mf">1.</span><span class="p">,</span> <span class="mf">0.</span><span class="p">,</span> <span class="mf">1.</span><span class="p">,</span> <span class="mf">0.</span><span class="p">,</span> <span class="mf">1.</span><span class="p">,</span> <span class="mf">0.</span><span class="p">,</span> <span class="mf">1.</span><span class="p">,</span> <span class="mf">0.</span><span class="p">,</span> <span class="mf">1.</span><span class="p">],</span>
       <span class="p">[</span><span class="mf">1.</span><span class="p">,</span> <span class="mf">0.</span><span class="p">,</span> <span class="mf">1.</span><span class="p">,</span> <span class="mf">0.</span><span class="p">,</span> <span class="mf">1.</span><span class="p">,</span> <span class="mf">0.</span><span class="p">,</span> <span class="mf">1.</span><span class="p">,</span> <span class="mf">0.</span><span class="p">,</span> <span class="mf">1.</span><span class="p">,</span> <span class="mf">0.</span><span class="p">],</span>
       <span class="p">[</span><span class="mf">0.</span><span class="p">,</span> <span class="mf">1.</span><span class="p">,</span> <span class="mf">1.</span><span class="p">,</span> <span class="mf">0.</span><span class="p">,</span> <span class="mf">1.</span><span class="p">,</span> <span class="mf">0.</span><span class="p">,</span> <span class="mf">0.</span><span class="p">,</span> <span class="mf">1.</span><span class="p">,</span> <span class="mf">1.</span><span class="p">,</span> <span class="mf">0.</span><span class="p">]])</span>
</code></pre></div>

</details>
<h3 id="get_item_12">get_item<a class="headerlink" href="#get_item_12" title="Permanent link">&para;</a></h3>
<details class="note" open="open"><summary>method get_item</summary><div class="highlight"><pre><span></span><code><span class="k">val</span> <span class="n">get_item</span> <span class="o">:</span>
  <span class="n">index</span><span class="o">:</span><span class="nn">Py</span><span class="p">.</span><span class="nn">Object</span><span class="p">.</span><span class="n">t</span> <span class="o">-&gt;</span>
  <span class="o">[&gt;</span> <span class="n">tag</span><span class="o">]</span> <span class="nn">Obj</span><span class="p">.</span><span class="n">t</span> <span class="o">-&gt;</span>
  <span class="nn">Py</span><span class="p">.</span><span class="nn">Object</span><span class="p">.</span><span class="n">t</span>
</code></pre></div>

<p>Return the index'th estimator in the ensemble.</p>
</details>
<h3 id="iter_12">iter<a class="headerlink" href="#iter_12" title="Permanent link">&para;</a></h3>
<details class="note" open="open"><summary>method iter</summary><div class="highlight"><pre><span></span><code><span class="k">val</span> <span class="n">iter</span> <span class="o">:</span>
  <span class="o">[&gt;</span> <span class="n">tag</span><span class="o">]</span> <span class="nn">Obj</span><span class="p">.</span><span class="n">t</span> <span class="o">-&gt;</span>
  <span class="nn">Dict</span><span class="p">.</span><span class="n">t</span> <span class="nn">Seq</span><span class="p">.</span><span class="n">t</span>
</code></pre></div>

<p>Return iterator over estimators in the ensemble.</p>
</details>
<h3 id="apply_6">apply<a class="headerlink" href="#apply_6" title="Permanent link">&para;</a></h3>
<details class="note" open="open"><summary>method apply</summary><div class="highlight"><pre><span></span><code><span class="k">val</span> <span class="n">apply</span> <span class="o">:</span>
  <span class="n">x</span><span class="o">:[&gt;`</span><span class="nc">ArrayLike</span><span class="o">]</span> <span class="nn">Np</span><span class="p">.</span><span class="nn">Obj</span><span class="p">.</span><span class="n">t</span> <span class="o">-&gt;</span>
  <span class="o">[&gt;</span> <span class="n">tag</span><span class="o">]</span> <span class="nn">Obj</span><span class="p">.</span><span class="n">t</span> <span class="o">-&gt;</span>
  <span class="o">[&gt;`</span><span class="nc">ArrayLike</span><span class="o">]</span> <span class="nn">Np</span><span class="p">.</span><span class="nn">Obj</span><span class="p">.</span><span class="n">t</span>
</code></pre></div>

<p>Apply trees in the forest to X, return leaf indices.</p>
<h4>Parameters</h4>
<ul>
<li><strong>X : {array-like, sparse matrix} of shape (n_samples, n_features)</strong>
    The input samples. Internally, its dtype will be converted to
    <code>dtype=np.float32</code>. If a sparse matrix is provided, it will be
    converted into a sparse <code>csr_matrix</code>.</li>
</ul>
<h4>Returns</h4>
<ul>
<li><strong>X_leaves : ndarray of shape (n_samples, n_estimators)</strong>
    For each datapoint x in X and for each tree in the forest,
    return the index of the leaf x ends up in.</li>
</ul>
</details>
<h3 id="decision_path_4">decision_path<a class="headerlink" href="#decision_path_4" title="Permanent link">&para;</a></h3>
<details class="note" open="open"><summary>method decision_path</summary><div class="highlight"><pre><span></span><code><span class="k">val</span> <span class="n">decision_path</span> <span class="o">:</span>
  <span class="n">x</span><span class="o">:[&gt;`</span><span class="nc">ArrayLike</span><span class="o">]</span> <span class="nn">Np</span><span class="p">.</span><span class="nn">Obj</span><span class="p">.</span><span class="n">t</span> <span class="o">-&gt;</span>
  <span class="o">[&gt;</span> <span class="n">tag</span><span class="o">]</span> <span class="nn">Obj</span><span class="p">.</span><span class="n">t</span> <span class="o">-&gt;</span>
  <span class="o">([`</span><span class="nc">ArrayLike</span><span class="o">|`</span><span class="nc">Object</span><span class="o">|`</span><span class="nc">Spmatrix</span><span class="o">]</span> <span class="nn">Np</span><span class="p">.</span><span class="nn">Obj</span><span class="p">.</span><span class="n">t</span> <span class="o">*</span> <span class="o">[&gt;`</span><span class="nc">ArrayLike</span><span class="o">]</span> <span class="nn">Np</span><span class="p">.</span><span class="nn">Obj</span><span class="p">.</span><span class="n">t</span><span class="o">)</span>
</code></pre></div>

<p>Return the decision path in the forest.</p>
<p>.. versionadded:: 0.18</p>
<h4>Parameters</h4>
<ul>
<li><strong>X : {array-like, sparse matrix} of shape (n_samples, n_features)</strong>
    The input samples. Internally, its dtype will be converted to
    <code>dtype=np.float32</code>. If a sparse matrix is provided, it will be
    converted into a sparse <code>csr_matrix</code>.</li>
</ul>
<h4>Returns</h4>
<ul>
<li>
<p><strong>indicator : sparse matrix of shape (n_samples, n_nodes)</strong>
    Return a node indicator matrix where non zero elements indicates
    that the samples goes through the nodes. The matrix is of CSR
    format.</p>
</li>
<li>
<p><strong>n_nodes_ptr : ndarray of shape (n_estimators + 1,)</strong>
    The columns from indicator[n_nodes_ptr[i]:n_nodes_ptr[i+1]]
    gives the indicator value for the i-th estimator.</p>
</li>
</ul>
</details>
<h3 id="fit_11">fit<a class="headerlink" href="#fit_11" title="Permanent link">&para;</a></h3>
<details class="note" open="open"><summary>method fit</summary><div class="highlight"><pre><span></span><code><span class="k">val</span> <span class="n">fit</span> <span class="o">:</span>
  <span class="o">?</span><span class="n">y</span><span class="o">:</span><span class="nn">Py</span><span class="p">.</span><span class="nn">Object</span><span class="p">.</span><span class="n">t</span> <span class="o">-&gt;</span>
  <span class="o">?</span><span class="n">sample_weight</span><span class="o">:[&gt;`</span><span class="nc">ArrayLike</span><span class="o">]</span> <span class="nn">Np</span><span class="p">.</span><span class="nn">Obj</span><span class="p">.</span><span class="n">t</span> <span class="o">-&gt;</span>
  <span class="n">x</span><span class="o">:[&gt;`</span><span class="nc">ArrayLike</span><span class="o">]</span> <span class="nn">Np</span><span class="p">.</span><span class="nn">Obj</span><span class="p">.</span><span class="n">t</span> <span class="o">-&gt;</span>
  <span class="o">[&gt;</span> <span class="n">tag</span><span class="o">]</span> <span class="nn">Obj</span><span class="p">.</span><span class="n">t</span> <span class="o">-&gt;</span>
  <span class="n">t</span>
</code></pre></div>

<p>Fit estimator.</p>
<h4>Parameters</h4>
<ul>
<li>
<p><strong>X : {array-like, sparse matrix} of shape (n_samples, n_features)</strong>
    The input samples. Use <code>dtype=np.float32</code> for maximum
    efficiency. Sparse matrices are also supported, use sparse
    <code>csc_matrix</code> for maximum efficiency.</p>
</li>
<li>
<p><strong>y : Ignored</strong>
    Not used, present for API consistency by convention.</p>
</li>
<li>
<p><strong>sample_weight : array-like of shape (n_samples,), default=None</strong>
    Sample weights. If None, then samples are equally weighted. Splits
    that would create child nodes with net zero or negative weight are
    ignored while searching for a split in each node. In the case of
    classification, splits are also ignored if they would result in any
    single class carrying a negative weight in either child node.</p>
</li>
</ul>
<h4>Returns</h4>
<ul>
<li><strong>self : object</strong></li>
</ul>
</details>
<h3 id="fit_transform">fit_transform<a class="headerlink" href="#fit_transform" title="Permanent link">&para;</a></h3>
<details class="note" open="open"><summary>method fit_transform</summary><div class="highlight"><pre><span></span><code><span class="k">val</span> <span class="n">fit_transform</span> <span class="o">:</span>
  <span class="o">?</span><span class="n">y</span><span class="o">:</span><span class="nn">Py</span><span class="p">.</span><span class="nn">Object</span><span class="p">.</span><span class="n">t</span> <span class="o">-&gt;</span>
  <span class="o">?</span><span class="n">sample_weight</span><span class="o">:[&gt;`</span><span class="nc">ArrayLike</span><span class="o">]</span> <span class="nn">Np</span><span class="p">.</span><span class="nn">Obj</span><span class="p">.</span><span class="n">t</span> <span class="o">-&gt;</span>
  <span class="n">x</span><span class="o">:[&gt;`</span><span class="nc">ArrayLike</span><span class="o">]</span> <span class="nn">Np</span><span class="p">.</span><span class="nn">Obj</span><span class="p">.</span><span class="n">t</span> <span class="o">-&gt;</span>
  <span class="o">[&gt;</span> <span class="n">tag</span><span class="o">]</span> <span class="nn">Obj</span><span class="p">.</span><span class="n">t</span> <span class="o">-&gt;</span>
  <span class="o">[&gt;`</span><span class="nc">ArrayLike</span><span class="o">]</span> <span class="nn">Np</span><span class="p">.</span><span class="nn">Obj</span><span class="p">.</span><span class="n">t</span>
</code></pre></div>

<p>Fit estimator and transform dataset.</p>
<h4>Parameters</h4>
<ul>
<li>
<p><strong>X : {array-like, sparse matrix} of shape (n_samples, n_features)</strong>
    Input data used to build forests. Use <code>dtype=np.float32</code> for
    maximum efficiency.</p>
</li>
<li>
<p><strong>y : Ignored</strong>
    Not used, present for API consistency by convention.</p>
</li>
<li>
<p><strong>sample_weight : array-like of shape (n_samples,), default=None</strong>
    Sample weights. If None, then samples are equally weighted. Splits
    that would create child nodes with net zero or negative weight are
    ignored while searching for a split in each node. In the case of
    classification, splits are also ignored if they would result in any
    single class carrying a negative weight in either child node.</p>
</li>
</ul>
<h4>Returns</h4>
<ul>
<li><strong>X_transformed : sparse matrix of shape (n_samples, n_out)</strong>
    Transformed dataset.</li>
</ul>
</details>
<h3 id="get_params_12">get_params<a class="headerlink" href="#get_params_12" title="Permanent link">&para;</a></h3>
<details class="note" open="open"><summary>method get_params</summary><div class="highlight"><pre><span></span><code><span class="k">val</span> <span class="n">get_params</span> <span class="o">:</span>
  <span class="o">?</span><span class="n">deep</span><span class="o">:</span><span class="kt">bool</span> <span class="o">-&gt;</span>
  <span class="o">[&gt;</span> <span class="n">tag</span><span class="o">]</span> <span class="nn">Obj</span><span class="p">.</span><span class="n">t</span> <span class="o">-&gt;</span>
  <span class="nn">Dict</span><span class="p">.</span><span class="n">t</span>
</code></pre></div>

<p>Get parameters for this estimator.</p>
<h4>Parameters</h4>
<ul>
<li><strong>deep : bool, default=True</strong>
    If True, will return the parameters for this estimator and
    contained subobjects that are estimators.</li>
</ul>
<h4>Returns</h4>
<ul>
<li><strong>params : mapping of string to any</strong>
    Parameter names mapped to their values.</li>
</ul>
</details>
<h3 id="set_params_12">set_params<a class="headerlink" href="#set_params_12" title="Permanent link">&para;</a></h3>
<details class="note" open="open"><summary>method set_params</summary><div class="highlight"><pre><span></span><code><span class="k">val</span> <span class="n">set_params</span> <span class="o">:</span>
  <span class="o">?</span><span class="n">params</span><span class="o">:(</span><span class="kt">string</span> <span class="o">*</span> <span class="nn">Py</span><span class="p">.</span><span class="nn">Object</span><span class="p">.</span><span class="n">t</span><span class="o">)</span> <span class="kt">list</span> <span class="o">-&gt;</span>
  <span class="o">[&gt;</span> <span class="n">tag</span><span class="o">]</span> <span class="nn">Obj</span><span class="p">.</span><span class="n">t</span> <span class="o">-&gt;</span>
  <span class="n">t</span>
</code></pre></div>

<p>Set the parameters of this estimator.</p>
<p>The method works on simple estimators as well as on nested objects
(such as pipelines). The latter have parameters of the form
<code>&lt;component&gt;__&lt;parameter&gt;</code> so that it's possible to update each
component of a nested object.</p>
<h4>Parameters</h4>
<ul>
<li><strong>**params : dict</strong>
    Estimator parameters.</li>
</ul>
<h4>Returns</h4>
<ul>
<li><strong>self : object</strong>
    Estimator instance.</li>
</ul>
</details>
<h3 id="transform">transform<a class="headerlink" href="#transform" title="Permanent link">&para;</a></h3>
<details class="note" open="open"><summary>method transform</summary><div class="highlight"><pre><span></span><code><span class="k">val</span> <span class="n">transform</span> <span class="o">:</span>
  <span class="n">x</span><span class="o">:[&gt;`</span><span class="nc">ArrayLike</span><span class="o">]</span> <span class="nn">Np</span><span class="p">.</span><span class="nn">Obj</span><span class="p">.</span><span class="n">t</span> <span class="o">-&gt;</span>
  <span class="o">[&gt;</span> <span class="n">tag</span><span class="o">]</span> <span class="nn">Obj</span><span class="p">.</span><span class="n">t</span> <span class="o">-&gt;</span>
  <span class="o">[&gt;`</span><span class="nc">ArrayLike</span><span class="o">]</span> <span class="nn">Np</span><span class="p">.</span><span class="nn">Obj</span><span class="p">.</span><span class="n">t</span>
</code></pre></div>

<p>Transform dataset.</p>
<h4>Parameters</h4>
<ul>
<li><strong>X : {array-like, sparse matrix} of shape (n_samples, n_features)</strong>
    Input data to be transformed. Use <code>dtype=np.float32</code> for maximum
    efficiency. Sparse matrices are also supported, use sparse
    <code>csr_matrix</code> for maximum efficiency.</li>
</ul>
<h4>Returns</h4>
<ul>
<li><strong>X_transformed : sparse matrix of shape (n_samples, n_out)</strong>
    Transformed dataset.</li>
</ul>
</details>
<h3 id="estimators__12">estimators_<a class="headerlink" href="#estimators__12" title="Permanent link">&para;</a></h3>
<details class="note" open="open"><summary>attribute estimators_</summary><div class="highlight"><pre><span></span><code><span class="k">val</span> <span class="n">estimators_</span> <span class="o">:</span> <span class="n">t</span> <span class="o">-&gt;</span> <span class="nn">Py</span><span class="p">.</span><span class="nn">Object</span><span class="p">.</span><span class="n">t</span>
<span class="k">val</span> <span class="n">estimators_opt</span> <span class="o">:</span> <span class="n">t</span> <span class="o">-&gt;</span> <span class="o">(</span><span class="nn">Py</span><span class="p">.</span><span class="nn">Object</span><span class="p">.</span><span class="n">t</span><span class="o">)</span> <span class="n">option</span>
</code></pre></div>

<p>This attribute is documented in <code>create</code> above. The first version raises Not_found
if the attribute is None. The _opt version returns an option.</p>
</details>
<h3 id="to_string_12">to_string<a class="headerlink" href="#to_string_12" title="Permanent link">&para;</a></h3>
<details class="note" open="open"><summary>method to_string</summary><div class="highlight"><pre><span></span><code><span class="k">val</span> <span class="n">to_string</span><span class="o">:</span> <span class="n">t</span> <span class="o">-&gt;</span> <span class="kt">string</span>
</code></pre></div>

<p>Print the object to a human-readable representation.</p>
</details>
<h3 id="show_12">show<a class="headerlink" href="#show_12" title="Permanent link">&para;</a></h3>
<details class="note" open="open"><summary>method show</summary><div class="highlight"><pre><span></span><code><span class="k">val</span> <span class="n">show</span><span class="o">:</span> <span class="n">t</span> <span class="o">-&gt;</span> <span class="kt">string</span>
</code></pre></div>

<p>Print the object to a human-readable representation.</p>
</details>
<h3 id="pp_12">pp<a class="headerlink" href="#pp_12" title="Permanent link">&para;</a></h3>
<details class="note" open="open"><summary>method pp</summary><div class="highlight"><pre><span></span><code><span class="k">val</span> <span class="n">pp</span><span class="o">:</span> <span class="nn">Format</span><span class="p">.</span><span class="n">formatter</span> <span class="o">-&gt;</span> <span class="n">t</span> <span class="o">-&gt;</span> <span class="kt">unit</span>
</code></pre></div>

<p>Pretty-print the object to a formatter.</p>
</details>
<h2 id="stackingclassifier">StackingClassifier<a class="headerlink" href="#stackingclassifier" title="Permanent link">&para;</a></h2>
<p>Module <code>Sklearn.​Ensemble.​StackingClassifier</code> wraps Python class <a href="https://scikit-learn.org/stable/modules/generated/sklearn.ensemble.StackingClassifier.html"><code>sklearn.ensemble.StackingClassifier</code></a>.</p>
<div class="highlight"><pre><span></span><code><span class="k">type</span> <span class="n">t</span>
</code></pre></div>

<h3 id="create_12">create<a class="headerlink" href="#create_12" title="Permanent link">&para;</a></h3>
<details class="note" open="open"><summary>constructor and attributes create</summary><div class="highlight"><pre><span></span><code><span class="k">val</span> <span class="n">create</span> <span class="o">:</span>
  <span class="o">?</span><span class="n">final_estimator</span><span class="o">:[&gt;`</span><span class="nc">BaseEstimator</span><span class="o">]</span> <span class="nn">Np</span><span class="p">.</span><span class="nn">Obj</span><span class="p">.</span><span class="n">t</span> <span class="o">-&gt;</span>
  <span class="o">?</span><span class="n">cv</span><span class="o">:[`</span><span class="nc">BaseCrossValidator</span> <span class="k">of</span> <span class="o">[&gt;`</span><span class="nc">BaseCrossValidator</span><span class="o">]</span> <span class="nn">Np</span><span class="p">.</span><span class="nn">Obj</span><span class="p">.</span><span class="n">t</span> <span class="o">|</span> <span class="o">`</span><span class="nc">I</span> <span class="k">of</span> <span class="kt">int</span> <span class="o">|</span> <span class="o">`</span><span class="nc">Arr</span> <span class="k">of</span> <span class="o">[&gt;`</span><span class="nc">ArrayLike</span><span class="o">]</span> <span class="nn">Np</span><span class="p">.</span><span class="nn">Obj</span><span class="p">.</span><span class="n">t</span><span class="o">]</span> <span class="o">-&gt;</span>
  <span class="o">?</span><span class="n">stack_method</span><span class="o">:[`</span><span class="nc">Auto</span> <span class="o">|</span> <span class="o">`</span><span class="nc">Predict_proba</span> <span class="o">|</span> <span class="o">`</span><span class="nc">Decision_function</span> <span class="o">|</span> <span class="o">`</span><span class="nc">Predict</span><span class="o">]</span> <span class="o">-&gt;</span>
  <span class="o">?</span><span class="n">n_jobs</span><span class="o">:</span><span class="kt">int</span> <span class="o">-&gt;</span>
  <span class="o">?</span><span class="n">passthrough</span><span class="o">:</span><span class="kt">bool</span> <span class="o">-&gt;</span>
  <span class="o">?</span><span class="n">verbose</span><span class="o">:</span><span class="kt">int</span> <span class="o">-&gt;</span>
  <span class="n">estimators</span><span class="o">:(</span><span class="kt">string</span> <span class="o">*</span> <span class="o">[&gt;`</span><span class="nc">BaseEstimator</span><span class="o">]</span> <span class="nn">Np</span><span class="p">.</span><span class="nn">Obj</span><span class="p">.</span><span class="n">t</span><span class="o">)</span> <span class="kt">list</span> <span class="o">-&gt;</span>
  <span class="kt">unit</span> <span class="o">-&gt;</span>
  <span class="n">t</span>
</code></pre></div>

<p>Stack of estimators with a final classifier.</p>
<p>Stacked generalization consists in stacking the output of individual
estimator and use a classifier to compute the final prediction. Stacking
allows to use the strength of each individual estimator by using their
output as input of a final estimator.</p>
<p>Note that <code>estimators_</code> are fitted on the full <code>X</code> while <code>final_estimator_</code>
is trained using cross-validated predictions of the base estimators using
<code>cross_val_predict</code>.</p>
<p>.. versionadded:: 0.22</p>
<p>Read more in the :ref:<code>User Guide &lt;stacking&gt;</code>.</p>
<h4>Parameters</h4>
<ul>
<li>
<p><strong>estimators : list of (str, estimator)</strong>
    Base estimators which will be stacked together. Each element of the
    list is defined as a tuple of string (i.e. name) and an estimator
    instance. An estimator can be set to 'drop' using <code>set_params</code>.</p>
</li>
<li>
<p><strong>final_estimator : estimator, default=None</strong>
    A classifier which will be used to combine the base estimators.
    The default classifier is a <code>LogisticRegression</code>.</p>
</li>
<li>
<p><strong>cv : int, cross-validation generator or an iterable, default=None</strong>
    Determines the cross-validation splitting strategy used in
    <code>cross_val_predict</code> to train <code>final_estimator</code>. Possible inputs for
    cv are:</p>
<ul>
<li>None, to use the default 5-fold cross validation,</li>
<li>integer, to specify the number of folds in a (Stratified) KFold,</li>
<li>An object to be used as a cross-validation generator,</li>
<li>An iterable yielding train, test splits.</li>
</ul>
<p>For integer/None inputs, if the estimator is a classifier and y is
either binary or multiclass, <code>StratifiedKFold</code> is used. In all other
cases, <code>KFold</code> is used.</p>
</li>
<li>
<p><strong>Refer :ref:<code>User Guide &lt;cross_validation&gt;</code> for the various</strong>
    cross-validation strategies that can be used here.</p>
<p>.. note::
   A larger number of split will provide no benefits if the number
   of training samples is large enough. Indeed, the training time
   will increase. <code>cv</code> is not used for model evaluation but for
   prediction.</p>
</li>
<li>
<p><strong>stack_method : {'auto', 'predict_proba', 'decision_function', 'predict'},             default='auto'</strong>
    Methods called for each base estimator. It can be:</p>
<ul>
<li>if 'auto', it will try to invoke, for each estimator,
  <code>'predict_proba'</code>, <code>'decision_function'</code> or <code>'predict'</code> in that
  order.</li>
<li>otherwise, one of <code>'predict_proba'</code>, <code>'decision_function'</code> or
  <code>'predict'</code>. If the method is not implemented by the estimator, it
  will raise an error.</li>
</ul>
</li>
<li>
<p><strong>n_jobs : int, default=None</strong>
    The number of jobs to run in parallel all <code>estimators</code> <code>fit</code>.
    <code>None</code> means 1 unless in a <code>joblib.parallel_backend</code> context. -1 means
    using all processors. See Glossary for more details.</p>
</li>
<li>
<p><strong>passthrough : bool, default=False</strong>
    When False, only the predictions of estimators will be used as
    training data for <code>final_estimator</code>. When True, the
    <code>final_estimator</code> is trained on the predictions as well as the
    original training data.</p>
</li>
<li>
<p><strong>verbose : int, default=0</strong>
    Verbosity level.</p>
</li>
</ul>
<h4>Attributes</h4>
<ul>
<li>
<p><strong>classes_ : ndarray of shape (n_classes,)</strong>
    Class labels.</p>
</li>
<li>
<p><strong>estimators_ : list of estimators</strong>
    The elements of the estimators parameter, having been fitted on the
    training data. If an estimator has been set to <code>'drop'</code>, it
    will not appear in <code>estimators_</code>.</p>
</li>
<li>
<p><strong>named_estimators_ : :class:<code>~sklearn.utils.Bunch</code></strong>
    Attribute to access any fitted sub-estimators by name.</p>
</li>
<li>
<p><strong>final_estimator_ : estimator</strong>
    The classifier which predicts given the output of <code>estimators_</code>.</p>
</li>
<li>
<p><strong>stack_method_ : list of str</strong>
    The method used by each base estimator.</p>
</li>
</ul>
<h4>Notes</h4>
<p>When <code>predict_proba</code> is used by each estimator (i.e. most of the time for
<code>stack_method='auto'</code> or specifically for <code>stack_method='predict_proba'</code>),
The first column predicted by each estimator will be dropped in the case
of a binary classification problem. Indeed, both feature will be perfectly
collinear.</p>
<h4>References</h4>
<p>.. [1] Wolpert, David H. 'Stacked generalization.' Neural networks 5.2
   (1992): 241-259.</p>
<h4>Examples</h4>
<div class="highlight"><pre><span></span><code><span class="o">&gt;&gt;&gt;</span> <span class="kn">from</span> <span class="nn">sklearn.datasets</span> <span class="kn">import</span> <span class="n">load_iris</span>
<span class="o">&gt;&gt;&gt;</span> <span class="kn">from</span> <span class="nn">sklearn.ensemble</span> <span class="kn">import</span> <span class="n">RandomForestClassifier</span>
<span class="o">&gt;&gt;&gt;</span> <span class="kn">from</span> <span class="nn">sklearn.svm</span> <span class="kn">import</span> <span class="n">LinearSVC</span>
<span class="o">&gt;&gt;&gt;</span> <span class="kn">from</span> <span class="nn">sklearn.linear_model</span> <span class="kn">import</span> <span class="n">LogisticRegression</span>
<span class="o">&gt;&gt;&gt;</span> <span class="kn">from</span> <span class="nn">sklearn.preprocessing</span> <span class="kn">import</span> <span class="n">StandardScaler</span>
<span class="o">&gt;&gt;&gt;</span> <span class="kn">from</span> <span class="nn">sklearn.pipeline</span> <span class="kn">import</span> <span class="n">make_pipeline</span>
<span class="o">&gt;&gt;&gt;</span> <span class="kn">from</span> <span class="nn">sklearn.ensemble</span> <span class="kn">import</span> <span class="n">StackingClassifier</span>
<span class="o">&gt;&gt;&gt;</span> <span class="n">X</span><span class="p">,</span> <span class="n">y</span> <span class="o">=</span> <span class="n">load_iris</span><span class="p">(</span><span class="n">return_X_y</span><span class="o">=</span><span class="kc">True</span><span class="p">)</span>
<span class="o">&gt;&gt;&gt;</span> <span class="n">estimators</span> <span class="o">=</span> <span class="p">[</span>
<span class="o">...</span>     <span class="p">(</span><span class="s1">&#39;rf&#39;</span><span class="p">,</span> <span class="n">RandomForestClassifier</span><span class="p">(</span><span class="n">n_estimators</span><span class="o">=</span><span class="mi">10</span><span class="p">,</span> <span class="n">random_state</span><span class="o">=</span><span class="mi">42</span><span class="p">)),</span>
<span class="o">...</span>     <span class="p">(</span><span class="s1">&#39;svr&#39;</span><span class="p">,</span> <span class="n">make_pipeline</span><span class="p">(</span><span class="n">StandardScaler</span><span class="p">(),</span>
<span class="o">...</span>                           <span class="n">LinearSVC</span><span class="p">(</span><span class="n">random_state</span><span class="o">=</span><span class="mi">42</span><span class="p">)))</span>
<span class="o">...</span> <span class="p">]</span>
<span class="o">&gt;&gt;&gt;</span> <span class="n">clf</span> <span class="o">=</span> <span class="n">StackingClassifier</span><span class="p">(</span>
<span class="o">...</span>     <span class="n">estimators</span><span class="o">=</span><span class="n">estimators</span><span class="p">,</span> <span class="n">final_estimator</span><span class="o">=</span><span class="n">LogisticRegression</span><span class="p">()</span>
<span class="o">...</span> <span class="p">)</span>
<span class="o">&gt;&gt;&gt;</span> <span class="kn">from</span> <span class="nn">sklearn.model_selection</span> <span class="kn">import</span> <span class="n">train_test_split</span>
<span class="o">&gt;&gt;&gt;</span> <span class="n">X_train</span><span class="p">,</span> <span class="n">X_test</span><span class="p">,</span> <span class="n">y_train</span><span class="p">,</span> <span class="n">y_test</span> <span class="o">=</span> <span class="n">train_test_split</span><span class="p">(</span>
<span class="o">...</span>     <span class="n">X</span><span class="p">,</span> <span class="n">y</span><span class="p">,</span> <span class="n">stratify</span><span class="o">=</span><span class="n">y</span><span class="p">,</span> <span class="n">random_state</span><span class="o">=</span><span class="mi">42</span>
<span class="o">...</span> <span class="p">)</span>
<span class="o">&gt;&gt;&gt;</span> <span class="n">clf</span><span class="o">.</span><span class="n">fit</span><span class="p">(</span><span class="n">X_train</span><span class="p">,</span> <span class="n">y_train</span><span class="p">)</span><span class="o">.</span><span class="n">score</span><span class="p">(</span><span class="n">X_test</span><span class="p">,</span> <span class="n">y_test</span><span class="p">)</span>
<span class="mf">0.9</span><span class="o">...</span>
</code></pre></div>

</details>
<h3 id="decision_function_3">decision_function<a class="headerlink" href="#decision_function_3" title="Permanent link">&para;</a></h3>
<details class="note" open="open"><summary>method decision_function</summary><div class="highlight"><pre><span></span><code><span class="k">val</span> <span class="n">decision_function</span> <span class="o">:</span>
  <span class="n">x</span><span class="o">:[&gt;`</span><span class="nc">ArrayLike</span><span class="o">]</span> <span class="nn">Np</span><span class="p">.</span><span class="nn">Obj</span><span class="p">.</span><span class="n">t</span> <span class="o">-&gt;</span>
  <span class="o">[&gt;</span> <span class="n">tag</span><span class="o">]</span> <span class="nn">Obj</span><span class="p">.</span><span class="n">t</span> <span class="o">-&gt;</span>
  <span class="o">[&gt;`</span><span class="nc">ArrayLike</span><span class="o">]</span> <span class="nn">Np</span><span class="p">.</span><span class="nn">Obj</span><span class="p">.</span><span class="n">t</span>
</code></pre></div>

<p>Predict decision function for samples in X using
<code>final_estimator_.decision_function</code>.</p>
<h4>Parameters</h4>
<ul>
<li><strong>X : {array-like, sparse matrix} of shape (n_samples, n_features)</strong>
    Training vectors, where n_samples is the number of samples and
    n_features is the number of features.</li>
</ul>
<h4>Returns</h4>
<ul>
<li><strong>decisions : ndarray of shape (n_samples,), (n_samples, n_classes),             or (n_samples, n_classes * (n_classes-1) / 2)</strong>
    The decision function computed the final estimator.</li>
</ul>
</details>
<h3 id="fit_12">fit<a class="headerlink" href="#fit_12" title="Permanent link">&para;</a></h3>
<details class="note" open="open"><summary>method fit</summary><div class="highlight"><pre><span></span><code><span class="k">val</span> <span class="n">fit</span> <span class="o">:</span>
  <span class="o">?</span><span class="n">sample_weight</span><span class="o">:[&gt;`</span><span class="nc">ArrayLike</span><span class="o">]</span> <span class="nn">Np</span><span class="p">.</span><span class="nn">Obj</span><span class="p">.</span><span class="n">t</span> <span class="o">-&gt;</span>
  <span class="n">x</span><span class="o">:[&gt;`</span><span class="nc">ArrayLike</span><span class="o">]</span> <span class="nn">Np</span><span class="p">.</span><span class="nn">Obj</span><span class="p">.</span><span class="n">t</span> <span class="o">-&gt;</span>
  <span class="n">y</span><span class="o">:[&gt;`</span><span class="nc">ArrayLike</span><span class="o">]</span> <span class="nn">Np</span><span class="p">.</span><span class="nn">Obj</span><span class="p">.</span><span class="n">t</span> <span class="o">-&gt;</span>
  <span class="o">[&gt;</span> <span class="n">tag</span><span class="o">]</span> <span class="nn">Obj</span><span class="p">.</span><span class="n">t</span> <span class="o">-&gt;</span>
  <span class="n">t</span>
</code></pre></div>

<p>Fit the estimators.</p>
<h4>Parameters</h4>
<ul>
<li>
<p><strong>X : {array-like, sparse matrix} of shape (n_samples, n_features)</strong>
    Training vectors, where <code>n_samples</code> is the number of samples and
    <code>n_features</code> is the number of features.</p>
</li>
<li>
<p><strong>y : array-like of shape (n_samples,)</strong>
    Target values.</p>
</li>
<li>
<p><strong>sample_weight : array-like of shape (n_samples,), default=None</strong>
    Sample weights. If None, then samples are equally weighted.
    Note that this is supported only if all underlying estimators
    support sample weights.</p>
</li>
</ul>
<h4>Returns</h4>
<ul>
<li><strong>self : object</strong></li>
</ul>
</details>
<h3 id="fit_transform_1">fit_transform<a class="headerlink" href="#fit_transform_1" title="Permanent link">&para;</a></h3>
<details class="note" open="open"><summary>method fit_transform</summary><div class="highlight"><pre><span></span><code><span class="k">val</span> <span class="n">fit_transform</span> <span class="o">:</span>
  <span class="o">?</span><span class="n">y</span><span class="o">:[&gt;`</span><span class="nc">ArrayLike</span><span class="o">]</span> <span class="nn">Np</span><span class="p">.</span><span class="nn">Obj</span><span class="p">.</span><span class="n">t</span> <span class="o">-&gt;</span>
  <span class="o">?</span><span class="n">fit_params</span><span class="o">:(</span><span class="kt">string</span> <span class="o">*</span> <span class="nn">Py</span><span class="p">.</span><span class="nn">Object</span><span class="p">.</span><span class="n">t</span><span class="o">)</span> <span class="kt">list</span> <span class="o">-&gt;</span>
  <span class="n">x</span><span class="o">:[&gt;`</span><span class="nc">ArrayLike</span><span class="o">]</span> <span class="nn">Np</span><span class="p">.</span><span class="nn">Obj</span><span class="p">.</span><span class="n">t</span> <span class="o">-&gt;</span>
  <span class="o">[&gt;</span> <span class="n">tag</span><span class="o">]</span> <span class="nn">Obj</span><span class="p">.</span><span class="n">t</span> <span class="o">-&gt;</span>
  <span class="o">[&gt;`</span><span class="nc">ArrayLike</span><span class="o">]</span> <span class="nn">Np</span><span class="p">.</span><span class="nn">Obj</span><span class="p">.</span><span class="n">t</span>
</code></pre></div>

<p>Fit to data, then transform it.</p>
<p>Fits transformer to X and y with optional parameters fit_params
and returns a transformed version of X.</p>
<h4>Parameters</h4>
<ul>
<li>
<p><strong>X : {array-like, sparse matrix, dataframe} of shape                 (n_samples, n_features)</strong></p>
</li>
<li>
<p><strong>y : ndarray of shape (n_samples,), default=None</strong>
    Target values.</p>
</li>
<li>
<p><strong>**fit_params : dict</strong>
    Additional fit parameters.</p>
</li>
</ul>
<h4>Returns</h4>
<ul>
<li><strong>X_new : ndarray array of shape (n_samples, n_features_new)</strong>
    Transformed array.</li>
</ul>
</details>
<h3 id="get_params_13">get_params<a class="headerlink" href="#get_params_13" title="Permanent link">&para;</a></h3>
<details class="note" open="open"><summary>method get_params</summary><div class="highlight"><pre><span></span><code><span class="k">val</span> <span class="n">get_params</span> <span class="o">:</span>
  <span class="o">?</span><span class="n">deep</span><span class="o">:</span><span class="kt">bool</span> <span class="o">-&gt;</span>
  <span class="o">[&gt;</span> <span class="n">tag</span><span class="o">]</span> <span class="nn">Obj</span><span class="p">.</span><span class="n">t</span> <span class="o">-&gt;</span>
  <span class="nn">Py</span><span class="p">.</span><span class="nn">Object</span><span class="p">.</span><span class="n">t</span>
</code></pre></div>

<p>Get the parameters of an estimator from the ensemble.</p>
<h4>Parameters</h4>
<ul>
<li><strong>deep : bool, default=True</strong>
    Setting it to True gets the various classifiers and the parameters
    of the classifiers as well.</li>
</ul>
</details>
<h3 id="predict_11">predict<a class="headerlink" href="#predict_11" title="Permanent link">&para;</a></h3>
<details class="note" open="open"><summary>method predict</summary><div class="highlight"><pre><span></span><code><span class="k">val</span> <span class="n">predict</span> <span class="o">:</span>
  <span class="o">?</span><span class="n">predict_params</span><span class="o">:(</span><span class="kt">string</span> <span class="o">*</span> <span class="nn">Py</span><span class="p">.</span><span class="nn">Object</span><span class="p">.</span><span class="n">t</span><span class="o">)</span> <span class="kt">list</span> <span class="o">-&gt;</span>
  <span class="n">x</span><span class="o">:[&gt;`</span><span class="nc">ArrayLike</span><span class="o">]</span> <span class="nn">Np</span><span class="p">.</span><span class="nn">Obj</span><span class="p">.</span><span class="n">t</span> <span class="o">-&gt;</span>
  <span class="o">[&gt;</span> <span class="n">tag</span><span class="o">]</span> <span class="nn">Obj</span><span class="p">.</span><span class="n">t</span> <span class="o">-&gt;</span>
  <span class="o">[&gt;`</span><span class="nc">ArrayLike</span><span class="o">]</span> <span class="nn">Np</span><span class="p">.</span><span class="nn">Obj</span><span class="p">.</span><span class="n">t</span>
</code></pre></div>

<p>Predict target for X.</p>
<h4>Parameters</h4>
<ul>
<li>
<p><strong>X : {array-like, sparse matrix} of shape (n_samples, n_features)</strong>
    Training vectors, where n_samples is the number of samples and
    n_features is the number of features.</p>
</li>
<li>
<p><strong>**predict_params : dict of str -&gt; obj</strong>
    Parameters to the <code>predict</code> called by the <code>final_estimator</code>. Note
    that this may be used to return uncertainties from some estimators
    with <code>return_std</code> or <code>return_cov</code>. Be aware that it will only
    accounts for uncertainty in the final estimator.</p>
</li>
</ul>
<h4>Returns</h4>
<ul>
<li><strong>y_pred : ndarray of shape (n_samples,) or (n_samples, n_output)</strong>
    Predicted targets.</li>
</ul>
</details>
<h3 id="predict_proba_5">predict_proba<a class="headerlink" href="#predict_proba_5" title="Permanent link">&para;</a></h3>
<details class="note" open="open"><summary>method predict_proba</summary><div class="highlight"><pre><span></span><code><span class="k">val</span> <span class="n">predict_proba</span> <span class="o">:</span>
  <span class="n">x</span><span class="o">:[&gt;`</span><span class="nc">ArrayLike</span><span class="o">]</span> <span class="nn">Np</span><span class="p">.</span><span class="nn">Obj</span><span class="p">.</span><span class="n">t</span> <span class="o">-&gt;</span>
  <span class="o">[&gt;</span> <span class="n">tag</span><span class="o">]</span> <span class="nn">Obj</span><span class="p">.</span><span class="n">t</span> <span class="o">-&gt;</span>
  <span class="o">[&gt;`</span><span class="nc">ArrayLike</span><span class="o">]</span> <span class="nn">Np</span><span class="p">.</span><span class="nn">Obj</span><span class="p">.</span><span class="n">t</span>
</code></pre></div>

<p>Predict class probabilities for X using
<code>final_estimator_.predict_proba</code>.</p>
<h4>Parameters</h4>
<ul>
<li><strong>X : {array-like, sparse matrix} of shape (n_samples, n_features)</strong>
    Training vectors, where n_samples is the number of samples and
    n_features is the number of features.</li>
</ul>
<h4>Returns</h4>
<ul>
<li><strong>probabilities : ndarray of shape (n_samples, n_classes) or             list of ndarray of shape (n_output,)</strong>
    The class probabilities of the input samples.</li>
</ul>
</details>
<h3 id="score_10">score<a class="headerlink" href="#score_10" title="Permanent link">&para;</a></h3>
<details class="note" open="open"><summary>method score</summary><div class="highlight"><pre><span></span><code><span class="k">val</span> <span class="n">score</span> <span class="o">:</span>
  <span class="o">?</span><span class="n">sample_weight</span><span class="o">:[&gt;`</span><span class="nc">ArrayLike</span><span class="o">]</span> <span class="nn">Np</span><span class="p">.</span><span class="nn">Obj</span><span class="p">.</span><span class="n">t</span> <span class="o">-&gt;</span>
  <span class="n">x</span><span class="o">:[&gt;`</span><span class="nc">ArrayLike</span><span class="o">]</span> <span class="nn">Np</span><span class="p">.</span><span class="nn">Obj</span><span class="p">.</span><span class="n">t</span> <span class="o">-&gt;</span>
  <span class="n">y</span><span class="o">:[&gt;`</span><span class="nc">ArrayLike</span><span class="o">]</span> <span class="nn">Np</span><span class="p">.</span><span class="nn">Obj</span><span class="p">.</span><span class="n">t</span> <span class="o">-&gt;</span>
  <span class="o">[&gt;</span> <span class="n">tag</span><span class="o">]</span> <span class="nn">Obj</span><span class="p">.</span><span class="n">t</span> <span class="o">-&gt;</span>
  <span class="kt">float</span>
</code></pre></div>

<p>Return the mean accuracy on the given test data and labels.</p>
<p>In multi-label classification, this is the subset accuracy
which is a harsh metric since you require for each sample that
each label set be correctly predicted.</p>
<h4>Parameters</h4>
<ul>
<li>
<p><strong>X : array-like of shape (n_samples, n_features)</strong>
    Test samples.</p>
</li>
<li>
<p><strong>y : array-like of shape (n_samples,) or (n_samples, n_outputs)</strong>
    True labels for X.</p>
</li>
<li>
<p><strong>sample_weight : array-like of shape (n_samples,), default=None</strong>
    Sample weights.</p>
</li>
</ul>
<h4>Returns</h4>
<ul>
<li><strong>score : float</strong>
    Mean accuracy of self.predict(X) wrt. y.</li>
</ul>
</details>
<h3 id="set_params_13">set_params<a class="headerlink" href="#set_params_13" title="Permanent link">&para;</a></h3>
<details class="note" open="open"><summary>method set_params</summary><div class="highlight"><pre><span></span><code><span class="k">val</span> <span class="n">set_params</span> <span class="o">:</span>
  <span class="o">?</span><span class="n">params</span><span class="o">:(</span><span class="kt">string</span> <span class="o">*</span> <span class="nn">Py</span><span class="p">.</span><span class="nn">Object</span><span class="p">.</span><span class="n">t</span><span class="o">)</span> <span class="kt">list</span> <span class="o">-&gt;</span>
  <span class="o">[&gt;</span> <span class="n">tag</span><span class="o">]</span> <span class="nn">Obj</span><span class="p">.</span><span class="n">t</span> <span class="o">-&gt;</span>
  <span class="n">t</span>
</code></pre></div>

<p>Set the parameters of an estimator from the ensemble.</p>
<p>Valid parameter keys can be listed with <code>get_params()</code>.</p>
<h4>Parameters</h4>
<ul>
<li><strong>**params : keyword arguments</strong>
    Specific parameters using e.g.
    <code>set_params(parameter_name=new_value)</code>. In addition, to setting the
    parameters of the stacking estimator, the individual estimator of
    the stacking estimators can also be set, or can be removed by
    setting them to 'drop'.</li>
</ul>
</details>
<h3 id="transform_1">transform<a class="headerlink" href="#transform_1" title="Permanent link">&para;</a></h3>
<details class="note" open="open"><summary>method transform</summary><div class="highlight"><pre><span></span><code><span class="k">val</span> <span class="n">transform</span> <span class="o">:</span>
  <span class="n">x</span><span class="o">:[&gt;`</span><span class="nc">ArrayLike</span><span class="o">]</span> <span class="nn">Np</span><span class="p">.</span><span class="nn">Obj</span><span class="p">.</span><span class="n">t</span> <span class="o">-&gt;</span>
  <span class="o">[&gt;</span> <span class="n">tag</span><span class="o">]</span> <span class="nn">Obj</span><span class="p">.</span><span class="n">t</span> <span class="o">-&gt;</span>
  <span class="o">[&gt;`</span><span class="nc">ArrayLike</span><span class="o">]</span> <span class="nn">Np</span><span class="p">.</span><span class="nn">Obj</span><span class="p">.</span><span class="n">t</span>
</code></pre></div>

<p>Return class labels or probabilities for X for each estimator.</p>
<h4>Parameters</h4>
<ul>
<li><strong>X : {array-like, sparse matrix} of shape (n_samples, n_features)</strong>
    Training vectors, where <code>n_samples</code> is the number of samples and
    <code>n_features</code> is the number of features.</li>
</ul>
<h4>Returns</h4>
<ul>
<li><strong>y_preds : ndarray of shape (n_samples, n_estimators) or                 (n_samples, n_classes * n_estimators)</strong>
    Prediction outputs for each estimator.</li>
</ul>
</details>
<h3 id="classes__5">classes_<a class="headerlink" href="#classes__5" title="Permanent link">&para;</a></h3>
<details class="note" open="open"><summary>attribute classes_</summary><div class="highlight"><pre><span></span><code><span class="k">val</span> <span class="n">classes_</span> <span class="o">:</span> <span class="n">t</span> <span class="o">-&gt;</span> <span class="o">[&gt;`</span><span class="nc">ArrayLike</span><span class="o">]</span> <span class="nn">Np</span><span class="p">.</span><span class="nn">Obj</span><span class="p">.</span><span class="n">t</span>
<span class="k">val</span> <span class="n">classes_opt</span> <span class="o">:</span> <span class="n">t</span> <span class="o">-&gt;</span> <span class="o">([&gt;`</span><span class="nc">ArrayLike</span><span class="o">]</span> <span class="nn">Np</span><span class="p">.</span><span class="nn">Obj</span><span class="p">.</span><span class="n">t</span><span class="o">)</span> <span class="n">option</span>
</code></pre></div>

<p>This attribute is documented in <code>create</code> above. The first version raises Not_found
if the attribute is None. The _opt version returns an option.</p>
</details>
<h3 id="estimators__13">estimators_<a class="headerlink" href="#estimators__13" title="Permanent link">&para;</a></h3>
<details class="note" open="open"><summary>attribute estimators_</summary><div class="highlight"><pre><span></span><code><span class="k">val</span> <span class="n">estimators_</span> <span class="o">:</span> <span class="n">t</span> <span class="o">-&gt;</span> <span class="o">[`</span><span class="nc">BaseEstimator</span><span class="o">|`</span><span class="nc">Object</span><span class="o">]</span> <span class="nn">Np</span><span class="p">.</span><span class="nn">Obj</span><span class="p">.</span><span class="n">t</span> <span class="kt">list</span>
<span class="k">val</span> <span class="n">estimators_opt</span> <span class="o">:</span> <span class="n">t</span> <span class="o">-&gt;</span> <span class="o">([`</span><span class="nc">BaseEstimator</span><span class="o">|`</span><span class="nc">Object</span><span class="o">]</span> <span class="nn">Np</span><span class="p">.</span><span class="nn">Obj</span><span class="p">.</span><span class="n">t</span> <span class="kt">list</span><span class="o">)</span> <span class="n">option</span>
</code></pre></div>

<p>This attribute is documented in <code>create</code> above. The first version raises Not_found
if the attribute is None. The _opt version returns an option.</p>
</details>
<h3 id="named_estimators_">named_estimators_<a class="headerlink" href="#named_estimators_" title="Permanent link">&para;</a></h3>
<details class="note" open="open"><summary>attribute named_estimators_</summary><div class="highlight"><pre><span></span><code><span class="k">val</span> <span class="n">named_estimators_</span> <span class="o">:</span> <span class="n">t</span> <span class="o">-&gt;</span> <span class="nn">Dict</span><span class="p">.</span><span class="n">t</span>
<span class="k">val</span> <span class="n">named_estimators_opt</span> <span class="o">:</span> <span class="n">t</span> <span class="o">-&gt;</span> <span class="o">(</span><span class="nn">Dict</span><span class="p">.</span><span class="n">t</span><span class="o">)</span> <span class="n">option</span>
</code></pre></div>

<p>This attribute is documented in <code>create</code> above. The first version raises Not_found
if the attribute is None. The _opt version returns an option.</p>
</details>
<h3 id="final_estimator_">final_estimator_<a class="headerlink" href="#final_estimator_" title="Permanent link">&para;</a></h3>
<details class="note" open="open"><summary>attribute final_estimator_</summary><div class="highlight"><pre><span></span><code><span class="k">val</span> <span class="n">final_estimator_</span> <span class="o">:</span> <span class="n">t</span> <span class="o">-&gt;</span> <span class="o">[`</span><span class="nc">BaseEstimator</span><span class="o">|`</span><span class="nc">Object</span><span class="o">]</span> <span class="nn">Np</span><span class="p">.</span><span class="nn">Obj</span><span class="p">.</span><span class="n">t</span>
<span class="k">val</span> <span class="n">final_estimator_opt</span> <span class="o">:</span> <span class="n">t</span> <span class="o">-&gt;</span> <span class="o">([`</span><span class="nc">BaseEstimator</span><span class="o">|`</span><span class="nc">Object</span><span class="o">]</span> <span class="nn">Np</span><span class="p">.</span><span class="nn">Obj</span><span class="p">.</span><span class="n">t</span><span class="o">)</span> <span class="n">option</span>
</code></pre></div>

<p>This attribute is documented in <code>create</code> above. The first version raises Not_found
if the attribute is None. The _opt version returns an option.</p>
</details>
<h3 id="stack_method_">stack_method_<a class="headerlink" href="#stack_method_" title="Permanent link">&para;</a></h3>
<details class="note" open="open"><summary>attribute stack_method_</summary><div class="highlight"><pre><span></span><code><span class="k">val</span> <span class="n">stack_method_</span> <span class="o">:</span> <span class="n">t</span> <span class="o">-&gt;</span> <span class="kt">string</span> <span class="kt">list</span>
<span class="k">val</span> <span class="n">stack_method_opt</span> <span class="o">:</span> <span class="n">t</span> <span class="o">-&gt;</span> <span class="o">(</span><span class="kt">string</span> <span class="kt">list</span><span class="o">)</span> <span class="n">option</span>
</code></pre></div>

<p>This attribute is documented in <code>create</code> above. The first version raises Not_found
if the attribute is None. The _opt version returns an option.</p>
</details>
<h3 id="to_string_13">to_string<a class="headerlink" href="#to_string_13" title="Permanent link">&para;</a></h3>
<details class="note" open="open"><summary>method to_string</summary><div class="highlight"><pre><span></span><code><span class="k">val</span> <span class="n">to_string</span><span class="o">:</span> <span class="n">t</span> <span class="o">-&gt;</span> <span class="kt">string</span>
</code></pre></div>

<p>Print the object to a human-readable representation.</p>
</details>
<h3 id="show_13">show<a class="headerlink" href="#show_13" title="Permanent link">&para;</a></h3>
<details class="note" open="open"><summary>method show</summary><div class="highlight"><pre><span></span><code><span class="k">val</span> <span class="n">show</span><span class="o">:</span> <span class="n">t</span> <span class="o">-&gt;</span> <span class="kt">string</span>
</code></pre></div>

<p>Print the object to a human-readable representation.</p>
</details>
<h3 id="pp_13">pp<a class="headerlink" href="#pp_13" title="Permanent link">&para;</a></h3>
<details class="note" open="open"><summary>method pp</summary><div class="highlight"><pre><span></span><code><span class="k">val</span> <span class="n">pp</span><span class="o">:</span> <span class="nn">Format</span><span class="p">.</span><span class="n">formatter</span> <span class="o">-&gt;</span> <span class="n">t</span> <span class="o">-&gt;</span> <span class="kt">unit</span>
</code></pre></div>

<p>Pretty-print the object to a formatter.</p>
</details>
<h2 id="stackingregressor">StackingRegressor<a class="headerlink" href="#stackingregressor" title="Permanent link">&para;</a></h2>
<p>Module <code>Sklearn.​Ensemble.​StackingRegressor</code> wraps Python class <a href="https://scikit-learn.org/stable/modules/generated/sklearn.ensemble.StackingRegressor.html"><code>sklearn.ensemble.StackingRegressor</code></a>.</p>
<div class="highlight"><pre><span></span><code><span class="k">type</span> <span class="n">t</span>
</code></pre></div>

<h3 id="create_13">create<a class="headerlink" href="#create_13" title="Permanent link">&para;</a></h3>
<details class="note" open="open"><summary>constructor and attributes create</summary><div class="highlight"><pre><span></span><code><span class="k">val</span> <span class="n">create</span> <span class="o">:</span>
  <span class="o">?</span><span class="n">final_estimator</span><span class="o">:[&gt;`</span><span class="nc">BaseEstimator</span><span class="o">]</span> <span class="nn">Np</span><span class="p">.</span><span class="nn">Obj</span><span class="p">.</span><span class="n">t</span> <span class="o">-&gt;</span>
  <span class="o">?</span><span class="n">cv</span><span class="o">:[`</span><span class="nc">BaseCrossValidator</span> <span class="k">of</span> <span class="o">[&gt;`</span><span class="nc">BaseCrossValidator</span><span class="o">]</span> <span class="nn">Np</span><span class="p">.</span><span class="nn">Obj</span><span class="p">.</span><span class="n">t</span> <span class="o">|</span> <span class="o">`</span><span class="nc">I</span> <span class="k">of</span> <span class="kt">int</span> <span class="o">|</span> <span class="o">`</span><span class="nc">Arr</span> <span class="k">of</span> <span class="o">[&gt;`</span><span class="nc">ArrayLike</span><span class="o">]</span> <span class="nn">Np</span><span class="p">.</span><span class="nn">Obj</span><span class="p">.</span><span class="n">t</span><span class="o">]</span> <span class="o">-&gt;</span>
  <span class="o">?</span><span class="n">n_jobs</span><span class="o">:</span><span class="kt">int</span> <span class="o">-&gt;</span>
  <span class="o">?</span><span class="n">passthrough</span><span class="o">:</span><span class="kt">bool</span> <span class="o">-&gt;</span>
  <span class="o">?</span><span class="n">verbose</span><span class="o">:</span><span class="kt">int</span> <span class="o">-&gt;</span>
  <span class="n">estimators</span><span class="o">:(</span><span class="kt">string</span> <span class="o">*</span> <span class="o">[&gt;`</span><span class="nc">BaseEstimator</span><span class="o">]</span> <span class="nn">Np</span><span class="p">.</span><span class="nn">Obj</span><span class="p">.</span><span class="n">t</span><span class="o">)</span> <span class="kt">list</span> <span class="o">-&gt;</span>
  <span class="kt">unit</span> <span class="o">-&gt;</span>
  <span class="n">t</span>
</code></pre></div>

<p>Stack of estimators with a final regressor.</p>
<p>Stacked generalization consists in stacking the output of individual
estimator and use a regressor to compute the final prediction. Stacking
allows to use the strength of each individual estimator by using their
output as input of a final estimator.</p>
<p>Note that <code>estimators_</code> are fitted on the full <code>X</code> while <code>final_estimator_</code>
is trained using cross-validated predictions of the base estimators using
<code>cross_val_predict</code>.</p>
<p>.. versionadded:: 0.22</p>
<p>Read more in the :ref:<code>User Guide &lt;stacking&gt;</code>.</p>
<h4>Parameters</h4>
<ul>
<li>
<p><strong>estimators : list of (str, estimator)</strong>
    Base estimators which will be stacked together. Each element of the
    list is defined as a tuple of string (i.e. name) and an estimator
    instance. An estimator can be set to 'drop' using <code>set_params</code>.</p>
</li>
<li>
<p><strong>final_estimator : estimator, default=None</strong>
    A regressor which will be used to combine the base estimators.
    The default regressor is a <code>RidgeCV</code>.</p>
</li>
<li>
<p><strong>cv : int, cross-validation generator or an iterable, default=None</strong>
    Determines the cross-validation splitting strategy used in
    <code>cross_val_predict</code> to train <code>final_estimator</code>. Possible inputs for
    cv are:</p>
<ul>
<li>None, to use the default 5-fold cross validation,</li>
<li>integer, to specify the number of folds in a (Stratified) KFold,</li>
<li>An object to be used as a cross-validation generator,</li>
<li>An iterable yielding train, test splits.</li>
</ul>
<p>For integer/None inputs, if the estimator is a classifier and y is
either binary or multiclass, <code>StratifiedKFold</code> is used. In all other
cases, <code>KFold</code> is used.</p>
</li>
<li>
<p><strong>Refer :ref:<code>User Guide &lt;cross_validation&gt;</code> for the various</strong>
    cross-validation strategies that can be used here.</p>
<p>.. note::
   A larger number of split will provide no benefits if the number
   of training samples is large enough. Indeed, the training time
   will increase. <code>cv</code> is not used for model evaluation but for
   prediction.</p>
</li>
<li>
<p><strong>n_jobs : int, default=None</strong>
    The number of jobs to run in parallel for <code>fit</code> of all <code>estimators</code>.
    <code>None</code> means 1 unless in a <code>joblib.parallel_backend</code> context. -1 means
    using all processors. See Glossary for more details.</p>
</li>
<li>
<p><strong>passthrough : bool, default=False</strong>
    When False, only the predictions of estimators will be used as
    training data for <code>final_estimator</code>. When True, the
    <code>final_estimator</code> is trained on the predictions as well as the
    original training data.</p>
</li>
<li>
<p><strong>verbose : int, default=0</strong>
    Verbosity level.</p>
</li>
</ul>
<h4>Attributes</h4>
<ul>
<li>
<p><strong>estimators_ : list of estimator</strong>
    The elements of the estimators parameter, having been fitted on the
    training data. If an estimator has been set to <code>'drop'</code>, it
    will not appear in <code>estimators_</code>.</p>
</li>
<li>
<p><strong>named_estimators_ : :class:<code>~sklearn.utils.Bunch</code></strong>
    Attribute to access any fitted sub-estimators by name.</p>
</li>
<li>
<p><strong>final_estimator_ : estimator</strong>
    The regressor to stacked the base estimators fitted.</p>
</li>
</ul>
<h4>References</h4>
<p>.. [1] Wolpert, David H. 'Stacked generalization.' Neural networks 5.2
   (1992): 241-259.</p>
<h4>Examples</h4>
<div class="highlight"><pre><span></span><code><span class="o">&gt;&gt;&gt;</span> <span class="kn">from</span> <span class="nn">sklearn.datasets</span> <span class="kn">import</span> <span class="n">load_diabetes</span>
<span class="o">&gt;&gt;&gt;</span> <span class="kn">from</span> <span class="nn">sklearn.linear_model</span> <span class="kn">import</span> <span class="n">RidgeCV</span>
<span class="o">&gt;&gt;&gt;</span> <span class="kn">from</span> <span class="nn">sklearn.svm</span> <span class="kn">import</span> <span class="n">LinearSVR</span>
<span class="o">&gt;&gt;&gt;</span> <span class="kn">from</span> <span class="nn">sklearn.ensemble</span> <span class="kn">import</span> <span class="n">RandomForestRegressor</span>
<span class="o">&gt;&gt;&gt;</span> <span class="kn">from</span> <span class="nn">sklearn.ensemble</span> <span class="kn">import</span> <span class="n">StackingRegressor</span>
<span class="o">&gt;&gt;&gt;</span> <span class="n">X</span><span class="p">,</span> <span class="n">y</span> <span class="o">=</span> <span class="n">load_diabetes</span><span class="p">(</span><span class="n">return_X_y</span><span class="o">=</span><span class="kc">True</span><span class="p">)</span>
<span class="o">&gt;&gt;&gt;</span> <span class="n">estimators</span> <span class="o">=</span> <span class="p">[</span>
<span class="o">...</span>     <span class="p">(</span><span class="s1">&#39;lr&#39;</span><span class="p">,</span> <span class="n">RidgeCV</span><span class="p">()),</span>
<span class="o">...</span>     <span class="p">(</span><span class="s1">&#39;svr&#39;</span><span class="p">,</span> <span class="n">LinearSVR</span><span class="p">(</span><span class="n">random_state</span><span class="o">=</span><span class="mi">42</span><span class="p">))</span>
<span class="o">...</span> <span class="p">]</span>
<span class="o">&gt;&gt;&gt;</span> <span class="n">reg</span> <span class="o">=</span> <span class="n">StackingRegressor</span><span class="p">(</span>
<span class="o">...</span>     <span class="n">estimators</span><span class="o">=</span><span class="n">estimators</span><span class="p">,</span>
<span class="o">...</span>     <span class="n">final_estimator</span><span class="o">=</span><span class="n">RandomForestRegressor</span><span class="p">(</span><span class="n">n_estimators</span><span class="o">=</span><span class="mi">10</span><span class="p">,</span>
<span class="o">...</span>                                           <span class="n">random_state</span><span class="o">=</span><span class="mi">42</span><span class="p">)</span>
<span class="o">...</span> <span class="p">)</span>
<span class="o">&gt;&gt;&gt;</span> <span class="kn">from</span> <span class="nn">sklearn.model_selection</span> <span class="kn">import</span> <span class="n">train_test_split</span>
<span class="o">&gt;&gt;&gt;</span> <span class="n">X_train</span><span class="p">,</span> <span class="n">X_test</span><span class="p">,</span> <span class="n">y_train</span><span class="p">,</span> <span class="n">y_test</span> <span class="o">=</span> <span class="n">train_test_split</span><span class="p">(</span>
<span class="o">...</span>     <span class="n">X</span><span class="p">,</span> <span class="n">y</span><span class="p">,</span> <span class="n">random_state</span><span class="o">=</span><span class="mi">42</span>
<span class="o">...</span> <span class="p">)</span>
<span class="o">&gt;&gt;&gt;</span> <span class="n">reg</span><span class="o">.</span><span class="n">fit</span><span class="p">(</span><span class="n">X_train</span><span class="p">,</span> <span class="n">y_train</span><span class="p">)</span><span class="o">.</span><span class="n">score</span><span class="p">(</span><span class="n">X_test</span><span class="p">,</span> <span class="n">y_test</span><span class="p">)</span>
<span class="mf">0.3</span><span class="o">...</span>
</code></pre></div>

</details>
<h3 id="fit_13">fit<a class="headerlink" href="#fit_13" title="Permanent link">&para;</a></h3>
<details class="note" open="open"><summary>method fit</summary><div class="highlight"><pre><span></span><code><span class="k">val</span> <span class="n">fit</span> <span class="o">:</span>
  <span class="o">?</span><span class="n">sample_weight</span><span class="o">:[&gt;`</span><span class="nc">ArrayLike</span><span class="o">]</span> <span class="nn">Np</span><span class="p">.</span><span class="nn">Obj</span><span class="p">.</span><span class="n">t</span> <span class="o">-&gt;</span>
  <span class="n">x</span><span class="o">:[&gt;`</span><span class="nc">ArrayLike</span><span class="o">]</span> <span class="nn">Np</span><span class="p">.</span><span class="nn">Obj</span><span class="p">.</span><span class="n">t</span> <span class="o">-&gt;</span>
  <span class="n">y</span><span class="o">:[&gt;`</span><span class="nc">ArrayLike</span><span class="o">]</span> <span class="nn">Np</span><span class="p">.</span><span class="nn">Obj</span><span class="p">.</span><span class="n">t</span> <span class="o">-&gt;</span>
  <span class="o">[&gt;</span> <span class="n">tag</span><span class="o">]</span> <span class="nn">Obj</span><span class="p">.</span><span class="n">t</span> <span class="o">-&gt;</span>
  <span class="n">t</span>
</code></pre></div>

<p>Fit the estimators.</p>
<h4>Parameters</h4>
<ul>
<li>
<p><strong>X : {array-like, sparse matrix} of shape (n_samples, n_features)</strong>
    Training vectors, where n_samples is the number of samples and
    n_features is the number of features.</p>
</li>
<li>
<p><strong>y : array-like of shape (n_samples,)</strong>
    Target values.</p>
</li>
<li>
<p><strong>sample_weight : array-like of shape (n_samples,), default=None</strong>
    Sample weights. If None, then samples are equally weighted.
    Note that this is supported only if all underlying estimators
    support sample weights.</p>
</li>
</ul>
<h4>Returns</h4>
<ul>
<li><strong>self : object</strong></li>
</ul>
</details>
<h3 id="fit_transform_2">fit_transform<a class="headerlink" href="#fit_transform_2" title="Permanent link">&para;</a></h3>
<details class="note" open="open"><summary>method fit_transform</summary><div class="highlight"><pre><span></span><code><span class="k">val</span> <span class="n">fit_transform</span> <span class="o">:</span>
  <span class="o">?</span><span class="n">y</span><span class="o">:[&gt;`</span><span class="nc">ArrayLike</span><span class="o">]</span> <span class="nn">Np</span><span class="p">.</span><span class="nn">Obj</span><span class="p">.</span><span class="n">t</span> <span class="o">-&gt;</span>
  <span class="o">?</span><span class="n">fit_params</span><span class="o">:(</span><span class="kt">string</span> <span class="o">*</span> <span class="nn">Py</span><span class="p">.</span><span class="nn">Object</span><span class="p">.</span><span class="n">t</span><span class="o">)</span> <span class="kt">list</span> <span class="o">-&gt;</span>
  <span class="n">x</span><span class="o">:[&gt;`</span><span class="nc">ArrayLike</span><span class="o">]</span> <span class="nn">Np</span><span class="p">.</span><span class="nn">Obj</span><span class="p">.</span><span class="n">t</span> <span class="o">-&gt;</span>
  <span class="o">[&gt;</span> <span class="n">tag</span><span class="o">]</span> <span class="nn">Obj</span><span class="p">.</span><span class="n">t</span> <span class="o">-&gt;</span>
  <span class="o">[&gt;`</span><span class="nc">ArrayLike</span><span class="o">]</span> <span class="nn">Np</span><span class="p">.</span><span class="nn">Obj</span><span class="p">.</span><span class="n">t</span>
</code></pre></div>

<p>Fit to data, then transform it.</p>
<p>Fits transformer to X and y with optional parameters fit_params
and returns a transformed version of X.</p>
<h4>Parameters</h4>
<ul>
<li>
<p><strong>X : {array-like, sparse matrix, dataframe} of shape                 (n_samples, n_features)</strong></p>
</li>
<li>
<p><strong>y : ndarray of shape (n_samples,), default=None</strong>
    Target values.</p>
</li>
<li>
<p><strong>**fit_params : dict</strong>
    Additional fit parameters.</p>
</li>
</ul>
<h4>Returns</h4>
<ul>
<li><strong>X_new : ndarray array of shape (n_samples, n_features_new)</strong>
    Transformed array.</li>
</ul>
</details>
<h3 id="get_params_14">get_params<a class="headerlink" href="#get_params_14" title="Permanent link">&para;</a></h3>
<details class="note" open="open"><summary>method get_params</summary><div class="highlight"><pre><span></span><code><span class="k">val</span> <span class="n">get_params</span> <span class="o">:</span>
  <span class="o">?</span><span class="n">deep</span><span class="o">:</span><span class="kt">bool</span> <span class="o">-&gt;</span>
  <span class="o">[&gt;</span> <span class="n">tag</span><span class="o">]</span> <span class="nn">Obj</span><span class="p">.</span><span class="n">t</span> <span class="o">-&gt;</span>
  <span class="nn">Py</span><span class="p">.</span><span class="nn">Object</span><span class="p">.</span><span class="n">t</span>
</code></pre></div>

<p>Get the parameters of an estimator from the ensemble.</p>
<h4>Parameters</h4>
<ul>
<li><strong>deep : bool, default=True</strong>
    Setting it to True gets the various classifiers and the parameters
    of the classifiers as well.</li>
</ul>
</details>
<h3 id="predict_12">predict<a class="headerlink" href="#predict_12" title="Permanent link">&para;</a></h3>
<details class="note" open="open"><summary>method predict</summary><div class="highlight"><pre><span></span><code><span class="k">val</span> <span class="n">predict</span> <span class="o">:</span>
  <span class="o">?</span><span class="n">predict_params</span><span class="o">:(</span><span class="kt">string</span> <span class="o">*</span> <span class="nn">Py</span><span class="p">.</span><span class="nn">Object</span><span class="p">.</span><span class="n">t</span><span class="o">)</span> <span class="kt">list</span> <span class="o">-&gt;</span>
  <span class="n">x</span><span class="o">:[&gt;`</span><span class="nc">ArrayLike</span><span class="o">]</span> <span class="nn">Np</span><span class="p">.</span><span class="nn">Obj</span><span class="p">.</span><span class="n">t</span> <span class="o">-&gt;</span>
  <span class="o">[&gt;</span> <span class="n">tag</span><span class="o">]</span> <span class="nn">Obj</span><span class="p">.</span><span class="n">t</span> <span class="o">-&gt;</span>
  <span class="o">[&gt;`</span><span class="nc">ArrayLike</span><span class="o">]</span> <span class="nn">Np</span><span class="p">.</span><span class="nn">Obj</span><span class="p">.</span><span class="n">t</span>
</code></pre></div>

<p>Predict target for X.</p>
<h4>Parameters</h4>
<ul>
<li>
<p><strong>X : {array-like, sparse matrix} of shape (n_samples, n_features)</strong>
    Training vectors, where n_samples is the number of samples and
    n_features is the number of features.</p>
</li>
<li>
<p><strong>**predict_params : dict of str -&gt; obj</strong>
    Parameters to the <code>predict</code> called by the <code>final_estimator</code>. Note
    that this may be used to return uncertainties from some estimators
    with <code>return_std</code> or <code>return_cov</code>. Be aware that it will only
    accounts for uncertainty in the final estimator.</p>
</li>
</ul>
<h4>Returns</h4>
<ul>
<li><strong>y_pred : ndarray of shape (n_samples,) or (n_samples, n_output)</strong>
    Predicted targets.</li>
</ul>
</details>
<h3 id="score_11">score<a class="headerlink" href="#score_11" title="Permanent link">&para;</a></h3>
<details class="note" open="open"><summary>method score</summary><div class="highlight"><pre><span></span><code><span class="k">val</span> <span class="n">score</span> <span class="o">:</span>
  <span class="o">?</span><span class="n">sample_weight</span><span class="o">:[&gt;`</span><span class="nc">ArrayLike</span><span class="o">]</span> <span class="nn">Np</span><span class="p">.</span><span class="nn">Obj</span><span class="p">.</span><span class="n">t</span> <span class="o">-&gt;</span>
  <span class="n">x</span><span class="o">:[&gt;`</span><span class="nc">ArrayLike</span><span class="o">]</span> <span class="nn">Np</span><span class="p">.</span><span class="nn">Obj</span><span class="p">.</span><span class="n">t</span> <span class="o">-&gt;</span>
  <span class="n">y</span><span class="o">:[&gt;`</span><span class="nc">ArrayLike</span><span class="o">]</span> <span class="nn">Np</span><span class="p">.</span><span class="nn">Obj</span><span class="p">.</span><span class="n">t</span> <span class="o">-&gt;</span>
  <span class="o">[&gt;</span> <span class="n">tag</span><span class="o">]</span> <span class="nn">Obj</span><span class="p">.</span><span class="n">t</span> <span class="o">-&gt;</span>
  <span class="kt">float</span>
</code></pre></div>

<p>Return the coefficient of determination R^2 of the prediction.</p>
<p>The coefficient R^2 is defined as (1 - u/v), where u is the residual
sum of squares ((y_true - y_pred) <strong> 2).sum() and v is the total
sum of squares ((y_true - y_true.mean()) </strong> 2).sum().
The best possible score is 1.0 and it can be negative (because the
model can be arbitrarily worse). A constant model that always
predicts the expected value of y, disregarding the input features,
would get a R^2 score of 0.0.</p>
<h4>Parameters</h4>
<ul>
<li>
<p><strong>X : array-like of shape (n_samples, n_features)</strong>
    Test samples. For some estimators this may be a
    precomputed kernel matrix or a list of generic objects instead,
    shape = (n_samples, n_samples_fitted),
    where n_samples_fitted is the number of
    samples used in the fitting for the estimator.</p>
</li>
<li>
<p><strong>y : array-like of shape (n_samples,) or (n_samples, n_outputs)</strong>
    True values for X.</p>
</li>
<li>
<p><strong>sample_weight : array-like of shape (n_samples,), default=None</strong>
    Sample weights.</p>
</li>
</ul>
<h4>Returns</h4>
<ul>
<li><strong>score : float</strong>
    R^2 of self.predict(X) wrt. y.</li>
</ul>
<h4>Notes</h4>
<p>The R2 score used when calling <code>score</code> on a regressor uses
<code>multioutput='uniform_average'</code> from version 0.23 to keep consistent
with default value of :func:<code>~sklearn.metrics.r2_score</code>.
This influences the <code>score</code> method of all the multioutput
regressors (except for
:class:<code>~sklearn.multioutput.MultiOutputRegressor</code>).</p>
</details>
<h3 id="set_params_14">set_params<a class="headerlink" href="#set_params_14" title="Permanent link">&para;</a></h3>
<details class="note" open="open"><summary>method set_params</summary><div class="highlight"><pre><span></span><code><span class="k">val</span> <span class="n">set_params</span> <span class="o">:</span>
  <span class="o">?</span><span class="n">params</span><span class="o">:(</span><span class="kt">string</span> <span class="o">*</span> <span class="nn">Py</span><span class="p">.</span><span class="nn">Object</span><span class="p">.</span><span class="n">t</span><span class="o">)</span> <span class="kt">list</span> <span class="o">-&gt;</span>
  <span class="o">[&gt;</span> <span class="n">tag</span><span class="o">]</span> <span class="nn">Obj</span><span class="p">.</span><span class="n">t</span> <span class="o">-&gt;</span>
  <span class="n">t</span>
</code></pre></div>

<p>Set the parameters of an estimator from the ensemble.</p>
<p>Valid parameter keys can be listed with <code>get_params()</code>.</p>
<h4>Parameters</h4>
<ul>
<li><strong>**params : keyword arguments</strong>
    Specific parameters using e.g.
    <code>set_params(parameter_name=new_value)</code>. In addition, to setting the
    parameters of the stacking estimator, the individual estimator of
    the stacking estimators can also be set, or can be removed by
    setting them to 'drop'.</li>
</ul>
</details>
<h3 id="transform_2">transform<a class="headerlink" href="#transform_2" title="Permanent link">&para;</a></h3>
<details class="note" open="open"><summary>method transform</summary><div class="highlight"><pre><span></span><code><span class="k">val</span> <span class="n">transform</span> <span class="o">:</span>
  <span class="n">x</span><span class="o">:[&gt;`</span><span class="nc">ArrayLike</span><span class="o">]</span> <span class="nn">Np</span><span class="p">.</span><span class="nn">Obj</span><span class="p">.</span><span class="n">t</span> <span class="o">-&gt;</span>
  <span class="o">[&gt;</span> <span class="n">tag</span><span class="o">]</span> <span class="nn">Obj</span><span class="p">.</span><span class="n">t</span> <span class="o">-&gt;</span>
  <span class="o">[&gt;`</span><span class="nc">ArrayLike</span><span class="o">]</span> <span class="nn">Np</span><span class="p">.</span><span class="nn">Obj</span><span class="p">.</span><span class="n">t</span>
</code></pre></div>

<p>Return the predictions for X for each estimator.</p>
<h4>Parameters</h4>
<ul>
<li><strong>X : {array-like, sparse matrix} of shape (n_samples, n_features)</strong>
    Training vectors, where <code>n_samples</code> is the number of samples and
    <code>n_features</code> is the number of features.</li>
</ul>
<h4>Returns</h4>
<ul>
<li><strong>y_preds : ndarray of shape (n_samples, n_estimators)</strong>
    Prediction outputs for each estimator.</li>
</ul>
</details>
<h3 id="estimators__14">estimators_<a class="headerlink" href="#estimators__14" title="Permanent link">&para;</a></h3>
<details class="note" open="open"><summary>attribute estimators_</summary><div class="highlight"><pre><span></span><code><span class="k">val</span> <span class="n">estimators_</span> <span class="o">:</span> <span class="n">t</span> <span class="o">-&gt;</span> <span class="o">[`</span><span class="nc">BaseEstimator</span><span class="o">|`</span><span class="nc">Object</span><span class="o">]</span> <span class="nn">Np</span><span class="p">.</span><span class="nn">Obj</span><span class="p">.</span><span class="n">t</span> <span class="kt">list</span>
<span class="k">val</span> <span class="n">estimators_opt</span> <span class="o">:</span> <span class="n">t</span> <span class="o">-&gt;</span> <span class="o">([`</span><span class="nc">BaseEstimator</span><span class="o">|`</span><span class="nc">Object</span><span class="o">]</span> <span class="nn">Np</span><span class="p">.</span><span class="nn">Obj</span><span class="p">.</span><span class="n">t</span> <span class="kt">list</span><span class="o">)</span> <span class="n">option</span>
</code></pre></div>

<p>This attribute is documented in <code>create</code> above. The first version raises Not_found
if the attribute is None. The _opt version returns an option.</p>
</details>
<h3 id="named_estimators__1">named_estimators_<a class="headerlink" href="#named_estimators__1" title="Permanent link">&para;</a></h3>
<details class="note" open="open"><summary>attribute named_estimators_</summary><div class="highlight"><pre><span></span><code><span class="k">val</span> <span class="n">named_estimators_</span> <span class="o">:</span> <span class="n">t</span> <span class="o">-&gt;</span> <span class="nn">Dict</span><span class="p">.</span><span class="n">t</span>
<span class="k">val</span> <span class="n">named_estimators_opt</span> <span class="o">:</span> <span class="n">t</span> <span class="o">-&gt;</span> <span class="o">(</span><span class="nn">Dict</span><span class="p">.</span><span class="n">t</span><span class="o">)</span> <span class="n">option</span>
</code></pre></div>

<p>This attribute is documented in <code>create</code> above. The first version raises Not_found
if the attribute is None. The _opt version returns an option.</p>
</details>
<h3 id="final_estimator__1">final_estimator_<a class="headerlink" href="#final_estimator__1" title="Permanent link">&para;</a></h3>
<details class="note" open="open"><summary>attribute final_estimator_</summary><div class="highlight"><pre><span></span><code><span class="k">val</span> <span class="n">final_estimator_</span> <span class="o">:</span> <span class="n">t</span> <span class="o">-&gt;</span> <span class="o">[`</span><span class="nc">BaseEstimator</span><span class="o">|`</span><span class="nc">Object</span><span class="o">]</span> <span class="nn">Np</span><span class="p">.</span><span class="nn">Obj</span><span class="p">.</span><span class="n">t</span>
<span class="k">val</span> <span class="n">final_estimator_opt</span> <span class="o">:</span> <span class="n">t</span> <span class="o">-&gt;</span> <span class="o">([`</span><span class="nc">BaseEstimator</span><span class="o">|`</span><span class="nc">Object</span><span class="o">]</span> <span class="nn">Np</span><span class="p">.</span><span class="nn">Obj</span><span class="p">.</span><span class="n">t</span><span class="o">)</span> <span class="n">option</span>
</code></pre></div>

<p>This attribute is documented in <code>create</code> above. The first version raises Not_found
if the attribute is None. The _opt version returns an option.</p>
</details>
<h3 id="to_string_14">to_string<a class="headerlink" href="#to_string_14" title="Permanent link">&para;</a></h3>
<details class="note" open="open"><summary>method to_string</summary><div class="highlight"><pre><span></span><code><span class="k">val</span> <span class="n">to_string</span><span class="o">:</span> <span class="n">t</span> <span class="o">-&gt;</span> <span class="kt">string</span>
</code></pre></div>

<p>Print the object to a human-readable representation.</p>
</details>
<h3 id="show_14">show<a class="headerlink" href="#show_14" title="Permanent link">&para;</a></h3>
<details class="note" open="open"><summary>method show</summary><div class="highlight"><pre><span></span><code><span class="k">val</span> <span class="n">show</span><span class="o">:</span> <span class="n">t</span> <span class="o">-&gt;</span> <span class="kt">string</span>
</code></pre></div>

<p>Print the object to a human-readable representation.</p>
</details>
<h3 id="pp_14">pp<a class="headerlink" href="#pp_14" title="Permanent link">&para;</a></h3>
<details class="note" open="open"><summary>method pp</summary><div class="highlight"><pre><span></span><code><span class="k">val</span> <span class="n">pp</span><span class="o">:</span> <span class="nn">Format</span><span class="p">.</span><span class="n">formatter</span> <span class="o">-&gt;</span> <span class="n">t</span> <span class="o">-&gt;</span> <span class="kt">unit</span>
</code></pre></div>

<p>Pretty-print the object to a formatter.</p>
</details>
<h2 id="votingclassifier">VotingClassifier<a class="headerlink" href="#votingclassifier" title="Permanent link">&para;</a></h2>
<p>Module <code>Sklearn.​Ensemble.​VotingClassifier</code> wraps Python class <a href="https://scikit-learn.org/stable/modules/generated/sklearn.ensemble.VotingClassifier.html"><code>sklearn.ensemble.VotingClassifier</code></a>.</p>
<div class="highlight"><pre><span></span><code><span class="k">type</span> <span class="n">t</span>
</code></pre></div>

<h3 id="create_14">create<a class="headerlink" href="#create_14" title="Permanent link">&para;</a></h3>
<details class="note" open="open"><summary>constructor and attributes create</summary><div class="highlight"><pre><span></span><code><span class="k">val</span> <span class="n">create</span> <span class="o">:</span>
  <span class="o">?</span><span class="n">voting</span><span class="o">:[`</span><span class="nc">Hard</span> <span class="o">|</span> <span class="o">`</span><span class="nc">Soft</span><span class="o">]</span> <span class="o">-&gt;</span>
  <span class="o">?</span><span class="n">weights</span><span class="o">:[&gt;`</span><span class="nc">ArrayLike</span><span class="o">]</span> <span class="nn">Np</span><span class="p">.</span><span class="nn">Obj</span><span class="p">.</span><span class="n">t</span> <span class="o">-&gt;</span>
  <span class="o">?</span><span class="n">n_jobs</span><span class="o">:</span><span class="kt">int</span> <span class="o">-&gt;</span>
  <span class="o">?</span><span class="n">flatten_transform</span><span class="o">:</span><span class="kt">bool</span> <span class="o">-&gt;</span>
  <span class="o">?</span><span class="n">verbose</span><span class="o">:</span><span class="kt">int</span> <span class="o">-&gt;</span>
  <span class="n">estimators</span><span class="o">:(</span><span class="kt">string</span> <span class="o">*</span> <span class="o">[&gt;`</span><span class="nc">BaseEstimator</span><span class="o">]</span> <span class="nn">Np</span><span class="p">.</span><span class="nn">Obj</span><span class="p">.</span><span class="n">t</span><span class="o">)</span> <span class="kt">list</span> <span class="o">-&gt;</span>
  <span class="kt">unit</span> <span class="o">-&gt;</span>
  <span class="n">t</span>
</code></pre></div>

<p>Soft Voting/Majority Rule classifier for unfitted estimators.</p>
<p>.. versionadded:: 0.17</p>
<p>Read more in the :ref:<code>User Guide &lt;voting_classifier&gt;</code>.</p>
<h4>Parameters</h4>
<ul>
<li>
<p><strong>estimators : list of (str, estimator) tuples</strong>
    Invoking the <code>fit</code> method on the <code>VotingClassifier</code> will fit clones
    of those original estimators that will be stored in the class attribute
    <code>self.estimators_</code>. An estimator can be set to <code>'drop'</code>
    using <code>set_params</code>.</p>
<p>.. versionchanged:: 0.21
    <code>'drop'</code> is accepted.</p>
<p>.. deprecated:: 0.22
   Using <code>None</code> to drop an estimator is deprecated in 0.22 and
   support will be dropped in 0.24. Use the string <code>'drop'</code> instead.</p>
</li>
<li>
<p><strong>voting : {'hard', 'soft'}, default='hard'</strong>
    If 'hard', uses predicted class labels for majority rule voting.
    Else if 'soft', predicts the class label based on the argmax of
    the sums of the predicted probabilities, which is recommended for
    an ensemble of well-calibrated classifiers.</p>
</li>
<li>
<p><strong>weights : array-like of shape (n_classifiers,), default=None</strong>
    Sequence of weights (<code>float</code> or <code>int</code>) to weight the occurrences of
    predicted class labels (<code>hard</code> voting) or class probabilities
    before averaging (<code>soft</code> voting). Uses uniform weights if <code>None</code>.</p>
</li>
<li>
<p><strong>n_jobs : int, default=None</strong>
    The number of jobs to run in parallel for <code>fit</code>.
    <code>None</code> means 1 unless in a :obj:<code>joblib.parallel_backend</code> context.
    <code>-1</code> means using all processors. See :term:<code>Glossary &lt;n_jobs&gt;</code>
    for more details.</p>
<p>.. versionadded:: 0.18</p>
</li>
<li>
<p><strong>flatten_transform : bool, default=True</strong>
    Affects shape of transform output only when voting='soft'
    If voting='soft' and flatten_transform=True, transform method returns
    matrix with shape (n_samples, n_classifiers * n_classes). If
    flatten_transform=False, it returns
    (n_classifiers, n_samples, n_classes).</p>
</li>
<li>
<p><strong>verbose : bool, default=False</strong>
    If True, the time elapsed while fitting will be printed as it
    is completed.</p>
</li>
</ul>
<h4>Attributes</h4>
<ul>
<li>
<p><strong>estimators_ : list of classifiers</strong>
    The collection of fitted sub-estimators as defined in <code>estimators</code>
    that are not 'drop'.</p>
</li>
<li>
<p><strong>named_estimators_ : :class:<code>~sklearn.utils.Bunch</code></strong>
    Attribute to access any fitted sub-estimators by name.</p>
<p>.. versionadded:: 0.20</p>
</li>
<li>
<p><strong>classes_ : array-like of shape (n_predictions,)</strong>
    The classes labels.</p>
</li>
</ul>
<h4>See Also</h4>
<ul>
<li><strong>VotingRegressor: Prediction voting regressor.</strong></li>
</ul>
<h4>Examples</h4>
<div class="highlight"><pre><span></span><code><span class="o">&gt;&gt;&gt;</span> <span class="kn">import</span> <span class="nn">numpy</span> <span class="k">as</span> <span class="nn">np</span>
<span class="o">&gt;&gt;&gt;</span> <span class="kn">from</span> <span class="nn">sklearn.linear_model</span> <span class="kn">import</span> <span class="n">LogisticRegression</span>
<span class="o">&gt;&gt;&gt;</span> <span class="kn">from</span> <span class="nn">sklearn.naive_bayes</span> <span class="kn">import</span> <span class="n">GaussianNB</span>
<span class="o">&gt;&gt;&gt;</span> <span class="kn">from</span> <span class="nn">sklearn.ensemble</span> <span class="kn">import</span> <span class="n">RandomForestClassifier</span><span class="p">,</span> <span class="n">VotingClassifier</span>
<span class="o">&gt;&gt;&gt;</span> <span class="n">clf1</span> <span class="o">=</span> <span class="n">LogisticRegression</span><span class="p">(</span><span class="n">multi_class</span><span class="o">=</span><span class="s1">&#39;multinomial&#39;</span><span class="p">,</span> <span class="n">random_state</span><span class="o">=</span><span class="mi">1</span><span class="p">)</span>
<span class="o">&gt;&gt;&gt;</span> <span class="n">clf2</span> <span class="o">=</span> <span class="n">RandomForestClassifier</span><span class="p">(</span><span class="n">n_estimators</span><span class="o">=</span><span class="mi">50</span><span class="p">,</span> <span class="n">random_state</span><span class="o">=</span><span class="mi">1</span><span class="p">)</span>
<span class="o">&gt;&gt;&gt;</span> <span class="n">clf3</span> <span class="o">=</span> <span class="n">GaussianNB</span><span class="p">()</span>
<span class="o">&gt;&gt;&gt;</span> <span class="n">X</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">array</span><span class="p">([[</span><span class="o">-</span><span class="mi">1</span><span class="p">,</span> <span class="o">-</span><span class="mi">1</span><span class="p">],</span> <span class="p">[</span><span class="o">-</span><span class="mi">2</span><span class="p">,</span> <span class="o">-</span><span class="mi">1</span><span class="p">],</span> <span class="p">[</span><span class="o">-</span><span class="mi">3</span><span class="p">,</span> <span class="o">-</span><span class="mi">2</span><span class="p">],</span> <span class="p">[</span><span class="mi">1</span><span class="p">,</span> <span class="mi">1</span><span class="p">],</span> <span class="p">[</span><span class="mi">2</span><span class="p">,</span> <span class="mi">1</span><span class="p">],</span> <span class="p">[</span><span class="mi">3</span><span class="p">,</span> <span class="mi">2</span><span class="p">]])</span>
<span class="o">&gt;&gt;&gt;</span> <span class="n">y</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">array</span><span class="p">([</span><span class="mi">1</span><span class="p">,</span> <span class="mi">1</span><span class="p">,</span> <span class="mi">1</span><span class="p">,</span> <span class="mi">2</span><span class="p">,</span> <span class="mi">2</span><span class="p">,</span> <span class="mi">2</span><span class="p">])</span>
<span class="o">&gt;&gt;&gt;</span> <span class="n">eclf1</span> <span class="o">=</span> <span class="n">VotingClassifier</span><span class="p">(</span><span class="n">estimators</span><span class="o">=</span><span class="p">[</span>
<span class="o">...</span>         <span class="p">(</span><span class="s1">&#39;lr&#39;</span><span class="p">,</span> <span class="n">clf1</span><span class="p">),</span> <span class="p">(</span><span class="s1">&#39;rf&#39;</span><span class="p">,</span> <span class="n">clf2</span><span class="p">),</span> <span class="p">(</span><span class="s1">&#39;gnb&#39;</span><span class="p">,</span> <span class="n">clf3</span><span class="p">)],</span> <span class="n">voting</span><span class="o">=</span><span class="s1">&#39;hard&#39;</span><span class="p">)</span>
<span class="o">&gt;&gt;&gt;</span> <span class="n">eclf1</span> <span class="o">=</span> <span class="n">eclf1</span><span class="o">.</span><span class="n">fit</span><span class="p">(</span><span class="n">X</span><span class="p">,</span> <span class="n">y</span><span class="p">)</span>
<span class="o">&gt;&gt;&gt;</span> <span class="nb">print</span><span class="p">(</span><span class="n">eclf1</span><span class="o">.</span><span class="n">predict</span><span class="p">(</span><span class="n">X</span><span class="p">))</span>
<span class="p">[</span><span class="mi">1</span> <span class="mi">1</span> <span class="mi">1</span> <span class="mi">2</span> <span class="mi">2</span> <span class="mi">2</span><span class="p">]</span>
<span class="o">&gt;&gt;&gt;</span> <span class="n">np</span><span class="o">.</span><span class="n">array_equal</span><span class="p">(</span><span class="n">eclf1</span><span class="o">.</span><span class="n">named_estimators_</span><span class="o">.</span><span class="n">lr</span><span class="o">.</span><span class="n">predict</span><span class="p">(</span><span class="n">X</span><span class="p">),</span>
<span class="o">...</span>                <span class="n">eclf1</span><span class="o">.</span><span class="n">named_estimators_</span><span class="p">[</span><span class="s1">&#39;lr&#39;</span><span class="p">]</span><span class="o">.</span><span class="n">predict</span><span class="p">(</span><span class="n">X</span><span class="p">))</span>
<span class="kc">True</span>
<span class="o">&gt;&gt;&gt;</span> <span class="n">eclf2</span> <span class="o">=</span> <span class="n">VotingClassifier</span><span class="p">(</span><span class="n">estimators</span><span class="o">=</span><span class="p">[</span>
<span class="o">...</span>         <span class="p">(</span><span class="s1">&#39;lr&#39;</span><span class="p">,</span> <span class="n">clf1</span><span class="p">),</span> <span class="p">(</span><span class="s1">&#39;rf&#39;</span><span class="p">,</span> <span class="n">clf2</span><span class="p">),</span> <span class="p">(</span><span class="s1">&#39;gnb&#39;</span><span class="p">,</span> <span class="n">clf3</span><span class="p">)],</span>
<span class="o">...</span>         <span class="n">voting</span><span class="o">=</span><span class="s1">&#39;soft&#39;</span><span class="p">)</span>
<span class="o">&gt;&gt;&gt;</span> <span class="n">eclf2</span> <span class="o">=</span> <span class="n">eclf2</span><span class="o">.</span><span class="n">fit</span><span class="p">(</span><span class="n">X</span><span class="p">,</span> <span class="n">y</span><span class="p">)</span>
<span class="o">&gt;&gt;&gt;</span> <span class="nb">print</span><span class="p">(</span><span class="n">eclf2</span><span class="o">.</span><span class="n">predict</span><span class="p">(</span><span class="n">X</span><span class="p">))</span>
<span class="p">[</span><span class="mi">1</span> <span class="mi">1</span> <span class="mi">1</span> <span class="mi">2</span> <span class="mi">2</span> <span class="mi">2</span><span class="p">]</span>
<span class="o">&gt;&gt;&gt;</span> <span class="n">eclf3</span> <span class="o">=</span> <span class="n">VotingClassifier</span><span class="p">(</span><span class="n">estimators</span><span class="o">=</span><span class="p">[</span>
<span class="o">...</span>        <span class="p">(</span><span class="s1">&#39;lr&#39;</span><span class="p">,</span> <span class="n">clf1</span><span class="p">),</span> <span class="p">(</span><span class="s1">&#39;rf&#39;</span><span class="p">,</span> <span class="n">clf2</span><span class="p">),</span> <span class="p">(</span><span class="s1">&#39;gnb&#39;</span><span class="p">,</span> <span class="n">clf3</span><span class="p">)],</span>
<span class="o">...</span>        <span class="n">voting</span><span class="o">=</span><span class="s1">&#39;soft&#39;</span><span class="p">,</span> <span class="n">weights</span><span class="o">=</span><span class="p">[</span><span class="mi">2</span><span class="p">,</span><span class="mi">1</span><span class="p">,</span><span class="mi">1</span><span class="p">],</span>
<span class="o">...</span>        <span class="n">flatten_transform</span><span class="o">=</span><span class="kc">True</span><span class="p">)</span>
<span class="o">&gt;&gt;&gt;</span> <span class="n">eclf3</span> <span class="o">=</span> <span class="n">eclf3</span><span class="o">.</span><span class="n">fit</span><span class="p">(</span><span class="n">X</span><span class="p">,</span> <span class="n">y</span><span class="p">)</span>
<span class="o">&gt;&gt;&gt;</span> <span class="nb">print</span><span class="p">(</span><span class="n">eclf3</span><span class="o">.</span><span class="n">predict</span><span class="p">(</span><span class="n">X</span><span class="p">))</span>
<span class="p">[</span><span class="mi">1</span> <span class="mi">1</span> <span class="mi">1</span> <span class="mi">2</span> <span class="mi">2</span> <span class="mi">2</span><span class="p">]</span>
<span class="o">&gt;&gt;&gt;</span> <span class="nb">print</span><span class="p">(</span><span class="n">eclf3</span><span class="o">.</span><span class="n">transform</span><span class="p">(</span><span class="n">X</span><span class="p">)</span><span class="o">.</span><span class="n">shape</span><span class="p">)</span>
<span class="p">(</span><span class="mi">6</span><span class="p">,</span> <span class="mi">6</span><span class="p">)</span>
</code></pre></div>

</details>
<h3 id="fit_14">fit<a class="headerlink" href="#fit_14" title="Permanent link">&para;</a></h3>
<details class="note" open="open"><summary>method fit</summary><div class="highlight"><pre><span></span><code><span class="k">val</span> <span class="n">fit</span> <span class="o">:</span>
  <span class="o">?</span><span class="n">sample_weight</span><span class="o">:[&gt;`</span><span class="nc">ArrayLike</span><span class="o">]</span> <span class="nn">Np</span><span class="p">.</span><span class="nn">Obj</span><span class="p">.</span><span class="n">t</span> <span class="o">-&gt;</span>
  <span class="n">x</span><span class="o">:[&gt;`</span><span class="nc">ArrayLike</span><span class="o">]</span> <span class="nn">Np</span><span class="p">.</span><span class="nn">Obj</span><span class="p">.</span><span class="n">t</span> <span class="o">-&gt;</span>
  <span class="n">y</span><span class="o">:[&gt;`</span><span class="nc">ArrayLike</span><span class="o">]</span> <span class="nn">Np</span><span class="p">.</span><span class="nn">Obj</span><span class="p">.</span><span class="n">t</span> <span class="o">-&gt;</span>
  <span class="o">[&gt;</span> <span class="n">tag</span><span class="o">]</span> <span class="nn">Obj</span><span class="p">.</span><span class="n">t</span> <span class="o">-&gt;</span>
  <span class="n">t</span>
</code></pre></div>

<p>Fit the estimators.</p>
<h4>Parameters</h4>
<ul>
<li>
<p><strong>X : {array-like, sparse matrix} of shape (n_samples, n_features)</strong>
    Training vectors, where n_samples is the number of samples and
    n_features is the number of features.</p>
</li>
<li>
<p><strong>y : array-like of shape (n_samples,)</strong>
    Target values.</p>
</li>
<li>
<p><strong>sample_weight : array-like of shape (n_samples,), default=None</strong>
    Sample weights. If None, then samples are equally weighted.
    Note that this is supported only if all underlying estimators
    support sample weights.</p>
<p>.. versionadded:: 0.18</p>
</li>
</ul>
<h4>Returns</h4>
<ul>
<li><strong>self : object</strong></li>
</ul>
</details>
<h3 id="fit_transform_3">fit_transform<a class="headerlink" href="#fit_transform_3" title="Permanent link">&para;</a></h3>
<details class="note" open="open"><summary>method fit_transform</summary><div class="highlight"><pre><span></span><code><span class="k">val</span> <span class="n">fit_transform</span> <span class="o">:</span>
  <span class="o">?</span><span class="n">y</span><span class="o">:[&gt;`</span><span class="nc">ArrayLike</span><span class="o">]</span> <span class="nn">Np</span><span class="p">.</span><span class="nn">Obj</span><span class="p">.</span><span class="n">t</span> <span class="o">-&gt;</span>
  <span class="o">?</span><span class="n">fit_params</span><span class="o">:(</span><span class="kt">string</span> <span class="o">*</span> <span class="nn">Py</span><span class="p">.</span><span class="nn">Object</span><span class="p">.</span><span class="n">t</span><span class="o">)</span> <span class="kt">list</span> <span class="o">-&gt;</span>
  <span class="n">x</span><span class="o">:[&gt;`</span><span class="nc">ArrayLike</span><span class="o">]</span> <span class="nn">Np</span><span class="p">.</span><span class="nn">Obj</span><span class="p">.</span><span class="n">t</span> <span class="o">-&gt;</span>
  <span class="o">[&gt;</span> <span class="n">tag</span><span class="o">]</span> <span class="nn">Obj</span><span class="p">.</span><span class="n">t</span> <span class="o">-&gt;</span>
  <span class="o">[&gt;`</span><span class="nc">ArrayLike</span><span class="o">]</span> <span class="nn">Np</span><span class="p">.</span><span class="nn">Obj</span><span class="p">.</span><span class="n">t</span>
</code></pre></div>

<p>Fit to data, then transform it.</p>
<p>Fits transformer to X and y with optional parameters fit_params
and returns a transformed version of X.</p>
<h4>Parameters</h4>
<ul>
<li>
<p><strong>X : {array-like, sparse matrix, dataframe} of shape                 (n_samples, n_features)</strong></p>
</li>
<li>
<p><strong>y : ndarray of shape (n_samples,), default=None</strong>
    Target values.</p>
</li>
<li>
<p><strong>**fit_params : dict</strong>
    Additional fit parameters.</p>
</li>
</ul>
<h4>Returns</h4>
<ul>
<li><strong>X_new : ndarray array of shape (n_samples, n_features_new)</strong>
    Transformed array.</li>
</ul>
</details>
<h3 id="get_params_15">get_params<a class="headerlink" href="#get_params_15" title="Permanent link">&para;</a></h3>
<details class="note" open="open"><summary>method get_params</summary><div class="highlight"><pre><span></span><code><span class="k">val</span> <span class="n">get_params</span> <span class="o">:</span>
  <span class="o">?</span><span class="n">deep</span><span class="o">:</span><span class="kt">bool</span> <span class="o">-&gt;</span>
  <span class="o">[&gt;</span> <span class="n">tag</span><span class="o">]</span> <span class="nn">Obj</span><span class="p">.</span><span class="n">t</span> <span class="o">-&gt;</span>
  <span class="nn">Py</span><span class="p">.</span><span class="nn">Object</span><span class="p">.</span><span class="n">t</span>
</code></pre></div>

<p>Get the parameters of an estimator from the ensemble.</p>
<h4>Parameters</h4>
<ul>
<li><strong>deep : bool, default=True</strong>
    Setting it to True gets the various classifiers and the parameters
    of the classifiers as well.</li>
</ul>
</details>
<h3 id="predict_13">predict<a class="headerlink" href="#predict_13" title="Permanent link">&para;</a></h3>
<details class="note" open="open"><summary>method predict</summary><div class="highlight"><pre><span></span><code><span class="k">val</span> <span class="n">predict</span> <span class="o">:</span>
  <span class="n">x</span><span class="o">:[&gt;`</span><span class="nc">ArrayLike</span><span class="o">]</span> <span class="nn">Np</span><span class="p">.</span><span class="nn">Obj</span><span class="p">.</span><span class="n">t</span> <span class="o">-&gt;</span>
  <span class="o">[&gt;</span> <span class="n">tag</span><span class="o">]</span> <span class="nn">Obj</span><span class="p">.</span><span class="n">t</span> <span class="o">-&gt;</span>
  <span class="o">[&gt;`</span><span class="nc">ArrayLike</span><span class="o">]</span> <span class="nn">Np</span><span class="p">.</span><span class="nn">Obj</span><span class="p">.</span><span class="n">t</span>
</code></pre></div>

<p>Predict class labels for X.</p>
<h4>Parameters</h4>
<ul>
<li><strong>X : {array-like, sparse matrix} of shape (n_samples, n_features)</strong>
    The input samples.</li>
</ul>
<h4>Returns</h4>
<ul>
<li><strong>maj : array-like of shape (n_samples,)</strong>
    Predicted class labels.</li>
</ul>
</details>
<h3 id="score_12">score<a class="headerlink" href="#score_12" title="Permanent link">&para;</a></h3>
<details class="note" open="open"><summary>method score</summary><div class="highlight"><pre><span></span><code><span class="k">val</span> <span class="n">score</span> <span class="o">:</span>
  <span class="o">?</span><span class="n">sample_weight</span><span class="o">:[&gt;`</span><span class="nc">ArrayLike</span><span class="o">]</span> <span class="nn">Np</span><span class="p">.</span><span class="nn">Obj</span><span class="p">.</span><span class="n">t</span> <span class="o">-&gt;</span>
  <span class="n">x</span><span class="o">:[&gt;`</span><span class="nc">ArrayLike</span><span class="o">]</span> <span class="nn">Np</span><span class="p">.</span><span class="nn">Obj</span><span class="p">.</span><span class="n">t</span> <span class="o">-&gt;</span>
  <span class="n">y</span><span class="o">:[&gt;`</span><span class="nc">ArrayLike</span><span class="o">]</span> <span class="nn">Np</span><span class="p">.</span><span class="nn">Obj</span><span class="p">.</span><span class="n">t</span> <span class="o">-&gt;</span>
  <span class="o">[&gt;</span> <span class="n">tag</span><span class="o">]</span> <span class="nn">Obj</span><span class="p">.</span><span class="n">t</span> <span class="o">-&gt;</span>
  <span class="kt">float</span>
</code></pre></div>

<p>Return the mean accuracy on the given test data and labels.</p>
<p>In multi-label classification, this is the subset accuracy
which is a harsh metric since you require for each sample that
each label set be correctly predicted.</p>
<h4>Parameters</h4>
<ul>
<li>
<p><strong>X : array-like of shape (n_samples, n_features)</strong>
    Test samples.</p>
</li>
<li>
<p><strong>y : array-like of shape (n_samples,) or (n_samples, n_outputs)</strong>
    True labels for X.</p>
</li>
<li>
<p><strong>sample_weight : array-like of shape (n_samples,), default=None</strong>
    Sample weights.</p>
</li>
</ul>
<h4>Returns</h4>
<ul>
<li><strong>score : float</strong>
    Mean accuracy of self.predict(X) wrt. y.</li>
</ul>
</details>
<h3 id="set_params_15">set_params<a class="headerlink" href="#set_params_15" title="Permanent link">&para;</a></h3>
<details class="note" open="open"><summary>method set_params</summary><div class="highlight"><pre><span></span><code><span class="k">val</span> <span class="n">set_params</span> <span class="o">:</span>
  <span class="o">?</span><span class="n">params</span><span class="o">:(</span><span class="kt">string</span> <span class="o">*</span> <span class="nn">Py</span><span class="p">.</span><span class="nn">Object</span><span class="p">.</span><span class="n">t</span><span class="o">)</span> <span class="kt">list</span> <span class="o">-&gt;</span>
  <span class="o">[&gt;</span> <span class="n">tag</span><span class="o">]</span> <span class="nn">Obj</span><span class="p">.</span><span class="n">t</span> <span class="o">-&gt;</span>
  <span class="n">t</span>
</code></pre></div>

<p>Set the parameters of an estimator from the ensemble.</p>
<p>Valid parameter keys can be listed with <code>get_params()</code>.</p>
<h4>Parameters</h4>
<ul>
<li><strong>**params : keyword arguments</strong>
    Specific parameters using e.g.
    <code>set_params(parameter_name=new_value)</code>. In addition, to setting the
    parameters of the stacking estimator, the individual estimator of
    the stacking estimators can also be set, or can be removed by
    setting them to 'drop'.</li>
</ul>
</details>
<h3 id="transform_3">transform<a class="headerlink" href="#transform_3" title="Permanent link">&para;</a></h3>
<details class="note" open="open"><summary>method transform</summary><div class="highlight"><pre><span></span><code><span class="k">val</span> <span class="n">transform</span> <span class="o">:</span>
  <span class="n">x</span><span class="o">:[&gt;`</span><span class="nc">ArrayLike</span><span class="o">]</span> <span class="nn">Np</span><span class="p">.</span><span class="nn">Obj</span><span class="p">.</span><span class="n">t</span> <span class="o">-&gt;</span>
  <span class="o">[&gt;</span> <span class="n">tag</span><span class="o">]</span> <span class="nn">Obj</span><span class="p">.</span><span class="n">t</span> <span class="o">-&gt;</span>
  <span class="o">[&gt;`</span><span class="nc">ArrayLike</span><span class="o">]</span> <span class="nn">Np</span><span class="p">.</span><span class="nn">Obj</span><span class="p">.</span><span class="n">t</span>
</code></pre></div>

<p>Return class labels or probabilities for X for each estimator.</p>
<h4>Parameters</h4>
<ul>
<li><strong>X : {array-like, sparse matrix} of shape (n_samples, n_features)</strong>
    Training vectors, where n_samples is the number of samples and
    n_features is the number of features.</li>
</ul>
<h4>Returns</h4>
<p>probabilities_or_labels
    If <code>voting='soft'</code> and <code>flatten_transform=True</code>:
        returns ndarray of shape (n_classifiers, n_samples *
        n_classes), being class probabilities calculated by each
        classifier.
    If <code>voting='soft' and</code>flatten_transform=False<code>:
        ndarray of shape (n_classifiers, n_samples, n_classes)
    If</code>voting='hard'`:
        ndarray of shape (n_samples, n_classifiers), being
        class labels predicted by each classifier.</p>
</details>
<h3 id="estimators__15">estimators_<a class="headerlink" href="#estimators__15" title="Permanent link">&para;</a></h3>
<details class="note" open="open"><summary>attribute estimators_</summary><div class="highlight"><pre><span></span><code><span class="k">val</span> <span class="n">estimators_</span> <span class="o">:</span> <span class="n">t</span> <span class="o">-&gt;</span> <span class="nn">Py</span><span class="p">.</span><span class="nn">Object</span><span class="p">.</span><span class="n">t</span>
<span class="k">val</span> <span class="n">estimators_opt</span> <span class="o">:</span> <span class="n">t</span> <span class="o">-&gt;</span> <span class="o">(</span><span class="nn">Py</span><span class="p">.</span><span class="nn">Object</span><span class="p">.</span><span class="n">t</span><span class="o">)</span> <span class="n">option</span>
</code></pre></div>

<p>This attribute is documented in <code>create</code> above. The first version raises Not_found
if the attribute is None. The _opt version returns an option.</p>
</details>
<h3 id="named_estimators__2">named_estimators_<a class="headerlink" href="#named_estimators__2" title="Permanent link">&para;</a></h3>
<details class="note" open="open"><summary>attribute named_estimators_</summary><div class="highlight"><pre><span></span><code><span class="k">val</span> <span class="n">named_estimators_</span> <span class="o">:</span> <span class="n">t</span> <span class="o">-&gt;</span> <span class="nn">Dict</span><span class="p">.</span><span class="n">t</span>
<span class="k">val</span> <span class="n">named_estimators_opt</span> <span class="o">:</span> <span class="n">t</span> <span class="o">-&gt;</span> <span class="o">(</span><span class="nn">Dict</span><span class="p">.</span><span class="n">t</span><span class="o">)</span> <span class="n">option</span>
</code></pre></div>

<p>This attribute is documented in <code>create</code> above. The first version raises Not_found
if the attribute is None. The _opt version returns an option.</p>
</details>
<h3 id="classes__6">classes_<a class="headerlink" href="#classes__6" title="Permanent link">&para;</a></h3>
<details class="note" open="open"><summary>attribute classes_</summary><div class="highlight"><pre><span></span><code><span class="k">val</span> <span class="n">classes_</span> <span class="o">:</span> <span class="n">t</span> <span class="o">-&gt;</span> <span class="o">[&gt;`</span><span class="nc">ArrayLike</span><span class="o">]</span> <span class="nn">Np</span><span class="p">.</span><span class="nn">Obj</span><span class="p">.</span><span class="n">t</span>
<span class="k">val</span> <span class="n">classes_opt</span> <span class="o">:</span> <span class="n">t</span> <span class="o">-&gt;</span> <span class="o">([&gt;`</span><span class="nc">ArrayLike</span><span class="o">]</span> <span class="nn">Np</span><span class="p">.</span><span class="nn">Obj</span><span class="p">.</span><span class="n">t</span><span class="o">)</span> <span class="n">option</span>
</code></pre></div>

<p>This attribute is documented in <code>create</code> above. The first version raises Not_found
if the attribute is None. The _opt version returns an option.</p>
</details>
<h3 id="to_string_15">to_string<a class="headerlink" href="#to_string_15" title="Permanent link">&para;</a></h3>
<details class="note" open="open"><summary>method to_string</summary><div class="highlight"><pre><span></span><code><span class="k">val</span> <span class="n">to_string</span><span class="o">:</span> <span class="n">t</span> <span class="o">-&gt;</span> <span class="kt">string</span>
</code></pre></div>

<p>Print the object to a human-readable representation.</p>
</details>
<h3 id="show_15">show<a class="headerlink" href="#show_15" title="Permanent link">&para;</a></h3>
<details class="note" open="open"><summary>method show</summary><div class="highlight"><pre><span></span><code><span class="k">val</span> <span class="n">show</span><span class="o">:</span> <span class="n">t</span> <span class="o">-&gt;</span> <span class="kt">string</span>
</code></pre></div>

<p>Print the object to a human-readable representation.</p>
</details>
<h3 id="pp_15">pp<a class="headerlink" href="#pp_15" title="Permanent link">&para;</a></h3>
<details class="note" open="open"><summary>method pp</summary><div class="highlight"><pre><span></span><code><span class="k">val</span> <span class="n">pp</span><span class="o">:</span> <span class="nn">Format</span><span class="p">.</span><span class="n">formatter</span> <span class="o">-&gt;</span> <span class="n">t</span> <span class="o">-&gt;</span> <span class="kt">unit</span>
</code></pre></div>

<p>Pretty-print the object to a formatter.</p>
</details>
<h2 id="votingregressor">VotingRegressor<a class="headerlink" href="#votingregressor" title="Permanent link">&para;</a></h2>
<p>Module <code>Sklearn.​Ensemble.​VotingRegressor</code> wraps Python class <a href="https://scikit-learn.org/stable/modules/generated/sklearn.ensemble.VotingRegressor.html"><code>sklearn.ensemble.VotingRegressor</code></a>.</p>
<div class="highlight"><pre><span></span><code><span class="k">type</span> <span class="n">t</span>
</code></pre></div>

<h3 id="create_15">create<a class="headerlink" href="#create_15" title="Permanent link">&para;</a></h3>
<details class="note" open="open"><summary>constructor and attributes create</summary><div class="highlight"><pre><span></span><code><span class="k">val</span> <span class="n">create</span> <span class="o">:</span>
  <span class="o">?</span><span class="n">weights</span><span class="o">:[&gt;`</span><span class="nc">ArrayLike</span><span class="o">]</span> <span class="nn">Np</span><span class="p">.</span><span class="nn">Obj</span><span class="p">.</span><span class="n">t</span> <span class="o">-&gt;</span>
  <span class="o">?</span><span class="n">n_jobs</span><span class="o">:</span><span class="kt">int</span> <span class="o">-&gt;</span>
  <span class="o">?</span><span class="n">verbose</span><span class="o">:</span><span class="kt">int</span> <span class="o">-&gt;</span>
  <span class="n">estimators</span><span class="o">:(</span><span class="kt">string</span> <span class="o">*</span> <span class="o">[&gt;`</span><span class="nc">BaseEstimator</span><span class="o">]</span> <span class="nn">Np</span><span class="p">.</span><span class="nn">Obj</span><span class="p">.</span><span class="n">t</span><span class="o">)</span> <span class="kt">list</span> <span class="o">-&gt;</span>
  <span class="kt">unit</span> <span class="o">-&gt;</span>
  <span class="n">t</span>
</code></pre></div>

<p>Prediction voting regressor for unfitted estimators.</p>
<p>.. versionadded:: 0.21</p>
<p>A voting regressor is an ensemble meta-estimator that fits several base
regressors, each on the whole dataset. Then it averages the individual
predictions to form a final prediction.</p>
<p>Read more in the :ref:<code>User Guide &lt;voting_regressor&gt;</code>.</p>
<h4>Parameters</h4>
<ul>
<li>
<p><strong>estimators : list of (str, estimator) tuples</strong>
    Invoking the <code>fit</code> method on the <code>VotingRegressor</code> will fit clones
    of those original estimators that will be stored in the class attribute
    <code>self.estimators_</code>. An estimator can be set to <code>'drop'</code> using
    <code>set_params</code>.</p>
<p>.. versionchanged:: 0.21
    <code>'drop'</code> is accepted.</p>
<p>.. deprecated:: 0.22
   Using <code>None</code> to drop an estimator is deprecated in 0.22 and
   support will be dropped in 0.24. Use the string <code>'drop'</code> instead.</p>
</li>
<li>
<p><strong>weights : array-like of shape (n_regressors,), default=None</strong>
    Sequence of weights (<code>float</code> or <code>int</code>) to weight the occurrences of
    predicted values before averaging. Uses uniform weights if <code>None</code>.</p>
</li>
<li>
<p><strong>n_jobs : int, default=None</strong>
    The number of jobs to run in parallel for <code>fit</code>.
    <code>None</code> means 1 unless in a :obj:<code>joblib.parallel_backend</code> context.
    <code>-1</code> means using all processors. See :term:<code>Glossary &lt;n_jobs&gt;</code>
    for more details.</p>
</li>
<li>
<p><strong>verbose : bool, default=False</strong>
    If True, the time elapsed while fitting will be printed as it
    is completed.</p>
</li>
</ul>
<h4>Attributes</h4>
<ul>
<li>
<p><strong>estimators_ : list of regressors</strong>
    The collection of fitted sub-estimators as defined in <code>estimators</code>
    that are not 'drop'.</p>
</li>
<li>
<p><strong>named_estimators_ : Bunch</strong>
    Attribute to access any fitted sub-estimators by name.</p>
<p>.. versionadded:: 0.20</p>
</li>
</ul>
<h4>See Also</h4>
<ul>
<li><strong>VotingClassifier: Soft Voting/Majority Rule classifier.</strong></li>
</ul>
<h4>Examples</h4>
<div class="highlight"><pre><span></span><code><span class="o">&gt;&gt;&gt;</span> <span class="kn">import</span> <span class="nn">numpy</span> <span class="k">as</span> <span class="nn">np</span>
<span class="o">&gt;&gt;&gt;</span> <span class="kn">from</span> <span class="nn">sklearn.linear_model</span> <span class="kn">import</span> <span class="n">LinearRegression</span>
<span class="o">&gt;&gt;&gt;</span> <span class="kn">from</span> <span class="nn">sklearn.ensemble</span> <span class="kn">import</span> <span class="n">RandomForestRegressor</span>
<span class="o">&gt;&gt;&gt;</span> <span class="kn">from</span> <span class="nn">sklearn.ensemble</span> <span class="kn">import</span> <span class="n">VotingRegressor</span>
<span class="o">&gt;&gt;&gt;</span> <span class="n">r1</span> <span class="o">=</span> <span class="n">LinearRegression</span><span class="p">()</span>
<span class="o">&gt;&gt;&gt;</span> <span class="n">r2</span> <span class="o">=</span> <span class="n">RandomForestRegressor</span><span class="p">(</span><span class="n">n_estimators</span><span class="o">=</span><span class="mi">10</span><span class="p">,</span> <span class="n">random_state</span><span class="o">=</span><span class="mi">1</span><span class="p">)</span>
<span class="o">&gt;&gt;&gt;</span> <span class="n">X</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">array</span><span class="p">([[</span><span class="mi">1</span><span class="p">,</span> <span class="mi">1</span><span class="p">],</span> <span class="p">[</span><span class="mi">2</span><span class="p">,</span> <span class="mi">4</span><span class="p">],</span> <span class="p">[</span><span class="mi">3</span><span class="p">,</span> <span class="mi">9</span><span class="p">],</span> <span class="p">[</span><span class="mi">4</span><span class="p">,</span> <span class="mi">16</span><span class="p">],</span> <span class="p">[</span><span class="mi">5</span><span class="p">,</span> <span class="mi">25</span><span class="p">],</span> <span class="p">[</span><span class="mi">6</span><span class="p">,</span> <span class="mi">36</span><span class="p">]])</span>
<span class="o">&gt;&gt;&gt;</span> <span class="n">y</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">array</span><span class="p">([</span><span class="mi">2</span><span class="p">,</span> <span class="mi">6</span><span class="p">,</span> <span class="mi">12</span><span class="p">,</span> <span class="mi">20</span><span class="p">,</span> <span class="mi">30</span><span class="p">,</span> <span class="mi">42</span><span class="p">])</span>
<span class="o">&gt;&gt;&gt;</span> <span class="n">er</span> <span class="o">=</span> <span class="n">VotingRegressor</span><span class="p">([(</span><span class="s1">&#39;lr&#39;</span><span class="p">,</span> <span class="n">r1</span><span class="p">),</span> <span class="p">(</span><span class="s1">&#39;rf&#39;</span><span class="p">,</span> <span class="n">r2</span><span class="p">)])</span>
<span class="o">&gt;&gt;&gt;</span> <span class="nb">print</span><span class="p">(</span><span class="n">er</span><span class="o">.</span><span class="n">fit</span><span class="p">(</span><span class="n">X</span><span class="p">,</span> <span class="n">y</span><span class="p">)</span><span class="o">.</span><span class="n">predict</span><span class="p">(</span><span class="n">X</span><span class="p">))</span>
<span class="p">[</span> <span class="mf">3.3</span>  <span class="mf">5.7</span> <span class="mf">11.8</span> <span class="mf">19.7</span> <span class="mf">28.</span>  <span class="mf">40.3</span><span class="p">]</span>
</code></pre></div>

</details>
<h3 id="fit_15">fit<a class="headerlink" href="#fit_15" title="Permanent link">&para;</a></h3>
<details class="note" open="open"><summary>method fit</summary><div class="highlight"><pre><span></span><code><span class="k">val</span> <span class="n">fit</span> <span class="o">:</span>
  <span class="o">?</span><span class="n">sample_weight</span><span class="o">:[&gt;`</span><span class="nc">ArrayLike</span><span class="o">]</span> <span class="nn">Np</span><span class="p">.</span><span class="nn">Obj</span><span class="p">.</span><span class="n">t</span> <span class="o">-&gt;</span>
  <span class="n">x</span><span class="o">:[&gt;`</span><span class="nc">ArrayLike</span><span class="o">]</span> <span class="nn">Np</span><span class="p">.</span><span class="nn">Obj</span><span class="p">.</span><span class="n">t</span> <span class="o">-&gt;</span>
  <span class="n">y</span><span class="o">:[&gt;`</span><span class="nc">ArrayLike</span><span class="o">]</span> <span class="nn">Np</span><span class="p">.</span><span class="nn">Obj</span><span class="p">.</span><span class="n">t</span> <span class="o">-&gt;</span>
  <span class="o">[&gt;</span> <span class="n">tag</span><span class="o">]</span> <span class="nn">Obj</span><span class="p">.</span><span class="n">t</span> <span class="o">-&gt;</span>
  <span class="n">t</span>
</code></pre></div>

<p>Fit the estimators.</p>
<h4>Parameters</h4>
<ul>
<li>
<p><strong>X : {array-like, sparse matrix} of shape (n_samples, n_features)</strong>
    Training vectors, where n_samples is the number of samples and
    n_features is the number of features.</p>
</li>
<li>
<p><strong>y : array-like of shape (n_samples,)</strong>
    Target values.</p>
</li>
<li>
<p><strong>sample_weight : array-like of shape (n_samples,), default=None</strong>
    Sample weights. If None, then samples are equally weighted.
    Note that this is supported only if all underlying estimators
    support sample weights.</p>
</li>
</ul>
<h4>Returns</h4>
<ul>
<li><strong>self : object</strong>
    Fitted estimator.</li>
</ul>
</details>
<h3 id="fit_transform_4">fit_transform<a class="headerlink" href="#fit_transform_4" title="Permanent link">&para;</a></h3>
<details class="note" open="open"><summary>method fit_transform</summary><div class="highlight"><pre><span></span><code><span class="k">val</span> <span class="n">fit_transform</span> <span class="o">:</span>
  <span class="o">?</span><span class="n">y</span><span class="o">:[&gt;`</span><span class="nc">ArrayLike</span><span class="o">]</span> <span class="nn">Np</span><span class="p">.</span><span class="nn">Obj</span><span class="p">.</span><span class="n">t</span> <span class="o">-&gt;</span>
  <span class="o">?</span><span class="n">fit_params</span><span class="o">:(</span><span class="kt">string</span> <span class="o">*</span> <span class="nn">Py</span><span class="p">.</span><span class="nn">Object</span><span class="p">.</span><span class="n">t</span><span class="o">)</span> <span class="kt">list</span> <span class="o">-&gt;</span>
  <span class="n">x</span><span class="o">:[&gt;`</span><span class="nc">ArrayLike</span><span class="o">]</span> <span class="nn">Np</span><span class="p">.</span><span class="nn">Obj</span><span class="p">.</span><span class="n">t</span> <span class="o">-&gt;</span>
  <span class="o">[&gt;</span> <span class="n">tag</span><span class="o">]</span> <span class="nn">Obj</span><span class="p">.</span><span class="n">t</span> <span class="o">-&gt;</span>
  <span class="o">[&gt;`</span><span class="nc">ArrayLike</span><span class="o">]</span> <span class="nn">Np</span><span class="p">.</span><span class="nn">Obj</span><span class="p">.</span><span class="n">t</span>
</code></pre></div>

<p>Fit to data, then transform it.</p>
<p>Fits transformer to X and y with optional parameters fit_params
and returns a transformed version of X.</p>
<h4>Parameters</h4>
<ul>
<li>
<p><strong>X : {array-like, sparse matrix, dataframe} of shape                 (n_samples, n_features)</strong></p>
</li>
<li>
<p><strong>y : ndarray of shape (n_samples,), default=None</strong>
    Target values.</p>
</li>
<li>
<p><strong>**fit_params : dict</strong>
    Additional fit parameters.</p>
</li>
</ul>
<h4>Returns</h4>
<ul>
<li><strong>X_new : ndarray array of shape (n_samples, n_features_new)</strong>
    Transformed array.</li>
</ul>
</details>
<h3 id="get_params_16">get_params<a class="headerlink" href="#get_params_16" title="Permanent link">&para;</a></h3>
<details class="note" open="open"><summary>method get_params</summary><div class="highlight"><pre><span></span><code><span class="k">val</span> <span class="n">get_params</span> <span class="o">:</span>
  <span class="o">?</span><span class="n">deep</span><span class="o">:</span><span class="kt">bool</span> <span class="o">-&gt;</span>
  <span class="o">[&gt;</span> <span class="n">tag</span><span class="o">]</span> <span class="nn">Obj</span><span class="p">.</span><span class="n">t</span> <span class="o">-&gt;</span>
  <span class="nn">Py</span><span class="p">.</span><span class="nn">Object</span><span class="p">.</span><span class="n">t</span>
</code></pre></div>

<p>Get the parameters of an estimator from the ensemble.</p>
<h4>Parameters</h4>
<ul>
<li><strong>deep : bool, default=True</strong>
    Setting it to True gets the various classifiers and the parameters
    of the classifiers as well.</li>
</ul>
</details>
<h3 id="predict_14">predict<a class="headerlink" href="#predict_14" title="Permanent link">&para;</a></h3>
<details class="note" open="open"><summary>method predict</summary><div class="highlight"><pre><span></span><code><span class="k">val</span> <span class="n">predict</span> <span class="o">:</span>
  <span class="n">x</span><span class="o">:[&gt;`</span><span class="nc">ArrayLike</span><span class="o">]</span> <span class="nn">Np</span><span class="p">.</span><span class="nn">Obj</span><span class="p">.</span><span class="n">t</span> <span class="o">-&gt;</span>
  <span class="o">[&gt;</span> <span class="n">tag</span><span class="o">]</span> <span class="nn">Obj</span><span class="p">.</span><span class="n">t</span> <span class="o">-&gt;</span>
  <span class="o">[&gt;`</span><span class="nc">ArrayLike</span><span class="o">]</span> <span class="nn">Np</span><span class="p">.</span><span class="nn">Obj</span><span class="p">.</span><span class="n">t</span>
</code></pre></div>

<p>Predict regression target for X.</p>
<p>The predicted regression target of an input sample is computed as the
mean predicted regression targets of the estimators in the ensemble.</p>
<h4>Parameters</h4>
<ul>
<li><strong>X : {array-like, sparse matrix} of shape (n_samples, n_features)</strong>
    The input samples.</li>
</ul>
<h4>Returns</h4>
<ul>
<li><strong>y : ndarray of shape (n_samples,)</strong>
    The predicted values.</li>
</ul>
</details>
<h3 id="score_13">score<a class="headerlink" href="#score_13" title="Permanent link">&para;</a></h3>
<details class="note" open="open"><summary>method score</summary><div class="highlight"><pre><span></span><code><span class="k">val</span> <span class="n">score</span> <span class="o">:</span>
  <span class="o">?</span><span class="n">sample_weight</span><span class="o">:[&gt;`</span><span class="nc">ArrayLike</span><span class="o">]</span> <span class="nn">Np</span><span class="p">.</span><span class="nn">Obj</span><span class="p">.</span><span class="n">t</span> <span class="o">-&gt;</span>
  <span class="n">x</span><span class="o">:[&gt;`</span><span class="nc">ArrayLike</span><span class="o">]</span> <span class="nn">Np</span><span class="p">.</span><span class="nn">Obj</span><span class="p">.</span><span class="n">t</span> <span class="o">-&gt;</span>
  <span class="n">y</span><span class="o">:[&gt;`</span><span class="nc">ArrayLike</span><span class="o">]</span> <span class="nn">Np</span><span class="p">.</span><span class="nn">Obj</span><span class="p">.</span><span class="n">t</span> <span class="o">-&gt;</span>
  <span class="o">[&gt;</span> <span class="n">tag</span><span class="o">]</span> <span class="nn">Obj</span><span class="p">.</span><span class="n">t</span> <span class="o">-&gt;</span>
  <span class="kt">float</span>
</code></pre></div>

<p>Return the coefficient of determination R^2 of the prediction.</p>
<p>The coefficient R^2 is defined as (1 - u/v), where u is the residual
sum of squares ((y_true - y_pred) <strong> 2).sum() and v is the total
sum of squares ((y_true - y_true.mean()) </strong> 2).sum().
The best possible score is 1.0 and it can be negative (because the
model can be arbitrarily worse). A constant model that always
predicts the expected value of y, disregarding the input features,
would get a R^2 score of 0.0.</p>
<h4>Parameters</h4>
<ul>
<li>
<p><strong>X : array-like of shape (n_samples, n_features)</strong>
    Test samples. For some estimators this may be a
    precomputed kernel matrix or a list of generic objects instead,
    shape = (n_samples, n_samples_fitted),
    where n_samples_fitted is the number of
    samples used in the fitting for the estimator.</p>
</li>
<li>
<p><strong>y : array-like of shape (n_samples,) or (n_samples, n_outputs)</strong>
    True values for X.</p>
</li>
<li>
<p><strong>sample_weight : array-like of shape (n_samples,), default=None</strong>
    Sample weights.</p>
</li>
</ul>
<h4>Returns</h4>
<ul>
<li><strong>score : float</strong>
    R^2 of self.predict(X) wrt. y.</li>
</ul>
<h4>Notes</h4>
<p>The R2 score used when calling <code>score</code> on a regressor uses
<code>multioutput='uniform_average'</code> from version 0.23 to keep consistent
with default value of :func:<code>~sklearn.metrics.r2_score</code>.
This influences the <code>score</code> method of all the multioutput
regressors (except for
:class:<code>~sklearn.multioutput.MultiOutputRegressor</code>).</p>
</details>
<h3 id="set_params_16">set_params<a class="headerlink" href="#set_params_16" title="Permanent link">&para;</a></h3>
<details class="note" open="open"><summary>method set_params</summary><div class="highlight"><pre><span></span><code><span class="k">val</span> <span class="n">set_params</span> <span class="o">:</span>
  <span class="o">?</span><span class="n">params</span><span class="o">:(</span><span class="kt">string</span> <span class="o">*</span> <span class="nn">Py</span><span class="p">.</span><span class="nn">Object</span><span class="p">.</span><span class="n">t</span><span class="o">)</span> <span class="kt">list</span> <span class="o">-&gt;</span>
  <span class="o">[&gt;</span> <span class="n">tag</span><span class="o">]</span> <span class="nn">Obj</span><span class="p">.</span><span class="n">t</span> <span class="o">-&gt;</span>
  <span class="n">t</span>
</code></pre></div>

<p>Set the parameters of an estimator from the ensemble.</p>
<p>Valid parameter keys can be listed with <code>get_params()</code>.</p>
<h4>Parameters</h4>
<ul>
<li><strong>**params : keyword arguments</strong>
    Specific parameters using e.g.
    <code>set_params(parameter_name=new_value)</code>. In addition, to setting the
    parameters of the stacking estimator, the individual estimator of
    the stacking estimators can also be set, or can be removed by
    setting them to 'drop'.</li>
</ul>
</details>
<h3 id="transform_4">transform<a class="headerlink" href="#transform_4" title="Permanent link">&para;</a></h3>
<details class="note" open="open"><summary>method transform</summary><div class="highlight"><pre><span></span><code><span class="k">val</span> <span class="n">transform</span> <span class="o">:</span>
  <span class="n">x</span><span class="o">:[&gt;`</span><span class="nc">ArrayLike</span><span class="o">]</span> <span class="nn">Np</span><span class="p">.</span><span class="nn">Obj</span><span class="p">.</span><span class="n">t</span> <span class="o">-&gt;</span>
  <span class="o">[&gt;</span> <span class="n">tag</span><span class="o">]</span> <span class="nn">Obj</span><span class="p">.</span><span class="n">t</span> <span class="o">-&gt;</span>
  <span class="o">[&gt;`</span><span class="nc">ArrayLike</span><span class="o">]</span> <span class="nn">Np</span><span class="p">.</span><span class="nn">Obj</span><span class="p">.</span><span class="n">t</span>
</code></pre></div>

<p>Return predictions for X for each estimator.</p>
<h4>Parameters</h4>
<ul>
<li><strong>X : {array-like, sparse matrix} of shape (n_samples, n_features)</strong>
    The input samples.</li>
</ul>
<h4>Returns</h4>
<ul>
<li><strong>predictions: ndarray of shape (n_samples, n_classifiers)</strong>
    Values predicted by each regressor.</li>
</ul>
</details>
<h3 id="estimators__16">estimators_<a class="headerlink" href="#estimators__16" title="Permanent link">&para;</a></h3>
<details class="note" open="open"><summary>attribute estimators_</summary><div class="highlight"><pre><span></span><code><span class="k">val</span> <span class="n">estimators_</span> <span class="o">:</span> <span class="n">t</span> <span class="o">-&gt;</span> <span class="o">[`</span><span class="nc">Object</span><span class="o">|`</span><span class="nc">RegressorMixin</span><span class="o">]</span> <span class="nn">Np</span><span class="p">.</span><span class="nn">Obj</span><span class="p">.</span><span class="n">t</span> <span class="kt">list</span>
<span class="k">val</span> <span class="n">estimators_opt</span> <span class="o">:</span> <span class="n">t</span> <span class="o">-&gt;</span> <span class="o">([`</span><span class="nc">Object</span><span class="o">|`</span><span class="nc">RegressorMixin</span><span class="o">]</span> <span class="nn">Np</span><span class="p">.</span><span class="nn">Obj</span><span class="p">.</span><span class="n">t</span> <span class="kt">list</span><span class="o">)</span> <span class="n">option</span>
</code></pre></div>

<p>This attribute is documented in <code>create</code> above. The first version raises Not_found
if the attribute is None. The _opt version returns an option.</p>
</details>
<h3 id="named_estimators__3">named_estimators_<a class="headerlink" href="#named_estimators__3" title="Permanent link">&para;</a></h3>
<details class="note" open="open"><summary>attribute named_estimators_</summary><div class="highlight"><pre><span></span><code><span class="k">val</span> <span class="n">named_estimators_</span> <span class="o">:</span> <span class="n">t</span> <span class="o">-&gt;</span> <span class="nn">Dict</span><span class="p">.</span><span class="n">t</span>
<span class="k">val</span> <span class="n">named_estimators_opt</span> <span class="o">:</span> <span class="n">t</span> <span class="o">-&gt;</span> <span class="o">(</span><span class="nn">Dict</span><span class="p">.</span><span class="n">t</span><span class="o">)</span> <span class="n">option</span>
</code></pre></div>

<p>This attribute is documented in <code>create</code> above. The first version raises Not_found
if the attribute is None. The _opt version returns an option.</p>
</details>
<h3 id="to_string_16">to_string<a class="headerlink" href="#to_string_16" title="Permanent link">&para;</a></h3>
<details class="note" open="open"><summary>method to_string</summary><div class="highlight"><pre><span></span><code><span class="k">val</span> <span class="n">to_string</span><span class="o">:</span> <span class="n">t</span> <span class="o">-&gt;</span> <span class="kt">string</span>
</code></pre></div>

<p>Print the object to a human-readable representation.</p>
</details>
<h3 id="show_16">show<a class="headerlink" href="#show_16" title="Permanent link">&para;</a></h3>
<details class="note" open="open"><summary>method show</summary><div class="highlight"><pre><span></span><code><span class="k">val</span> <span class="n">show</span><span class="o">:</span> <span class="n">t</span> <span class="o">-&gt;</span> <span class="kt">string</span>
</code></pre></div>

<p>Print the object to a human-readable representation.</p>
</details>
<h3 id="pp_16">pp<a class="headerlink" href="#pp_16" title="Permanent link">&para;</a></h3>
<details class="note" open="open"><summary>method pp</summary><div class="highlight"><pre><span></span><code><span class="k">val</span> <span class="n">pp</span><span class="o">:</span> <span class="nn">Format</span><span class="p">.</span><span class="n">formatter</span> <span class="o">-&gt;</span> <span class="n">t</span> <span class="o">-&gt;</span> <span class="kt">unit</span>
</code></pre></div>

<p>Pretty-print the object to a formatter.</p>
</details>
                
              
              
                


              
            </article>
          </div>
        </div>
      </main>
      
        
<footer class="md-footer">
  
    <div class="md-footer-nav">
      <nav class="md-footer-nav__inner md-grid" aria-label="Footer">
        
          <a href="../Dummy/" class="md-footer-nav__link md-footer-nav__link--prev" rel="prev">
            <div class="md-footer-nav__button md-icon">
              <svg xmlns="http://www.w3.org/2000/svg" viewBox="0 0 24 24"><path d="M20 11v2H8l5.5 5.5-1.42 1.42L4.16 12l7.92-7.92L13.5 5.5 8 11h12z"/></svg>
            </div>
            <div class="md-footer-nav__title">
              <div class="md-ellipsis">
                <span class="md-footer-nav__direction">
                  Previous
                </span>
                Dummy
              </div>
            </div>
          </a>
        
        
          <a href="../Exceptions/" class="md-footer-nav__link md-footer-nav__link--next" rel="next">
            <div class="md-footer-nav__title">
              <div class="md-ellipsis">
                <span class="md-footer-nav__direction">
                  Next
                </span>
                Exceptions
              </div>
            </div>
            <div class="md-footer-nav__button md-icon">
              <svg xmlns="http://www.w3.org/2000/svg" viewBox="0 0 24 24"><path d="M4 11v2h12l-5.5 5.5 1.42 1.42L19.84 12l-7.92-7.92L10.5 5.5 16 11H4z"/></svg>
            </div>
          </a>
        
      </nav>
    </div>
  
  <div class="md-footer-meta md-typeset">
    <div class="md-footer-meta__inner md-grid">
      <div class="md-footer-copyright">
        
        Made with
        <a href="https://squidfunk.github.io/mkdocs-material/" target="_blank" rel="noopener">
          Material for MkDocs
        </a>
      </div>
      
    </div>
  </div>
</footer>
      
    </div>
    
      <script src="../../assets/javascripts/vendor.0ac82a11.min.js"></script>
      <script src="../../assets/javascripts/bundle.f81dfb4d.min.js"></script><script id="__lang" type="application/json">{"clipboard.copy": "Copy to clipboard", "clipboard.copied": "Copied to clipboard", "search.config.lang": "en", "search.config.pipeline": "trimmer, stopWordFilter", "search.config.separator": "[\\s\\-]+", "search.placeholder": "Search", "search.result.placeholder": "Type to start searching", "search.result.none": "No matching documents", "search.result.one": "1 matching document", "search.result.other": "# matching documents", "search.result.more.one": "1 more on this page", "search.result.more.other": "# more on this page", "search.result.term.missing": "Missing"}</script>
      
      <script>
        app = initialize({
          base: "../..",
          features: ['instant', 'tabs'],
          search: Object.assign({
            worker: "../../assets/javascripts/worker/search.4ac00218.min.js"
          }, typeof search !== "undefined" && search)
        })
      </script>
      
        <script src="https://cdnjs.cloudflare.com/ajax/libs/mathjax/2.7.0/MathJax.js?config=TeX-MML-AM_CHTML"></script>
      
    
  </body>
</html>