


<!doctype html>
<html lang="en" class="no-js">
  <head>
    
      <meta charset="utf-8">
      <meta name="viewport" content="width=device-width,initial-scale=1">
      
      
      
      <link rel="shortcut icon" href="../../assets/images/favicon.png">
      <meta name="generator" content="mkdocs-1.1.2, mkdocs-material-5.2.3">
    
    
      
        <title>Linear model - OCaml scikit-learn interface</title>
      
    
    
      <link rel="stylesheet" href="../../assets/stylesheets/main.6e35a1a6.min.css">
      
        <link rel="stylesheet" href="../../assets/stylesheets/palette.a46bcfb3.min.css">
      
      
        
        
        <meta name="theme-color" content="#3f51b5">
      
    
    
    
      
        <link href="https://fonts.gstatic.com" rel="preconnect" crossorigin>
        <link rel="stylesheet" href="https://fonts.googleapis.com/css?family=Roboto:300,400,400i,700%7CRoboto+Mono&display=fallback">
        <style>body,input{font-family:"Roboto",-apple-system,BlinkMacSystemFont,Helvetica,Arial,sans-serif}code,kbd,pre{font-family:"Roboto Mono",SFMono-Regular,Consolas,Menlo,monospace}</style>
      
    
    
    
    
      
    
    
  </head>
  
  
    
    
    
    <body dir="ltr" data-md-color-scheme="" data-md-color-primary="indigo" data-md-color-accent="indigo">
  
    <input class="md-toggle" data-md-toggle="drawer" type="checkbox" id="__drawer" autocomplete="off">
    <input class="md-toggle" data-md-toggle="search" type="checkbox" id="__search" autocomplete="off">
    <label class="md-overlay" for="__drawer"></label>
    <div data-md-component="skip">
      
        
        <a href="#parameters" class="md-skip">
          Skip to content
        </a>
      
    </div>
    <div data-md-component="announce">
      
    </div>
    
      <header class="md-header" data-md-component="header">
  <nav class="md-header-nav md-grid" aria-label="Header">
    <a href="../.." title="OCaml scikit-learn interface" class="md-header-nav__button md-logo" aria-label="OCaml scikit-learn interface">
      
  
  <svg xmlns="http://www.w3.org/2000/svg" viewBox="0 0 24 24"><path d="M12 8a3 3 0 003-3 3 3 0 00-3-3 3 3 0 00-3 3 3 3 0 003 3m0 3.54C9.64 9.35 6.5 8 3 8v11c3.5 0 6.64 1.35 9 3.54 2.36-2.19 5.5-3.54 9-3.54V8c-3.5 0-6.64 1.35-9 3.54z"/></svg>

    </a>
    <label class="md-header-nav__button md-icon" for="__drawer">
      <svg xmlns="http://www.w3.org/2000/svg" viewBox="0 0 24 24"><path d="M3 6h18v2H3V6m0 5h18v2H3v-2m0 5h18v2H3v-2z"/></svg>
    </label>
    <div class="md-header-nav__title" data-md-component="header-title">
      
        <div class="md-header-nav__ellipsis">
          <span class="md-header-nav__topic md-ellipsis">
            OCaml scikit-learn interface
          </span>
          <span class="md-header-nav__topic md-ellipsis">
            
              Linear model
            
          </span>
        </div>
      
    </div>
    
      <label class="md-header-nav__button md-icon" for="__search">
        <svg xmlns="http://www.w3.org/2000/svg" viewBox="0 0 24 24"><path d="M9.5 3A6.5 6.5 0 0116 9.5c0 1.61-.59 3.09-1.56 4.23l.27.27h.79l5 5-1.5 1.5-5-5v-.79l-.27-.27A6.516 6.516 0 019.5 16 6.5 6.5 0 013 9.5 6.5 6.5 0 019.5 3m0 2C7 5 5 7 5 9.5S7 14 9.5 14 14 12 14 9.5 12 5 9.5 5z"/></svg>
      </label>
      
<div class="md-search" data-md-component="search" role="dialog">
  <label class="md-search__overlay" for="__search"></label>
  <div class="md-search__inner" role="search">
    <form class="md-search__form" name="search">
      <input type="text" class="md-search__input" name="query" aria-label="Search" placeholder="Search" autocapitalize="off" autocorrect="off" autocomplete="off" spellcheck="false" data-md-component="search-query" data-md-state="active">
      <label class="md-search__icon md-icon" for="__search">
        <svg xmlns="http://www.w3.org/2000/svg" viewBox="0 0 24 24"><path d="M9.5 3A6.5 6.5 0 0116 9.5c0 1.61-.59 3.09-1.56 4.23l.27.27h.79l5 5-1.5 1.5-5-5v-.79l-.27-.27A6.516 6.516 0 019.5 16 6.5 6.5 0 013 9.5 6.5 6.5 0 019.5 3m0 2C7 5 5 7 5 9.5S7 14 9.5 14 14 12 14 9.5 12 5 9.5 5z"/></svg>
        <svg xmlns="http://www.w3.org/2000/svg" viewBox="0 0 24 24"><path d="M20 11v2H8l5.5 5.5-1.42 1.42L4.16 12l7.92-7.92L13.5 5.5 8 11h12z"/></svg>
      </label>
      <button type="reset" class="md-search__icon md-icon" aria-label="Clear" data-md-component="search-reset" tabindex="-1">
        <svg xmlns="http://www.w3.org/2000/svg" viewBox="0 0 24 24"><path d="M19 6.41L17.59 5 12 10.59 6.41 5 5 6.41 10.59 12 5 17.59 6.41 19 12 13.41 17.59 19 19 17.59 13.41 12 19 6.41z"/></svg>
      </button>
    </form>
    <div class="md-search__output">
      <div class="md-search__scrollwrap" data-md-scrollfix>
        <div class="md-search-result" data-md-component="search-result">
          <div class="md-search-result__meta">
            Initializing search
          </div>
          <ol class="md-search-result__list"></ol>
        </div>
      </div>
    </div>
  </div>
</div>
    
    
      <div class="md-header-nav__source">
        
<a href="https://github.com/lehy/ocaml-sklearn/" title="Go to repository" class="md-source">
  <div class="md-source__icon md-icon">
    
    <svg xmlns="http://www.w3.org/2000/svg" viewBox="0 0 448 512"><path d="M439.55 236.05L244 40.45a28.87 28.87 0 00-40.81 0l-40.66 40.63 51.52 51.52c27.06-9.14 52.68 16.77 43.39 43.68l49.66 49.66c34.23-11.8 61.18 31 35.47 56.69-26.49 26.49-70.21-2.87-56-37.34L240.22 199v121.85c25.3 12.54 22.26 41.85 9.08 55a34.34 34.34 0 01-48.55 0c-17.57-17.6-11.07-46.91 11.25-56v-123c-20.8-8.51-24.6-30.74-18.64-45L142.57 101 8.45 235.14a28.86 28.86 0 000 40.81l195.61 195.6a28.86 28.86 0 0040.8 0l194.69-194.69a28.86 28.86 0 000-40.81z"/></svg>
  </div>
  <div class="md-source__repository">
    lehy/ocaml-sklearn
  </div>
</a>
      </div>
    
  </nav>
</header>
    
    <div class="md-container" data-md-component="container">
      
        
      
      
        
          

  

<nav class="md-tabs md-tabs--active" aria-label="Tabs" data-md-component="tabs">
  <div class="md-tabs__inner md-grid">
    <ul class="md-tabs__list">
      
        
  <li class="md-tabs__item">
    
      <a href="../.." class="md-tabs__link">
        Home
      </a>
    
  </li>

      
        
  
  
    <li class="md-tabs__item">
      
        <a href="../../np/" class="md-tabs__link">
          Np
        </a>
      
    </li>
  

      
        
  
  
    <li class="md-tabs__item">
      
        <a href="../../scipy/" class="md-tabs__link">
          Scipy
        </a>
      
    </li>
  

      
        
  
  
    <li class="md-tabs__item">
      
        <a href="../Base/" class="md-tabs__link md-tabs__link--active">
          Sklearn
        </a>
      
    </li>
  

      
    </ul>
  </div>
</nav>
        
      
      <main class="md-main" data-md-component="main">
        <div class="md-main__inner md-grid">
          
            
              <div class="md-sidebar md-sidebar--primary" data-md-component="navigation">
                <div class="md-sidebar__scrollwrap">
                  <div class="md-sidebar__inner">
                    <nav class="md-nav md-nav--primary" aria-label="Navigation" data-md-level="0">
  <label class="md-nav__title" for="__drawer">
    <a href="../.." title="OCaml scikit-learn interface" class="md-nav__button md-logo" aria-label="OCaml scikit-learn interface">
      
  
  <svg xmlns="http://www.w3.org/2000/svg" viewBox="0 0 24 24"><path d="M12 8a3 3 0 003-3 3 3 0 00-3-3 3 3 0 00-3 3 3 3 0 003 3m0 3.54C9.64 9.35 6.5 8 3 8v11c3.5 0 6.64 1.35 9 3.54 2.36-2.19 5.5-3.54 9-3.54V8c-3.5 0-6.64 1.35-9 3.54z"/></svg>

    </a>
    OCaml scikit-learn interface
  </label>
  
    <div class="md-nav__source">
      
<a href="https://github.com/lehy/ocaml-sklearn/" title="Go to repository" class="md-source">
  <div class="md-source__icon md-icon">
    
    <svg xmlns="http://www.w3.org/2000/svg" viewBox="0 0 448 512"><path d="M439.55 236.05L244 40.45a28.87 28.87 0 00-40.81 0l-40.66 40.63 51.52 51.52c27.06-9.14 52.68 16.77 43.39 43.68l49.66 49.66c34.23-11.8 61.18 31 35.47 56.69-26.49 26.49-70.21-2.87-56-37.34L240.22 199v121.85c25.3 12.54 22.26 41.85 9.08 55a34.34 34.34 0 01-48.55 0c-17.57-17.6-11.07-46.91 11.25-56v-123c-20.8-8.51-24.6-30.74-18.64-45L142.57 101 8.45 235.14a28.86 28.86 0 000 40.81l195.61 195.6a28.86 28.86 0 0040.8 0l194.69-194.69a28.86 28.86 0 000-40.81z"/></svg>
  </div>
  <div class="md-source__repository">
    lehy/ocaml-sklearn
  </div>
</a>
    </div>
  
  <ul class="md-nav__list" data-md-scrollfix>
    
      
      
      


  <li class="md-nav__item">
    <a href="../.." title="Home" class="md-nav__link">
      Home
    </a>
  </li>

    
      
      
      


  <li class="md-nav__item md-nav__item--nested">
    
      <input class="md-nav__toggle md-toggle" data-md-toggle="nav-2" type="checkbox" id="nav-2">
    
    <label class="md-nav__link" for="nav-2">
      Np
      <span class="md-nav__icon md-icon">
        <svg xmlns="http://www.w3.org/2000/svg" viewBox="0 0 24 24"><path d="M8.59 16.58L13.17 12 8.59 7.41 10 6l6 6-6 6-1.41-1.42z"/></svg>
      </span>
    </label>
    <nav class="md-nav" aria-label="Np" data-md-level="1">
      <label class="md-nav__title" for="nav-2">
        <span class="md-nav__icon md-icon">
          <svg xmlns="http://www.w3.org/2000/svg" viewBox="0 0 24 24"><path d="M20 11v2H8l5.5 5.5-1.42 1.42L4.16 12l7.92-7.92L13.5 5.5 8 11h12z"/></svg>
        </span>
        Np
      </label>
      <ul class="md-nav__list" data-md-scrollfix>
        
        
          
          
          


  <li class="md-nav__item">
    <a href="../../np/" title="Numpy for OCaml" class="md-nav__link">
      Numpy for OCaml
    </a>
  </li>

        
          
          
          


  <li class="md-nav__item">
    <a href="../../np/Numpy/" title="Numpy" class="md-nav__link">
      Numpy
    </a>
  </li>

        
          
          
          


  <li class="md-nav__item">
    <a href="../../np/NumpyRaw/" title="NumpyRaw" class="md-nav__link">
      NumpyRaw
    </a>
  </li>

        
          
          
          


  <li class="md-nav__item">
    <a href="../../np/PyList/" title="PyList" class="md-nav__link">
      PyList
    </a>
  </li>

        
          
          
          


  <li class="md-nav__item">
    <a href="../../np/dtype/" title="Dtype" class="md-nav__link">
      Dtype
    </a>
  </li>

        
          
          
          


  <li class="md-nav__item">
    <a href="../../np/obj/" title="Obj" class="md-nav__link">
      Obj
    </a>
  </li>

        
      </ul>
    </nav>
  </li>

    
      
      
      


  <li class="md-nav__item md-nav__item--nested">
    
      <input class="md-nav__toggle md-toggle" data-md-toggle="nav-3" type="checkbox" id="nav-3">
    
    <label class="md-nav__link" for="nav-3">
      Scipy
      <span class="md-nav__icon md-icon">
        <svg xmlns="http://www.w3.org/2000/svg" viewBox="0 0 24 24"><path d="M8.59 16.58L13.17 12 8.59 7.41 10 6l6 6-6 6-1.41-1.42z"/></svg>
      </span>
    </label>
    <nav class="md-nav" aria-label="Scipy" data-md-level="1">
      <label class="md-nav__title" for="nav-3">
        <span class="md-nav__icon md-icon">
          <svg xmlns="http://www.w3.org/2000/svg" viewBox="0 0 24 24"><path d="M20 11v2H8l5.5 5.5-1.42 1.42L4.16 12l7.92-7.92L13.5 5.5 8 11h12z"/></svg>
        </span>
        Scipy
      </label>
      <ul class="md-nav__list" data-md-scrollfix>
        
        
          
          
          


  <li class="md-nav__item">
    <a href="../../scipy/" title="SciPy library for OCaml" class="md-nav__link">
      SciPy library for OCaml
    </a>
  </li>

        
          
          
          


  <li class="md-nav__item">
    <a href="../../scipy/Cluster/" title="Cluster" class="md-nav__link">
      Cluster
    </a>
  </li>

        
          
          
          


  <li class="md-nav__item">
    <a href="../../scipy/Conftest/" title="Conftest" class="md-nav__link">
      Conftest
    </a>
  </li>

        
          
          
          


  <li class="md-nav__item">
    <a href="../../scipy/Constants/" title="Constants" class="md-nav__link">
      Constants
    </a>
  </li>

        
          
          
          


  <li class="md-nav__item">
    <a href="../../scipy/Fft/" title="Fft" class="md-nav__link">
      Fft
    </a>
  </li>

        
          
          
          


  <li class="md-nav__item">
    <a href="../../scipy/Fftpack/" title="Fftpack" class="md-nav__link">
      Fftpack
    </a>
  </li>

        
          
          
          


  <li class="md-nav__item">
    <a href="../../scipy/Integrate/" title="Integrate" class="md-nav__link">
      Integrate
    </a>
  </li>

        
          
          
          


  <li class="md-nav__item">
    <a href="../../scipy/Interpolate/" title="Interpolate" class="md-nav__link">
      Interpolate
    </a>
  </li>

        
          
          
          


  <li class="md-nav__item">
    <a href="../../scipy/Io/" title="Io" class="md-nav__link">
      Io
    </a>
  </li>

        
          
          
          


  <li class="md-nav__item">
    <a href="../../scipy/Linalg/" title="Linalg" class="md-nav__link">
      Linalg
    </a>
  </li>

        
          
          
          


  <li class="md-nav__item">
    <a href="../../scipy/Misc/" title="Misc" class="md-nav__link">
      Misc
    </a>
  </li>

        
          
          
          


  <li class="md-nav__item">
    <a href="../../scipy/Ndimage/" title="Ndimage" class="md-nav__link">
      Ndimage
    </a>
  </li>

        
          
          
          


  <li class="md-nav__item">
    <a href="../../scipy/Odr/" title="Odr" class="md-nav__link">
      Odr
    </a>
  </li>

        
          
          
          


  <li class="md-nav__item">
    <a href="../../scipy/Optimize/" title="Optimize" class="md-nav__link">
      Optimize
    </a>
  </li>

        
          
          
          


  <li class="md-nav__item">
    <a href="../../scipy/Setup/" title="Setup" class="md-nav__link">
      Setup
    </a>
  </li>

        
          
          
          


  <li class="md-nav__item">
    <a href="../../scipy/Signal/" title="Signal" class="md-nav__link">
      Signal
    </a>
  </li>

        
          
          
          


  <li class="md-nav__item">
    <a href="../../scipy/Sparse/" title="Sparse" class="md-nav__link">
      Sparse
    </a>
  </li>

        
          
          
          


  <li class="md-nav__item">
    <a href="../../scipy/Spatial/" title="Spatial" class="md-nav__link">
      Spatial
    </a>
  </li>

        
          
          
          


  <li class="md-nav__item">
    <a href="../../scipy/Special/" title="Special" class="md-nav__link">
      Special
    </a>
  </li>

        
          
          
          


  <li class="md-nav__item">
    <a href="../../scipy/Stats/" title="Stats" class="md-nav__link">
      Stats
    </a>
  </li>

        
          
          
          


  <li class="md-nav__item">
    <a href="../../scipy/Version/" title="Version" class="md-nav__link">
      Version
    </a>
  </li>

        
          
          
          


  <li class="md-nav__item">
    <a href="../../scipy/wrap_version/" title="Wrap version" class="md-nav__link">
      Wrap version
    </a>
  </li>

        
      </ul>
    </nav>
  </li>

    
      
      
      

  


  <li class="md-nav__item md-nav__item--active md-nav__item--nested">
    
      <input class="md-nav__toggle md-toggle" data-md-toggle="nav-4" type="checkbox" id="nav-4" checked>
    
    <label class="md-nav__link" for="nav-4">
      Sklearn
      <span class="md-nav__icon md-icon">
        <svg xmlns="http://www.w3.org/2000/svg" viewBox="0 0 24 24"><path d="M8.59 16.58L13.17 12 8.59 7.41 10 6l6 6-6 6-1.41-1.42z"/></svg>
      </span>
    </label>
    <nav class="md-nav" aria-label="Sklearn" data-md-level="1">
      <label class="md-nav__title" for="nav-4">
        <span class="md-nav__icon md-icon">
          <svg xmlns="http://www.w3.org/2000/svg" viewBox="0 0 24 24"><path d="M20 11v2H8l5.5 5.5-1.42 1.42L4.16 12l7.92-7.92L13.5 5.5 8 11h12z"/></svg>
        </span>
        Sklearn
      </label>
      <ul class="md-nav__list" data-md-scrollfix>
        
        
          
          
          


  <li class="md-nav__item">
    <a href="../Base/" title="Base" class="md-nav__link">
      Base
    </a>
  </li>

        
          
          
          


  <li class="md-nav__item">
    <a href="../Calibration/" title="Calibration" class="md-nav__link">
      Calibration
    </a>
  </li>

        
          
          
          


  <li class="md-nav__item">
    <a href="../Cluster/" title="Cluster" class="md-nav__link">
      Cluster
    </a>
  </li>

        
          
          
          


  <li class="md-nav__item">
    <a href="../Compose/" title="Compose" class="md-nav__link">
      Compose
    </a>
  </li>

        
          
          
          


  <li class="md-nav__item">
    <a href="../Conftest/" title="Conftest" class="md-nav__link">
      Conftest
    </a>
  </li>

        
          
          
          


  <li class="md-nav__item">
    <a href="../Covariance/" title="Covariance" class="md-nav__link">
      Covariance
    </a>
  </li>

        
          
          
          


  <li class="md-nav__item">
    <a href="../Cross_decomposition/" title="Cross decomposition" class="md-nav__link">
      Cross decomposition
    </a>
  </li>

        
          
          
          


  <li class="md-nav__item">
    <a href="../Datasets/" title="Datasets" class="md-nav__link">
      Datasets
    </a>
  </li>

        
          
          
          


  <li class="md-nav__item">
    <a href="../Decomposition/" title="Decomposition" class="md-nav__link">
      Decomposition
    </a>
  </li>

        
          
          
          


  <li class="md-nav__item">
    <a href="../Discriminant_analysis/" title="Discriminant analysis" class="md-nav__link">
      Discriminant analysis
    </a>
  </li>

        
          
          
          


  <li class="md-nav__item">
    <a href="../Dummy/" title="Dummy" class="md-nav__link">
      Dummy
    </a>
  </li>

        
          
          
          


  <li class="md-nav__item">
    <a href="../Ensemble/" title="Ensemble" class="md-nav__link">
      Ensemble
    </a>
  </li>

        
          
          
          


  <li class="md-nav__item">
    <a href="../Exceptions/" title="Exceptions" class="md-nav__link">
      Exceptions
    </a>
  </li>

        
          
          
          


  <li class="md-nav__item">
    <a href="../Experimental/" title="Experimental" class="md-nav__link">
      Experimental
    </a>
  </li>

        
          
          
          


  <li class="md-nav__item">
    <a href="../Externals/" title="Externals" class="md-nav__link">
      Externals
    </a>
  </li>

        
          
          
          


  <li class="md-nav__item">
    <a href="../Feature_extraction/" title="Feature extraction" class="md-nav__link">
      Feature extraction
    </a>
  </li>

        
          
          
          


  <li class="md-nav__item">
    <a href="../Feature_selection/" title="Feature selection" class="md-nav__link">
      Feature selection
    </a>
  </li>

        
          
          
          


  <li class="md-nav__item">
    <a href="../Gaussian_process/" title="Gaussian process" class="md-nav__link">
      Gaussian process
    </a>
  </li>

        
          
          
          


  <li class="md-nav__item">
    <a href="../Impute/" title="Impute" class="md-nav__link">
      Impute
    </a>
  </li>

        
          
          
          


  <li class="md-nav__item">
    <a href="../Inspection/" title="Inspection" class="md-nav__link">
      Inspection
    </a>
  </li>

        
          
          
          


  <li class="md-nav__item">
    <a href="../Isotonic/" title="Isotonic" class="md-nav__link">
      Isotonic
    </a>
  </li>

        
          
          
          


  <li class="md-nav__item">
    <a href="../Kernel_approximation/" title="Kernel approximation" class="md-nav__link">
      Kernel approximation
    </a>
  </li>

        
          
          
          


  <li class="md-nav__item">
    <a href="../Kernel_ridge/" title="Kernel ridge" class="md-nav__link">
      Kernel ridge
    </a>
  </li>

        
          
          
          

  


  <li class="md-nav__item md-nav__item--active">
    
    <input class="md-nav__toggle md-toggle" data-md-toggle="toc" type="checkbox" id="__toc">
    
      
    
    
    <a href="./" title="Linear model" class="md-nav__link md-nav__link--active">
      Linear model
    </a>
    
  </li>

        
          
          
          


  <li class="md-nav__item">
    <a href="../Manifold/" title="Manifold" class="md-nav__link">
      Manifold
    </a>
  </li>

        
          
          
          


  <li class="md-nav__item">
    <a href="../Metrics/" title="Metrics" class="md-nav__link">
      Metrics
    </a>
  </li>

        
          
          
          


  <li class="md-nav__item">
    <a href="../Mixture/" title="Mixture" class="md-nav__link">
      Mixture
    </a>
  </li>

        
          
          
          


  <li class="md-nav__item">
    <a href="../Model_selection/" title="Model selection" class="md-nav__link">
      Model selection
    </a>
  </li>

        
          
          
          


  <li class="md-nav__item">
    <a href="../Multiclass/" title="Multiclass" class="md-nav__link">
      Multiclass
    </a>
  </li>

        
          
          
          


  <li class="md-nav__item">
    <a href="../Multioutput/" title="Multioutput" class="md-nav__link">
      Multioutput
    </a>
  </li>

        
          
          
          


  <li class="md-nav__item">
    <a href="../Naive_bayes/" title="Naive bayes" class="md-nav__link">
      Naive bayes
    </a>
  </li>

        
          
          
          


  <li class="md-nav__item">
    <a href="../Neighbors/" title="Neighbors" class="md-nav__link">
      Neighbors
    </a>
  </li>

        
          
          
          


  <li class="md-nav__item">
    <a href="../Neural_network/" title="Neural network" class="md-nav__link">
      Neural network
    </a>
  </li>

        
          
          
          


  <li class="md-nav__item">
    <a href="../Pipeline/" title="Pipeline" class="md-nav__link">
      Pipeline
    </a>
  </li>

        
          
          
          


  <li class="md-nav__item">
    <a href="../Preprocessing/" title="Preprocessing" class="md-nav__link">
      Preprocessing
    </a>
  </li>

        
          
          
          


  <li class="md-nav__item">
    <a href="../Random_projection/" title="Random projection" class="md-nav__link">
      Random projection
    </a>
  </li>

        
          
          
          


  <li class="md-nav__item">
    <a href="../Semi_supervised/" title="Semi supervised" class="md-nav__link">
      Semi supervised
    </a>
  </li>

        
          
          
          


  <li class="md-nav__item">
    <a href="../Setup/" title="Setup" class="md-nav__link">
      Setup
    </a>
  </li>

        
          
          
          


  <li class="md-nav__item">
    <a href="../Svm/" title="Svm" class="md-nav__link">
      Svm
    </a>
  </li>

        
          
          
          


  <li class="md-nav__item">
    <a href="../Tests/" title="Tests" class="md-nav__link">
      Tests
    </a>
  </li>

        
          
          
          


  <li class="md-nav__item">
    <a href="../Tree/" title="Tree" class="md-nav__link">
      Tree
    </a>
  </li>

        
          
          
          


  <li class="md-nav__item">
    <a href="../Utils/" title="Utils" class="md-nav__link">
      Utils
    </a>
  </li>

        
          
          
          


  <li class="md-nav__item">
    <a href="../arr/" title="Arr" class="md-nav__link">
      Arr
    </a>
  </li>

        
          
          
          


  <li class="md-nav__item">
    <a href="../dict/" title="Dict" class="md-nav__link">
      Dict
    </a>
  </li>

        
          
          
          


  <li class="md-nav__item">
    <a href="../wrap_version/" title="Wrap version" class="md-nav__link">
      Wrap version
    </a>
  </li>

        
      </ul>
    </nav>
  </li>

    
  </ul>
</nav>
                  </div>
                </div>
              </div>
            
            
              <div class="md-sidebar md-sidebar--secondary" data-md-component="toc">
                <div class="md-sidebar__scrollwrap">
                  <div class="md-sidebar__inner">
                    
<nav class="md-nav md-nav--secondary" aria-label="Table of contents">
  
  
    
  
  
</nav>
                  </div>
                </div>
              </div>
            
          
          <div class="md-content">
            <article class="md-content__inner md-typeset">
              
                
                  <a href="https://github.com/lehy/ocaml-sklearn/edit/master/docs/sklearn/Linear_model.md" title="Edit this page" class="md-content__button md-icon">
                    <svg xmlns="http://www.w3.org/2000/svg" viewBox="0 0 24 24"><path d="M20.71 7.04c.39-.39.39-1.04 0-1.41l-2.34-2.34c-.37-.39-1.02-.39-1.41 0l-1.84 1.83 3.75 3.75M3 17.25V21h3.75L17.81 9.93l-3.75-3.75L3 17.25z"/></svg>
                  </a>
                
                
                  
                
                
                <p>Get an attribute of this module as a Py.Object.t.
This is useful to pass a Python function to another function.</p>
<div class="highlight"><pre><span></span><code><span class="k">val</span> <span class="n">get_py</span> <span class="o">:</span> <span class="kt">string</span> <span class="o">-&gt;</span> <span class="nn">Py</span><span class="p">.</span><span class="nn">Object</span><span class="p">.</span><span class="n">t</span>

<span class="k">module</span> <span class="nc">ARDRegression</span> <span class="o">:</span> <span class="k">sig</span>
<span class="k">type</span> <span class="n">tag</span> <span class="o">=</span> <span class="o">[`</span><span class="nc">ARDRegression</span><span class="o">]</span>
<span class="k">type</span> <span class="n">t</span> <span class="o">=</span> <span class="o">[`</span><span class="nc">ARDRegression</span> <span class="o">|</span> <span class="o">`</span><span class="nc">BaseEstimator</span> <span class="o">|</span> <span class="o">`</span><span class="nc">Object</span> <span class="o">|</span> <span class="o">`</span><span class="nc">RegressorMixin</span><span class="o">]</span> <span class="nn">Obj</span><span class="p">.</span><span class="n">t</span>
<span class="k">val</span> <span class="n">of_pyobject</span> <span class="o">:</span> <span class="nn">Py</span><span class="p">.</span><span class="nn">Object</span><span class="p">.</span><span class="n">t</span> <span class="o">-&gt;</span> <span class="n">t</span>
<span class="k">val</span> <span class="n">to_pyobject</span> <span class="o">:</span> <span class="o">[&gt;</span> <span class="n">tag</span><span class="o">]</span> <span class="nn">Obj</span><span class="p">.</span><span class="n">t</span> <span class="o">-&gt;</span> <span class="nn">Py</span><span class="p">.</span><span class="nn">Object</span><span class="p">.</span><span class="n">t</span>

<span class="k">val</span> <span class="n">as_regressor</span> <span class="o">:</span> <span class="n">t</span> <span class="o">-&gt;</span> <span class="o">[`</span><span class="nc">RegressorMixin</span><span class="o">]</span> <span class="nn">Obj</span><span class="p">.</span><span class="n">t</span>
<span class="k">val</span> <span class="n">as_estimator</span> <span class="o">:</span> <span class="n">t</span> <span class="o">-&gt;</span> <span class="o">[`</span><span class="nc">BaseEstimator</span><span class="o">]</span> <span class="nn">Obj</span><span class="p">.</span><span class="n">t</span>
<span class="k">val</span> <span class="n">create</span> <span class="o">:</span> <span class="o">?</span><span class="n">n_iter</span><span class="o">:</span><span class="kt">int</span> <span class="o">-&gt;</span> <span class="o">?</span><span class="n">tol</span><span class="o">:</span><span class="kt">float</span> <span class="o">-&gt;</span> <span class="o">?</span><span class="n">alpha_1</span><span class="o">:</span><span class="kt">float</span> <span class="o">-&gt;</span> <span class="o">?</span><span class="n">alpha_2</span><span class="o">:</span><span class="kt">float</span> <span class="o">-&gt;</span> <span class="o">?</span><span class="n">lambda_1</span><span class="o">:</span><span class="kt">float</span> <span class="o">-&gt;</span> <span class="o">?</span><span class="n">lambda_2</span><span class="o">:</span><span class="kt">float</span> <span class="o">-&gt;</span> <span class="o">?</span><span class="n">compute_score</span><span class="o">:</span><span class="kt">bool</span> <span class="o">-&gt;</span> <span class="o">?</span><span class="n">threshold_lambda</span><span class="o">:</span><span class="kt">float</span> <span class="o">-&gt;</span> <span class="o">?</span><span class="n">fit_intercept</span><span class="o">:</span><span class="kt">bool</span> <span class="o">-&gt;</span> <span class="o">?</span><span class="n">normalize</span><span class="o">:</span><span class="kt">bool</span> <span class="o">-&gt;</span> <span class="o">?</span><span class="n">copy_X</span><span class="o">:</span><span class="kt">bool</span> <span class="o">-&gt;</span> <span class="o">?</span><span class="n">verbose</span><span class="o">:</span><span class="kt">int</span> <span class="o">-&gt;</span> <span class="kt">unit</span> <span class="o">-&gt;</span> <span class="n">t</span>
</code></pre></div>

<p>Bayesian ARD regression.</p>
<p>Fit the weights of a regression model, using an ARD prior. The weights of
the regression model are assumed to be in Gaussian distributions.
Also estimate the parameters lambda (precisions of the distributions of the
weights) and alpha (precision of the distribution of the noise).
The estimation is done by an iterative procedures (Evidence Maximization)</p>
<p>Read more in the :ref:<code>User Guide &lt;bayesian_regression&gt;</code>.</p>
<h2 id="parameters">Parameters<a class="headerlink" href="#parameters" title="Permanent link">&para;</a></h2>
<p>n_iter : int, default=300
Maximum number of iterations.</p>
<p>tol : float, default=1e-3
Stop the algorithm if w has converged.</p>
<p>alpha_1 : float, default=1e-6
Hyper-parameter : shape parameter for the Gamma distribution prior
over the alpha parameter.</p>
<p>alpha_2 : float, default=1e-6
Hyper-parameter : inverse scale parameter (rate parameter) for the
Gamma distribution prior over the alpha parameter.</p>
<p>lambda_1 : float, default=1e-6
Hyper-parameter : shape parameter for the Gamma distribution prior
over the lambda parameter.</p>
<p>lambda_2 : float, default=1e-6
Hyper-parameter : inverse scale parameter (rate parameter) for the
Gamma distribution prior over the lambda parameter.</p>
<p>compute_score : bool, default=False
If True, compute the objective function at each step of the model.</p>
<p>threshold_lambda : float, default=10 000
threshold for removing (pruning) weights with high precision from
the computation.</p>
<p>fit_intercept : bool, default=True
whether to calculate the intercept for this model. If set
to false, no intercept will be used in calculations
(i.e. data is expected to be centered).</p>
<p>normalize : bool, default=False
This parameter is ignored when <code>fit_intercept</code> is set to False.
If True, the regressors X will be normalized before regression by
subtracting the mean and dividing by the l2-norm.
If you wish to standardize, please use
:class:<code>sklearn.preprocessing.StandardScaler</code> before calling <code>fit</code>
on an estimator with <code>normalize=False</code>.</p>
<p>copy_X : bool, default=True
If True, X will be copied; else, it may be overwritten.</p>
<p>verbose : bool, default=False
Verbose mode when fitting the model.</p>
<h2 id="attributes">Attributes<a class="headerlink" href="#attributes" title="Permanent link">&para;</a></h2>
<p>coef_ : array-like of shape (n_features,)
Coefficients of the regression model (mean of distribution)</p>
<p>alpha_ : float
estimated precision of the noise.</p>
<p>lambda_ : array-like of shape (n_features,)
estimated precisions of the weights.</p>
<p>sigma_ : array-like of shape (n_features, n_features)
estimated variance-covariance matrix of the weights</p>
<p>scores_ : float
if computed, value of the objective function (to be maximized)</p>
<p>intercept_ : float
Independent term in decision function. Set to 0.0 if
<code>fit_intercept = False</code>.</p>
<h2 id="examples">Examples<a class="headerlink" href="#examples" title="Permanent link">&para;</a></h2>
<blockquote>
<blockquote>
<blockquote>
<p>from sklearn import linear_model
clf = linear_model.ARDRegression()
clf.fit([[0,0], [1, 1], [2, 2]], [0, 1, 2])
ARDRegression()
clf.predict([[1, 1]])
array([1.])</p>
</blockquote>
</blockquote>
</blockquote>
<h2 id="notes">Notes<a class="headerlink" href="#notes" title="Permanent link">&para;</a></h2>
<p>For an example, see :ref:<code>examples/linear_model/plot_ard.py
&lt;sphx_glr_auto_examples_linear_model_plot_ard.py&gt;</code>.</p>
<h2 id="references">References<a class="headerlink" href="#references" title="Permanent link">&para;</a></h2>
<p>D. J. C. MacKay, Bayesian nonlinear modeling for the prediction
competition, ASHRAE Transactions, 1994.</p>
<p>R. Salakhutdinov, Lecture notes on Statistical Machine Learning,
http://www.utstat.toronto.edu/~rsalakhu/sta4273/notes/Lecture2.pdf#page=15
Their beta is our <code>self.alpha_</code>
Their alpha is our <code>self.lambda_</code>
ARD is a little different than the slide: only dimensions/features for
which <code>self.lambda_ &lt; self.threshold_lambda</code> are kept and the rest are
discarded.</p>
<div class="highlight"><pre><span></span><code><span class="k">val</span> <span class="n">fit</span> <span class="o">:</span> <span class="n">x</span><span class="o">:[&gt;`</span><span class="nc">ArrayLike</span><span class="o">]</span> <span class="nn">Np</span><span class="p">.</span><span class="nn">Obj</span><span class="p">.</span><span class="n">t</span> <span class="o">-&gt;</span> <span class="n">y</span><span class="o">:[&gt;`</span><span class="nc">ArrayLike</span><span class="o">]</span> <span class="nn">Np</span><span class="p">.</span><span class="nn">Obj</span><span class="p">.</span><span class="n">t</span> <span class="o">-&gt;</span> <span class="o">[&gt;</span> <span class="n">tag</span><span class="o">]</span> <span class="nn">Obj</span><span class="p">.</span><span class="n">t</span> <span class="o">-&gt;</span> <span class="n">t</span>
</code></pre></div>

<p>Fit the ARDRegression model according to the given training data
and parameters.</p>
<p>Iterative procedure to maximize the evidence</p>
<h2 id="parameters_1">Parameters<a class="headerlink" href="#parameters_1" title="Permanent link">&para;</a></h2>
<p>X : array-like of shape (n_samples, n_features)
Training vector, where n_samples in the number of samples and
n_features is the number of features.
y : array-like of shape (n_samples,)
Target values (integers). Will be cast to X's dtype if necessary</p>
<h2 id="returns">Returns<a class="headerlink" href="#returns" title="Permanent link">&para;</a></h2>
<p>self : returns an instance of self.</p>
<div class="highlight"><pre><span></span><code><span class="k">val</span> <span class="n">get_params</span> <span class="o">:</span> <span class="o">?</span><span class="n">deep</span><span class="o">:</span><span class="kt">bool</span> <span class="o">-&gt;</span> <span class="o">[&gt;</span> <span class="n">tag</span><span class="o">]</span> <span class="nn">Obj</span><span class="p">.</span><span class="n">t</span> <span class="o">-&gt;</span> <span class="nn">Dict</span><span class="p">.</span><span class="n">t</span>
</code></pre></div>

<p>Get parameters for this estimator.</p>
<h2 id="parameters_2">Parameters<a class="headerlink" href="#parameters_2" title="Permanent link">&para;</a></h2>
<p>deep : bool, default=True
If True, will return the parameters for this estimator and
contained subobjects that are estimators.</p>
<h2 id="returns_1">Returns<a class="headerlink" href="#returns_1" title="Permanent link">&para;</a></h2>
<p>params : mapping of string to any
Parameter names mapped to their values.</p>
<div class="highlight"><pre><span></span><code><span class="k">val</span> <span class="n">predict</span> <span class="o">:</span> <span class="o">?</span><span class="n">return_std</span><span class="o">:</span><span class="kt">bool</span> <span class="o">-&gt;</span> <span class="n">x</span><span class="o">:[&gt;`</span><span class="nc">ArrayLike</span><span class="o">]</span> <span class="nn">Np</span><span class="p">.</span><span class="nn">Obj</span><span class="p">.</span><span class="n">t</span> <span class="o">-&gt;</span> <span class="o">[&gt;</span> <span class="n">tag</span><span class="o">]</span> <span class="nn">Obj</span><span class="p">.</span><span class="n">t</span> <span class="o">-&gt;</span> <span class="o">[&gt;`</span><span class="nc">ArrayLike</span><span class="o">]</span> <span class="nn">Np</span><span class="p">.</span><span class="nn">Obj</span><span class="p">.</span><span class="n">t</span>
</code></pre></div>

<p>Predict using the linear model.</p>
<p>In addition to the mean of the predictive distribution, also its
standard deviation can be returned.</p>
<h2 id="parameters_3">Parameters<a class="headerlink" href="#parameters_3" title="Permanent link">&para;</a></h2>
<p>X : {array-like, sparse matrix} of shape (n_samples, n_features)
Samples.</p>
<p>return_std : bool, default=False
Whether to return the standard deviation of posterior prediction.</p>
<h2 id="returns_2">Returns<a class="headerlink" href="#returns_2" title="Permanent link">&para;</a></h2>
<p>y_mean : array-like of shape (n_samples,)
Mean of predictive distribution of query points.</p>
<p>y_std : array-like of shape (n_samples,)
Standard deviation of predictive distribution of query points.</p>
<div class="highlight"><pre><span></span><code><span class="k">val</span> <span class="n">score</span> <span class="o">:</span> <span class="o">?</span><span class="n">sample_weight</span><span class="o">:[&gt;`</span><span class="nc">ArrayLike</span><span class="o">]</span> <span class="nn">Np</span><span class="p">.</span><span class="nn">Obj</span><span class="p">.</span><span class="n">t</span> <span class="o">-&gt;</span> <span class="n">x</span><span class="o">:[&gt;`</span><span class="nc">ArrayLike</span><span class="o">]</span> <span class="nn">Np</span><span class="p">.</span><span class="nn">Obj</span><span class="p">.</span><span class="n">t</span> <span class="o">-&gt;</span> <span class="n">y</span><span class="o">:[&gt;`</span><span class="nc">ArrayLike</span><span class="o">]</span> <span class="nn">Np</span><span class="p">.</span><span class="nn">Obj</span><span class="p">.</span><span class="n">t</span> <span class="o">-&gt;</span> <span class="o">[&gt;</span> <span class="n">tag</span><span class="o">]</span> <span class="nn">Obj</span><span class="p">.</span><span class="n">t</span> <span class="o">-&gt;</span> <span class="kt">float</span>
</code></pre></div>

<p>Return the coefficient of determination R^2 of the prediction.</p>
<p>The coefficient R^2 is defined as (1 - u/v), where u is the residual
sum of squares ((y_true - y_pred) <strong> 2).sum() and v is the total
sum of squares ((y_true - y_true.mean()) </strong> 2).sum().
The best possible score is 1.0 and it can be negative (because the
model can be arbitrarily worse). A constant model that always
predicts the expected value of y, disregarding the input features,
would get a R^2 score of 0.0.</p>
<h2 id="parameters_4">Parameters<a class="headerlink" href="#parameters_4" title="Permanent link">&para;</a></h2>
<p>X : array-like of shape (n_samples, n_features)
Test samples. For some estimators this may be a
precomputed kernel matrix or a list of generic objects instead,
shape = (n_samples, n_samples_fitted),
where n_samples_fitted is the number of
samples used in the fitting for the estimator.</p>
<p>y : array-like of shape (n_samples,) or (n_samples, n_outputs)
True values for X.</p>
<p>sample_weight : array-like of shape (n_samples,), default=None
Sample weights.</p>
<h2 id="returns_3">Returns<a class="headerlink" href="#returns_3" title="Permanent link">&para;</a></h2>
<p>score : float
R^2 of self.predict(X) wrt. y.</p>
<h2 id="notes_1">Notes<a class="headerlink" href="#notes_1" title="Permanent link">&para;</a></h2>
<p>The R2 score used when calling <code>score</code> on a regressor will use
<code>multioutput='uniform_average'</code> from version 0.23 to keep consistent
with :func:<code>~sklearn.metrics.r2_score</code>. This will influence the
<code>score</code> method of all the multioutput regressors (except for
:class:<code>~sklearn.multioutput.MultiOutputRegressor</code>). To specify the
default value manually and avoid the warning, please either call
:func:<code>~sklearn.metrics.r2_score</code> directly or make a custom scorer with
:func:<code>~sklearn.metrics.make_scorer</code> (the built-in scorer <code>'r2'</code> uses
<code>multioutput='uniform_average'</code>).</p>
<div class="highlight"><pre><span></span><code><span class="k">val</span> <span class="n">set_params</span> <span class="o">:</span> <span class="o">?</span><span class="n">params</span><span class="o">:(</span><span class="kt">string</span> <span class="o">*</span> <span class="nn">Py</span><span class="p">.</span><span class="nn">Object</span><span class="p">.</span><span class="n">t</span><span class="o">)</span> <span class="kt">list</span> <span class="o">-&gt;</span> <span class="o">[&gt;</span> <span class="n">tag</span><span class="o">]</span> <span class="nn">Obj</span><span class="p">.</span><span class="n">t</span> <span class="o">-&gt;</span> <span class="n">t</span>
</code></pre></div>

<p>Set the parameters of this estimator.</p>
<p>The method works on simple estimators as well as on nested objects
(such as pipelines). The latter have parameters of the form
<code>&lt;component&gt;__&lt;parameter&gt;</code> so that it's possible to update each
component of a nested object.</p>
<h2 id="parameters_5">Parameters<a class="headerlink" href="#parameters_5" title="Permanent link">&para;</a></h2>
<p>**params : dict
Estimator parameters.</p>
<h2 id="returns_4">Returns<a class="headerlink" href="#returns_4" title="Permanent link">&para;</a></h2>
<p>self : object
Estimator instance.</p>
<p>Attribute coef_: get value or raise Not_found if None.</p>
<div class="highlight"><pre><span></span><code><span class="k">val</span> <span class="n">coef_</span> <span class="o">:</span> <span class="n">t</span> <span class="o">-&gt;</span> <span class="o">[&gt;`</span><span class="nc">ArrayLike</span><span class="o">]</span> <span class="nn">Np</span><span class="p">.</span><span class="nn">Obj</span><span class="p">.</span><span class="n">t</span>
</code></pre></div>

<p>Attribute coef_: get value as an option.</p>
<div class="highlight"><pre><span></span><code><span class="k">val</span> <span class="n">coef_opt</span> <span class="o">:</span> <span class="n">t</span> <span class="o">-&gt;</span> <span class="o">([&gt;`</span><span class="nc">ArrayLike</span><span class="o">]</span> <span class="nn">Np</span><span class="p">.</span><span class="nn">Obj</span><span class="p">.</span><span class="n">t</span><span class="o">)</span> <span class="n">option</span>
</code></pre></div>

<p>Attribute alpha_: get value or raise Not_found if None.</p>
<div class="highlight"><pre><span></span><code><span class="k">val</span> <span class="n">alpha_</span> <span class="o">:</span> <span class="n">t</span> <span class="o">-&gt;</span> <span class="kt">float</span>
</code></pre></div>

<p>Attribute alpha_: get value as an option.</p>
<div class="highlight"><pre><span></span><code><span class="k">val</span> <span class="n">alpha_opt</span> <span class="o">:</span> <span class="n">t</span> <span class="o">-&gt;</span> <span class="o">(</span><span class="kt">float</span><span class="o">)</span> <span class="n">option</span>
</code></pre></div>

<p>Attribute lambda_: get value or raise Not_found if None.</p>
<div class="highlight"><pre><span></span><code><span class="k">val</span> <span class="n">lambda_</span> <span class="o">:</span> <span class="n">t</span> <span class="o">-&gt;</span> <span class="o">[&gt;`</span><span class="nc">ArrayLike</span><span class="o">]</span> <span class="nn">Np</span><span class="p">.</span><span class="nn">Obj</span><span class="p">.</span><span class="n">t</span>
</code></pre></div>

<p>Attribute lambda_: get value as an option.</p>
<div class="highlight"><pre><span></span><code><span class="k">val</span> <span class="n">lambda_opt</span> <span class="o">:</span> <span class="n">t</span> <span class="o">-&gt;</span> <span class="o">([&gt;`</span><span class="nc">ArrayLike</span><span class="o">]</span> <span class="nn">Np</span><span class="p">.</span><span class="nn">Obj</span><span class="p">.</span><span class="n">t</span><span class="o">)</span> <span class="n">option</span>
</code></pre></div>

<p>Attribute sigma_: get value or raise Not_found if None.</p>
<div class="highlight"><pre><span></span><code><span class="k">val</span> <span class="n">sigma_</span> <span class="o">:</span> <span class="n">t</span> <span class="o">-&gt;</span> <span class="o">[&gt;`</span><span class="nc">ArrayLike</span><span class="o">]</span> <span class="nn">Np</span><span class="p">.</span><span class="nn">Obj</span><span class="p">.</span><span class="n">t</span>
</code></pre></div>

<p>Attribute sigma_: get value as an option.</p>
<div class="highlight"><pre><span></span><code><span class="k">val</span> <span class="n">sigma_opt</span> <span class="o">:</span> <span class="n">t</span> <span class="o">-&gt;</span> <span class="o">([&gt;`</span><span class="nc">ArrayLike</span><span class="o">]</span> <span class="nn">Np</span><span class="p">.</span><span class="nn">Obj</span><span class="p">.</span><span class="n">t</span><span class="o">)</span> <span class="n">option</span>
</code></pre></div>

<p>Attribute scores_: get value or raise Not_found if None.</p>
<div class="highlight"><pre><span></span><code><span class="k">val</span> <span class="n">scores_</span> <span class="o">:</span> <span class="n">t</span> <span class="o">-&gt;</span> <span class="kt">float</span>
</code></pre></div>

<p>Attribute scores_: get value as an option.</p>
<div class="highlight"><pre><span></span><code><span class="k">val</span> <span class="n">scores_opt</span> <span class="o">:</span> <span class="n">t</span> <span class="o">-&gt;</span> <span class="o">(</span><span class="kt">float</span><span class="o">)</span> <span class="n">option</span>
</code></pre></div>

<p>Attribute intercept_: get value or raise Not_found if None.</p>
<div class="highlight"><pre><span></span><code><span class="k">val</span> <span class="n">intercept_</span> <span class="o">:</span> <span class="n">t</span> <span class="o">-&gt;</span> <span class="o">[&gt;`</span><span class="nc">ArrayLike</span><span class="o">]</span> <span class="nn">Np</span><span class="p">.</span><span class="nn">Obj</span><span class="p">.</span><span class="n">t</span>
</code></pre></div>

<p>Attribute intercept_: get value as an option.</p>
<div class="highlight"><pre><span></span><code><span class="k">val</span> <span class="n">intercept_opt</span> <span class="o">:</span> <span class="n">t</span> <span class="o">-&gt;</span> <span class="o">([&gt;`</span><span class="nc">ArrayLike</span><span class="o">]</span> <span class="nn">Np</span><span class="p">.</span><span class="nn">Obj</span><span class="p">.</span><span class="n">t</span><span class="o">)</span> <span class="n">option</span>
</code></pre></div>

<p>Print the object to a human-readable representation.</p>
<div class="highlight"><pre><span></span><code><span class="k">val</span> <span class="n">to_string</span> <span class="o">:</span> <span class="n">t</span> <span class="o">-&gt;</span> <span class="kt">string</span>
</code></pre></div>

<p>Print the object to a human-readable representation.</p>
<div class="highlight"><pre><span></span><code><span class="k">val</span> <span class="n">show</span> <span class="o">:</span> <span class="n">t</span> <span class="o">-&gt;</span> <span class="kt">string</span>
</code></pre></div>

<p>Pretty-print the object to a formatter.</p>
<div class="highlight"><pre><span></span><code><span class="k">val</span> <span class="n">pp</span> <span class="o">:</span> <span class="nn">Format</span><span class="p">.</span><span class="n">formatter</span> <span class="o">-&gt;</span> <span class="n">t</span> <span class="o">-&gt;</span> <span class="kt">unit</span> <span class="o">[@@</span><span class="n">ocaml</span><span class="o">.</span><span class="n">toplevel_printer</span><span class="o">]</span>



<span class="k">module</span> <span class="nc">BayesianRidge</span> <span class="o">:</span> <span class="k">sig</span>
<span class="k">type</span> <span class="n">tag</span> <span class="o">=</span> <span class="o">[`</span><span class="nc">BayesianRidge</span><span class="o">]</span>
<span class="k">type</span> <span class="n">t</span> <span class="o">=</span> <span class="o">[`</span><span class="nc">BaseEstimator</span> <span class="o">|</span> <span class="o">`</span><span class="nc">BayesianRidge</span> <span class="o">|</span> <span class="o">`</span><span class="nc">Object</span> <span class="o">|</span> <span class="o">`</span><span class="nc">RegressorMixin</span><span class="o">]</span> <span class="nn">Obj</span><span class="p">.</span><span class="n">t</span>
<span class="k">val</span> <span class="n">of_pyobject</span> <span class="o">:</span> <span class="nn">Py</span><span class="p">.</span><span class="nn">Object</span><span class="p">.</span><span class="n">t</span> <span class="o">-&gt;</span> <span class="n">t</span>
<span class="k">val</span> <span class="n">to_pyobject</span> <span class="o">:</span> <span class="o">[&gt;</span> <span class="n">tag</span><span class="o">]</span> <span class="nn">Obj</span><span class="p">.</span><span class="n">t</span> <span class="o">-&gt;</span> <span class="nn">Py</span><span class="p">.</span><span class="nn">Object</span><span class="p">.</span><span class="n">t</span>

<span class="k">val</span> <span class="n">as_regressor</span> <span class="o">:</span> <span class="n">t</span> <span class="o">-&gt;</span> <span class="o">[`</span><span class="nc">RegressorMixin</span><span class="o">]</span> <span class="nn">Obj</span><span class="p">.</span><span class="n">t</span>
<span class="k">val</span> <span class="n">as_estimator</span> <span class="o">:</span> <span class="n">t</span> <span class="o">-&gt;</span> <span class="o">[`</span><span class="nc">BaseEstimator</span><span class="o">]</span> <span class="nn">Obj</span><span class="p">.</span><span class="n">t</span>
<span class="k">val</span> <span class="n">create</span> <span class="o">:</span> <span class="o">?</span><span class="n">n_iter</span><span class="o">:</span><span class="kt">int</span> <span class="o">-&gt;</span> <span class="o">?</span><span class="n">tol</span><span class="o">:</span><span class="kt">float</span> <span class="o">-&gt;</span> <span class="o">?</span><span class="n">alpha_1</span><span class="o">:</span><span class="kt">float</span> <span class="o">-&gt;</span> <span class="o">?</span><span class="n">alpha_2</span><span class="o">:</span><span class="kt">float</span> <span class="o">-&gt;</span> <span class="o">?</span><span class="n">lambda_1</span><span class="o">:</span><span class="kt">float</span> <span class="o">-&gt;</span> <span class="o">?</span><span class="n">lambda_2</span><span class="o">:</span><span class="kt">float</span> <span class="o">-&gt;</span> <span class="o">?</span><span class="n">alpha_init</span><span class="o">:</span><span class="kt">float</span> <span class="o">-&gt;</span> <span class="o">?</span><span class="n">lambda_init</span><span class="o">:</span><span class="kt">float</span> <span class="o">-&gt;</span> <span class="o">?</span><span class="n">compute_score</span><span class="o">:</span><span class="kt">bool</span> <span class="o">-&gt;</span> <span class="o">?</span><span class="n">fit_intercept</span><span class="o">:</span><span class="kt">bool</span> <span class="o">-&gt;</span> <span class="o">?</span><span class="n">normalize</span><span class="o">:</span><span class="kt">bool</span> <span class="o">-&gt;</span> <span class="o">?</span><span class="n">copy_X</span><span class="o">:</span><span class="kt">bool</span> <span class="o">-&gt;</span> <span class="o">?</span><span class="n">verbose</span><span class="o">:</span><span class="kt">int</span> <span class="o">-&gt;</span> <span class="kt">unit</span> <span class="o">-&gt;</span> <span class="n">t</span>
</code></pre></div>

<p>Bayesian ridge regression.</p>
<p>Fit a Bayesian ridge model. See the Notes section for details on this
implementation and the optimization of the regularization parameters
lambda (precision of the weights) and alpha (precision of the noise).</p>
<p>Read more in the :ref:<code>User Guide &lt;bayesian_regression&gt;</code>.</p>
<h2 id="parameters_6">Parameters<a class="headerlink" href="#parameters_6" title="Permanent link">&para;</a></h2>
<p>n_iter : int, default=300
Maximum number of iterations. Should be greater than or equal to 1.</p>
<p>tol : float, default=1e-3
Stop the algorithm if w has converged.</p>
<p>alpha_1 : float, default=1e-6
Hyper-parameter : shape parameter for the Gamma distribution prior
over the alpha parameter.</p>
<p>alpha_2 : float, default=1e-6
Hyper-parameter : inverse scale parameter (rate parameter) for the
Gamma distribution prior over the alpha parameter.</p>
<p>lambda_1 : float, default=1e-6
Hyper-parameter : shape parameter for the Gamma distribution prior
over the lambda parameter.</p>
<p>lambda_2 : float, default=1e-6
Hyper-parameter : inverse scale parameter (rate parameter) for the
Gamma distribution prior over the lambda parameter.</p>
<p>alpha_init : float, default=None
Initial value for alpha (precision of the noise).
If not set, alpha_init is 1/Var(y).</p>
<p>.. versionadded:: 0.22</p>
<p>lambda_init : float, default=None
Initial value for lambda (precision of the weights).
If not set, lambda_init is 1.</p>
<p>.. versionadded:: 0.22</p>
<p>compute_score : bool, default=False
If True, compute the log marginal likelihood at each iteration of the
optimization.</p>
<p>fit_intercept : bool, default=True
Whether to calculate the intercept for this model.
The intercept is not treated as a probabilistic parameter
and thus has no associated variance. If set
to False, no intercept will be used in calculations
(i.e. data is expected to be centered).</p>
<p>normalize : bool, default=False
This parameter is ignored when <code>fit_intercept</code> is set to False.
If True, the regressors X will be normalized before regression by
subtracting the mean and dividing by the l2-norm.
If you wish to standardize, please use
:class:<code>sklearn.preprocessing.StandardScaler</code> before calling <code>fit</code>
on an estimator with <code>normalize=False</code>.</p>
<p>copy_X : bool, default=True
If True, X will be copied; else, it may be overwritten.</p>
<p>verbose : bool, default=False
Verbose mode when fitting the model.</p>
<h2 id="attributes_1">Attributes<a class="headerlink" href="#attributes_1" title="Permanent link">&para;</a></h2>
<p>coef_ : array-like of shape (n_features,)
Coefficients of the regression model (mean of distribution)</p>
<p>intercept_ : float
Independent term in decision function. Set to 0.0 if
<code>fit_intercept = False</code>.</p>
<p>alpha_ : float
Estimated precision of the noise.</p>
<p>lambda_ : float
Estimated precision of the weights.</p>
<p>sigma_ : array-like of shape (n_features, n_features)
Estimated variance-covariance matrix of the weights</p>
<p>scores_ : array-like of shape (n_iter_+1,)
If computed_score is True, value of the log marginal likelihood (to be
maximized) at each iteration of the optimization. The array starts
with the value of the log marginal likelihood obtained for the initial
values of alpha and lambda and ends with the value obtained for the
estimated alpha and lambda.</p>
<p>n_iter_ : int
The actual number of iterations to reach the stopping criterion.</p>
<h2 id="examples_1">Examples<a class="headerlink" href="#examples_1" title="Permanent link">&para;</a></h2>
<blockquote>
<blockquote>
<blockquote>
<p>from sklearn import linear_model
clf = linear_model.BayesianRidge()
clf.fit([[0,0], [1, 1], [2, 2]], [0, 1, 2])
BayesianRidge()
clf.predict([[1, 1]])
array([1.])</p>
</blockquote>
</blockquote>
</blockquote>
<h2 id="notes_2">Notes<a class="headerlink" href="#notes_2" title="Permanent link">&para;</a></h2>
<p>There exist several strategies to perform Bayesian ridge regression. This
implementation is based on the algorithm described in Appendix A of
(Tipping, 2001) where updates of the regularization parameters are done as
suggested in (MacKay, 1992). Note that according to A New
View of Automatic Relevance Determination (Wipf and Nagarajan, 2008) these
update rules do not guarantee that the marginal likelihood is increasing
between two consecutive iterations of the optimization.</p>
<h2 id="references_1">References<a class="headerlink" href="#references_1" title="Permanent link">&para;</a></h2>
<p>D. J. C. MacKay, Bayesian Interpolation, Computation and Neural Systems,
Vol. 4, No. 3, 1992.</p>
<p>M. E. Tipping, Sparse Bayesian Learning and the Relevance Vector Machine,
Journal of Machine Learning Research, Vol. 1, 2001.</p>
<div class="highlight"><pre><span></span><code><span class="k">val</span> <span class="n">fit</span> <span class="o">:</span> <span class="o">?</span><span class="n">sample_weight</span><span class="o">:[&gt;`</span><span class="nc">ArrayLike</span><span class="o">]</span> <span class="nn">Np</span><span class="p">.</span><span class="nn">Obj</span><span class="p">.</span><span class="n">t</span> <span class="o">-&gt;</span> <span class="n">x</span><span class="o">:[&gt;`</span><span class="nc">ArrayLike</span><span class="o">]</span> <span class="nn">Np</span><span class="p">.</span><span class="nn">Obj</span><span class="p">.</span><span class="n">t</span> <span class="o">-&gt;</span> <span class="n">y</span><span class="o">:[&gt;`</span><span class="nc">ArrayLike</span><span class="o">]</span> <span class="nn">Np</span><span class="p">.</span><span class="nn">Obj</span><span class="p">.</span><span class="n">t</span> <span class="o">-&gt;</span> <span class="o">[&gt;</span> <span class="n">tag</span><span class="o">]</span> <span class="nn">Obj</span><span class="p">.</span><span class="n">t</span> <span class="o">-&gt;</span> <span class="n">t</span>
</code></pre></div>

<p>Fit the model</p>
<h2 id="parameters_7">Parameters<a class="headerlink" href="#parameters_7" title="Permanent link">&para;</a></h2>
<p>X : ndarray of shape (n_samples, n_features)
Training data
y : ndarray of shape (n_samples,)
Target values. Will be cast to X's dtype if necessary</p>
<p>sample_weight : ndarray of shape (n_samples,), default=None
Individual weights for each sample</p>
<p>.. versionadded:: 0.20
parameter <em>sample_weight</em> support to BayesianRidge.</p>
<h2 id="returns_5">Returns<a class="headerlink" href="#returns_5" title="Permanent link">&para;</a></h2>
<p>self : returns an instance of self.</p>
<div class="highlight"><pre><span></span><code><span class="k">val</span> <span class="n">get_params</span> <span class="o">:</span> <span class="o">?</span><span class="n">deep</span><span class="o">:</span><span class="kt">bool</span> <span class="o">-&gt;</span> <span class="o">[&gt;</span> <span class="n">tag</span><span class="o">]</span> <span class="nn">Obj</span><span class="p">.</span><span class="n">t</span> <span class="o">-&gt;</span> <span class="nn">Dict</span><span class="p">.</span><span class="n">t</span>
</code></pre></div>

<p>Get parameters for this estimator.</p>
<h2 id="parameters_8">Parameters<a class="headerlink" href="#parameters_8" title="Permanent link">&para;</a></h2>
<p>deep : bool, default=True
If True, will return the parameters for this estimator and
contained subobjects that are estimators.</p>
<h2 id="returns_6">Returns<a class="headerlink" href="#returns_6" title="Permanent link">&para;</a></h2>
<p>params : mapping of string to any
Parameter names mapped to their values.</p>
<div class="highlight"><pre><span></span><code><span class="k">val</span> <span class="n">predict</span> <span class="o">:</span> <span class="o">?</span><span class="n">return_std</span><span class="o">:</span><span class="kt">bool</span> <span class="o">-&gt;</span> <span class="n">x</span><span class="o">:[&gt;`</span><span class="nc">ArrayLike</span><span class="o">]</span> <span class="nn">Np</span><span class="p">.</span><span class="nn">Obj</span><span class="p">.</span><span class="n">t</span> <span class="o">-&gt;</span> <span class="o">[&gt;</span> <span class="n">tag</span><span class="o">]</span> <span class="nn">Obj</span><span class="p">.</span><span class="n">t</span> <span class="o">-&gt;</span> <span class="o">[&gt;`</span><span class="nc">ArrayLike</span><span class="o">]</span> <span class="nn">Np</span><span class="p">.</span><span class="nn">Obj</span><span class="p">.</span><span class="n">t</span>
</code></pre></div>

<p>Predict using the linear model.</p>
<p>In addition to the mean of the predictive distribution, also its
standard deviation can be returned.</p>
<h2 id="parameters_9">Parameters<a class="headerlink" href="#parameters_9" title="Permanent link">&para;</a></h2>
<p>X : {array-like, sparse matrix} of shape (n_samples, n_features)
Samples.</p>
<p>return_std : bool, default=False
Whether to return the standard deviation of posterior prediction.</p>
<h2 id="returns_7">Returns<a class="headerlink" href="#returns_7" title="Permanent link">&para;</a></h2>
<p>y_mean : array-like of shape (n_samples,)
Mean of predictive distribution of query points.</p>
<p>y_std : array-like of shape (n_samples,)
Standard deviation of predictive distribution of query points.</p>
<div class="highlight"><pre><span></span><code><span class="k">val</span> <span class="n">score</span> <span class="o">:</span> <span class="o">?</span><span class="n">sample_weight</span><span class="o">:[&gt;`</span><span class="nc">ArrayLike</span><span class="o">]</span> <span class="nn">Np</span><span class="p">.</span><span class="nn">Obj</span><span class="p">.</span><span class="n">t</span> <span class="o">-&gt;</span> <span class="n">x</span><span class="o">:[&gt;`</span><span class="nc">ArrayLike</span><span class="o">]</span> <span class="nn">Np</span><span class="p">.</span><span class="nn">Obj</span><span class="p">.</span><span class="n">t</span> <span class="o">-&gt;</span> <span class="n">y</span><span class="o">:[&gt;`</span><span class="nc">ArrayLike</span><span class="o">]</span> <span class="nn">Np</span><span class="p">.</span><span class="nn">Obj</span><span class="p">.</span><span class="n">t</span> <span class="o">-&gt;</span> <span class="o">[&gt;</span> <span class="n">tag</span><span class="o">]</span> <span class="nn">Obj</span><span class="p">.</span><span class="n">t</span> <span class="o">-&gt;</span> <span class="kt">float</span>
</code></pre></div>

<p>Return the coefficient of determination R^2 of the prediction.</p>
<p>The coefficient R^2 is defined as (1 - u/v), where u is the residual
sum of squares ((y_true - y_pred) <strong> 2).sum() and v is the total
sum of squares ((y_true - y_true.mean()) </strong> 2).sum().
The best possible score is 1.0 and it can be negative (because the
model can be arbitrarily worse). A constant model that always
predicts the expected value of y, disregarding the input features,
would get a R^2 score of 0.0.</p>
<h2 id="parameters_10">Parameters<a class="headerlink" href="#parameters_10" title="Permanent link">&para;</a></h2>
<p>X : array-like of shape (n_samples, n_features)
Test samples. For some estimators this may be a
precomputed kernel matrix or a list of generic objects instead,
shape = (n_samples, n_samples_fitted),
where n_samples_fitted is the number of
samples used in the fitting for the estimator.</p>
<p>y : array-like of shape (n_samples,) or (n_samples, n_outputs)
True values for X.</p>
<p>sample_weight : array-like of shape (n_samples,), default=None
Sample weights.</p>
<h2 id="returns_8">Returns<a class="headerlink" href="#returns_8" title="Permanent link">&para;</a></h2>
<p>score : float
R^2 of self.predict(X) wrt. y.</p>
<h2 id="notes_3">Notes<a class="headerlink" href="#notes_3" title="Permanent link">&para;</a></h2>
<p>The R2 score used when calling <code>score</code> on a regressor will use
<code>multioutput='uniform_average'</code> from version 0.23 to keep consistent
with :func:<code>~sklearn.metrics.r2_score</code>. This will influence the
<code>score</code> method of all the multioutput regressors (except for
:class:<code>~sklearn.multioutput.MultiOutputRegressor</code>). To specify the
default value manually and avoid the warning, please either call
:func:<code>~sklearn.metrics.r2_score</code> directly or make a custom scorer with
:func:<code>~sklearn.metrics.make_scorer</code> (the built-in scorer <code>'r2'</code> uses
<code>multioutput='uniform_average'</code>).</p>
<div class="highlight"><pre><span></span><code><span class="k">val</span> <span class="n">set_params</span> <span class="o">:</span> <span class="o">?</span><span class="n">params</span><span class="o">:(</span><span class="kt">string</span> <span class="o">*</span> <span class="nn">Py</span><span class="p">.</span><span class="nn">Object</span><span class="p">.</span><span class="n">t</span><span class="o">)</span> <span class="kt">list</span> <span class="o">-&gt;</span> <span class="o">[&gt;</span> <span class="n">tag</span><span class="o">]</span> <span class="nn">Obj</span><span class="p">.</span><span class="n">t</span> <span class="o">-&gt;</span> <span class="n">t</span>
</code></pre></div>

<p>Set the parameters of this estimator.</p>
<p>The method works on simple estimators as well as on nested objects
(such as pipelines). The latter have parameters of the form
<code>&lt;component&gt;__&lt;parameter&gt;</code> so that it's possible to update each
component of a nested object.</p>
<h2 id="parameters_11">Parameters<a class="headerlink" href="#parameters_11" title="Permanent link">&para;</a></h2>
<p>**params : dict
Estimator parameters.</p>
<h2 id="returns_9">Returns<a class="headerlink" href="#returns_9" title="Permanent link">&para;</a></h2>
<p>self : object
Estimator instance.</p>
<p>Attribute coef_: get value or raise Not_found if None.</p>
<div class="highlight"><pre><span></span><code><span class="k">val</span> <span class="n">coef_</span> <span class="o">:</span> <span class="n">t</span> <span class="o">-&gt;</span> <span class="o">[&gt;`</span><span class="nc">ArrayLike</span><span class="o">]</span> <span class="nn">Np</span><span class="p">.</span><span class="nn">Obj</span><span class="p">.</span><span class="n">t</span>
</code></pre></div>

<p>Attribute coef_: get value as an option.</p>
<div class="highlight"><pre><span></span><code><span class="k">val</span> <span class="n">coef_opt</span> <span class="o">:</span> <span class="n">t</span> <span class="o">-&gt;</span> <span class="o">([&gt;`</span><span class="nc">ArrayLike</span><span class="o">]</span> <span class="nn">Np</span><span class="p">.</span><span class="nn">Obj</span><span class="p">.</span><span class="n">t</span><span class="o">)</span> <span class="n">option</span>
</code></pre></div>

<p>Attribute intercept_: get value or raise Not_found if None.</p>
<div class="highlight"><pre><span></span><code><span class="k">val</span> <span class="n">intercept_</span> <span class="o">:</span> <span class="n">t</span> <span class="o">-&gt;</span> <span class="o">[&gt;`</span><span class="nc">ArrayLike</span><span class="o">]</span> <span class="nn">Np</span><span class="p">.</span><span class="nn">Obj</span><span class="p">.</span><span class="n">t</span>
</code></pre></div>

<p>Attribute intercept_: get value as an option.</p>
<div class="highlight"><pre><span></span><code><span class="k">val</span> <span class="n">intercept_opt</span> <span class="o">:</span> <span class="n">t</span> <span class="o">-&gt;</span> <span class="o">([&gt;`</span><span class="nc">ArrayLike</span><span class="o">]</span> <span class="nn">Np</span><span class="p">.</span><span class="nn">Obj</span><span class="p">.</span><span class="n">t</span><span class="o">)</span> <span class="n">option</span>
</code></pre></div>

<p>Attribute alpha_: get value or raise Not_found if None.</p>
<div class="highlight"><pre><span></span><code><span class="k">val</span> <span class="n">alpha_</span> <span class="o">:</span> <span class="n">t</span> <span class="o">-&gt;</span> <span class="kt">float</span>
</code></pre></div>

<p>Attribute alpha_: get value as an option.</p>
<div class="highlight"><pre><span></span><code><span class="k">val</span> <span class="n">alpha_opt</span> <span class="o">:</span> <span class="n">t</span> <span class="o">-&gt;</span> <span class="o">(</span><span class="kt">float</span><span class="o">)</span> <span class="n">option</span>
</code></pre></div>

<p>Attribute lambda_: get value or raise Not_found if None.</p>
<div class="highlight"><pre><span></span><code><span class="k">val</span> <span class="n">lambda_</span> <span class="o">:</span> <span class="n">t</span> <span class="o">-&gt;</span> <span class="kt">float</span>
</code></pre></div>

<p>Attribute lambda_: get value as an option.</p>
<div class="highlight"><pre><span></span><code><span class="k">val</span> <span class="n">lambda_opt</span> <span class="o">:</span> <span class="n">t</span> <span class="o">-&gt;</span> <span class="o">(</span><span class="kt">float</span><span class="o">)</span> <span class="n">option</span>
</code></pre></div>

<p>Attribute sigma_: get value or raise Not_found if None.</p>
<div class="highlight"><pre><span></span><code><span class="k">val</span> <span class="n">sigma_</span> <span class="o">:</span> <span class="n">t</span> <span class="o">-&gt;</span> <span class="o">[&gt;`</span><span class="nc">ArrayLike</span><span class="o">]</span> <span class="nn">Np</span><span class="p">.</span><span class="nn">Obj</span><span class="p">.</span><span class="n">t</span>
</code></pre></div>

<p>Attribute sigma_: get value as an option.</p>
<div class="highlight"><pre><span></span><code><span class="k">val</span> <span class="n">sigma_opt</span> <span class="o">:</span> <span class="n">t</span> <span class="o">-&gt;</span> <span class="o">([&gt;`</span><span class="nc">ArrayLike</span><span class="o">]</span> <span class="nn">Np</span><span class="p">.</span><span class="nn">Obj</span><span class="p">.</span><span class="n">t</span><span class="o">)</span> <span class="n">option</span>
</code></pre></div>

<p>Attribute scores_: get value or raise Not_found if None.</p>
<div class="highlight"><pre><span></span><code><span class="k">val</span> <span class="n">scores_</span> <span class="o">:</span> <span class="n">t</span> <span class="o">-&gt;</span> <span class="o">[&gt;`</span><span class="nc">ArrayLike</span><span class="o">]</span> <span class="nn">Np</span><span class="p">.</span><span class="nn">Obj</span><span class="p">.</span><span class="n">t</span>
</code></pre></div>

<p>Attribute scores_: get value as an option.</p>
<div class="highlight"><pre><span></span><code><span class="k">val</span> <span class="n">scores_opt</span> <span class="o">:</span> <span class="n">t</span> <span class="o">-&gt;</span> <span class="o">([&gt;`</span><span class="nc">ArrayLike</span><span class="o">]</span> <span class="nn">Np</span><span class="p">.</span><span class="nn">Obj</span><span class="p">.</span><span class="n">t</span><span class="o">)</span> <span class="n">option</span>
</code></pre></div>

<p>Attribute n_iter_: get value or raise Not_found if None.</p>
<div class="highlight"><pre><span></span><code><span class="k">val</span> <span class="n">n_iter_</span> <span class="o">:</span> <span class="n">t</span> <span class="o">-&gt;</span> <span class="kt">int</span>
</code></pre></div>

<p>Attribute n_iter_: get value as an option.</p>
<div class="highlight"><pre><span></span><code><span class="k">val</span> <span class="n">n_iter_opt</span> <span class="o">:</span> <span class="n">t</span> <span class="o">-&gt;</span> <span class="o">(</span><span class="kt">int</span><span class="o">)</span> <span class="n">option</span>
</code></pre></div>

<p>Print the object to a human-readable representation.</p>
<div class="highlight"><pre><span></span><code><span class="k">val</span> <span class="n">to_string</span> <span class="o">:</span> <span class="n">t</span> <span class="o">-&gt;</span> <span class="kt">string</span>
</code></pre></div>

<p>Print the object to a human-readable representation.</p>
<div class="highlight"><pre><span></span><code><span class="k">val</span> <span class="n">show</span> <span class="o">:</span> <span class="n">t</span> <span class="o">-&gt;</span> <span class="kt">string</span>
</code></pre></div>

<p>Pretty-print the object to a formatter.</p>
<div class="highlight"><pre><span></span><code><span class="k">val</span> <span class="n">pp</span> <span class="o">:</span> <span class="nn">Format</span><span class="p">.</span><span class="n">formatter</span> <span class="o">-&gt;</span> <span class="n">t</span> <span class="o">-&gt;</span> <span class="kt">unit</span> <span class="o">[@@</span><span class="n">ocaml</span><span class="o">.</span><span class="n">toplevel_printer</span><span class="o">]</span>



<span class="k">module</span> <span class="nc">ElasticNet</span> <span class="o">:</span> <span class="k">sig</span>
<span class="k">type</span> <span class="n">tag</span> <span class="o">=</span> <span class="o">[`</span><span class="nc">ElasticNet</span><span class="o">]</span>
<span class="k">type</span> <span class="n">t</span> <span class="o">=</span> <span class="o">[`</span><span class="nc">BaseEstimator</span> <span class="o">|</span> <span class="o">`</span><span class="nc">ElasticNet</span> <span class="o">|</span> <span class="o">`</span><span class="nc">MultiOutputMixin</span> <span class="o">|</span> <span class="o">`</span><span class="nc">Object</span> <span class="o">|</span> <span class="o">`</span><span class="nc">RegressorMixin</span><span class="o">]</span> <span class="nn">Obj</span><span class="p">.</span><span class="n">t</span>
<span class="k">val</span> <span class="n">of_pyobject</span> <span class="o">:</span> <span class="nn">Py</span><span class="p">.</span><span class="nn">Object</span><span class="p">.</span><span class="n">t</span> <span class="o">-&gt;</span> <span class="n">t</span>
<span class="k">val</span> <span class="n">to_pyobject</span> <span class="o">:</span> <span class="o">[&gt;</span> <span class="n">tag</span><span class="o">]</span> <span class="nn">Obj</span><span class="p">.</span><span class="n">t</span> <span class="o">-&gt;</span> <span class="nn">Py</span><span class="p">.</span><span class="nn">Object</span><span class="p">.</span><span class="n">t</span>

<span class="k">val</span> <span class="n">as_regressor</span> <span class="o">:</span> <span class="n">t</span> <span class="o">-&gt;</span> <span class="o">[`</span><span class="nc">RegressorMixin</span><span class="o">]</span> <span class="nn">Obj</span><span class="p">.</span><span class="n">t</span>
<span class="k">val</span> <span class="n">as_multi_output</span> <span class="o">:</span> <span class="n">t</span> <span class="o">-&gt;</span> <span class="o">[`</span><span class="nc">MultiOutputMixin</span><span class="o">]</span> <span class="nn">Obj</span><span class="p">.</span><span class="n">t</span>
<span class="k">val</span> <span class="n">as_estimator</span> <span class="o">:</span> <span class="n">t</span> <span class="o">-&gt;</span> <span class="o">[`</span><span class="nc">BaseEstimator</span><span class="o">]</span> <span class="nn">Obj</span><span class="p">.</span><span class="n">t</span>
<span class="k">val</span> <span class="n">create</span> <span class="o">:</span> <span class="o">?</span><span class="n">alpha</span><span class="o">:</span><span class="kt">float</span> <span class="o">-&gt;</span> <span class="o">?</span><span class="n">l1_ratio</span><span class="o">:</span><span class="kt">float</span> <span class="o">-&gt;</span> <span class="o">?</span><span class="n">fit_intercept</span><span class="o">:</span><span class="kt">bool</span> <span class="o">-&gt;</span> <span class="o">?</span><span class="n">normalize</span><span class="o">:</span><span class="kt">bool</span> <span class="o">-&gt;</span> <span class="o">?</span><span class="n">precompute</span><span class="o">:[`</span><span class="nc">Arr</span> <span class="k">of</span> <span class="o">[&gt;`</span><span class="nc">ArrayLike</span><span class="o">]</span> <span class="nn">Np</span><span class="p">.</span><span class="nn">Obj</span><span class="p">.</span><span class="n">t</span> <span class="o">|</span> <span class="o">`</span><span class="nc">Bool</span> <span class="k">of</span> <span class="kt">bool</span><span class="o">]</span> <span class="o">-&gt;</span> <span class="o">?</span><span class="n">max_iter</span><span class="o">:</span><span class="kt">int</span> <span class="o">-&gt;</span> <span class="o">?</span><span class="n">copy_X</span><span class="o">:</span><span class="kt">bool</span> <span class="o">-&gt;</span> <span class="o">?</span><span class="n">tol</span><span class="o">:</span><span class="kt">float</span> <span class="o">-&gt;</span> <span class="o">?</span><span class="n">warm_start</span><span class="o">:</span><span class="kt">bool</span> <span class="o">-&gt;</span> <span class="o">?</span><span class="n">positive</span><span class="o">:</span><span class="kt">bool</span> <span class="o">-&gt;</span> <span class="o">?</span><span class="n">random_state</span><span class="o">:</span><span class="kt">int</span> <span class="o">-&gt;</span> <span class="o">?</span><span class="n">selection</span><span class="o">:</span><span class="kt">string</span> <span class="o">-&gt;</span> <span class="kt">unit</span> <span class="o">-&gt;</span> <span class="n">t</span>
</code></pre></div>

<p>Linear regression with combined L1 and L2 priors as regularizer.</p>
<p>Minimizes the objective function::</p>
<p>1 / (2 * n_samples) * ||y - Xw||^2_2
+ alpha * l1_ratio * ||w||_1
+ 0.5 * alpha * (1 - l1_ratio) * ||w||^2_2</p>
<p>If you are interested in controlling the L1 and L2 penalty
separately, keep in mind that this is equivalent to::</p>
<p>a * L1 + b * L2</p>
<p>where::</p>
<p>alpha = a + b and l1_ratio = a / (a + b)</p>
<p>The parameter l1_ratio corresponds to alpha in the glmnet R package while
alpha corresponds to the lambda parameter in glmnet. Specifically, l1_ratio
= 1 is the lasso penalty. Currently, l1_ratio &lt;= 0.01 is not reliable,
unless you supply your own sequence of alpha.</p>
<p>Read more in the :ref:<code>User Guide &lt;elastic_net&gt;</code>.</p>
<h2 id="parameters_12">Parameters<a class="headerlink" href="#parameters_12" title="Permanent link">&para;</a></h2>
<p>alpha : float, optional
Constant that multiplies the penalty terms. Defaults to 1.0.
See the notes for the exact mathematical meaning of this
parameter. <code>alpha = 0</code> is equivalent to an ordinary least square,
solved by the :class:<code>LinearRegression</code> object. For numerical
reasons, using <code>alpha = 0</code> with the <code>Lasso</code> object is not advised.
Given this, you should use the :class:<code>LinearRegression</code> object.</p>
<p>l1_ratio : float
The ElasticNet mixing parameter, with <code>0 &lt;= l1_ratio &lt;= 1</code>. For
<code>l1_ratio = 0</code> the penalty is an L2 penalty. <code>For l1_ratio = 1</code> it
is an L1 penalty.  For <code>0 &lt; l1_ratio &lt; 1</code>, the penalty is a
combination of L1 and L2.</p>
<p>fit_intercept : bool
Whether the intercept should be estimated or not. If <code>False</code>, the
data is assumed to be already centered.</p>
<p>normalize : boolean, optional, default False
This parameter is ignored when <code>fit_intercept</code> is set to False.
If True, the regressors X will be normalized before regression by
subtracting the mean and dividing by the l2-norm.
If you wish to standardize, please use
:class:<code>sklearn.preprocessing.StandardScaler</code> before calling <code>fit</code>
on an estimator with <code>normalize=False</code>.</p>
<p>precompute : True | False | array-like
Whether to use a precomputed Gram matrix to speed up
calculations. The Gram matrix can also be passed as argument.
For sparse input this option is always <code>True</code> to preserve sparsity.</p>
<p>max_iter : int, optional
The maximum number of iterations</p>
<p>copy_X : boolean, optional, default True
If <code>True</code>, X will be copied; else, it may be overwritten.</p>
<p>tol : float, optional
The tolerance for the optimization: if the updates are
smaller than <code>tol</code>, the optimization code checks the
dual gap for optimality and continues until it is smaller
than <code>tol</code>.</p>
<p>warm_start : bool, optional
When set to <code>True</code>, reuse the solution of the previous call to fit as
initialization, otherwise, just erase the previous solution.
See :term:<code>the Glossary &lt;warm_start&gt;</code>.</p>
<p>positive : bool, optional
When set to <code>True</code>, forces the coefficients to be positive.</p>
<p>random_state : int, RandomState instance or None, optional, default None
The seed of the pseudo random number generator that selects a random
feature to update.  If int, random_state is the seed used by the random
number generator; If RandomState instance, random_state is the random
number generator; If None, the random number generator is the
RandomState instance used by <code>np.random</code>. Used when <code>selection</code> ==
'random'.</p>
<p>selection : str, default 'cyclic'
If set to 'random', a random coefficient is updated every iteration
rather than looping over features sequentially by default. This
(setting to 'random') often leads to significantly faster convergence
especially when tol is higher than 1e-4.</p>
<h2 id="attributes_2">Attributes<a class="headerlink" href="#attributes_2" title="Permanent link">&para;</a></h2>
<p>coef_ : array, shape (n_features,) | (n_targets, n_features)
parameter vector (w in the cost function formula)</p>
<p>sparse_coef_ : scipy.sparse matrix, shape (n_features, 1) |             (n_targets, n_features)
<code>sparse_coef_</code> is a readonly property derived from <code>coef_</code></p>
<p>intercept_ : float | array, shape (n_targets,)
independent term in decision function.</p>
<p>n_iter_ : array-like, shape (n_targets,)
number of iterations run by the coordinate descent solver to reach
the specified tolerance.</p>
<h2 id="examples_2">Examples<a class="headerlink" href="#examples_2" title="Permanent link">&para;</a></h2>
<blockquote>
<blockquote>
<blockquote>
<p>from sklearn.linear_model import ElasticNet
from sklearn.datasets import make_regression</p>
<p>X, y = make_regression(n_features=2, random_state=0)
regr = ElasticNet(random_state=0)
regr.fit(X, y)
ElasticNet(random_state=0)
print(regr.coef_)
[18.83816048 64.55968825]
print(regr.intercept_)
1.451...
print(regr.predict([[0, 0]]))
[1.451...]</p>
</blockquote>
</blockquote>
</blockquote>
<h2 id="notes_4">Notes<a class="headerlink" href="#notes_4" title="Permanent link">&para;</a></h2>
<p>To avoid unnecessary memory duplication the X argument of the fit method
should be directly passed as a Fortran-contiguous numpy array.</p>
<h2 id="see-also">See also<a class="headerlink" href="#see-also" title="Permanent link">&para;</a></h2>
<p>ElasticNetCV : Elastic net model with best model selection by
cross-validation.
SGDRegressor: implements elastic net regression with incremental training.
SGDClassifier: implements logistic regression with elastic net penalty
(<code>SGDClassifier(loss='log', penalty='elasticnet')</code>).</p>
<div class="highlight"><pre><span></span><code><span class="k">val</span> <span class="n">fit</span> <span class="o">:</span> <span class="o">?</span><span class="n">check_input</span><span class="o">:</span><span class="kt">bool</span> <span class="o">-&gt;</span> <span class="n">x</span><span class="o">:[&gt;`</span><span class="nc">ArrayLike</span><span class="o">]</span> <span class="nn">Np</span><span class="p">.</span><span class="nn">Obj</span><span class="p">.</span><span class="n">t</span> <span class="o">-&gt;</span> <span class="n">y</span><span class="o">:[&gt;`</span><span class="nc">ArrayLike</span><span class="o">]</span> <span class="nn">Np</span><span class="p">.</span><span class="nn">Obj</span><span class="p">.</span><span class="n">t</span> <span class="o">-&gt;</span> <span class="o">[&gt;</span> <span class="n">tag</span><span class="o">]</span> <span class="nn">Obj</span><span class="p">.</span><span class="n">t</span> <span class="o">-&gt;</span> <span class="n">t</span>
</code></pre></div>

<p>Fit model with coordinate descent.</p>
<h2 id="parameters_13">Parameters<a class="headerlink" href="#parameters_13" title="Permanent link">&para;</a></h2>
<p>X : ndarray or scipy.sparse matrix, (n_samples, n_features)
Data</p>
<p>y : ndarray, shape (n_samples,) or (n_samples, n_targets)
Target. Will be cast to X's dtype if necessary</p>
<p>check_input : boolean, (default=True)
Allow to bypass several input checking.
Don't use this parameter unless you know what you do.</p>
<h2 id="notes_5">Notes<a class="headerlink" href="#notes_5" title="Permanent link">&para;</a></h2>
<p>Coordinate descent is an algorithm that considers each column of
data at a time hence it will automatically convert the X input
as a Fortran-contiguous numpy array if necessary.</p>
<p>To avoid memory re-allocation it is advised to allocate the
initial data in memory directly using that format.</p>
<div class="highlight"><pre><span></span><code><span class="k">val</span> <span class="n">get_params</span> <span class="o">:</span> <span class="o">?</span><span class="n">deep</span><span class="o">:</span><span class="kt">bool</span> <span class="o">-&gt;</span> <span class="o">[&gt;</span> <span class="n">tag</span><span class="o">]</span> <span class="nn">Obj</span><span class="p">.</span><span class="n">t</span> <span class="o">-&gt;</span> <span class="nn">Dict</span><span class="p">.</span><span class="n">t</span>
</code></pre></div>

<p>Get parameters for this estimator.</p>
<h2 id="parameters_14">Parameters<a class="headerlink" href="#parameters_14" title="Permanent link">&para;</a></h2>
<p>deep : bool, default=True
If True, will return the parameters for this estimator and
contained subobjects that are estimators.</p>
<h2 id="returns_10">Returns<a class="headerlink" href="#returns_10" title="Permanent link">&para;</a></h2>
<p>params : mapping of string to any
Parameter names mapped to their values.</p>
<div class="highlight"><pre><span></span><code><span class="k">val</span> <span class="n">predict</span> <span class="o">:</span> <span class="n">x</span><span class="o">:[&gt;`</span><span class="nc">ArrayLike</span><span class="o">]</span> <span class="nn">Np</span><span class="p">.</span><span class="nn">Obj</span><span class="p">.</span><span class="n">t</span> <span class="o">-&gt;</span> <span class="o">[&gt;</span> <span class="n">tag</span><span class="o">]</span> <span class="nn">Obj</span><span class="p">.</span><span class="n">t</span> <span class="o">-&gt;</span> <span class="o">[&gt;`</span><span class="nc">ArrayLike</span><span class="o">]</span> <span class="nn">Np</span><span class="p">.</span><span class="nn">Obj</span><span class="p">.</span><span class="n">t</span>
</code></pre></div>

<p>Predict using the linear model.</p>
<h2 id="parameters_15">Parameters<a class="headerlink" href="#parameters_15" title="Permanent link">&para;</a></h2>
<p>X : array_like or sparse matrix, shape (n_samples, n_features)
Samples.</p>
<h2 id="returns_11">Returns<a class="headerlink" href="#returns_11" title="Permanent link">&para;</a></h2>
<p>C : array, shape (n_samples,)
Returns predicted values.</p>
<div class="highlight"><pre><span></span><code><span class="k">val</span> <span class="n">score</span> <span class="o">:</span> <span class="o">?</span><span class="n">sample_weight</span><span class="o">:[&gt;`</span><span class="nc">ArrayLike</span><span class="o">]</span> <span class="nn">Np</span><span class="p">.</span><span class="nn">Obj</span><span class="p">.</span><span class="n">t</span> <span class="o">-&gt;</span> <span class="n">x</span><span class="o">:[&gt;`</span><span class="nc">ArrayLike</span><span class="o">]</span> <span class="nn">Np</span><span class="p">.</span><span class="nn">Obj</span><span class="p">.</span><span class="n">t</span> <span class="o">-&gt;</span> <span class="n">y</span><span class="o">:[&gt;`</span><span class="nc">ArrayLike</span><span class="o">]</span> <span class="nn">Np</span><span class="p">.</span><span class="nn">Obj</span><span class="p">.</span><span class="n">t</span> <span class="o">-&gt;</span> <span class="o">[&gt;</span> <span class="n">tag</span><span class="o">]</span> <span class="nn">Obj</span><span class="p">.</span><span class="n">t</span> <span class="o">-&gt;</span> <span class="kt">float</span>
</code></pre></div>

<p>Return the coefficient of determination R^2 of the prediction.</p>
<p>The coefficient R^2 is defined as (1 - u/v), where u is the residual
sum of squares ((y_true - y_pred) <strong> 2).sum() and v is the total
sum of squares ((y_true - y_true.mean()) </strong> 2).sum().
The best possible score is 1.0 and it can be negative (because the
model can be arbitrarily worse). A constant model that always
predicts the expected value of y, disregarding the input features,
would get a R^2 score of 0.0.</p>
<h2 id="parameters_16">Parameters<a class="headerlink" href="#parameters_16" title="Permanent link">&para;</a></h2>
<p>X : array-like of shape (n_samples, n_features)
Test samples. For some estimators this may be a
precomputed kernel matrix or a list of generic objects instead,
shape = (n_samples, n_samples_fitted),
where n_samples_fitted is the number of
samples used in the fitting for the estimator.</p>
<p>y : array-like of shape (n_samples,) or (n_samples, n_outputs)
True values for X.</p>
<p>sample_weight : array-like of shape (n_samples,), default=None
Sample weights.</p>
<h2 id="returns_12">Returns<a class="headerlink" href="#returns_12" title="Permanent link">&para;</a></h2>
<p>score : float
R^2 of self.predict(X) wrt. y.</p>
<h2 id="notes_6">Notes<a class="headerlink" href="#notes_6" title="Permanent link">&para;</a></h2>
<p>The R2 score used when calling <code>score</code> on a regressor will use
<code>multioutput='uniform_average'</code> from version 0.23 to keep consistent
with :func:<code>~sklearn.metrics.r2_score</code>. This will influence the
<code>score</code> method of all the multioutput regressors (except for
:class:<code>~sklearn.multioutput.MultiOutputRegressor</code>). To specify the
default value manually and avoid the warning, please either call
:func:<code>~sklearn.metrics.r2_score</code> directly or make a custom scorer with
:func:<code>~sklearn.metrics.make_scorer</code> (the built-in scorer <code>'r2'</code> uses
<code>multioutput='uniform_average'</code>).</p>
<div class="highlight"><pre><span></span><code><span class="k">val</span> <span class="n">set_params</span> <span class="o">:</span> <span class="o">?</span><span class="n">params</span><span class="o">:(</span><span class="kt">string</span> <span class="o">*</span> <span class="nn">Py</span><span class="p">.</span><span class="nn">Object</span><span class="p">.</span><span class="n">t</span><span class="o">)</span> <span class="kt">list</span> <span class="o">-&gt;</span> <span class="o">[&gt;</span> <span class="n">tag</span><span class="o">]</span> <span class="nn">Obj</span><span class="p">.</span><span class="n">t</span> <span class="o">-&gt;</span> <span class="n">t</span>
</code></pre></div>

<p>Set the parameters of this estimator.</p>
<p>The method works on simple estimators as well as on nested objects
(such as pipelines). The latter have parameters of the form
<code>&lt;component&gt;__&lt;parameter&gt;</code> so that it's possible to update each
component of a nested object.</p>
<h2 id="parameters_17">Parameters<a class="headerlink" href="#parameters_17" title="Permanent link">&para;</a></h2>
<p>**params : dict
Estimator parameters.</p>
<h2 id="returns_13">Returns<a class="headerlink" href="#returns_13" title="Permanent link">&para;</a></h2>
<p>self : object
Estimator instance.</p>
<p>Attribute coef_: get value or raise Not_found if None.</p>
<div class="highlight"><pre><span></span><code><span class="k">val</span> <span class="n">coef_</span> <span class="o">:</span> <span class="n">t</span> <span class="o">-&gt;</span> <span class="o">[&gt;`</span><span class="nc">ArrayLike</span><span class="o">]</span> <span class="nn">Np</span><span class="p">.</span><span class="nn">Obj</span><span class="p">.</span><span class="n">t</span>
</code></pre></div>

<p>Attribute coef_: get value as an option.</p>
<div class="highlight"><pre><span></span><code><span class="k">val</span> <span class="n">coef_opt</span> <span class="o">:</span> <span class="n">t</span> <span class="o">-&gt;</span> <span class="o">([&gt;`</span><span class="nc">ArrayLike</span><span class="o">]</span> <span class="nn">Np</span><span class="p">.</span><span class="nn">Obj</span><span class="p">.</span><span class="n">t</span><span class="o">)</span> <span class="n">option</span>
</code></pre></div>

<p>Attribute sparse_coef_: get value or raise Not_found if None.</p>
<div class="highlight"><pre><span></span><code><span class="k">val</span> <span class="n">sparse_coef_</span> <span class="o">:</span> <span class="n">t</span> <span class="o">-&gt;</span> <span class="o">[`</span><span class="nc">ArrayLike</span><span class="o">|`</span><span class="nc">Object</span><span class="o">|`</span><span class="nc">Spmatrix</span><span class="o">]</span> <span class="nn">Np</span><span class="p">.</span><span class="nn">Obj</span><span class="p">.</span><span class="n">t</span>
</code></pre></div>

<p>Attribute sparse_coef_: get value as an option.</p>
<div class="highlight"><pre><span></span><code><span class="k">val</span> <span class="n">sparse_coef_opt</span> <span class="o">:</span> <span class="n">t</span> <span class="o">-&gt;</span> <span class="o">([`</span><span class="nc">ArrayLike</span><span class="o">|`</span><span class="nc">Object</span><span class="o">|`</span><span class="nc">Spmatrix</span><span class="o">]</span> <span class="nn">Np</span><span class="p">.</span><span class="nn">Obj</span><span class="p">.</span><span class="n">t</span><span class="o">)</span> <span class="n">option</span>
</code></pre></div>

<p>Attribute intercept_: get value or raise Not_found if None.</p>
<div class="highlight"><pre><span></span><code><span class="k">val</span> <span class="n">intercept_</span> <span class="o">:</span> <span class="n">t</span> <span class="o">-&gt;</span> <span class="o">[&gt;`</span><span class="nc">ArrayLike</span><span class="o">]</span> <span class="nn">Np</span><span class="p">.</span><span class="nn">Obj</span><span class="p">.</span><span class="n">t</span>
</code></pre></div>

<p>Attribute intercept_: get value as an option.</p>
<div class="highlight"><pre><span></span><code><span class="k">val</span> <span class="n">intercept_opt</span> <span class="o">:</span> <span class="n">t</span> <span class="o">-&gt;</span> <span class="o">([&gt;`</span><span class="nc">ArrayLike</span><span class="o">]</span> <span class="nn">Np</span><span class="p">.</span><span class="nn">Obj</span><span class="p">.</span><span class="n">t</span><span class="o">)</span> <span class="n">option</span>
</code></pre></div>

<p>Attribute n_iter_: get value or raise Not_found if None.</p>
<div class="highlight"><pre><span></span><code><span class="k">val</span> <span class="n">n_iter_</span> <span class="o">:</span> <span class="n">t</span> <span class="o">-&gt;</span> <span class="o">[&gt;`</span><span class="nc">ArrayLike</span><span class="o">]</span> <span class="nn">Np</span><span class="p">.</span><span class="nn">Obj</span><span class="p">.</span><span class="n">t</span>
</code></pre></div>

<p>Attribute n_iter_: get value as an option.</p>
<div class="highlight"><pre><span></span><code><span class="k">val</span> <span class="n">n_iter_opt</span> <span class="o">:</span> <span class="n">t</span> <span class="o">-&gt;</span> <span class="o">([&gt;`</span><span class="nc">ArrayLike</span><span class="o">]</span> <span class="nn">Np</span><span class="p">.</span><span class="nn">Obj</span><span class="p">.</span><span class="n">t</span><span class="o">)</span> <span class="n">option</span>
</code></pre></div>

<p>Print the object to a human-readable representation.</p>
<div class="highlight"><pre><span></span><code><span class="k">val</span> <span class="n">to_string</span> <span class="o">:</span> <span class="n">t</span> <span class="o">-&gt;</span> <span class="kt">string</span>
</code></pre></div>

<p>Print the object to a human-readable representation.</p>
<div class="highlight"><pre><span></span><code><span class="k">val</span> <span class="n">show</span> <span class="o">:</span> <span class="n">t</span> <span class="o">-&gt;</span> <span class="kt">string</span>
</code></pre></div>

<p>Pretty-print the object to a formatter.</p>
<div class="highlight"><pre><span></span><code><span class="k">val</span> <span class="n">pp</span> <span class="o">:</span> <span class="nn">Format</span><span class="p">.</span><span class="n">formatter</span> <span class="o">-&gt;</span> <span class="n">t</span> <span class="o">-&gt;</span> <span class="kt">unit</span> <span class="o">[@@</span><span class="n">ocaml</span><span class="o">.</span><span class="n">toplevel_printer</span><span class="o">]</span>



<span class="k">module</span> <span class="nc">ElasticNetCV</span> <span class="o">:</span> <span class="k">sig</span>
<span class="k">type</span> <span class="n">tag</span> <span class="o">=</span> <span class="o">[`</span><span class="nc">ElasticNetCV</span><span class="o">]</span>
<span class="k">type</span> <span class="n">t</span> <span class="o">=</span> <span class="o">[`</span><span class="nc">BaseEstimator</span> <span class="o">|</span> <span class="o">`</span><span class="nc">ElasticNetCV</span> <span class="o">|</span> <span class="o">`</span><span class="nc">MultiOutputMixin</span> <span class="o">|</span> <span class="o">`</span><span class="nc">Object</span> <span class="o">|</span> <span class="o">`</span><span class="nc">RegressorMixin</span><span class="o">]</span> <span class="nn">Obj</span><span class="p">.</span><span class="n">t</span>
<span class="k">val</span> <span class="n">of_pyobject</span> <span class="o">:</span> <span class="nn">Py</span><span class="p">.</span><span class="nn">Object</span><span class="p">.</span><span class="n">t</span> <span class="o">-&gt;</span> <span class="n">t</span>
<span class="k">val</span> <span class="n">to_pyobject</span> <span class="o">:</span> <span class="o">[&gt;</span> <span class="n">tag</span><span class="o">]</span> <span class="nn">Obj</span><span class="p">.</span><span class="n">t</span> <span class="o">-&gt;</span> <span class="nn">Py</span><span class="p">.</span><span class="nn">Object</span><span class="p">.</span><span class="n">t</span>

<span class="k">val</span> <span class="n">as_regressor</span> <span class="o">:</span> <span class="n">t</span> <span class="o">-&gt;</span> <span class="o">[`</span><span class="nc">RegressorMixin</span><span class="o">]</span> <span class="nn">Obj</span><span class="p">.</span><span class="n">t</span>
<span class="k">val</span> <span class="n">as_multi_output</span> <span class="o">:</span> <span class="n">t</span> <span class="o">-&gt;</span> <span class="o">[`</span><span class="nc">MultiOutputMixin</span><span class="o">]</span> <span class="nn">Obj</span><span class="p">.</span><span class="n">t</span>
<span class="k">val</span> <span class="n">as_estimator</span> <span class="o">:</span> <span class="n">t</span> <span class="o">-&gt;</span> <span class="o">[`</span><span class="nc">BaseEstimator</span><span class="o">]</span> <span class="nn">Obj</span><span class="p">.</span><span class="n">t</span>
<span class="k">val</span> <span class="n">create</span> <span class="o">:</span> <span class="o">?</span><span class="n">l1_ratio</span><span class="o">:[&gt;`</span><span class="nc">ArrayLike</span><span class="o">]</span> <span class="nn">Np</span><span class="p">.</span><span class="nn">Obj</span><span class="p">.</span><span class="n">t</span> <span class="o">-&gt;</span> <span class="o">?</span><span class="n">eps</span><span class="o">:</span><span class="kt">float</span> <span class="o">-&gt;</span> <span class="o">?</span><span class="n">n_alphas</span><span class="o">:</span><span class="kt">int</span> <span class="o">-&gt;</span> <span class="o">?</span><span class="n">alphas</span><span class="o">:[&gt;`</span><span class="nc">ArrayLike</span><span class="o">]</span> <span class="nn">Np</span><span class="p">.</span><span class="nn">Obj</span><span class="p">.</span><span class="n">t</span> <span class="o">-&gt;</span> <span class="o">?</span><span class="n">fit_intercept</span><span class="o">:</span><span class="kt">bool</span> <span class="o">-&gt;</span> <span class="o">?</span><span class="n">normalize</span><span class="o">:</span><span class="kt">bool</span> <span class="o">-&gt;</span> <span class="o">?</span><span class="n">precompute</span><span class="o">:[`</span><span class="nc">Arr</span> <span class="k">of</span> <span class="o">[&gt;`</span><span class="nc">ArrayLike</span><span class="o">]</span> <span class="nn">Np</span><span class="p">.</span><span class="nn">Obj</span><span class="p">.</span><span class="n">t</span> <span class="o">|</span> <span class="o">`</span><span class="nc">Auto</span> <span class="o">|</span> <span class="o">`</span><span class="nc">Bool</span> <span class="k">of</span> <span class="kt">bool</span><span class="o">]</span> <span class="o">-&gt;</span> <span class="o">?</span><span class="n">max_iter</span><span class="o">:</span><span class="kt">int</span> <span class="o">-&gt;</span> <span class="o">?</span><span class="n">tol</span><span class="o">:</span><span class="kt">float</span> <span class="o">-&gt;</span> <span class="o">?</span><span class="n">cv</span><span class="o">:[`</span><span class="nc">Arr</span> <span class="k">of</span> <span class="o">[&gt;`</span><span class="nc">ArrayLike</span><span class="o">]</span> <span class="nn">Np</span><span class="p">.</span><span class="nn">Obj</span><span class="p">.</span><span class="n">t</span> <span class="o">|</span> <span class="o">`</span><span class="nc">BaseCrossValidator</span> <span class="k">of</span> <span class="o">[&gt;`</span><span class="nc">BaseCrossValidator</span><span class="o">]</span> <span class="nn">Np</span><span class="p">.</span><span class="nn">Obj</span><span class="p">.</span><span class="n">t</span> <span class="o">|</span> <span class="o">`</span><span class="nc">I</span> <span class="k">of</span> <span class="kt">int</span><span class="o">]</span> <span class="o">-&gt;</span> <span class="o">?</span><span class="n">copy_X</span><span class="o">:</span><span class="kt">bool</span> <span class="o">-&gt;</span> <span class="o">?</span><span class="n">verbose</span><span class="o">:</span><span class="kt">int</span> <span class="o">-&gt;</span> <span class="o">?</span><span class="n">n_jobs</span><span class="o">:</span><span class="kt">int</span> <span class="o">-&gt;</span> <span class="o">?</span><span class="n">positive</span><span class="o">:</span><span class="kt">bool</span> <span class="o">-&gt;</span> <span class="o">?</span><span class="n">random_state</span><span class="o">:</span><span class="kt">int</span> <span class="o">-&gt;</span> <span class="o">?</span><span class="n">selection</span><span class="o">:</span><span class="kt">string</span> <span class="o">-&gt;</span> <span class="kt">unit</span> <span class="o">-&gt;</span> <span class="n">t</span>
</code></pre></div>

<p>Elastic Net model with iterative fitting along a regularization path.</p>
<p>See glossary entry for :term:<code>cross-validation estimator</code>.</p>
<p>Read more in the :ref:<code>User Guide &lt;elastic_net&gt;</code>.</p>
<h2 id="parameters_18">Parameters<a class="headerlink" href="#parameters_18" title="Permanent link">&para;</a></h2>
<p>l1_ratio : float or array of floats, optional
float between 0 and 1 passed to ElasticNet (scaling between
l1 and l2 penalties). For <code>l1_ratio = 0</code>
the penalty is an L2 penalty. For <code>l1_ratio = 1</code> it is an L1 penalty.
For <code>0 &lt; l1_ratio &lt; 1</code>, the penalty is a combination of L1 and L2
This parameter can be a list, in which case the different
values are tested by cross-validation and the one giving the best
prediction score is used. Note that a good choice of list of
values for l1_ratio is often to put more values close to 1
(i.e. Lasso) and less close to 0 (i.e. Ridge), as in <code>[.1, .5, .7,
.9, .95, .99, 1]</code></p>
<p>eps : float, optional
Length of the path. <code>eps=1e-3</code> means that
<code>alpha_min / alpha_max = 1e-3</code>.</p>
<p>n_alphas : int, optional
Number of alphas along the regularization path, used for each l1_ratio.</p>
<p>alphas : numpy array, optional
List of alphas where to compute the models.
If None alphas are set automatically</p>
<p>fit_intercept : boolean
whether to calculate the intercept for this model. If set
to false, no intercept will be used in calculations
(i.e. data is expected to be centered).</p>
<p>normalize : boolean, optional, default False
This parameter is ignored when <code>fit_intercept</code> is set to False.
If True, the regressors X will be normalized before regression by
subtracting the mean and dividing by the l2-norm.
If you wish to standardize, please use
:class:<code>sklearn.preprocessing.StandardScaler</code> before calling <code>fit</code>
on an estimator with <code>normalize=False</code>.</p>
<p>precompute : True | False | 'auto' | array-like
Whether to use a precomputed Gram matrix to speed up
calculations. If set to <code>'auto'</code> let us decide. The Gram
matrix can also be passed as argument.</p>
<p>max_iter : int, optional
The maximum number of iterations</p>
<p>tol : float, optional
The tolerance for the optimization: if the updates are
smaller than <code>tol</code>, the optimization code checks the
dual gap for optimality and continues until it is smaller
than <code>tol</code>.</p>
<p>cv : int, cross-validation generator or an iterable, optional
Determines the cross-validation splitting strategy.
Possible inputs for cv are:</p>
<ul>
<li>None, to use the default 5-fold cross-validation,</li>
<li>integer, to specify the number of folds.</li>
<li>:term:<code>CV splitter</code>,</li>
<li>An iterable yielding (train, test) splits as arrays of indices.</li>
</ul>
<p>For integer/None inputs, :class:<code>KFold</code> is used.</p>
<p>Refer :ref:<code>User Guide &lt;cross_validation&gt;</code> for the various
cross-validation strategies that can be used here.</p>
<p>.. versionchanged:: 0.22
<code>cv</code> default value if None changed from 3-fold to 5-fold.</p>
<p>copy_X : boolean, optional, default True
If <code>True</code>, X will be copied; else, it may be overwritten.</p>
<p>verbose : bool or integer
Amount of verbosity.</p>
<p>n_jobs : int or None, optional (default=None)
Number of CPUs to use during the cross validation.
<code>None</code> means 1 unless in a :obj:<code>joblib.parallel_backend</code> context.
<code>-1</code> means using all processors. See :term:<code>Glossary &lt;n_jobs&gt;</code>
for more details.</p>
<p>positive : bool, optional
When set to <code>True</code>, forces the coefficients to be positive.</p>
<p>random_state : int, RandomState instance or None, optional, default None
The seed of the pseudo random number generator that selects a random
feature to update.  If int, random_state is the seed used by the random
number generator; If RandomState instance, random_state is the random
number generator; If None, the random number generator is the
RandomState instance used by <code>np.random</code>. Used when <code>selection</code> ==
'random'.</p>
<p>selection : str, default 'cyclic'
If set to 'random', a random coefficient is updated every iteration
rather than looping over features sequentially by default. This
(setting to 'random') often leads to significantly faster convergence
especially when tol is higher than 1e-4.</p>
<h2 id="attributes_3">Attributes<a class="headerlink" href="#attributes_3" title="Permanent link">&para;</a></h2>
<p>alpha_ : float
The amount of penalization chosen by cross validation</p>
<p>l1_ratio_ : float
The compromise between l1 and l2 penalization chosen by
cross validation</p>
<p>coef_ : array, shape (n_features,) | (n_targets, n_features)
Parameter vector (w in the cost function formula),</p>
<p>intercept_ : float | array, shape (n_targets, n_features)
Independent term in the decision function.</p>
<p>mse_path_ : array, shape (n_l1_ratio, n_alpha, n_folds)
Mean square error for the test set on each fold, varying l1_ratio and
alpha.</p>
<p>alphas_ : numpy array, shape (n_alphas,) or (n_l1_ratio, n_alphas)
The grid of alphas used for fitting, for each l1_ratio.</p>
<p>n_iter_ : int
number of iterations run by the coordinate descent solver to reach
the specified tolerance for the optimal alpha.</p>
<h2 id="examples_3">Examples<a class="headerlink" href="#examples_3" title="Permanent link">&para;</a></h2>
<blockquote>
<blockquote>
<blockquote>
<p>from sklearn.linear_model import ElasticNetCV
from sklearn.datasets import make_regression</p>
<p>X, y = make_regression(n_features=2, random_state=0)
regr = ElasticNetCV(cv=5, random_state=0)
regr.fit(X, y)
ElasticNetCV(cv=5, random_state=0)
print(regr.alpha_)
0.199...
print(regr.intercept_)
0.398...
print(regr.predict([[0, 0]]))
[0.398...]</p>
</blockquote>
</blockquote>
</blockquote>
<h2 id="notes_7">Notes<a class="headerlink" href="#notes_7" title="Permanent link">&para;</a></h2>
<p>For an example, see
:ref:<code>examples/linear_model/plot_lasso_model_selection.py
&lt;sphx_glr_auto_examples_linear_model_plot_lasso_model_selection.py&gt;</code>.</p>
<p>To avoid unnecessary memory duplication the X argument of the fit method
should be directly passed as a Fortran-contiguous numpy array.</p>
<p>The parameter l1_ratio corresponds to alpha in the glmnet R package
while alpha corresponds to the lambda parameter in glmnet.
More specifically, the optimization objective is::</p>
<p>1 / (2 * n_samples) * ||y - Xw||^2_2
+ alpha * l1_ratio * ||w||_1
+ 0.5 * alpha * (1 - l1_ratio) * ||w||^2_2</p>
<p>If you are interested in controlling the L1 and L2 penalty
separately, keep in mind that this is equivalent to::</p>
<p>a * L1 + b * L2</p>
<p>for::</p>
<p>alpha = a + b and l1_ratio = a / (a + b).</p>
<h2 id="see-also_1">See also<a class="headerlink" href="#see-also_1" title="Permanent link">&para;</a></h2>
<p>enet_path
ElasticNet</p>
<div class="highlight"><pre><span></span><code><span class="k">val</span> <span class="n">fit</span> <span class="o">:</span> <span class="n">x</span><span class="o">:</span><span class="nn">Py</span><span class="p">.</span><span class="nn">Object</span><span class="p">.</span><span class="n">t</span> <span class="o">-&gt;</span> <span class="n">y</span><span class="o">:[&gt;`</span><span class="nc">ArrayLike</span><span class="o">]</span> <span class="nn">Np</span><span class="p">.</span><span class="nn">Obj</span><span class="p">.</span><span class="n">t</span> <span class="o">-&gt;</span> <span class="o">[&gt;</span> <span class="n">tag</span><span class="o">]</span> <span class="nn">Obj</span><span class="p">.</span><span class="n">t</span> <span class="o">-&gt;</span> <span class="n">t</span>
</code></pre></div>

<p>Fit linear model with coordinate descent</p>
<p>Fit is on grid of alphas and best alpha estimated by cross-validation.</p>
<h2 id="parameters_19">Parameters<a class="headerlink" href="#parameters_19" title="Permanent link">&para;</a></h2>
<p>X : {array-like}, shape (n_samples, n_features)
Training data. Pass directly as Fortran-contiguous data
to avoid unnecessary memory duplication. If y is mono-output,
X can be sparse.</p>
<p>y : array-like, shape (n_samples,) or (n_samples, n_targets)
Target values</p>
<div class="highlight"><pre><span></span><code><span class="k">val</span> <span class="n">get_params</span> <span class="o">:</span> <span class="o">?</span><span class="n">deep</span><span class="o">:</span><span class="kt">bool</span> <span class="o">-&gt;</span> <span class="o">[&gt;</span> <span class="n">tag</span><span class="o">]</span> <span class="nn">Obj</span><span class="p">.</span><span class="n">t</span> <span class="o">-&gt;</span> <span class="nn">Dict</span><span class="p">.</span><span class="n">t</span>
</code></pre></div>

<p>Get parameters for this estimator.</p>
<h2 id="parameters_20">Parameters<a class="headerlink" href="#parameters_20" title="Permanent link">&para;</a></h2>
<p>deep : bool, default=True
If True, will return the parameters for this estimator and
contained subobjects that are estimators.</p>
<h2 id="returns_14">Returns<a class="headerlink" href="#returns_14" title="Permanent link">&para;</a></h2>
<p>params : mapping of string to any
Parameter names mapped to their values.</p>
<div class="highlight"><pre><span></span><code><span class="k">val</span> <span class="n">predict</span> <span class="o">:</span> <span class="n">x</span><span class="o">:[&gt;`</span><span class="nc">ArrayLike</span><span class="o">]</span> <span class="nn">Np</span><span class="p">.</span><span class="nn">Obj</span><span class="p">.</span><span class="n">t</span> <span class="o">-&gt;</span> <span class="o">[&gt;</span> <span class="n">tag</span><span class="o">]</span> <span class="nn">Obj</span><span class="p">.</span><span class="n">t</span> <span class="o">-&gt;</span> <span class="o">[&gt;`</span><span class="nc">ArrayLike</span><span class="o">]</span> <span class="nn">Np</span><span class="p">.</span><span class="nn">Obj</span><span class="p">.</span><span class="n">t</span>
</code></pre></div>

<p>Predict using the linear model.</p>
<h2 id="parameters_21">Parameters<a class="headerlink" href="#parameters_21" title="Permanent link">&para;</a></h2>
<p>X : array_like or sparse matrix, shape (n_samples, n_features)
Samples.</p>
<h2 id="returns_15">Returns<a class="headerlink" href="#returns_15" title="Permanent link">&para;</a></h2>
<p>C : array, shape (n_samples,)
Returns predicted values.</p>
<div class="highlight"><pre><span></span><code><span class="k">val</span> <span class="n">score</span> <span class="o">:</span> <span class="o">?</span><span class="n">sample_weight</span><span class="o">:[&gt;`</span><span class="nc">ArrayLike</span><span class="o">]</span> <span class="nn">Np</span><span class="p">.</span><span class="nn">Obj</span><span class="p">.</span><span class="n">t</span> <span class="o">-&gt;</span> <span class="n">x</span><span class="o">:[&gt;`</span><span class="nc">ArrayLike</span><span class="o">]</span> <span class="nn">Np</span><span class="p">.</span><span class="nn">Obj</span><span class="p">.</span><span class="n">t</span> <span class="o">-&gt;</span> <span class="n">y</span><span class="o">:[&gt;`</span><span class="nc">ArrayLike</span><span class="o">]</span> <span class="nn">Np</span><span class="p">.</span><span class="nn">Obj</span><span class="p">.</span><span class="n">t</span> <span class="o">-&gt;</span> <span class="o">[&gt;</span> <span class="n">tag</span><span class="o">]</span> <span class="nn">Obj</span><span class="p">.</span><span class="n">t</span> <span class="o">-&gt;</span> <span class="kt">float</span>
</code></pre></div>

<p>Return the coefficient of determination R^2 of the prediction.</p>
<p>The coefficient R^2 is defined as (1 - u/v), where u is the residual
sum of squares ((y_true - y_pred) <strong> 2).sum() and v is the total
sum of squares ((y_true - y_true.mean()) </strong> 2).sum().
The best possible score is 1.0 and it can be negative (because the
model can be arbitrarily worse). A constant model that always
predicts the expected value of y, disregarding the input features,
would get a R^2 score of 0.0.</p>
<h2 id="parameters_22">Parameters<a class="headerlink" href="#parameters_22" title="Permanent link">&para;</a></h2>
<p>X : array-like of shape (n_samples, n_features)
Test samples. For some estimators this may be a
precomputed kernel matrix or a list of generic objects instead,
shape = (n_samples, n_samples_fitted),
where n_samples_fitted is the number of
samples used in the fitting for the estimator.</p>
<p>y : array-like of shape (n_samples,) or (n_samples, n_outputs)
True values for X.</p>
<p>sample_weight : array-like of shape (n_samples,), default=None
Sample weights.</p>
<h2 id="returns_16">Returns<a class="headerlink" href="#returns_16" title="Permanent link">&para;</a></h2>
<p>score : float
R^2 of self.predict(X) wrt. y.</p>
<h2 id="notes_8">Notes<a class="headerlink" href="#notes_8" title="Permanent link">&para;</a></h2>
<p>The R2 score used when calling <code>score</code> on a regressor will use
<code>multioutput='uniform_average'</code> from version 0.23 to keep consistent
with :func:<code>~sklearn.metrics.r2_score</code>. This will influence the
<code>score</code> method of all the multioutput regressors (except for
:class:<code>~sklearn.multioutput.MultiOutputRegressor</code>). To specify the
default value manually and avoid the warning, please either call
:func:<code>~sklearn.metrics.r2_score</code> directly or make a custom scorer with
:func:<code>~sklearn.metrics.make_scorer</code> (the built-in scorer <code>'r2'</code> uses
<code>multioutput='uniform_average'</code>).</p>
<div class="highlight"><pre><span></span><code><span class="k">val</span> <span class="n">set_params</span> <span class="o">:</span> <span class="o">?</span><span class="n">params</span><span class="o">:(</span><span class="kt">string</span> <span class="o">*</span> <span class="nn">Py</span><span class="p">.</span><span class="nn">Object</span><span class="p">.</span><span class="n">t</span><span class="o">)</span> <span class="kt">list</span> <span class="o">-&gt;</span> <span class="o">[&gt;</span> <span class="n">tag</span><span class="o">]</span> <span class="nn">Obj</span><span class="p">.</span><span class="n">t</span> <span class="o">-&gt;</span> <span class="n">t</span>
</code></pre></div>

<p>Set the parameters of this estimator.</p>
<p>The method works on simple estimators as well as on nested objects
(such as pipelines). The latter have parameters of the form
<code>&lt;component&gt;__&lt;parameter&gt;</code> so that it's possible to update each
component of a nested object.</p>
<h2 id="parameters_23">Parameters<a class="headerlink" href="#parameters_23" title="Permanent link">&para;</a></h2>
<p>**params : dict
Estimator parameters.</p>
<h2 id="returns_17">Returns<a class="headerlink" href="#returns_17" title="Permanent link">&para;</a></h2>
<p>self : object
Estimator instance.</p>
<p>Attribute alpha_: get value or raise Not_found if None.</p>
<div class="highlight"><pre><span></span><code><span class="k">val</span> <span class="n">alpha_</span> <span class="o">:</span> <span class="n">t</span> <span class="o">-&gt;</span> <span class="kt">float</span>
</code></pre></div>

<p>Attribute alpha_: get value as an option.</p>
<div class="highlight"><pre><span></span><code><span class="k">val</span> <span class="n">alpha_opt</span> <span class="o">:</span> <span class="n">t</span> <span class="o">-&gt;</span> <span class="o">(</span><span class="kt">float</span><span class="o">)</span> <span class="n">option</span>
</code></pre></div>

<p>Attribute l1_ratio_: get value or raise Not_found if None.</p>
<div class="highlight"><pre><span></span><code><span class="k">val</span> <span class="n">l1_ratio_</span> <span class="o">:</span> <span class="n">t</span> <span class="o">-&gt;</span> <span class="kt">float</span>
</code></pre></div>

<p>Attribute l1_ratio_: get value as an option.</p>
<div class="highlight"><pre><span></span><code><span class="k">val</span> <span class="n">l1_ratio_opt</span> <span class="o">:</span> <span class="n">t</span> <span class="o">-&gt;</span> <span class="o">(</span><span class="kt">float</span><span class="o">)</span> <span class="n">option</span>
</code></pre></div>

<p>Attribute coef_: get value or raise Not_found if None.</p>
<div class="highlight"><pre><span></span><code><span class="k">val</span> <span class="n">coef_</span> <span class="o">:</span> <span class="n">t</span> <span class="o">-&gt;</span> <span class="o">[&gt;`</span><span class="nc">ArrayLike</span><span class="o">]</span> <span class="nn">Np</span><span class="p">.</span><span class="nn">Obj</span><span class="p">.</span><span class="n">t</span>
</code></pre></div>

<p>Attribute coef_: get value as an option.</p>
<div class="highlight"><pre><span></span><code><span class="k">val</span> <span class="n">coef_opt</span> <span class="o">:</span> <span class="n">t</span> <span class="o">-&gt;</span> <span class="o">([&gt;`</span><span class="nc">ArrayLike</span><span class="o">]</span> <span class="nn">Np</span><span class="p">.</span><span class="nn">Obj</span><span class="p">.</span><span class="n">t</span><span class="o">)</span> <span class="n">option</span>
</code></pre></div>

<p>Attribute intercept_: get value or raise Not_found if None.</p>
<div class="highlight"><pre><span></span><code><span class="k">val</span> <span class="n">intercept_</span> <span class="o">:</span> <span class="n">t</span> <span class="o">-&gt;</span> <span class="o">[&gt;`</span><span class="nc">ArrayLike</span><span class="o">]</span> <span class="nn">Np</span><span class="p">.</span><span class="nn">Obj</span><span class="p">.</span><span class="n">t</span>
</code></pre></div>

<p>Attribute intercept_: get value as an option.</p>
<div class="highlight"><pre><span></span><code><span class="k">val</span> <span class="n">intercept_opt</span> <span class="o">:</span> <span class="n">t</span> <span class="o">-&gt;</span> <span class="o">([&gt;`</span><span class="nc">ArrayLike</span><span class="o">]</span> <span class="nn">Np</span><span class="p">.</span><span class="nn">Obj</span><span class="p">.</span><span class="n">t</span><span class="o">)</span> <span class="n">option</span>
</code></pre></div>

<p>Attribute mse_path_: get value or raise Not_found if None.</p>
<div class="highlight"><pre><span></span><code><span class="k">val</span> <span class="n">mse_path_</span> <span class="o">:</span> <span class="n">t</span> <span class="o">-&gt;</span> <span class="o">[&gt;`</span><span class="nc">ArrayLike</span><span class="o">]</span> <span class="nn">Np</span><span class="p">.</span><span class="nn">Obj</span><span class="p">.</span><span class="n">t</span>
</code></pre></div>

<p>Attribute mse_path_: get value as an option.</p>
<div class="highlight"><pre><span></span><code><span class="k">val</span> <span class="n">mse_path_opt</span> <span class="o">:</span> <span class="n">t</span> <span class="o">-&gt;</span> <span class="o">([&gt;`</span><span class="nc">ArrayLike</span><span class="o">]</span> <span class="nn">Np</span><span class="p">.</span><span class="nn">Obj</span><span class="p">.</span><span class="n">t</span><span class="o">)</span> <span class="n">option</span>
</code></pre></div>

<p>Attribute alphas_: get value or raise Not_found if None.</p>
<div class="highlight"><pre><span></span><code><span class="k">val</span> <span class="n">alphas_</span> <span class="o">:</span> <span class="n">t</span> <span class="o">-&gt;</span> <span class="o">[&gt;`</span><span class="nc">ArrayLike</span><span class="o">]</span> <span class="nn">Np</span><span class="p">.</span><span class="nn">Obj</span><span class="p">.</span><span class="n">t</span>
</code></pre></div>

<p>Attribute alphas_: get value as an option.</p>
<div class="highlight"><pre><span></span><code><span class="k">val</span> <span class="n">alphas_opt</span> <span class="o">:</span> <span class="n">t</span> <span class="o">-&gt;</span> <span class="o">([&gt;`</span><span class="nc">ArrayLike</span><span class="o">]</span> <span class="nn">Np</span><span class="p">.</span><span class="nn">Obj</span><span class="p">.</span><span class="n">t</span><span class="o">)</span> <span class="n">option</span>
</code></pre></div>

<p>Attribute n_iter_: get value or raise Not_found if None.</p>
<div class="highlight"><pre><span></span><code><span class="k">val</span> <span class="n">n_iter_</span> <span class="o">:</span> <span class="n">t</span> <span class="o">-&gt;</span> <span class="kt">int</span>
</code></pre></div>

<p>Attribute n_iter_: get value as an option.</p>
<div class="highlight"><pre><span></span><code><span class="k">val</span> <span class="n">n_iter_opt</span> <span class="o">:</span> <span class="n">t</span> <span class="o">-&gt;</span> <span class="o">(</span><span class="kt">int</span><span class="o">)</span> <span class="n">option</span>
</code></pre></div>

<p>Print the object to a human-readable representation.</p>
<div class="highlight"><pre><span></span><code><span class="k">val</span> <span class="n">to_string</span> <span class="o">:</span> <span class="n">t</span> <span class="o">-&gt;</span> <span class="kt">string</span>
</code></pre></div>

<p>Print the object to a human-readable representation.</p>
<div class="highlight"><pre><span></span><code><span class="k">val</span> <span class="n">show</span> <span class="o">:</span> <span class="n">t</span> <span class="o">-&gt;</span> <span class="kt">string</span>
</code></pre></div>

<p>Pretty-print the object to a formatter.</p>
<div class="highlight"><pre><span></span><code><span class="k">val</span> <span class="n">pp</span> <span class="o">:</span> <span class="nn">Format</span><span class="p">.</span><span class="n">formatter</span> <span class="o">-&gt;</span> <span class="n">t</span> <span class="o">-&gt;</span> <span class="kt">unit</span> <span class="o">[@@</span><span class="n">ocaml</span><span class="o">.</span><span class="n">toplevel_printer</span><span class="o">]</span>



<span class="k">module</span> <span class="nc">Hinge</span> <span class="o">:</span> <span class="k">sig</span>
<span class="k">type</span> <span class="n">tag</span> <span class="o">=</span> <span class="o">[`</span><span class="nc">Hinge</span><span class="o">]</span>
<span class="k">type</span> <span class="n">t</span> <span class="o">=</span> <span class="o">[`</span><span class="nc">Hinge</span> <span class="o">|</span> <span class="o">`</span><span class="nc">Object</span><span class="o">]</span> <span class="nn">Obj</span><span class="p">.</span><span class="n">t</span>
<span class="k">val</span> <span class="n">of_pyobject</span> <span class="o">:</span> <span class="nn">Py</span><span class="p">.</span><span class="nn">Object</span><span class="p">.</span><span class="n">t</span> <span class="o">-&gt;</span> <span class="n">t</span>
<span class="k">val</span> <span class="n">to_pyobject</span> <span class="o">:</span> <span class="o">[&gt;</span> <span class="n">tag</span><span class="o">]</span> <span class="nn">Obj</span><span class="p">.</span><span class="n">t</span> <span class="o">-&gt;</span> <span class="nn">Py</span><span class="p">.</span><span class="nn">Object</span><span class="p">.</span><span class="n">t</span>
</code></pre></div>

<p>Print the object to a human-readable representation.</p>
<div class="highlight"><pre><span></span><code><span class="k">val</span> <span class="n">to_string</span> <span class="o">:</span> <span class="n">t</span> <span class="o">-&gt;</span> <span class="kt">string</span>
</code></pre></div>

<p>Print the object to a human-readable representation.</p>
<div class="highlight"><pre><span></span><code><span class="k">val</span> <span class="n">show</span> <span class="o">:</span> <span class="n">t</span> <span class="o">-&gt;</span> <span class="kt">string</span>
</code></pre></div>

<p>Pretty-print the object to a formatter.</p>
<div class="highlight"><pre><span></span><code><span class="k">val</span> <span class="n">pp</span> <span class="o">:</span> <span class="nn">Format</span><span class="p">.</span><span class="n">formatter</span> <span class="o">-&gt;</span> <span class="n">t</span> <span class="o">-&gt;</span> <span class="kt">unit</span> <span class="o">[@@</span><span class="n">ocaml</span><span class="o">.</span><span class="n">toplevel_printer</span><span class="o">]</span>



<span class="k">module</span> <span class="nc">Huber</span> <span class="o">:</span> <span class="k">sig</span>
<span class="k">type</span> <span class="n">tag</span> <span class="o">=</span> <span class="o">[`</span><span class="nc">Huber</span><span class="o">]</span>
<span class="k">type</span> <span class="n">t</span> <span class="o">=</span> <span class="o">[`</span><span class="nc">Huber</span> <span class="o">|</span> <span class="o">`</span><span class="nc">Object</span><span class="o">]</span> <span class="nn">Obj</span><span class="p">.</span><span class="n">t</span>
<span class="k">val</span> <span class="n">of_pyobject</span> <span class="o">:</span> <span class="nn">Py</span><span class="p">.</span><span class="nn">Object</span><span class="p">.</span><span class="n">t</span> <span class="o">-&gt;</span> <span class="n">t</span>
<span class="k">val</span> <span class="n">to_pyobject</span> <span class="o">:</span> <span class="o">[&gt;</span> <span class="n">tag</span><span class="o">]</span> <span class="nn">Obj</span><span class="p">.</span><span class="n">t</span> <span class="o">-&gt;</span> <span class="nn">Py</span><span class="p">.</span><span class="nn">Object</span><span class="p">.</span><span class="n">t</span>
</code></pre></div>

<p>Print the object to a human-readable representation.</p>
<div class="highlight"><pre><span></span><code><span class="k">val</span> <span class="n">to_string</span> <span class="o">:</span> <span class="n">t</span> <span class="o">-&gt;</span> <span class="kt">string</span>
</code></pre></div>

<p>Print the object to a human-readable representation.</p>
<div class="highlight"><pre><span></span><code><span class="k">val</span> <span class="n">show</span> <span class="o">:</span> <span class="n">t</span> <span class="o">-&gt;</span> <span class="kt">string</span>
</code></pre></div>

<p>Pretty-print the object to a formatter.</p>
<div class="highlight"><pre><span></span><code><span class="k">val</span> <span class="n">pp</span> <span class="o">:</span> <span class="nn">Format</span><span class="p">.</span><span class="n">formatter</span> <span class="o">-&gt;</span> <span class="n">t</span> <span class="o">-&gt;</span> <span class="kt">unit</span> <span class="o">[@@</span><span class="n">ocaml</span><span class="o">.</span><span class="n">toplevel_printer</span><span class="o">]</span>



<span class="k">module</span> <span class="nc">HuberRegressor</span> <span class="o">:</span> <span class="k">sig</span>
<span class="k">type</span> <span class="n">tag</span> <span class="o">=</span> <span class="o">[`</span><span class="nc">HuberRegressor</span><span class="o">]</span>
<span class="k">type</span> <span class="n">t</span> <span class="o">=</span> <span class="o">[`</span><span class="nc">BaseEstimator</span> <span class="o">|</span> <span class="o">`</span><span class="nc">HuberRegressor</span> <span class="o">|</span> <span class="o">`</span><span class="nc">Object</span> <span class="o">|</span> <span class="o">`</span><span class="nc">RegressorMixin</span><span class="o">]</span> <span class="nn">Obj</span><span class="p">.</span><span class="n">t</span>
<span class="k">val</span> <span class="n">of_pyobject</span> <span class="o">:</span> <span class="nn">Py</span><span class="p">.</span><span class="nn">Object</span><span class="p">.</span><span class="n">t</span> <span class="o">-&gt;</span> <span class="n">t</span>
<span class="k">val</span> <span class="n">to_pyobject</span> <span class="o">:</span> <span class="o">[&gt;</span> <span class="n">tag</span><span class="o">]</span> <span class="nn">Obj</span><span class="p">.</span><span class="n">t</span> <span class="o">-&gt;</span> <span class="nn">Py</span><span class="p">.</span><span class="nn">Object</span><span class="p">.</span><span class="n">t</span>

<span class="k">val</span> <span class="n">as_regressor</span> <span class="o">:</span> <span class="n">t</span> <span class="o">-&gt;</span> <span class="o">[`</span><span class="nc">RegressorMixin</span><span class="o">]</span> <span class="nn">Obj</span><span class="p">.</span><span class="n">t</span>
<span class="k">val</span> <span class="n">as_estimator</span> <span class="o">:</span> <span class="n">t</span> <span class="o">-&gt;</span> <span class="o">[`</span><span class="nc">BaseEstimator</span><span class="o">]</span> <span class="nn">Obj</span><span class="p">.</span><span class="n">t</span>
<span class="k">val</span> <span class="n">create</span> <span class="o">:</span> <span class="o">?</span><span class="n">epsilon</span><span class="o">:</span><span class="kt">float</span> <span class="o">-&gt;</span> <span class="o">?</span><span class="n">max_iter</span><span class="o">:</span><span class="kt">int</span> <span class="o">-&gt;</span> <span class="o">?</span><span class="n">alpha</span><span class="o">:</span><span class="kt">float</span> <span class="o">-&gt;</span> <span class="o">?</span><span class="n">warm_start</span><span class="o">:</span><span class="kt">bool</span> <span class="o">-&gt;</span> <span class="o">?</span><span class="n">fit_intercept</span><span class="o">:</span><span class="kt">bool</span> <span class="o">-&gt;</span> <span class="o">?</span><span class="n">tol</span><span class="o">:</span><span class="kt">float</span> <span class="o">-&gt;</span> <span class="kt">unit</span> <span class="o">-&gt;</span> <span class="n">t</span>
</code></pre></div>

<p>Linear regression model that is robust to outliers.</p>
<p>The Huber Regressor optimizes the squared loss for the samples where
<code>|(y - X'w) / sigma| &lt; epsilon</code> and the absolute loss for the samples
where <code>|(y - X'w) / sigma| &gt; epsilon</code>, where w and sigma are parameters
to be optimized. The parameter sigma makes sure that if y is scaled up
or down by a certain factor, one does not need to rescale epsilon to
achieve the same robustness. Note that this does not take into account
the fact that the different features of X may be of different scales.</p>
<p>This makes sure that the loss function is not heavily influenced by the
outliers while not completely ignoring their effect.</p>
<p>Read more in the :ref:<code>User Guide &lt;huber_regression&gt;</code></p>
<p>.. versionadded:: 0.18</p>
<h2 id="parameters_24">Parameters<a class="headerlink" href="#parameters_24" title="Permanent link">&para;</a></h2>
<p>epsilon : float, greater than 1.0, default 1.35
The parameter epsilon controls the number of samples that should be
classified as outliers. The smaller the epsilon, the more robust it is
to outliers.</p>
<p>max_iter : int, default 100
Maximum number of iterations that
<code>scipy.optimize.minimize(method='L-BFGS-B')</code> should run for.</p>
<p>alpha : float, default 0.0001
Regularization parameter.</p>
<p>warm_start : bool, default False
This is useful if the stored attributes of a previously used model
has to be reused. If set to False, then the coefficients will
be rewritten for every call to fit.
See :term:<code>the Glossary &lt;warm_start&gt;</code>.</p>
<p>fit_intercept : bool, default True
Whether or not to fit the intercept. This can be set to False
if the data is already centered around the origin.</p>
<p>tol : float, default 1e-5
The iteration will stop when
<code>max{ |proj g_i | i = 1, ..., n}</code> &lt;= <code>tol</code>
where pg_i is the i-th component of the projected gradient.</p>
<h2 id="attributes_4">Attributes<a class="headerlink" href="#attributes_4" title="Permanent link">&para;</a></h2>
<p>coef_ : array, shape (n_features,)
Features got by optimizing the Huber loss.</p>
<p>intercept_ : float
Bias.</p>
<p>scale_ : float
The value by which <code>|y - X'w - c|</code> is scaled down.</p>
<p>n_iter_ : int
Number of iterations that
<code>scipy.optimize.minimize(method='L-BFGS-B')</code> has run for.</p>
<p>.. versionchanged:: 0.20</p>
<p>In SciPy &lt;= 1.0.0 the number of lbfgs iterations may exceed
<code>max_iter</code>. <code>n_iter_</code> will now report at most <code>max_iter</code>.</p>
<p>outliers_ : array, shape (n_samples,)
A boolean mask which is set to True where the samples are identified
as outliers.</p>
<h2 id="examples_4">Examples<a class="headerlink" href="#examples_4" title="Permanent link">&para;</a></h2>
<blockquote>
<blockquote>
<blockquote>
<p>import numpy as np
from sklearn.linear_model import HuberRegressor, LinearRegression
from sklearn.datasets import make_regression
rng = np.random.RandomState(0)
X, y, coef = make_regression(
...     n_samples=200, n_features=2, noise=4.0, coef=True, random_state=0)
X[:4] = rng.uniform(10, 20, (4, 2))
y[:4] = rng.uniform(10, 20, 4)
huber = HuberRegressor().fit(X, y)
huber.score(X, y)
-7.284608623514573
huber.predict(X[:1,])
array([806.7200...])
linear = LinearRegression().fit(X, y)
print('True coefficients:', coef)
True coefficients: [20.4923...  34.1698...]
print('Huber coefficients:', huber.coef_)
Huber coefficients: [17.7906... 31.0106...]
print('Linear Regression coefficients:', linear.coef_)
Linear Regression coefficients: [-1.9221...  7.0226...]</p>
</blockquote>
</blockquote>
</blockquote>
<h2 id="references_2">References<a class="headerlink" href="#references_2" title="Permanent link">&para;</a></h2>
<p>.. [1] Peter J. Huber, Elvezio M. Ronchetti, Robust Statistics
Concomitant scale estimates, pg 172
.. [2] Art B. Owen (2006), A robust hybrid of lasso and ridge regression.
https://statweb.stanford.edu/~owen/reports/hhu.pdf</p>
<div class="highlight"><pre><span></span><code><span class="k">val</span> <span class="n">fit</span> <span class="o">:</span> <span class="o">?</span><span class="n">sample_weight</span><span class="o">:[&gt;`</span><span class="nc">ArrayLike</span><span class="o">]</span> <span class="nn">Np</span><span class="p">.</span><span class="nn">Obj</span><span class="p">.</span><span class="n">t</span> <span class="o">-&gt;</span> <span class="n">x</span><span class="o">:[&gt;`</span><span class="nc">ArrayLike</span><span class="o">]</span> <span class="nn">Np</span><span class="p">.</span><span class="nn">Obj</span><span class="p">.</span><span class="n">t</span> <span class="o">-&gt;</span> <span class="n">y</span><span class="o">:[&gt;`</span><span class="nc">ArrayLike</span><span class="o">]</span> <span class="nn">Np</span><span class="p">.</span><span class="nn">Obj</span><span class="p">.</span><span class="n">t</span> <span class="o">-&gt;</span> <span class="o">[&gt;</span> <span class="n">tag</span><span class="o">]</span> <span class="nn">Obj</span><span class="p">.</span><span class="n">t</span> <span class="o">-&gt;</span> <span class="n">t</span>
</code></pre></div>

<p>Fit the model according to the given training data.</p>
<h2 id="parameters_25">Parameters<a class="headerlink" href="#parameters_25" title="Permanent link">&para;</a></h2>
<p>X : array-like, shape (n_samples, n_features)
Training vector, where n_samples in the number of samples and
n_features is the number of features.</p>
<p>y : array-like, shape (n_samples,)
Target vector relative to X.</p>
<p>sample_weight : array-like, shape (n_samples,)
Weight given to each sample.</p>
<h2 id="returns_18">Returns<a class="headerlink" href="#returns_18" title="Permanent link">&para;</a></h2>
<p>self : object</p>
<div class="highlight"><pre><span></span><code><span class="k">val</span> <span class="n">get_params</span> <span class="o">:</span> <span class="o">?</span><span class="n">deep</span><span class="o">:</span><span class="kt">bool</span> <span class="o">-&gt;</span> <span class="o">[&gt;</span> <span class="n">tag</span><span class="o">]</span> <span class="nn">Obj</span><span class="p">.</span><span class="n">t</span> <span class="o">-&gt;</span> <span class="nn">Dict</span><span class="p">.</span><span class="n">t</span>
</code></pre></div>

<p>Get parameters for this estimator.</p>
<h2 id="parameters_26">Parameters<a class="headerlink" href="#parameters_26" title="Permanent link">&para;</a></h2>
<p>deep : bool, default=True
If True, will return the parameters for this estimator and
contained subobjects that are estimators.</p>
<h2 id="returns_19">Returns<a class="headerlink" href="#returns_19" title="Permanent link">&para;</a></h2>
<p>params : mapping of string to any
Parameter names mapped to their values.</p>
<div class="highlight"><pre><span></span><code><span class="k">val</span> <span class="n">predict</span> <span class="o">:</span> <span class="n">x</span><span class="o">:[&gt;`</span><span class="nc">ArrayLike</span><span class="o">]</span> <span class="nn">Np</span><span class="p">.</span><span class="nn">Obj</span><span class="p">.</span><span class="n">t</span> <span class="o">-&gt;</span> <span class="o">[&gt;</span> <span class="n">tag</span><span class="o">]</span> <span class="nn">Obj</span><span class="p">.</span><span class="n">t</span> <span class="o">-&gt;</span> <span class="o">[&gt;`</span><span class="nc">ArrayLike</span><span class="o">]</span> <span class="nn">Np</span><span class="p">.</span><span class="nn">Obj</span><span class="p">.</span><span class="n">t</span>
</code></pre></div>

<p>Predict using the linear model.</p>
<h2 id="parameters_27">Parameters<a class="headerlink" href="#parameters_27" title="Permanent link">&para;</a></h2>
<p>X : array_like or sparse matrix, shape (n_samples, n_features)
Samples.</p>
<h2 id="returns_20">Returns<a class="headerlink" href="#returns_20" title="Permanent link">&para;</a></h2>
<p>C : array, shape (n_samples,)
Returns predicted values.</p>
<div class="highlight"><pre><span></span><code><span class="k">val</span> <span class="n">score</span> <span class="o">:</span> <span class="o">?</span><span class="n">sample_weight</span><span class="o">:[&gt;`</span><span class="nc">ArrayLike</span><span class="o">]</span> <span class="nn">Np</span><span class="p">.</span><span class="nn">Obj</span><span class="p">.</span><span class="n">t</span> <span class="o">-&gt;</span> <span class="n">x</span><span class="o">:[&gt;`</span><span class="nc">ArrayLike</span><span class="o">]</span> <span class="nn">Np</span><span class="p">.</span><span class="nn">Obj</span><span class="p">.</span><span class="n">t</span> <span class="o">-&gt;</span> <span class="n">y</span><span class="o">:[&gt;`</span><span class="nc">ArrayLike</span><span class="o">]</span> <span class="nn">Np</span><span class="p">.</span><span class="nn">Obj</span><span class="p">.</span><span class="n">t</span> <span class="o">-&gt;</span> <span class="o">[&gt;</span> <span class="n">tag</span><span class="o">]</span> <span class="nn">Obj</span><span class="p">.</span><span class="n">t</span> <span class="o">-&gt;</span> <span class="kt">float</span>
</code></pre></div>

<p>Return the coefficient of determination R^2 of the prediction.</p>
<p>The coefficient R^2 is defined as (1 - u/v), where u is the residual
sum of squares ((y_true - y_pred) <strong> 2).sum() and v is the total
sum of squares ((y_true - y_true.mean()) </strong> 2).sum().
The best possible score is 1.0 and it can be negative (because the
model can be arbitrarily worse). A constant model that always
predicts the expected value of y, disregarding the input features,
would get a R^2 score of 0.0.</p>
<h2 id="parameters_28">Parameters<a class="headerlink" href="#parameters_28" title="Permanent link">&para;</a></h2>
<p>X : array-like of shape (n_samples, n_features)
Test samples. For some estimators this may be a
precomputed kernel matrix or a list of generic objects instead,
shape = (n_samples, n_samples_fitted),
where n_samples_fitted is the number of
samples used in the fitting for the estimator.</p>
<p>y : array-like of shape (n_samples,) or (n_samples, n_outputs)
True values for X.</p>
<p>sample_weight : array-like of shape (n_samples,), default=None
Sample weights.</p>
<h2 id="returns_21">Returns<a class="headerlink" href="#returns_21" title="Permanent link">&para;</a></h2>
<p>score : float
R^2 of self.predict(X) wrt. y.</p>
<h2 id="notes_9">Notes<a class="headerlink" href="#notes_9" title="Permanent link">&para;</a></h2>
<p>The R2 score used when calling <code>score</code> on a regressor will use
<code>multioutput='uniform_average'</code> from version 0.23 to keep consistent
with :func:<code>~sklearn.metrics.r2_score</code>. This will influence the
<code>score</code> method of all the multioutput regressors (except for
:class:<code>~sklearn.multioutput.MultiOutputRegressor</code>). To specify the
default value manually and avoid the warning, please either call
:func:<code>~sklearn.metrics.r2_score</code> directly or make a custom scorer with
:func:<code>~sklearn.metrics.make_scorer</code> (the built-in scorer <code>'r2'</code> uses
<code>multioutput='uniform_average'</code>).</p>
<div class="highlight"><pre><span></span><code><span class="k">val</span> <span class="n">set_params</span> <span class="o">:</span> <span class="o">?</span><span class="n">params</span><span class="o">:(</span><span class="kt">string</span> <span class="o">*</span> <span class="nn">Py</span><span class="p">.</span><span class="nn">Object</span><span class="p">.</span><span class="n">t</span><span class="o">)</span> <span class="kt">list</span> <span class="o">-&gt;</span> <span class="o">[&gt;</span> <span class="n">tag</span><span class="o">]</span> <span class="nn">Obj</span><span class="p">.</span><span class="n">t</span> <span class="o">-&gt;</span> <span class="n">t</span>
</code></pre></div>

<p>Set the parameters of this estimator.</p>
<p>The method works on simple estimators as well as on nested objects
(such as pipelines). The latter have parameters of the form
<code>&lt;component&gt;__&lt;parameter&gt;</code> so that it's possible to update each
component of a nested object.</p>
<h2 id="parameters_29">Parameters<a class="headerlink" href="#parameters_29" title="Permanent link">&para;</a></h2>
<p>**params : dict
Estimator parameters.</p>
<h2 id="returns_22">Returns<a class="headerlink" href="#returns_22" title="Permanent link">&para;</a></h2>
<p>self : object
Estimator instance.</p>
<p>Attribute coef_: get value or raise Not_found if None.</p>
<div class="highlight"><pre><span></span><code><span class="k">val</span> <span class="n">coef_</span> <span class="o">:</span> <span class="n">t</span> <span class="o">-&gt;</span> <span class="o">[&gt;`</span><span class="nc">ArrayLike</span><span class="o">]</span> <span class="nn">Np</span><span class="p">.</span><span class="nn">Obj</span><span class="p">.</span><span class="n">t</span>
</code></pre></div>

<p>Attribute coef_: get value as an option.</p>
<div class="highlight"><pre><span></span><code><span class="k">val</span> <span class="n">coef_opt</span> <span class="o">:</span> <span class="n">t</span> <span class="o">-&gt;</span> <span class="o">([&gt;`</span><span class="nc">ArrayLike</span><span class="o">]</span> <span class="nn">Np</span><span class="p">.</span><span class="nn">Obj</span><span class="p">.</span><span class="n">t</span><span class="o">)</span> <span class="n">option</span>
</code></pre></div>

<p>Attribute intercept_: get value or raise Not_found if None.</p>
<div class="highlight"><pre><span></span><code><span class="k">val</span> <span class="n">intercept_</span> <span class="o">:</span> <span class="n">t</span> <span class="o">-&gt;</span> <span class="o">[&gt;`</span><span class="nc">ArrayLike</span><span class="o">]</span> <span class="nn">Np</span><span class="p">.</span><span class="nn">Obj</span><span class="p">.</span><span class="n">t</span>
</code></pre></div>

<p>Attribute intercept_: get value as an option.</p>
<div class="highlight"><pre><span></span><code><span class="k">val</span> <span class="n">intercept_opt</span> <span class="o">:</span> <span class="n">t</span> <span class="o">-&gt;</span> <span class="o">([&gt;`</span><span class="nc">ArrayLike</span><span class="o">]</span> <span class="nn">Np</span><span class="p">.</span><span class="nn">Obj</span><span class="p">.</span><span class="n">t</span><span class="o">)</span> <span class="n">option</span>
</code></pre></div>

<p>Attribute scale_: get value or raise Not_found if None.</p>
<div class="highlight"><pre><span></span><code><span class="k">val</span> <span class="n">scale_</span> <span class="o">:</span> <span class="n">t</span> <span class="o">-&gt;</span> <span class="kt">float</span>
</code></pre></div>

<p>Attribute scale_: get value as an option.</p>
<div class="highlight"><pre><span></span><code><span class="k">val</span> <span class="n">scale_opt</span> <span class="o">:</span> <span class="n">t</span> <span class="o">-&gt;</span> <span class="o">(</span><span class="kt">float</span><span class="o">)</span> <span class="n">option</span>
</code></pre></div>

<p>Attribute n_iter_: get value or raise Not_found if None.</p>
<div class="highlight"><pre><span></span><code><span class="k">val</span> <span class="n">n_iter_</span> <span class="o">:</span> <span class="n">t</span> <span class="o">-&gt;</span> <span class="kt">int</span>
</code></pre></div>

<p>Attribute n_iter_: get value as an option.</p>
<div class="highlight"><pre><span></span><code><span class="k">val</span> <span class="n">n_iter_opt</span> <span class="o">:</span> <span class="n">t</span> <span class="o">-&gt;</span> <span class="o">(</span><span class="kt">int</span><span class="o">)</span> <span class="n">option</span>
</code></pre></div>

<p>Attribute outliers_: get value or raise Not_found if None.</p>
<div class="highlight"><pre><span></span><code><span class="k">val</span> <span class="n">outliers_</span> <span class="o">:</span> <span class="n">t</span> <span class="o">-&gt;</span> <span class="o">[&gt;`</span><span class="nc">ArrayLike</span><span class="o">]</span> <span class="nn">Np</span><span class="p">.</span><span class="nn">Obj</span><span class="p">.</span><span class="n">t</span>
</code></pre></div>

<p>Attribute outliers_: get value as an option.</p>
<div class="highlight"><pre><span></span><code><span class="k">val</span> <span class="n">outliers_opt</span> <span class="o">:</span> <span class="n">t</span> <span class="o">-&gt;</span> <span class="o">([&gt;`</span><span class="nc">ArrayLike</span><span class="o">]</span> <span class="nn">Np</span><span class="p">.</span><span class="nn">Obj</span><span class="p">.</span><span class="n">t</span><span class="o">)</span> <span class="n">option</span>
</code></pre></div>

<p>Print the object to a human-readable representation.</p>
<div class="highlight"><pre><span></span><code><span class="k">val</span> <span class="n">to_string</span> <span class="o">:</span> <span class="n">t</span> <span class="o">-&gt;</span> <span class="kt">string</span>
</code></pre></div>

<p>Print the object to a human-readable representation.</p>
<div class="highlight"><pre><span></span><code><span class="k">val</span> <span class="n">show</span> <span class="o">:</span> <span class="n">t</span> <span class="o">-&gt;</span> <span class="kt">string</span>
</code></pre></div>

<p>Pretty-print the object to a formatter.</p>
<div class="highlight"><pre><span></span><code><span class="k">val</span> <span class="n">pp</span> <span class="o">:</span> <span class="nn">Format</span><span class="p">.</span><span class="n">formatter</span> <span class="o">-&gt;</span> <span class="n">t</span> <span class="o">-&gt;</span> <span class="kt">unit</span> <span class="o">[@@</span><span class="n">ocaml</span><span class="o">.</span><span class="n">toplevel_printer</span><span class="o">]</span>



<span class="k">module</span> <span class="nc">Lars</span> <span class="o">:</span> <span class="k">sig</span>
<span class="k">type</span> <span class="n">tag</span> <span class="o">=</span> <span class="o">[`</span><span class="nc">Lars</span><span class="o">]</span>
<span class="k">type</span> <span class="n">t</span> <span class="o">=</span> <span class="o">[`</span><span class="nc">BaseEstimator</span> <span class="o">|</span> <span class="o">`</span><span class="nc">Lars</span> <span class="o">|</span> <span class="o">`</span><span class="nc">MultiOutputMixin</span> <span class="o">|</span> <span class="o">`</span><span class="nc">Object</span> <span class="o">|</span> <span class="o">`</span><span class="nc">RegressorMixin</span><span class="o">]</span> <span class="nn">Obj</span><span class="p">.</span><span class="n">t</span>
<span class="k">val</span> <span class="n">of_pyobject</span> <span class="o">:</span> <span class="nn">Py</span><span class="p">.</span><span class="nn">Object</span><span class="p">.</span><span class="n">t</span> <span class="o">-&gt;</span> <span class="n">t</span>
<span class="k">val</span> <span class="n">to_pyobject</span> <span class="o">:</span> <span class="o">[&gt;</span> <span class="n">tag</span><span class="o">]</span> <span class="nn">Obj</span><span class="p">.</span><span class="n">t</span> <span class="o">-&gt;</span> <span class="nn">Py</span><span class="p">.</span><span class="nn">Object</span><span class="p">.</span><span class="n">t</span>

<span class="k">val</span> <span class="n">as_regressor</span> <span class="o">:</span> <span class="n">t</span> <span class="o">-&gt;</span> <span class="o">[`</span><span class="nc">RegressorMixin</span><span class="o">]</span> <span class="nn">Obj</span><span class="p">.</span><span class="n">t</span>
<span class="k">val</span> <span class="n">as_multi_output</span> <span class="o">:</span> <span class="n">t</span> <span class="o">-&gt;</span> <span class="o">[`</span><span class="nc">MultiOutputMixin</span><span class="o">]</span> <span class="nn">Obj</span><span class="p">.</span><span class="n">t</span>
<span class="k">val</span> <span class="n">as_estimator</span> <span class="o">:</span> <span class="n">t</span> <span class="o">-&gt;</span> <span class="o">[`</span><span class="nc">BaseEstimator</span><span class="o">]</span> <span class="nn">Obj</span><span class="p">.</span><span class="n">t</span>
<span class="k">val</span> <span class="n">create</span> <span class="o">:</span> <span class="o">?</span><span class="n">fit_intercept</span><span class="o">:</span><span class="kt">bool</span> <span class="o">-&gt;</span> <span class="o">?</span><span class="n">verbose</span><span class="o">:</span><span class="kt">int</span> <span class="o">-&gt;</span> <span class="o">?</span><span class="n">normalize</span><span class="o">:</span><span class="kt">bool</span> <span class="o">-&gt;</span> <span class="o">?</span><span class="n">precompute</span><span class="o">:[`</span><span class="nc">Arr</span> <span class="k">of</span> <span class="o">[&gt;`</span><span class="nc">ArrayLike</span><span class="o">]</span> <span class="nn">Np</span><span class="p">.</span><span class="nn">Obj</span><span class="p">.</span><span class="n">t</span> <span class="o">|</span> <span class="o">`</span><span class="nc">Auto</span> <span class="o">|</span> <span class="o">`</span><span class="nc">Bool</span> <span class="k">of</span> <span class="kt">bool</span><span class="o">]</span> <span class="o">-&gt;</span> <span class="o">?</span><span class="n">n_nonzero_coefs</span><span class="o">:</span><span class="kt">int</span> <span class="o">-&gt;</span> <span class="o">?</span><span class="n">eps</span><span class="o">:</span><span class="kt">float</span> <span class="o">-&gt;</span> <span class="o">?</span><span class="n">copy_X</span><span class="o">:</span><span class="kt">bool</span> <span class="o">-&gt;</span> <span class="o">?</span><span class="n">fit_path</span><span class="o">:</span><span class="kt">bool</span> <span class="o">-&gt;</span> <span class="kt">unit</span> <span class="o">-&gt;</span> <span class="n">t</span>
</code></pre></div>

<p>Least Angle Regression model a.k.a. LAR</p>
<p>Read more in the :ref:<code>User Guide &lt;least_angle_regression&gt;</code>.</p>
<h2 id="parameters_30">Parameters<a class="headerlink" href="#parameters_30" title="Permanent link">&para;</a></h2>
<p>fit_intercept : bool, default=True
Whether to calculate the intercept for this model. If set
to false, no intercept will be used in calculations
(i.e. data is expected to be centered).</p>
<p>verbose : bool or int, default=False
Sets the verbosity amount</p>
<p>normalize : bool, default=True
This parameter is ignored when <code>fit_intercept</code> is set to False.
If True, the regressors X will be normalized before regression by
subtracting the mean and dividing by the l2-norm.
If you wish to standardize, please use
:class:<code>sklearn.preprocessing.StandardScaler</code> before calling <code>fit</code>
on an estimator with <code>normalize=False</code>.</p>
<p>precompute : bool, 'auto' or array-like , default='auto'
Whether to use a precomputed Gram matrix to speed up
calculations. If set to <code>'auto'</code> let us decide. The Gram
matrix can also be passed as argument.</p>
<p>n_nonzero_coefs : int, default=500
Target number of non-zero coefficients. Use <code>np.inf</code> for no limit.</p>
<p>eps : float, optional
The machine-precision regularization in the computation of the
Cholesky diagonal factors. Increase this for very ill-conditioned
systems. Unlike the <code>tol</code> parameter in some iterative
optimization-based algorithms, this parameter does not control
the tolerance of the optimization.
By default, <code>np.finfo(np.float).eps</code> is used.</p>
<p>copy_X : bool, default=True
If <code>True</code>, X will be copied; else, it may be overwritten.</p>
<p>fit_path : bool, default=True
If True the full path is stored in the <code>coef_path_</code> attribute.
If you compute the solution for a large problem or many targets,
setting <code>fit_path</code> to <code>False</code> will lead to a speedup, especially
with a small alpha.</p>
<h2 id="attributes_5">Attributes<a class="headerlink" href="#attributes_5" title="Permanent link">&para;</a></h2>
<p>alphas_ : array-like of shape (n_alphas + 1,) | list of n_targets such             arrays
Maximum of covariances (in absolute value) at each iteration.         <code>n_alphas</code> is either <code>n_nonzero_coefs</code> or <code>n_features</code>,         whichever is smaller.</p>
<p>active_ : list, length = n_alphas | list of n_targets such lists
Indices of active variables at the end of the path.</p>
<p>coef_path_ : array-like of shape (n_features, n_alphas + 1)         | list of n_targets such arrays
The varying values of the coefficients along the path. It is not
present if the <code>fit_path</code> parameter is <code>False</code>.</p>
<p>coef_ : array-like of shape (n_features,) or (n_targets, n_features)
Parameter vector (w in the formulation formula).</p>
<p>intercept_ : float or array-like of shape (n_targets,)
Independent term in decision function.</p>
<p>n_iter_ : array-like or int
The number of iterations taken by lars_path to find the
grid of alphas for each target.</p>
<h2 id="examples_5">Examples<a class="headerlink" href="#examples_5" title="Permanent link">&para;</a></h2>
<blockquote>
<blockquote>
<blockquote>
<p>from sklearn import linear_model
reg = linear_model.Lars(n_nonzero_coefs=1)
reg.fit([[-1, 1], [0, 0], [1, 1]], [-1.1111, 0, -1.1111])
Lars(n_nonzero_coefs=1)
print(reg.coef_)
[ 0. -1.11...]</p>
</blockquote>
</blockquote>
</blockquote>
<h2 id="see-also_2">See also<a class="headerlink" href="#see-also_2" title="Permanent link">&para;</a></h2>
<p>lars_path, LarsCV
sklearn.decomposition.sparse_encode</p>
<div class="highlight"><pre><span></span><code><span class="k">val</span> <span class="n">fit</span> <span class="o">:</span> <span class="o">?</span><span class="n">xy</span><span class="o">:[&gt;`</span><span class="nc">ArrayLike</span><span class="o">]</span> <span class="nn">Np</span><span class="p">.</span><span class="nn">Obj</span><span class="p">.</span><span class="n">t</span> <span class="o">-&gt;</span> <span class="n">x</span><span class="o">:[&gt;`</span><span class="nc">ArrayLike</span><span class="o">]</span> <span class="nn">Np</span><span class="p">.</span><span class="nn">Obj</span><span class="p">.</span><span class="n">t</span> <span class="o">-&gt;</span> <span class="n">y</span><span class="o">:[&gt;`</span><span class="nc">ArrayLike</span><span class="o">]</span> <span class="nn">Np</span><span class="p">.</span><span class="nn">Obj</span><span class="p">.</span><span class="n">t</span> <span class="o">-&gt;</span> <span class="o">[&gt;</span> <span class="n">tag</span><span class="o">]</span> <span class="nn">Obj</span><span class="p">.</span><span class="n">t</span> <span class="o">-&gt;</span> <span class="n">t</span>
</code></pre></div>

<p>Fit the model using X, y as training data.</p>
<h2 id="parameters_31">Parameters<a class="headerlink" href="#parameters_31" title="Permanent link">&para;</a></h2>
<p>X : array-like of shape (n_samples, n_features)
Training data.</p>
<p>y : array-like of shape (n_samples,) or (n_samples, n_targets)
Target values.</p>
<p>Xy : array-like of shape (n_samples,) or (n_samples, n_targets),                 default=None
Xy = np.dot(X.T, y) that can be precomputed. It is useful
only when the Gram matrix is precomputed.</p>
<h2 id="returns_23">Returns<a class="headerlink" href="#returns_23" title="Permanent link">&para;</a></h2>
<p>self : object
returns an instance of self.</p>
<div class="highlight"><pre><span></span><code><span class="k">val</span> <span class="n">get_params</span> <span class="o">:</span> <span class="o">?</span><span class="n">deep</span><span class="o">:</span><span class="kt">bool</span> <span class="o">-&gt;</span> <span class="o">[&gt;</span> <span class="n">tag</span><span class="o">]</span> <span class="nn">Obj</span><span class="p">.</span><span class="n">t</span> <span class="o">-&gt;</span> <span class="nn">Dict</span><span class="p">.</span><span class="n">t</span>
</code></pre></div>

<p>Get parameters for this estimator.</p>
<h2 id="parameters_32">Parameters<a class="headerlink" href="#parameters_32" title="Permanent link">&para;</a></h2>
<p>deep : bool, default=True
If True, will return the parameters for this estimator and
contained subobjects that are estimators.</p>
<h2 id="returns_24">Returns<a class="headerlink" href="#returns_24" title="Permanent link">&para;</a></h2>
<p>params : mapping of string to any
Parameter names mapped to their values.</p>
<div class="highlight"><pre><span></span><code><span class="k">val</span> <span class="n">predict</span> <span class="o">:</span> <span class="n">x</span><span class="o">:[&gt;`</span><span class="nc">ArrayLike</span><span class="o">]</span> <span class="nn">Np</span><span class="p">.</span><span class="nn">Obj</span><span class="p">.</span><span class="n">t</span> <span class="o">-&gt;</span> <span class="o">[&gt;</span> <span class="n">tag</span><span class="o">]</span> <span class="nn">Obj</span><span class="p">.</span><span class="n">t</span> <span class="o">-&gt;</span> <span class="o">[&gt;`</span><span class="nc">ArrayLike</span><span class="o">]</span> <span class="nn">Np</span><span class="p">.</span><span class="nn">Obj</span><span class="p">.</span><span class="n">t</span>
</code></pre></div>

<p>Predict using the linear model.</p>
<h2 id="parameters_33">Parameters<a class="headerlink" href="#parameters_33" title="Permanent link">&para;</a></h2>
<p>X : array_like or sparse matrix, shape (n_samples, n_features)
Samples.</p>
<h2 id="returns_25">Returns<a class="headerlink" href="#returns_25" title="Permanent link">&para;</a></h2>
<p>C : array, shape (n_samples,)
Returns predicted values.</p>
<div class="highlight"><pre><span></span><code><span class="k">val</span> <span class="n">score</span> <span class="o">:</span> <span class="o">?</span><span class="n">sample_weight</span><span class="o">:[&gt;`</span><span class="nc">ArrayLike</span><span class="o">]</span> <span class="nn">Np</span><span class="p">.</span><span class="nn">Obj</span><span class="p">.</span><span class="n">t</span> <span class="o">-&gt;</span> <span class="n">x</span><span class="o">:[&gt;`</span><span class="nc">ArrayLike</span><span class="o">]</span> <span class="nn">Np</span><span class="p">.</span><span class="nn">Obj</span><span class="p">.</span><span class="n">t</span> <span class="o">-&gt;</span> <span class="n">y</span><span class="o">:[&gt;`</span><span class="nc">ArrayLike</span><span class="o">]</span> <span class="nn">Np</span><span class="p">.</span><span class="nn">Obj</span><span class="p">.</span><span class="n">t</span> <span class="o">-&gt;</span> <span class="o">[&gt;</span> <span class="n">tag</span><span class="o">]</span> <span class="nn">Obj</span><span class="p">.</span><span class="n">t</span> <span class="o">-&gt;</span> <span class="kt">float</span>
</code></pre></div>

<p>Return the coefficient of determination R^2 of the prediction.</p>
<p>The coefficient R^2 is defined as (1 - u/v), where u is the residual
sum of squares ((y_true - y_pred) <strong> 2).sum() and v is the total
sum of squares ((y_true - y_true.mean()) </strong> 2).sum().
The best possible score is 1.0 and it can be negative (because the
model can be arbitrarily worse). A constant model that always
predicts the expected value of y, disregarding the input features,
would get a R^2 score of 0.0.</p>
<h2 id="parameters_34">Parameters<a class="headerlink" href="#parameters_34" title="Permanent link">&para;</a></h2>
<p>X : array-like of shape (n_samples, n_features)
Test samples. For some estimators this may be a
precomputed kernel matrix or a list of generic objects instead,
shape = (n_samples, n_samples_fitted),
where n_samples_fitted is the number of
samples used in the fitting for the estimator.</p>
<p>y : array-like of shape (n_samples,) or (n_samples, n_outputs)
True values for X.</p>
<p>sample_weight : array-like of shape (n_samples,), default=None
Sample weights.</p>
<h2 id="returns_26">Returns<a class="headerlink" href="#returns_26" title="Permanent link">&para;</a></h2>
<p>score : float
R^2 of self.predict(X) wrt. y.</p>
<h2 id="notes_10">Notes<a class="headerlink" href="#notes_10" title="Permanent link">&para;</a></h2>
<p>The R2 score used when calling <code>score</code> on a regressor will use
<code>multioutput='uniform_average'</code> from version 0.23 to keep consistent
with :func:<code>~sklearn.metrics.r2_score</code>. This will influence the
<code>score</code> method of all the multioutput regressors (except for
:class:<code>~sklearn.multioutput.MultiOutputRegressor</code>). To specify the
default value manually and avoid the warning, please either call
:func:<code>~sklearn.metrics.r2_score</code> directly or make a custom scorer with
:func:<code>~sklearn.metrics.make_scorer</code> (the built-in scorer <code>'r2'</code> uses
<code>multioutput='uniform_average'</code>).</p>
<div class="highlight"><pre><span></span><code><span class="k">val</span> <span class="n">set_params</span> <span class="o">:</span> <span class="o">?</span><span class="n">params</span><span class="o">:(</span><span class="kt">string</span> <span class="o">*</span> <span class="nn">Py</span><span class="p">.</span><span class="nn">Object</span><span class="p">.</span><span class="n">t</span><span class="o">)</span> <span class="kt">list</span> <span class="o">-&gt;</span> <span class="o">[&gt;</span> <span class="n">tag</span><span class="o">]</span> <span class="nn">Obj</span><span class="p">.</span><span class="n">t</span> <span class="o">-&gt;</span> <span class="n">t</span>
</code></pre></div>

<p>Set the parameters of this estimator.</p>
<p>The method works on simple estimators as well as on nested objects
(such as pipelines). The latter have parameters of the form
<code>&lt;component&gt;__&lt;parameter&gt;</code> so that it's possible to update each
component of a nested object.</p>
<h2 id="parameters_35">Parameters<a class="headerlink" href="#parameters_35" title="Permanent link">&para;</a></h2>
<p>**params : dict
Estimator parameters.</p>
<h2 id="returns_27">Returns<a class="headerlink" href="#returns_27" title="Permanent link">&para;</a></h2>
<p>self : object
Estimator instance.</p>
<p>Attribute alphas_: get value or raise Not_found if None.</p>
<div class="highlight"><pre><span></span><code><span class="k">val</span> <span class="n">alphas_</span> <span class="o">:</span> <span class="n">t</span> <span class="o">-&gt;</span> <span class="nn">Py</span><span class="p">.</span><span class="nn">Object</span><span class="p">.</span><span class="n">t</span>
</code></pre></div>

<p>Attribute alphas_: get value as an option.</p>
<div class="highlight"><pre><span></span><code><span class="k">val</span> <span class="n">alphas_opt</span> <span class="o">:</span> <span class="n">t</span> <span class="o">-&gt;</span> <span class="o">(</span><span class="nn">Py</span><span class="p">.</span><span class="nn">Object</span><span class="p">.</span><span class="n">t</span><span class="o">)</span> <span class="n">option</span>
</code></pre></div>

<p>Attribute active_: get value or raise Not_found if None.</p>
<div class="highlight"><pre><span></span><code><span class="k">val</span> <span class="n">active_</span> <span class="o">:</span> <span class="n">t</span> <span class="o">-&gt;</span> <span class="nn">Py</span><span class="p">.</span><span class="nn">Object</span><span class="p">.</span><span class="n">t</span>
</code></pre></div>

<p>Attribute active_: get value as an option.</p>
<div class="highlight"><pre><span></span><code><span class="k">val</span> <span class="n">active_opt</span> <span class="o">:</span> <span class="n">t</span> <span class="o">-&gt;</span> <span class="o">(</span><span class="nn">Py</span><span class="p">.</span><span class="nn">Object</span><span class="p">.</span><span class="n">t</span><span class="o">)</span> <span class="n">option</span>
</code></pre></div>

<p>Attribute coef_path_: get value or raise Not_found if None.</p>
<div class="highlight"><pre><span></span><code><span class="k">val</span> <span class="n">coef_path_</span> <span class="o">:</span> <span class="n">t</span> <span class="o">-&gt;</span> <span class="nn">Py</span><span class="p">.</span><span class="nn">Object</span><span class="p">.</span><span class="n">t</span>
</code></pre></div>

<p>Attribute coef_path_: get value as an option.</p>
<div class="highlight"><pre><span></span><code><span class="k">val</span> <span class="n">coef_path_opt</span> <span class="o">:</span> <span class="n">t</span> <span class="o">-&gt;</span> <span class="o">(</span><span class="nn">Py</span><span class="p">.</span><span class="nn">Object</span><span class="p">.</span><span class="n">t</span><span class="o">)</span> <span class="n">option</span>
</code></pre></div>

<p>Attribute coef_: get value or raise Not_found if None.</p>
<div class="highlight"><pre><span></span><code><span class="k">val</span> <span class="n">coef_</span> <span class="o">:</span> <span class="n">t</span> <span class="o">-&gt;</span> <span class="o">[&gt;`</span><span class="nc">ArrayLike</span><span class="o">]</span> <span class="nn">Np</span><span class="p">.</span><span class="nn">Obj</span><span class="p">.</span><span class="n">t</span>
</code></pre></div>

<p>Attribute coef_: get value as an option.</p>
<div class="highlight"><pre><span></span><code><span class="k">val</span> <span class="n">coef_opt</span> <span class="o">:</span> <span class="n">t</span> <span class="o">-&gt;</span> <span class="o">([&gt;`</span><span class="nc">ArrayLike</span><span class="o">]</span> <span class="nn">Np</span><span class="p">.</span><span class="nn">Obj</span><span class="p">.</span><span class="n">t</span><span class="o">)</span> <span class="n">option</span>
</code></pre></div>

<p>Attribute intercept_: get value or raise Not_found if None.</p>
<div class="highlight"><pre><span></span><code><span class="k">val</span> <span class="n">intercept_</span> <span class="o">:</span> <span class="n">t</span> <span class="o">-&gt;</span> <span class="o">[&gt;`</span><span class="nc">ArrayLike</span><span class="o">]</span> <span class="nn">Np</span><span class="p">.</span><span class="nn">Obj</span><span class="p">.</span><span class="n">t</span>
</code></pre></div>

<p>Attribute intercept_: get value as an option.</p>
<div class="highlight"><pre><span></span><code><span class="k">val</span> <span class="n">intercept_opt</span> <span class="o">:</span> <span class="n">t</span> <span class="o">-&gt;</span> <span class="o">([&gt;`</span><span class="nc">ArrayLike</span><span class="o">]</span> <span class="nn">Np</span><span class="p">.</span><span class="nn">Obj</span><span class="p">.</span><span class="n">t</span><span class="o">)</span> <span class="n">option</span>
</code></pre></div>

<p>Attribute n_iter_: get value or raise Not_found if None.</p>
<div class="highlight"><pre><span></span><code><span class="k">val</span> <span class="n">n_iter_</span> <span class="o">:</span> <span class="n">t</span> <span class="o">-&gt;</span> <span class="nn">Py</span><span class="p">.</span><span class="nn">Object</span><span class="p">.</span><span class="n">t</span>
</code></pre></div>

<p>Attribute n_iter_: get value as an option.</p>
<div class="highlight"><pre><span></span><code><span class="k">val</span> <span class="n">n_iter_opt</span> <span class="o">:</span> <span class="n">t</span> <span class="o">-&gt;</span> <span class="o">(</span><span class="nn">Py</span><span class="p">.</span><span class="nn">Object</span><span class="p">.</span><span class="n">t</span><span class="o">)</span> <span class="n">option</span>
</code></pre></div>

<p>Print the object to a human-readable representation.</p>
<div class="highlight"><pre><span></span><code><span class="k">val</span> <span class="n">to_string</span> <span class="o">:</span> <span class="n">t</span> <span class="o">-&gt;</span> <span class="kt">string</span>
</code></pre></div>

<p>Print the object to a human-readable representation.</p>
<div class="highlight"><pre><span></span><code><span class="k">val</span> <span class="n">show</span> <span class="o">:</span> <span class="n">t</span> <span class="o">-&gt;</span> <span class="kt">string</span>
</code></pre></div>

<p>Pretty-print the object to a formatter.</p>
<div class="highlight"><pre><span></span><code><span class="k">val</span> <span class="n">pp</span> <span class="o">:</span> <span class="nn">Format</span><span class="p">.</span><span class="n">formatter</span> <span class="o">-&gt;</span> <span class="n">t</span> <span class="o">-&gt;</span> <span class="kt">unit</span> <span class="o">[@@</span><span class="n">ocaml</span><span class="o">.</span><span class="n">toplevel_printer</span><span class="o">]</span>



<span class="k">module</span> <span class="nc">LarsCV</span> <span class="o">:</span> <span class="k">sig</span>
<span class="k">type</span> <span class="n">tag</span> <span class="o">=</span> <span class="o">[`</span><span class="nc">LarsCV</span><span class="o">]</span>
<span class="k">type</span> <span class="n">t</span> <span class="o">=</span> <span class="o">[`</span><span class="nc">BaseEstimator</span> <span class="o">|</span> <span class="o">`</span><span class="nc">LarsCV</span> <span class="o">|</span> <span class="o">`</span><span class="nc">MultiOutputMixin</span> <span class="o">|</span> <span class="o">`</span><span class="nc">Object</span> <span class="o">|</span> <span class="o">`</span><span class="nc">RegressorMixin</span><span class="o">]</span> <span class="nn">Obj</span><span class="p">.</span><span class="n">t</span>
<span class="k">val</span> <span class="n">of_pyobject</span> <span class="o">:</span> <span class="nn">Py</span><span class="p">.</span><span class="nn">Object</span><span class="p">.</span><span class="n">t</span> <span class="o">-&gt;</span> <span class="n">t</span>
<span class="k">val</span> <span class="n">to_pyobject</span> <span class="o">:</span> <span class="o">[&gt;</span> <span class="n">tag</span><span class="o">]</span> <span class="nn">Obj</span><span class="p">.</span><span class="n">t</span> <span class="o">-&gt;</span> <span class="nn">Py</span><span class="p">.</span><span class="nn">Object</span><span class="p">.</span><span class="n">t</span>

<span class="k">val</span> <span class="n">as_regressor</span> <span class="o">:</span> <span class="n">t</span> <span class="o">-&gt;</span> <span class="o">[`</span><span class="nc">RegressorMixin</span><span class="o">]</span> <span class="nn">Obj</span><span class="p">.</span><span class="n">t</span>
<span class="k">val</span> <span class="n">as_multi_output</span> <span class="o">:</span> <span class="n">t</span> <span class="o">-&gt;</span> <span class="o">[`</span><span class="nc">MultiOutputMixin</span><span class="o">]</span> <span class="nn">Obj</span><span class="p">.</span><span class="n">t</span>
<span class="k">val</span> <span class="n">as_estimator</span> <span class="o">:</span> <span class="n">t</span> <span class="o">-&gt;</span> <span class="o">[`</span><span class="nc">BaseEstimator</span><span class="o">]</span> <span class="nn">Obj</span><span class="p">.</span><span class="n">t</span>
<span class="k">val</span> <span class="n">create</span> <span class="o">:</span> <span class="o">?</span><span class="n">fit_intercept</span><span class="o">:</span><span class="kt">bool</span> <span class="o">-&gt;</span> <span class="o">?</span><span class="n">verbose</span><span class="o">:</span><span class="kt">int</span> <span class="o">-&gt;</span> <span class="o">?</span><span class="n">max_iter</span><span class="o">:</span><span class="kt">int</span> <span class="o">-&gt;</span> <span class="o">?</span><span class="n">normalize</span><span class="o">:</span><span class="kt">bool</span> <span class="o">-&gt;</span> <span class="o">?</span><span class="n">precompute</span><span class="o">:[`</span><span class="nc">Arr</span> <span class="k">of</span> <span class="o">[&gt;`</span><span class="nc">ArrayLike</span><span class="o">]</span> <span class="nn">Np</span><span class="p">.</span><span class="nn">Obj</span><span class="p">.</span><span class="n">t</span> <span class="o">|</span> <span class="o">`</span><span class="nc">Auto</span> <span class="o">|</span> <span class="o">`</span><span class="nc">Bool</span> <span class="k">of</span> <span class="kt">bool</span><span class="o">]</span> <span class="o">-&gt;</span> <span class="o">?</span><span class="n">cv</span><span class="o">:[`</span><span class="nc">Arr</span> <span class="k">of</span> <span class="o">[&gt;`</span><span class="nc">ArrayLike</span><span class="o">]</span> <span class="nn">Np</span><span class="p">.</span><span class="nn">Obj</span><span class="p">.</span><span class="n">t</span> <span class="o">|</span> <span class="o">`</span><span class="nc">BaseCrossValidator</span> <span class="k">of</span> <span class="o">[&gt;`</span><span class="nc">BaseCrossValidator</span><span class="o">]</span> <span class="nn">Np</span><span class="p">.</span><span class="nn">Obj</span><span class="p">.</span><span class="n">t</span> <span class="o">|</span> <span class="o">`</span><span class="nc">I</span> <span class="k">of</span> <span class="kt">int</span><span class="o">]</span> <span class="o">-&gt;</span> <span class="o">?</span><span class="n">max_n_alphas</span><span class="o">:</span><span class="kt">int</span> <span class="o">-&gt;</span> <span class="o">?</span><span class="n">n_jobs</span><span class="o">:</span><span class="kt">int</span> <span class="o">-&gt;</span> <span class="o">?</span><span class="n">eps</span><span class="o">:</span><span class="kt">float</span> <span class="o">-&gt;</span> <span class="o">?</span><span class="n">copy_X</span><span class="o">:</span><span class="kt">bool</span> <span class="o">-&gt;</span> <span class="kt">unit</span> <span class="o">-&gt;</span> <span class="n">t</span>
</code></pre></div>

<p>Cross-validated Least Angle Regression model.</p>
<p>See glossary entry for :term:<code>cross-validation estimator</code>.</p>
<p>Read more in the :ref:<code>User Guide &lt;least_angle_regression&gt;</code>.</p>
<h2 id="parameters_36">Parameters<a class="headerlink" href="#parameters_36" title="Permanent link">&para;</a></h2>
<p>fit_intercept : bool, default=True
whether to calculate the intercept for this model. If set
to false, no intercept will be used in calculations
(i.e. data is expected to be centered).</p>
<p>verbose : bool or int, default=False
Sets the verbosity amount</p>
<p>max_iter : int, default=500
Maximum number of iterations to perform.</p>
<p>normalize : bool, default=True
This parameter is ignored when <code>fit_intercept</code> is set to False.
If True, the regressors X will be normalized before regression by
subtracting the mean and dividing by the l2-norm.
If you wish to standardize, please use
:class:<code>sklearn.preprocessing.StandardScaler</code> before calling <code>fit</code>
on an estimator with <code>normalize=False</code>.</p>
<p>precompute : bool, 'auto' or array-like , default='auto'
Whether to use a precomputed Gram matrix to speed up
calculations. If set to <code>'auto'</code> let us decide. The Gram matrix
cannot be passed as argument since we will use only subsets of X.</p>
<p>cv : int, cross-validation generator or an iterable, default=None
Determines the cross-validation splitting strategy.
Possible inputs for cv are:</p>
<ul>
<li>None, to use the default 5-fold cross-validation,</li>
<li>integer, to specify the number of folds.</li>
<li>:term:<code>CV splitter</code>,</li>
<li>An iterable yielding (train, test) splits as arrays of indices.</li>
</ul>
<p>For integer/None inputs, :class:<code>KFold</code> is used.</p>
<p>Refer :ref:<code>User Guide &lt;cross_validation&gt;</code> for the various
cross-validation strategies that can be used here.</p>
<p>.. versionchanged:: 0.22
<code>cv</code> default value if None changed from 3-fold to 5-fold.</p>
<p>max_n_alphas : int, default=1000
The maximum number of points on the path used to compute the
residuals in the cross-validation</p>
<p>n_jobs : int or None, default=None
Number of CPUs to use during the cross validation.
<code>None</code> means 1 unless in a :obj:<code>joblib.parallel_backend</code> context.
<code>-1</code> means using all processors. See :term:<code>Glossary &lt;n_jobs&gt;</code>
for more details.</p>
<p>eps : float, optional
The machine-precision regularization in the computation of the
Cholesky diagonal factors. Increase this for very ill-conditioned
systems. By default, <code>np.finfo(np.float).eps</code> is used.</p>
<p>copy_X : bool, default=True
If <code>True</code>, X will be copied; else, it may be overwritten.</p>
<h2 id="attributes_6">Attributes<a class="headerlink" href="#attributes_6" title="Permanent link">&para;</a></h2>
<p>coef_ : array-like of shape (n_features,)
parameter vector (w in the formulation formula)</p>
<p>intercept_ : float
independent term in decision function</p>
<p>coef_path_ : array-like of shape (n_features, n_alphas)
the varying values of the coefficients along the path</p>
<p>alpha_ : float
the estimated regularization parameter alpha</p>
<p>alphas_ : array-like of shape (n_alphas,)
the different values of alpha along the path</p>
<p>cv_alphas_ : array-like of shape (n_cv_alphas,)
all the values of alpha along the path for the different folds</p>
<p>mse_path_ : array-like of shape (n_folds, n_cv_alphas)
the mean square error on left-out for each fold along the path
(alpha values given by <code>cv_alphas</code>)</p>
<p>n_iter_ : array-like or int
the number of iterations run by Lars with the optimal alpha.</p>
<h2 id="examples_6">Examples<a class="headerlink" href="#examples_6" title="Permanent link">&para;</a></h2>
<blockquote>
<blockquote>
<blockquote>
<p>from sklearn.linear_model import LarsCV
from sklearn.datasets import make_regression
X, y = make_regression(n_samples=200, noise=4.0, random_state=0)
reg = LarsCV(cv=5).fit(X, y)
reg.score(X, y)
0.9996...
reg.alpha_
0.0254...
reg.predict(X[:1,])
array([154.0842...])</p>
</blockquote>
</blockquote>
</blockquote>
<h2 id="see-also_3">See also<a class="headerlink" href="#see-also_3" title="Permanent link">&para;</a></h2>
<p>lars_path, LassoLars, LassoLarsCV</p>
<div class="highlight"><pre><span></span><code><span class="k">val</span> <span class="n">fit</span> <span class="o">:</span> <span class="n">x</span><span class="o">:[&gt;`</span><span class="nc">ArrayLike</span><span class="o">]</span> <span class="nn">Np</span><span class="p">.</span><span class="nn">Obj</span><span class="p">.</span><span class="n">t</span> <span class="o">-&gt;</span> <span class="n">y</span><span class="o">:[&gt;`</span><span class="nc">ArrayLike</span><span class="o">]</span> <span class="nn">Np</span><span class="p">.</span><span class="nn">Obj</span><span class="p">.</span><span class="n">t</span> <span class="o">-&gt;</span> <span class="o">[&gt;</span> <span class="n">tag</span><span class="o">]</span> <span class="nn">Obj</span><span class="p">.</span><span class="n">t</span> <span class="o">-&gt;</span> <span class="n">t</span>
</code></pre></div>

<p>Fit the model using X, y as training data.</p>
<h2 id="parameters_37">Parameters<a class="headerlink" href="#parameters_37" title="Permanent link">&para;</a></h2>
<p>X : array-like of shape (n_samples, n_features)
Training data.</p>
<p>y : array-like of shape (n_samples,)
Target values.</p>
<h2 id="returns_28">Returns<a class="headerlink" href="#returns_28" title="Permanent link">&para;</a></h2>
<p>self : object
returns an instance of self.</p>
<div class="highlight"><pre><span></span><code><span class="k">val</span> <span class="n">get_params</span> <span class="o">:</span> <span class="o">?</span><span class="n">deep</span><span class="o">:</span><span class="kt">bool</span> <span class="o">-&gt;</span> <span class="o">[&gt;</span> <span class="n">tag</span><span class="o">]</span> <span class="nn">Obj</span><span class="p">.</span><span class="n">t</span> <span class="o">-&gt;</span> <span class="nn">Dict</span><span class="p">.</span><span class="n">t</span>
</code></pre></div>

<p>Get parameters for this estimator.</p>
<h2 id="parameters_38">Parameters<a class="headerlink" href="#parameters_38" title="Permanent link">&para;</a></h2>
<p>deep : bool, default=True
If True, will return the parameters for this estimator and
contained subobjects that are estimators.</p>
<h2 id="returns_29">Returns<a class="headerlink" href="#returns_29" title="Permanent link">&para;</a></h2>
<p>params : mapping of string to any
Parameter names mapped to their values.</p>
<div class="highlight"><pre><span></span><code><span class="k">val</span> <span class="n">predict</span> <span class="o">:</span> <span class="n">x</span><span class="o">:[&gt;`</span><span class="nc">ArrayLike</span><span class="o">]</span> <span class="nn">Np</span><span class="p">.</span><span class="nn">Obj</span><span class="p">.</span><span class="n">t</span> <span class="o">-&gt;</span> <span class="o">[&gt;</span> <span class="n">tag</span><span class="o">]</span> <span class="nn">Obj</span><span class="p">.</span><span class="n">t</span> <span class="o">-&gt;</span> <span class="o">[&gt;`</span><span class="nc">ArrayLike</span><span class="o">]</span> <span class="nn">Np</span><span class="p">.</span><span class="nn">Obj</span><span class="p">.</span><span class="n">t</span>
</code></pre></div>

<p>Predict using the linear model.</p>
<h2 id="parameters_39">Parameters<a class="headerlink" href="#parameters_39" title="Permanent link">&para;</a></h2>
<p>X : array_like or sparse matrix, shape (n_samples, n_features)
Samples.</p>
<h2 id="returns_30">Returns<a class="headerlink" href="#returns_30" title="Permanent link">&para;</a></h2>
<p>C : array, shape (n_samples,)
Returns predicted values.</p>
<div class="highlight"><pre><span></span><code><span class="k">val</span> <span class="n">score</span> <span class="o">:</span> <span class="o">?</span><span class="n">sample_weight</span><span class="o">:[&gt;`</span><span class="nc">ArrayLike</span><span class="o">]</span> <span class="nn">Np</span><span class="p">.</span><span class="nn">Obj</span><span class="p">.</span><span class="n">t</span> <span class="o">-&gt;</span> <span class="n">x</span><span class="o">:[&gt;`</span><span class="nc">ArrayLike</span><span class="o">]</span> <span class="nn">Np</span><span class="p">.</span><span class="nn">Obj</span><span class="p">.</span><span class="n">t</span> <span class="o">-&gt;</span> <span class="n">y</span><span class="o">:[&gt;`</span><span class="nc">ArrayLike</span><span class="o">]</span> <span class="nn">Np</span><span class="p">.</span><span class="nn">Obj</span><span class="p">.</span><span class="n">t</span> <span class="o">-&gt;</span> <span class="o">[&gt;</span> <span class="n">tag</span><span class="o">]</span> <span class="nn">Obj</span><span class="p">.</span><span class="n">t</span> <span class="o">-&gt;</span> <span class="kt">float</span>
</code></pre></div>

<p>Return the coefficient of determination R^2 of the prediction.</p>
<p>The coefficient R^2 is defined as (1 - u/v), where u is the residual
sum of squares ((y_true - y_pred) <strong> 2).sum() and v is the total
sum of squares ((y_true - y_true.mean()) </strong> 2).sum().
The best possible score is 1.0 and it can be negative (because the
model can be arbitrarily worse). A constant model that always
predicts the expected value of y, disregarding the input features,
would get a R^2 score of 0.0.</p>
<h2 id="parameters_40">Parameters<a class="headerlink" href="#parameters_40" title="Permanent link">&para;</a></h2>
<p>X : array-like of shape (n_samples, n_features)
Test samples. For some estimators this may be a
precomputed kernel matrix or a list of generic objects instead,
shape = (n_samples, n_samples_fitted),
where n_samples_fitted is the number of
samples used in the fitting for the estimator.</p>
<p>y : array-like of shape (n_samples,) or (n_samples, n_outputs)
True values for X.</p>
<p>sample_weight : array-like of shape (n_samples,), default=None
Sample weights.</p>
<h2 id="returns_31">Returns<a class="headerlink" href="#returns_31" title="Permanent link">&para;</a></h2>
<p>score : float
R^2 of self.predict(X) wrt. y.</p>
<h2 id="notes_11">Notes<a class="headerlink" href="#notes_11" title="Permanent link">&para;</a></h2>
<p>The R2 score used when calling <code>score</code> on a regressor will use
<code>multioutput='uniform_average'</code> from version 0.23 to keep consistent
with :func:<code>~sklearn.metrics.r2_score</code>. This will influence the
<code>score</code> method of all the multioutput regressors (except for
:class:<code>~sklearn.multioutput.MultiOutputRegressor</code>). To specify the
default value manually and avoid the warning, please either call
:func:<code>~sklearn.metrics.r2_score</code> directly or make a custom scorer with
:func:<code>~sklearn.metrics.make_scorer</code> (the built-in scorer <code>'r2'</code> uses
<code>multioutput='uniform_average'</code>).</p>
<div class="highlight"><pre><span></span><code><span class="k">val</span> <span class="n">set_params</span> <span class="o">:</span> <span class="o">?</span><span class="n">params</span><span class="o">:(</span><span class="kt">string</span> <span class="o">*</span> <span class="nn">Py</span><span class="p">.</span><span class="nn">Object</span><span class="p">.</span><span class="n">t</span><span class="o">)</span> <span class="kt">list</span> <span class="o">-&gt;</span> <span class="o">[&gt;</span> <span class="n">tag</span><span class="o">]</span> <span class="nn">Obj</span><span class="p">.</span><span class="n">t</span> <span class="o">-&gt;</span> <span class="n">t</span>
</code></pre></div>

<p>Set the parameters of this estimator.</p>
<p>The method works on simple estimators as well as on nested objects
(such as pipelines). The latter have parameters of the form
<code>&lt;component&gt;__&lt;parameter&gt;</code> so that it's possible to update each
component of a nested object.</p>
<h2 id="parameters_41">Parameters<a class="headerlink" href="#parameters_41" title="Permanent link">&para;</a></h2>
<p>**params : dict
Estimator parameters.</p>
<h2 id="returns_32">Returns<a class="headerlink" href="#returns_32" title="Permanent link">&para;</a></h2>
<p>self : object
Estimator instance.</p>
<p>Attribute coef_: get value or raise Not_found if None.</p>
<div class="highlight"><pre><span></span><code><span class="k">val</span> <span class="n">coef_</span> <span class="o">:</span> <span class="n">t</span> <span class="o">-&gt;</span> <span class="o">[&gt;`</span><span class="nc">ArrayLike</span><span class="o">]</span> <span class="nn">Np</span><span class="p">.</span><span class="nn">Obj</span><span class="p">.</span><span class="n">t</span>
</code></pre></div>

<p>Attribute coef_: get value as an option.</p>
<div class="highlight"><pre><span></span><code><span class="k">val</span> <span class="n">coef_opt</span> <span class="o">:</span> <span class="n">t</span> <span class="o">-&gt;</span> <span class="o">([&gt;`</span><span class="nc">ArrayLike</span><span class="o">]</span> <span class="nn">Np</span><span class="p">.</span><span class="nn">Obj</span><span class="p">.</span><span class="n">t</span><span class="o">)</span> <span class="n">option</span>
</code></pre></div>

<p>Attribute intercept_: get value or raise Not_found if None.</p>
<div class="highlight"><pre><span></span><code><span class="k">val</span> <span class="n">intercept_</span> <span class="o">:</span> <span class="n">t</span> <span class="o">-&gt;</span> <span class="o">[&gt;`</span><span class="nc">ArrayLike</span><span class="o">]</span> <span class="nn">Np</span><span class="p">.</span><span class="nn">Obj</span><span class="p">.</span><span class="n">t</span>
</code></pre></div>

<p>Attribute intercept_: get value as an option.</p>
<div class="highlight"><pre><span></span><code><span class="k">val</span> <span class="n">intercept_opt</span> <span class="o">:</span> <span class="n">t</span> <span class="o">-&gt;</span> <span class="o">([&gt;`</span><span class="nc">ArrayLike</span><span class="o">]</span> <span class="nn">Np</span><span class="p">.</span><span class="nn">Obj</span><span class="p">.</span><span class="n">t</span><span class="o">)</span> <span class="n">option</span>
</code></pre></div>

<p>Attribute coef_path_: get value or raise Not_found if None.</p>
<div class="highlight"><pre><span></span><code><span class="k">val</span> <span class="n">coef_path_</span> <span class="o">:</span> <span class="n">t</span> <span class="o">-&gt;</span> <span class="o">[&gt;`</span><span class="nc">ArrayLike</span><span class="o">]</span> <span class="nn">Np</span><span class="p">.</span><span class="nn">Obj</span><span class="p">.</span><span class="n">t</span>
</code></pre></div>

<p>Attribute coef_path_: get value as an option.</p>
<div class="highlight"><pre><span></span><code><span class="k">val</span> <span class="n">coef_path_opt</span> <span class="o">:</span> <span class="n">t</span> <span class="o">-&gt;</span> <span class="o">([&gt;`</span><span class="nc">ArrayLike</span><span class="o">]</span> <span class="nn">Np</span><span class="p">.</span><span class="nn">Obj</span><span class="p">.</span><span class="n">t</span><span class="o">)</span> <span class="n">option</span>
</code></pre></div>

<p>Attribute alpha_: get value or raise Not_found if None.</p>
<div class="highlight"><pre><span></span><code><span class="k">val</span> <span class="n">alpha_</span> <span class="o">:</span> <span class="n">t</span> <span class="o">-&gt;</span> <span class="kt">float</span>
</code></pre></div>

<p>Attribute alpha_: get value as an option.</p>
<div class="highlight"><pre><span></span><code><span class="k">val</span> <span class="n">alpha_opt</span> <span class="o">:</span> <span class="n">t</span> <span class="o">-&gt;</span> <span class="o">(</span><span class="kt">float</span><span class="o">)</span> <span class="n">option</span>
</code></pre></div>

<p>Attribute alphas_: get value or raise Not_found if None.</p>
<div class="highlight"><pre><span></span><code><span class="k">val</span> <span class="n">alphas_</span> <span class="o">:</span> <span class="n">t</span> <span class="o">-&gt;</span> <span class="o">[&gt;`</span><span class="nc">ArrayLike</span><span class="o">]</span> <span class="nn">Np</span><span class="p">.</span><span class="nn">Obj</span><span class="p">.</span><span class="n">t</span>
</code></pre></div>

<p>Attribute alphas_: get value as an option.</p>
<div class="highlight"><pre><span></span><code><span class="k">val</span> <span class="n">alphas_opt</span> <span class="o">:</span> <span class="n">t</span> <span class="o">-&gt;</span> <span class="o">([&gt;`</span><span class="nc">ArrayLike</span><span class="o">]</span> <span class="nn">Np</span><span class="p">.</span><span class="nn">Obj</span><span class="p">.</span><span class="n">t</span><span class="o">)</span> <span class="n">option</span>
</code></pre></div>

<p>Attribute cv_alphas_: get value or raise Not_found if None.</p>
<div class="highlight"><pre><span></span><code><span class="k">val</span> <span class="n">cv_alphas_</span> <span class="o">:</span> <span class="n">t</span> <span class="o">-&gt;</span> <span class="o">[&gt;`</span><span class="nc">ArrayLike</span><span class="o">]</span> <span class="nn">Np</span><span class="p">.</span><span class="nn">Obj</span><span class="p">.</span><span class="n">t</span>
</code></pre></div>

<p>Attribute cv_alphas_: get value as an option.</p>
<div class="highlight"><pre><span></span><code><span class="k">val</span> <span class="n">cv_alphas_opt</span> <span class="o">:</span> <span class="n">t</span> <span class="o">-&gt;</span> <span class="o">([&gt;`</span><span class="nc">ArrayLike</span><span class="o">]</span> <span class="nn">Np</span><span class="p">.</span><span class="nn">Obj</span><span class="p">.</span><span class="n">t</span><span class="o">)</span> <span class="n">option</span>
</code></pre></div>

<p>Attribute mse_path_: get value or raise Not_found if None.</p>
<div class="highlight"><pre><span></span><code><span class="k">val</span> <span class="n">mse_path_</span> <span class="o">:</span> <span class="n">t</span> <span class="o">-&gt;</span> <span class="o">[&gt;`</span><span class="nc">ArrayLike</span><span class="o">]</span> <span class="nn">Np</span><span class="p">.</span><span class="nn">Obj</span><span class="p">.</span><span class="n">t</span>
</code></pre></div>

<p>Attribute mse_path_: get value as an option.</p>
<div class="highlight"><pre><span></span><code><span class="k">val</span> <span class="n">mse_path_opt</span> <span class="o">:</span> <span class="n">t</span> <span class="o">-&gt;</span> <span class="o">([&gt;`</span><span class="nc">ArrayLike</span><span class="o">]</span> <span class="nn">Np</span><span class="p">.</span><span class="nn">Obj</span><span class="p">.</span><span class="n">t</span><span class="o">)</span> <span class="n">option</span>
</code></pre></div>

<p>Attribute n_iter_: get value or raise Not_found if None.</p>
<div class="highlight"><pre><span></span><code><span class="k">val</span> <span class="n">n_iter_</span> <span class="o">:</span> <span class="n">t</span> <span class="o">-&gt;</span> <span class="nn">Py</span><span class="p">.</span><span class="nn">Object</span><span class="p">.</span><span class="n">t</span>
</code></pre></div>

<p>Attribute n_iter_: get value as an option.</p>
<div class="highlight"><pre><span></span><code><span class="k">val</span> <span class="n">n_iter_opt</span> <span class="o">:</span> <span class="n">t</span> <span class="o">-&gt;</span> <span class="o">(</span><span class="nn">Py</span><span class="p">.</span><span class="nn">Object</span><span class="p">.</span><span class="n">t</span><span class="o">)</span> <span class="n">option</span>
</code></pre></div>

<p>Print the object to a human-readable representation.</p>
<div class="highlight"><pre><span></span><code><span class="k">val</span> <span class="n">to_string</span> <span class="o">:</span> <span class="n">t</span> <span class="o">-&gt;</span> <span class="kt">string</span>
</code></pre></div>

<p>Print the object to a human-readable representation.</p>
<div class="highlight"><pre><span></span><code><span class="k">val</span> <span class="n">show</span> <span class="o">:</span> <span class="n">t</span> <span class="o">-&gt;</span> <span class="kt">string</span>
</code></pre></div>

<p>Pretty-print the object to a formatter.</p>
<div class="highlight"><pre><span></span><code><span class="k">val</span> <span class="n">pp</span> <span class="o">:</span> <span class="nn">Format</span><span class="p">.</span><span class="n">formatter</span> <span class="o">-&gt;</span> <span class="n">t</span> <span class="o">-&gt;</span> <span class="kt">unit</span> <span class="o">[@@</span><span class="n">ocaml</span><span class="o">.</span><span class="n">toplevel_printer</span><span class="o">]</span>



<span class="k">module</span> <span class="nc">Lasso</span> <span class="o">:</span> <span class="k">sig</span>
<span class="k">type</span> <span class="n">tag</span> <span class="o">=</span> <span class="o">[`</span><span class="nc">Lasso</span><span class="o">]</span>
<span class="k">type</span> <span class="n">t</span> <span class="o">=</span> <span class="o">[`</span><span class="nc">BaseEstimator</span> <span class="o">|</span> <span class="o">`</span><span class="nc">Lasso</span> <span class="o">|</span> <span class="o">`</span><span class="nc">MultiOutputMixin</span> <span class="o">|</span> <span class="o">`</span><span class="nc">Object</span> <span class="o">|</span> <span class="o">`</span><span class="nc">RegressorMixin</span><span class="o">]</span> <span class="nn">Obj</span><span class="p">.</span><span class="n">t</span>
<span class="k">val</span> <span class="n">of_pyobject</span> <span class="o">:</span> <span class="nn">Py</span><span class="p">.</span><span class="nn">Object</span><span class="p">.</span><span class="n">t</span> <span class="o">-&gt;</span> <span class="n">t</span>
<span class="k">val</span> <span class="n">to_pyobject</span> <span class="o">:</span> <span class="o">[&gt;</span> <span class="n">tag</span><span class="o">]</span> <span class="nn">Obj</span><span class="p">.</span><span class="n">t</span> <span class="o">-&gt;</span> <span class="nn">Py</span><span class="p">.</span><span class="nn">Object</span><span class="p">.</span><span class="n">t</span>

<span class="k">val</span> <span class="n">as_regressor</span> <span class="o">:</span> <span class="n">t</span> <span class="o">-&gt;</span> <span class="o">[`</span><span class="nc">RegressorMixin</span><span class="o">]</span> <span class="nn">Obj</span><span class="p">.</span><span class="n">t</span>
<span class="k">val</span> <span class="n">as_multi_output</span> <span class="o">:</span> <span class="n">t</span> <span class="o">-&gt;</span> <span class="o">[`</span><span class="nc">MultiOutputMixin</span><span class="o">]</span> <span class="nn">Obj</span><span class="p">.</span><span class="n">t</span>
<span class="k">val</span> <span class="n">as_estimator</span> <span class="o">:</span> <span class="n">t</span> <span class="o">-&gt;</span> <span class="o">[`</span><span class="nc">BaseEstimator</span><span class="o">]</span> <span class="nn">Obj</span><span class="p">.</span><span class="n">t</span>
<span class="k">val</span> <span class="n">create</span> <span class="o">:</span> <span class="o">?</span><span class="n">alpha</span><span class="o">:</span><span class="kt">float</span> <span class="o">-&gt;</span> <span class="o">?</span><span class="n">fit_intercept</span><span class="o">:</span><span class="kt">bool</span> <span class="o">-&gt;</span> <span class="o">?</span><span class="n">normalize</span><span class="o">:</span><span class="kt">bool</span> <span class="o">-&gt;</span> <span class="o">?</span><span class="n">precompute</span><span class="o">:[`</span><span class="nc">Arr</span> <span class="k">of</span> <span class="o">[&gt;`</span><span class="nc">ArrayLike</span><span class="o">]</span> <span class="nn">Np</span><span class="p">.</span><span class="nn">Obj</span><span class="p">.</span><span class="n">t</span> <span class="o">|</span> <span class="o">`</span><span class="nc">Bool</span> <span class="k">of</span> <span class="kt">bool</span><span class="o">]</span> <span class="o">-&gt;</span> <span class="o">?</span><span class="n">copy_X</span><span class="o">:</span><span class="kt">bool</span> <span class="o">-&gt;</span> <span class="o">?</span><span class="n">max_iter</span><span class="o">:</span><span class="kt">int</span> <span class="o">-&gt;</span> <span class="o">?</span><span class="n">tol</span><span class="o">:</span><span class="kt">float</span> <span class="o">-&gt;</span> <span class="o">?</span><span class="n">warm_start</span><span class="o">:</span><span class="kt">bool</span> <span class="o">-&gt;</span> <span class="o">?</span><span class="n">positive</span><span class="o">:</span><span class="kt">bool</span> <span class="o">-&gt;</span> <span class="o">?</span><span class="n">random_state</span><span class="o">:</span><span class="kt">int</span> <span class="o">-&gt;</span> <span class="o">?</span><span class="n">selection</span><span class="o">:</span><span class="kt">string</span> <span class="o">-&gt;</span> <span class="kt">unit</span> <span class="o">-&gt;</span> <span class="n">t</span>
</code></pre></div>

<p>Linear Model trained with L1 prior as regularizer (aka the Lasso)</p>
<p>The optimization objective for Lasso is::</p>
<p>(1 / (2 * n_samples)) * ||y - Xw||^2_2 + alpha * ||w||_1</p>
<p>Technically the Lasso model is optimizing the same objective function as
the Elastic Net with <code>l1_ratio=1.0</code> (no L2 penalty).</p>
<p>Read more in the :ref:<code>User Guide &lt;lasso&gt;</code>.</p>
<h2 id="parameters_42">Parameters<a class="headerlink" href="#parameters_42" title="Permanent link">&para;</a></h2>
<p>alpha : float, optional
Constant that multiplies the L1 term. Defaults to 1.0.
<code>alpha = 0</code> is equivalent to an ordinary least square, solved
by the :class:<code>LinearRegression</code> object. For numerical
reasons, using <code>alpha = 0</code> with the <code>Lasso</code> object is not advised.
Given this, you should use the :class:<code>LinearRegression</code> object.</p>
<p>fit_intercept : boolean, optional, default True
Whether to calculate the intercept for this model. If set
to False, no intercept will be used in calculations
(i.e. data is expected to be centered).</p>
<p>normalize : boolean, optional, default False
This parameter is ignored when <code>fit_intercept</code> is set to False.
If True, the regressors X will be normalized before regression by
subtracting the mean and dividing by the l2-norm.
If you wish to standardize, please use
:class:<code>sklearn.preprocessing.StandardScaler</code> before calling <code>fit</code>
on an estimator with <code>normalize=False</code>.</p>
<p>precompute : True | False | array-like, default=False
Whether to use a precomputed Gram matrix to speed up
calculations. If set to <code>'auto'</code> let us decide. The Gram
matrix can also be passed as argument. For sparse input
this option is always <code>True</code> to preserve sparsity.</p>
<p>copy_X : boolean, optional, default True
If <code>True</code>, X will be copied; else, it may be overwritten.</p>
<p>max_iter : int, optional
The maximum number of iterations</p>
<p>tol : float, optional
The tolerance for the optimization: if the updates are
smaller than <code>tol</code>, the optimization code checks the
dual gap for optimality and continues until it is smaller
than <code>tol</code>.</p>
<p>warm_start : bool, optional
When set to True, reuse the solution of the previous call to fit as
initialization, otherwise, just erase the previous solution.
See :term:<code>the Glossary &lt;warm_start&gt;</code>.</p>
<p>positive : bool, optional
When set to <code>True</code>, forces the coefficients to be positive.</p>
<p>random_state : int, RandomState instance or None, optional, default None
The seed of the pseudo random number generator that selects a random
feature to update.  If int, random_state is the seed used by the random
number generator; If RandomState instance, random_state is the random
number generator; If None, the random number generator is the
RandomState instance used by <code>np.random</code>. Used when <code>selection</code> ==
'random'.</p>
<p>selection : str, default 'cyclic'
If set to 'random', a random coefficient is updated every iteration
rather than looping over features sequentially by default. This
(setting to 'random') often leads to significantly faster convergence
especially when tol is higher than 1e-4.</p>
<h2 id="attributes_7">Attributes<a class="headerlink" href="#attributes_7" title="Permanent link">&para;</a></h2>
<p>coef_ : array, shape (n_features,) | (n_targets, n_features)
parameter vector (w in the cost function formula)</p>
<p>sparse_coef_ : scipy.sparse matrix, shape (n_features, 1) |             (n_targets, n_features)
<code>sparse_coef_</code> is a readonly property derived from <code>coef_</code></p>
<p>intercept_ : float | array, shape (n_targets,)
independent term in decision function.</p>
<p>n_iter_ : int | array-like, shape (n_targets,)
number of iterations run by the coordinate descent solver to reach
the specified tolerance.</p>
<h2 id="examples_7">Examples<a class="headerlink" href="#examples_7" title="Permanent link">&para;</a></h2>
<blockquote>
<blockquote>
<blockquote>
<p>from sklearn import linear_model
clf = linear_model.Lasso(alpha=0.1)
clf.fit([[0,0], [1, 1], [2, 2]], [0, 1, 2])
Lasso(alpha=0.1)
print(clf.coef_)
[0.85 0.  ]
print(clf.intercept_)
0.15...</p>
</blockquote>
</blockquote>
</blockquote>
<h2 id="see-also_4">See also<a class="headerlink" href="#see-also_4" title="Permanent link">&para;</a></h2>
<p>lars_path
lasso_path
LassoLars
LassoCV
LassoLarsCV
sklearn.decomposition.sparse_encode</p>
<h2 id="notes_12">Notes<a class="headerlink" href="#notes_12" title="Permanent link">&para;</a></h2>
<p>The algorithm used to fit the model is coordinate descent.</p>
<p>To avoid unnecessary memory duplication the X argument of the fit method
should be directly passed as a Fortran-contiguous numpy array.</p>
<div class="highlight"><pre><span></span><code><span class="k">val</span> <span class="n">fit</span> <span class="o">:</span> <span class="o">?</span><span class="n">check_input</span><span class="o">:</span><span class="kt">bool</span> <span class="o">-&gt;</span> <span class="n">x</span><span class="o">:[&gt;`</span><span class="nc">ArrayLike</span><span class="o">]</span> <span class="nn">Np</span><span class="p">.</span><span class="nn">Obj</span><span class="p">.</span><span class="n">t</span> <span class="o">-&gt;</span> <span class="n">y</span><span class="o">:[&gt;`</span><span class="nc">ArrayLike</span><span class="o">]</span> <span class="nn">Np</span><span class="p">.</span><span class="nn">Obj</span><span class="p">.</span><span class="n">t</span> <span class="o">-&gt;</span> <span class="o">[&gt;</span> <span class="n">tag</span><span class="o">]</span> <span class="nn">Obj</span><span class="p">.</span><span class="n">t</span> <span class="o">-&gt;</span> <span class="n">t</span>
</code></pre></div>

<p>Fit model with coordinate descent.</p>
<h2 id="parameters_43">Parameters<a class="headerlink" href="#parameters_43" title="Permanent link">&para;</a></h2>
<p>X : ndarray or scipy.sparse matrix, (n_samples, n_features)
Data</p>
<p>y : ndarray, shape (n_samples,) or (n_samples, n_targets)
Target. Will be cast to X's dtype if necessary</p>
<p>check_input : boolean, (default=True)
Allow to bypass several input checking.
Don't use this parameter unless you know what you do.</p>
<h2 id="notes_13">Notes<a class="headerlink" href="#notes_13" title="Permanent link">&para;</a></h2>
<p>Coordinate descent is an algorithm that considers each column of
data at a time hence it will automatically convert the X input
as a Fortran-contiguous numpy array if necessary.</p>
<p>To avoid memory re-allocation it is advised to allocate the
initial data in memory directly using that format.</p>
<div class="highlight"><pre><span></span><code><span class="k">val</span> <span class="n">get_params</span> <span class="o">:</span> <span class="o">?</span><span class="n">deep</span><span class="o">:</span><span class="kt">bool</span> <span class="o">-&gt;</span> <span class="o">[&gt;</span> <span class="n">tag</span><span class="o">]</span> <span class="nn">Obj</span><span class="p">.</span><span class="n">t</span> <span class="o">-&gt;</span> <span class="nn">Dict</span><span class="p">.</span><span class="n">t</span>
</code></pre></div>

<p>Get parameters for this estimator.</p>
<h2 id="parameters_44">Parameters<a class="headerlink" href="#parameters_44" title="Permanent link">&para;</a></h2>
<p>deep : bool, default=True
If True, will return the parameters for this estimator and
contained subobjects that are estimators.</p>
<h2 id="returns_33">Returns<a class="headerlink" href="#returns_33" title="Permanent link">&para;</a></h2>
<p>params : mapping of string to any
Parameter names mapped to their values.</p>
<div class="highlight"><pre><span></span><code><span class="k">val</span> <span class="n">predict</span> <span class="o">:</span> <span class="n">x</span><span class="o">:[&gt;`</span><span class="nc">ArrayLike</span><span class="o">]</span> <span class="nn">Np</span><span class="p">.</span><span class="nn">Obj</span><span class="p">.</span><span class="n">t</span> <span class="o">-&gt;</span> <span class="o">[&gt;</span> <span class="n">tag</span><span class="o">]</span> <span class="nn">Obj</span><span class="p">.</span><span class="n">t</span> <span class="o">-&gt;</span> <span class="o">[&gt;`</span><span class="nc">ArrayLike</span><span class="o">]</span> <span class="nn">Np</span><span class="p">.</span><span class="nn">Obj</span><span class="p">.</span><span class="n">t</span>
</code></pre></div>

<p>Predict using the linear model.</p>
<h2 id="parameters_45">Parameters<a class="headerlink" href="#parameters_45" title="Permanent link">&para;</a></h2>
<p>X : array_like or sparse matrix, shape (n_samples, n_features)
Samples.</p>
<h2 id="returns_34">Returns<a class="headerlink" href="#returns_34" title="Permanent link">&para;</a></h2>
<p>C : array, shape (n_samples,)
Returns predicted values.</p>
<div class="highlight"><pre><span></span><code><span class="k">val</span> <span class="n">score</span> <span class="o">:</span> <span class="o">?</span><span class="n">sample_weight</span><span class="o">:[&gt;`</span><span class="nc">ArrayLike</span><span class="o">]</span> <span class="nn">Np</span><span class="p">.</span><span class="nn">Obj</span><span class="p">.</span><span class="n">t</span> <span class="o">-&gt;</span> <span class="n">x</span><span class="o">:[&gt;`</span><span class="nc">ArrayLike</span><span class="o">]</span> <span class="nn">Np</span><span class="p">.</span><span class="nn">Obj</span><span class="p">.</span><span class="n">t</span> <span class="o">-&gt;</span> <span class="n">y</span><span class="o">:[&gt;`</span><span class="nc">ArrayLike</span><span class="o">]</span> <span class="nn">Np</span><span class="p">.</span><span class="nn">Obj</span><span class="p">.</span><span class="n">t</span> <span class="o">-&gt;</span> <span class="o">[&gt;</span> <span class="n">tag</span><span class="o">]</span> <span class="nn">Obj</span><span class="p">.</span><span class="n">t</span> <span class="o">-&gt;</span> <span class="kt">float</span>
</code></pre></div>

<p>Return the coefficient of determination R^2 of the prediction.</p>
<p>The coefficient R^2 is defined as (1 - u/v), where u is the residual
sum of squares ((y_true - y_pred) <strong> 2).sum() and v is the total
sum of squares ((y_true - y_true.mean()) </strong> 2).sum().
The best possible score is 1.0 and it can be negative (because the
model can be arbitrarily worse). A constant model that always
predicts the expected value of y, disregarding the input features,
would get a R^2 score of 0.0.</p>
<h2 id="parameters_46">Parameters<a class="headerlink" href="#parameters_46" title="Permanent link">&para;</a></h2>
<p>X : array-like of shape (n_samples, n_features)
Test samples. For some estimators this may be a
precomputed kernel matrix or a list of generic objects instead,
shape = (n_samples, n_samples_fitted),
where n_samples_fitted is the number of
samples used in the fitting for the estimator.</p>
<p>y : array-like of shape (n_samples,) or (n_samples, n_outputs)
True values for X.</p>
<p>sample_weight : array-like of shape (n_samples,), default=None
Sample weights.</p>
<h2 id="returns_35">Returns<a class="headerlink" href="#returns_35" title="Permanent link">&para;</a></h2>
<p>score : float
R^2 of self.predict(X) wrt. y.</p>
<h2 id="notes_14">Notes<a class="headerlink" href="#notes_14" title="Permanent link">&para;</a></h2>
<p>The R2 score used when calling <code>score</code> on a regressor will use
<code>multioutput='uniform_average'</code> from version 0.23 to keep consistent
with :func:<code>~sklearn.metrics.r2_score</code>. This will influence the
<code>score</code> method of all the multioutput regressors (except for
:class:<code>~sklearn.multioutput.MultiOutputRegressor</code>). To specify the
default value manually and avoid the warning, please either call
:func:<code>~sklearn.metrics.r2_score</code> directly or make a custom scorer with
:func:<code>~sklearn.metrics.make_scorer</code> (the built-in scorer <code>'r2'</code> uses
<code>multioutput='uniform_average'</code>).</p>
<div class="highlight"><pre><span></span><code><span class="k">val</span> <span class="n">set_params</span> <span class="o">:</span> <span class="o">?</span><span class="n">params</span><span class="o">:(</span><span class="kt">string</span> <span class="o">*</span> <span class="nn">Py</span><span class="p">.</span><span class="nn">Object</span><span class="p">.</span><span class="n">t</span><span class="o">)</span> <span class="kt">list</span> <span class="o">-&gt;</span> <span class="o">[&gt;</span> <span class="n">tag</span><span class="o">]</span> <span class="nn">Obj</span><span class="p">.</span><span class="n">t</span> <span class="o">-&gt;</span> <span class="n">t</span>
</code></pre></div>

<p>Set the parameters of this estimator.</p>
<p>The method works on simple estimators as well as on nested objects
(such as pipelines). The latter have parameters of the form
<code>&lt;component&gt;__&lt;parameter&gt;</code> so that it's possible to update each
component of a nested object.</p>
<h2 id="parameters_47">Parameters<a class="headerlink" href="#parameters_47" title="Permanent link">&para;</a></h2>
<p>**params : dict
Estimator parameters.</p>
<h2 id="returns_36">Returns<a class="headerlink" href="#returns_36" title="Permanent link">&para;</a></h2>
<p>self : object
Estimator instance.</p>
<p>Attribute coef_: get value or raise Not_found if None.</p>
<div class="highlight"><pre><span></span><code><span class="k">val</span> <span class="n">coef_</span> <span class="o">:</span> <span class="n">t</span> <span class="o">-&gt;</span> <span class="o">[&gt;`</span><span class="nc">ArrayLike</span><span class="o">]</span> <span class="nn">Np</span><span class="p">.</span><span class="nn">Obj</span><span class="p">.</span><span class="n">t</span>
</code></pre></div>

<p>Attribute coef_: get value as an option.</p>
<div class="highlight"><pre><span></span><code><span class="k">val</span> <span class="n">coef_opt</span> <span class="o">:</span> <span class="n">t</span> <span class="o">-&gt;</span> <span class="o">([&gt;`</span><span class="nc">ArrayLike</span><span class="o">]</span> <span class="nn">Np</span><span class="p">.</span><span class="nn">Obj</span><span class="p">.</span><span class="n">t</span><span class="o">)</span> <span class="n">option</span>
</code></pre></div>

<p>Attribute sparse_coef_: get value or raise Not_found if None.</p>
<div class="highlight"><pre><span></span><code><span class="k">val</span> <span class="n">sparse_coef_</span> <span class="o">:</span> <span class="n">t</span> <span class="o">-&gt;</span> <span class="o">[`</span><span class="nc">ArrayLike</span><span class="o">|`</span><span class="nc">Object</span><span class="o">|`</span><span class="nc">Spmatrix</span><span class="o">]</span> <span class="nn">Np</span><span class="p">.</span><span class="nn">Obj</span><span class="p">.</span><span class="n">t</span>
</code></pre></div>

<p>Attribute sparse_coef_: get value as an option.</p>
<div class="highlight"><pre><span></span><code><span class="k">val</span> <span class="n">sparse_coef_opt</span> <span class="o">:</span> <span class="n">t</span> <span class="o">-&gt;</span> <span class="o">([`</span><span class="nc">ArrayLike</span><span class="o">|`</span><span class="nc">Object</span><span class="o">|`</span><span class="nc">Spmatrix</span><span class="o">]</span> <span class="nn">Np</span><span class="p">.</span><span class="nn">Obj</span><span class="p">.</span><span class="n">t</span><span class="o">)</span> <span class="n">option</span>
</code></pre></div>

<p>Attribute intercept_: get value or raise Not_found if None.</p>
<div class="highlight"><pre><span></span><code><span class="k">val</span> <span class="n">intercept_</span> <span class="o">:</span> <span class="n">t</span> <span class="o">-&gt;</span> <span class="o">[&gt;`</span><span class="nc">ArrayLike</span><span class="o">]</span> <span class="nn">Np</span><span class="p">.</span><span class="nn">Obj</span><span class="p">.</span><span class="n">t</span>
</code></pre></div>

<p>Attribute intercept_: get value as an option.</p>
<div class="highlight"><pre><span></span><code><span class="k">val</span> <span class="n">intercept_opt</span> <span class="o">:</span> <span class="n">t</span> <span class="o">-&gt;</span> <span class="o">([&gt;`</span><span class="nc">ArrayLike</span><span class="o">]</span> <span class="nn">Np</span><span class="p">.</span><span class="nn">Obj</span><span class="p">.</span><span class="n">t</span><span class="o">)</span> <span class="n">option</span>
</code></pre></div>

<p>Attribute n_iter_: get value or raise Not_found if None.</p>
<div class="highlight"><pre><span></span><code><span class="k">val</span> <span class="n">n_iter_</span> <span class="o">:</span> <span class="n">t</span> <span class="o">-&gt;</span> <span class="nn">Py</span><span class="p">.</span><span class="nn">Object</span><span class="p">.</span><span class="n">t</span>
</code></pre></div>

<p>Attribute n_iter_: get value as an option.</p>
<div class="highlight"><pre><span></span><code><span class="k">val</span> <span class="n">n_iter_opt</span> <span class="o">:</span> <span class="n">t</span> <span class="o">-&gt;</span> <span class="o">(</span><span class="nn">Py</span><span class="p">.</span><span class="nn">Object</span><span class="p">.</span><span class="n">t</span><span class="o">)</span> <span class="n">option</span>
</code></pre></div>

<p>Print the object to a human-readable representation.</p>
<div class="highlight"><pre><span></span><code><span class="k">val</span> <span class="n">to_string</span> <span class="o">:</span> <span class="n">t</span> <span class="o">-&gt;</span> <span class="kt">string</span>
</code></pre></div>

<p>Print the object to a human-readable representation.</p>
<div class="highlight"><pre><span></span><code><span class="k">val</span> <span class="n">show</span> <span class="o">:</span> <span class="n">t</span> <span class="o">-&gt;</span> <span class="kt">string</span>
</code></pre></div>

<p>Pretty-print the object to a formatter.</p>
<div class="highlight"><pre><span></span><code><span class="k">val</span> <span class="n">pp</span> <span class="o">:</span> <span class="nn">Format</span><span class="p">.</span><span class="n">formatter</span> <span class="o">-&gt;</span> <span class="n">t</span> <span class="o">-&gt;</span> <span class="kt">unit</span> <span class="o">[@@</span><span class="n">ocaml</span><span class="o">.</span><span class="n">toplevel_printer</span><span class="o">]</span>



<span class="k">module</span> <span class="nc">LassoCV</span> <span class="o">:</span> <span class="k">sig</span>
<span class="k">type</span> <span class="n">tag</span> <span class="o">=</span> <span class="o">[`</span><span class="nc">LassoCV</span><span class="o">]</span>
<span class="k">type</span> <span class="n">t</span> <span class="o">=</span> <span class="o">[`</span><span class="nc">BaseEstimator</span> <span class="o">|</span> <span class="o">`</span><span class="nc">LassoCV</span> <span class="o">|</span> <span class="o">`</span><span class="nc">MultiOutputMixin</span> <span class="o">|</span> <span class="o">`</span><span class="nc">Object</span> <span class="o">|</span> <span class="o">`</span><span class="nc">RegressorMixin</span><span class="o">]</span> <span class="nn">Obj</span><span class="p">.</span><span class="n">t</span>
<span class="k">val</span> <span class="n">of_pyobject</span> <span class="o">:</span> <span class="nn">Py</span><span class="p">.</span><span class="nn">Object</span><span class="p">.</span><span class="n">t</span> <span class="o">-&gt;</span> <span class="n">t</span>
<span class="k">val</span> <span class="n">to_pyobject</span> <span class="o">:</span> <span class="o">[&gt;</span> <span class="n">tag</span><span class="o">]</span> <span class="nn">Obj</span><span class="p">.</span><span class="n">t</span> <span class="o">-&gt;</span> <span class="nn">Py</span><span class="p">.</span><span class="nn">Object</span><span class="p">.</span><span class="n">t</span>

<span class="k">val</span> <span class="n">as_regressor</span> <span class="o">:</span> <span class="n">t</span> <span class="o">-&gt;</span> <span class="o">[`</span><span class="nc">RegressorMixin</span><span class="o">]</span> <span class="nn">Obj</span><span class="p">.</span><span class="n">t</span>
<span class="k">val</span> <span class="n">as_multi_output</span> <span class="o">:</span> <span class="n">t</span> <span class="o">-&gt;</span> <span class="o">[`</span><span class="nc">MultiOutputMixin</span><span class="o">]</span> <span class="nn">Obj</span><span class="p">.</span><span class="n">t</span>
<span class="k">val</span> <span class="n">as_estimator</span> <span class="o">:</span> <span class="n">t</span> <span class="o">-&gt;</span> <span class="o">[`</span><span class="nc">BaseEstimator</span><span class="o">]</span> <span class="nn">Obj</span><span class="p">.</span><span class="n">t</span>
<span class="k">val</span> <span class="n">create</span> <span class="o">:</span> <span class="o">?</span><span class="n">eps</span><span class="o">:</span><span class="kt">float</span> <span class="o">-&gt;</span> <span class="o">?</span><span class="n">n_alphas</span><span class="o">:</span><span class="kt">int</span> <span class="o">-&gt;</span> <span class="o">?</span><span class="n">alphas</span><span class="o">:[&gt;`</span><span class="nc">ArrayLike</span><span class="o">]</span> <span class="nn">Np</span><span class="p">.</span><span class="nn">Obj</span><span class="p">.</span><span class="n">t</span> <span class="o">-&gt;</span> <span class="o">?</span><span class="n">fit_intercept</span><span class="o">:</span><span class="kt">bool</span> <span class="o">-&gt;</span> <span class="o">?</span><span class="n">normalize</span><span class="o">:</span><span class="kt">bool</span> <span class="o">-&gt;</span> <span class="o">?</span><span class="n">precompute</span><span class="o">:[`</span><span class="nc">Arr</span> <span class="k">of</span> <span class="o">[&gt;`</span><span class="nc">ArrayLike</span><span class="o">]</span> <span class="nn">Np</span><span class="p">.</span><span class="nn">Obj</span><span class="p">.</span><span class="n">t</span> <span class="o">|</span> <span class="o">`</span><span class="nc">Auto</span> <span class="o">|</span> <span class="o">`</span><span class="nc">Bool</span> <span class="k">of</span> <span class="kt">bool</span><span class="o">]</span> <span class="o">-&gt;</span> <span class="o">?</span><span class="n">max_iter</span><span class="o">:</span><span class="kt">int</span> <span class="o">-&gt;</span> <span class="o">?</span><span class="n">tol</span><span class="o">:</span><span class="kt">float</span> <span class="o">-&gt;</span> <span class="o">?</span><span class="n">copy_X</span><span class="o">:</span><span class="kt">bool</span> <span class="o">-&gt;</span> <span class="o">?</span><span class="n">cv</span><span class="o">:[`</span><span class="nc">Arr</span> <span class="k">of</span> <span class="o">[&gt;`</span><span class="nc">ArrayLike</span><span class="o">]</span> <span class="nn">Np</span><span class="p">.</span><span class="nn">Obj</span><span class="p">.</span><span class="n">t</span> <span class="o">|</span> <span class="o">`</span><span class="nc">BaseCrossValidator</span> <span class="k">of</span> <span class="o">[&gt;`</span><span class="nc">BaseCrossValidator</span><span class="o">]</span> <span class="nn">Np</span><span class="p">.</span><span class="nn">Obj</span><span class="p">.</span><span class="n">t</span> <span class="o">|</span> <span class="o">`</span><span class="nc">I</span> <span class="k">of</span> <span class="kt">int</span><span class="o">]</span> <span class="o">-&gt;</span> <span class="o">?</span><span class="n">verbose</span><span class="o">:</span><span class="kt">int</span> <span class="o">-&gt;</span> <span class="o">?</span><span class="n">n_jobs</span><span class="o">:</span><span class="kt">int</span> <span class="o">-&gt;</span> <span class="o">?</span><span class="n">positive</span><span class="o">:</span><span class="kt">bool</span> <span class="o">-&gt;</span> <span class="o">?</span><span class="n">random_state</span><span class="o">:</span><span class="kt">int</span> <span class="o">-&gt;</span> <span class="o">?</span><span class="n">selection</span><span class="o">:</span><span class="kt">string</span> <span class="o">-&gt;</span> <span class="kt">unit</span> <span class="o">-&gt;</span> <span class="n">t</span>
</code></pre></div>

<p>Lasso linear model with iterative fitting along a regularization path.</p>
<p>See glossary entry for :term:<code>cross-validation estimator</code>.</p>
<p>The best model is selected by cross-validation.</p>
<p>The optimization objective for Lasso is::</p>
<p>(1 / (2 * n_samples)) * ||y - Xw||^2_2 + alpha * ||w||_1</p>
<p>Read more in the :ref:<code>User Guide &lt;lasso&gt;</code>.</p>
<h2 id="parameters_48">Parameters<a class="headerlink" href="#parameters_48" title="Permanent link">&para;</a></h2>
<p>eps : float, optional
Length of the path. <code>eps=1e-3</code> means that
<code>alpha_min / alpha_max = 1e-3</code>.</p>
<p>n_alphas : int, optional
Number of alphas along the regularization path</p>
<p>alphas : numpy array, optional
List of alphas where to compute the models.
If <code>None</code> alphas are set automatically</p>
<p>fit_intercept : boolean, default True
whether to calculate the intercept for this model. If set
to false, no intercept will be used in calculations
(i.e. data is expected to be centered).</p>
<p>normalize : boolean, optional, default False
This parameter is ignored when <code>fit_intercept</code> is set to False.
If True, the regressors X will be normalized before regression by
subtracting the mean and dividing by the l2-norm.
If you wish to standardize, please use
:class:<code>sklearn.preprocessing.StandardScaler</code> before calling <code>fit</code>
on an estimator with <code>normalize=False</code>.</p>
<p>precompute : True | False | 'auto' | array-like
Whether to use a precomputed Gram matrix to speed up
calculations. If set to <code>'auto'</code> let us decide. The Gram
matrix can also be passed as argument.</p>
<p>max_iter : int, optional
The maximum number of iterations</p>
<p>tol : float, optional
The tolerance for the optimization: if the updates are
smaller than <code>tol</code>, the optimization code checks the
dual gap for optimality and continues until it is smaller
than <code>tol</code>.</p>
<p>copy_X : boolean, optional, default True
If <code>True</code>, X will be copied; else, it may be overwritten.</p>
<p>cv : int, cross-validation generator or an iterable, optional
Determines the cross-validation splitting strategy.
Possible inputs for cv are:</p>
<ul>
<li>None, to use the default 5-fold cross-validation,</li>
<li>integer, to specify the number of folds.</li>
<li>:term:<code>CV splitter</code>,</li>
<li>An iterable yielding (train, test) splits as arrays of indices.</li>
</ul>
<p>For integer/None inputs, :class:<code>KFold</code> is used.</p>
<p>Refer :ref:<code>User Guide &lt;cross_validation&gt;</code> for the various
cross-validation strategies that can be used here.</p>
<p>.. versionchanged:: 0.22
<code>cv</code> default value if None changed from 3-fold to 5-fold.</p>
<p>verbose : bool or integer
Amount of verbosity.</p>
<p>n_jobs : int or None, optional (default=None)
Number of CPUs to use during the cross validation.
<code>None</code> means 1 unless in a :obj:<code>joblib.parallel_backend</code> context.
<code>-1</code> means using all processors. See :term:<code>Glossary &lt;n_jobs&gt;</code>
for more details.</p>
<p>positive : bool, optional
If positive, restrict regression coefficients to be positive</p>
<p>random_state : int, RandomState instance or None, optional, default None
The seed of the pseudo random number generator that selects a random
feature to update.  If int, random_state is the seed used by the random
number generator; If RandomState instance, random_state is the random
number generator; If None, the random number generator is the
RandomState instance used by <code>np.random</code>. Used when <code>selection</code> ==
'random'.</p>
<p>selection : str, default 'cyclic'
If set to 'random', a random coefficient is updated every iteration
rather than looping over features sequentially by default. This
(setting to 'random') often leads to significantly faster convergence
especially when tol is higher than 1e-4.</p>
<h2 id="attributes_8">Attributes<a class="headerlink" href="#attributes_8" title="Permanent link">&para;</a></h2>
<p>alpha_ : float
The amount of penalization chosen by cross validation</p>
<p>coef_ : array, shape (n_features,) | (n_targets, n_features)
parameter vector (w in the cost function formula)</p>
<p>intercept_ : float | array, shape (n_targets,)
independent term in decision function.</p>
<p>mse_path_ : array, shape (n_alphas, n_folds)
mean square error for the test set on each fold, varying alpha</p>
<p>alphas_ : numpy array, shape (n_alphas,)
The grid of alphas used for fitting</p>
<p>dual_gap_ : ndarray, shape ()
The dual gap at the end of the optimization for the optimal alpha
(<code>alpha_</code>).</p>
<p>n_iter_ : int
number of iterations run by the coordinate descent solver to reach
the specified tolerance for the optimal alpha.</p>
<h2 id="examples_8">Examples<a class="headerlink" href="#examples_8" title="Permanent link">&para;</a></h2>
<blockquote>
<blockquote>
<blockquote>
<p>from sklearn.linear_model import LassoCV
from sklearn.datasets import make_regression
X, y = make_regression(noise=4, random_state=0)
reg = LassoCV(cv=5, random_state=0).fit(X, y)
reg.score(X, y)
0.9993...
reg.predict(X[:1,])
array([-78.4951...])</p>
</blockquote>
</blockquote>
</blockquote>
<h2 id="notes_15">Notes<a class="headerlink" href="#notes_15" title="Permanent link">&para;</a></h2>
<p>For an example, see
:ref:<code>examples/linear_model/plot_lasso_model_selection.py
&lt;sphx_glr_auto_examples_linear_model_plot_lasso_model_selection.py&gt;</code>.</p>
<p>To avoid unnecessary memory duplication the X argument of the fit method
should be directly passed as a Fortran-contiguous numpy array.</p>
<h2 id="see-also_5">See also<a class="headerlink" href="#see-also_5" title="Permanent link">&para;</a></h2>
<p>lars_path
lasso_path
LassoLars
Lasso
LassoLarsCV</p>
<div class="highlight"><pre><span></span><code><span class="k">val</span> <span class="n">fit</span> <span class="o">:</span> <span class="n">x</span><span class="o">:</span><span class="nn">Py</span><span class="p">.</span><span class="nn">Object</span><span class="p">.</span><span class="n">t</span> <span class="o">-&gt;</span> <span class="n">y</span><span class="o">:[&gt;`</span><span class="nc">ArrayLike</span><span class="o">]</span> <span class="nn">Np</span><span class="p">.</span><span class="nn">Obj</span><span class="p">.</span><span class="n">t</span> <span class="o">-&gt;</span> <span class="o">[&gt;</span> <span class="n">tag</span><span class="o">]</span> <span class="nn">Obj</span><span class="p">.</span><span class="n">t</span> <span class="o">-&gt;</span> <span class="n">t</span>
</code></pre></div>

<p>Fit linear model with coordinate descent</p>
<p>Fit is on grid of alphas and best alpha estimated by cross-validation.</p>
<h2 id="parameters_49">Parameters<a class="headerlink" href="#parameters_49" title="Permanent link">&para;</a></h2>
<p>X : {array-like}, shape (n_samples, n_features)
Training data. Pass directly as Fortran-contiguous data
to avoid unnecessary memory duplication. If y is mono-output,
X can be sparse.</p>
<p>y : array-like, shape (n_samples,) or (n_samples, n_targets)
Target values</p>
<div class="highlight"><pre><span></span><code><span class="k">val</span> <span class="n">get_params</span> <span class="o">:</span> <span class="o">?</span><span class="n">deep</span><span class="o">:</span><span class="kt">bool</span> <span class="o">-&gt;</span> <span class="o">[&gt;</span> <span class="n">tag</span><span class="o">]</span> <span class="nn">Obj</span><span class="p">.</span><span class="n">t</span> <span class="o">-&gt;</span> <span class="nn">Dict</span><span class="p">.</span><span class="n">t</span>
</code></pre></div>

<p>Get parameters for this estimator.</p>
<h2 id="parameters_50">Parameters<a class="headerlink" href="#parameters_50" title="Permanent link">&para;</a></h2>
<p>deep : bool, default=True
If True, will return the parameters for this estimator and
contained subobjects that are estimators.</p>
<h2 id="returns_37">Returns<a class="headerlink" href="#returns_37" title="Permanent link">&para;</a></h2>
<p>params : mapping of string to any
Parameter names mapped to their values.</p>
<div class="highlight"><pre><span></span><code><span class="k">val</span> <span class="n">predict</span> <span class="o">:</span> <span class="n">x</span><span class="o">:[&gt;`</span><span class="nc">ArrayLike</span><span class="o">]</span> <span class="nn">Np</span><span class="p">.</span><span class="nn">Obj</span><span class="p">.</span><span class="n">t</span> <span class="o">-&gt;</span> <span class="o">[&gt;</span> <span class="n">tag</span><span class="o">]</span> <span class="nn">Obj</span><span class="p">.</span><span class="n">t</span> <span class="o">-&gt;</span> <span class="o">[&gt;`</span><span class="nc">ArrayLike</span><span class="o">]</span> <span class="nn">Np</span><span class="p">.</span><span class="nn">Obj</span><span class="p">.</span><span class="n">t</span>
</code></pre></div>

<p>Predict using the linear model.</p>
<h2 id="parameters_51">Parameters<a class="headerlink" href="#parameters_51" title="Permanent link">&para;</a></h2>
<p>X : array_like or sparse matrix, shape (n_samples, n_features)
Samples.</p>
<h2 id="returns_38">Returns<a class="headerlink" href="#returns_38" title="Permanent link">&para;</a></h2>
<p>C : array, shape (n_samples,)
Returns predicted values.</p>
<div class="highlight"><pre><span></span><code><span class="k">val</span> <span class="n">score</span> <span class="o">:</span> <span class="o">?</span><span class="n">sample_weight</span><span class="o">:[&gt;`</span><span class="nc">ArrayLike</span><span class="o">]</span> <span class="nn">Np</span><span class="p">.</span><span class="nn">Obj</span><span class="p">.</span><span class="n">t</span> <span class="o">-&gt;</span> <span class="n">x</span><span class="o">:[&gt;`</span><span class="nc">ArrayLike</span><span class="o">]</span> <span class="nn">Np</span><span class="p">.</span><span class="nn">Obj</span><span class="p">.</span><span class="n">t</span> <span class="o">-&gt;</span> <span class="n">y</span><span class="o">:[&gt;`</span><span class="nc">ArrayLike</span><span class="o">]</span> <span class="nn">Np</span><span class="p">.</span><span class="nn">Obj</span><span class="p">.</span><span class="n">t</span> <span class="o">-&gt;</span> <span class="o">[&gt;</span> <span class="n">tag</span><span class="o">]</span> <span class="nn">Obj</span><span class="p">.</span><span class="n">t</span> <span class="o">-&gt;</span> <span class="kt">float</span>
</code></pre></div>

<p>Return the coefficient of determination R^2 of the prediction.</p>
<p>The coefficient R^2 is defined as (1 - u/v), where u is the residual
sum of squares ((y_true - y_pred) <strong> 2).sum() and v is the total
sum of squares ((y_true - y_true.mean()) </strong> 2).sum().
The best possible score is 1.0 and it can be negative (because the
model can be arbitrarily worse). A constant model that always
predicts the expected value of y, disregarding the input features,
would get a R^2 score of 0.0.</p>
<h2 id="parameters_52">Parameters<a class="headerlink" href="#parameters_52" title="Permanent link">&para;</a></h2>
<p>X : array-like of shape (n_samples, n_features)
Test samples. For some estimators this may be a
precomputed kernel matrix or a list of generic objects instead,
shape = (n_samples, n_samples_fitted),
where n_samples_fitted is the number of
samples used in the fitting for the estimator.</p>
<p>y : array-like of shape (n_samples,) or (n_samples, n_outputs)
True values for X.</p>
<p>sample_weight : array-like of shape (n_samples,), default=None
Sample weights.</p>
<h2 id="returns_39">Returns<a class="headerlink" href="#returns_39" title="Permanent link">&para;</a></h2>
<p>score : float
R^2 of self.predict(X) wrt. y.</p>
<h2 id="notes_16">Notes<a class="headerlink" href="#notes_16" title="Permanent link">&para;</a></h2>
<p>The R2 score used when calling <code>score</code> on a regressor will use
<code>multioutput='uniform_average'</code> from version 0.23 to keep consistent
with :func:<code>~sklearn.metrics.r2_score</code>. This will influence the
<code>score</code> method of all the multioutput regressors (except for
:class:<code>~sklearn.multioutput.MultiOutputRegressor</code>). To specify the
default value manually and avoid the warning, please either call
:func:<code>~sklearn.metrics.r2_score</code> directly or make a custom scorer with
:func:<code>~sklearn.metrics.make_scorer</code> (the built-in scorer <code>'r2'</code> uses
<code>multioutput='uniform_average'</code>).</p>
<div class="highlight"><pre><span></span><code><span class="k">val</span> <span class="n">set_params</span> <span class="o">:</span> <span class="o">?</span><span class="n">params</span><span class="o">:(</span><span class="kt">string</span> <span class="o">*</span> <span class="nn">Py</span><span class="p">.</span><span class="nn">Object</span><span class="p">.</span><span class="n">t</span><span class="o">)</span> <span class="kt">list</span> <span class="o">-&gt;</span> <span class="o">[&gt;</span> <span class="n">tag</span><span class="o">]</span> <span class="nn">Obj</span><span class="p">.</span><span class="n">t</span> <span class="o">-&gt;</span> <span class="n">t</span>
</code></pre></div>

<p>Set the parameters of this estimator.</p>
<p>The method works on simple estimators as well as on nested objects
(such as pipelines). The latter have parameters of the form
<code>&lt;component&gt;__&lt;parameter&gt;</code> so that it's possible to update each
component of a nested object.</p>
<h2 id="parameters_53">Parameters<a class="headerlink" href="#parameters_53" title="Permanent link">&para;</a></h2>
<p>**params : dict
Estimator parameters.</p>
<h2 id="returns_40">Returns<a class="headerlink" href="#returns_40" title="Permanent link">&para;</a></h2>
<p>self : object
Estimator instance.</p>
<p>Attribute alpha_: get value or raise Not_found if None.</p>
<div class="highlight"><pre><span></span><code><span class="k">val</span> <span class="n">alpha_</span> <span class="o">:</span> <span class="n">t</span> <span class="o">-&gt;</span> <span class="kt">float</span>
</code></pre></div>

<p>Attribute alpha_: get value as an option.</p>
<div class="highlight"><pre><span></span><code><span class="k">val</span> <span class="n">alpha_opt</span> <span class="o">:</span> <span class="n">t</span> <span class="o">-&gt;</span> <span class="o">(</span><span class="kt">float</span><span class="o">)</span> <span class="n">option</span>
</code></pre></div>

<p>Attribute coef_: get value or raise Not_found if None.</p>
<div class="highlight"><pre><span></span><code><span class="k">val</span> <span class="n">coef_</span> <span class="o">:</span> <span class="n">t</span> <span class="o">-&gt;</span> <span class="o">[&gt;`</span><span class="nc">ArrayLike</span><span class="o">]</span> <span class="nn">Np</span><span class="p">.</span><span class="nn">Obj</span><span class="p">.</span><span class="n">t</span>
</code></pre></div>

<p>Attribute coef_: get value as an option.</p>
<div class="highlight"><pre><span></span><code><span class="k">val</span> <span class="n">coef_opt</span> <span class="o">:</span> <span class="n">t</span> <span class="o">-&gt;</span> <span class="o">([&gt;`</span><span class="nc">ArrayLike</span><span class="o">]</span> <span class="nn">Np</span><span class="p">.</span><span class="nn">Obj</span><span class="p">.</span><span class="n">t</span><span class="o">)</span> <span class="n">option</span>
</code></pre></div>

<p>Attribute intercept_: get value or raise Not_found if None.</p>
<div class="highlight"><pre><span></span><code><span class="k">val</span> <span class="n">intercept_</span> <span class="o">:</span> <span class="n">t</span> <span class="o">-&gt;</span> <span class="o">[&gt;`</span><span class="nc">ArrayLike</span><span class="o">]</span> <span class="nn">Np</span><span class="p">.</span><span class="nn">Obj</span><span class="p">.</span><span class="n">t</span>
</code></pre></div>

<p>Attribute intercept_: get value as an option.</p>
<div class="highlight"><pre><span></span><code><span class="k">val</span> <span class="n">intercept_opt</span> <span class="o">:</span> <span class="n">t</span> <span class="o">-&gt;</span> <span class="o">([&gt;`</span><span class="nc">ArrayLike</span><span class="o">]</span> <span class="nn">Np</span><span class="p">.</span><span class="nn">Obj</span><span class="p">.</span><span class="n">t</span><span class="o">)</span> <span class="n">option</span>
</code></pre></div>

<p>Attribute mse_path_: get value or raise Not_found if None.</p>
<div class="highlight"><pre><span></span><code><span class="k">val</span> <span class="n">mse_path_</span> <span class="o">:</span> <span class="n">t</span> <span class="o">-&gt;</span> <span class="o">[&gt;`</span><span class="nc">ArrayLike</span><span class="o">]</span> <span class="nn">Np</span><span class="p">.</span><span class="nn">Obj</span><span class="p">.</span><span class="n">t</span>
</code></pre></div>

<p>Attribute mse_path_: get value as an option.</p>
<div class="highlight"><pre><span></span><code><span class="k">val</span> <span class="n">mse_path_opt</span> <span class="o">:</span> <span class="n">t</span> <span class="o">-&gt;</span> <span class="o">([&gt;`</span><span class="nc">ArrayLike</span><span class="o">]</span> <span class="nn">Np</span><span class="p">.</span><span class="nn">Obj</span><span class="p">.</span><span class="n">t</span><span class="o">)</span> <span class="n">option</span>
</code></pre></div>

<p>Attribute alphas_: get value or raise Not_found if None.</p>
<div class="highlight"><pre><span></span><code><span class="k">val</span> <span class="n">alphas_</span> <span class="o">:</span> <span class="n">t</span> <span class="o">-&gt;</span> <span class="o">[&gt;`</span><span class="nc">ArrayLike</span><span class="o">]</span> <span class="nn">Np</span><span class="p">.</span><span class="nn">Obj</span><span class="p">.</span><span class="n">t</span>
</code></pre></div>

<p>Attribute alphas_: get value as an option.</p>
<div class="highlight"><pre><span></span><code><span class="k">val</span> <span class="n">alphas_opt</span> <span class="o">:</span> <span class="n">t</span> <span class="o">-&gt;</span> <span class="o">([&gt;`</span><span class="nc">ArrayLike</span><span class="o">]</span> <span class="nn">Np</span><span class="p">.</span><span class="nn">Obj</span><span class="p">.</span><span class="n">t</span><span class="o">)</span> <span class="n">option</span>
</code></pre></div>

<p>Attribute dual_gap_: get value or raise Not_found if None.</p>
<div class="highlight"><pre><span></span><code><span class="k">val</span> <span class="n">dual_gap_</span> <span class="o">:</span> <span class="n">t</span> <span class="o">-&gt;</span> <span class="o">[&gt;`</span><span class="nc">ArrayLike</span><span class="o">]</span> <span class="nn">Np</span><span class="p">.</span><span class="nn">Obj</span><span class="p">.</span><span class="n">t</span>
</code></pre></div>

<p>Attribute dual_gap_: get value as an option.</p>
<div class="highlight"><pre><span></span><code><span class="k">val</span> <span class="n">dual_gap_opt</span> <span class="o">:</span> <span class="n">t</span> <span class="o">-&gt;</span> <span class="o">([&gt;`</span><span class="nc">ArrayLike</span><span class="o">]</span> <span class="nn">Np</span><span class="p">.</span><span class="nn">Obj</span><span class="p">.</span><span class="n">t</span><span class="o">)</span> <span class="n">option</span>
</code></pre></div>

<p>Attribute n_iter_: get value or raise Not_found if None.</p>
<div class="highlight"><pre><span></span><code><span class="k">val</span> <span class="n">n_iter_</span> <span class="o">:</span> <span class="n">t</span> <span class="o">-&gt;</span> <span class="kt">int</span>
</code></pre></div>

<p>Attribute n_iter_: get value as an option.</p>
<div class="highlight"><pre><span></span><code><span class="k">val</span> <span class="n">n_iter_opt</span> <span class="o">:</span> <span class="n">t</span> <span class="o">-&gt;</span> <span class="o">(</span><span class="kt">int</span><span class="o">)</span> <span class="n">option</span>
</code></pre></div>

<p>Print the object to a human-readable representation.</p>
<div class="highlight"><pre><span></span><code><span class="k">val</span> <span class="n">to_string</span> <span class="o">:</span> <span class="n">t</span> <span class="o">-&gt;</span> <span class="kt">string</span>
</code></pre></div>

<p>Print the object to a human-readable representation.</p>
<div class="highlight"><pre><span></span><code><span class="k">val</span> <span class="n">show</span> <span class="o">:</span> <span class="n">t</span> <span class="o">-&gt;</span> <span class="kt">string</span>
</code></pre></div>

<p>Pretty-print the object to a formatter.</p>
<div class="highlight"><pre><span></span><code><span class="k">val</span> <span class="n">pp</span> <span class="o">:</span> <span class="nn">Format</span><span class="p">.</span><span class="n">formatter</span> <span class="o">-&gt;</span> <span class="n">t</span> <span class="o">-&gt;</span> <span class="kt">unit</span> <span class="o">[@@</span><span class="n">ocaml</span><span class="o">.</span><span class="n">toplevel_printer</span><span class="o">]</span>



<span class="k">module</span> <span class="nc">LassoLars</span> <span class="o">:</span> <span class="k">sig</span>
<span class="k">type</span> <span class="n">tag</span> <span class="o">=</span> <span class="o">[`</span><span class="nc">LassoLars</span><span class="o">]</span>
<span class="k">type</span> <span class="n">t</span> <span class="o">=</span> <span class="o">[`</span><span class="nc">BaseEstimator</span> <span class="o">|</span> <span class="o">`</span><span class="nc">LassoLars</span> <span class="o">|</span> <span class="o">`</span><span class="nc">MultiOutputMixin</span> <span class="o">|</span> <span class="o">`</span><span class="nc">Object</span> <span class="o">|</span> <span class="o">`</span><span class="nc">RegressorMixin</span><span class="o">]</span> <span class="nn">Obj</span><span class="p">.</span><span class="n">t</span>
<span class="k">val</span> <span class="n">of_pyobject</span> <span class="o">:</span> <span class="nn">Py</span><span class="p">.</span><span class="nn">Object</span><span class="p">.</span><span class="n">t</span> <span class="o">-&gt;</span> <span class="n">t</span>
<span class="k">val</span> <span class="n">to_pyobject</span> <span class="o">:</span> <span class="o">[&gt;</span> <span class="n">tag</span><span class="o">]</span> <span class="nn">Obj</span><span class="p">.</span><span class="n">t</span> <span class="o">-&gt;</span> <span class="nn">Py</span><span class="p">.</span><span class="nn">Object</span><span class="p">.</span><span class="n">t</span>

<span class="k">val</span> <span class="n">as_regressor</span> <span class="o">:</span> <span class="n">t</span> <span class="o">-&gt;</span> <span class="o">[`</span><span class="nc">RegressorMixin</span><span class="o">]</span> <span class="nn">Obj</span><span class="p">.</span><span class="n">t</span>
<span class="k">val</span> <span class="n">as_multi_output</span> <span class="o">:</span> <span class="n">t</span> <span class="o">-&gt;</span> <span class="o">[`</span><span class="nc">MultiOutputMixin</span><span class="o">]</span> <span class="nn">Obj</span><span class="p">.</span><span class="n">t</span>
<span class="k">val</span> <span class="n">as_estimator</span> <span class="o">:</span> <span class="n">t</span> <span class="o">-&gt;</span> <span class="o">[`</span><span class="nc">BaseEstimator</span><span class="o">]</span> <span class="nn">Obj</span><span class="p">.</span><span class="n">t</span>
<span class="k">val</span> <span class="n">create</span> <span class="o">:</span> <span class="o">?</span><span class="n">alpha</span><span class="o">:</span><span class="kt">float</span> <span class="o">-&gt;</span> <span class="o">?</span><span class="n">fit_intercept</span><span class="o">:</span><span class="kt">bool</span> <span class="o">-&gt;</span> <span class="o">?</span><span class="n">verbose</span><span class="o">:</span><span class="kt">int</span> <span class="o">-&gt;</span> <span class="o">?</span><span class="n">normalize</span><span class="o">:</span><span class="kt">bool</span> <span class="o">-&gt;</span> <span class="o">?</span><span class="n">precompute</span><span class="o">:[`</span><span class="nc">Arr</span> <span class="k">of</span> <span class="o">[&gt;`</span><span class="nc">ArrayLike</span><span class="o">]</span> <span class="nn">Np</span><span class="p">.</span><span class="nn">Obj</span><span class="p">.</span><span class="n">t</span> <span class="o">|</span> <span class="o">`</span><span class="nc">Auto</span> <span class="o">|</span> <span class="o">`</span><span class="nc">Bool</span> <span class="k">of</span> <span class="kt">bool</span><span class="o">]</span> <span class="o">-&gt;</span> <span class="o">?</span><span class="n">max_iter</span><span class="o">:</span><span class="kt">int</span> <span class="o">-&gt;</span> <span class="o">?</span><span class="n">eps</span><span class="o">:</span><span class="kt">float</span> <span class="o">-&gt;</span> <span class="o">?</span><span class="n">copy_X</span><span class="o">:</span><span class="kt">bool</span> <span class="o">-&gt;</span> <span class="o">?</span><span class="n">fit_path</span><span class="o">:</span><span class="kt">bool</span> <span class="o">-&gt;</span> <span class="o">?</span><span class="n">positive</span><span class="o">:</span><span class="kt">bool</span> <span class="o">-&gt;</span> <span class="kt">unit</span> <span class="o">-&gt;</span> <span class="n">t</span>
</code></pre></div>

<p>Lasso model fit with Least Angle Regression a.k.a. Lars</p>
<p>It is a Linear Model trained with an L1 prior as regularizer.</p>
<p>The optimization objective for Lasso is::</p>
<p>(1 / (2 * n_samples)) * ||y - Xw||^2_2 + alpha * ||w||_1</p>
<p>Read more in the :ref:<code>User Guide &lt;least_angle_regression&gt;</code>.</p>
<h2 id="parameters_54">Parameters<a class="headerlink" href="#parameters_54" title="Permanent link">&para;</a></h2>
<p>alpha : float, default=1.0
Constant that multiplies the penalty term. Defaults to 1.0.
<code>alpha = 0</code> is equivalent to an ordinary least square, solved
by :class:<code>LinearRegression</code>. For numerical reasons, using
<code>alpha = 0</code> with the LassoLars object is not advised and you
should prefer the LinearRegression object.</p>
<p>fit_intercept : bool, default=True
whether to calculate the intercept for this model. If set
to false, no intercept will be used in calculations
(i.e. data is expected to be centered).</p>
<p>verbose : bool or int, default=False
Sets the verbosity amount</p>
<p>normalize : bool, default=True
This parameter is ignored when <code>fit_intercept</code> is set to False.
If True, the regressors X will be normalized before regression by
subtracting the mean and dividing by the l2-norm.
If you wish to standardize, please use
:class:<code>sklearn.preprocessing.StandardScaler</code> before calling <code>fit</code>
on an estimator with <code>normalize=False</code>.</p>
<p>precompute : bool, 'auto' or array-like, default='auto'
Whether to use a precomputed Gram matrix to speed up
calculations. If set to <code>'auto'</code> let us decide. The Gram
matrix can also be passed as argument.</p>
<p>max_iter : int, default=500
Maximum number of iterations to perform.</p>
<p>eps : float, optional
The machine-precision regularization in the computation of the
Cholesky diagonal factors. Increase this for very ill-conditioned
systems. Unlike the <code>tol</code> parameter in some iterative
optimization-based algorithms, this parameter does not control
the tolerance of the optimization.
By default, <code>np.finfo(np.float).eps</code> is used.</p>
<p>copy_X : bool, default=True
If True, X will be copied; else, it may be overwritten.</p>
<p>fit_path : bool, default=True
If <code>True</code> the full path is stored in the <code>coef_path_</code> attribute.
If you compute the solution for a large problem or many targets,
setting <code>fit_path</code> to <code>False</code> will lead to a speedup, especially
with a small alpha.</p>
<p>positive : bool, default=False
Restrict coefficients to be &gt;= 0. Be aware that you might want to
remove fit_intercept which is set True by default.
Under the positive restriction the model coefficients will not converge
to the ordinary-least-squares solution for small values of alpha.
Only coefficients up to the smallest alpha value (<code>alphas_[alphas_ &gt;
0.].min()</code> when fit_path=True) reached by the stepwise Lars-Lasso
algorithm are typically in congruence with the solution of the
coordinate descent Lasso estimator.</p>
<h2 id="attributes_9">Attributes<a class="headerlink" href="#attributes_9" title="Permanent link">&para;</a></h2>
<p>alphas_ : array-like of shape (n_alphas + 1,) | list of n_targets such             arrays
Maximum of covariances (in absolute value) at each iteration.         <code>n_alphas</code> is either <code>max_iter</code>, <code>n_features</code>, or the number of         nodes in the path with correlation greater than <code>alpha</code>, whichever         is smaller.</p>
<p>active_ : list, length = n_alphas | list of n_targets such lists
Indices of active variables at the end of the path.</p>
<p>coef_path_ : array-like of shape (n_features, n_alphas + 1) or list
If a list is passed it's expected to be one of n_targets such arrays.
The varying values of the coefficients along the path. It is not
present if the <code>fit_path</code> parameter is <code>False</code>.</p>
<p>coef_ : array-like of shape (n_features,) or (n_targets, n_features)
Parameter vector (w in the formulation formula).</p>
<p>intercept_ : float or array-like of shape (n_targets,)
Independent term in decision function.</p>
<p>n_iter_ : array-like or int.
The number of iterations taken by lars_path to find the
grid of alphas for each target.</p>
<h2 id="examples_9">Examples<a class="headerlink" href="#examples_9" title="Permanent link">&para;</a></h2>
<blockquote>
<blockquote>
<blockquote>
<p>from sklearn import linear_model
reg = linear_model.LassoLars(alpha=0.01)
reg.fit([[-1, 1], [0, 0], [1, 1]], [-1, 0, -1])
LassoLars(alpha=0.01)
print(reg.coef_)
[ 0.         -0.963257...]</p>
</blockquote>
</blockquote>
</blockquote>
<h2 id="see-also_6">See also<a class="headerlink" href="#see-also_6" title="Permanent link">&para;</a></h2>
<p>lars_path
lasso_path
Lasso
LassoCV
LassoLarsCV
LassoLarsIC
sklearn.decomposition.sparse_encode</p>
<div class="highlight"><pre><span></span><code><span class="k">val</span> <span class="n">fit</span> <span class="o">:</span> <span class="o">?</span><span class="n">xy</span><span class="o">:[&gt;`</span><span class="nc">ArrayLike</span><span class="o">]</span> <span class="nn">Np</span><span class="p">.</span><span class="nn">Obj</span><span class="p">.</span><span class="n">t</span> <span class="o">-&gt;</span> <span class="n">x</span><span class="o">:[&gt;`</span><span class="nc">ArrayLike</span><span class="o">]</span> <span class="nn">Np</span><span class="p">.</span><span class="nn">Obj</span><span class="p">.</span><span class="n">t</span> <span class="o">-&gt;</span> <span class="n">y</span><span class="o">:[&gt;`</span><span class="nc">ArrayLike</span><span class="o">]</span> <span class="nn">Np</span><span class="p">.</span><span class="nn">Obj</span><span class="p">.</span><span class="n">t</span> <span class="o">-&gt;</span> <span class="o">[&gt;</span> <span class="n">tag</span><span class="o">]</span> <span class="nn">Obj</span><span class="p">.</span><span class="n">t</span> <span class="o">-&gt;</span> <span class="n">t</span>
</code></pre></div>

<p>Fit the model using X, y as training data.</p>
<h2 id="parameters_55">Parameters<a class="headerlink" href="#parameters_55" title="Permanent link">&para;</a></h2>
<p>X : array-like of shape (n_samples, n_features)
Training data.</p>
<p>y : array-like of shape (n_samples,) or (n_samples, n_targets)
Target values.</p>
<p>Xy : array-like of shape (n_samples,) or (n_samples, n_targets),                 default=None
Xy = np.dot(X.T, y) that can be precomputed. It is useful
only when the Gram matrix is precomputed.</p>
<h2 id="returns_41">Returns<a class="headerlink" href="#returns_41" title="Permanent link">&para;</a></h2>
<p>self : object
returns an instance of self.</p>
<div class="highlight"><pre><span></span><code><span class="k">val</span> <span class="n">get_params</span> <span class="o">:</span> <span class="o">?</span><span class="n">deep</span><span class="o">:</span><span class="kt">bool</span> <span class="o">-&gt;</span> <span class="o">[&gt;</span> <span class="n">tag</span><span class="o">]</span> <span class="nn">Obj</span><span class="p">.</span><span class="n">t</span> <span class="o">-&gt;</span> <span class="nn">Dict</span><span class="p">.</span><span class="n">t</span>
</code></pre></div>

<p>Get parameters for this estimator.</p>
<h2 id="parameters_56">Parameters<a class="headerlink" href="#parameters_56" title="Permanent link">&para;</a></h2>
<p>deep : bool, default=True
If True, will return the parameters for this estimator and
contained subobjects that are estimators.</p>
<h2 id="returns_42">Returns<a class="headerlink" href="#returns_42" title="Permanent link">&para;</a></h2>
<p>params : mapping of string to any
Parameter names mapped to their values.</p>
<div class="highlight"><pre><span></span><code><span class="k">val</span> <span class="n">predict</span> <span class="o">:</span> <span class="n">x</span><span class="o">:[&gt;`</span><span class="nc">ArrayLike</span><span class="o">]</span> <span class="nn">Np</span><span class="p">.</span><span class="nn">Obj</span><span class="p">.</span><span class="n">t</span> <span class="o">-&gt;</span> <span class="o">[&gt;</span> <span class="n">tag</span><span class="o">]</span> <span class="nn">Obj</span><span class="p">.</span><span class="n">t</span> <span class="o">-&gt;</span> <span class="o">[&gt;`</span><span class="nc">ArrayLike</span><span class="o">]</span> <span class="nn">Np</span><span class="p">.</span><span class="nn">Obj</span><span class="p">.</span><span class="n">t</span>
</code></pre></div>

<p>Predict using the linear model.</p>
<h2 id="parameters_57">Parameters<a class="headerlink" href="#parameters_57" title="Permanent link">&para;</a></h2>
<p>X : array_like or sparse matrix, shape (n_samples, n_features)
Samples.</p>
<h2 id="returns_43">Returns<a class="headerlink" href="#returns_43" title="Permanent link">&para;</a></h2>
<p>C : array, shape (n_samples,)
Returns predicted values.</p>
<div class="highlight"><pre><span></span><code><span class="k">val</span> <span class="n">score</span> <span class="o">:</span> <span class="o">?</span><span class="n">sample_weight</span><span class="o">:[&gt;`</span><span class="nc">ArrayLike</span><span class="o">]</span> <span class="nn">Np</span><span class="p">.</span><span class="nn">Obj</span><span class="p">.</span><span class="n">t</span> <span class="o">-&gt;</span> <span class="n">x</span><span class="o">:[&gt;`</span><span class="nc">ArrayLike</span><span class="o">]</span> <span class="nn">Np</span><span class="p">.</span><span class="nn">Obj</span><span class="p">.</span><span class="n">t</span> <span class="o">-&gt;</span> <span class="n">y</span><span class="o">:[&gt;`</span><span class="nc">ArrayLike</span><span class="o">]</span> <span class="nn">Np</span><span class="p">.</span><span class="nn">Obj</span><span class="p">.</span><span class="n">t</span> <span class="o">-&gt;</span> <span class="o">[&gt;</span> <span class="n">tag</span><span class="o">]</span> <span class="nn">Obj</span><span class="p">.</span><span class="n">t</span> <span class="o">-&gt;</span> <span class="kt">float</span>
</code></pre></div>

<p>Return the coefficient of determination R^2 of the prediction.</p>
<p>The coefficient R^2 is defined as (1 - u/v), where u is the residual
sum of squares ((y_true - y_pred) <strong> 2).sum() and v is the total
sum of squares ((y_true - y_true.mean()) </strong> 2).sum().
The best possible score is 1.0 and it can be negative (because the
model can be arbitrarily worse). A constant model that always
predicts the expected value of y, disregarding the input features,
would get a R^2 score of 0.0.</p>
<h2 id="parameters_58">Parameters<a class="headerlink" href="#parameters_58" title="Permanent link">&para;</a></h2>
<p>X : array-like of shape (n_samples, n_features)
Test samples. For some estimators this may be a
precomputed kernel matrix or a list of generic objects instead,
shape = (n_samples, n_samples_fitted),
where n_samples_fitted is the number of
samples used in the fitting for the estimator.</p>
<p>y : array-like of shape (n_samples,) or (n_samples, n_outputs)
True values for X.</p>
<p>sample_weight : array-like of shape (n_samples,), default=None
Sample weights.</p>
<h2 id="returns_44">Returns<a class="headerlink" href="#returns_44" title="Permanent link">&para;</a></h2>
<p>score : float
R^2 of self.predict(X) wrt. y.</p>
<h2 id="notes_17">Notes<a class="headerlink" href="#notes_17" title="Permanent link">&para;</a></h2>
<p>The R2 score used when calling <code>score</code> on a regressor will use
<code>multioutput='uniform_average'</code> from version 0.23 to keep consistent
with :func:<code>~sklearn.metrics.r2_score</code>. This will influence the
<code>score</code> method of all the multioutput regressors (except for
:class:<code>~sklearn.multioutput.MultiOutputRegressor</code>). To specify the
default value manually and avoid the warning, please either call
:func:<code>~sklearn.metrics.r2_score</code> directly or make a custom scorer with
:func:<code>~sklearn.metrics.make_scorer</code> (the built-in scorer <code>'r2'</code> uses
<code>multioutput='uniform_average'</code>).</p>
<div class="highlight"><pre><span></span><code><span class="k">val</span> <span class="n">set_params</span> <span class="o">:</span> <span class="o">?</span><span class="n">params</span><span class="o">:(</span><span class="kt">string</span> <span class="o">*</span> <span class="nn">Py</span><span class="p">.</span><span class="nn">Object</span><span class="p">.</span><span class="n">t</span><span class="o">)</span> <span class="kt">list</span> <span class="o">-&gt;</span> <span class="o">[&gt;</span> <span class="n">tag</span><span class="o">]</span> <span class="nn">Obj</span><span class="p">.</span><span class="n">t</span> <span class="o">-&gt;</span> <span class="n">t</span>
</code></pre></div>

<p>Set the parameters of this estimator.</p>
<p>The method works on simple estimators as well as on nested objects
(such as pipelines). The latter have parameters of the form
<code>&lt;component&gt;__&lt;parameter&gt;</code> so that it's possible to update each
component of a nested object.</p>
<h2 id="parameters_59">Parameters<a class="headerlink" href="#parameters_59" title="Permanent link">&para;</a></h2>
<p>**params : dict
Estimator parameters.</p>
<h2 id="returns_45">Returns<a class="headerlink" href="#returns_45" title="Permanent link">&para;</a></h2>
<p>self : object
Estimator instance.</p>
<p>Attribute alphas_: get value or raise Not_found if None.</p>
<div class="highlight"><pre><span></span><code><span class="k">val</span> <span class="n">alphas_</span> <span class="o">:</span> <span class="n">t</span> <span class="o">-&gt;</span> <span class="nn">Py</span><span class="p">.</span><span class="nn">Object</span><span class="p">.</span><span class="n">t</span>
</code></pre></div>

<p>Attribute alphas_: get value as an option.</p>
<div class="highlight"><pre><span></span><code><span class="k">val</span> <span class="n">alphas_opt</span> <span class="o">:</span> <span class="n">t</span> <span class="o">-&gt;</span> <span class="o">(</span><span class="nn">Py</span><span class="p">.</span><span class="nn">Object</span><span class="p">.</span><span class="n">t</span><span class="o">)</span> <span class="n">option</span>
</code></pre></div>

<p>Attribute active_: get value or raise Not_found if None.</p>
<div class="highlight"><pre><span></span><code><span class="k">val</span> <span class="n">active_</span> <span class="o">:</span> <span class="n">t</span> <span class="o">-&gt;</span> <span class="nn">Py</span><span class="p">.</span><span class="nn">Object</span><span class="p">.</span><span class="n">t</span>
</code></pre></div>

<p>Attribute active_: get value as an option.</p>
<div class="highlight"><pre><span></span><code><span class="k">val</span> <span class="n">active_opt</span> <span class="o">:</span> <span class="n">t</span> <span class="o">-&gt;</span> <span class="o">(</span><span class="nn">Py</span><span class="p">.</span><span class="nn">Object</span><span class="p">.</span><span class="n">t</span><span class="o">)</span> <span class="n">option</span>
</code></pre></div>

<p>Attribute coef_path_: get value or raise Not_found if None.</p>
<div class="highlight"><pre><span></span><code><span class="k">val</span> <span class="n">coef_path_</span> <span class="o">:</span> <span class="n">t</span> <span class="o">-&gt;</span> <span class="o">[&gt;`</span><span class="nc">ArrayLike</span><span class="o">]</span> <span class="nn">Np</span><span class="p">.</span><span class="nn">Obj</span><span class="p">.</span><span class="n">t</span>
</code></pre></div>

<p>Attribute coef_path_: get value as an option.</p>
<div class="highlight"><pre><span></span><code><span class="k">val</span> <span class="n">coef_path_opt</span> <span class="o">:</span> <span class="n">t</span> <span class="o">-&gt;</span> <span class="o">([&gt;`</span><span class="nc">ArrayLike</span><span class="o">]</span> <span class="nn">Np</span><span class="p">.</span><span class="nn">Obj</span><span class="p">.</span><span class="n">t</span><span class="o">)</span> <span class="n">option</span>
</code></pre></div>

<p>Attribute coef_: get value or raise Not_found if None.</p>
<div class="highlight"><pre><span></span><code><span class="k">val</span> <span class="n">coef_</span> <span class="o">:</span> <span class="n">t</span> <span class="o">-&gt;</span> <span class="o">[&gt;`</span><span class="nc">ArrayLike</span><span class="o">]</span> <span class="nn">Np</span><span class="p">.</span><span class="nn">Obj</span><span class="p">.</span><span class="n">t</span>
</code></pre></div>

<p>Attribute coef_: get value as an option.</p>
<div class="highlight"><pre><span></span><code><span class="k">val</span> <span class="n">coef_opt</span> <span class="o">:</span> <span class="n">t</span> <span class="o">-&gt;</span> <span class="o">([&gt;`</span><span class="nc">ArrayLike</span><span class="o">]</span> <span class="nn">Np</span><span class="p">.</span><span class="nn">Obj</span><span class="p">.</span><span class="n">t</span><span class="o">)</span> <span class="n">option</span>
</code></pre></div>

<p>Attribute intercept_: get value or raise Not_found if None.</p>
<div class="highlight"><pre><span></span><code><span class="k">val</span> <span class="n">intercept_</span> <span class="o">:</span> <span class="n">t</span> <span class="o">-&gt;</span> <span class="o">[&gt;`</span><span class="nc">ArrayLike</span><span class="o">]</span> <span class="nn">Np</span><span class="p">.</span><span class="nn">Obj</span><span class="p">.</span><span class="n">t</span>
</code></pre></div>

<p>Attribute intercept_: get value as an option.</p>
<div class="highlight"><pre><span></span><code><span class="k">val</span> <span class="n">intercept_opt</span> <span class="o">:</span> <span class="n">t</span> <span class="o">-&gt;</span> <span class="o">([&gt;`</span><span class="nc">ArrayLike</span><span class="o">]</span> <span class="nn">Np</span><span class="p">.</span><span class="nn">Obj</span><span class="p">.</span><span class="n">t</span><span class="o">)</span> <span class="n">option</span>
</code></pre></div>

<p>Attribute n_iter_: get value or raise Not_found if None.</p>
<div class="highlight"><pre><span></span><code><span class="k">val</span> <span class="n">n_iter_</span> <span class="o">:</span> <span class="n">t</span> <span class="o">-&gt;</span> <span class="nn">Py</span><span class="p">.</span><span class="nn">Object</span><span class="p">.</span><span class="n">t</span>
</code></pre></div>

<p>Attribute n_iter_: get value as an option.</p>
<div class="highlight"><pre><span></span><code><span class="k">val</span> <span class="n">n_iter_opt</span> <span class="o">:</span> <span class="n">t</span> <span class="o">-&gt;</span> <span class="o">(</span><span class="nn">Py</span><span class="p">.</span><span class="nn">Object</span><span class="p">.</span><span class="n">t</span><span class="o">)</span> <span class="n">option</span>
</code></pre></div>

<p>Print the object to a human-readable representation.</p>
<div class="highlight"><pre><span></span><code><span class="k">val</span> <span class="n">to_string</span> <span class="o">:</span> <span class="n">t</span> <span class="o">-&gt;</span> <span class="kt">string</span>
</code></pre></div>

<p>Print the object to a human-readable representation.</p>
<div class="highlight"><pre><span></span><code><span class="k">val</span> <span class="n">show</span> <span class="o">:</span> <span class="n">t</span> <span class="o">-&gt;</span> <span class="kt">string</span>
</code></pre></div>

<p>Pretty-print the object to a formatter.</p>
<div class="highlight"><pre><span></span><code><span class="k">val</span> <span class="n">pp</span> <span class="o">:</span> <span class="nn">Format</span><span class="p">.</span><span class="n">formatter</span> <span class="o">-&gt;</span> <span class="n">t</span> <span class="o">-&gt;</span> <span class="kt">unit</span> <span class="o">[@@</span><span class="n">ocaml</span><span class="o">.</span><span class="n">toplevel_printer</span><span class="o">]</span>



<span class="k">module</span> <span class="nc">LassoLarsCV</span> <span class="o">:</span> <span class="k">sig</span>
<span class="k">type</span> <span class="n">tag</span> <span class="o">=</span> <span class="o">[`</span><span class="nc">LassoLarsCV</span><span class="o">]</span>
<span class="k">type</span> <span class="n">t</span> <span class="o">=</span> <span class="o">[`</span><span class="nc">BaseEstimator</span> <span class="o">|</span> <span class="o">`</span><span class="nc">LassoLarsCV</span> <span class="o">|</span> <span class="o">`</span><span class="nc">MultiOutputMixin</span> <span class="o">|</span> <span class="o">`</span><span class="nc">Object</span> <span class="o">|</span> <span class="o">`</span><span class="nc">RegressorMixin</span><span class="o">]</span> <span class="nn">Obj</span><span class="p">.</span><span class="n">t</span>
<span class="k">val</span> <span class="n">of_pyobject</span> <span class="o">:</span> <span class="nn">Py</span><span class="p">.</span><span class="nn">Object</span><span class="p">.</span><span class="n">t</span> <span class="o">-&gt;</span> <span class="n">t</span>
<span class="k">val</span> <span class="n">to_pyobject</span> <span class="o">:</span> <span class="o">[&gt;</span> <span class="n">tag</span><span class="o">]</span> <span class="nn">Obj</span><span class="p">.</span><span class="n">t</span> <span class="o">-&gt;</span> <span class="nn">Py</span><span class="p">.</span><span class="nn">Object</span><span class="p">.</span><span class="n">t</span>

<span class="k">val</span> <span class="n">as_regressor</span> <span class="o">:</span> <span class="n">t</span> <span class="o">-&gt;</span> <span class="o">[`</span><span class="nc">RegressorMixin</span><span class="o">]</span> <span class="nn">Obj</span><span class="p">.</span><span class="n">t</span>
<span class="k">val</span> <span class="n">as_multi_output</span> <span class="o">:</span> <span class="n">t</span> <span class="o">-&gt;</span> <span class="o">[`</span><span class="nc">MultiOutputMixin</span><span class="o">]</span> <span class="nn">Obj</span><span class="p">.</span><span class="n">t</span>
<span class="k">val</span> <span class="n">as_estimator</span> <span class="o">:</span> <span class="n">t</span> <span class="o">-&gt;</span> <span class="o">[`</span><span class="nc">BaseEstimator</span><span class="o">]</span> <span class="nn">Obj</span><span class="p">.</span><span class="n">t</span>
<span class="k">val</span> <span class="n">create</span> <span class="o">:</span> <span class="o">?</span><span class="n">fit_intercept</span><span class="o">:</span><span class="kt">bool</span> <span class="o">-&gt;</span> <span class="o">?</span><span class="n">verbose</span><span class="o">:</span><span class="kt">int</span> <span class="o">-&gt;</span> <span class="o">?</span><span class="n">max_iter</span><span class="o">:</span><span class="kt">int</span> <span class="o">-&gt;</span> <span class="o">?</span><span class="n">normalize</span><span class="o">:</span><span class="kt">bool</span> <span class="o">-&gt;</span> <span class="o">?</span><span class="n">precompute</span><span class="o">:[`</span><span class="nc">Auto</span> <span class="o">|</span> <span class="o">`</span><span class="nc">Bool</span> <span class="k">of</span> <span class="kt">bool</span><span class="o">]</span> <span class="o">-&gt;</span> <span class="o">?</span><span class="n">cv</span><span class="o">:[`</span><span class="nc">Arr</span> <span class="k">of</span> <span class="o">[&gt;`</span><span class="nc">ArrayLike</span><span class="o">]</span> <span class="nn">Np</span><span class="p">.</span><span class="nn">Obj</span><span class="p">.</span><span class="n">t</span> <span class="o">|</span> <span class="o">`</span><span class="nc">BaseCrossValidator</span> <span class="k">of</span> <span class="o">[&gt;`</span><span class="nc">BaseCrossValidator</span><span class="o">]</span> <span class="nn">Np</span><span class="p">.</span><span class="nn">Obj</span><span class="p">.</span><span class="n">t</span> <span class="o">|</span> <span class="o">`</span><span class="nc">I</span> <span class="k">of</span> <span class="kt">int</span><span class="o">]</span> <span class="o">-&gt;</span> <span class="o">?</span><span class="n">max_n_alphas</span><span class="o">:</span><span class="kt">int</span> <span class="o">-&gt;</span> <span class="o">?</span><span class="n">n_jobs</span><span class="o">:</span><span class="kt">int</span> <span class="o">-&gt;</span> <span class="o">?</span><span class="n">eps</span><span class="o">:</span><span class="kt">float</span> <span class="o">-&gt;</span> <span class="o">?</span><span class="n">copy_X</span><span class="o">:</span><span class="kt">bool</span> <span class="o">-&gt;</span> <span class="o">?</span><span class="n">positive</span><span class="o">:</span><span class="kt">bool</span> <span class="o">-&gt;</span> <span class="kt">unit</span> <span class="o">-&gt;</span> <span class="n">t</span>
</code></pre></div>

<p>Cross-validated Lasso, using the LARS algorithm.</p>
<p>See glossary entry for :term:<code>cross-validation estimator</code>.</p>
<p>The optimization objective for Lasso is::</p>
<p>(1 / (2 * n_samples)) * ||y - Xw||^2_2 + alpha * ||w||_1</p>
<p>Read more in the :ref:<code>User Guide &lt;least_angle_regression&gt;</code>.</p>
<h2 id="parameters_60">Parameters<a class="headerlink" href="#parameters_60" title="Permanent link">&para;</a></h2>
<p>fit_intercept : bool, default=True
whether to calculate the intercept for this model. If set
to false, no intercept will be used in calculations
(i.e. data is expected to be centered).</p>
<p>verbose : bool or int, default=False
Sets the verbosity amount</p>
<p>max_iter : int, default=500
Maximum number of iterations to perform.</p>
<p>normalize : bool, default=True
This parameter is ignored when <code>fit_intercept</code> is set to False.
If True, the regressors X will be normalized before regression by
subtracting the mean and dividing by the l2-norm.
If you wish to standardize, please use
:class:<code>sklearn.preprocessing.StandardScaler</code> before calling <code>fit</code>
on an estimator with <code>normalize=False</code>.</p>
<p>precompute : bool or 'auto' , default='auto'
Whether to use a precomputed Gram matrix to speed up
calculations. If set to <code>'auto'</code> let us decide. The Gram matrix
cannot be passed as argument since we will use only subsets of X.</p>
<p>cv : int, cross-validation generator or an iterable, default=None
Determines the cross-validation splitting strategy.
Possible inputs for cv are:</p>
<ul>
<li>None, to use the default 5-fold cross-validation,</li>
<li>integer, to specify the number of folds.</li>
<li>:term:<code>CV splitter</code>,</li>
<li>An iterable yielding (train, test) splits as arrays of indices.</li>
</ul>
<p>For integer/None inputs, :class:<code>KFold</code> is used.</p>
<p>Refer :ref:<code>User Guide &lt;cross_validation&gt;</code> for the various
cross-validation strategies that can be used here.</p>
<p>.. versionchanged:: 0.22
<code>cv</code> default value if None changed from 3-fold to 5-fold.</p>
<p>max_n_alphas : int, default=1000
The maximum number of points on the path used to compute the
residuals in the cross-validation</p>
<p>n_jobs : int or None, default=None
Number of CPUs to use during the cross validation.
<code>None</code> means 1 unless in a :obj:<code>joblib.parallel_backend</code> context.
<code>-1</code> means using all processors. See :term:<code>Glossary &lt;n_jobs&gt;</code>
for more details.</p>
<p>eps : float, optional
The machine-precision regularization in the computation of the
Cholesky diagonal factors. Increase this for very ill-conditioned
systems. By default, <code>np.finfo(np.float).eps</code> is used.</p>
<p>copy_X : bool, default=True
If True, X will be copied; else, it may be overwritten.</p>
<p>positive : bool, default=False
Restrict coefficients to be &gt;= 0. Be aware that you might want to
remove fit_intercept which is set True by default.
Under the positive restriction the model coefficients do not converge
to the ordinary-least-squares solution for small values of alpha.
Only coefficients up to the smallest alpha value (<code>alphas_[alphas_ &gt;
0.].min()</code> when fit_path=True) reached by the stepwise Lars-Lasso
algorithm are typically in congruence with the solution of the
coordinate descent Lasso estimator.
As a consequence using LassoLarsCV only makes sense for problems where
a sparse solution is expected and/or reached.</p>
<h2 id="attributes_10">Attributes<a class="headerlink" href="#attributes_10" title="Permanent link">&para;</a></h2>
<p>coef_ : array-like of shape (n_features,)
parameter vector (w in the formulation formula)</p>
<p>intercept_ : float
independent term in decision function.</p>
<p>coef_path_ : array-like of shape (n_features, n_alphas)
the varying values of the coefficients along the path</p>
<p>alpha_ : float
the estimated regularization parameter alpha</p>
<p>alphas_ : array-like of shape (n_alphas,)
the different values of alpha along the path</p>
<p>cv_alphas_ : array-like of shape (n_cv_alphas,)
all the values of alpha along the path for the different folds</p>
<p>mse_path_ : array-like of shape (n_folds, n_cv_alphas)
the mean square error on left-out for each fold along the path
(alpha values given by <code>cv_alphas</code>)</p>
<p>n_iter_ : array-like or int
the number of iterations run by Lars with the optimal alpha.</p>
<h2 id="examples_10">Examples<a class="headerlink" href="#examples_10" title="Permanent link">&para;</a></h2>
<blockquote>
<blockquote>
<blockquote>
<p>from sklearn.linear_model import LassoLarsCV
from sklearn.datasets import make_regression
X, y = make_regression(noise=4.0, random_state=0)
reg = LassoLarsCV(cv=5).fit(X, y)
reg.score(X, y)
0.9992...
reg.alpha_
0.0484...
reg.predict(X[:1,])
array([-77.8723...])</p>
</blockquote>
</blockquote>
</blockquote>
<h2 id="notes_18">Notes<a class="headerlink" href="#notes_18" title="Permanent link">&para;</a></h2>
<p>The object solves the same problem as the LassoCV object. However,
unlike the LassoCV, it find the relevant alphas values by itself.
In general, because of this property, it will be more stable.
However, it is more fragile to heavily multicollinear datasets.</p>
<p>It is more efficient than the LassoCV if only a small number of
features are selected compared to the total number, for instance if
there are very few samples compared to the number of features.</p>
<h2 id="see-also_7">See also<a class="headerlink" href="#see-also_7" title="Permanent link">&para;</a></h2>
<p>lars_path, LassoLars, LarsCV, LassoCV</p>
<div class="highlight"><pre><span></span><code><span class="k">val</span> <span class="n">fit</span> <span class="o">:</span> <span class="n">x</span><span class="o">:[&gt;`</span><span class="nc">ArrayLike</span><span class="o">]</span> <span class="nn">Np</span><span class="p">.</span><span class="nn">Obj</span><span class="p">.</span><span class="n">t</span> <span class="o">-&gt;</span> <span class="n">y</span><span class="o">:[&gt;`</span><span class="nc">ArrayLike</span><span class="o">]</span> <span class="nn">Np</span><span class="p">.</span><span class="nn">Obj</span><span class="p">.</span><span class="n">t</span> <span class="o">-&gt;</span> <span class="o">[&gt;</span> <span class="n">tag</span><span class="o">]</span> <span class="nn">Obj</span><span class="p">.</span><span class="n">t</span> <span class="o">-&gt;</span> <span class="n">t</span>
</code></pre></div>

<p>Fit the model using X, y as training data.</p>
<h2 id="parameters_61">Parameters<a class="headerlink" href="#parameters_61" title="Permanent link">&para;</a></h2>
<p>X : array-like of shape (n_samples, n_features)
Training data.</p>
<p>y : array-like of shape (n_samples,)
Target values.</p>
<h2 id="returns_46">Returns<a class="headerlink" href="#returns_46" title="Permanent link">&para;</a></h2>
<p>self : object
returns an instance of self.</p>
<div class="highlight"><pre><span></span><code><span class="k">val</span> <span class="n">get_params</span> <span class="o">:</span> <span class="o">?</span><span class="n">deep</span><span class="o">:</span><span class="kt">bool</span> <span class="o">-&gt;</span> <span class="o">[&gt;</span> <span class="n">tag</span><span class="o">]</span> <span class="nn">Obj</span><span class="p">.</span><span class="n">t</span> <span class="o">-&gt;</span> <span class="nn">Dict</span><span class="p">.</span><span class="n">t</span>
</code></pre></div>

<p>Get parameters for this estimator.</p>
<h2 id="parameters_62">Parameters<a class="headerlink" href="#parameters_62" title="Permanent link">&para;</a></h2>
<p>deep : bool, default=True
If True, will return the parameters for this estimator and
contained subobjects that are estimators.</p>
<h2 id="returns_47">Returns<a class="headerlink" href="#returns_47" title="Permanent link">&para;</a></h2>
<p>params : mapping of string to any
Parameter names mapped to their values.</p>
<div class="highlight"><pre><span></span><code><span class="k">val</span> <span class="n">predict</span> <span class="o">:</span> <span class="n">x</span><span class="o">:[&gt;`</span><span class="nc">ArrayLike</span><span class="o">]</span> <span class="nn">Np</span><span class="p">.</span><span class="nn">Obj</span><span class="p">.</span><span class="n">t</span> <span class="o">-&gt;</span> <span class="o">[&gt;</span> <span class="n">tag</span><span class="o">]</span> <span class="nn">Obj</span><span class="p">.</span><span class="n">t</span> <span class="o">-&gt;</span> <span class="o">[&gt;`</span><span class="nc">ArrayLike</span><span class="o">]</span> <span class="nn">Np</span><span class="p">.</span><span class="nn">Obj</span><span class="p">.</span><span class="n">t</span>
</code></pre></div>

<p>Predict using the linear model.</p>
<h2 id="parameters_63">Parameters<a class="headerlink" href="#parameters_63" title="Permanent link">&para;</a></h2>
<p>X : array_like or sparse matrix, shape (n_samples, n_features)
Samples.</p>
<h2 id="returns_48">Returns<a class="headerlink" href="#returns_48" title="Permanent link">&para;</a></h2>
<p>C : array, shape (n_samples,)
Returns predicted values.</p>
<div class="highlight"><pre><span></span><code><span class="k">val</span> <span class="n">score</span> <span class="o">:</span> <span class="o">?</span><span class="n">sample_weight</span><span class="o">:[&gt;`</span><span class="nc">ArrayLike</span><span class="o">]</span> <span class="nn">Np</span><span class="p">.</span><span class="nn">Obj</span><span class="p">.</span><span class="n">t</span> <span class="o">-&gt;</span> <span class="n">x</span><span class="o">:[&gt;`</span><span class="nc">ArrayLike</span><span class="o">]</span> <span class="nn">Np</span><span class="p">.</span><span class="nn">Obj</span><span class="p">.</span><span class="n">t</span> <span class="o">-&gt;</span> <span class="n">y</span><span class="o">:[&gt;`</span><span class="nc">ArrayLike</span><span class="o">]</span> <span class="nn">Np</span><span class="p">.</span><span class="nn">Obj</span><span class="p">.</span><span class="n">t</span> <span class="o">-&gt;</span> <span class="o">[&gt;</span> <span class="n">tag</span><span class="o">]</span> <span class="nn">Obj</span><span class="p">.</span><span class="n">t</span> <span class="o">-&gt;</span> <span class="kt">float</span>
</code></pre></div>

<p>Return the coefficient of determination R^2 of the prediction.</p>
<p>The coefficient R^2 is defined as (1 - u/v), where u is the residual
sum of squares ((y_true - y_pred) <strong> 2).sum() and v is the total
sum of squares ((y_true - y_true.mean()) </strong> 2).sum().
The best possible score is 1.0 and it can be negative (because the
model can be arbitrarily worse). A constant model that always
predicts the expected value of y, disregarding the input features,
would get a R^2 score of 0.0.</p>
<h2 id="parameters_64">Parameters<a class="headerlink" href="#parameters_64" title="Permanent link">&para;</a></h2>
<p>X : array-like of shape (n_samples, n_features)
Test samples. For some estimators this may be a
precomputed kernel matrix or a list of generic objects instead,
shape = (n_samples, n_samples_fitted),
where n_samples_fitted is the number of
samples used in the fitting for the estimator.</p>
<p>y : array-like of shape (n_samples,) or (n_samples, n_outputs)
True values for X.</p>
<p>sample_weight : array-like of shape (n_samples,), default=None
Sample weights.</p>
<h2 id="returns_49">Returns<a class="headerlink" href="#returns_49" title="Permanent link">&para;</a></h2>
<p>score : float
R^2 of self.predict(X) wrt. y.</p>
<h2 id="notes_19">Notes<a class="headerlink" href="#notes_19" title="Permanent link">&para;</a></h2>
<p>The R2 score used when calling <code>score</code> on a regressor will use
<code>multioutput='uniform_average'</code> from version 0.23 to keep consistent
with :func:<code>~sklearn.metrics.r2_score</code>. This will influence the
<code>score</code> method of all the multioutput regressors (except for
:class:<code>~sklearn.multioutput.MultiOutputRegressor</code>). To specify the
default value manually and avoid the warning, please either call
:func:<code>~sklearn.metrics.r2_score</code> directly or make a custom scorer with
:func:<code>~sklearn.metrics.make_scorer</code> (the built-in scorer <code>'r2'</code> uses
<code>multioutput='uniform_average'</code>).</p>
<div class="highlight"><pre><span></span><code><span class="k">val</span> <span class="n">set_params</span> <span class="o">:</span> <span class="o">?</span><span class="n">params</span><span class="o">:(</span><span class="kt">string</span> <span class="o">*</span> <span class="nn">Py</span><span class="p">.</span><span class="nn">Object</span><span class="p">.</span><span class="n">t</span><span class="o">)</span> <span class="kt">list</span> <span class="o">-&gt;</span> <span class="o">[&gt;</span> <span class="n">tag</span><span class="o">]</span> <span class="nn">Obj</span><span class="p">.</span><span class="n">t</span> <span class="o">-&gt;</span> <span class="n">t</span>
</code></pre></div>

<p>Set the parameters of this estimator.</p>
<p>The method works on simple estimators as well as on nested objects
(such as pipelines). The latter have parameters of the form
<code>&lt;component&gt;__&lt;parameter&gt;</code> so that it's possible to update each
component of a nested object.</p>
<h2 id="parameters_65">Parameters<a class="headerlink" href="#parameters_65" title="Permanent link">&para;</a></h2>
<p>**params : dict
Estimator parameters.</p>
<h2 id="returns_50">Returns<a class="headerlink" href="#returns_50" title="Permanent link">&para;</a></h2>
<p>self : object
Estimator instance.</p>
<p>Attribute coef_: get value or raise Not_found if None.</p>
<div class="highlight"><pre><span></span><code><span class="k">val</span> <span class="n">coef_</span> <span class="o">:</span> <span class="n">t</span> <span class="o">-&gt;</span> <span class="o">[&gt;`</span><span class="nc">ArrayLike</span><span class="o">]</span> <span class="nn">Np</span><span class="p">.</span><span class="nn">Obj</span><span class="p">.</span><span class="n">t</span>
</code></pre></div>

<p>Attribute coef_: get value as an option.</p>
<div class="highlight"><pre><span></span><code><span class="k">val</span> <span class="n">coef_opt</span> <span class="o">:</span> <span class="n">t</span> <span class="o">-&gt;</span> <span class="o">([&gt;`</span><span class="nc">ArrayLike</span><span class="o">]</span> <span class="nn">Np</span><span class="p">.</span><span class="nn">Obj</span><span class="p">.</span><span class="n">t</span><span class="o">)</span> <span class="n">option</span>
</code></pre></div>

<p>Attribute intercept_: get value or raise Not_found if None.</p>
<div class="highlight"><pre><span></span><code><span class="k">val</span> <span class="n">intercept_</span> <span class="o">:</span> <span class="n">t</span> <span class="o">-&gt;</span> <span class="o">[&gt;`</span><span class="nc">ArrayLike</span><span class="o">]</span> <span class="nn">Np</span><span class="p">.</span><span class="nn">Obj</span><span class="p">.</span><span class="n">t</span>
</code></pre></div>

<p>Attribute intercept_: get value as an option.</p>
<div class="highlight"><pre><span></span><code><span class="k">val</span> <span class="n">intercept_opt</span> <span class="o">:</span> <span class="n">t</span> <span class="o">-&gt;</span> <span class="o">([&gt;`</span><span class="nc">ArrayLike</span><span class="o">]</span> <span class="nn">Np</span><span class="p">.</span><span class="nn">Obj</span><span class="p">.</span><span class="n">t</span><span class="o">)</span> <span class="n">option</span>
</code></pre></div>

<p>Attribute coef_path_: get value or raise Not_found if None.</p>
<div class="highlight"><pre><span></span><code><span class="k">val</span> <span class="n">coef_path_</span> <span class="o">:</span> <span class="n">t</span> <span class="o">-&gt;</span> <span class="o">[&gt;`</span><span class="nc">ArrayLike</span><span class="o">]</span> <span class="nn">Np</span><span class="p">.</span><span class="nn">Obj</span><span class="p">.</span><span class="n">t</span>
</code></pre></div>

<p>Attribute coef_path_: get value as an option.</p>
<div class="highlight"><pre><span></span><code><span class="k">val</span> <span class="n">coef_path_opt</span> <span class="o">:</span> <span class="n">t</span> <span class="o">-&gt;</span> <span class="o">([&gt;`</span><span class="nc">ArrayLike</span><span class="o">]</span> <span class="nn">Np</span><span class="p">.</span><span class="nn">Obj</span><span class="p">.</span><span class="n">t</span><span class="o">)</span> <span class="n">option</span>
</code></pre></div>

<p>Attribute alpha_: get value or raise Not_found if None.</p>
<div class="highlight"><pre><span></span><code><span class="k">val</span> <span class="n">alpha_</span> <span class="o">:</span> <span class="n">t</span> <span class="o">-&gt;</span> <span class="kt">float</span>
</code></pre></div>

<p>Attribute alpha_: get value as an option.</p>
<div class="highlight"><pre><span></span><code><span class="k">val</span> <span class="n">alpha_opt</span> <span class="o">:</span> <span class="n">t</span> <span class="o">-&gt;</span> <span class="o">(</span><span class="kt">float</span><span class="o">)</span> <span class="n">option</span>
</code></pre></div>

<p>Attribute alphas_: get value or raise Not_found if None.</p>
<div class="highlight"><pre><span></span><code><span class="k">val</span> <span class="n">alphas_</span> <span class="o">:</span> <span class="n">t</span> <span class="o">-&gt;</span> <span class="o">[&gt;`</span><span class="nc">ArrayLike</span><span class="o">]</span> <span class="nn">Np</span><span class="p">.</span><span class="nn">Obj</span><span class="p">.</span><span class="n">t</span>
</code></pre></div>

<p>Attribute alphas_: get value as an option.</p>
<div class="highlight"><pre><span></span><code><span class="k">val</span> <span class="n">alphas_opt</span> <span class="o">:</span> <span class="n">t</span> <span class="o">-&gt;</span> <span class="o">([&gt;`</span><span class="nc">ArrayLike</span><span class="o">]</span> <span class="nn">Np</span><span class="p">.</span><span class="nn">Obj</span><span class="p">.</span><span class="n">t</span><span class="o">)</span> <span class="n">option</span>
</code></pre></div>

<p>Attribute cv_alphas_: get value or raise Not_found if None.</p>
<div class="highlight"><pre><span></span><code><span class="k">val</span> <span class="n">cv_alphas_</span> <span class="o">:</span> <span class="n">t</span> <span class="o">-&gt;</span> <span class="o">[&gt;`</span><span class="nc">ArrayLike</span><span class="o">]</span> <span class="nn">Np</span><span class="p">.</span><span class="nn">Obj</span><span class="p">.</span><span class="n">t</span>
</code></pre></div>

<p>Attribute cv_alphas_: get value as an option.</p>
<div class="highlight"><pre><span></span><code><span class="k">val</span> <span class="n">cv_alphas_opt</span> <span class="o">:</span> <span class="n">t</span> <span class="o">-&gt;</span> <span class="o">([&gt;`</span><span class="nc">ArrayLike</span><span class="o">]</span> <span class="nn">Np</span><span class="p">.</span><span class="nn">Obj</span><span class="p">.</span><span class="n">t</span><span class="o">)</span> <span class="n">option</span>
</code></pre></div>

<p>Attribute mse_path_: get value or raise Not_found if None.</p>
<div class="highlight"><pre><span></span><code><span class="k">val</span> <span class="n">mse_path_</span> <span class="o">:</span> <span class="n">t</span> <span class="o">-&gt;</span> <span class="o">[&gt;`</span><span class="nc">ArrayLike</span><span class="o">]</span> <span class="nn">Np</span><span class="p">.</span><span class="nn">Obj</span><span class="p">.</span><span class="n">t</span>
</code></pre></div>

<p>Attribute mse_path_: get value as an option.</p>
<div class="highlight"><pre><span></span><code><span class="k">val</span> <span class="n">mse_path_opt</span> <span class="o">:</span> <span class="n">t</span> <span class="o">-&gt;</span> <span class="o">([&gt;`</span><span class="nc">ArrayLike</span><span class="o">]</span> <span class="nn">Np</span><span class="p">.</span><span class="nn">Obj</span><span class="p">.</span><span class="n">t</span><span class="o">)</span> <span class="n">option</span>
</code></pre></div>

<p>Attribute n_iter_: get value or raise Not_found if None.</p>
<div class="highlight"><pre><span></span><code><span class="k">val</span> <span class="n">n_iter_</span> <span class="o">:</span> <span class="n">t</span> <span class="o">-&gt;</span> <span class="nn">Py</span><span class="p">.</span><span class="nn">Object</span><span class="p">.</span><span class="n">t</span>
</code></pre></div>

<p>Attribute n_iter_: get value as an option.</p>
<div class="highlight"><pre><span></span><code><span class="k">val</span> <span class="n">n_iter_opt</span> <span class="o">:</span> <span class="n">t</span> <span class="o">-&gt;</span> <span class="o">(</span><span class="nn">Py</span><span class="p">.</span><span class="nn">Object</span><span class="p">.</span><span class="n">t</span><span class="o">)</span> <span class="n">option</span>
</code></pre></div>

<p>Print the object to a human-readable representation.</p>
<div class="highlight"><pre><span></span><code><span class="k">val</span> <span class="n">to_string</span> <span class="o">:</span> <span class="n">t</span> <span class="o">-&gt;</span> <span class="kt">string</span>
</code></pre></div>

<p>Print the object to a human-readable representation.</p>
<div class="highlight"><pre><span></span><code><span class="k">val</span> <span class="n">show</span> <span class="o">:</span> <span class="n">t</span> <span class="o">-&gt;</span> <span class="kt">string</span>
</code></pre></div>

<p>Pretty-print the object to a formatter.</p>
<div class="highlight"><pre><span></span><code><span class="k">val</span> <span class="n">pp</span> <span class="o">:</span> <span class="nn">Format</span><span class="p">.</span><span class="n">formatter</span> <span class="o">-&gt;</span> <span class="n">t</span> <span class="o">-&gt;</span> <span class="kt">unit</span> <span class="o">[@@</span><span class="n">ocaml</span><span class="o">.</span><span class="n">toplevel_printer</span><span class="o">]</span>



<span class="k">module</span> <span class="nc">LassoLarsIC</span> <span class="o">:</span> <span class="k">sig</span>
<span class="k">type</span> <span class="n">tag</span> <span class="o">=</span> <span class="o">[`</span><span class="nc">LassoLarsIC</span><span class="o">]</span>
<span class="k">type</span> <span class="n">t</span> <span class="o">=</span> <span class="o">[`</span><span class="nc">BaseEstimator</span> <span class="o">|</span> <span class="o">`</span><span class="nc">LassoLarsIC</span> <span class="o">|</span> <span class="o">`</span><span class="nc">MultiOutputMixin</span> <span class="o">|</span> <span class="o">`</span><span class="nc">Object</span> <span class="o">|</span> <span class="o">`</span><span class="nc">RegressorMixin</span><span class="o">]</span> <span class="nn">Obj</span><span class="p">.</span><span class="n">t</span>
<span class="k">val</span> <span class="n">of_pyobject</span> <span class="o">:</span> <span class="nn">Py</span><span class="p">.</span><span class="nn">Object</span><span class="p">.</span><span class="n">t</span> <span class="o">-&gt;</span> <span class="n">t</span>
<span class="k">val</span> <span class="n">to_pyobject</span> <span class="o">:</span> <span class="o">[&gt;</span> <span class="n">tag</span><span class="o">]</span> <span class="nn">Obj</span><span class="p">.</span><span class="n">t</span> <span class="o">-&gt;</span> <span class="nn">Py</span><span class="p">.</span><span class="nn">Object</span><span class="p">.</span><span class="n">t</span>

<span class="k">val</span> <span class="n">as_regressor</span> <span class="o">:</span> <span class="n">t</span> <span class="o">-&gt;</span> <span class="o">[`</span><span class="nc">RegressorMixin</span><span class="o">]</span> <span class="nn">Obj</span><span class="p">.</span><span class="n">t</span>
<span class="k">val</span> <span class="n">as_multi_output</span> <span class="o">:</span> <span class="n">t</span> <span class="o">-&gt;</span> <span class="o">[`</span><span class="nc">MultiOutputMixin</span><span class="o">]</span> <span class="nn">Obj</span><span class="p">.</span><span class="n">t</span>
<span class="k">val</span> <span class="n">as_estimator</span> <span class="o">:</span> <span class="n">t</span> <span class="o">-&gt;</span> <span class="o">[`</span><span class="nc">BaseEstimator</span><span class="o">]</span> <span class="nn">Obj</span><span class="p">.</span><span class="n">t</span>
<span class="k">val</span> <span class="n">create</span> <span class="o">:</span> <span class="o">?</span><span class="n">criterion</span><span class="o">:[`</span><span class="nc">Bic</span> <span class="o">|</span> <span class="o">`</span><span class="nc">Aic</span><span class="o">]</span> <span class="o">-&gt;</span> <span class="o">?</span><span class="n">fit_intercept</span><span class="o">:</span><span class="kt">bool</span> <span class="o">-&gt;</span> <span class="o">?</span><span class="n">verbose</span><span class="o">:</span><span class="kt">int</span> <span class="o">-&gt;</span> <span class="o">?</span><span class="n">normalize</span><span class="o">:</span><span class="kt">bool</span> <span class="o">-&gt;</span> <span class="o">?</span><span class="n">precompute</span><span class="o">:[`</span><span class="nc">Arr</span> <span class="k">of</span> <span class="o">[&gt;`</span><span class="nc">ArrayLike</span><span class="o">]</span> <span class="nn">Np</span><span class="p">.</span><span class="nn">Obj</span><span class="p">.</span><span class="n">t</span> <span class="o">|</span> <span class="o">`</span><span class="nc">Auto</span> <span class="o">|</span> <span class="o">`</span><span class="nc">Bool</span> <span class="k">of</span> <span class="kt">bool</span><span class="o">]</span> <span class="o">-&gt;</span> <span class="o">?</span><span class="n">max_iter</span><span class="o">:</span><span class="kt">int</span> <span class="o">-&gt;</span> <span class="o">?</span><span class="n">eps</span><span class="o">:</span><span class="kt">float</span> <span class="o">-&gt;</span> <span class="o">?</span><span class="n">copy_X</span><span class="o">:</span><span class="kt">bool</span> <span class="o">-&gt;</span> <span class="o">?</span><span class="n">positive</span><span class="o">:</span><span class="kt">bool</span> <span class="o">-&gt;</span> <span class="kt">unit</span> <span class="o">-&gt;</span> <span class="n">t</span>
</code></pre></div>

<p>Lasso model fit with Lars using BIC or AIC for model selection</p>
<p>The optimization objective for Lasso is::</p>
<p>(1 / (2 * n_samples)) * ||y - Xw||^2_2 + alpha * ||w||_1</p>
<p>AIC is the Akaike information criterion and BIC is the Bayes
Information criterion. Such criteria are useful to select the value
of the regularization parameter by making a trade-off between the
goodness of fit and the complexity of the model. A good model should
explain well the data while being simple.</p>
<p>Read more in the :ref:<code>User Guide &lt;least_angle_regression&gt;</code>.</p>
<h2 id="parameters_66">Parameters<a class="headerlink" href="#parameters_66" title="Permanent link">&para;</a></h2>
<p>criterion : {'bic' , 'aic'}, default='aic'
The type of criterion to use.</p>
<p>fit_intercept : bool, default=True
whether to calculate the intercept for this model. If set
to false, no intercept will be used in calculations
(i.e. data is expected to be centered).</p>
<p>verbose : bool or int, default=False
Sets the verbosity amount</p>
<p>normalize : bool, default=True
This parameter is ignored when <code>fit_intercept</code> is set to False.
If True, the regressors X will be normalized before regression by
subtracting the mean and dividing by the l2-norm.
If you wish to standardize, please use
:class:<code>sklearn.preprocessing.StandardScaler</code> before calling <code>fit</code>
on an estimator with <code>normalize=False</code>.</p>
<p>precompute : bool, 'auto' or array-like, default='auto'
Whether to use a precomputed Gram matrix to speed up
calculations. If set to <code>'auto'</code> let us decide. The Gram
matrix can also be passed as argument.</p>
<p>max_iter : int, default=500
Maximum number of iterations to perform. Can be used for
early stopping.</p>
<p>eps : float, optional
The machine-precision regularization in the computation of the
Cholesky diagonal factors. Increase this for very ill-conditioned
systems. Unlike the <code>tol</code> parameter in some iterative
optimization-based algorithms, this parameter does not control
the tolerance of the optimization.
By default, <code>np.finfo(np.float).eps</code> is used</p>
<p>copy_X : bool, default=True
If True, X will be copied; else, it may be overwritten.</p>
<p>positive : bool, default=False
Restrict coefficients to be &gt;= 0. Be aware that you might want to
remove fit_intercept which is set True by default.
Under the positive restriction the model coefficients do not converge
to the ordinary-least-squares solution for small values of alpha.
Only coefficients up to the smallest alpha value (<code>alphas_[alphas_ &gt;
0.].min()</code> when fit_path=True) reached by the stepwise Lars-Lasso
algorithm are typically in congruence with the solution of the
coordinate descent Lasso estimator.
As a consequence using LassoLarsIC only makes sense for problems where
a sparse solution is expected and/or reached.</p>
<h2 id="attributes_11">Attributes<a class="headerlink" href="#attributes_11" title="Permanent link">&para;</a></h2>
<p>coef_ : array-like of shape (n_features,)
parameter vector (w in the formulation formula)</p>
<p>intercept_ : float
independent term in decision function.</p>
<p>alpha_ : float
the alpha parameter chosen by the information criterion</p>
<p>n_iter_ : int
number of iterations run by lars_path to find the grid of
alphas.</p>
<p>criterion_ : array-like of shape (n_alphas,)
The value of the information criteria ('aic', 'bic') across all
alphas. The alpha which has the smallest information criterion is
chosen. This value is larger by a factor of <code>n_samples</code> compared to
Eqns. 2.15 and 2.16 in (Zou et al, 2007).</p>
<h2 id="examples_11">Examples<a class="headerlink" href="#examples_11" title="Permanent link">&para;</a></h2>
<blockquote>
<blockquote>
<blockquote>
<p>from sklearn import linear_model
reg = linear_model.LassoLarsIC(criterion='bic')
reg.fit([[-1, 1], [0, 0], [1, 1]], [-1.1111, 0, -1.1111])
LassoLarsIC(criterion='bic')
print(reg.coef_)
[ 0.  -1.11...]</p>
</blockquote>
</blockquote>
</blockquote>
<h2 id="notes_20">Notes<a class="headerlink" href="#notes_20" title="Permanent link">&para;</a></h2>
<p>The estimation of the number of degrees of freedom is given by:</p>
<p>'On the degrees of freedom of the lasso'
Hui Zou, Trevor Hastie, and Robert Tibshirani
Ann. Statist. Volume 35, Number 5 (2007), 2173-2192.</p>
<p>https://en.wikipedia.org/wiki/Akaike_information_criterion
https://en.wikipedia.org/wiki/Bayesian_information_criterion</p>
<h2 id="see-also_8">See also<a class="headerlink" href="#see-also_8" title="Permanent link">&para;</a></h2>
<p>lars_path, LassoLars, LassoLarsCV</p>
<div class="highlight"><pre><span></span><code><span class="k">val</span> <span class="n">fit</span> <span class="o">:</span> <span class="o">?</span><span class="n">copy_X</span><span class="o">:</span><span class="kt">bool</span> <span class="o">-&gt;</span> <span class="n">x</span><span class="o">:[&gt;`</span><span class="nc">ArrayLike</span><span class="o">]</span> <span class="nn">Np</span><span class="p">.</span><span class="nn">Obj</span><span class="p">.</span><span class="n">t</span> <span class="o">-&gt;</span> <span class="n">y</span><span class="o">:[&gt;`</span><span class="nc">ArrayLike</span><span class="o">]</span> <span class="nn">Np</span><span class="p">.</span><span class="nn">Obj</span><span class="p">.</span><span class="n">t</span> <span class="o">-&gt;</span> <span class="o">[&gt;</span> <span class="n">tag</span><span class="o">]</span> <span class="nn">Obj</span><span class="p">.</span><span class="n">t</span> <span class="o">-&gt;</span> <span class="n">t</span>
</code></pre></div>

<p>Fit the model using X, y as training data.</p>
<h2 id="parameters_67">Parameters<a class="headerlink" href="#parameters_67" title="Permanent link">&para;</a></h2>
<p>X : array-like of shape (n_samples, n_features)
training data.</p>
<p>y : array-like of shape (n_samples,)
target values. Will be cast to X's dtype if necessary</p>
<p>copy_X : bool, default=None
If provided, this parameter will override the choice
of copy_X made at instance creation.
If <code>True</code>, X will be copied; else, it may be overwritten.</p>
<h2 id="returns_51">Returns<a class="headerlink" href="#returns_51" title="Permanent link">&para;</a></h2>
<p>self : object
returns an instance of self.</p>
<div class="highlight"><pre><span></span><code><span class="k">val</span> <span class="n">get_params</span> <span class="o">:</span> <span class="o">?</span><span class="n">deep</span><span class="o">:</span><span class="kt">bool</span> <span class="o">-&gt;</span> <span class="o">[&gt;</span> <span class="n">tag</span><span class="o">]</span> <span class="nn">Obj</span><span class="p">.</span><span class="n">t</span> <span class="o">-&gt;</span> <span class="nn">Dict</span><span class="p">.</span><span class="n">t</span>
</code></pre></div>

<p>Get parameters for this estimator.</p>
<h2 id="parameters_68">Parameters<a class="headerlink" href="#parameters_68" title="Permanent link">&para;</a></h2>
<p>deep : bool, default=True
If True, will return the parameters for this estimator and
contained subobjects that are estimators.</p>
<h2 id="returns_52">Returns<a class="headerlink" href="#returns_52" title="Permanent link">&para;</a></h2>
<p>params : mapping of string to any
Parameter names mapped to their values.</p>
<div class="highlight"><pre><span></span><code><span class="k">val</span> <span class="n">predict</span> <span class="o">:</span> <span class="n">x</span><span class="o">:[&gt;`</span><span class="nc">ArrayLike</span><span class="o">]</span> <span class="nn">Np</span><span class="p">.</span><span class="nn">Obj</span><span class="p">.</span><span class="n">t</span> <span class="o">-&gt;</span> <span class="o">[&gt;</span> <span class="n">tag</span><span class="o">]</span> <span class="nn">Obj</span><span class="p">.</span><span class="n">t</span> <span class="o">-&gt;</span> <span class="o">[&gt;`</span><span class="nc">ArrayLike</span><span class="o">]</span> <span class="nn">Np</span><span class="p">.</span><span class="nn">Obj</span><span class="p">.</span><span class="n">t</span>
</code></pre></div>

<p>Predict using the linear model.</p>
<h2 id="parameters_69">Parameters<a class="headerlink" href="#parameters_69" title="Permanent link">&para;</a></h2>
<p>X : array_like or sparse matrix, shape (n_samples, n_features)
Samples.</p>
<h2 id="returns_53">Returns<a class="headerlink" href="#returns_53" title="Permanent link">&para;</a></h2>
<p>C : array, shape (n_samples,)
Returns predicted values.</p>
<div class="highlight"><pre><span></span><code><span class="k">val</span> <span class="n">score</span> <span class="o">:</span> <span class="o">?</span><span class="n">sample_weight</span><span class="o">:[&gt;`</span><span class="nc">ArrayLike</span><span class="o">]</span> <span class="nn">Np</span><span class="p">.</span><span class="nn">Obj</span><span class="p">.</span><span class="n">t</span> <span class="o">-&gt;</span> <span class="n">x</span><span class="o">:[&gt;`</span><span class="nc">ArrayLike</span><span class="o">]</span> <span class="nn">Np</span><span class="p">.</span><span class="nn">Obj</span><span class="p">.</span><span class="n">t</span> <span class="o">-&gt;</span> <span class="n">y</span><span class="o">:[&gt;`</span><span class="nc">ArrayLike</span><span class="o">]</span> <span class="nn">Np</span><span class="p">.</span><span class="nn">Obj</span><span class="p">.</span><span class="n">t</span> <span class="o">-&gt;</span> <span class="o">[&gt;</span> <span class="n">tag</span><span class="o">]</span> <span class="nn">Obj</span><span class="p">.</span><span class="n">t</span> <span class="o">-&gt;</span> <span class="kt">float</span>
</code></pre></div>

<p>Return the coefficient of determination R^2 of the prediction.</p>
<p>The coefficient R^2 is defined as (1 - u/v), where u is the residual
sum of squares ((y_true - y_pred) <strong> 2).sum() and v is the total
sum of squares ((y_true - y_true.mean()) </strong> 2).sum().
The best possible score is 1.0 and it can be negative (because the
model can be arbitrarily worse). A constant model that always
predicts the expected value of y, disregarding the input features,
would get a R^2 score of 0.0.</p>
<h2 id="parameters_70">Parameters<a class="headerlink" href="#parameters_70" title="Permanent link">&para;</a></h2>
<p>X : array-like of shape (n_samples, n_features)
Test samples. For some estimators this may be a
precomputed kernel matrix or a list of generic objects instead,
shape = (n_samples, n_samples_fitted),
where n_samples_fitted is the number of
samples used in the fitting for the estimator.</p>
<p>y : array-like of shape (n_samples,) or (n_samples, n_outputs)
True values for X.</p>
<p>sample_weight : array-like of shape (n_samples,), default=None
Sample weights.</p>
<h2 id="returns_54">Returns<a class="headerlink" href="#returns_54" title="Permanent link">&para;</a></h2>
<p>score : float
R^2 of self.predict(X) wrt. y.</p>
<h2 id="notes_21">Notes<a class="headerlink" href="#notes_21" title="Permanent link">&para;</a></h2>
<p>The R2 score used when calling <code>score</code> on a regressor will use
<code>multioutput='uniform_average'</code> from version 0.23 to keep consistent
with :func:<code>~sklearn.metrics.r2_score</code>. This will influence the
<code>score</code> method of all the multioutput regressors (except for
:class:<code>~sklearn.multioutput.MultiOutputRegressor</code>). To specify the
default value manually and avoid the warning, please either call
:func:<code>~sklearn.metrics.r2_score</code> directly or make a custom scorer with
:func:<code>~sklearn.metrics.make_scorer</code> (the built-in scorer <code>'r2'</code> uses
<code>multioutput='uniform_average'</code>).</p>
<div class="highlight"><pre><span></span><code><span class="k">val</span> <span class="n">set_params</span> <span class="o">:</span> <span class="o">?</span><span class="n">params</span><span class="o">:(</span><span class="kt">string</span> <span class="o">*</span> <span class="nn">Py</span><span class="p">.</span><span class="nn">Object</span><span class="p">.</span><span class="n">t</span><span class="o">)</span> <span class="kt">list</span> <span class="o">-&gt;</span> <span class="o">[&gt;</span> <span class="n">tag</span><span class="o">]</span> <span class="nn">Obj</span><span class="p">.</span><span class="n">t</span> <span class="o">-&gt;</span> <span class="n">t</span>
</code></pre></div>

<p>Set the parameters of this estimator.</p>
<p>The method works on simple estimators as well as on nested objects
(such as pipelines). The latter have parameters of the form
<code>&lt;component&gt;__&lt;parameter&gt;</code> so that it's possible to update each
component of a nested object.</p>
<h2 id="parameters_71">Parameters<a class="headerlink" href="#parameters_71" title="Permanent link">&para;</a></h2>
<p>**params : dict
Estimator parameters.</p>
<h2 id="returns_55">Returns<a class="headerlink" href="#returns_55" title="Permanent link">&para;</a></h2>
<p>self : object
Estimator instance.</p>
<p>Attribute coef_: get value or raise Not_found if None.</p>
<div class="highlight"><pre><span></span><code><span class="k">val</span> <span class="n">coef_</span> <span class="o">:</span> <span class="n">t</span> <span class="o">-&gt;</span> <span class="o">[&gt;`</span><span class="nc">ArrayLike</span><span class="o">]</span> <span class="nn">Np</span><span class="p">.</span><span class="nn">Obj</span><span class="p">.</span><span class="n">t</span>
</code></pre></div>

<p>Attribute coef_: get value as an option.</p>
<div class="highlight"><pre><span></span><code><span class="k">val</span> <span class="n">coef_opt</span> <span class="o">:</span> <span class="n">t</span> <span class="o">-&gt;</span> <span class="o">([&gt;`</span><span class="nc">ArrayLike</span><span class="o">]</span> <span class="nn">Np</span><span class="p">.</span><span class="nn">Obj</span><span class="p">.</span><span class="n">t</span><span class="o">)</span> <span class="n">option</span>
</code></pre></div>

<p>Attribute intercept_: get value or raise Not_found if None.</p>
<div class="highlight"><pre><span></span><code><span class="k">val</span> <span class="n">intercept_</span> <span class="o">:</span> <span class="n">t</span> <span class="o">-&gt;</span> <span class="o">[&gt;`</span><span class="nc">ArrayLike</span><span class="o">]</span> <span class="nn">Np</span><span class="p">.</span><span class="nn">Obj</span><span class="p">.</span><span class="n">t</span>
</code></pre></div>

<p>Attribute intercept_: get value as an option.</p>
<div class="highlight"><pre><span></span><code><span class="k">val</span> <span class="n">intercept_opt</span> <span class="o">:</span> <span class="n">t</span> <span class="o">-&gt;</span> <span class="o">([&gt;`</span><span class="nc">ArrayLike</span><span class="o">]</span> <span class="nn">Np</span><span class="p">.</span><span class="nn">Obj</span><span class="p">.</span><span class="n">t</span><span class="o">)</span> <span class="n">option</span>
</code></pre></div>

<p>Attribute alpha_: get value or raise Not_found if None.</p>
<div class="highlight"><pre><span></span><code><span class="k">val</span> <span class="n">alpha_</span> <span class="o">:</span> <span class="n">t</span> <span class="o">-&gt;</span> <span class="kt">float</span>
</code></pre></div>

<p>Attribute alpha_: get value as an option.</p>
<div class="highlight"><pre><span></span><code><span class="k">val</span> <span class="n">alpha_opt</span> <span class="o">:</span> <span class="n">t</span> <span class="o">-&gt;</span> <span class="o">(</span><span class="kt">float</span><span class="o">)</span> <span class="n">option</span>
</code></pre></div>

<p>Attribute n_iter_: get value or raise Not_found if None.</p>
<div class="highlight"><pre><span></span><code><span class="k">val</span> <span class="n">n_iter_</span> <span class="o">:</span> <span class="n">t</span> <span class="o">-&gt;</span> <span class="kt">int</span>
</code></pre></div>

<p>Attribute n_iter_: get value as an option.</p>
<div class="highlight"><pre><span></span><code><span class="k">val</span> <span class="n">n_iter_opt</span> <span class="o">:</span> <span class="n">t</span> <span class="o">-&gt;</span> <span class="o">(</span><span class="kt">int</span><span class="o">)</span> <span class="n">option</span>
</code></pre></div>

<p>Attribute criterion_: get value or raise Not_found if None.</p>
<div class="highlight"><pre><span></span><code><span class="k">val</span> <span class="n">criterion_</span> <span class="o">:</span> <span class="n">t</span> <span class="o">-&gt;</span> <span class="o">[&gt;`</span><span class="nc">ArrayLike</span><span class="o">]</span> <span class="nn">Np</span><span class="p">.</span><span class="nn">Obj</span><span class="p">.</span><span class="n">t</span>
</code></pre></div>

<p>Attribute criterion_: get value as an option.</p>
<div class="highlight"><pre><span></span><code><span class="k">val</span> <span class="n">criterion_opt</span> <span class="o">:</span> <span class="n">t</span> <span class="o">-&gt;</span> <span class="o">([&gt;`</span><span class="nc">ArrayLike</span><span class="o">]</span> <span class="nn">Np</span><span class="p">.</span><span class="nn">Obj</span><span class="p">.</span><span class="n">t</span><span class="o">)</span> <span class="n">option</span>
</code></pre></div>

<p>Print the object to a human-readable representation.</p>
<div class="highlight"><pre><span></span><code><span class="k">val</span> <span class="n">to_string</span> <span class="o">:</span> <span class="n">t</span> <span class="o">-&gt;</span> <span class="kt">string</span>
</code></pre></div>

<p>Print the object to a human-readable representation.</p>
<div class="highlight"><pre><span></span><code><span class="k">val</span> <span class="n">show</span> <span class="o">:</span> <span class="n">t</span> <span class="o">-&gt;</span> <span class="kt">string</span>
</code></pre></div>

<p>Pretty-print the object to a formatter.</p>
<div class="highlight"><pre><span></span><code><span class="k">val</span> <span class="n">pp</span> <span class="o">:</span> <span class="nn">Format</span><span class="p">.</span><span class="n">formatter</span> <span class="o">-&gt;</span> <span class="n">t</span> <span class="o">-&gt;</span> <span class="kt">unit</span> <span class="o">[@@</span><span class="n">ocaml</span><span class="o">.</span><span class="n">toplevel_printer</span><span class="o">]</span>



<span class="k">module</span> <span class="nc">LinearRegression</span> <span class="o">:</span> <span class="k">sig</span>
<span class="k">type</span> <span class="n">tag</span> <span class="o">=</span> <span class="o">[`</span><span class="nc">LinearRegression</span><span class="o">]</span>
<span class="k">type</span> <span class="n">t</span> <span class="o">=</span> <span class="o">[`</span><span class="nc">BaseEstimator</span> <span class="o">|</span> <span class="o">`</span><span class="nc">LinearRegression</span> <span class="o">|</span> <span class="o">`</span><span class="nc">MultiOutputMixin</span> <span class="o">|</span> <span class="o">`</span><span class="nc">Object</span> <span class="o">|</span> <span class="o">`</span><span class="nc">RegressorMixin</span><span class="o">]</span> <span class="nn">Obj</span><span class="p">.</span><span class="n">t</span>
<span class="k">val</span> <span class="n">of_pyobject</span> <span class="o">:</span> <span class="nn">Py</span><span class="p">.</span><span class="nn">Object</span><span class="p">.</span><span class="n">t</span> <span class="o">-&gt;</span> <span class="n">t</span>
<span class="k">val</span> <span class="n">to_pyobject</span> <span class="o">:</span> <span class="o">[&gt;</span> <span class="n">tag</span><span class="o">]</span> <span class="nn">Obj</span><span class="p">.</span><span class="n">t</span> <span class="o">-&gt;</span> <span class="nn">Py</span><span class="p">.</span><span class="nn">Object</span><span class="p">.</span><span class="n">t</span>

<span class="k">val</span> <span class="n">as_regressor</span> <span class="o">:</span> <span class="n">t</span> <span class="o">-&gt;</span> <span class="o">[`</span><span class="nc">RegressorMixin</span><span class="o">]</span> <span class="nn">Obj</span><span class="p">.</span><span class="n">t</span>
<span class="k">val</span> <span class="n">as_multi_output</span> <span class="o">:</span> <span class="n">t</span> <span class="o">-&gt;</span> <span class="o">[`</span><span class="nc">MultiOutputMixin</span><span class="o">]</span> <span class="nn">Obj</span><span class="p">.</span><span class="n">t</span>
<span class="k">val</span> <span class="n">as_estimator</span> <span class="o">:</span> <span class="n">t</span> <span class="o">-&gt;</span> <span class="o">[`</span><span class="nc">BaseEstimator</span><span class="o">]</span> <span class="nn">Obj</span><span class="p">.</span><span class="n">t</span>
<span class="k">val</span> <span class="n">create</span> <span class="o">:</span> <span class="o">?</span><span class="n">fit_intercept</span><span class="o">:</span><span class="kt">bool</span> <span class="o">-&gt;</span> <span class="o">?</span><span class="n">normalize</span><span class="o">:</span><span class="kt">bool</span> <span class="o">-&gt;</span> <span class="o">?</span><span class="n">copy_X</span><span class="o">:</span><span class="kt">bool</span> <span class="o">-&gt;</span> <span class="o">?</span><span class="n">n_jobs</span><span class="o">:</span><span class="kt">int</span> <span class="o">-&gt;</span> <span class="kt">unit</span> <span class="o">-&gt;</span> <span class="n">t</span>
</code></pre></div>

<p>Ordinary least squares Linear Regression.</p>
<p>LinearRegression fits a linear model with coefficients w = (w1, ..., wp)
to minimize the residual sum of squares between the observed targets in
the dataset, and the targets predicted by the linear approximation.</p>
<h2 id="parameters_72">Parameters<a class="headerlink" href="#parameters_72" title="Permanent link">&para;</a></h2>
<p>fit_intercept : bool, optional, default True
Whether to calculate the intercept for this model. If set
to False, no intercept will be used in calculations
(i.e. data is expected to be centered).</p>
<p>normalize : bool, optional, default False
This parameter is ignored when <code>fit_intercept</code> is set to False.
If True, the regressors X will be normalized before regression by
subtracting the mean and dividing by the l2-norm.
If you wish to standardize, please use
:class:<code>sklearn.preprocessing.StandardScaler</code> before calling <code>fit</code> on
an estimator with <code>normalize=False</code>.</p>
<p>copy_X : bool, optional, default True
If True, X will be copied; else, it may be overwritten.</p>
<p>n_jobs : int or None, optional (default=None)
The number of jobs to use for the computation. This will only provide
speedup for n_targets &gt; 1 and sufficient large problems.
<code>None</code> means 1 unless in a :obj:<code>joblib.parallel_backend</code> context.
<code>-1</code> means using all processors. See :term:<code>Glossary &lt;n_jobs&gt;</code>
for more details.</p>
<h2 id="attributes_12">Attributes<a class="headerlink" href="#attributes_12" title="Permanent link">&para;</a></h2>
<p>coef_ : array of shape (n_features, ) or (n_targets, n_features)
Estimated coefficients for the linear regression problem.
If multiple targets are passed during the fit (y 2D), this
is a 2D array of shape (n_targets, n_features), while if only
one target is passed, this is a 1D array of length n_features.</p>
<p>rank_ : int
Rank of matrix <code>X</code>. Only available when <code>X</code> is dense.</p>
<p>singular_ : array of shape (min(X, y),)
Singular values of <code>X</code>. Only available when <code>X</code> is dense.</p>
<p>intercept_ : float or array of shape of (n_targets,)
Independent term in the linear model. Set to 0.0 if
<code>fit_intercept = False</code>.</p>
<h2 id="see-also_9">See Also<a class="headerlink" href="#see-also_9" title="Permanent link">&para;</a></h2>
<p>sklearn.linear_model.Ridge : Ridge regression addresses some of the
problems of Ordinary Least Squares by imposing a penalty on the
size of the coefficients with l2 regularization.
sklearn.linear_model.Lasso : The Lasso is a linear model that estimates
sparse coefficients with l1 regularization.
sklearn.linear_model.ElasticNet : Elastic-Net is a linear regression
model trained with both l1 and l2 -norm regularization of the
coefficients.</p>
<h2 id="notes_22">Notes<a class="headerlink" href="#notes_22" title="Permanent link">&para;</a></h2>
<p>From the implementation point of view, this is just plain Ordinary
Least Squares (scipy.linalg.lstsq) wrapped as a predictor object.</p>
<h2 id="examples_12">Examples<a class="headerlink" href="#examples_12" title="Permanent link">&para;</a></h2>
<blockquote>
<blockquote>
<blockquote>
<p>import numpy as np
from sklearn.linear_model import LinearRegression
X = np.array([[1, 1], [1, 2], [2, 2], [2, 3]])</p>
<h1 id="y-1-x_0-2-x_1-3">y = 1 * x_0 + 2 * x_1 + 3<a class="headerlink" href="#y-1-x_0-2-x_1-3" title="Permanent link">&para;</a></h1>
<p>y = np.dot(X, np.array([1, 2])) + 3
reg = LinearRegression().fit(X, y)
reg.score(X, y)
1.0
reg.coef_
array([1., 2.])
reg.intercept_
3.0000...
reg.predict(np.array([[3, 5]]))
array([16.])</p>
</blockquote>
</blockquote>
</blockquote>
<div class="highlight"><pre><span></span><code><span class="k">val</span> <span class="n">fit</span> <span class="o">:</span> <span class="o">?</span><span class="n">sample_weight</span><span class="o">:[&gt;`</span><span class="nc">ArrayLike</span><span class="o">]</span> <span class="nn">Np</span><span class="p">.</span><span class="nn">Obj</span><span class="p">.</span><span class="n">t</span> <span class="o">-&gt;</span> <span class="n">x</span><span class="o">:[&gt;`</span><span class="nc">ArrayLike</span><span class="o">]</span> <span class="nn">Np</span><span class="p">.</span><span class="nn">Obj</span><span class="p">.</span><span class="n">t</span> <span class="o">-&gt;</span> <span class="n">y</span><span class="o">:[&gt;`</span><span class="nc">ArrayLike</span><span class="o">]</span> <span class="nn">Np</span><span class="p">.</span><span class="nn">Obj</span><span class="p">.</span><span class="n">t</span> <span class="o">-&gt;</span> <span class="o">[&gt;</span> <span class="n">tag</span><span class="o">]</span> <span class="nn">Obj</span><span class="p">.</span><span class="n">t</span> <span class="o">-&gt;</span> <span class="n">t</span>
</code></pre></div>

<p>Fit linear model.</p>
<h2 id="parameters_73">Parameters<a class="headerlink" href="#parameters_73" title="Permanent link">&para;</a></h2>
<p>X : {array-like, sparse matrix} of shape (n_samples, n_features)
Training data</p>
<p>y : array-like of shape (n_samples,) or (n_samples, n_targets)
Target values. Will be cast to X's dtype if necessary</p>
<p>sample_weight : array-like of shape (n_samples,), default=None
Individual weights for each sample</p>
<p>.. versionadded:: 0.17
parameter <em>sample_weight</em> support to LinearRegression.</p>
<h2 id="returns_56">Returns<a class="headerlink" href="#returns_56" title="Permanent link">&para;</a></h2>
<p>self : returns an instance of self.</p>
<div class="highlight"><pre><span></span><code><span class="k">val</span> <span class="n">get_params</span> <span class="o">:</span> <span class="o">?</span><span class="n">deep</span><span class="o">:</span><span class="kt">bool</span> <span class="o">-&gt;</span> <span class="o">[&gt;</span> <span class="n">tag</span><span class="o">]</span> <span class="nn">Obj</span><span class="p">.</span><span class="n">t</span> <span class="o">-&gt;</span> <span class="nn">Dict</span><span class="p">.</span><span class="n">t</span>
</code></pre></div>

<p>Get parameters for this estimator.</p>
<h2 id="parameters_74">Parameters<a class="headerlink" href="#parameters_74" title="Permanent link">&para;</a></h2>
<p>deep : bool, default=True
If True, will return the parameters for this estimator and
contained subobjects that are estimators.</p>
<h2 id="returns_57">Returns<a class="headerlink" href="#returns_57" title="Permanent link">&para;</a></h2>
<p>params : mapping of string to any
Parameter names mapped to their values.</p>
<div class="highlight"><pre><span></span><code><span class="k">val</span> <span class="n">predict</span> <span class="o">:</span> <span class="n">x</span><span class="o">:[&gt;`</span><span class="nc">ArrayLike</span><span class="o">]</span> <span class="nn">Np</span><span class="p">.</span><span class="nn">Obj</span><span class="p">.</span><span class="n">t</span> <span class="o">-&gt;</span> <span class="o">[&gt;</span> <span class="n">tag</span><span class="o">]</span> <span class="nn">Obj</span><span class="p">.</span><span class="n">t</span> <span class="o">-&gt;</span> <span class="o">[&gt;`</span><span class="nc">ArrayLike</span><span class="o">]</span> <span class="nn">Np</span><span class="p">.</span><span class="nn">Obj</span><span class="p">.</span><span class="n">t</span>
</code></pre></div>

<p>Predict using the linear model.</p>
<h2 id="parameters_75">Parameters<a class="headerlink" href="#parameters_75" title="Permanent link">&para;</a></h2>
<p>X : array_like or sparse matrix, shape (n_samples, n_features)
Samples.</p>
<h2 id="returns_58">Returns<a class="headerlink" href="#returns_58" title="Permanent link">&para;</a></h2>
<p>C : array, shape (n_samples,)
Returns predicted values.</p>
<div class="highlight"><pre><span></span><code><span class="k">val</span> <span class="n">score</span> <span class="o">:</span> <span class="o">?</span><span class="n">sample_weight</span><span class="o">:[&gt;`</span><span class="nc">ArrayLike</span><span class="o">]</span> <span class="nn">Np</span><span class="p">.</span><span class="nn">Obj</span><span class="p">.</span><span class="n">t</span> <span class="o">-&gt;</span> <span class="n">x</span><span class="o">:[&gt;`</span><span class="nc">ArrayLike</span><span class="o">]</span> <span class="nn">Np</span><span class="p">.</span><span class="nn">Obj</span><span class="p">.</span><span class="n">t</span> <span class="o">-&gt;</span> <span class="n">y</span><span class="o">:[&gt;`</span><span class="nc">ArrayLike</span><span class="o">]</span> <span class="nn">Np</span><span class="p">.</span><span class="nn">Obj</span><span class="p">.</span><span class="n">t</span> <span class="o">-&gt;</span> <span class="o">[&gt;</span> <span class="n">tag</span><span class="o">]</span> <span class="nn">Obj</span><span class="p">.</span><span class="n">t</span> <span class="o">-&gt;</span> <span class="kt">float</span>
</code></pre></div>

<p>Return the coefficient of determination R^2 of the prediction.</p>
<p>The coefficient R^2 is defined as (1 - u/v), where u is the residual
sum of squares ((y_true - y_pred) <strong> 2).sum() and v is the total
sum of squares ((y_true - y_true.mean()) </strong> 2).sum().
The best possible score is 1.0 and it can be negative (because the
model can be arbitrarily worse). A constant model that always
predicts the expected value of y, disregarding the input features,
would get a R^2 score of 0.0.</p>
<h2 id="parameters_76">Parameters<a class="headerlink" href="#parameters_76" title="Permanent link">&para;</a></h2>
<p>X : array-like of shape (n_samples, n_features)
Test samples. For some estimators this may be a
precomputed kernel matrix or a list of generic objects instead,
shape = (n_samples, n_samples_fitted),
where n_samples_fitted is the number of
samples used in the fitting for the estimator.</p>
<p>y : array-like of shape (n_samples,) or (n_samples, n_outputs)
True values for X.</p>
<p>sample_weight : array-like of shape (n_samples,), default=None
Sample weights.</p>
<h2 id="returns_59">Returns<a class="headerlink" href="#returns_59" title="Permanent link">&para;</a></h2>
<p>score : float
R^2 of self.predict(X) wrt. y.</p>
<h2 id="notes_23">Notes<a class="headerlink" href="#notes_23" title="Permanent link">&para;</a></h2>
<p>The R2 score used when calling <code>score</code> on a regressor will use
<code>multioutput='uniform_average'</code> from version 0.23 to keep consistent
with :func:<code>~sklearn.metrics.r2_score</code>. This will influence the
<code>score</code> method of all the multioutput regressors (except for
:class:<code>~sklearn.multioutput.MultiOutputRegressor</code>). To specify the
default value manually and avoid the warning, please either call
:func:<code>~sklearn.metrics.r2_score</code> directly or make a custom scorer with
:func:<code>~sklearn.metrics.make_scorer</code> (the built-in scorer <code>'r2'</code> uses
<code>multioutput='uniform_average'</code>).</p>
<div class="highlight"><pre><span></span><code><span class="k">val</span> <span class="n">set_params</span> <span class="o">:</span> <span class="o">?</span><span class="n">params</span><span class="o">:(</span><span class="kt">string</span> <span class="o">*</span> <span class="nn">Py</span><span class="p">.</span><span class="nn">Object</span><span class="p">.</span><span class="n">t</span><span class="o">)</span> <span class="kt">list</span> <span class="o">-&gt;</span> <span class="o">[&gt;</span> <span class="n">tag</span><span class="o">]</span> <span class="nn">Obj</span><span class="p">.</span><span class="n">t</span> <span class="o">-&gt;</span> <span class="n">t</span>
</code></pre></div>

<p>Set the parameters of this estimator.</p>
<p>The method works on simple estimators as well as on nested objects
(such as pipelines). The latter have parameters of the form
<code>&lt;component&gt;__&lt;parameter&gt;</code> so that it's possible to update each
component of a nested object.</p>
<h2 id="parameters_77">Parameters<a class="headerlink" href="#parameters_77" title="Permanent link">&para;</a></h2>
<p>**params : dict
Estimator parameters.</p>
<h2 id="returns_60">Returns<a class="headerlink" href="#returns_60" title="Permanent link">&para;</a></h2>
<p>self : object
Estimator instance.</p>
<p>Attribute coef_: get value or raise Not_found if None.</p>
<div class="highlight"><pre><span></span><code><span class="k">val</span> <span class="n">coef_</span> <span class="o">:</span> <span class="n">t</span> <span class="o">-&gt;</span> <span class="o">[&gt;`</span><span class="nc">ArrayLike</span><span class="o">]</span> <span class="nn">Np</span><span class="p">.</span><span class="nn">Obj</span><span class="p">.</span><span class="n">t</span>
</code></pre></div>

<p>Attribute coef_: get value as an option.</p>
<div class="highlight"><pre><span></span><code><span class="k">val</span> <span class="n">coef_opt</span> <span class="o">:</span> <span class="n">t</span> <span class="o">-&gt;</span> <span class="o">([&gt;`</span><span class="nc">ArrayLike</span><span class="o">]</span> <span class="nn">Np</span><span class="p">.</span><span class="nn">Obj</span><span class="p">.</span><span class="n">t</span><span class="o">)</span> <span class="n">option</span>
</code></pre></div>

<p>Attribute rank_: get value or raise Not_found if None.</p>
<div class="highlight"><pre><span></span><code><span class="k">val</span> <span class="n">rank_</span> <span class="o">:</span> <span class="n">t</span> <span class="o">-&gt;</span> <span class="kt">int</span>
</code></pre></div>

<p>Attribute rank_: get value as an option.</p>
<div class="highlight"><pre><span></span><code><span class="k">val</span> <span class="n">rank_opt</span> <span class="o">:</span> <span class="n">t</span> <span class="o">-&gt;</span> <span class="o">(</span><span class="kt">int</span><span class="o">)</span> <span class="n">option</span>
</code></pre></div>

<p>Attribute singular_: get value or raise Not_found if None.</p>
<div class="highlight"><pre><span></span><code><span class="k">val</span> <span class="n">singular_</span> <span class="o">:</span> <span class="n">t</span> <span class="o">-&gt;</span> <span class="o">[&gt;`</span><span class="nc">ArrayLike</span><span class="o">]</span> <span class="nn">Np</span><span class="p">.</span><span class="nn">Obj</span><span class="p">.</span><span class="n">t</span>
</code></pre></div>

<p>Attribute singular_: get value as an option.</p>
<div class="highlight"><pre><span></span><code><span class="k">val</span> <span class="n">singular_opt</span> <span class="o">:</span> <span class="n">t</span> <span class="o">-&gt;</span> <span class="o">([&gt;`</span><span class="nc">ArrayLike</span><span class="o">]</span> <span class="nn">Np</span><span class="p">.</span><span class="nn">Obj</span><span class="p">.</span><span class="n">t</span><span class="o">)</span> <span class="n">option</span>
</code></pre></div>

<p>Attribute intercept_: get value or raise Not_found if None.</p>
<div class="highlight"><pre><span></span><code><span class="k">val</span> <span class="n">intercept_</span> <span class="o">:</span> <span class="n">t</span> <span class="o">-&gt;</span> <span class="o">[&gt;`</span><span class="nc">ArrayLike</span><span class="o">]</span> <span class="nn">Np</span><span class="p">.</span><span class="nn">Obj</span><span class="p">.</span><span class="n">t</span>
</code></pre></div>

<p>Attribute intercept_: get value as an option.</p>
<div class="highlight"><pre><span></span><code><span class="k">val</span> <span class="n">intercept_opt</span> <span class="o">:</span> <span class="n">t</span> <span class="o">-&gt;</span> <span class="o">([&gt;`</span><span class="nc">ArrayLike</span><span class="o">]</span> <span class="nn">Np</span><span class="p">.</span><span class="nn">Obj</span><span class="p">.</span><span class="n">t</span><span class="o">)</span> <span class="n">option</span>
</code></pre></div>

<p>Print the object to a human-readable representation.</p>
<div class="highlight"><pre><span></span><code><span class="k">val</span> <span class="n">to_string</span> <span class="o">:</span> <span class="n">t</span> <span class="o">-&gt;</span> <span class="kt">string</span>
</code></pre></div>

<p>Print the object to a human-readable representation.</p>
<div class="highlight"><pre><span></span><code><span class="k">val</span> <span class="n">show</span> <span class="o">:</span> <span class="n">t</span> <span class="o">-&gt;</span> <span class="kt">string</span>
</code></pre></div>

<p>Pretty-print the object to a formatter.</p>
<div class="highlight"><pre><span></span><code><span class="k">val</span> <span class="n">pp</span> <span class="o">:</span> <span class="nn">Format</span><span class="p">.</span><span class="n">formatter</span> <span class="o">-&gt;</span> <span class="n">t</span> <span class="o">-&gt;</span> <span class="kt">unit</span> <span class="o">[@@</span><span class="n">ocaml</span><span class="o">.</span><span class="n">toplevel_printer</span><span class="o">]</span>



<span class="k">module</span> <span class="nc">Log</span> <span class="o">:</span> <span class="k">sig</span>
<span class="k">type</span> <span class="n">tag</span> <span class="o">=</span> <span class="o">[`</span><span class="nc">Log</span><span class="o">]</span>
<span class="k">type</span> <span class="n">t</span> <span class="o">=</span> <span class="o">[`</span><span class="nc">Log</span> <span class="o">|</span> <span class="o">`</span><span class="nc">Object</span><span class="o">]</span> <span class="nn">Obj</span><span class="p">.</span><span class="n">t</span>
<span class="k">val</span> <span class="n">of_pyobject</span> <span class="o">:</span> <span class="nn">Py</span><span class="p">.</span><span class="nn">Object</span><span class="p">.</span><span class="n">t</span> <span class="o">-&gt;</span> <span class="n">t</span>
<span class="k">val</span> <span class="n">to_pyobject</span> <span class="o">:</span> <span class="o">[&gt;</span> <span class="n">tag</span><span class="o">]</span> <span class="nn">Obj</span><span class="p">.</span><span class="n">t</span> <span class="o">-&gt;</span> <span class="nn">Py</span><span class="p">.</span><span class="nn">Object</span><span class="p">.</span><span class="n">t</span>
</code></pre></div>

<p>Print the object to a human-readable representation.</p>
<div class="highlight"><pre><span></span><code><span class="k">val</span> <span class="n">to_string</span> <span class="o">:</span> <span class="n">t</span> <span class="o">-&gt;</span> <span class="kt">string</span>
</code></pre></div>

<p>Print the object to a human-readable representation.</p>
<div class="highlight"><pre><span></span><code><span class="k">val</span> <span class="n">show</span> <span class="o">:</span> <span class="n">t</span> <span class="o">-&gt;</span> <span class="kt">string</span>
</code></pre></div>

<p>Pretty-print the object to a formatter.</p>
<div class="highlight"><pre><span></span><code><span class="k">val</span> <span class="n">pp</span> <span class="o">:</span> <span class="nn">Format</span><span class="p">.</span><span class="n">formatter</span> <span class="o">-&gt;</span> <span class="n">t</span> <span class="o">-&gt;</span> <span class="kt">unit</span> <span class="o">[@@</span><span class="n">ocaml</span><span class="o">.</span><span class="n">toplevel_printer</span><span class="o">]</span>



<span class="k">module</span> <span class="nc">LogisticRegression</span> <span class="o">:</span> <span class="k">sig</span>
<span class="k">type</span> <span class="n">tag</span> <span class="o">=</span> <span class="o">[`</span><span class="nc">LogisticRegression</span><span class="o">]</span>
<span class="k">type</span> <span class="n">t</span> <span class="o">=</span> <span class="o">[`</span><span class="nc">BaseEstimator</span> <span class="o">|</span> <span class="o">`</span><span class="nc">ClassifierMixin</span> <span class="o">|</span> <span class="o">`</span><span class="nc">LinearClassifierMixin</span> <span class="o">|</span> <span class="o">`</span><span class="nc">LogisticRegression</span> <span class="o">|</span> <span class="o">`</span><span class="nc">Object</span> <span class="o">|</span> <span class="o">`</span><span class="nc">SparseCoefMixin</span><span class="o">]</span> <span class="nn">Obj</span><span class="p">.</span><span class="n">t</span>
<span class="k">val</span> <span class="n">of_pyobject</span> <span class="o">:</span> <span class="nn">Py</span><span class="p">.</span><span class="nn">Object</span><span class="p">.</span><span class="n">t</span> <span class="o">-&gt;</span> <span class="n">t</span>
<span class="k">val</span> <span class="n">to_pyobject</span> <span class="o">:</span> <span class="o">[&gt;</span> <span class="n">tag</span><span class="o">]</span> <span class="nn">Obj</span><span class="p">.</span><span class="n">t</span> <span class="o">-&gt;</span> <span class="nn">Py</span><span class="p">.</span><span class="nn">Object</span><span class="p">.</span><span class="n">t</span>

<span class="k">val</span> <span class="n">as_classifier</span> <span class="o">:</span> <span class="n">t</span> <span class="o">-&gt;</span> <span class="o">[`</span><span class="nc">ClassifierMixin</span><span class="o">]</span> <span class="nn">Obj</span><span class="p">.</span><span class="n">t</span>
<span class="k">val</span> <span class="n">as_linear_classifier</span> <span class="o">:</span> <span class="n">t</span> <span class="o">-&gt;</span> <span class="o">[`</span><span class="nc">LinearClassifierMixin</span><span class="o">]</span> <span class="nn">Obj</span><span class="p">.</span><span class="n">t</span>
<span class="k">val</span> <span class="n">as_estimator</span> <span class="o">:</span> <span class="n">t</span> <span class="o">-&gt;</span> <span class="o">[`</span><span class="nc">BaseEstimator</span><span class="o">]</span> <span class="nn">Obj</span><span class="p">.</span><span class="n">t</span>
<span class="k">val</span> <span class="n">as_sparse_coef</span> <span class="o">:</span> <span class="n">t</span> <span class="o">-&gt;</span> <span class="o">[`</span><span class="nc">SparseCoefMixin</span><span class="o">]</span> <span class="nn">Obj</span><span class="p">.</span><span class="n">t</span>
<span class="k">val</span> <span class="n">create</span> <span class="o">:</span> <span class="o">?</span><span class="n">penalty</span><span class="o">:[`</span><span class="nc">L1</span> <span class="o">|</span> <span class="o">`</span><span class="nc">L2</span> <span class="o">|</span> <span class="o">`</span><span class="nc">Elasticnet</span> <span class="o">|</span> <span class="o">`</span><span class="nc">None</span><span class="o">]</span> <span class="o">-&gt;</span> <span class="o">?</span><span class="n">dual</span><span class="o">:</span><span class="kt">bool</span> <span class="o">-&gt;</span> <span class="o">?</span><span class="n">tol</span><span class="o">:</span><span class="kt">float</span> <span class="o">-&gt;</span> <span class="o">?</span><span class="n">c</span><span class="o">:</span><span class="kt">float</span> <span class="o">-&gt;</span> <span class="o">?</span><span class="n">fit_intercept</span><span class="o">:</span><span class="kt">bool</span> <span class="o">-&gt;</span> <span class="o">?</span><span class="n">intercept_scaling</span><span class="o">:</span><span class="kt">float</span> <span class="o">-&gt;</span> <span class="o">?</span><span class="n">class_weight</span><span class="o">:[`</span><span class="nc">DictIntToFloat</span> <span class="k">of</span> <span class="o">(</span><span class="kt">int</span> <span class="o">*</span> <span class="kt">float</span><span class="o">)</span> <span class="kt">list</span> <span class="o">|</span> <span class="o">`</span><span class="nc">Balanced</span><span class="o">]</span> <span class="o">-&gt;</span> <span class="o">?</span><span class="n">random_state</span><span class="o">:</span><span class="kt">int</span> <span class="o">-&gt;</span> <span class="o">?</span><span class="n">solver</span><span class="o">:[`</span><span class="nc">Newton_cg</span> <span class="o">|</span> <span class="o">`</span><span class="nc">Lbfgs</span> <span class="o">|</span> <span class="o">`</span><span class="nc">Liblinear</span> <span class="o">|</span> <span class="o">`</span><span class="nc">Sag</span> <span class="o">|</span> <span class="o">`</span><span class="nc">Saga</span><span class="o">]</span> <span class="o">-&gt;</span> <span class="o">?</span><span class="n">max_iter</span><span class="o">:</span><span class="kt">int</span> <span class="o">-&gt;</span> <span class="o">?</span><span class="n">multi_class</span><span class="o">:[`</span><span class="nc">Auto</span> <span class="o">|</span> <span class="o">`</span><span class="nc">Ovr</span> <span class="o">|</span> <span class="o">`</span><span class="nc">Multinomial</span><span class="o">]</span> <span class="o">-&gt;</span> <span class="o">?</span><span class="n">verbose</span><span class="o">:</span><span class="kt">int</span> <span class="o">-&gt;</span> <span class="o">?</span><span class="n">warm_start</span><span class="o">:</span><span class="kt">bool</span> <span class="o">-&gt;</span> <span class="o">?</span><span class="n">n_jobs</span><span class="o">:</span><span class="kt">int</span> <span class="o">-&gt;</span> <span class="o">?</span><span class="n">l1_ratio</span><span class="o">:</span><span class="kt">float</span> <span class="o">-&gt;</span> <span class="kt">unit</span> <span class="o">-&gt;</span> <span class="n">t</span>
</code></pre></div>

<p>Logistic Regression (aka logit, MaxEnt) classifier.</p>
<p>In the multiclass case, the training algorithm uses the one-vs-rest (OvR)
scheme if the 'multi_class' option is set to 'ovr', and uses the
cross-entropy loss if the 'multi_class' option is set to 'multinomial'.
(Currently the 'multinomial' option is supported only by the 'lbfgs',
'sag', 'saga' and 'newton-cg' solvers.)</p>
<p>This class implements regularized logistic regression using the
'liblinear' library, 'newton-cg', 'sag', 'saga' and 'lbfgs' solvers. <strong>Note
that regularization is applied by default</strong>. It can handle both dense
and sparse input. Use C-ordered arrays or CSR matrices containing 64-bit
floats for optimal performance; any other input format will be converted
(and copied).</p>
<p>The 'newton-cg', 'sag', and 'lbfgs' solvers support only L2 regularization
with primal formulation, or no regularization. The 'liblinear' solver
supports both L1 and L2 regularization, with a dual formulation only for
the L2 penalty. The Elastic-Net regularization is only supported by the
'saga' solver.</p>
<p>Read more in the :ref:<code>User Guide &lt;logistic_regression&gt;</code>.</p>
<h2 id="parameters_78">Parameters<a class="headerlink" href="#parameters_78" title="Permanent link">&para;</a></h2>
<p>penalty : {'l1', 'l2', 'elasticnet', 'none'}, default='l2'
Used to specify the norm used in the penalization. The 'newton-cg',
'sag' and 'lbfgs' solvers support only l2 penalties. 'elasticnet' is
only supported by the 'saga' solver. If 'none' (not supported by the
liblinear solver), no regularization is applied.</p>
<p>.. versionadded:: 0.19
l1 penalty with SAGA solver (allowing 'multinomial' + L1)</p>
<p>dual : bool, default=False
Dual or primal formulation. Dual formulation is only implemented for
l2 penalty with liblinear solver. Prefer dual=False when
n_samples &gt; n_features.</p>
<p>tol : float, default=1e-4
Tolerance for stopping criteria.</p>
<p>C : float, default=1.0
Inverse of regularization strength; must be a positive float.
Like in support vector machines, smaller values specify stronger
regularization.</p>
<p>fit_intercept : bool, default=True
Specifies if a constant (a.k.a. bias or intercept) should be
added to the decision function.</p>
<p>intercept_scaling : float, default=1
Useful only when the solver 'liblinear' is used
and self.fit_intercept is set to True. In this case, x becomes
[x, self.intercept_scaling],
i.e. a 'synthetic' feature with constant value equal to
intercept_scaling is appended to the instance vector.
The intercept becomes <code>intercept_scaling * synthetic_feature_weight</code>.</p>
<p>Note! the synthetic feature weight is subject to l1/l2 regularization
as all other features.
To lessen the effect of regularization on synthetic feature weight
(and therefore on the intercept) intercept_scaling has to be increased.</p>
<p>class_weight : dict or 'balanced', default=None
Weights associated with classes in the form <code>{class_label: weight}</code>.
If not given, all classes are supposed to have weight one.</p>
<p>The 'balanced' mode uses the values of y to automatically adjust
weights inversely proportional to class frequencies in the input data
as <code>n_samples / (n_classes * np.bincount(y))</code>.</p>
<p>Note that these weights will be multiplied with sample_weight (passed
through the fit method) if sample_weight is specified.</p>
<p>.. versionadded:: 0.17
<em>class_weight='balanced'</em></p>
<p>random_state : int, RandomState instance, default=None
The seed of the pseudo random number generator to use when shuffling
the data.  If int, random_state is the seed used by the random number
generator; If RandomState instance, random_state is the random number
generator; If None, the random number generator is the RandomState
instance used by <code>np.random</code>. Used when <code>solver</code> == 'sag' or
'liblinear'.</p>
<p>solver : {'newton-cg', 'lbfgs', 'liblinear', 'sag', 'saga'},             default='lbfgs'</p>
<p>Algorithm to use in the optimization problem.</p>
<ul>
<li>For small datasets, 'liblinear' is a good choice, whereas 'sag' and
'saga' are faster for large ones.</li>
<li>For multiclass problems, only 'newton-cg', 'sag', 'saga' and 'lbfgs'
handle multinomial loss; 'liblinear' is limited to one-versus-rest
schemes.</li>
<li>'newton-cg', 'lbfgs', 'sag' and 'saga' handle L2 or no penalty</li>
<li>'liblinear' and 'saga' also handle L1 penalty</li>
<li>'saga' also supports 'elasticnet' penalty</li>
<li>'liblinear' does not support setting <code>penalty='none'</code></li>
</ul>
<p>Note that 'sag' and 'saga' fast convergence is only guaranteed on
features with approximately the same scale. You can
preprocess the data with a scaler from sklearn.preprocessing.</p>
<p>.. versionadded:: 0.17
Stochastic Average Gradient descent solver.
.. versionadded:: 0.19
SAGA solver.
.. versionchanged:: 0.22
The default solver changed from 'liblinear' to 'lbfgs' in 0.22.</p>
<p>max_iter : int, default=100
Maximum number of iterations taken for the solvers to converge.</p>
<p>multi_class : {'auto', 'ovr', 'multinomial'}, default='auto'
If the option chosen is 'ovr', then a binary problem is fit for each
label. For 'multinomial' the loss minimised is the multinomial loss fit
across the entire probability distribution, <em>even when the data is
binary</em>. 'multinomial' is unavailable when solver='liblinear'.
'auto' selects 'ovr' if the data is binary, or if solver='liblinear',
and otherwise selects 'multinomial'.</p>
<p>.. versionadded:: 0.18
Stochastic Average Gradient descent solver for 'multinomial' case.
.. versionchanged:: 0.22
Default changed from 'ovr' to 'auto' in 0.22.</p>
<p>verbose : int, default=0
For the liblinear and lbfgs solvers set verbose to any positive
number for verbosity.</p>
<p>warm_start : bool, default=False
When set to True, reuse the solution of the previous call to fit as
initialization, otherwise, just erase the previous solution.
Useless for liblinear solver. See :term:<code>the Glossary &lt;warm_start&gt;</code>.</p>
<p>.. versionadded:: 0.17
<em>warm_start</em> to support <em>lbfgs</em>, <em>newton-cg</em>, <em>sag</em>, <em>saga</em> solvers.</p>
<p>n_jobs : int, default=None
Number of CPU cores used when parallelizing over classes if
multi_class='ovr''. This parameter is ignored when the <code>solver</code> is
set to 'liblinear' regardless of whether 'multi_class' is specified or
not. <code>None</code> means 1 unless in a :obj:<code>joblib.parallel_backend</code>
context. <code>-1</code> means using all processors.
See :term:<code>Glossary &lt;n_jobs&gt;</code> for more details.</p>
<p>l1_ratio : float, default=None
The Elastic-Net mixing parameter, with <code>0 &lt;= l1_ratio &lt;= 1</code>. Only
used if <code>penalty='elasticnet'`. Setting</code>l1_ratio=0<code>is equivalent
to using</code>penalty='l2'<code>, while setting</code>l1_ratio=1<code>is equivalent
to using</code>penalty='l1'<code>. For</code>0 &lt; l1_ratio &lt;1``, the penalty is a
combination of L1 and L2.</p>
<h2 id="attributes_13">Attributes<a class="headerlink" href="#attributes_13" title="Permanent link">&para;</a></h2>
<p>classes_ : ndarray of shape (n_classes, )
A list of class labels known to the classifier.</p>
<p>coef_ : ndarray of shape (1, n_features) or (n_classes, n_features)
Coefficient of the features in the decision function.</p>
<p><code>coef_</code> is of shape (1, n_features) when the given problem is binary.
In particular, when <code>multi_class='multinomial'</code>, <code>coef_</code> corresponds
to outcome 1 (True) and <code>-coef_</code> corresponds to outcome 0 (False).</p>
<p>intercept_ : ndarray of shape (1,) or (n_classes,)
Intercept (a.k.a. bias) added to the decision function.</p>
<p>If <code>fit_intercept</code> is set to False, the intercept is set to zero.
<code>intercept_</code> is of shape (1,) when the given problem is binary.
In particular, when <code>multi_class='multinomial'</code>, <code>intercept_</code>
corresponds to outcome 1 (True) and <code>-intercept_</code> corresponds to
outcome 0 (False).</p>
<p>n_iter_ : ndarray of shape (n_classes,) or (1, )
Actual number of iterations for all classes. If binary or multinomial,
it returns only 1 element. For liblinear solver, only the maximum
number of iteration across all classes is given.</p>
<p>.. versionchanged:: 0.20</p>
<p>In SciPy &lt;= 1.0.0 the number of lbfgs iterations may exceed
<code>max_iter</code>. <code>n_iter_</code> will now report at most <code>max_iter</code>.</p>
<h2 id="see-also_10">See Also<a class="headerlink" href="#see-also_10" title="Permanent link">&para;</a></h2>
<p>SGDClassifier : Incrementally trained logistic regression (when given
the parameter <code>loss='log'</code>).
LogisticRegressionCV : Logistic regression with built-in cross validation.</p>
<h2 id="notes_24">Notes<a class="headerlink" href="#notes_24" title="Permanent link">&para;</a></h2>
<p>The underlying C implementation uses a random number generator to
select features when fitting the model. It is thus not uncommon,
to have slightly different results for the same input data. If
that happens, try with a smaller tol parameter.</p>
<p>Predict output may not match that of standalone liblinear in certain
cases. See :ref:<code>differences from liblinear &lt;liblinear_differences&gt;</code>
in the narrative documentation.</p>
<h2 id="references_3">References<a class="headerlink" href="#references_3" title="Permanent link">&para;</a></h2>
<p>L-BFGS-B -- Software for Large-scale Bound-constrained Optimization
Ciyou Zhu, Richard Byrd, Jorge Nocedal and Jose Luis Morales.
http://users.iems.northwestern.edu/~nocedal/lbfgsb.html</p>
<p>LIBLINEAR -- A Library for Large Linear Classification
https://www.csie.ntu.edu.tw/~cjlin/liblinear/</p>
<p>SAG -- Mark Schmidt, Nicolas Le Roux, and Francis Bach
Minimizing Finite Sums with the Stochastic Average Gradient
https://hal.inria.fr/hal-00860051/document</p>
<p>SAGA -- Defazio, A., Bach F. &amp; Lacoste-Julien S. (2014).
SAGA: A Fast Incremental Gradient Method With Support
for Non-Strongly Convex Composite Objectives
https://arxiv.org/abs/1407.0202</p>
<p>Hsiang-Fu Yu, Fang-Lan Huang, Chih-Jen Lin (2011). Dual coordinate descent
methods for logistic regression and maximum entropy models.
Machine Learning 85(1-2):41-75.
https://www.csie.ntu.edu.tw/~cjlin/papers/maxent_dual.pdf</p>
<h2 id="examples_13">Examples<a class="headerlink" href="#examples_13" title="Permanent link">&para;</a></h2>
<blockquote>
<blockquote>
<blockquote>
<p>from sklearn.datasets import load_iris
from sklearn.linear_model import LogisticRegression
X, y = load_iris(return_X_y=True)
clf = LogisticRegression(random_state=0).fit(X, y)
clf.predict(X[:2, :])
array([0, 0])
clf.predict_proba(X[:2, :])
array([[9.8...e-01, 1.8...e-02, 1.4...e-08],
[9.7...e-01, 2.8...e-02, ...e-08]])
clf.score(X, y)
0.97...</p>
</blockquote>
</blockquote>
</blockquote>
<div class="highlight"><pre><span></span><code><span class="k">val</span> <span class="n">decision_function</span> <span class="o">:</span> <span class="n">x</span><span class="o">:[&gt;`</span><span class="nc">ArrayLike</span><span class="o">]</span> <span class="nn">Np</span><span class="p">.</span><span class="nn">Obj</span><span class="p">.</span><span class="n">t</span> <span class="o">-&gt;</span> <span class="o">[&gt;</span> <span class="n">tag</span><span class="o">]</span> <span class="nn">Obj</span><span class="p">.</span><span class="n">t</span> <span class="o">-&gt;</span> <span class="o">[&gt;`</span><span class="nc">ArrayLike</span><span class="o">]</span> <span class="nn">Np</span><span class="p">.</span><span class="nn">Obj</span><span class="p">.</span><span class="n">t</span>
</code></pre></div>

<p>Predict confidence scores for samples.</p>
<p>The confidence score for a sample is the signed distance of that
sample to the hyperplane.</p>
<h2 id="parameters_79">Parameters<a class="headerlink" href="#parameters_79" title="Permanent link">&para;</a></h2>
<p>X : array_like or sparse matrix, shape (n_samples, n_features)
Samples.</p>
<h2 id="returns_61">Returns<a class="headerlink" href="#returns_61" title="Permanent link">&para;</a></h2>
<p>array, shape=(n_samples,) if n_classes == 2 else (n_samples, n_classes)
Confidence scores per (sample, class) combination. In the binary
case, confidence score for self.classes_[1] where &gt;0 means this
class would be predicted.</p>
<div class="highlight"><pre><span></span><code><span class="k">val</span> <span class="n">densify</span> <span class="o">:</span> <span class="o">[&gt;</span> <span class="n">tag</span><span class="o">]</span> <span class="nn">Obj</span><span class="p">.</span><span class="n">t</span> <span class="o">-&gt;</span> <span class="n">t</span>
</code></pre></div>

<p>Convert coefficient matrix to dense array format.</p>
<p>Converts the <code>coef_</code> member (back) to a numpy.ndarray. This is the
default format of <code>coef_</code> and is required for fitting, so calling
this method is only required on models that have previously been
sparsified; otherwise, it is a no-op.</p>
<h2 id="returns_62">Returns<a class="headerlink" href="#returns_62" title="Permanent link">&para;</a></h2>
<p>self
Fitted estimator.</p>
<div class="highlight"><pre><span></span><code><span class="k">val</span> <span class="n">fit</span> <span class="o">:</span> <span class="o">?</span><span class="n">sample_weight</span><span class="o">:[&gt;`</span><span class="nc">ArrayLike</span><span class="o">]</span> <span class="nn">Np</span><span class="p">.</span><span class="nn">Obj</span><span class="p">.</span><span class="n">t</span> <span class="o">-&gt;</span> <span class="n">x</span><span class="o">:[&gt;`</span><span class="nc">ArrayLike</span><span class="o">]</span> <span class="nn">Np</span><span class="p">.</span><span class="nn">Obj</span><span class="p">.</span><span class="n">t</span> <span class="o">-&gt;</span> <span class="n">y</span><span class="o">:[&gt;`</span><span class="nc">ArrayLike</span><span class="o">]</span> <span class="nn">Np</span><span class="p">.</span><span class="nn">Obj</span><span class="p">.</span><span class="n">t</span> <span class="o">-&gt;</span> <span class="o">[&gt;</span> <span class="n">tag</span><span class="o">]</span> <span class="nn">Obj</span><span class="p">.</span><span class="n">t</span> <span class="o">-&gt;</span> <span class="n">t</span>
</code></pre></div>

<p>Fit the model according to the given training data.</p>
<h2 id="parameters_80">Parameters<a class="headerlink" href="#parameters_80" title="Permanent link">&para;</a></h2>
<p>X : {array-like, sparse matrix} of shape (n_samples, n_features)
Training vector, where n_samples is the number of samples and
n_features is the number of features.</p>
<p>y : array-like of shape (n_samples,)
Target vector relative to X.</p>
<p>sample_weight : array-like of shape (n_samples,) default=None
Array of weights that are assigned to individual samples.
If not provided, then each sample is given unit weight.</p>
<p>.. versionadded:: 0.17
<em>sample_weight</em> support to LogisticRegression.</p>
<h2 id="returns_63">Returns<a class="headerlink" href="#returns_63" title="Permanent link">&para;</a></h2>
<p>self
Fitted estimator.</p>
<h2 id="notes_25">Notes<a class="headerlink" href="#notes_25" title="Permanent link">&para;</a></h2>
<p>The SAGA solver supports both float64 and float32 bit arrays.</p>
<div class="highlight"><pre><span></span><code><span class="k">val</span> <span class="n">get_params</span> <span class="o">:</span> <span class="o">?</span><span class="n">deep</span><span class="o">:</span><span class="kt">bool</span> <span class="o">-&gt;</span> <span class="o">[&gt;</span> <span class="n">tag</span><span class="o">]</span> <span class="nn">Obj</span><span class="p">.</span><span class="n">t</span> <span class="o">-&gt;</span> <span class="nn">Dict</span><span class="p">.</span><span class="n">t</span>
</code></pre></div>

<p>Get parameters for this estimator.</p>
<h2 id="parameters_81">Parameters<a class="headerlink" href="#parameters_81" title="Permanent link">&para;</a></h2>
<p>deep : bool, default=True
If True, will return the parameters for this estimator and
contained subobjects that are estimators.</p>
<h2 id="returns_64">Returns<a class="headerlink" href="#returns_64" title="Permanent link">&para;</a></h2>
<p>params : mapping of string to any
Parameter names mapped to their values.</p>
<div class="highlight"><pre><span></span><code><span class="k">val</span> <span class="n">predict</span> <span class="o">:</span> <span class="n">x</span><span class="o">:[&gt;`</span><span class="nc">ArrayLike</span><span class="o">]</span> <span class="nn">Np</span><span class="p">.</span><span class="nn">Obj</span><span class="p">.</span><span class="n">t</span> <span class="o">-&gt;</span> <span class="o">[&gt;</span> <span class="n">tag</span><span class="o">]</span> <span class="nn">Obj</span><span class="p">.</span><span class="n">t</span> <span class="o">-&gt;</span> <span class="o">[&gt;`</span><span class="nc">ArrayLike</span><span class="o">]</span> <span class="nn">Np</span><span class="p">.</span><span class="nn">Obj</span><span class="p">.</span><span class="n">t</span>
</code></pre></div>

<p>Predict class labels for samples in X.</p>
<h2 id="parameters_82">Parameters<a class="headerlink" href="#parameters_82" title="Permanent link">&para;</a></h2>
<p>X : array_like or sparse matrix, shape (n_samples, n_features)
Samples.</p>
<h2 id="returns_65">Returns<a class="headerlink" href="#returns_65" title="Permanent link">&para;</a></h2>
<p>C : array, shape [n_samples]
Predicted class label per sample.</p>
<div class="highlight"><pre><span></span><code><span class="k">val</span> <span class="n">predict_log_proba</span> <span class="o">:</span> <span class="n">x</span><span class="o">:[&gt;`</span><span class="nc">ArrayLike</span><span class="o">]</span> <span class="nn">Np</span><span class="p">.</span><span class="nn">Obj</span><span class="p">.</span><span class="n">t</span> <span class="o">-&gt;</span> <span class="o">[&gt;</span> <span class="n">tag</span><span class="o">]</span> <span class="nn">Obj</span><span class="p">.</span><span class="n">t</span> <span class="o">-&gt;</span> <span class="o">[&gt;`</span><span class="nc">ArrayLike</span><span class="o">]</span> <span class="nn">Np</span><span class="p">.</span><span class="nn">Obj</span><span class="p">.</span><span class="n">t</span>
</code></pre></div>

<p>Predict logarithm of probability estimates.</p>
<p>The returned estimates for all classes are ordered by the
label of classes.</p>
<h2 id="parameters_83">Parameters<a class="headerlink" href="#parameters_83" title="Permanent link">&para;</a></h2>
<p>X : array-like of shape (n_samples, n_features)
Vector to be scored, where <code>n_samples</code> is the number of samples and
<code>n_features</code> is the number of features.</p>
<h2 id="returns_66">Returns<a class="headerlink" href="#returns_66" title="Permanent link">&para;</a></h2>
<p>T : array-like of shape (n_samples, n_classes)
Returns the log-probability of the sample for each class in the
model, where classes are ordered as they are in <code>self.classes_</code>.</p>
<div class="highlight"><pre><span></span><code><span class="k">val</span> <span class="n">predict_proba</span> <span class="o">:</span> <span class="n">x</span><span class="o">:[&gt;`</span><span class="nc">ArrayLike</span><span class="o">]</span> <span class="nn">Np</span><span class="p">.</span><span class="nn">Obj</span><span class="p">.</span><span class="n">t</span> <span class="o">-&gt;</span> <span class="o">[&gt;</span> <span class="n">tag</span><span class="o">]</span> <span class="nn">Obj</span><span class="p">.</span><span class="n">t</span> <span class="o">-&gt;</span> <span class="o">[&gt;`</span><span class="nc">ArrayLike</span><span class="o">]</span> <span class="nn">Np</span><span class="p">.</span><span class="nn">Obj</span><span class="p">.</span><span class="n">t</span>
</code></pre></div>

<p>Probability estimates.</p>
<p>The returned estimates for all classes are ordered by the
label of classes.</p>
<p>For a multi_class problem, if multi_class is set to be 'multinomial'
the softmax function is used to find the predicted probability of
each class.
Else use a one-vs-rest approach, i.e calculate the probability
of each class assuming it to be positive using the logistic function.
and normalize these values across all the classes.</p>
<h2 id="parameters_84">Parameters<a class="headerlink" href="#parameters_84" title="Permanent link">&para;</a></h2>
<p>X : array-like of shape (n_samples, n_features)
Vector to be scored, where <code>n_samples</code> is the number of samples and
<code>n_features</code> is the number of features.</p>
<h2 id="returns_67">Returns<a class="headerlink" href="#returns_67" title="Permanent link">&para;</a></h2>
<p>T : array-like of shape (n_samples, n_classes)
Returns the probability of the sample for each class in the model,
where classes are ordered as they are in <code>self.classes_</code>.</p>
<div class="highlight"><pre><span></span><code><span class="k">val</span> <span class="n">score</span> <span class="o">:</span> <span class="o">?</span><span class="n">sample_weight</span><span class="o">:[&gt;`</span><span class="nc">ArrayLike</span><span class="o">]</span> <span class="nn">Np</span><span class="p">.</span><span class="nn">Obj</span><span class="p">.</span><span class="n">t</span> <span class="o">-&gt;</span> <span class="n">x</span><span class="o">:[&gt;`</span><span class="nc">ArrayLike</span><span class="o">]</span> <span class="nn">Np</span><span class="p">.</span><span class="nn">Obj</span><span class="p">.</span><span class="n">t</span> <span class="o">-&gt;</span> <span class="n">y</span><span class="o">:[&gt;`</span><span class="nc">ArrayLike</span><span class="o">]</span> <span class="nn">Np</span><span class="p">.</span><span class="nn">Obj</span><span class="p">.</span><span class="n">t</span> <span class="o">-&gt;</span> <span class="o">[&gt;</span> <span class="n">tag</span><span class="o">]</span> <span class="nn">Obj</span><span class="p">.</span><span class="n">t</span> <span class="o">-&gt;</span> <span class="kt">float</span>
</code></pre></div>

<p>Return the mean accuracy on the given test data and labels.</p>
<p>In multi-label classification, this is the subset accuracy
which is a harsh metric since you require for each sample that
each label set be correctly predicted.</p>
<h2 id="parameters_85">Parameters<a class="headerlink" href="#parameters_85" title="Permanent link">&para;</a></h2>
<p>X : array-like of shape (n_samples, n_features)
Test samples.</p>
<p>y : array-like of shape (n_samples,) or (n_samples, n_outputs)
True labels for X.</p>
<p>sample_weight : array-like of shape (n_samples,), default=None
Sample weights.</p>
<h2 id="returns_68">Returns<a class="headerlink" href="#returns_68" title="Permanent link">&para;</a></h2>
<p>score : float
Mean accuracy of self.predict(X) wrt. y.</p>
<div class="highlight"><pre><span></span><code><span class="k">val</span> <span class="n">set_params</span> <span class="o">:</span> <span class="o">?</span><span class="n">params</span><span class="o">:(</span><span class="kt">string</span> <span class="o">*</span> <span class="nn">Py</span><span class="p">.</span><span class="nn">Object</span><span class="p">.</span><span class="n">t</span><span class="o">)</span> <span class="kt">list</span> <span class="o">-&gt;</span> <span class="o">[&gt;</span> <span class="n">tag</span><span class="o">]</span> <span class="nn">Obj</span><span class="p">.</span><span class="n">t</span> <span class="o">-&gt;</span> <span class="n">t</span>
</code></pre></div>

<p>Set the parameters of this estimator.</p>
<p>The method works on simple estimators as well as on nested objects
(such as pipelines). The latter have parameters of the form
<code>&lt;component&gt;__&lt;parameter&gt;</code> so that it's possible to update each
component of a nested object.</p>
<h2 id="parameters_86">Parameters<a class="headerlink" href="#parameters_86" title="Permanent link">&para;</a></h2>
<p>**params : dict
Estimator parameters.</p>
<h2 id="returns_69">Returns<a class="headerlink" href="#returns_69" title="Permanent link">&para;</a></h2>
<p>self : object
Estimator instance.</p>
<div class="highlight"><pre><span></span><code><span class="k">val</span> <span class="n">sparsify</span> <span class="o">:</span> <span class="o">[&gt;</span> <span class="n">tag</span><span class="o">]</span> <span class="nn">Obj</span><span class="p">.</span><span class="n">t</span> <span class="o">-&gt;</span> <span class="n">t</span>
</code></pre></div>

<p>Convert coefficient matrix to sparse format.</p>
<p>Converts the <code>coef_</code> member to a scipy.sparse matrix, which for
L1-regularized models can be much more memory- and storage-efficient
than the usual numpy.ndarray representation.</p>
<p>The <code>intercept_</code> member is not converted.</p>
<h2 id="returns_70">Returns<a class="headerlink" href="#returns_70" title="Permanent link">&para;</a></h2>
<p>self
Fitted estimator.</p>
<h2 id="notes_26">Notes<a class="headerlink" href="#notes_26" title="Permanent link">&para;</a></h2>
<p>For non-sparse models, i.e. when there are not many zeros in <code>coef_</code>,
this may actually <em>increase</em> memory usage, so use this method with
care. A rule of thumb is that the number of zero elements, which can
be computed with <code>(coef_ == 0).sum()</code>, must be more than 50% for this
to provide significant benefits.</p>
<p>After calling this method, further fitting with the partial_fit
method (if any) will not work until you call densify.</p>
<p>Attribute classes_: get value or raise Not_found if None.</p>
<div class="highlight"><pre><span></span><code><span class="k">val</span> <span class="n">classes_</span> <span class="o">:</span> <span class="n">t</span> <span class="o">-&gt;</span> <span class="o">[&gt;`</span><span class="nc">ArrayLike</span><span class="o">]</span> <span class="nn">Np</span><span class="p">.</span><span class="nn">Obj</span><span class="p">.</span><span class="n">t</span>
</code></pre></div>

<p>Attribute classes_: get value as an option.</p>
<div class="highlight"><pre><span></span><code><span class="k">val</span> <span class="n">classes_opt</span> <span class="o">:</span> <span class="n">t</span> <span class="o">-&gt;</span> <span class="o">([&gt;`</span><span class="nc">ArrayLike</span><span class="o">]</span> <span class="nn">Np</span><span class="p">.</span><span class="nn">Obj</span><span class="p">.</span><span class="n">t</span><span class="o">)</span> <span class="n">option</span>
</code></pre></div>

<p>Attribute coef_: get value or raise Not_found if None.</p>
<div class="highlight"><pre><span></span><code><span class="k">val</span> <span class="n">coef_</span> <span class="o">:</span> <span class="n">t</span> <span class="o">-&gt;</span> <span class="o">[&gt;`</span><span class="nc">ArrayLike</span><span class="o">]</span> <span class="nn">Np</span><span class="p">.</span><span class="nn">Obj</span><span class="p">.</span><span class="n">t</span>
</code></pre></div>

<p>Attribute coef_: get value as an option.</p>
<div class="highlight"><pre><span></span><code><span class="k">val</span> <span class="n">coef_opt</span> <span class="o">:</span> <span class="n">t</span> <span class="o">-&gt;</span> <span class="o">([&gt;`</span><span class="nc">ArrayLike</span><span class="o">]</span> <span class="nn">Np</span><span class="p">.</span><span class="nn">Obj</span><span class="p">.</span><span class="n">t</span><span class="o">)</span> <span class="n">option</span>
</code></pre></div>

<p>Attribute intercept_: get value or raise Not_found if None.</p>
<div class="highlight"><pre><span></span><code><span class="k">val</span> <span class="n">intercept_</span> <span class="o">:</span> <span class="n">t</span> <span class="o">-&gt;</span> <span class="o">[&gt;`</span><span class="nc">ArrayLike</span><span class="o">]</span> <span class="nn">Np</span><span class="p">.</span><span class="nn">Obj</span><span class="p">.</span><span class="n">t</span>
</code></pre></div>

<p>Attribute intercept_: get value as an option.</p>
<div class="highlight"><pre><span></span><code><span class="k">val</span> <span class="n">intercept_opt</span> <span class="o">:</span> <span class="n">t</span> <span class="o">-&gt;</span> <span class="o">([&gt;`</span><span class="nc">ArrayLike</span><span class="o">]</span> <span class="nn">Np</span><span class="p">.</span><span class="nn">Obj</span><span class="p">.</span><span class="n">t</span><span class="o">)</span> <span class="n">option</span>
</code></pre></div>

<p>Attribute n_iter_: get value or raise Not_found if None.</p>
<div class="highlight"><pre><span></span><code><span class="k">val</span> <span class="n">n_iter_</span> <span class="o">:</span> <span class="n">t</span> <span class="o">-&gt;</span> <span class="o">[&gt;`</span><span class="nc">ArrayLike</span><span class="o">]</span> <span class="nn">Np</span><span class="p">.</span><span class="nn">Obj</span><span class="p">.</span><span class="n">t</span>
</code></pre></div>

<p>Attribute n_iter_: get value as an option.</p>
<div class="highlight"><pre><span></span><code><span class="k">val</span> <span class="n">n_iter_opt</span> <span class="o">:</span> <span class="n">t</span> <span class="o">-&gt;</span> <span class="o">([&gt;`</span><span class="nc">ArrayLike</span><span class="o">]</span> <span class="nn">Np</span><span class="p">.</span><span class="nn">Obj</span><span class="p">.</span><span class="n">t</span><span class="o">)</span> <span class="n">option</span>
</code></pre></div>

<p>Print the object to a human-readable representation.</p>
<div class="highlight"><pre><span></span><code><span class="k">val</span> <span class="n">to_string</span> <span class="o">:</span> <span class="n">t</span> <span class="o">-&gt;</span> <span class="kt">string</span>
</code></pre></div>

<p>Print the object to a human-readable representation.</p>
<div class="highlight"><pre><span></span><code><span class="k">val</span> <span class="n">show</span> <span class="o">:</span> <span class="n">t</span> <span class="o">-&gt;</span> <span class="kt">string</span>
</code></pre></div>

<p>Pretty-print the object to a formatter.</p>
<div class="highlight"><pre><span></span><code><span class="k">val</span> <span class="n">pp</span> <span class="o">:</span> <span class="nn">Format</span><span class="p">.</span><span class="n">formatter</span> <span class="o">-&gt;</span> <span class="n">t</span> <span class="o">-&gt;</span> <span class="kt">unit</span> <span class="o">[@@</span><span class="n">ocaml</span><span class="o">.</span><span class="n">toplevel_printer</span><span class="o">]</span>



<span class="k">module</span> <span class="nc">LogisticRegressionCV</span> <span class="o">:</span> <span class="k">sig</span>
<span class="k">type</span> <span class="n">tag</span> <span class="o">=</span> <span class="o">[`</span><span class="nc">LogisticRegressionCV</span><span class="o">]</span>
<span class="k">type</span> <span class="n">t</span> <span class="o">=</span> <span class="o">[`</span><span class="nc">BaseEstimator</span> <span class="o">|</span> <span class="o">`</span><span class="nc">ClassifierMixin</span> <span class="o">|</span> <span class="o">`</span><span class="nc">LinearClassifierMixin</span> <span class="o">|</span> <span class="o">`</span><span class="nc">LogisticRegressionCV</span> <span class="o">|</span> <span class="o">`</span><span class="nc">Object</span> <span class="o">|</span> <span class="o">`</span><span class="nc">SparseCoefMixin</span><span class="o">]</span> <span class="nn">Obj</span><span class="p">.</span><span class="n">t</span>
<span class="k">val</span> <span class="n">of_pyobject</span> <span class="o">:</span> <span class="nn">Py</span><span class="p">.</span><span class="nn">Object</span><span class="p">.</span><span class="n">t</span> <span class="o">-&gt;</span> <span class="n">t</span>
<span class="k">val</span> <span class="n">to_pyobject</span> <span class="o">:</span> <span class="o">[&gt;</span> <span class="n">tag</span><span class="o">]</span> <span class="nn">Obj</span><span class="p">.</span><span class="n">t</span> <span class="o">-&gt;</span> <span class="nn">Py</span><span class="p">.</span><span class="nn">Object</span><span class="p">.</span><span class="n">t</span>

<span class="k">val</span> <span class="n">as_classifier</span> <span class="o">:</span> <span class="n">t</span> <span class="o">-&gt;</span> <span class="o">[`</span><span class="nc">ClassifierMixin</span><span class="o">]</span> <span class="nn">Obj</span><span class="p">.</span><span class="n">t</span>
<span class="k">val</span> <span class="n">as_linear_classifier</span> <span class="o">:</span> <span class="n">t</span> <span class="o">-&gt;</span> <span class="o">[`</span><span class="nc">LinearClassifierMixin</span><span class="o">]</span> <span class="nn">Obj</span><span class="p">.</span><span class="n">t</span>
<span class="k">val</span> <span class="n">as_estimator</span> <span class="o">:</span> <span class="n">t</span> <span class="o">-&gt;</span> <span class="o">[`</span><span class="nc">BaseEstimator</span><span class="o">]</span> <span class="nn">Obj</span><span class="p">.</span><span class="n">t</span>
<span class="k">val</span> <span class="n">as_sparse_coef</span> <span class="o">:</span> <span class="n">t</span> <span class="o">-&gt;</span> <span class="o">[`</span><span class="nc">SparseCoefMixin</span><span class="o">]</span> <span class="nn">Obj</span><span class="p">.</span><span class="n">t</span>
<span class="k">val</span> <span class="n">create</span> <span class="o">:</span> <span class="o">?</span><span class="n">cs</span><span class="o">:[`</span><span class="nc">Fs</span> <span class="k">of</span> <span class="kt">float</span> <span class="kt">list</span> <span class="o">|</span> <span class="o">`</span><span class="nc">I</span> <span class="k">of</span> <span class="kt">int</span><span class="o">]</span> <span class="o">-&gt;</span> <span class="o">?</span><span class="n">fit_intercept</span><span class="o">:</span><span class="kt">bool</span> <span class="o">-&gt;</span> <span class="o">?</span><span class="n">cv</span><span class="o">:[`</span><span class="nc">BaseCrossValidator</span> <span class="k">of</span> <span class="o">[&gt;`</span><span class="nc">BaseCrossValidator</span><span class="o">]</span> <span class="nn">Np</span><span class="p">.</span><span class="nn">Obj</span><span class="p">.</span><span class="n">t</span> <span class="o">|</span> <span class="o">`</span><span class="nc">I</span> <span class="k">of</span> <span class="kt">int</span><span class="o">]</span> <span class="o">-&gt;</span> <span class="o">?</span><span class="n">dual</span><span class="o">:</span><span class="kt">bool</span> <span class="o">-&gt;</span> <span class="o">?</span><span class="n">penalty</span><span class="o">:[`</span><span class="nc">L1</span> <span class="o">|</span> <span class="o">`</span><span class="nc">L2</span> <span class="o">|</span> <span class="o">`</span><span class="nc">Elasticnet</span><span class="o">]</span> <span class="o">-&gt;</span> <span class="o">?</span><span class="n">scoring</span><span class="o">:[`</span><span class="nc">Max_error</span> <span class="o">|</span> <span class="o">`</span><span class="nc">Mutual_info_score</span> <span class="o">|</span> <span class="o">`</span><span class="nc">Homogeneity_score</span> <span class="o">|</span> <span class="o">`</span><span class="nc">Roc_auc</span> <span class="o">|</span> <span class="o">`</span><span class="nc">Neg_mean_squared_error</span> <span class="o">|</span> <span class="o">`</span><span class="nc">Recall_micro</span> <span class="o">|</span> <span class="o">`</span><span class="nc">Neg_mean_poisson_deviance</span> <span class="o">|</span> <span class="o">`</span><span class="nc">Neg_log_loss</span> <span class="o">|</span> <span class="o">`</span><span class="nc">F1_macro</span> <span class="o">|</span> <span class="o">`</span><span class="nc">Neg_mean_gamma_deviance</span> <span class="o">|</span> <span class="o">`</span><span class="nc">Neg_median_absolute_error</span> <span class="o">|</span> <span class="o">`</span><span class="nc">Callable</span> <span class="k">of</span> <span class="nn">Py</span><span class="p">.</span><span class="nn">Object</span><span class="p">.</span><span class="n">t</span> <span class="o">|</span> <span class="o">`</span><span class="nc">Neg_brier_score</span> <span class="o">|</span> <span class="o">`</span><span class="nc">Neg_mean_squared_log_error</span> <span class="o">|</span> <span class="o">`</span><span class="nc">Recall_macro</span> <span class="o">|</span> <span class="o">`</span><span class="nc">Explained_variance</span> <span class="o">|</span> <span class="o">`</span><span class="nc">Roc_auc_ovr_weighted</span> <span class="o">|</span> <span class="o">`</span><span class="nc">Adjusted_rand_score</span> <span class="o">|</span> <span class="o">`</span><span class="nc">Precision_macro</span> <span class="o">|</span> <span class="o">`</span><span class="nc">Jaccard_samples</span> <span class="o">|</span> <span class="o">`</span><span class="nc">Roc_auc_ovo_weighted</span> <span class="o">|</span> <span class="o">`</span><span class="nc">Jaccard_macro</span> <span class="o">|</span> <span class="o">`</span><span class="nc">Precision</span> <span class="o">|</span> <span class="o">`</span><span class="nc">Balanced_accuracy</span> <span class="o">|</span> <span class="o">`</span><span class="nc">Precision_micro</span> <span class="o">|</span> <span class="o">`</span><span class="nc">Precision_weighted</span> <span class="o">|</span> <span class="o">`</span><span class="nc">V_measure_score</span> <span class="o">|</span> <span class="o">`</span><span class="nc">Normalized_mutual_info_score</span> <span class="o">|</span> <span class="o">`</span><span class="nc">F1_weighted</span> <span class="o">|</span> <span class="o">`</span><span class="nc">Neg_root_mean_squared_error</span> <span class="o">|</span> <span class="o">`</span><span class="nc">Neg_mean_absolute_error</span> <span class="o">|</span> <span class="o">`</span><span class="nc">F1</span> <span class="o">|</span> <span class="o">`</span><span class="nc">Roc_auc_ovo</span> <span class="o">|</span> <span class="o">`</span><span class="nc">Jaccard_micro</span> <span class="o">|</span> <span class="o">`</span><span class="nc">Average_precision</span> <span class="o">|</span> <span class="o">`</span><span class="nc">Adjusted_mutual_info_score</span> <span class="o">|</span> <span class="o">`</span><span class="nc">R2</span> <span class="o">|</span> <span class="o">`</span><span class="nc">F1_samples</span> <span class="o">|</span> <span class="o">`</span><span class="nc">Fowlkes_mallows_score</span> <span class="o">|</span> <span class="o">`</span><span class="nc">Accuracy</span> <span class="o">|</span> <span class="o">`</span><span class="nc">Recall_weighted</span> <span class="o">|</span> <span class="o">`</span><span class="nc">Jaccard_weighted</span> <span class="o">|</span> <span class="o">`</span><span class="nc">Roc_auc_ovr</span> <span class="o">|</span> <span class="o">`</span><span class="nc">F1_micro</span> <span class="o">|</span> <span class="o">`</span><span class="nc">Precision_samples</span> <span class="o">|</span> <span class="o">`</span><span class="nc">Jaccard</span> <span class="o">|</span> <span class="o">`</span><span class="nc">Completeness_score</span> <span class="o">|</span> <span class="o">`</span><span class="nc">Recall_samples</span> <span class="o">|</span> <span class="o">`</span><span class="nc">Recall</span><span class="o">]</span> <span class="o">-&gt;</span> <span class="o">?</span><span class="n">solver</span><span class="o">:[`</span><span class="nc">Newton_cg</span> <span class="o">|</span> <span class="o">`</span><span class="nc">Lbfgs</span> <span class="o">|</span> <span class="o">`</span><span class="nc">Liblinear</span> <span class="o">|</span> <span class="o">`</span><span class="nc">Sag</span> <span class="o">|</span> <span class="o">`</span><span class="nc">Saga</span><span class="o">]</span> <span class="o">-&gt;</span> <span class="o">?</span><span class="n">tol</span><span class="o">:</span><span class="kt">float</span> <span class="o">-&gt;</span> <span class="o">?</span><span class="n">max_iter</span><span class="o">:</span><span class="kt">int</span> <span class="o">-&gt;</span> <span class="o">?</span><span class="n">class_weight</span><span class="o">:[`</span><span class="nc">DictIntToFloat</span> <span class="k">of</span> <span class="o">(</span><span class="kt">int</span> <span class="o">*</span> <span class="kt">float</span><span class="o">)</span> <span class="kt">list</span> <span class="o">|</span> <span class="o">`</span><span class="nc">Balanced</span><span class="o">]</span> <span class="o">-&gt;</span> <span class="o">?</span><span class="n">n_jobs</span><span class="o">:</span><span class="kt">int</span> <span class="o">-&gt;</span> <span class="o">?</span><span class="n">verbose</span><span class="o">:</span><span class="kt">int</span> <span class="o">-&gt;</span> <span class="o">?</span><span class="n">refit</span><span class="o">:</span><span class="kt">bool</span> <span class="o">-&gt;</span> <span class="o">?</span><span class="n">intercept_scaling</span><span class="o">:</span><span class="kt">float</span> <span class="o">-&gt;</span> <span class="o">?</span><span class="n">multi_class</span><span class="o">:[`</span><span class="nc">T_auto</span> <span class="k">of</span> <span class="nn">Py</span><span class="p">.</span><span class="nn">Object</span><span class="p">.</span><span class="n">t</span> <span class="o">|</span> <span class="o">`</span><span class="nc">Multinomial</span> <span class="o">|</span> <span class="o">`</span><span class="nc">Ovr</span><span class="o">]</span> <span class="o">-&gt;</span> <span class="o">?</span><span class="n">random_state</span><span class="o">:</span><span class="kt">int</span> <span class="o">-&gt;</span> <span class="o">?</span><span class="n">l1_ratios</span><span class="o">:</span><span class="kt">float</span> <span class="kt">list</span> <span class="o">-&gt;</span> <span class="kt">unit</span> <span class="o">-&gt;</span> <span class="n">t</span>
</code></pre></div>

<p>Logistic Regression CV (aka logit, MaxEnt) classifier.</p>
<p>See glossary entry for :term:<code>cross-validation estimator</code>.</p>
<p>This class implements logistic regression using liblinear, newton-cg, sag
of lbfgs optimizer. The newton-cg, sag and lbfgs solvers support only L2
regularization with primal formulation. The liblinear solver supports both
L1 and L2 regularization, with a dual formulation only for the L2 penalty.
Elastic-Net penalty is only supported by the saga solver.</p>
<p>For the grid of <code>Cs</code> values and <code>l1_ratios</code> values, the best hyperparameter
is selected by the cross-validator
:class:<code>~sklearn.model_selection.StratifiedKFold</code>, but it can be changed
using the :term:<code>cv</code> parameter. The 'newton-cg', 'sag', 'saga' and 'lbfgs'
solvers can warm-start the coefficients (see :term:<code>Glossary&lt;warm_start&gt;</code>).</p>
<p>Read more in the :ref:<code>User Guide &lt;logistic_regression&gt;</code>.</p>
<h2 id="parameters_87">Parameters<a class="headerlink" href="#parameters_87" title="Permanent link">&para;</a></h2>
<p>Cs : int or list of floats, default=10
Each of the values in Cs describes the inverse of regularization
strength. If Cs is as an int, then a grid of Cs values are chosen
in a logarithmic scale between 1e-4 and 1e4.
Like in support vector machines, smaller values specify stronger
regularization.</p>
<p>fit_intercept : bool, default=True
Specifies if a constant (a.k.a. bias or intercept) should be
added to the decision function.</p>
<p>cv : int or cross-validation generator, default=None
The default cross-validation generator used is Stratified K-Folds.
If an integer is provided, then it is the number of folds used.
See the module :mod:<code>sklearn.model_selection</code> module for the
list of possible cross-validation objects.</p>
<p>.. versionchanged:: 0.22
<code>cv</code> default value if None changed from 3-fold to 5-fold.</p>
<p>dual : bool, default=False
Dual or primal formulation. Dual formulation is only implemented for
l2 penalty with liblinear solver. Prefer dual=False when
n_samples &gt; n_features.</p>
<p>penalty : {'l1', 'l2', 'elasticnet'}, default='l2'
Used to specify the norm used in the penalization. The 'newton-cg',
'sag' and 'lbfgs' solvers support only l2 penalties. 'elasticnet' is
only supported by the 'saga' solver.</p>
<p>scoring : str or callable, default=None
A string (see model evaluation documentation) or
a scorer callable object / function with signature
<code>scorer(estimator, X, y)</code>. For a list of scoring functions
that can be used, look at :mod:<code>sklearn.metrics</code>. The
default scoring option used is 'accuracy'.</p>
<p>solver : {'newton-cg', 'lbfgs', 'liblinear', 'sag', 'saga'},             default='lbfgs'</p>
<p>Algorithm to use in the optimization problem.</p>
<ul>
<li>For small datasets, 'liblinear' is a good choice, whereas 'sag' and
'saga' are faster for large ones.</li>
<li>For multiclass problems, only 'newton-cg', 'sag', 'saga' and 'lbfgs'
handle multinomial loss; 'liblinear' is limited to one-versus-rest
schemes.</li>
<li>'newton-cg', 'lbfgs' and 'sag' only handle L2 penalty, whereas
'liblinear' and 'saga' handle L1 penalty.</li>
<li>'liblinear' might be slower in LogisticRegressionCV because it does
not handle warm-starting.</li>
</ul>
<p>Note that 'sag' and 'saga' fast convergence is only guaranteed on
features with approximately the same scale. You can preprocess the data
with a scaler from sklearn.preprocessing.</p>
<p>.. versionadded:: 0.17
Stochastic Average Gradient descent solver.
.. versionadded:: 0.19
SAGA solver.</p>
<p>tol : float, default=1e-4
Tolerance for stopping criteria.</p>
<p>max_iter : int, default=100
Maximum number of iterations of the optimization algorithm.</p>
<p>class_weight : dict or 'balanced', default=None
Weights associated with classes in the form <code>{class_label: weight}</code>.
If not given, all classes are supposed to have weight one.</p>
<p>The 'balanced' mode uses the values of y to automatically adjust
weights inversely proportional to class frequencies in the input data
as <code>n_samples / (n_classes * np.bincount(y))</code>.</p>
<p>Note that these weights will be multiplied with sample_weight (passed
through the fit method) if sample_weight is specified.</p>
<p>.. versionadded:: 0.17
class_weight == 'balanced'</p>
<p>n_jobs : int, default=None
Number of CPU cores used during the cross-validation loop.
<code>None</code> means 1 unless in a :obj:<code>joblib.parallel_backend</code> context.
<code>-1</code> means using all processors. See :term:<code>Glossary &lt;n_jobs&gt;</code>
for more details.</p>
<p>verbose : int, default=0
For the 'liblinear', 'sag' and 'lbfgs' solvers set verbose to any
positive number for verbosity.</p>
<p>refit : bool, default=True
If set to True, the scores are averaged across all folds, and the
coefs and the C that corresponds to the best score is taken, and a
final refit is done using these parameters.
Otherwise the coefs, intercepts and C that correspond to the
best scores across folds are averaged.</p>
<p>intercept_scaling : float, default=1
Useful only when the solver 'liblinear' is used
and self.fit_intercept is set to True. In this case, x becomes
[x, self.intercept_scaling],
i.e. a 'synthetic' feature with constant value equal to
intercept_scaling is appended to the instance vector.
The intercept becomes <code>intercept_scaling * synthetic_feature_weight</code>.</p>
<p>Note! the synthetic feature weight is subject to l1/l2 regularization
as all other features.
To lessen the effect of regularization on synthetic feature weight
(and therefore on the intercept) intercept_scaling has to be increased.</p>
<p>multi_class : {'auto, 'ovr', 'multinomial'}, default='auto'
If the option chosen is 'ovr', then a binary problem is fit for each
label. For 'multinomial' the loss minimised is the multinomial loss fit
across the entire probability distribution, <em>even when the data is
binary</em>. 'multinomial' is unavailable when solver='liblinear'.
'auto' selects 'ovr' if the data is binary, or if solver='liblinear',
and otherwise selects 'multinomial'.</p>
<p>.. versionadded:: 0.18
Stochastic Average Gradient descent solver for 'multinomial' case.
.. versionchanged:: 0.22
Default changed from 'ovr' to 'auto' in 0.22.</p>
<p>random_state : int, RandomState instance, default=None
If int, random_state is the seed used by the random number generator;
If RandomState instance, random_state is the random number generator;
If None, the random number generator is the RandomState instance used
by <code>np.random</code>. Used when <code>solver='sag'</code> or <code>solver='liblinear'</code>.
Note that this only applies to the solver and not the cross-validation
generator.</p>
<p>l1_ratios : list of float, default=None
The list of Elastic-Net mixing parameter, with <code>0 &lt;= l1_ratio &lt;= 1</code>.
Only used if <code>penalty='elasticnet'</code>. A value of 0 is equivalent to
using <code>penalty='l2'</code>, while 1 is equivalent to using
<code>penalty='l1'</code>. For <code>0 &lt; l1_ratio &lt;1</code>, the penalty is a combination
of L1 and L2.</p>
<h2 id="attributes_14">Attributes<a class="headerlink" href="#attributes_14" title="Permanent link">&para;</a></h2>
<p>classes_ : ndarray of shape (n_classes, )
A list of class labels known to the classifier.</p>
<p>coef_ : ndarray of shape (1, n_features) or (n_classes, n_features)
Coefficient of the features in the decision function.</p>
<p><code>coef_</code> is of shape (1, n_features) when the given problem
is binary.</p>
<p>intercept_ : ndarray of shape (1,) or (n_classes,)
Intercept (a.k.a. bias) added to the decision function.</p>
<p>If <code>fit_intercept</code> is set to False, the intercept is set to zero.
<code>intercept_</code> is of shape(1,) when the problem is binary.</p>
<p>Cs_ : ndarray of shape (n_cs)
Array of C i.e. inverse of regularization parameter values used
for cross-validation.</p>
<p>l1_ratios_ : ndarray of shape (n_l1_ratios)
Array of l1_ratios used for cross-validation. If no l1_ratio is used
(i.e. penalty is not 'elasticnet'), this is set to <code>[None]</code></p>
<p>coefs_paths_ : ndarray of shape (n_folds, n_cs, n_features) or                    (n_folds, n_cs, n_features + 1)
dict with classes as the keys, and the path of coefficients obtained
during cross-validating across each fold and then across each Cs
after doing an OvR for the corresponding class as values.
If the 'multi_class' option is set to 'multinomial', then
the coefs_paths are the coefficients corresponding to each class.
Each dict value has shape <code>(n_folds, n_cs, n_features)</code> or
<code>(n_folds, n_cs, n_features + 1)</code> depending on whether the
intercept is fit or not. If <code>penalty='elasticnet'</code>, the shape is
<code>(n_folds, n_cs, n_l1_ratios_, n_features)</code> or
<code>(n_folds, n_cs, n_l1_ratios_, n_features + 1)</code>.</p>
<p>scores_ : dict
dict with classes as the keys, and the values as the
grid of scores obtained during cross-validating each fold, after doing
an OvR for the corresponding class. If the 'multi_class' option
given is 'multinomial' then the same scores are repeated across
all classes, since this is the multinomial class. Each dict value
has shape <code>(n_folds, n_cs</code> or <code>(n_folds, n_cs, n_l1_ratios)</code> if
<code>penalty='elasticnet'</code>.</p>
<p>C_ : ndarray of shape (n_classes,) or (n_classes - 1,)
Array of C that maps to the best scores across every class. If refit is
set to False, then for each class, the best C is the average of the
C's that correspond to the best scores for each fold.
<code>C_</code> is of shape(n_classes,) when the problem is binary.</p>
<p>l1_ratio_ : ndarray of shape (n_classes,) or (n_classes - 1,)
Array of l1_ratio that maps to the best scores across every class. If
refit is set to False, then for each class, the best l1_ratio is the
average of the l1_ratio's that correspond to the best scores for each
fold.  <code>l1_ratio_</code> is of shape(n_classes,) when the problem is binary.</p>
<p>n_iter_ : ndarray of shape (n_classes, n_folds, n_cs) or (1, n_folds, n_cs)
Actual number of iterations for all classes, folds and Cs.
In the binary or multinomial cases, the first dimension is equal to 1.
If <code>penalty='elasticnet'</code>, the shape is <code>(n_classes, n_folds,
n_cs, n_l1_ratios)</code> or <code>(1, n_folds, n_cs, n_l1_ratios)</code>.</p>
<h2 id="examples_14">Examples<a class="headerlink" href="#examples_14" title="Permanent link">&para;</a></h2>
<blockquote>
<blockquote>
<blockquote>
<p>from sklearn.datasets import load_iris
from sklearn.linear_model import LogisticRegressionCV
X, y = load_iris(return_X_y=True)
clf = LogisticRegressionCV(cv=5, random_state=0).fit(X, y)
clf.predict(X[:2, :])
array([0, 0])
clf.predict_proba(X[:2, :]).shape
(2, 3)
clf.score(X, y)
0.98...</p>
</blockquote>
</blockquote>
</blockquote>
<h2 id="see-also_11">See also<a class="headerlink" href="#see-also_11" title="Permanent link">&para;</a></h2>
<p>LogisticRegression</p>
<div class="highlight"><pre><span></span><code><span class="k">val</span> <span class="n">decision_function</span> <span class="o">:</span> <span class="n">x</span><span class="o">:[&gt;`</span><span class="nc">ArrayLike</span><span class="o">]</span> <span class="nn">Np</span><span class="p">.</span><span class="nn">Obj</span><span class="p">.</span><span class="n">t</span> <span class="o">-&gt;</span> <span class="o">[&gt;</span> <span class="n">tag</span><span class="o">]</span> <span class="nn">Obj</span><span class="p">.</span><span class="n">t</span> <span class="o">-&gt;</span> <span class="o">[&gt;`</span><span class="nc">ArrayLike</span><span class="o">]</span> <span class="nn">Np</span><span class="p">.</span><span class="nn">Obj</span><span class="p">.</span><span class="n">t</span>
</code></pre></div>

<p>Predict confidence scores for samples.</p>
<p>The confidence score for a sample is the signed distance of that
sample to the hyperplane.</p>
<h2 id="parameters_88">Parameters<a class="headerlink" href="#parameters_88" title="Permanent link">&para;</a></h2>
<p>X : array_like or sparse matrix, shape (n_samples, n_features)
Samples.</p>
<h2 id="returns_71">Returns<a class="headerlink" href="#returns_71" title="Permanent link">&para;</a></h2>
<p>array, shape=(n_samples,) if n_classes == 2 else (n_samples, n_classes)
Confidence scores per (sample, class) combination. In the binary
case, confidence score for self.classes_[1] where &gt;0 means this
class would be predicted.</p>
<div class="highlight"><pre><span></span><code><span class="k">val</span> <span class="n">densify</span> <span class="o">:</span> <span class="o">[&gt;</span> <span class="n">tag</span><span class="o">]</span> <span class="nn">Obj</span><span class="p">.</span><span class="n">t</span> <span class="o">-&gt;</span> <span class="n">t</span>
</code></pre></div>

<p>Convert coefficient matrix to dense array format.</p>
<p>Converts the <code>coef_</code> member (back) to a numpy.ndarray. This is the
default format of <code>coef_</code> and is required for fitting, so calling
this method is only required on models that have previously been
sparsified; otherwise, it is a no-op.</p>
<h2 id="returns_72">Returns<a class="headerlink" href="#returns_72" title="Permanent link">&para;</a></h2>
<p>self
Fitted estimator.</p>
<div class="highlight"><pre><span></span><code><span class="k">val</span> <span class="n">fit</span> <span class="o">:</span> <span class="o">?</span><span class="n">sample_weight</span><span class="o">:[&gt;`</span><span class="nc">ArrayLike</span><span class="o">]</span> <span class="nn">Np</span><span class="p">.</span><span class="nn">Obj</span><span class="p">.</span><span class="n">t</span> <span class="o">-&gt;</span> <span class="n">x</span><span class="o">:[&gt;`</span><span class="nc">ArrayLike</span><span class="o">]</span> <span class="nn">Np</span><span class="p">.</span><span class="nn">Obj</span><span class="p">.</span><span class="n">t</span> <span class="o">-&gt;</span> <span class="n">y</span><span class="o">:[&gt;`</span><span class="nc">ArrayLike</span><span class="o">]</span> <span class="nn">Np</span><span class="p">.</span><span class="nn">Obj</span><span class="p">.</span><span class="n">t</span> <span class="o">-&gt;</span> <span class="o">[&gt;</span> <span class="n">tag</span><span class="o">]</span> <span class="nn">Obj</span><span class="p">.</span><span class="n">t</span> <span class="o">-&gt;</span> <span class="n">t</span>
</code></pre></div>

<p>Fit the model according to the given training data.</p>
<h2 id="parameters_89">Parameters<a class="headerlink" href="#parameters_89" title="Permanent link">&para;</a></h2>
<p>X : {array-like, sparse matrix} of shape (n_samples, n_features)
Training vector, where n_samples is the number of samples and
n_features is the number of features.</p>
<p>y : array-like of shape (n_samples,)
Target vector relative to X.</p>
<p>sample_weight : array-like of shape (n_samples,) default=None
Array of weights that are assigned to individual samples.
If not provided, then each sample is given unit weight.</p>
<h2 id="returns_73">Returns<a class="headerlink" href="#returns_73" title="Permanent link">&para;</a></h2>
<p>self : object</p>
<div class="highlight"><pre><span></span><code><span class="k">val</span> <span class="n">get_params</span> <span class="o">:</span> <span class="o">?</span><span class="n">deep</span><span class="o">:</span><span class="kt">bool</span> <span class="o">-&gt;</span> <span class="o">[&gt;</span> <span class="n">tag</span><span class="o">]</span> <span class="nn">Obj</span><span class="p">.</span><span class="n">t</span> <span class="o">-&gt;</span> <span class="nn">Dict</span><span class="p">.</span><span class="n">t</span>
</code></pre></div>

<p>Get parameters for this estimator.</p>
<h2 id="parameters_90">Parameters<a class="headerlink" href="#parameters_90" title="Permanent link">&para;</a></h2>
<p>deep : bool, default=True
If True, will return the parameters for this estimator and
contained subobjects that are estimators.</p>
<h2 id="returns_74">Returns<a class="headerlink" href="#returns_74" title="Permanent link">&para;</a></h2>
<p>params : mapping of string to any
Parameter names mapped to their values.</p>
<div class="highlight"><pre><span></span><code><span class="k">val</span> <span class="n">predict</span> <span class="o">:</span> <span class="n">x</span><span class="o">:[&gt;`</span><span class="nc">ArrayLike</span><span class="o">]</span> <span class="nn">Np</span><span class="p">.</span><span class="nn">Obj</span><span class="p">.</span><span class="n">t</span> <span class="o">-&gt;</span> <span class="o">[&gt;</span> <span class="n">tag</span><span class="o">]</span> <span class="nn">Obj</span><span class="p">.</span><span class="n">t</span> <span class="o">-&gt;</span> <span class="o">[&gt;`</span><span class="nc">ArrayLike</span><span class="o">]</span> <span class="nn">Np</span><span class="p">.</span><span class="nn">Obj</span><span class="p">.</span><span class="n">t</span>
</code></pre></div>

<p>Predict class labels for samples in X.</p>
<h2 id="parameters_91">Parameters<a class="headerlink" href="#parameters_91" title="Permanent link">&para;</a></h2>
<p>X : array_like or sparse matrix, shape (n_samples, n_features)
Samples.</p>
<h2 id="returns_75">Returns<a class="headerlink" href="#returns_75" title="Permanent link">&para;</a></h2>
<p>C : array, shape [n_samples]
Predicted class label per sample.</p>
<div class="highlight"><pre><span></span><code><span class="k">val</span> <span class="n">predict_log_proba</span> <span class="o">:</span> <span class="n">x</span><span class="o">:[&gt;`</span><span class="nc">ArrayLike</span><span class="o">]</span> <span class="nn">Np</span><span class="p">.</span><span class="nn">Obj</span><span class="p">.</span><span class="n">t</span> <span class="o">-&gt;</span> <span class="o">[&gt;</span> <span class="n">tag</span><span class="o">]</span> <span class="nn">Obj</span><span class="p">.</span><span class="n">t</span> <span class="o">-&gt;</span> <span class="o">[&gt;`</span><span class="nc">ArrayLike</span><span class="o">]</span> <span class="nn">Np</span><span class="p">.</span><span class="nn">Obj</span><span class="p">.</span><span class="n">t</span>
</code></pre></div>

<p>Predict logarithm of probability estimates.</p>
<p>The returned estimates for all classes are ordered by the
label of classes.</p>
<h2 id="parameters_92">Parameters<a class="headerlink" href="#parameters_92" title="Permanent link">&para;</a></h2>
<p>X : array-like of shape (n_samples, n_features)
Vector to be scored, where <code>n_samples</code> is the number of samples and
<code>n_features</code> is the number of features.</p>
<h2 id="returns_76">Returns<a class="headerlink" href="#returns_76" title="Permanent link">&para;</a></h2>
<p>T : array-like of shape (n_samples, n_classes)
Returns the log-probability of the sample for each class in the
model, where classes are ordered as they are in <code>self.classes_</code>.</p>
<div class="highlight"><pre><span></span><code><span class="k">val</span> <span class="n">predict_proba</span> <span class="o">:</span> <span class="n">x</span><span class="o">:[&gt;`</span><span class="nc">ArrayLike</span><span class="o">]</span> <span class="nn">Np</span><span class="p">.</span><span class="nn">Obj</span><span class="p">.</span><span class="n">t</span> <span class="o">-&gt;</span> <span class="o">[&gt;</span> <span class="n">tag</span><span class="o">]</span> <span class="nn">Obj</span><span class="p">.</span><span class="n">t</span> <span class="o">-&gt;</span> <span class="o">[&gt;`</span><span class="nc">ArrayLike</span><span class="o">]</span> <span class="nn">Np</span><span class="p">.</span><span class="nn">Obj</span><span class="p">.</span><span class="n">t</span>
</code></pre></div>

<p>Probability estimates.</p>
<p>The returned estimates for all classes are ordered by the
label of classes.</p>
<p>For a multi_class problem, if multi_class is set to be 'multinomial'
the softmax function is used to find the predicted probability of
each class.
Else use a one-vs-rest approach, i.e calculate the probability
of each class assuming it to be positive using the logistic function.
and normalize these values across all the classes.</p>
<h2 id="parameters_93">Parameters<a class="headerlink" href="#parameters_93" title="Permanent link">&para;</a></h2>
<p>X : array-like of shape (n_samples, n_features)
Vector to be scored, where <code>n_samples</code> is the number of samples and
<code>n_features</code> is the number of features.</p>
<h2 id="returns_77">Returns<a class="headerlink" href="#returns_77" title="Permanent link">&para;</a></h2>
<p>T : array-like of shape (n_samples, n_classes)
Returns the probability of the sample for each class in the model,
where classes are ordered as they are in <code>self.classes_</code>.</p>
<div class="highlight"><pre><span></span><code><span class="k">val</span> <span class="n">score</span> <span class="o">:</span> <span class="o">?</span><span class="n">sample_weight</span><span class="o">:[&gt;`</span><span class="nc">ArrayLike</span><span class="o">]</span> <span class="nn">Np</span><span class="p">.</span><span class="nn">Obj</span><span class="p">.</span><span class="n">t</span> <span class="o">-&gt;</span> <span class="n">x</span><span class="o">:[&gt;`</span><span class="nc">ArrayLike</span><span class="o">]</span> <span class="nn">Np</span><span class="p">.</span><span class="nn">Obj</span><span class="p">.</span><span class="n">t</span> <span class="o">-&gt;</span> <span class="n">y</span><span class="o">:[&gt;`</span><span class="nc">ArrayLike</span><span class="o">]</span> <span class="nn">Np</span><span class="p">.</span><span class="nn">Obj</span><span class="p">.</span><span class="n">t</span> <span class="o">-&gt;</span> <span class="o">[&gt;</span> <span class="n">tag</span><span class="o">]</span> <span class="nn">Obj</span><span class="p">.</span><span class="n">t</span> <span class="o">-&gt;</span> <span class="kt">float</span>
</code></pre></div>

<p>Returns the score using the <code>scoring</code> option on the given
test data and labels.</p>
<h2 id="parameters_94">Parameters<a class="headerlink" href="#parameters_94" title="Permanent link">&para;</a></h2>
<p>X : array-like of shape (n_samples, n_features)
Test samples.</p>
<p>y : array-like of shape (n_samples,)
True labels for X.</p>
<p>sample_weight : array-like of shape (n_samples,), default=None
Sample weights.</p>
<h2 id="returns_78">Returns<a class="headerlink" href="#returns_78" title="Permanent link">&para;</a></h2>
<p>score : float
Score of self.predict(X) wrt. y.</p>
<div class="highlight"><pre><span></span><code><span class="k">val</span> <span class="n">set_params</span> <span class="o">:</span> <span class="o">?</span><span class="n">params</span><span class="o">:(</span><span class="kt">string</span> <span class="o">*</span> <span class="nn">Py</span><span class="p">.</span><span class="nn">Object</span><span class="p">.</span><span class="n">t</span><span class="o">)</span> <span class="kt">list</span> <span class="o">-&gt;</span> <span class="o">[&gt;</span> <span class="n">tag</span><span class="o">]</span> <span class="nn">Obj</span><span class="p">.</span><span class="n">t</span> <span class="o">-&gt;</span> <span class="n">t</span>
</code></pre></div>

<p>Set the parameters of this estimator.</p>
<p>The method works on simple estimators as well as on nested objects
(such as pipelines). The latter have parameters of the form
<code>&lt;component&gt;__&lt;parameter&gt;</code> so that it's possible to update each
component of a nested object.</p>
<h2 id="parameters_95">Parameters<a class="headerlink" href="#parameters_95" title="Permanent link">&para;</a></h2>
<p>**params : dict
Estimator parameters.</p>
<h2 id="returns_79">Returns<a class="headerlink" href="#returns_79" title="Permanent link">&para;</a></h2>
<p>self : object
Estimator instance.</p>
<div class="highlight"><pre><span></span><code><span class="k">val</span> <span class="n">sparsify</span> <span class="o">:</span> <span class="o">[&gt;</span> <span class="n">tag</span><span class="o">]</span> <span class="nn">Obj</span><span class="p">.</span><span class="n">t</span> <span class="o">-&gt;</span> <span class="n">t</span>
</code></pre></div>

<p>Convert coefficient matrix to sparse format.</p>
<p>Converts the <code>coef_</code> member to a scipy.sparse matrix, which for
L1-regularized models can be much more memory- and storage-efficient
than the usual numpy.ndarray representation.</p>
<p>The <code>intercept_</code> member is not converted.</p>
<h2 id="returns_80">Returns<a class="headerlink" href="#returns_80" title="Permanent link">&para;</a></h2>
<p>self
Fitted estimator.</p>
<h2 id="notes_27">Notes<a class="headerlink" href="#notes_27" title="Permanent link">&para;</a></h2>
<p>For non-sparse models, i.e. when there are not many zeros in <code>coef_</code>,
this may actually <em>increase</em> memory usage, so use this method with
care. A rule of thumb is that the number of zero elements, which can
be computed with <code>(coef_ == 0).sum()</code>, must be more than 50% for this
to provide significant benefits.</p>
<p>After calling this method, further fitting with the partial_fit
method (if any) will not work until you call densify.</p>
<p>Attribute classes_: get value or raise Not_found if None.</p>
<div class="highlight"><pre><span></span><code><span class="k">val</span> <span class="n">classes_</span> <span class="o">:</span> <span class="n">t</span> <span class="o">-&gt;</span> <span class="o">[&gt;`</span><span class="nc">ArrayLike</span><span class="o">]</span> <span class="nn">Np</span><span class="p">.</span><span class="nn">Obj</span><span class="p">.</span><span class="n">t</span>
</code></pre></div>

<p>Attribute classes_: get value as an option.</p>
<div class="highlight"><pre><span></span><code><span class="k">val</span> <span class="n">classes_opt</span> <span class="o">:</span> <span class="n">t</span> <span class="o">-&gt;</span> <span class="o">([&gt;`</span><span class="nc">ArrayLike</span><span class="o">]</span> <span class="nn">Np</span><span class="p">.</span><span class="nn">Obj</span><span class="p">.</span><span class="n">t</span><span class="o">)</span> <span class="n">option</span>
</code></pre></div>

<p>Attribute coef_: get value or raise Not_found if None.</p>
<div class="highlight"><pre><span></span><code><span class="k">val</span> <span class="n">coef_</span> <span class="o">:</span> <span class="n">t</span> <span class="o">-&gt;</span> <span class="o">[&gt;`</span><span class="nc">ArrayLike</span><span class="o">]</span> <span class="nn">Np</span><span class="p">.</span><span class="nn">Obj</span><span class="p">.</span><span class="n">t</span>
</code></pre></div>

<p>Attribute coef_: get value as an option.</p>
<div class="highlight"><pre><span></span><code><span class="k">val</span> <span class="n">coef_opt</span> <span class="o">:</span> <span class="n">t</span> <span class="o">-&gt;</span> <span class="o">([&gt;`</span><span class="nc">ArrayLike</span><span class="o">]</span> <span class="nn">Np</span><span class="p">.</span><span class="nn">Obj</span><span class="p">.</span><span class="n">t</span><span class="o">)</span> <span class="n">option</span>
</code></pre></div>

<p>Attribute intercept_: get value or raise Not_found if None.</p>
<div class="highlight"><pre><span></span><code><span class="k">val</span> <span class="n">intercept_</span> <span class="o">:</span> <span class="n">t</span> <span class="o">-&gt;</span> <span class="o">[&gt;`</span><span class="nc">ArrayLike</span><span class="o">]</span> <span class="nn">Np</span><span class="p">.</span><span class="nn">Obj</span><span class="p">.</span><span class="n">t</span>
</code></pre></div>

<p>Attribute intercept_: get value as an option.</p>
<div class="highlight"><pre><span></span><code><span class="k">val</span> <span class="n">intercept_opt</span> <span class="o">:</span> <span class="n">t</span> <span class="o">-&gt;</span> <span class="o">([&gt;`</span><span class="nc">ArrayLike</span><span class="o">]</span> <span class="nn">Np</span><span class="p">.</span><span class="nn">Obj</span><span class="p">.</span><span class="n">t</span><span class="o">)</span> <span class="n">option</span>
</code></pre></div>

<p>Attribute Cs_: get value or raise Not_found if None.</p>
<div class="highlight"><pre><span></span><code><span class="k">val</span> <span class="n">cs_</span> <span class="o">:</span> <span class="n">t</span> <span class="o">-&gt;</span> <span class="o">[&gt;`</span><span class="nc">ArrayLike</span><span class="o">]</span> <span class="nn">Np</span><span class="p">.</span><span class="nn">Obj</span><span class="p">.</span><span class="n">t</span>
</code></pre></div>

<p>Attribute Cs_: get value as an option.</p>
<div class="highlight"><pre><span></span><code><span class="k">val</span> <span class="n">cs_opt</span> <span class="o">:</span> <span class="n">t</span> <span class="o">-&gt;</span> <span class="o">([&gt;`</span><span class="nc">ArrayLike</span><span class="o">]</span> <span class="nn">Np</span><span class="p">.</span><span class="nn">Obj</span><span class="p">.</span><span class="n">t</span><span class="o">)</span> <span class="n">option</span>
</code></pre></div>

<p>Attribute l1_ratios_: get value or raise Not_found if None.</p>
<div class="highlight"><pre><span></span><code><span class="k">val</span> <span class="n">l1_ratios_</span> <span class="o">:</span> <span class="n">t</span> <span class="o">-&gt;</span> <span class="o">[&gt;`</span><span class="nc">ArrayLike</span><span class="o">]</span> <span class="nn">Np</span><span class="p">.</span><span class="nn">Obj</span><span class="p">.</span><span class="n">t</span>
</code></pre></div>

<p>Attribute l1_ratios_: get value as an option.</p>
<div class="highlight"><pre><span></span><code><span class="k">val</span> <span class="n">l1_ratios_opt</span> <span class="o">:</span> <span class="n">t</span> <span class="o">-&gt;</span> <span class="o">([&gt;`</span><span class="nc">ArrayLike</span><span class="o">]</span> <span class="nn">Np</span><span class="p">.</span><span class="nn">Obj</span><span class="p">.</span><span class="n">t</span><span class="o">)</span> <span class="n">option</span>
</code></pre></div>

<p>Attribute coefs_paths_: get value or raise Not_found if None.</p>
<div class="highlight"><pre><span></span><code><span class="k">val</span> <span class="n">coefs_paths_</span> <span class="o">:</span> <span class="n">t</span> <span class="o">-&gt;</span> <span class="o">[&gt;`</span><span class="nc">ArrayLike</span><span class="o">]</span> <span class="nn">Np</span><span class="p">.</span><span class="nn">Obj</span><span class="p">.</span><span class="n">t</span>
</code></pre></div>

<p>Attribute coefs_paths_: get value as an option.</p>
<div class="highlight"><pre><span></span><code><span class="k">val</span> <span class="n">coefs_paths_opt</span> <span class="o">:</span> <span class="n">t</span> <span class="o">-&gt;</span> <span class="o">([&gt;`</span><span class="nc">ArrayLike</span><span class="o">]</span> <span class="nn">Np</span><span class="p">.</span><span class="nn">Obj</span><span class="p">.</span><span class="n">t</span><span class="o">)</span> <span class="n">option</span>
</code></pre></div>

<p>Attribute scores_: get value or raise Not_found if None.</p>
<div class="highlight"><pre><span></span><code><span class="k">val</span> <span class="n">scores_</span> <span class="o">:</span> <span class="n">t</span> <span class="o">-&gt;</span> <span class="nn">Dict</span><span class="p">.</span><span class="n">t</span>
</code></pre></div>

<p>Attribute scores_: get value as an option.</p>
<div class="highlight"><pre><span></span><code><span class="k">val</span> <span class="n">scores_opt</span> <span class="o">:</span> <span class="n">t</span> <span class="o">-&gt;</span> <span class="o">(</span><span class="nn">Dict</span><span class="p">.</span><span class="n">t</span><span class="o">)</span> <span class="n">option</span>
</code></pre></div>

<p>Attribute C_: get value or raise Not_found if None.</p>
<div class="highlight"><pre><span></span><code><span class="k">val</span> <span class="n">c_</span> <span class="o">:</span> <span class="n">t</span> <span class="o">-&gt;</span> <span class="o">[&gt;`</span><span class="nc">ArrayLike</span><span class="o">]</span> <span class="nn">Np</span><span class="p">.</span><span class="nn">Obj</span><span class="p">.</span><span class="n">t</span>
</code></pre></div>

<p>Attribute C_: get value as an option.</p>
<div class="highlight"><pre><span></span><code><span class="k">val</span> <span class="n">c_opt</span> <span class="o">:</span> <span class="n">t</span> <span class="o">-&gt;</span> <span class="o">([&gt;`</span><span class="nc">ArrayLike</span><span class="o">]</span> <span class="nn">Np</span><span class="p">.</span><span class="nn">Obj</span><span class="p">.</span><span class="n">t</span><span class="o">)</span> <span class="n">option</span>
</code></pre></div>

<p>Attribute l1_ratio_: get value or raise Not_found if None.</p>
<div class="highlight"><pre><span></span><code><span class="k">val</span> <span class="n">l1_ratio_</span> <span class="o">:</span> <span class="n">t</span> <span class="o">-&gt;</span> <span class="o">[&gt;`</span><span class="nc">ArrayLike</span><span class="o">]</span> <span class="nn">Np</span><span class="p">.</span><span class="nn">Obj</span><span class="p">.</span><span class="n">t</span>
</code></pre></div>

<p>Attribute l1_ratio_: get value as an option.</p>
<div class="highlight"><pre><span></span><code><span class="k">val</span> <span class="n">l1_ratio_opt</span> <span class="o">:</span> <span class="n">t</span> <span class="o">-&gt;</span> <span class="o">([&gt;`</span><span class="nc">ArrayLike</span><span class="o">]</span> <span class="nn">Np</span><span class="p">.</span><span class="nn">Obj</span><span class="p">.</span><span class="n">t</span><span class="o">)</span> <span class="n">option</span>
</code></pre></div>

<p>Attribute n_iter_: get value or raise Not_found if None.</p>
<div class="highlight"><pre><span></span><code><span class="k">val</span> <span class="n">n_iter_</span> <span class="o">:</span> <span class="n">t</span> <span class="o">-&gt;</span> <span class="o">[&gt;`</span><span class="nc">ArrayLike</span><span class="o">]</span> <span class="nn">Np</span><span class="p">.</span><span class="nn">Obj</span><span class="p">.</span><span class="n">t</span>
</code></pre></div>

<p>Attribute n_iter_: get value as an option.</p>
<div class="highlight"><pre><span></span><code><span class="k">val</span> <span class="n">n_iter_opt</span> <span class="o">:</span> <span class="n">t</span> <span class="o">-&gt;</span> <span class="o">([&gt;`</span><span class="nc">ArrayLike</span><span class="o">]</span> <span class="nn">Np</span><span class="p">.</span><span class="nn">Obj</span><span class="p">.</span><span class="n">t</span><span class="o">)</span> <span class="n">option</span>
</code></pre></div>

<p>Print the object to a human-readable representation.</p>
<div class="highlight"><pre><span></span><code><span class="k">val</span> <span class="n">to_string</span> <span class="o">:</span> <span class="n">t</span> <span class="o">-&gt;</span> <span class="kt">string</span>
</code></pre></div>

<p>Print the object to a human-readable representation.</p>
<div class="highlight"><pre><span></span><code><span class="k">val</span> <span class="n">show</span> <span class="o">:</span> <span class="n">t</span> <span class="o">-&gt;</span> <span class="kt">string</span>
</code></pre></div>

<p>Pretty-print the object to a formatter.</p>
<div class="highlight"><pre><span></span><code><span class="k">val</span> <span class="n">pp</span> <span class="o">:</span> <span class="nn">Format</span><span class="p">.</span><span class="n">formatter</span> <span class="o">-&gt;</span> <span class="n">t</span> <span class="o">-&gt;</span> <span class="kt">unit</span> <span class="o">[@@</span><span class="n">ocaml</span><span class="o">.</span><span class="n">toplevel_printer</span><span class="o">]</span>



<span class="k">module</span> <span class="nc">ModifiedHuber</span> <span class="o">:</span> <span class="k">sig</span>
<span class="k">type</span> <span class="n">tag</span> <span class="o">=</span> <span class="o">[`</span><span class="nc">ModifiedHuber</span><span class="o">]</span>
<span class="k">type</span> <span class="n">t</span> <span class="o">=</span> <span class="o">[`</span><span class="nc">ModifiedHuber</span> <span class="o">|</span> <span class="o">`</span><span class="nc">Object</span><span class="o">]</span> <span class="nn">Obj</span><span class="p">.</span><span class="n">t</span>
<span class="k">val</span> <span class="n">of_pyobject</span> <span class="o">:</span> <span class="nn">Py</span><span class="p">.</span><span class="nn">Object</span><span class="p">.</span><span class="n">t</span> <span class="o">-&gt;</span> <span class="n">t</span>
<span class="k">val</span> <span class="n">to_pyobject</span> <span class="o">:</span> <span class="o">[&gt;</span> <span class="n">tag</span><span class="o">]</span> <span class="nn">Obj</span><span class="p">.</span><span class="n">t</span> <span class="o">-&gt;</span> <span class="nn">Py</span><span class="p">.</span><span class="nn">Object</span><span class="p">.</span><span class="n">t</span>
</code></pre></div>

<p>Print the object to a human-readable representation.</p>
<div class="highlight"><pre><span></span><code><span class="k">val</span> <span class="n">to_string</span> <span class="o">:</span> <span class="n">t</span> <span class="o">-&gt;</span> <span class="kt">string</span>
</code></pre></div>

<p>Print the object to a human-readable representation.</p>
<div class="highlight"><pre><span></span><code><span class="k">val</span> <span class="n">show</span> <span class="o">:</span> <span class="n">t</span> <span class="o">-&gt;</span> <span class="kt">string</span>
</code></pre></div>

<p>Pretty-print the object to a formatter.</p>
<div class="highlight"><pre><span></span><code><span class="k">val</span> <span class="n">pp</span> <span class="o">:</span> <span class="nn">Format</span><span class="p">.</span><span class="n">formatter</span> <span class="o">-&gt;</span> <span class="n">t</span> <span class="o">-&gt;</span> <span class="kt">unit</span> <span class="o">[@@</span><span class="n">ocaml</span><span class="o">.</span><span class="n">toplevel_printer</span><span class="o">]</span>



<span class="k">module</span> <span class="nc">MultiTaskElasticNet</span> <span class="o">:</span> <span class="k">sig</span>
<span class="k">type</span> <span class="n">tag</span> <span class="o">=</span> <span class="o">[`</span><span class="nc">MultiTaskElasticNet</span><span class="o">]</span>
<span class="k">type</span> <span class="n">t</span> <span class="o">=</span> <span class="o">[`</span><span class="nc">BaseEstimator</span> <span class="o">|</span> <span class="o">`</span><span class="nc">MultiOutputMixin</span> <span class="o">|</span> <span class="o">`</span><span class="nc">MultiTaskElasticNet</span> <span class="o">|</span> <span class="o">`</span><span class="nc">Object</span> <span class="o">|</span> <span class="o">`</span><span class="nc">RegressorMixin</span><span class="o">]</span> <span class="nn">Obj</span><span class="p">.</span><span class="n">t</span>
<span class="k">val</span> <span class="n">of_pyobject</span> <span class="o">:</span> <span class="nn">Py</span><span class="p">.</span><span class="nn">Object</span><span class="p">.</span><span class="n">t</span> <span class="o">-&gt;</span> <span class="n">t</span>
<span class="k">val</span> <span class="n">to_pyobject</span> <span class="o">:</span> <span class="o">[&gt;</span> <span class="n">tag</span><span class="o">]</span> <span class="nn">Obj</span><span class="p">.</span><span class="n">t</span> <span class="o">-&gt;</span> <span class="nn">Py</span><span class="p">.</span><span class="nn">Object</span><span class="p">.</span><span class="n">t</span>

<span class="k">val</span> <span class="n">as_regressor</span> <span class="o">:</span> <span class="n">t</span> <span class="o">-&gt;</span> <span class="o">[`</span><span class="nc">RegressorMixin</span><span class="o">]</span> <span class="nn">Obj</span><span class="p">.</span><span class="n">t</span>
<span class="k">val</span> <span class="n">as_multi_output</span> <span class="o">:</span> <span class="n">t</span> <span class="o">-&gt;</span> <span class="o">[`</span><span class="nc">MultiOutputMixin</span><span class="o">]</span> <span class="nn">Obj</span><span class="p">.</span><span class="n">t</span>
<span class="k">val</span> <span class="n">as_estimator</span> <span class="o">:</span> <span class="n">t</span> <span class="o">-&gt;</span> <span class="o">[`</span><span class="nc">BaseEstimator</span><span class="o">]</span> <span class="nn">Obj</span><span class="p">.</span><span class="n">t</span>
<span class="k">val</span> <span class="n">create</span> <span class="o">:</span> <span class="o">?</span><span class="n">alpha</span><span class="o">:</span><span class="kt">float</span> <span class="o">-&gt;</span> <span class="o">?</span><span class="n">l1_ratio</span><span class="o">:</span><span class="kt">float</span> <span class="o">-&gt;</span> <span class="o">?</span><span class="n">fit_intercept</span><span class="o">:</span><span class="kt">bool</span> <span class="o">-&gt;</span> <span class="o">?</span><span class="n">normalize</span><span class="o">:</span><span class="kt">bool</span> <span class="o">-&gt;</span> <span class="o">?</span><span class="n">copy_X</span><span class="o">:</span><span class="kt">bool</span> <span class="o">-&gt;</span> <span class="o">?</span><span class="n">max_iter</span><span class="o">:</span><span class="kt">int</span> <span class="o">-&gt;</span> <span class="o">?</span><span class="n">tol</span><span class="o">:</span><span class="kt">float</span> <span class="o">-&gt;</span> <span class="o">?</span><span class="n">warm_start</span><span class="o">:</span><span class="kt">bool</span> <span class="o">-&gt;</span> <span class="o">?</span><span class="n">random_state</span><span class="o">:</span><span class="kt">int</span> <span class="o">-&gt;</span> <span class="o">?</span><span class="n">selection</span><span class="o">:</span><span class="kt">string</span> <span class="o">-&gt;</span> <span class="kt">unit</span> <span class="o">-&gt;</span> <span class="n">t</span>
</code></pre></div>

<p>Multi-task ElasticNet model trained with L1/L2 mixed-norm as regularizer</p>
<p>The optimization objective for MultiTaskElasticNet is::</p>
<p>(1 / (2 * n_samples)) * ||Y - XW||_Fro^2
+ alpha * l1_ratio * ||W||_21
+ 0.5 * alpha * (1 - l1_ratio) * ||W||_Fro^2</p>
<p>Where::</p>
<p>||W||_21 = sum_i sqrt(sum_j w_ij ^ 2)</p>
<p>i.e. the sum of norm of each row.</p>
<p>Read more in the :ref:<code>User Guide &lt;multi_task_elastic_net&gt;</code>.</p>
<h2 id="parameters_96">Parameters<a class="headerlink" href="#parameters_96" title="Permanent link">&para;</a></h2>
<p>alpha : float, optional
Constant that multiplies the L1/L2 term. Defaults to 1.0</p>
<p>l1_ratio : float
The ElasticNet mixing parameter, with 0 &lt; l1_ratio &lt;= 1.
For l1_ratio = 1 the penalty is an L1/L2 penalty. For l1_ratio = 0 it
is an L2 penalty.
For <code>0 &lt; l1_ratio &lt; 1</code>, the penalty is a combination of L1/L2 and L2.</p>
<p>fit_intercept : boolean
whether to calculate the intercept for this model. If set
to false, no intercept will be used in calculations
(i.e. data is expected to be centered).</p>
<p>normalize : boolean, optional, default False
This parameter is ignored when <code>fit_intercept</code> is set to False.
If True, the regressors X will be normalized before regression by
subtracting the mean and dividing by the l2-norm.
If you wish to standardize, please use
:class:<code>sklearn.preprocessing.StandardScaler</code> before calling <code>fit</code>
on an estimator with <code>normalize=False</code>.</p>
<p>copy_X : boolean, optional, default True
If <code>True</code>, X will be copied; else, it may be overwritten.</p>
<p>max_iter : int, optional
The maximum number of iterations</p>
<p>tol : float, optional
The tolerance for the optimization: if the updates are
smaller than <code>tol</code>, the optimization code checks the
dual gap for optimality and continues until it is smaller
than <code>tol</code>.</p>
<p>warm_start : bool, optional
When set to <code>True</code>, reuse the solution of the previous call to fit as
initialization, otherwise, just erase the previous solution.
See :term:<code>the Glossary &lt;warm_start&gt;</code>.</p>
<p>random_state : int, RandomState instance or None, optional, default None
The seed of the pseudo random number generator that selects a random
feature to update.  If int, random_state is the seed used by the random
number generator; If RandomState instance, random_state is the random
number generator; If None, the random number generator is the
RandomState instance used by <code>np.random</code>. Used when <code>selection</code> ==
'random'.</p>
<p>selection : str, default 'cyclic'
If set to 'random', a random coefficient is updated every iteration
rather than looping over features sequentially by default. This
(setting to 'random') often leads to significantly faster convergence
especially when tol is higher than 1e-4.</p>
<h2 id="attributes_15">Attributes<a class="headerlink" href="#attributes_15" title="Permanent link">&para;</a></h2>
<p>intercept_ : array, shape (n_tasks,)
Independent term in decision function.</p>
<p>coef_ : array, shape (n_tasks, n_features)
Parameter vector (W in the cost function formula). If a 1D y is
passed in at fit (non multi-task usage), <code>coef_</code> is then a 1D array.
Note that <code>coef_</code> stores the transpose of <code>W</code>, <code>W.T</code>.</p>
<p>n_iter_ : int
number of iterations run by the coordinate descent solver to reach
the specified tolerance.</p>
<h2 id="examples_15">Examples<a class="headerlink" href="#examples_15" title="Permanent link">&para;</a></h2>
<blockquote>
<blockquote>
<blockquote>
<p>from sklearn import linear_model
clf = linear_model.MultiTaskElasticNet(alpha=0.1)
clf.fit([[0,0], [1, 1], [2, 2]], [[0, 0], [1, 1], [2, 2]])
MultiTaskElasticNet(alpha=0.1)
print(clf.coef_)
[[0.45663524 0.45612256]
[0.45663524 0.45612256]]
print(clf.intercept_)
[0.0872422 0.0872422]</p>
</blockquote>
</blockquote>
</blockquote>
<h2 id="see-also_12">See also<a class="headerlink" href="#see-also_12" title="Permanent link">&para;</a></h2>
<p>MultiTaskElasticNet : Multi-task L1/L2 ElasticNet with built-in
cross-validation.
ElasticNet
MultiTaskLasso</p>
<h2 id="notes_28">Notes<a class="headerlink" href="#notes_28" title="Permanent link">&para;</a></h2>
<p>The algorithm used to fit the model is coordinate descent.</p>
<p>To avoid unnecessary memory duplication the X argument of the fit method
should be directly passed as a Fortran-contiguous numpy array.</p>
<div class="highlight"><pre><span></span><code><span class="k">val</span> <span class="n">fit</span> <span class="o">:</span> <span class="n">x</span><span class="o">:[&gt;`</span><span class="nc">ArrayLike</span><span class="o">]</span> <span class="nn">Np</span><span class="p">.</span><span class="nn">Obj</span><span class="p">.</span><span class="n">t</span> <span class="o">-&gt;</span> <span class="n">y</span><span class="o">:[&gt;`</span><span class="nc">ArrayLike</span><span class="o">]</span> <span class="nn">Np</span><span class="p">.</span><span class="nn">Obj</span><span class="p">.</span><span class="n">t</span> <span class="o">-&gt;</span> <span class="o">[&gt;</span> <span class="n">tag</span><span class="o">]</span> <span class="nn">Obj</span><span class="p">.</span><span class="n">t</span> <span class="o">-&gt;</span> <span class="n">t</span>
</code></pre></div>

<p>Fit MultiTaskElasticNet model with coordinate descent</p>
<h2 id="parameters_97">Parameters<a class="headerlink" href="#parameters_97" title="Permanent link">&para;</a></h2>
<p>X : ndarray, shape (n_samples, n_features)
Data
y : ndarray, shape (n_samples, n_tasks)
Target. Will be cast to X's dtype if necessary</p>
<h2 id="notes_29">Notes<a class="headerlink" href="#notes_29" title="Permanent link">&para;</a></h2>
<p>Coordinate descent is an algorithm that considers each column of
data at a time hence it will automatically convert the X input
as a Fortran-contiguous numpy array if necessary.</p>
<p>To avoid memory re-allocation it is advised to allocate the
initial data in memory directly using that format.</p>
<div class="highlight"><pre><span></span><code><span class="k">val</span> <span class="n">get_params</span> <span class="o">:</span> <span class="o">?</span><span class="n">deep</span><span class="o">:</span><span class="kt">bool</span> <span class="o">-&gt;</span> <span class="o">[&gt;</span> <span class="n">tag</span><span class="o">]</span> <span class="nn">Obj</span><span class="p">.</span><span class="n">t</span> <span class="o">-&gt;</span> <span class="nn">Dict</span><span class="p">.</span><span class="n">t</span>
</code></pre></div>

<p>Get parameters for this estimator.</p>
<h2 id="parameters_98">Parameters<a class="headerlink" href="#parameters_98" title="Permanent link">&para;</a></h2>
<p>deep : bool, default=True
If True, will return the parameters for this estimator and
contained subobjects that are estimators.</p>
<h2 id="returns_81">Returns<a class="headerlink" href="#returns_81" title="Permanent link">&para;</a></h2>
<p>params : mapping of string to any
Parameter names mapped to their values.</p>
<div class="highlight"><pre><span></span><code><span class="k">val</span> <span class="n">predict</span> <span class="o">:</span> <span class="n">x</span><span class="o">:[&gt;`</span><span class="nc">ArrayLike</span><span class="o">]</span> <span class="nn">Np</span><span class="p">.</span><span class="nn">Obj</span><span class="p">.</span><span class="n">t</span> <span class="o">-&gt;</span> <span class="o">[&gt;</span> <span class="n">tag</span><span class="o">]</span> <span class="nn">Obj</span><span class="p">.</span><span class="n">t</span> <span class="o">-&gt;</span> <span class="o">[&gt;`</span><span class="nc">ArrayLike</span><span class="o">]</span> <span class="nn">Np</span><span class="p">.</span><span class="nn">Obj</span><span class="p">.</span><span class="n">t</span>
</code></pre></div>

<p>Predict using the linear model.</p>
<h2 id="parameters_99">Parameters<a class="headerlink" href="#parameters_99" title="Permanent link">&para;</a></h2>
<p>X : array_like or sparse matrix, shape (n_samples, n_features)
Samples.</p>
<h2 id="returns_82">Returns<a class="headerlink" href="#returns_82" title="Permanent link">&para;</a></h2>
<p>C : array, shape (n_samples,)
Returns predicted values.</p>
<div class="highlight"><pre><span></span><code><span class="k">val</span> <span class="n">score</span> <span class="o">:</span> <span class="o">?</span><span class="n">sample_weight</span><span class="o">:[&gt;`</span><span class="nc">ArrayLike</span><span class="o">]</span> <span class="nn">Np</span><span class="p">.</span><span class="nn">Obj</span><span class="p">.</span><span class="n">t</span> <span class="o">-&gt;</span> <span class="n">x</span><span class="o">:[&gt;`</span><span class="nc">ArrayLike</span><span class="o">]</span> <span class="nn">Np</span><span class="p">.</span><span class="nn">Obj</span><span class="p">.</span><span class="n">t</span> <span class="o">-&gt;</span> <span class="n">y</span><span class="o">:[&gt;`</span><span class="nc">ArrayLike</span><span class="o">]</span> <span class="nn">Np</span><span class="p">.</span><span class="nn">Obj</span><span class="p">.</span><span class="n">t</span> <span class="o">-&gt;</span> <span class="o">[&gt;</span> <span class="n">tag</span><span class="o">]</span> <span class="nn">Obj</span><span class="p">.</span><span class="n">t</span> <span class="o">-&gt;</span> <span class="kt">float</span>
</code></pre></div>

<p>Return the coefficient of determination R^2 of the prediction.</p>
<p>The coefficient R^2 is defined as (1 - u/v), where u is the residual
sum of squares ((y_true - y_pred) <strong> 2).sum() and v is the total
sum of squares ((y_true - y_true.mean()) </strong> 2).sum().
The best possible score is 1.0 and it can be negative (because the
model can be arbitrarily worse). A constant model that always
predicts the expected value of y, disregarding the input features,
would get a R^2 score of 0.0.</p>
<h2 id="parameters_100">Parameters<a class="headerlink" href="#parameters_100" title="Permanent link">&para;</a></h2>
<p>X : array-like of shape (n_samples, n_features)
Test samples. For some estimators this may be a
precomputed kernel matrix or a list of generic objects instead,
shape = (n_samples, n_samples_fitted),
where n_samples_fitted is the number of
samples used in the fitting for the estimator.</p>
<p>y : array-like of shape (n_samples,) or (n_samples, n_outputs)
True values for X.</p>
<p>sample_weight : array-like of shape (n_samples,), default=None
Sample weights.</p>
<h2 id="returns_83">Returns<a class="headerlink" href="#returns_83" title="Permanent link">&para;</a></h2>
<p>score : float
R^2 of self.predict(X) wrt. y.</p>
<h2 id="notes_30">Notes<a class="headerlink" href="#notes_30" title="Permanent link">&para;</a></h2>
<p>The R2 score used when calling <code>score</code> on a regressor will use
<code>multioutput='uniform_average'</code> from version 0.23 to keep consistent
with :func:<code>~sklearn.metrics.r2_score</code>. This will influence the
<code>score</code> method of all the multioutput regressors (except for
:class:<code>~sklearn.multioutput.MultiOutputRegressor</code>). To specify the
default value manually and avoid the warning, please either call
:func:<code>~sklearn.metrics.r2_score</code> directly or make a custom scorer with
:func:<code>~sklearn.metrics.make_scorer</code> (the built-in scorer <code>'r2'</code> uses
<code>multioutput='uniform_average'</code>).</p>
<div class="highlight"><pre><span></span><code><span class="k">val</span> <span class="n">set_params</span> <span class="o">:</span> <span class="o">?</span><span class="n">params</span><span class="o">:(</span><span class="kt">string</span> <span class="o">*</span> <span class="nn">Py</span><span class="p">.</span><span class="nn">Object</span><span class="p">.</span><span class="n">t</span><span class="o">)</span> <span class="kt">list</span> <span class="o">-&gt;</span> <span class="o">[&gt;</span> <span class="n">tag</span><span class="o">]</span> <span class="nn">Obj</span><span class="p">.</span><span class="n">t</span> <span class="o">-&gt;</span> <span class="n">t</span>
</code></pre></div>

<p>Set the parameters of this estimator.</p>
<p>The method works on simple estimators as well as on nested objects
(such as pipelines). The latter have parameters of the form
<code>&lt;component&gt;__&lt;parameter&gt;</code> so that it's possible to update each
component of a nested object.</p>
<h2 id="parameters_101">Parameters<a class="headerlink" href="#parameters_101" title="Permanent link">&para;</a></h2>
<p>**params : dict
Estimator parameters.</p>
<h2 id="returns_84">Returns<a class="headerlink" href="#returns_84" title="Permanent link">&para;</a></h2>
<p>self : object
Estimator instance.</p>
<p>Attribute intercept_: get value or raise Not_found if None.</p>
<div class="highlight"><pre><span></span><code><span class="k">val</span> <span class="n">intercept_</span> <span class="o">:</span> <span class="n">t</span> <span class="o">-&gt;</span> <span class="o">[&gt;`</span><span class="nc">ArrayLike</span><span class="o">]</span> <span class="nn">Np</span><span class="p">.</span><span class="nn">Obj</span><span class="p">.</span><span class="n">t</span>
</code></pre></div>

<p>Attribute intercept_: get value as an option.</p>
<div class="highlight"><pre><span></span><code><span class="k">val</span> <span class="n">intercept_opt</span> <span class="o">:</span> <span class="n">t</span> <span class="o">-&gt;</span> <span class="o">([&gt;`</span><span class="nc">ArrayLike</span><span class="o">]</span> <span class="nn">Np</span><span class="p">.</span><span class="nn">Obj</span><span class="p">.</span><span class="n">t</span><span class="o">)</span> <span class="n">option</span>
</code></pre></div>

<p>Attribute coef_: get value or raise Not_found if None.</p>
<div class="highlight"><pre><span></span><code><span class="k">val</span> <span class="n">coef_</span> <span class="o">:</span> <span class="n">t</span> <span class="o">-&gt;</span> <span class="o">[&gt;`</span><span class="nc">ArrayLike</span><span class="o">]</span> <span class="nn">Np</span><span class="p">.</span><span class="nn">Obj</span><span class="p">.</span><span class="n">t</span>
</code></pre></div>

<p>Attribute coef_: get value as an option.</p>
<div class="highlight"><pre><span></span><code><span class="k">val</span> <span class="n">coef_opt</span> <span class="o">:</span> <span class="n">t</span> <span class="o">-&gt;</span> <span class="o">([&gt;`</span><span class="nc">ArrayLike</span><span class="o">]</span> <span class="nn">Np</span><span class="p">.</span><span class="nn">Obj</span><span class="p">.</span><span class="n">t</span><span class="o">)</span> <span class="n">option</span>
</code></pre></div>

<p>Attribute n_iter_: get value or raise Not_found if None.</p>
<div class="highlight"><pre><span></span><code><span class="k">val</span> <span class="n">n_iter_</span> <span class="o">:</span> <span class="n">t</span> <span class="o">-&gt;</span> <span class="kt">int</span>
</code></pre></div>

<p>Attribute n_iter_: get value as an option.</p>
<div class="highlight"><pre><span></span><code><span class="k">val</span> <span class="n">n_iter_opt</span> <span class="o">:</span> <span class="n">t</span> <span class="o">-&gt;</span> <span class="o">(</span><span class="kt">int</span><span class="o">)</span> <span class="n">option</span>
</code></pre></div>

<p>Print the object to a human-readable representation.</p>
<div class="highlight"><pre><span></span><code><span class="k">val</span> <span class="n">to_string</span> <span class="o">:</span> <span class="n">t</span> <span class="o">-&gt;</span> <span class="kt">string</span>
</code></pre></div>

<p>Print the object to a human-readable representation.</p>
<div class="highlight"><pre><span></span><code><span class="k">val</span> <span class="n">show</span> <span class="o">:</span> <span class="n">t</span> <span class="o">-&gt;</span> <span class="kt">string</span>
</code></pre></div>

<p>Pretty-print the object to a formatter.</p>
<div class="highlight"><pre><span></span><code><span class="k">val</span> <span class="n">pp</span> <span class="o">:</span> <span class="nn">Format</span><span class="p">.</span><span class="n">formatter</span> <span class="o">-&gt;</span> <span class="n">t</span> <span class="o">-&gt;</span> <span class="kt">unit</span> <span class="o">[@@</span><span class="n">ocaml</span><span class="o">.</span><span class="n">toplevel_printer</span><span class="o">]</span>



<span class="k">module</span> <span class="nc">MultiTaskElasticNetCV</span> <span class="o">:</span> <span class="k">sig</span>
<span class="k">type</span> <span class="n">tag</span> <span class="o">=</span> <span class="o">[`</span><span class="nc">MultiTaskElasticNetCV</span><span class="o">]</span>
<span class="k">type</span> <span class="n">t</span> <span class="o">=</span> <span class="o">[`</span><span class="nc">BaseEstimator</span> <span class="o">|</span> <span class="o">`</span><span class="nc">MultiOutputMixin</span> <span class="o">|</span> <span class="o">`</span><span class="nc">MultiTaskElasticNetCV</span> <span class="o">|</span> <span class="o">`</span><span class="nc">Object</span> <span class="o">|</span> <span class="o">`</span><span class="nc">RegressorMixin</span><span class="o">]</span> <span class="nn">Obj</span><span class="p">.</span><span class="n">t</span>
<span class="k">val</span> <span class="n">of_pyobject</span> <span class="o">:</span> <span class="nn">Py</span><span class="p">.</span><span class="nn">Object</span><span class="p">.</span><span class="n">t</span> <span class="o">-&gt;</span> <span class="n">t</span>
<span class="k">val</span> <span class="n">to_pyobject</span> <span class="o">:</span> <span class="o">[&gt;</span> <span class="n">tag</span><span class="o">]</span> <span class="nn">Obj</span><span class="p">.</span><span class="n">t</span> <span class="o">-&gt;</span> <span class="nn">Py</span><span class="p">.</span><span class="nn">Object</span><span class="p">.</span><span class="n">t</span>

<span class="k">val</span> <span class="n">as_regressor</span> <span class="o">:</span> <span class="n">t</span> <span class="o">-&gt;</span> <span class="o">[`</span><span class="nc">RegressorMixin</span><span class="o">]</span> <span class="nn">Obj</span><span class="p">.</span><span class="n">t</span>
<span class="k">val</span> <span class="n">as_multi_output</span> <span class="o">:</span> <span class="n">t</span> <span class="o">-&gt;</span> <span class="o">[`</span><span class="nc">MultiOutputMixin</span><span class="o">]</span> <span class="nn">Obj</span><span class="p">.</span><span class="n">t</span>
<span class="k">val</span> <span class="n">as_estimator</span> <span class="o">:</span> <span class="n">t</span> <span class="o">-&gt;</span> <span class="o">[`</span><span class="nc">BaseEstimator</span><span class="o">]</span> <span class="nn">Obj</span><span class="p">.</span><span class="n">t</span>
<span class="k">val</span> <span class="n">create</span> <span class="o">:</span> <span class="o">?</span><span class="n">l1_ratio</span><span class="o">:[&gt;`</span><span class="nc">ArrayLike</span><span class="o">]</span> <span class="nn">Np</span><span class="p">.</span><span class="nn">Obj</span><span class="p">.</span><span class="n">t</span> <span class="o">-&gt;</span> <span class="o">?</span><span class="n">eps</span><span class="o">:</span><span class="kt">float</span> <span class="o">-&gt;</span> <span class="o">?</span><span class="n">n_alphas</span><span class="o">:</span><span class="kt">int</span> <span class="o">-&gt;</span> <span class="o">?</span><span class="n">alphas</span><span class="o">:[&gt;`</span><span class="nc">ArrayLike</span><span class="o">]</span> <span class="nn">Np</span><span class="p">.</span><span class="nn">Obj</span><span class="p">.</span><span class="n">t</span> <span class="o">-&gt;</span> <span class="o">?</span><span class="n">fit_intercept</span><span class="o">:</span><span class="kt">bool</span> <span class="o">-&gt;</span> <span class="o">?</span><span class="n">normalize</span><span class="o">:</span><span class="kt">bool</span> <span class="o">-&gt;</span> <span class="o">?</span><span class="n">max_iter</span><span class="o">:</span><span class="kt">int</span> <span class="o">-&gt;</span> <span class="o">?</span><span class="n">tol</span><span class="o">:</span><span class="kt">float</span> <span class="o">-&gt;</span> <span class="o">?</span><span class="n">cv</span><span class="o">:[`</span><span class="nc">Arr</span> <span class="k">of</span> <span class="o">[&gt;`</span><span class="nc">ArrayLike</span><span class="o">]</span> <span class="nn">Np</span><span class="p">.</span><span class="nn">Obj</span><span class="p">.</span><span class="n">t</span> <span class="o">|</span> <span class="o">`</span><span class="nc">BaseCrossValidator</span> <span class="k">of</span> <span class="o">[&gt;`</span><span class="nc">BaseCrossValidator</span><span class="o">]</span> <span class="nn">Np</span><span class="p">.</span><span class="nn">Obj</span><span class="p">.</span><span class="n">t</span> <span class="o">|</span> <span class="o">`</span><span class="nc">I</span> <span class="k">of</span> <span class="kt">int</span><span class="o">]</span> <span class="o">-&gt;</span> <span class="o">?</span><span class="n">copy_X</span><span class="o">:</span><span class="kt">bool</span> <span class="o">-&gt;</span> <span class="o">?</span><span class="n">verbose</span><span class="o">:</span><span class="kt">int</span> <span class="o">-&gt;</span> <span class="o">?</span><span class="n">n_jobs</span><span class="o">:</span><span class="kt">int</span> <span class="o">-&gt;</span> <span class="o">?</span><span class="n">random_state</span><span class="o">:</span><span class="kt">int</span> <span class="o">-&gt;</span> <span class="o">?</span><span class="n">selection</span><span class="o">:</span><span class="kt">string</span> <span class="o">-&gt;</span> <span class="kt">unit</span> <span class="o">-&gt;</span> <span class="n">t</span>
</code></pre></div>

<p>Multi-task L1/L2 ElasticNet with built-in cross-validation.</p>
<p>See glossary entry for :term:<code>cross-validation estimator</code>.</p>
<p>The optimization objective for MultiTaskElasticNet is::</p>
<p>(1 / (2 * n_samples)) * ||Y - XW||^Fro_2
+ alpha * l1_ratio * ||W||_21
+ 0.5 * alpha * (1 - l1_ratio) * ||W||_Fro^2</p>
<p>Where::</p>
<p>||W||<em>21 = \sum_i \sqrt{\sum_j w</em>{ij}^2}</p>
<p>i.e. the sum of norm of each row.</p>
<p>Read more in the :ref:<code>User Guide &lt;multi_task_elastic_net&gt;</code>.</p>
<p>.. versionadded:: 0.15</p>
<h2 id="parameters_102">Parameters<a class="headerlink" href="#parameters_102" title="Permanent link">&para;</a></h2>
<p>l1_ratio : float or array of floats
The ElasticNet mixing parameter, with 0 &lt; l1_ratio &lt;= 1.
For l1_ratio = 1 the penalty is an L1/L2 penalty. For l1_ratio = 0 it
is an L2 penalty.
For <code>0 &lt; l1_ratio &lt; 1</code>, the penalty is a combination of L1/L2 and L2.
This parameter can be a list, in which case the different
values are tested by cross-validation and the one giving the best
prediction score is used. Note that a good choice of list of
values for l1_ratio is often to put more values close to 1
(i.e. Lasso) and less close to 0 (i.e. Ridge), as in <code>[.1, .5, .7,
.9, .95, .99, 1]</code></p>
<p>eps : float, optional
Length of the path. <code>eps=1e-3</code> means that
<code>alpha_min / alpha_max = 1e-3</code>.</p>
<p>n_alphas : int, optional
Number of alphas along the regularization path</p>
<p>alphas : array-like, optional
List of alphas where to compute the models.
If not provided, set automatically.</p>
<p>fit_intercept : boolean
whether to calculate the intercept for this model. If set
to false, no intercept will be used in calculations
(i.e. data is expected to be centered).</p>
<p>normalize : boolean, optional, default False
This parameter is ignored when <code>fit_intercept</code> is set to False.
If True, the regressors X will be normalized before regression by
subtracting the mean and dividing by the l2-norm.
If you wish to standardize, please use
:class:<code>sklearn.preprocessing.StandardScaler</code> before calling <code>fit</code>
on an estimator with <code>normalize=False</code>.</p>
<p>max_iter : int, optional
The maximum number of iterations</p>
<p>tol : float, optional
The tolerance for the optimization: if the updates are
smaller than <code>tol</code>, the optimization code checks the
dual gap for optimality and continues until it is smaller
than <code>tol</code>.</p>
<p>cv : int, cross-validation generator or an iterable, optional
Determines the cross-validation splitting strategy.
Possible inputs for cv are:</p>
<ul>
<li>None, to use the default 5-fold cross-validation,</li>
<li>integer, to specify the number of folds.</li>
<li>:term:<code>CV splitter</code>,</li>
<li>An iterable yielding (train, test) splits as arrays of indices.</li>
</ul>
<p>For integer/None inputs, :class:<code>KFold</code> is used.</p>
<p>Refer :ref:<code>User Guide &lt;cross_validation&gt;</code> for the various
cross-validation strategies that can be used here.</p>
<p>.. versionchanged:: 0.22
<code>cv</code> default value if None changed from 3-fold to 5-fold.</p>
<p>copy_X : boolean, optional, default True
If <code>True</code>, X will be copied; else, it may be overwritten.</p>
<p>verbose : bool or integer
Amount of verbosity.</p>
<p>n_jobs : int or None, optional (default=None)
Number of CPUs to use during the cross validation. Note that this is
used only if multiple values for l1_ratio are given.
<code>None</code> means 1 unless in a :obj:<code>joblib.parallel_backend</code> context.
<code>-1</code> means using all processors. See :term:<code>Glossary &lt;n_jobs&gt;</code>
for more details.</p>
<p>random_state : int, RandomState instance or None, optional, default None
The seed of the pseudo random number generator that selects a random
feature to update.  If int, random_state is the seed used by the random
number generator; If RandomState instance, random_state is the random
number generator; If None, the random number generator is the
RandomState instance used by <code>np.random</code>. Used when <code>selection</code> ==
'random'.</p>
<p>selection : str, default 'cyclic'
If set to 'random', a random coefficient is updated every iteration
rather than looping over features sequentially by default. This
(setting to 'random') often leads to significantly faster convergence
especially when tol is higher than 1e-4.</p>
<h2 id="attributes_16">Attributes<a class="headerlink" href="#attributes_16" title="Permanent link">&para;</a></h2>
<p>intercept_ : array, shape (n_tasks,)
Independent term in decision function.</p>
<p>coef_ : array, shape (n_tasks, n_features)
Parameter vector (W in the cost function formula).
Note that <code>coef_</code> stores the transpose of <code>W</code>, <code>W.T</code>.</p>
<p>alpha_ : float
The amount of penalization chosen by cross validation</p>
<p>mse_path_ : array, shape (n_alphas, n_folds) or                 (n_l1_ratio, n_alphas, n_folds)
mean square error for the test set on each fold, varying alpha</p>
<p>alphas_ : numpy array, shape (n_alphas,) or (n_l1_ratio, n_alphas)
The grid of alphas used for fitting, for each l1_ratio</p>
<p>l1_ratio_ : float
best l1_ratio obtained by cross-validation.</p>
<p>n_iter_ : int
number of iterations run by the coordinate descent solver to reach
the specified tolerance for the optimal alpha.</p>
<h2 id="examples_16">Examples<a class="headerlink" href="#examples_16" title="Permanent link">&para;</a></h2>
<blockquote>
<blockquote>
<blockquote>
<p>from sklearn import linear_model
clf = linear_model.MultiTaskElasticNetCV(cv=3)
clf.fit([[0,0], [1, 1], [2, 2]],
...         [[0, 0], [1, 1], [2, 2]])
MultiTaskElasticNetCV(cv=3)
print(clf.coef_)
[[0.52875032 0.46958558]
[0.52875032 0.46958558]]
print(clf.intercept_)
[0.00166409 0.00166409]</p>
</blockquote>
</blockquote>
</blockquote>
<h2 id="see-also_13">See also<a class="headerlink" href="#see-also_13" title="Permanent link">&para;</a></h2>
<p>MultiTaskElasticNet
ElasticNetCV
MultiTaskLassoCV</p>
<h2 id="notes_31">Notes<a class="headerlink" href="#notes_31" title="Permanent link">&para;</a></h2>
<p>The algorithm used to fit the model is coordinate descent.</p>
<p>To avoid unnecessary memory duplication the X argument of the fit method
should be directly passed as a Fortran-contiguous numpy array.</p>
<div class="highlight"><pre><span></span><code><span class="k">val</span> <span class="n">fit</span> <span class="o">:</span> <span class="n">x</span><span class="o">:</span><span class="nn">Py</span><span class="p">.</span><span class="nn">Object</span><span class="p">.</span><span class="n">t</span> <span class="o">-&gt;</span> <span class="n">y</span><span class="o">:[&gt;`</span><span class="nc">ArrayLike</span><span class="o">]</span> <span class="nn">Np</span><span class="p">.</span><span class="nn">Obj</span><span class="p">.</span><span class="n">t</span> <span class="o">-&gt;</span> <span class="o">[&gt;</span> <span class="n">tag</span><span class="o">]</span> <span class="nn">Obj</span><span class="p">.</span><span class="n">t</span> <span class="o">-&gt;</span> <span class="n">t</span>
</code></pre></div>

<p>Fit linear model with coordinate descent</p>
<p>Fit is on grid of alphas and best alpha estimated by cross-validation.</p>
<h2 id="parameters_103">Parameters<a class="headerlink" href="#parameters_103" title="Permanent link">&para;</a></h2>
<p>X : {array-like}, shape (n_samples, n_features)
Training data. Pass directly as Fortran-contiguous data
to avoid unnecessary memory duplication. If y is mono-output,
X can be sparse.</p>
<p>y : array-like, shape (n_samples,) or (n_samples, n_targets)
Target values</p>
<div class="highlight"><pre><span></span><code><span class="k">val</span> <span class="n">get_params</span> <span class="o">:</span> <span class="o">?</span><span class="n">deep</span><span class="o">:</span><span class="kt">bool</span> <span class="o">-&gt;</span> <span class="o">[&gt;</span> <span class="n">tag</span><span class="o">]</span> <span class="nn">Obj</span><span class="p">.</span><span class="n">t</span> <span class="o">-&gt;</span> <span class="nn">Dict</span><span class="p">.</span><span class="n">t</span>
</code></pre></div>

<p>Get parameters for this estimator.</p>
<h2 id="parameters_104">Parameters<a class="headerlink" href="#parameters_104" title="Permanent link">&para;</a></h2>
<p>deep : bool, default=True
If True, will return the parameters for this estimator and
contained subobjects that are estimators.</p>
<h2 id="returns_85">Returns<a class="headerlink" href="#returns_85" title="Permanent link">&para;</a></h2>
<p>params : mapping of string to any
Parameter names mapped to their values.</p>
<div class="highlight"><pre><span></span><code><span class="k">val</span> <span class="n">predict</span> <span class="o">:</span> <span class="n">x</span><span class="o">:[&gt;`</span><span class="nc">ArrayLike</span><span class="o">]</span> <span class="nn">Np</span><span class="p">.</span><span class="nn">Obj</span><span class="p">.</span><span class="n">t</span> <span class="o">-&gt;</span> <span class="o">[&gt;</span> <span class="n">tag</span><span class="o">]</span> <span class="nn">Obj</span><span class="p">.</span><span class="n">t</span> <span class="o">-&gt;</span> <span class="o">[&gt;`</span><span class="nc">ArrayLike</span><span class="o">]</span> <span class="nn">Np</span><span class="p">.</span><span class="nn">Obj</span><span class="p">.</span><span class="n">t</span>
</code></pre></div>

<p>Predict using the linear model.</p>
<h2 id="parameters_105">Parameters<a class="headerlink" href="#parameters_105" title="Permanent link">&para;</a></h2>
<p>X : array_like or sparse matrix, shape (n_samples, n_features)
Samples.</p>
<h2 id="returns_86">Returns<a class="headerlink" href="#returns_86" title="Permanent link">&para;</a></h2>
<p>C : array, shape (n_samples,)
Returns predicted values.</p>
<div class="highlight"><pre><span></span><code><span class="k">val</span> <span class="n">score</span> <span class="o">:</span> <span class="o">?</span><span class="n">sample_weight</span><span class="o">:[&gt;`</span><span class="nc">ArrayLike</span><span class="o">]</span> <span class="nn">Np</span><span class="p">.</span><span class="nn">Obj</span><span class="p">.</span><span class="n">t</span> <span class="o">-&gt;</span> <span class="n">x</span><span class="o">:[&gt;`</span><span class="nc">ArrayLike</span><span class="o">]</span> <span class="nn">Np</span><span class="p">.</span><span class="nn">Obj</span><span class="p">.</span><span class="n">t</span> <span class="o">-&gt;</span> <span class="n">y</span><span class="o">:[&gt;`</span><span class="nc">ArrayLike</span><span class="o">]</span> <span class="nn">Np</span><span class="p">.</span><span class="nn">Obj</span><span class="p">.</span><span class="n">t</span> <span class="o">-&gt;</span> <span class="o">[&gt;</span> <span class="n">tag</span><span class="o">]</span> <span class="nn">Obj</span><span class="p">.</span><span class="n">t</span> <span class="o">-&gt;</span> <span class="kt">float</span>
</code></pre></div>

<p>Return the coefficient of determination R^2 of the prediction.</p>
<p>The coefficient R^2 is defined as (1 - u/v), where u is the residual
sum of squares ((y_true - y_pred) <strong> 2).sum() and v is the total
sum of squares ((y_true - y_true.mean()) </strong> 2).sum().
The best possible score is 1.0 and it can be negative (because the
model can be arbitrarily worse). A constant model that always
predicts the expected value of y, disregarding the input features,
would get a R^2 score of 0.0.</p>
<h2 id="parameters_106">Parameters<a class="headerlink" href="#parameters_106" title="Permanent link">&para;</a></h2>
<p>X : array-like of shape (n_samples, n_features)
Test samples. For some estimators this may be a
precomputed kernel matrix or a list of generic objects instead,
shape = (n_samples, n_samples_fitted),
where n_samples_fitted is the number of
samples used in the fitting for the estimator.</p>
<p>y : array-like of shape (n_samples,) or (n_samples, n_outputs)
True values for X.</p>
<p>sample_weight : array-like of shape (n_samples,), default=None
Sample weights.</p>
<h2 id="returns_87">Returns<a class="headerlink" href="#returns_87" title="Permanent link">&para;</a></h2>
<p>score : float
R^2 of self.predict(X) wrt. y.</p>
<h2 id="notes_32">Notes<a class="headerlink" href="#notes_32" title="Permanent link">&para;</a></h2>
<p>The R2 score used when calling <code>score</code> on a regressor will use
<code>multioutput='uniform_average'</code> from version 0.23 to keep consistent
with :func:<code>~sklearn.metrics.r2_score</code>. This will influence the
<code>score</code> method of all the multioutput regressors (except for
:class:<code>~sklearn.multioutput.MultiOutputRegressor</code>). To specify the
default value manually and avoid the warning, please either call
:func:<code>~sklearn.metrics.r2_score</code> directly or make a custom scorer with
:func:<code>~sklearn.metrics.make_scorer</code> (the built-in scorer <code>'r2'</code> uses
<code>multioutput='uniform_average'</code>).</p>
<div class="highlight"><pre><span></span><code><span class="k">val</span> <span class="n">set_params</span> <span class="o">:</span> <span class="o">?</span><span class="n">params</span><span class="o">:(</span><span class="kt">string</span> <span class="o">*</span> <span class="nn">Py</span><span class="p">.</span><span class="nn">Object</span><span class="p">.</span><span class="n">t</span><span class="o">)</span> <span class="kt">list</span> <span class="o">-&gt;</span> <span class="o">[&gt;</span> <span class="n">tag</span><span class="o">]</span> <span class="nn">Obj</span><span class="p">.</span><span class="n">t</span> <span class="o">-&gt;</span> <span class="n">t</span>
</code></pre></div>

<p>Set the parameters of this estimator.</p>
<p>The method works on simple estimators as well as on nested objects
(such as pipelines). The latter have parameters of the form
<code>&lt;component&gt;__&lt;parameter&gt;</code> so that it's possible to update each
component of a nested object.</p>
<h2 id="parameters_107">Parameters<a class="headerlink" href="#parameters_107" title="Permanent link">&para;</a></h2>
<p>**params : dict
Estimator parameters.</p>
<h2 id="returns_88">Returns<a class="headerlink" href="#returns_88" title="Permanent link">&para;</a></h2>
<p>self : object
Estimator instance.</p>
<p>Attribute intercept_: get value or raise Not_found if None.</p>
<div class="highlight"><pre><span></span><code><span class="k">val</span> <span class="n">intercept_</span> <span class="o">:</span> <span class="n">t</span> <span class="o">-&gt;</span> <span class="o">[&gt;`</span><span class="nc">ArrayLike</span><span class="o">]</span> <span class="nn">Np</span><span class="p">.</span><span class="nn">Obj</span><span class="p">.</span><span class="n">t</span>
</code></pre></div>

<p>Attribute intercept_: get value as an option.</p>
<div class="highlight"><pre><span></span><code><span class="k">val</span> <span class="n">intercept_opt</span> <span class="o">:</span> <span class="n">t</span> <span class="o">-&gt;</span> <span class="o">([&gt;`</span><span class="nc">ArrayLike</span><span class="o">]</span> <span class="nn">Np</span><span class="p">.</span><span class="nn">Obj</span><span class="p">.</span><span class="n">t</span><span class="o">)</span> <span class="n">option</span>
</code></pre></div>

<p>Attribute coef_: get value or raise Not_found if None.</p>
<div class="highlight"><pre><span></span><code><span class="k">val</span> <span class="n">coef_</span> <span class="o">:</span> <span class="n">t</span> <span class="o">-&gt;</span> <span class="o">[&gt;`</span><span class="nc">ArrayLike</span><span class="o">]</span> <span class="nn">Np</span><span class="p">.</span><span class="nn">Obj</span><span class="p">.</span><span class="n">t</span>
</code></pre></div>

<p>Attribute coef_: get value as an option.</p>
<div class="highlight"><pre><span></span><code><span class="k">val</span> <span class="n">coef_opt</span> <span class="o">:</span> <span class="n">t</span> <span class="o">-&gt;</span> <span class="o">([&gt;`</span><span class="nc">ArrayLike</span><span class="o">]</span> <span class="nn">Np</span><span class="p">.</span><span class="nn">Obj</span><span class="p">.</span><span class="n">t</span><span class="o">)</span> <span class="n">option</span>
</code></pre></div>

<p>Attribute alpha_: get value or raise Not_found if None.</p>
<div class="highlight"><pre><span></span><code><span class="k">val</span> <span class="n">alpha_</span> <span class="o">:</span> <span class="n">t</span> <span class="o">-&gt;</span> <span class="kt">float</span>
</code></pre></div>

<p>Attribute alpha_: get value as an option.</p>
<div class="highlight"><pre><span></span><code><span class="k">val</span> <span class="n">alpha_opt</span> <span class="o">:</span> <span class="n">t</span> <span class="o">-&gt;</span> <span class="o">(</span><span class="kt">float</span><span class="o">)</span> <span class="n">option</span>
</code></pre></div>

<p>Attribute mse_path_: get value or raise Not_found if None.</p>
<div class="highlight"><pre><span></span><code><span class="k">val</span> <span class="n">mse_path_</span> <span class="o">:</span> <span class="n">t</span> <span class="o">-&gt;</span> <span class="o">[&gt;`</span><span class="nc">ArrayLike</span><span class="o">]</span> <span class="nn">Np</span><span class="p">.</span><span class="nn">Obj</span><span class="p">.</span><span class="n">t</span>
</code></pre></div>

<p>Attribute mse_path_: get value as an option.</p>
<div class="highlight"><pre><span></span><code><span class="k">val</span> <span class="n">mse_path_opt</span> <span class="o">:</span> <span class="n">t</span> <span class="o">-&gt;</span> <span class="o">([&gt;`</span><span class="nc">ArrayLike</span><span class="o">]</span> <span class="nn">Np</span><span class="p">.</span><span class="nn">Obj</span><span class="p">.</span><span class="n">t</span><span class="o">)</span> <span class="n">option</span>
</code></pre></div>

<p>Attribute alphas_: get value or raise Not_found if None.</p>
<div class="highlight"><pre><span></span><code><span class="k">val</span> <span class="n">alphas_</span> <span class="o">:</span> <span class="n">t</span> <span class="o">-&gt;</span> <span class="o">[&gt;`</span><span class="nc">ArrayLike</span><span class="o">]</span> <span class="nn">Np</span><span class="p">.</span><span class="nn">Obj</span><span class="p">.</span><span class="n">t</span>
</code></pre></div>

<p>Attribute alphas_: get value as an option.</p>
<div class="highlight"><pre><span></span><code><span class="k">val</span> <span class="n">alphas_opt</span> <span class="o">:</span> <span class="n">t</span> <span class="o">-&gt;</span> <span class="o">([&gt;`</span><span class="nc">ArrayLike</span><span class="o">]</span> <span class="nn">Np</span><span class="p">.</span><span class="nn">Obj</span><span class="p">.</span><span class="n">t</span><span class="o">)</span> <span class="n">option</span>
</code></pre></div>

<p>Attribute l1_ratio_: get value or raise Not_found if None.</p>
<div class="highlight"><pre><span></span><code><span class="k">val</span> <span class="n">l1_ratio_</span> <span class="o">:</span> <span class="n">t</span> <span class="o">-&gt;</span> <span class="kt">float</span>
</code></pre></div>

<p>Attribute l1_ratio_: get value as an option.</p>
<div class="highlight"><pre><span></span><code><span class="k">val</span> <span class="n">l1_ratio_opt</span> <span class="o">:</span> <span class="n">t</span> <span class="o">-&gt;</span> <span class="o">(</span><span class="kt">float</span><span class="o">)</span> <span class="n">option</span>
</code></pre></div>

<p>Attribute n_iter_: get value or raise Not_found if None.</p>
<div class="highlight"><pre><span></span><code><span class="k">val</span> <span class="n">n_iter_</span> <span class="o">:</span> <span class="n">t</span> <span class="o">-&gt;</span> <span class="kt">int</span>
</code></pre></div>

<p>Attribute n_iter_: get value as an option.</p>
<div class="highlight"><pre><span></span><code><span class="k">val</span> <span class="n">n_iter_opt</span> <span class="o">:</span> <span class="n">t</span> <span class="o">-&gt;</span> <span class="o">(</span><span class="kt">int</span><span class="o">)</span> <span class="n">option</span>
</code></pre></div>

<p>Print the object to a human-readable representation.</p>
<div class="highlight"><pre><span></span><code><span class="k">val</span> <span class="n">to_string</span> <span class="o">:</span> <span class="n">t</span> <span class="o">-&gt;</span> <span class="kt">string</span>
</code></pre></div>

<p>Print the object to a human-readable representation.</p>
<div class="highlight"><pre><span></span><code><span class="k">val</span> <span class="n">show</span> <span class="o">:</span> <span class="n">t</span> <span class="o">-&gt;</span> <span class="kt">string</span>
</code></pre></div>

<p>Pretty-print the object to a formatter.</p>
<div class="highlight"><pre><span></span><code><span class="k">val</span> <span class="n">pp</span> <span class="o">:</span> <span class="nn">Format</span><span class="p">.</span><span class="n">formatter</span> <span class="o">-&gt;</span> <span class="n">t</span> <span class="o">-&gt;</span> <span class="kt">unit</span> <span class="o">[@@</span><span class="n">ocaml</span><span class="o">.</span><span class="n">toplevel_printer</span><span class="o">]</span>



<span class="k">module</span> <span class="nc">MultiTaskLasso</span> <span class="o">:</span> <span class="k">sig</span>
<span class="k">type</span> <span class="n">tag</span> <span class="o">=</span> <span class="o">[`</span><span class="nc">MultiTaskLasso</span><span class="o">]</span>
<span class="k">type</span> <span class="n">t</span> <span class="o">=</span> <span class="o">[`</span><span class="nc">BaseEstimator</span> <span class="o">|</span> <span class="o">`</span><span class="nc">MultiOutputMixin</span> <span class="o">|</span> <span class="o">`</span><span class="nc">MultiTaskLasso</span> <span class="o">|</span> <span class="o">`</span><span class="nc">Object</span> <span class="o">|</span> <span class="o">`</span><span class="nc">RegressorMixin</span><span class="o">]</span> <span class="nn">Obj</span><span class="p">.</span><span class="n">t</span>
<span class="k">val</span> <span class="n">of_pyobject</span> <span class="o">:</span> <span class="nn">Py</span><span class="p">.</span><span class="nn">Object</span><span class="p">.</span><span class="n">t</span> <span class="o">-&gt;</span> <span class="n">t</span>
<span class="k">val</span> <span class="n">to_pyobject</span> <span class="o">:</span> <span class="o">[&gt;</span> <span class="n">tag</span><span class="o">]</span> <span class="nn">Obj</span><span class="p">.</span><span class="n">t</span> <span class="o">-&gt;</span> <span class="nn">Py</span><span class="p">.</span><span class="nn">Object</span><span class="p">.</span><span class="n">t</span>

<span class="k">val</span> <span class="n">as_regressor</span> <span class="o">:</span> <span class="n">t</span> <span class="o">-&gt;</span> <span class="o">[`</span><span class="nc">RegressorMixin</span><span class="o">]</span> <span class="nn">Obj</span><span class="p">.</span><span class="n">t</span>
<span class="k">val</span> <span class="n">as_multi_output</span> <span class="o">:</span> <span class="n">t</span> <span class="o">-&gt;</span> <span class="o">[`</span><span class="nc">MultiOutputMixin</span><span class="o">]</span> <span class="nn">Obj</span><span class="p">.</span><span class="n">t</span>
<span class="k">val</span> <span class="n">as_estimator</span> <span class="o">:</span> <span class="n">t</span> <span class="o">-&gt;</span> <span class="o">[`</span><span class="nc">BaseEstimator</span><span class="o">]</span> <span class="nn">Obj</span><span class="p">.</span><span class="n">t</span>
<span class="k">val</span> <span class="n">create</span> <span class="o">:</span> <span class="o">?</span><span class="n">alpha</span><span class="o">:</span><span class="kt">float</span> <span class="o">-&gt;</span> <span class="o">?</span><span class="n">fit_intercept</span><span class="o">:</span><span class="kt">bool</span> <span class="o">-&gt;</span> <span class="o">?</span><span class="n">normalize</span><span class="o">:</span><span class="kt">bool</span> <span class="o">-&gt;</span> <span class="o">?</span><span class="n">copy_X</span><span class="o">:</span><span class="kt">bool</span> <span class="o">-&gt;</span> <span class="o">?</span><span class="n">max_iter</span><span class="o">:</span><span class="kt">int</span> <span class="o">-&gt;</span> <span class="o">?</span><span class="n">tol</span><span class="o">:</span><span class="kt">float</span> <span class="o">-&gt;</span> <span class="o">?</span><span class="n">warm_start</span><span class="o">:</span><span class="kt">bool</span> <span class="o">-&gt;</span> <span class="o">?</span><span class="n">random_state</span><span class="o">:</span><span class="kt">int</span> <span class="o">-&gt;</span> <span class="o">?</span><span class="n">selection</span><span class="o">:</span><span class="kt">string</span> <span class="o">-&gt;</span> <span class="kt">unit</span> <span class="o">-&gt;</span> <span class="n">t</span>
</code></pre></div>

<p>Multi-task Lasso model trained with L1/L2 mixed-norm as regularizer.</p>
<p>The optimization objective for Lasso is::</p>
<p>(1 / (2 * n_samples)) * ||Y - XW||^2_Fro + alpha * ||W||_21</p>
<p>Where::</p>
<p>||W||<em>21 = \sum_i \sqrt{\sum_j w</em>{ij}^2}</p>
<p>i.e. the sum of norm of each row.</p>
<p>Read more in the :ref:<code>User Guide &lt;multi_task_lasso&gt;</code>.</p>
<h2 id="parameters_108">Parameters<a class="headerlink" href="#parameters_108" title="Permanent link">&para;</a></h2>
<p>alpha : float, optional
Constant that multiplies the L1/L2 term. Defaults to 1.0</p>
<p>fit_intercept : boolean
whether to calculate the intercept for this model. If set
to false, no intercept will be used in calculations
(i.e. data is expected to be centered).</p>
<p>normalize : boolean, optional, default False
This parameter is ignored when <code>fit_intercept</code> is set to False.
If True, the regressors X will be normalized before regression by
subtracting the mean and dividing by the l2-norm.
If you wish to standardize, please use
:class:<code>sklearn.preprocessing.StandardScaler</code> before calling <code>fit</code>
on an estimator with <code>normalize=False</code>.</p>
<p>copy_X : boolean, optional, default True
If <code>True</code>, X will be copied; else, it may be overwritten.</p>
<p>max_iter : int, optional
The maximum number of iterations</p>
<p>tol : float, optional
The tolerance for the optimization: if the updates are
smaller than <code>tol</code>, the optimization code checks the
dual gap for optimality and continues until it is smaller
than <code>tol</code>.</p>
<p>warm_start : bool, optional
When set to <code>True</code>, reuse the solution of the previous call to fit as
initialization, otherwise, just erase the previous solution.
See :term:<code>the Glossary &lt;warm_start&gt;</code>.</p>
<p>random_state : int, RandomState instance or None, optional, default None
The seed of the pseudo random number generator that selects a random
feature to update.  If int, random_state is the seed used by the random
number generator; If RandomState instance, random_state is the random
number generator; If None, the random number generator is the
RandomState instance used by <code>np.random</code>. Used when <code>selection</code> ==
'random'.</p>
<p>selection : str, default 'cyclic'
If set to 'random', a random coefficient is updated every iteration
rather than looping over features sequentially by default. This
(setting to 'random') often leads to significantly faster convergence
especially when tol is higher than 1e-4</p>
<h2 id="attributes_17">Attributes<a class="headerlink" href="#attributes_17" title="Permanent link">&para;</a></h2>
<p>coef_ : array, shape (n_tasks, n_features)
Parameter vector (W in the cost function formula).
Note that <code>coef_</code> stores the transpose of <code>W</code>, <code>W.T</code>.</p>
<p>intercept_ : array, shape (n_tasks,)
independent term in decision function.</p>
<p>n_iter_ : int
number of iterations run by the coordinate descent solver to reach
the specified tolerance.</p>
<h2 id="examples_17">Examples<a class="headerlink" href="#examples_17" title="Permanent link">&para;</a></h2>
<blockquote>
<blockquote>
<blockquote>
<p>from sklearn import linear_model
clf = linear_model.MultiTaskLasso(alpha=0.1)
clf.fit([[0,0], [1, 1], [2, 2]], [[0, 0], [1, 1], [2, 2]])
MultiTaskLasso(alpha=0.1)
print(clf.coef_)
[[0.89393398 0.        ]
[0.89393398 0.        ]]
print(clf.intercept_)
[0.10606602 0.10606602]</p>
</blockquote>
</blockquote>
</blockquote>
<h2 id="see-also_14">See also<a class="headerlink" href="#see-also_14" title="Permanent link">&para;</a></h2>
<p>MultiTaskLasso : Multi-task L1/L2 Lasso with built-in cross-validation
Lasso
MultiTaskElasticNet</p>
<h2 id="notes_33">Notes<a class="headerlink" href="#notes_33" title="Permanent link">&para;</a></h2>
<p>The algorithm used to fit the model is coordinate descent.</p>
<p>To avoid unnecessary memory duplication the X argument of the fit method
should be directly passed as a Fortran-contiguous numpy array.</p>
<div class="highlight"><pre><span></span><code><span class="k">val</span> <span class="n">fit</span> <span class="o">:</span> <span class="n">x</span><span class="o">:[&gt;`</span><span class="nc">ArrayLike</span><span class="o">]</span> <span class="nn">Np</span><span class="p">.</span><span class="nn">Obj</span><span class="p">.</span><span class="n">t</span> <span class="o">-&gt;</span> <span class="n">y</span><span class="o">:[&gt;`</span><span class="nc">ArrayLike</span><span class="o">]</span> <span class="nn">Np</span><span class="p">.</span><span class="nn">Obj</span><span class="p">.</span><span class="n">t</span> <span class="o">-&gt;</span> <span class="o">[&gt;</span> <span class="n">tag</span><span class="o">]</span> <span class="nn">Obj</span><span class="p">.</span><span class="n">t</span> <span class="o">-&gt;</span> <span class="n">t</span>
</code></pre></div>

<p>Fit MultiTaskElasticNet model with coordinate descent</p>
<h2 id="parameters_109">Parameters<a class="headerlink" href="#parameters_109" title="Permanent link">&para;</a></h2>
<p>X : ndarray, shape (n_samples, n_features)
Data
y : ndarray, shape (n_samples, n_tasks)
Target. Will be cast to X's dtype if necessary</p>
<h2 id="notes_34">Notes<a class="headerlink" href="#notes_34" title="Permanent link">&para;</a></h2>
<p>Coordinate descent is an algorithm that considers each column of
data at a time hence it will automatically convert the X input
as a Fortran-contiguous numpy array if necessary.</p>
<p>To avoid memory re-allocation it is advised to allocate the
initial data in memory directly using that format.</p>
<div class="highlight"><pre><span></span><code><span class="k">val</span> <span class="n">get_params</span> <span class="o">:</span> <span class="o">?</span><span class="n">deep</span><span class="o">:</span><span class="kt">bool</span> <span class="o">-&gt;</span> <span class="o">[&gt;</span> <span class="n">tag</span><span class="o">]</span> <span class="nn">Obj</span><span class="p">.</span><span class="n">t</span> <span class="o">-&gt;</span> <span class="nn">Dict</span><span class="p">.</span><span class="n">t</span>
</code></pre></div>

<p>Get parameters for this estimator.</p>
<h2 id="parameters_110">Parameters<a class="headerlink" href="#parameters_110" title="Permanent link">&para;</a></h2>
<p>deep : bool, default=True
If True, will return the parameters for this estimator and
contained subobjects that are estimators.</p>
<h2 id="returns_89">Returns<a class="headerlink" href="#returns_89" title="Permanent link">&para;</a></h2>
<p>params : mapping of string to any
Parameter names mapped to their values.</p>
<div class="highlight"><pre><span></span><code><span class="k">val</span> <span class="n">predict</span> <span class="o">:</span> <span class="n">x</span><span class="o">:[&gt;`</span><span class="nc">ArrayLike</span><span class="o">]</span> <span class="nn">Np</span><span class="p">.</span><span class="nn">Obj</span><span class="p">.</span><span class="n">t</span> <span class="o">-&gt;</span> <span class="o">[&gt;</span> <span class="n">tag</span><span class="o">]</span> <span class="nn">Obj</span><span class="p">.</span><span class="n">t</span> <span class="o">-&gt;</span> <span class="o">[&gt;`</span><span class="nc">ArrayLike</span><span class="o">]</span> <span class="nn">Np</span><span class="p">.</span><span class="nn">Obj</span><span class="p">.</span><span class="n">t</span>
</code></pre></div>

<p>Predict using the linear model.</p>
<h2 id="parameters_111">Parameters<a class="headerlink" href="#parameters_111" title="Permanent link">&para;</a></h2>
<p>X : array_like or sparse matrix, shape (n_samples, n_features)
Samples.</p>
<h2 id="returns_90">Returns<a class="headerlink" href="#returns_90" title="Permanent link">&para;</a></h2>
<p>C : array, shape (n_samples,)
Returns predicted values.</p>
<div class="highlight"><pre><span></span><code><span class="k">val</span> <span class="n">score</span> <span class="o">:</span> <span class="o">?</span><span class="n">sample_weight</span><span class="o">:[&gt;`</span><span class="nc">ArrayLike</span><span class="o">]</span> <span class="nn">Np</span><span class="p">.</span><span class="nn">Obj</span><span class="p">.</span><span class="n">t</span> <span class="o">-&gt;</span> <span class="n">x</span><span class="o">:[&gt;`</span><span class="nc">ArrayLike</span><span class="o">]</span> <span class="nn">Np</span><span class="p">.</span><span class="nn">Obj</span><span class="p">.</span><span class="n">t</span> <span class="o">-&gt;</span> <span class="n">y</span><span class="o">:[&gt;`</span><span class="nc">ArrayLike</span><span class="o">]</span> <span class="nn">Np</span><span class="p">.</span><span class="nn">Obj</span><span class="p">.</span><span class="n">t</span> <span class="o">-&gt;</span> <span class="o">[&gt;</span> <span class="n">tag</span><span class="o">]</span> <span class="nn">Obj</span><span class="p">.</span><span class="n">t</span> <span class="o">-&gt;</span> <span class="kt">float</span>
</code></pre></div>

<p>Return the coefficient of determination R^2 of the prediction.</p>
<p>The coefficient R^2 is defined as (1 - u/v), where u is the residual
sum of squares ((y_true - y_pred) <strong> 2).sum() and v is the total
sum of squares ((y_true - y_true.mean()) </strong> 2).sum().
The best possible score is 1.0 and it can be negative (because the
model can be arbitrarily worse). A constant model that always
predicts the expected value of y, disregarding the input features,
would get a R^2 score of 0.0.</p>
<h2 id="parameters_112">Parameters<a class="headerlink" href="#parameters_112" title="Permanent link">&para;</a></h2>
<p>X : array-like of shape (n_samples, n_features)
Test samples. For some estimators this may be a
precomputed kernel matrix or a list of generic objects instead,
shape = (n_samples, n_samples_fitted),
where n_samples_fitted is the number of
samples used in the fitting for the estimator.</p>
<p>y : array-like of shape (n_samples,) or (n_samples, n_outputs)
True values for X.</p>
<p>sample_weight : array-like of shape (n_samples,), default=None
Sample weights.</p>
<h2 id="returns_91">Returns<a class="headerlink" href="#returns_91" title="Permanent link">&para;</a></h2>
<p>score : float
R^2 of self.predict(X) wrt. y.</p>
<h2 id="notes_35">Notes<a class="headerlink" href="#notes_35" title="Permanent link">&para;</a></h2>
<p>The R2 score used when calling <code>score</code> on a regressor will use
<code>multioutput='uniform_average'</code> from version 0.23 to keep consistent
with :func:<code>~sklearn.metrics.r2_score</code>. This will influence the
<code>score</code> method of all the multioutput regressors (except for
:class:<code>~sklearn.multioutput.MultiOutputRegressor</code>). To specify the
default value manually and avoid the warning, please either call
:func:<code>~sklearn.metrics.r2_score</code> directly or make a custom scorer with
:func:<code>~sklearn.metrics.make_scorer</code> (the built-in scorer <code>'r2'</code> uses
<code>multioutput='uniform_average'</code>).</p>
<div class="highlight"><pre><span></span><code><span class="k">val</span> <span class="n">set_params</span> <span class="o">:</span> <span class="o">?</span><span class="n">params</span><span class="o">:(</span><span class="kt">string</span> <span class="o">*</span> <span class="nn">Py</span><span class="p">.</span><span class="nn">Object</span><span class="p">.</span><span class="n">t</span><span class="o">)</span> <span class="kt">list</span> <span class="o">-&gt;</span> <span class="o">[&gt;</span> <span class="n">tag</span><span class="o">]</span> <span class="nn">Obj</span><span class="p">.</span><span class="n">t</span> <span class="o">-&gt;</span> <span class="n">t</span>
</code></pre></div>

<p>Set the parameters of this estimator.</p>
<p>The method works on simple estimators as well as on nested objects
(such as pipelines). The latter have parameters of the form
<code>&lt;component&gt;__&lt;parameter&gt;</code> so that it's possible to update each
component of a nested object.</p>
<h2 id="parameters_113">Parameters<a class="headerlink" href="#parameters_113" title="Permanent link">&para;</a></h2>
<p>**params : dict
Estimator parameters.</p>
<h2 id="returns_92">Returns<a class="headerlink" href="#returns_92" title="Permanent link">&para;</a></h2>
<p>self : object
Estimator instance.</p>
<p>Attribute coef_: get value or raise Not_found if None.</p>
<div class="highlight"><pre><span></span><code><span class="k">val</span> <span class="n">coef_</span> <span class="o">:</span> <span class="n">t</span> <span class="o">-&gt;</span> <span class="o">[&gt;`</span><span class="nc">ArrayLike</span><span class="o">]</span> <span class="nn">Np</span><span class="p">.</span><span class="nn">Obj</span><span class="p">.</span><span class="n">t</span>
</code></pre></div>

<p>Attribute coef_: get value as an option.</p>
<div class="highlight"><pre><span></span><code><span class="k">val</span> <span class="n">coef_opt</span> <span class="o">:</span> <span class="n">t</span> <span class="o">-&gt;</span> <span class="o">([&gt;`</span><span class="nc">ArrayLike</span><span class="o">]</span> <span class="nn">Np</span><span class="p">.</span><span class="nn">Obj</span><span class="p">.</span><span class="n">t</span><span class="o">)</span> <span class="n">option</span>
</code></pre></div>

<p>Attribute intercept_: get value or raise Not_found if None.</p>
<div class="highlight"><pre><span></span><code><span class="k">val</span> <span class="n">intercept_</span> <span class="o">:</span> <span class="n">t</span> <span class="o">-&gt;</span> <span class="o">[&gt;`</span><span class="nc">ArrayLike</span><span class="o">]</span> <span class="nn">Np</span><span class="p">.</span><span class="nn">Obj</span><span class="p">.</span><span class="n">t</span>
</code></pre></div>

<p>Attribute intercept_: get value as an option.</p>
<div class="highlight"><pre><span></span><code><span class="k">val</span> <span class="n">intercept_opt</span> <span class="o">:</span> <span class="n">t</span> <span class="o">-&gt;</span> <span class="o">([&gt;`</span><span class="nc">ArrayLike</span><span class="o">]</span> <span class="nn">Np</span><span class="p">.</span><span class="nn">Obj</span><span class="p">.</span><span class="n">t</span><span class="o">)</span> <span class="n">option</span>
</code></pre></div>

<p>Attribute n_iter_: get value or raise Not_found if None.</p>
<div class="highlight"><pre><span></span><code><span class="k">val</span> <span class="n">n_iter_</span> <span class="o">:</span> <span class="n">t</span> <span class="o">-&gt;</span> <span class="kt">int</span>
</code></pre></div>

<p>Attribute n_iter_: get value as an option.</p>
<div class="highlight"><pre><span></span><code><span class="k">val</span> <span class="n">n_iter_opt</span> <span class="o">:</span> <span class="n">t</span> <span class="o">-&gt;</span> <span class="o">(</span><span class="kt">int</span><span class="o">)</span> <span class="n">option</span>
</code></pre></div>

<p>Print the object to a human-readable representation.</p>
<div class="highlight"><pre><span></span><code><span class="k">val</span> <span class="n">to_string</span> <span class="o">:</span> <span class="n">t</span> <span class="o">-&gt;</span> <span class="kt">string</span>
</code></pre></div>

<p>Print the object to a human-readable representation.</p>
<div class="highlight"><pre><span></span><code><span class="k">val</span> <span class="n">show</span> <span class="o">:</span> <span class="n">t</span> <span class="o">-&gt;</span> <span class="kt">string</span>
</code></pre></div>

<p>Pretty-print the object to a formatter.</p>
<div class="highlight"><pre><span></span><code><span class="k">val</span> <span class="n">pp</span> <span class="o">:</span> <span class="nn">Format</span><span class="p">.</span><span class="n">formatter</span> <span class="o">-&gt;</span> <span class="n">t</span> <span class="o">-&gt;</span> <span class="kt">unit</span> <span class="o">[@@</span><span class="n">ocaml</span><span class="o">.</span><span class="n">toplevel_printer</span><span class="o">]</span>



<span class="k">module</span> <span class="nc">MultiTaskLassoCV</span> <span class="o">:</span> <span class="k">sig</span>
<span class="k">type</span> <span class="n">tag</span> <span class="o">=</span> <span class="o">[`</span><span class="nc">MultiTaskLassoCV</span><span class="o">]</span>
<span class="k">type</span> <span class="n">t</span> <span class="o">=</span> <span class="o">[`</span><span class="nc">BaseEstimator</span> <span class="o">|</span> <span class="o">`</span><span class="nc">MultiOutputMixin</span> <span class="o">|</span> <span class="o">`</span><span class="nc">MultiTaskLassoCV</span> <span class="o">|</span> <span class="o">`</span><span class="nc">Object</span> <span class="o">|</span> <span class="o">`</span><span class="nc">RegressorMixin</span><span class="o">]</span> <span class="nn">Obj</span><span class="p">.</span><span class="n">t</span>
<span class="k">val</span> <span class="n">of_pyobject</span> <span class="o">:</span> <span class="nn">Py</span><span class="p">.</span><span class="nn">Object</span><span class="p">.</span><span class="n">t</span> <span class="o">-&gt;</span> <span class="n">t</span>
<span class="k">val</span> <span class="n">to_pyobject</span> <span class="o">:</span> <span class="o">[&gt;</span> <span class="n">tag</span><span class="o">]</span> <span class="nn">Obj</span><span class="p">.</span><span class="n">t</span> <span class="o">-&gt;</span> <span class="nn">Py</span><span class="p">.</span><span class="nn">Object</span><span class="p">.</span><span class="n">t</span>

<span class="k">val</span> <span class="n">as_regressor</span> <span class="o">:</span> <span class="n">t</span> <span class="o">-&gt;</span> <span class="o">[`</span><span class="nc">RegressorMixin</span><span class="o">]</span> <span class="nn">Obj</span><span class="p">.</span><span class="n">t</span>
<span class="k">val</span> <span class="n">as_multi_output</span> <span class="o">:</span> <span class="n">t</span> <span class="o">-&gt;</span> <span class="o">[`</span><span class="nc">MultiOutputMixin</span><span class="o">]</span> <span class="nn">Obj</span><span class="p">.</span><span class="n">t</span>
<span class="k">val</span> <span class="n">as_estimator</span> <span class="o">:</span> <span class="n">t</span> <span class="o">-&gt;</span> <span class="o">[`</span><span class="nc">BaseEstimator</span><span class="o">]</span> <span class="nn">Obj</span><span class="p">.</span><span class="n">t</span>
<span class="k">val</span> <span class="n">create</span> <span class="o">:</span> <span class="o">?</span><span class="n">eps</span><span class="o">:</span><span class="kt">float</span> <span class="o">-&gt;</span> <span class="o">?</span><span class="n">n_alphas</span><span class="o">:</span><span class="kt">int</span> <span class="o">-&gt;</span> <span class="o">?</span><span class="n">alphas</span><span class="o">:[&gt;`</span><span class="nc">ArrayLike</span><span class="o">]</span> <span class="nn">Np</span><span class="p">.</span><span class="nn">Obj</span><span class="p">.</span><span class="n">t</span> <span class="o">-&gt;</span> <span class="o">?</span><span class="n">fit_intercept</span><span class="o">:</span><span class="kt">bool</span> <span class="o">-&gt;</span> <span class="o">?</span><span class="n">normalize</span><span class="o">:</span><span class="kt">bool</span> <span class="o">-&gt;</span> <span class="o">?</span><span class="n">max_iter</span><span class="o">:</span><span class="kt">int</span> <span class="o">-&gt;</span> <span class="o">?</span><span class="n">tol</span><span class="o">:</span><span class="kt">float</span> <span class="o">-&gt;</span> <span class="o">?</span><span class="n">copy_X</span><span class="o">:</span><span class="kt">bool</span> <span class="o">-&gt;</span> <span class="o">?</span><span class="n">cv</span><span class="o">:[`</span><span class="nc">Arr</span> <span class="k">of</span> <span class="o">[&gt;`</span><span class="nc">ArrayLike</span><span class="o">]</span> <span class="nn">Np</span><span class="p">.</span><span class="nn">Obj</span><span class="p">.</span><span class="n">t</span> <span class="o">|</span> <span class="o">`</span><span class="nc">BaseCrossValidator</span> <span class="k">of</span> <span class="o">[&gt;`</span><span class="nc">BaseCrossValidator</span><span class="o">]</span> <span class="nn">Np</span><span class="p">.</span><span class="nn">Obj</span><span class="p">.</span><span class="n">t</span> <span class="o">|</span> <span class="o">`</span><span class="nc">I</span> <span class="k">of</span> <span class="kt">int</span><span class="o">]</span> <span class="o">-&gt;</span> <span class="o">?</span><span class="n">verbose</span><span class="o">:</span><span class="kt">int</span> <span class="o">-&gt;</span> <span class="o">?</span><span class="n">n_jobs</span><span class="o">:</span><span class="kt">int</span> <span class="o">-&gt;</span> <span class="o">?</span><span class="n">random_state</span><span class="o">:</span><span class="kt">int</span> <span class="o">-&gt;</span> <span class="o">?</span><span class="n">selection</span><span class="o">:</span><span class="kt">string</span> <span class="o">-&gt;</span> <span class="kt">unit</span> <span class="o">-&gt;</span> <span class="n">t</span>
</code></pre></div>

<p>Multi-task Lasso model trained with L1/L2 mixed-norm as regularizer.</p>
<p>See glossary entry for :term:<code>cross-validation estimator</code>.</p>
<p>The optimization objective for MultiTaskLasso is::</p>
<p>(1 / (2 * n_samples)) * ||Y - XW||^Fro_2 + alpha * ||W||_21</p>
<p>Where::</p>
<p>||W||<em>21 = \sum_i \sqrt{\sum_j w</em>{ij}^2}</p>
<p>i.e. the sum of norm of each row.</p>
<p>Read more in the :ref:<code>User Guide &lt;multi_task_lasso&gt;</code>.</p>
<p>.. versionadded:: 0.15</p>
<h2 id="parameters_114">Parameters<a class="headerlink" href="#parameters_114" title="Permanent link">&para;</a></h2>
<p>eps : float, optional
Length of the path. <code>eps=1e-3</code> means that
<code>alpha_min / alpha_max = 1e-3</code>.</p>
<p>n_alphas : int, optional
Number of alphas along the regularization path</p>
<p>alphas : array-like, optional
List of alphas where to compute the models.
If not provided, set automatically.</p>
<p>fit_intercept : boolean
whether to calculate the intercept for this model. If set
to false, no intercept will be used in calculations
(i.e. data is expected to be centered).</p>
<p>normalize : boolean, optional, default False
This parameter is ignored when <code>fit_intercept</code> is set to False.
If True, the regressors X will be normalized before regression by
subtracting the mean and dividing by the l2-norm.
If you wish to standardize, please use
:class:<code>sklearn.preprocessing.StandardScaler</code> before calling <code>fit</code>
on an estimator with <code>normalize=False</code>.</p>
<p>max_iter : int, optional
The maximum number of iterations.</p>
<p>tol : float, optional
The tolerance for the optimization: if the updates are
smaller than <code>tol</code>, the optimization code checks the
dual gap for optimality and continues until it is smaller
than <code>tol</code>.</p>
<p>copy_X : boolean, optional, default True
If <code>True</code>, X will be copied; else, it may be overwritten.</p>
<p>cv : int, cross-validation generator or an iterable, optional
Determines the cross-validation splitting strategy.
Possible inputs for cv are:</p>
<ul>
<li>None, to use the default 5-fold cross-validation,</li>
<li>integer, to specify the number of folds.</li>
<li>:term:<code>CV splitter</code>,</li>
<li>An iterable yielding (train, test) splits as arrays of indices.</li>
</ul>
<p>For integer/None inputs, :class:<code>KFold</code> is used.</p>
<p>Refer :ref:<code>User Guide &lt;cross_validation&gt;</code> for the various
cross-validation strategies that can be used here.</p>
<p>.. versionchanged:: 0.22
<code>cv</code> default value if None changed from 3-fold to 5-fold.</p>
<p>verbose : bool or integer
Amount of verbosity.</p>
<p>n_jobs : int or None, optional (default=None)
Number of CPUs to use during the cross validation. Note that this is
used only if multiple values for l1_ratio are given.
<code>None</code> means 1 unless in a :obj:<code>joblib.parallel_backend</code> context.
<code>-1</code> means using all processors. See :term:<code>Glossary &lt;n_jobs&gt;</code>
for more details.</p>
<p>random_state : int, RandomState instance or None, optional, default None
The seed of the pseudo random number generator that selects a random
feature to update.  If int, random_state is the seed used by the random
number generator; If RandomState instance, random_state is the random
number generator; If None, the random number generator is the
RandomState instance used by <code>np.random</code>. Used when <code>selection</code> ==
'random'</p>
<p>selection : str, default 'cyclic'
If set to 'random', a random coefficient is updated every iteration
rather than looping over features sequentially by default. This
(setting to 'random') often leads to significantly faster convergence
especially when tol is higher than 1e-4.</p>
<h2 id="attributes_18">Attributes<a class="headerlink" href="#attributes_18" title="Permanent link">&para;</a></h2>
<p>intercept_ : array, shape (n_tasks,)
Independent term in decision function.</p>
<p>coef_ : array, shape (n_tasks, n_features)
Parameter vector (W in the cost function formula).
Note that <code>coef_</code> stores the transpose of <code>W</code>, <code>W.T</code>.</p>
<p>alpha_ : float
The amount of penalization chosen by cross validation</p>
<p>mse_path_ : array, shape (n_alphas, n_folds)
mean square error for the test set on each fold, varying alpha</p>
<p>alphas_ : numpy array, shape (n_alphas,)
The grid of alphas used for fitting.</p>
<p>n_iter_ : int
number of iterations run by the coordinate descent solver to reach
the specified tolerance for the optimal alpha.</p>
<h2 id="examples_18">Examples<a class="headerlink" href="#examples_18" title="Permanent link">&para;</a></h2>
<blockquote>
<blockquote>
<blockquote>
<p>from sklearn.linear_model import MultiTaskLassoCV
from sklearn.datasets import make_regression
from sklearn.metrics import r2_score
X, y = make_regression(n_targets=2, noise=4, random_state=0)
reg = MultiTaskLassoCV(cv=5, random_state=0).fit(X, y)
r2_score(y, reg.predict(X))
0.9994...
reg.alpha_
0.5713...
reg.predict(X[:1,])
array([[153.7971...,  94.9015...]])</p>
</blockquote>
</blockquote>
</blockquote>
<h2 id="see-also_15">See also<a class="headerlink" href="#see-also_15" title="Permanent link">&para;</a></h2>
<p>MultiTaskElasticNet
ElasticNetCV
MultiTaskElasticNetCV</p>
<h2 id="notes_36">Notes<a class="headerlink" href="#notes_36" title="Permanent link">&para;</a></h2>
<p>The algorithm used to fit the model is coordinate descent.</p>
<p>To avoid unnecessary memory duplication the X argument of the fit method
should be directly passed as a Fortran-contiguous numpy array.</p>
<div class="highlight"><pre><span></span><code><span class="k">val</span> <span class="n">fit</span> <span class="o">:</span> <span class="n">x</span><span class="o">:</span><span class="nn">Py</span><span class="p">.</span><span class="nn">Object</span><span class="p">.</span><span class="n">t</span> <span class="o">-&gt;</span> <span class="n">y</span><span class="o">:[&gt;`</span><span class="nc">ArrayLike</span><span class="o">]</span> <span class="nn">Np</span><span class="p">.</span><span class="nn">Obj</span><span class="p">.</span><span class="n">t</span> <span class="o">-&gt;</span> <span class="o">[&gt;</span> <span class="n">tag</span><span class="o">]</span> <span class="nn">Obj</span><span class="p">.</span><span class="n">t</span> <span class="o">-&gt;</span> <span class="n">t</span>
</code></pre></div>

<p>Fit linear model with coordinate descent</p>
<p>Fit is on grid of alphas and best alpha estimated by cross-validation.</p>
<h2 id="parameters_115">Parameters<a class="headerlink" href="#parameters_115" title="Permanent link">&para;</a></h2>
<p>X : {array-like}, shape (n_samples, n_features)
Training data. Pass directly as Fortran-contiguous data
to avoid unnecessary memory duplication. If y is mono-output,
X can be sparse.</p>
<p>y : array-like, shape (n_samples,) or (n_samples, n_targets)
Target values</p>
<div class="highlight"><pre><span></span><code><span class="k">val</span> <span class="n">get_params</span> <span class="o">:</span> <span class="o">?</span><span class="n">deep</span><span class="o">:</span><span class="kt">bool</span> <span class="o">-&gt;</span> <span class="o">[&gt;</span> <span class="n">tag</span><span class="o">]</span> <span class="nn">Obj</span><span class="p">.</span><span class="n">t</span> <span class="o">-&gt;</span> <span class="nn">Dict</span><span class="p">.</span><span class="n">t</span>
</code></pre></div>

<p>Get parameters for this estimator.</p>
<h2 id="parameters_116">Parameters<a class="headerlink" href="#parameters_116" title="Permanent link">&para;</a></h2>
<p>deep : bool, default=True
If True, will return the parameters for this estimator and
contained subobjects that are estimators.</p>
<h2 id="returns_93">Returns<a class="headerlink" href="#returns_93" title="Permanent link">&para;</a></h2>
<p>params : mapping of string to any
Parameter names mapped to their values.</p>
<div class="highlight"><pre><span></span><code><span class="k">val</span> <span class="n">predict</span> <span class="o">:</span> <span class="n">x</span><span class="o">:[&gt;`</span><span class="nc">ArrayLike</span><span class="o">]</span> <span class="nn">Np</span><span class="p">.</span><span class="nn">Obj</span><span class="p">.</span><span class="n">t</span> <span class="o">-&gt;</span> <span class="o">[&gt;</span> <span class="n">tag</span><span class="o">]</span> <span class="nn">Obj</span><span class="p">.</span><span class="n">t</span> <span class="o">-&gt;</span> <span class="o">[&gt;`</span><span class="nc">ArrayLike</span><span class="o">]</span> <span class="nn">Np</span><span class="p">.</span><span class="nn">Obj</span><span class="p">.</span><span class="n">t</span>
</code></pre></div>

<p>Predict using the linear model.</p>
<h2 id="parameters_117">Parameters<a class="headerlink" href="#parameters_117" title="Permanent link">&para;</a></h2>
<p>X : array_like or sparse matrix, shape (n_samples, n_features)
Samples.</p>
<h2 id="returns_94">Returns<a class="headerlink" href="#returns_94" title="Permanent link">&para;</a></h2>
<p>C : array, shape (n_samples,)
Returns predicted values.</p>
<div class="highlight"><pre><span></span><code><span class="k">val</span> <span class="n">score</span> <span class="o">:</span> <span class="o">?</span><span class="n">sample_weight</span><span class="o">:[&gt;`</span><span class="nc">ArrayLike</span><span class="o">]</span> <span class="nn">Np</span><span class="p">.</span><span class="nn">Obj</span><span class="p">.</span><span class="n">t</span> <span class="o">-&gt;</span> <span class="n">x</span><span class="o">:[&gt;`</span><span class="nc">ArrayLike</span><span class="o">]</span> <span class="nn">Np</span><span class="p">.</span><span class="nn">Obj</span><span class="p">.</span><span class="n">t</span> <span class="o">-&gt;</span> <span class="n">y</span><span class="o">:[&gt;`</span><span class="nc">ArrayLike</span><span class="o">]</span> <span class="nn">Np</span><span class="p">.</span><span class="nn">Obj</span><span class="p">.</span><span class="n">t</span> <span class="o">-&gt;</span> <span class="o">[&gt;</span> <span class="n">tag</span><span class="o">]</span> <span class="nn">Obj</span><span class="p">.</span><span class="n">t</span> <span class="o">-&gt;</span> <span class="kt">float</span>
</code></pre></div>

<p>Return the coefficient of determination R^2 of the prediction.</p>
<p>The coefficient R^2 is defined as (1 - u/v), where u is the residual
sum of squares ((y_true - y_pred) <strong> 2).sum() and v is the total
sum of squares ((y_true - y_true.mean()) </strong> 2).sum().
The best possible score is 1.0 and it can be negative (because the
model can be arbitrarily worse). A constant model that always
predicts the expected value of y, disregarding the input features,
would get a R^2 score of 0.0.</p>
<h2 id="parameters_118">Parameters<a class="headerlink" href="#parameters_118" title="Permanent link">&para;</a></h2>
<p>X : array-like of shape (n_samples, n_features)
Test samples. For some estimators this may be a
precomputed kernel matrix or a list of generic objects instead,
shape = (n_samples, n_samples_fitted),
where n_samples_fitted is the number of
samples used in the fitting for the estimator.</p>
<p>y : array-like of shape (n_samples,) or (n_samples, n_outputs)
True values for X.</p>
<p>sample_weight : array-like of shape (n_samples,), default=None
Sample weights.</p>
<h2 id="returns_95">Returns<a class="headerlink" href="#returns_95" title="Permanent link">&para;</a></h2>
<p>score : float
R^2 of self.predict(X) wrt. y.</p>
<h2 id="notes_37">Notes<a class="headerlink" href="#notes_37" title="Permanent link">&para;</a></h2>
<p>The R2 score used when calling <code>score</code> on a regressor will use
<code>multioutput='uniform_average'</code> from version 0.23 to keep consistent
with :func:<code>~sklearn.metrics.r2_score</code>. This will influence the
<code>score</code> method of all the multioutput regressors (except for
:class:<code>~sklearn.multioutput.MultiOutputRegressor</code>). To specify the
default value manually and avoid the warning, please either call
:func:<code>~sklearn.metrics.r2_score</code> directly or make a custom scorer with
:func:<code>~sklearn.metrics.make_scorer</code> (the built-in scorer <code>'r2'</code> uses
<code>multioutput='uniform_average'</code>).</p>
<div class="highlight"><pre><span></span><code><span class="k">val</span> <span class="n">set_params</span> <span class="o">:</span> <span class="o">?</span><span class="n">params</span><span class="o">:(</span><span class="kt">string</span> <span class="o">*</span> <span class="nn">Py</span><span class="p">.</span><span class="nn">Object</span><span class="p">.</span><span class="n">t</span><span class="o">)</span> <span class="kt">list</span> <span class="o">-&gt;</span> <span class="o">[&gt;</span> <span class="n">tag</span><span class="o">]</span> <span class="nn">Obj</span><span class="p">.</span><span class="n">t</span> <span class="o">-&gt;</span> <span class="n">t</span>
</code></pre></div>

<p>Set the parameters of this estimator.</p>
<p>The method works on simple estimators as well as on nested objects
(such as pipelines). The latter have parameters of the form
<code>&lt;component&gt;__&lt;parameter&gt;</code> so that it's possible to update each
component of a nested object.</p>
<h2 id="parameters_119">Parameters<a class="headerlink" href="#parameters_119" title="Permanent link">&para;</a></h2>
<p>**params : dict
Estimator parameters.</p>
<h2 id="returns_96">Returns<a class="headerlink" href="#returns_96" title="Permanent link">&para;</a></h2>
<p>self : object
Estimator instance.</p>
<p>Attribute intercept_: get value or raise Not_found if None.</p>
<div class="highlight"><pre><span></span><code><span class="k">val</span> <span class="n">intercept_</span> <span class="o">:</span> <span class="n">t</span> <span class="o">-&gt;</span> <span class="o">[&gt;`</span><span class="nc">ArrayLike</span><span class="o">]</span> <span class="nn">Np</span><span class="p">.</span><span class="nn">Obj</span><span class="p">.</span><span class="n">t</span>
</code></pre></div>

<p>Attribute intercept_: get value as an option.</p>
<div class="highlight"><pre><span></span><code><span class="k">val</span> <span class="n">intercept_opt</span> <span class="o">:</span> <span class="n">t</span> <span class="o">-&gt;</span> <span class="o">([&gt;`</span><span class="nc">ArrayLike</span><span class="o">]</span> <span class="nn">Np</span><span class="p">.</span><span class="nn">Obj</span><span class="p">.</span><span class="n">t</span><span class="o">)</span> <span class="n">option</span>
</code></pre></div>

<p>Attribute coef_: get value or raise Not_found if None.</p>
<div class="highlight"><pre><span></span><code><span class="k">val</span> <span class="n">coef_</span> <span class="o">:</span> <span class="n">t</span> <span class="o">-&gt;</span> <span class="o">[&gt;`</span><span class="nc">ArrayLike</span><span class="o">]</span> <span class="nn">Np</span><span class="p">.</span><span class="nn">Obj</span><span class="p">.</span><span class="n">t</span>
</code></pre></div>

<p>Attribute coef_: get value as an option.</p>
<div class="highlight"><pre><span></span><code><span class="k">val</span> <span class="n">coef_opt</span> <span class="o">:</span> <span class="n">t</span> <span class="o">-&gt;</span> <span class="o">([&gt;`</span><span class="nc">ArrayLike</span><span class="o">]</span> <span class="nn">Np</span><span class="p">.</span><span class="nn">Obj</span><span class="p">.</span><span class="n">t</span><span class="o">)</span> <span class="n">option</span>
</code></pre></div>

<p>Attribute alpha_: get value or raise Not_found if None.</p>
<div class="highlight"><pre><span></span><code><span class="k">val</span> <span class="n">alpha_</span> <span class="o">:</span> <span class="n">t</span> <span class="o">-&gt;</span> <span class="kt">float</span>
</code></pre></div>

<p>Attribute alpha_: get value as an option.</p>
<div class="highlight"><pre><span></span><code><span class="k">val</span> <span class="n">alpha_opt</span> <span class="o">:</span> <span class="n">t</span> <span class="o">-&gt;</span> <span class="o">(</span><span class="kt">float</span><span class="o">)</span> <span class="n">option</span>
</code></pre></div>

<p>Attribute mse_path_: get value or raise Not_found if None.</p>
<div class="highlight"><pre><span></span><code><span class="k">val</span> <span class="n">mse_path_</span> <span class="o">:</span> <span class="n">t</span> <span class="o">-&gt;</span> <span class="o">[&gt;`</span><span class="nc">ArrayLike</span><span class="o">]</span> <span class="nn">Np</span><span class="p">.</span><span class="nn">Obj</span><span class="p">.</span><span class="n">t</span>
</code></pre></div>

<p>Attribute mse_path_: get value as an option.</p>
<div class="highlight"><pre><span></span><code><span class="k">val</span> <span class="n">mse_path_opt</span> <span class="o">:</span> <span class="n">t</span> <span class="o">-&gt;</span> <span class="o">([&gt;`</span><span class="nc">ArrayLike</span><span class="o">]</span> <span class="nn">Np</span><span class="p">.</span><span class="nn">Obj</span><span class="p">.</span><span class="n">t</span><span class="o">)</span> <span class="n">option</span>
</code></pre></div>

<p>Attribute alphas_: get value or raise Not_found if None.</p>
<div class="highlight"><pre><span></span><code><span class="k">val</span> <span class="n">alphas_</span> <span class="o">:</span> <span class="n">t</span> <span class="o">-&gt;</span> <span class="o">[&gt;`</span><span class="nc">ArrayLike</span><span class="o">]</span> <span class="nn">Np</span><span class="p">.</span><span class="nn">Obj</span><span class="p">.</span><span class="n">t</span>
</code></pre></div>

<p>Attribute alphas_: get value as an option.</p>
<div class="highlight"><pre><span></span><code><span class="k">val</span> <span class="n">alphas_opt</span> <span class="o">:</span> <span class="n">t</span> <span class="o">-&gt;</span> <span class="o">([&gt;`</span><span class="nc">ArrayLike</span><span class="o">]</span> <span class="nn">Np</span><span class="p">.</span><span class="nn">Obj</span><span class="p">.</span><span class="n">t</span><span class="o">)</span> <span class="n">option</span>
</code></pre></div>

<p>Attribute n_iter_: get value or raise Not_found if None.</p>
<div class="highlight"><pre><span></span><code><span class="k">val</span> <span class="n">n_iter_</span> <span class="o">:</span> <span class="n">t</span> <span class="o">-&gt;</span> <span class="kt">int</span>
</code></pre></div>

<p>Attribute n_iter_: get value as an option.</p>
<div class="highlight"><pre><span></span><code><span class="k">val</span> <span class="n">n_iter_opt</span> <span class="o">:</span> <span class="n">t</span> <span class="o">-&gt;</span> <span class="o">(</span><span class="kt">int</span><span class="o">)</span> <span class="n">option</span>
</code></pre></div>

<p>Print the object to a human-readable representation.</p>
<div class="highlight"><pre><span></span><code><span class="k">val</span> <span class="n">to_string</span> <span class="o">:</span> <span class="n">t</span> <span class="o">-&gt;</span> <span class="kt">string</span>
</code></pre></div>

<p>Print the object to a human-readable representation.</p>
<div class="highlight"><pre><span></span><code><span class="k">val</span> <span class="n">show</span> <span class="o">:</span> <span class="n">t</span> <span class="o">-&gt;</span> <span class="kt">string</span>
</code></pre></div>

<p>Pretty-print the object to a formatter.</p>
<div class="highlight"><pre><span></span><code><span class="k">val</span> <span class="n">pp</span> <span class="o">:</span> <span class="nn">Format</span><span class="p">.</span><span class="n">formatter</span> <span class="o">-&gt;</span> <span class="n">t</span> <span class="o">-&gt;</span> <span class="kt">unit</span> <span class="o">[@@</span><span class="n">ocaml</span><span class="o">.</span><span class="n">toplevel_printer</span><span class="o">]</span>



<span class="k">module</span> <span class="nc">OrthogonalMatchingPursuit</span> <span class="o">:</span> <span class="k">sig</span>
<span class="k">type</span> <span class="n">tag</span> <span class="o">=</span> <span class="o">[`</span><span class="nc">OrthogonalMatchingPursuit</span><span class="o">]</span>
<span class="k">type</span> <span class="n">t</span> <span class="o">=</span> <span class="o">[`</span><span class="nc">BaseEstimator</span> <span class="o">|</span> <span class="o">`</span><span class="nc">MultiOutputMixin</span> <span class="o">|</span> <span class="o">`</span><span class="nc">Object</span> <span class="o">|</span> <span class="o">`</span><span class="nc">OrthogonalMatchingPursuit</span> <span class="o">|</span> <span class="o">`</span><span class="nc">RegressorMixin</span><span class="o">]</span> <span class="nn">Obj</span><span class="p">.</span><span class="n">t</span>
<span class="k">val</span> <span class="n">of_pyobject</span> <span class="o">:</span> <span class="nn">Py</span><span class="p">.</span><span class="nn">Object</span><span class="p">.</span><span class="n">t</span> <span class="o">-&gt;</span> <span class="n">t</span>
<span class="k">val</span> <span class="n">to_pyobject</span> <span class="o">:</span> <span class="o">[&gt;</span> <span class="n">tag</span><span class="o">]</span> <span class="nn">Obj</span><span class="p">.</span><span class="n">t</span> <span class="o">-&gt;</span> <span class="nn">Py</span><span class="p">.</span><span class="nn">Object</span><span class="p">.</span><span class="n">t</span>

<span class="k">val</span> <span class="n">as_regressor</span> <span class="o">:</span> <span class="n">t</span> <span class="o">-&gt;</span> <span class="o">[`</span><span class="nc">RegressorMixin</span><span class="o">]</span> <span class="nn">Obj</span><span class="p">.</span><span class="n">t</span>
<span class="k">val</span> <span class="n">as_multi_output</span> <span class="o">:</span> <span class="n">t</span> <span class="o">-&gt;</span> <span class="o">[`</span><span class="nc">MultiOutputMixin</span><span class="o">]</span> <span class="nn">Obj</span><span class="p">.</span><span class="n">t</span>
<span class="k">val</span> <span class="n">as_estimator</span> <span class="o">:</span> <span class="n">t</span> <span class="o">-&gt;</span> <span class="o">[`</span><span class="nc">BaseEstimator</span><span class="o">]</span> <span class="nn">Obj</span><span class="p">.</span><span class="n">t</span>
<span class="k">val</span> <span class="n">create</span> <span class="o">:</span> <span class="o">?</span><span class="n">n_nonzero_coefs</span><span class="o">:</span><span class="kt">int</span> <span class="o">-&gt;</span> <span class="o">?</span><span class="n">tol</span><span class="o">:</span><span class="kt">float</span> <span class="o">-&gt;</span> <span class="o">?</span><span class="n">fit_intercept</span><span class="o">:</span><span class="kt">bool</span> <span class="o">-&gt;</span> <span class="o">?</span><span class="n">normalize</span><span class="o">:</span><span class="kt">bool</span> <span class="o">-&gt;</span> <span class="o">?</span><span class="n">precompute</span><span class="o">:[`</span><span class="nc">Auto</span> <span class="o">|</span> <span class="o">`</span><span class="nc">Bool</span> <span class="k">of</span> <span class="kt">bool</span><span class="o">]</span> <span class="o">-&gt;</span> <span class="kt">unit</span> <span class="o">-&gt;</span> <span class="n">t</span>
</code></pre></div>

<p>Orthogonal Matching Pursuit model (OMP)</p>
<p>Read more in the :ref:<code>User Guide &lt;omp&gt;</code>.</p>
<h2 id="parameters_120">Parameters<a class="headerlink" href="#parameters_120" title="Permanent link">&para;</a></h2>
<p>n_nonzero_coefs : int, optional
Desired number of non-zero entries in the solution. If None (by
default) this value is set to 10% of n_features.</p>
<p>tol : float, optional
Maximum norm of the residual. If not None, overrides n_nonzero_coefs.</p>
<p>fit_intercept : boolean, optional
whether to calculate the intercept for this model. If set
to false, no intercept will be used in calculations
(i.e. data is expected to be centered).</p>
<p>normalize : boolean, optional, default True
This parameter is ignored when <code>fit_intercept</code> is set to False.
If True, the regressors X will be normalized before regression by
subtracting the mean and dividing by the l2-norm.
If you wish to standardize, please use
:class:<code>sklearn.preprocessing.StandardScaler</code> before calling <code>fit</code>
on an estimator with <code>normalize=False</code>.</p>
<p>precompute : {True, False, 'auto'}, default 'auto'
Whether to use a precomputed Gram and Xy matrix to speed up
calculations. Improves performance when :term:<code>n_targets</code> or
:term:<code>n_samples</code> is very large. Note that if you already have such
matrices, you can pass them directly to the fit method.</p>
<h2 id="attributes_19">Attributes<a class="headerlink" href="#attributes_19" title="Permanent link">&para;</a></h2>
<p>coef_ : array, shape (n_features,) or (n_targets, n_features)
parameter vector (w in the formula)</p>
<p>intercept_ : float or array, shape (n_targets,)
independent term in decision function.</p>
<p>n_iter_ : int or array-like
Number of active features across every target.</p>
<h2 id="examples_19">Examples<a class="headerlink" href="#examples_19" title="Permanent link">&para;</a></h2>
<blockquote>
<blockquote>
<blockquote>
<p>from sklearn.linear_model import OrthogonalMatchingPursuit
from sklearn.datasets import make_regression
X, y = make_regression(noise=4, random_state=0)
reg = OrthogonalMatchingPursuit().fit(X, y)
reg.score(X, y)
0.9991...
reg.predict(X[:1,])
array([-78.3854...])</p>
</blockquote>
</blockquote>
</blockquote>
<h2 id="notes_38">Notes<a class="headerlink" href="#notes_38" title="Permanent link">&para;</a></h2>
<p>Orthogonal matching pursuit was introduced in G. Mallat, Z. Zhang,
Matching pursuits with time-frequency dictionaries, IEEE Transactions on
Signal Processing, Vol. 41, No. 12. (December 1993), pp. 3397-3415.
(http://blanche.polytechnique.fr/~mallat/papiers/MallatPursuit93.pdf)</p>
<p>This implementation is based on Rubinstein, R., Zibulevsky, M. and Elad,
M., Efficient Implementation of the K-SVD Algorithm using Batch Orthogonal
Matching Pursuit Technical Report - CS Technion, April 2008.
https://www.cs.technion.ac.il/~ronrubin/Publications/KSVD-OMP-v2.pdf</p>
<h2 id="see-also_16">See also<a class="headerlink" href="#see-also_16" title="Permanent link">&para;</a></h2>
<p>orthogonal_mp
orthogonal_mp_gram
lars_path
Lars
LassoLars
decomposition.sparse_encode
OrthogonalMatchingPursuitCV</p>
<div class="highlight"><pre><span></span><code><span class="k">val</span> <span class="n">fit</span> <span class="o">:</span> <span class="n">x</span><span class="o">:[&gt;`</span><span class="nc">ArrayLike</span><span class="o">]</span> <span class="nn">Np</span><span class="p">.</span><span class="nn">Obj</span><span class="p">.</span><span class="n">t</span> <span class="o">-&gt;</span> <span class="n">y</span><span class="o">:[&gt;`</span><span class="nc">ArrayLike</span><span class="o">]</span> <span class="nn">Np</span><span class="p">.</span><span class="nn">Obj</span><span class="p">.</span><span class="n">t</span> <span class="o">-&gt;</span> <span class="o">[&gt;</span> <span class="n">tag</span><span class="o">]</span> <span class="nn">Obj</span><span class="p">.</span><span class="n">t</span> <span class="o">-&gt;</span> <span class="n">t</span>
</code></pre></div>

<p>Fit the model using X, y as training data.</p>
<h2 id="parameters_121">Parameters<a class="headerlink" href="#parameters_121" title="Permanent link">&para;</a></h2>
<p>X : array-like, shape (n_samples, n_features)
Training data.</p>
<p>y : array-like, shape (n_samples,) or (n_samples, n_targets)
Target values. Will be cast to X's dtype if necessary</p>
<h2 id="returns_97">Returns<a class="headerlink" href="#returns_97" title="Permanent link">&para;</a></h2>
<p>self : object
returns an instance of self.</p>
<div class="highlight"><pre><span></span><code><span class="k">val</span> <span class="n">get_params</span> <span class="o">:</span> <span class="o">?</span><span class="n">deep</span><span class="o">:</span><span class="kt">bool</span> <span class="o">-&gt;</span> <span class="o">[&gt;</span> <span class="n">tag</span><span class="o">]</span> <span class="nn">Obj</span><span class="p">.</span><span class="n">t</span> <span class="o">-&gt;</span> <span class="nn">Dict</span><span class="p">.</span><span class="n">t</span>
</code></pre></div>

<p>Get parameters for this estimator.</p>
<h2 id="parameters_122">Parameters<a class="headerlink" href="#parameters_122" title="Permanent link">&para;</a></h2>
<p>deep : bool, default=True
If True, will return the parameters for this estimator and
contained subobjects that are estimators.</p>
<h2 id="returns_98">Returns<a class="headerlink" href="#returns_98" title="Permanent link">&para;</a></h2>
<p>params : mapping of string to any
Parameter names mapped to their values.</p>
<div class="highlight"><pre><span></span><code><span class="k">val</span> <span class="n">predict</span> <span class="o">:</span> <span class="n">x</span><span class="o">:[&gt;`</span><span class="nc">ArrayLike</span><span class="o">]</span> <span class="nn">Np</span><span class="p">.</span><span class="nn">Obj</span><span class="p">.</span><span class="n">t</span> <span class="o">-&gt;</span> <span class="o">[&gt;</span> <span class="n">tag</span><span class="o">]</span> <span class="nn">Obj</span><span class="p">.</span><span class="n">t</span> <span class="o">-&gt;</span> <span class="o">[&gt;`</span><span class="nc">ArrayLike</span><span class="o">]</span> <span class="nn">Np</span><span class="p">.</span><span class="nn">Obj</span><span class="p">.</span><span class="n">t</span>
</code></pre></div>

<p>Predict using the linear model.</p>
<h2 id="parameters_123">Parameters<a class="headerlink" href="#parameters_123" title="Permanent link">&para;</a></h2>
<p>X : array_like or sparse matrix, shape (n_samples, n_features)
Samples.</p>
<h2 id="returns_99">Returns<a class="headerlink" href="#returns_99" title="Permanent link">&para;</a></h2>
<p>C : array, shape (n_samples,)
Returns predicted values.</p>
<div class="highlight"><pre><span></span><code><span class="k">val</span> <span class="n">score</span> <span class="o">:</span> <span class="o">?</span><span class="n">sample_weight</span><span class="o">:[&gt;`</span><span class="nc">ArrayLike</span><span class="o">]</span> <span class="nn">Np</span><span class="p">.</span><span class="nn">Obj</span><span class="p">.</span><span class="n">t</span> <span class="o">-&gt;</span> <span class="n">x</span><span class="o">:[&gt;`</span><span class="nc">ArrayLike</span><span class="o">]</span> <span class="nn">Np</span><span class="p">.</span><span class="nn">Obj</span><span class="p">.</span><span class="n">t</span> <span class="o">-&gt;</span> <span class="n">y</span><span class="o">:[&gt;`</span><span class="nc">ArrayLike</span><span class="o">]</span> <span class="nn">Np</span><span class="p">.</span><span class="nn">Obj</span><span class="p">.</span><span class="n">t</span> <span class="o">-&gt;</span> <span class="o">[&gt;</span> <span class="n">tag</span><span class="o">]</span> <span class="nn">Obj</span><span class="p">.</span><span class="n">t</span> <span class="o">-&gt;</span> <span class="kt">float</span>
</code></pre></div>

<p>Return the coefficient of determination R^2 of the prediction.</p>
<p>The coefficient R^2 is defined as (1 - u/v), where u is the residual
sum of squares ((y_true - y_pred) <strong> 2).sum() and v is the total
sum of squares ((y_true - y_true.mean()) </strong> 2).sum().
The best possible score is 1.0 and it can be negative (because the
model can be arbitrarily worse). A constant model that always
predicts the expected value of y, disregarding the input features,
would get a R^2 score of 0.0.</p>
<h2 id="parameters_124">Parameters<a class="headerlink" href="#parameters_124" title="Permanent link">&para;</a></h2>
<p>X : array-like of shape (n_samples, n_features)
Test samples. For some estimators this may be a
precomputed kernel matrix or a list of generic objects instead,
shape = (n_samples, n_samples_fitted),
where n_samples_fitted is the number of
samples used in the fitting for the estimator.</p>
<p>y : array-like of shape (n_samples,) or (n_samples, n_outputs)
True values for X.</p>
<p>sample_weight : array-like of shape (n_samples,), default=None
Sample weights.</p>
<h2 id="returns_100">Returns<a class="headerlink" href="#returns_100" title="Permanent link">&para;</a></h2>
<p>score : float
R^2 of self.predict(X) wrt. y.</p>
<h2 id="notes_39">Notes<a class="headerlink" href="#notes_39" title="Permanent link">&para;</a></h2>
<p>The R2 score used when calling <code>score</code> on a regressor will use
<code>multioutput='uniform_average'</code> from version 0.23 to keep consistent
with :func:<code>~sklearn.metrics.r2_score</code>. This will influence the
<code>score</code> method of all the multioutput regressors (except for
:class:<code>~sklearn.multioutput.MultiOutputRegressor</code>). To specify the
default value manually and avoid the warning, please either call
:func:<code>~sklearn.metrics.r2_score</code> directly or make a custom scorer with
:func:<code>~sklearn.metrics.make_scorer</code> (the built-in scorer <code>'r2'</code> uses
<code>multioutput='uniform_average'</code>).</p>
<div class="highlight"><pre><span></span><code><span class="k">val</span> <span class="n">set_params</span> <span class="o">:</span> <span class="o">?</span><span class="n">params</span><span class="o">:(</span><span class="kt">string</span> <span class="o">*</span> <span class="nn">Py</span><span class="p">.</span><span class="nn">Object</span><span class="p">.</span><span class="n">t</span><span class="o">)</span> <span class="kt">list</span> <span class="o">-&gt;</span> <span class="o">[&gt;</span> <span class="n">tag</span><span class="o">]</span> <span class="nn">Obj</span><span class="p">.</span><span class="n">t</span> <span class="o">-&gt;</span> <span class="n">t</span>
</code></pre></div>

<p>Set the parameters of this estimator.</p>
<p>The method works on simple estimators as well as on nested objects
(such as pipelines). The latter have parameters of the form
<code>&lt;component&gt;__&lt;parameter&gt;</code> so that it's possible to update each
component of a nested object.</p>
<h2 id="parameters_125">Parameters<a class="headerlink" href="#parameters_125" title="Permanent link">&para;</a></h2>
<p>**params : dict
Estimator parameters.</p>
<h2 id="returns_101">Returns<a class="headerlink" href="#returns_101" title="Permanent link">&para;</a></h2>
<p>self : object
Estimator instance.</p>
<p>Attribute coef_: get value or raise Not_found if None.</p>
<div class="highlight"><pre><span></span><code><span class="k">val</span> <span class="n">coef_</span> <span class="o">:</span> <span class="n">t</span> <span class="o">-&gt;</span> <span class="o">[&gt;`</span><span class="nc">ArrayLike</span><span class="o">]</span> <span class="nn">Np</span><span class="p">.</span><span class="nn">Obj</span><span class="p">.</span><span class="n">t</span>
</code></pre></div>

<p>Attribute coef_: get value as an option.</p>
<div class="highlight"><pre><span></span><code><span class="k">val</span> <span class="n">coef_opt</span> <span class="o">:</span> <span class="n">t</span> <span class="o">-&gt;</span> <span class="o">([&gt;`</span><span class="nc">ArrayLike</span><span class="o">]</span> <span class="nn">Np</span><span class="p">.</span><span class="nn">Obj</span><span class="p">.</span><span class="n">t</span><span class="o">)</span> <span class="n">option</span>
</code></pre></div>

<p>Attribute intercept_: get value or raise Not_found if None.</p>
<div class="highlight"><pre><span></span><code><span class="k">val</span> <span class="n">intercept_</span> <span class="o">:</span> <span class="n">t</span> <span class="o">-&gt;</span> <span class="o">[&gt;`</span><span class="nc">ArrayLike</span><span class="o">]</span> <span class="nn">Np</span><span class="p">.</span><span class="nn">Obj</span><span class="p">.</span><span class="n">t</span>
</code></pre></div>

<p>Attribute intercept_: get value as an option.</p>
<div class="highlight"><pre><span></span><code><span class="k">val</span> <span class="n">intercept_opt</span> <span class="o">:</span> <span class="n">t</span> <span class="o">-&gt;</span> <span class="o">([&gt;`</span><span class="nc">ArrayLike</span><span class="o">]</span> <span class="nn">Np</span><span class="p">.</span><span class="nn">Obj</span><span class="p">.</span><span class="n">t</span><span class="o">)</span> <span class="n">option</span>
</code></pre></div>

<p>Attribute n_iter_: get value or raise Not_found if None.</p>
<div class="highlight"><pre><span></span><code><span class="k">val</span> <span class="n">n_iter_</span> <span class="o">:</span> <span class="n">t</span> <span class="o">-&gt;</span> <span class="nn">Py</span><span class="p">.</span><span class="nn">Object</span><span class="p">.</span><span class="n">t</span>
</code></pre></div>

<p>Attribute n_iter_: get value as an option.</p>
<div class="highlight"><pre><span></span><code><span class="k">val</span> <span class="n">n_iter_opt</span> <span class="o">:</span> <span class="n">t</span> <span class="o">-&gt;</span> <span class="o">(</span><span class="nn">Py</span><span class="p">.</span><span class="nn">Object</span><span class="p">.</span><span class="n">t</span><span class="o">)</span> <span class="n">option</span>
</code></pre></div>

<p>Print the object to a human-readable representation.</p>
<div class="highlight"><pre><span></span><code><span class="k">val</span> <span class="n">to_string</span> <span class="o">:</span> <span class="n">t</span> <span class="o">-&gt;</span> <span class="kt">string</span>
</code></pre></div>

<p>Print the object to a human-readable representation.</p>
<div class="highlight"><pre><span></span><code><span class="k">val</span> <span class="n">show</span> <span class="o">:</span> <span class="n">t</span> <span class="o">-&gt;</span> <span class="kt">string</span>
</code></pre></div>

<p>Pretty-print the object to a formatter.</p>
<div class="highlight"><pre><span></span><code><span class="k">val</span> <span class="n">pp</span> <span class="o">:</span> <span class="nn">Format</span><span class="p">.</span><span class="n">formatter</span> <span class="o">-&gt;</span> <span class="n">t</span> <span class="o">-&gt;</span> <span class="kt">unit</span> <span class="o">[@@</span><span class="n">ocaml</span><span class="o">.</span><span class="n">toplevel_printer</span><span class="o">]</span>



<span class="k">module</span> <span class="nc">OrthogonalMatchingPursuitCV</span> <span class="o">:</span> <span class="k">sig</span>
<span class="k">type</span> <span class="n">tag</span> <span class="o">=</span> <span class="o">[`</span><span class="nc">OrthogonalMatchingPursuitCV</span><span class="o">]</span>
<span class="k">type</span> <span class="n">t</span> <span class="o">=</span> <span class="o">[`</span><span class="nc">BaseEstimator</span> <span class="o">|</span> <span class="o">`</span><span class="nc">Object</span> <span class="o">|</span> <span class="o">`</span><span class="nc">OrthogonalMatchingPursuitCV</span> <span class="o">|</span> <span class="o">`</span><span class="nc">RegressorMixin</span><span class="o">]</span> <span class="nn">Obj</span><span class="p">.</span><span class="n">t</span>
<span class="k">val</span> <span class="n">of_pyobject</span> <span class="o">:</span> <span class="nn">Py</span><span class="p">.</span><span class="nn">Object</span><span class="p">.</span><span class="n">t</span> <span class="o">-&gt;</span> <span class="n">t</span>
<span class="k">val</span> <span class="n">to_pyobject</span> <span class="o">:</span> <span class="o">[&gt;</span> <span class="n">tag</span><span class="o">]</span> <span class="nn">Obj</span><span class="p">.</span><span class="n">t</span> <span class="o">-&gt;</span> <span class="nn">Py</span><span class="p">.</span><span class="nn">Object</span><span class="p">.</span><span class="n">t</span>

<span class="k">val</span> <span class="n">as_regressor</span> <span class="o">:</span> <span class="n">t</span> <span class="o">-&gt;</span> <span class="o">[`</span><span class="nc">RegressorMixin</span><span class="o">]</span> <span class="nn">Obj</span><span class="p">.</span><span class="n">t</span>
<span class="k">val</span> <span class="n">as_estimator</span> <span class="o">:</span> <span class="n">t</span> <span class="o">-&gt;</span> <span class="o">[`</span><span class="nc">BaseEstimator</span><span class="o">]</span> <span class="nn">Obj</span><span class="p">.</span><span class="n">t</span>
<span class="k">val</span> <span class="n">create</span> <span class="o">:</span> <span class="o">?</span><span class="n">copy</span><span class="o">:</span><span class="kt">bool</span> <span class="o">-&gt;</span> <span class="o">?</span><span class="n">fit_intercept</span><span class="o">:</span><span class="kt">bool</span> <span class="o">-&gt;</span> <span class="o">?</span><span class="n">normalize</span><span class="o">:</span><span class="kt">bool</span> <span class="o">-&gt;</span> <span class="o">?</span><span class="n">max_iter</span><span class="o">:</span><span class="kt">int</span> <span class="o">-&gt;</span> <span class="o">?</span><span class="n">cv</span><span class="o">:[`</span><span class="nc">Arr</span> <span class="k">of</span> <span class="o">[&gt;`</span><span class="nc">ArrayLike</span><span class="o">]</span> <span class="nn">Np</span><span class="p">.</span><span class="nn">Obj</span><span class="p">.</span><span class="n">t</span> <span class="o">|</span> <span class="o">`</span><span class="nc">BaseCrossValidator</span> <span class="k">of</span> <span class="o">[&gt;`</span><span class="nc">BaseCrossValidator</span><span class="o">]</span> <span class="nn">Np</span><span class="p">.</span><span class="nn">Obj</span><span class="p">.</span><span class="n">t</span> <span class="o">|</span> <span class="o">`</span><span class="nc">I</span> <span class="k">of</span> <span class="kt">int</span><span class="o">]</span> <span class="o">-&gt;</span> <span class="o">?</span><span class="n">n_jobs</span><span class="o">:</span><span class="kt">int</span> <span class="o">-&gt;</span> <span class="o">?</span><span class="n">verbose</span><span class="o">:</span><span class="kt">int</span> <span class="o">-&gt;</span> <span class="kt">unit</span> <span class="o">-&gt;</span> <span class="n">t</span>
</code></pre></div>

<p>Cross-validated Orthogonal Matching Pursuit model (OMP).</p>
<p>See glossary entry for :term:<code>cross-validation estimator</code>.</p>
<p>Read more in the :ref:<code>User Guide &lt;omp&gt;</code>.</p>
<h2 id="parameters_126">Parameters<a class="headerlink" href="#parameters_126" title="Permanent link">&para;</a></h2>
<p>copy : bool, optional
Whether the design matrix X must be copied by the algorithm. A false
value is only helpful if X is already Fortran-ordered, otherwise a
copy is made anyway.</p>
<p>fit_intercept : boolean, optional
whether to calculate the intercept for this model. If set
to false, no intercept will be used in calculations
(i.e. data is expected to be centered).</p>
<p>normalize : boolean, optional, default True
This parameter is ignored when <code>fit_intercept</code> is set to False.
If True, the regressors X will be normalized before regression by
subtracting the mean and dividing by the l2-norm.
If you wish to standardize, please use
:class:<code>sklearn.preprocessing.StandardScaler</code> before calling <code>fit</code>
on an estimator with <code>normalize=False</code>.</p>
<p>max_iter : integer, optional
Maximum numbers of iterations to perform, therefore maximum features
to include. 10% of <code>n_features</code> but at least 5 if available.</p>
<p>cv : int, cross-validation generator or an iterable, optional
Determines the cross-validation splitting strategy.
Possible inputs for cv are:</p>
<ul>
<li>None, to use the default 5-fold cross-validation,</li>
<li>integer, to specify the number of folds.</li>
<li>:term:<code>CV splitter</code>,</li>
<li>An iterable yielding (train, test) splits as arrays of indices.</li>
</ul>
<p>For integer/None inputs, :class:<code>KFold</code> is used.</p>
<p>Refer :ref:<code>User Guide &lt;cross_validation&gt;</code> for the various
cross-validation strategies that can be used here.</p>
<p>.. versionchanged:: 0.22
<code>cv</code> default value if None changed from 3-fold to 5-fold.</p>
<p>n_jobs : int or None, optional (default=None)
Number of CPUs to use during the cross validation.
<code>None</code> means 1 unless in a :obj:<code>joblib.parallel_backend</code> context.
<code>-1</code> means using all processors. See :term:<code>Glossary &lt;n_jobs&gt;</code>
for more details.</p>
<p>verbose : boolean or integer, optional
Sets the verbosity amount</p>
<h2 id="attributes_20">Attributes<a class="headerlink" href="#attributes_20" title="Permanent link">&para;</a></h2>
<p>intercept_ : float or array, shape (n_targets,)
Independent term in decision function.</p>
<p>coef_ : array, shape (n_features,) or (n_targets, n_features)
Parameter vector (w in the problem formulation).</p>
<p>n_nonzero_coefs_ : int
Estimated number of non-zero coefficients giving the best mean squared
error over the cross-validation folds.</p>
<p>n_iter_ : int or array-like
Number of active features across every target for the model refit with
the best hyperparameters got by cross-validating across all folds.</p>
<h2 id="examples_20">Examples<a class="headerlink" href="#examples_20" title="Permanent link">&para;</a></h2>
<blockquote>
<blockquote>
<blockquote>
<p>from sklearn.linear_model import OrthogonalMatchingPursuitCV
from sklearn.datasets import make_regression
X, y = make_regression(n_features=100, n_informative=10,
...                        noise=4, random_state=0)
reg = OrthogonalMatchingPursuitCV(cv=5).fit(X, y)
reg.score(X, y)
0.9991...
reg.n_nonzero_coefs_
10
reg.predict(X[:1,])
array([-78.3854...])</p>
</blockquote>
</blockquote>
</blockquote>
<h2 id="see-also_17">See also<a class="headerlink" href="#see-also_17" title="Permanent link">&para;</a></h2>
<p>orthogonal_mp
orthogonal_mp_gram
lars_path
Lars
LassoLars
OrthogonalMatchingPursuit
LarsCV
LassoLarsCV
decomposition.sparse_encode</p>
<div class="highlight"><pre><span></span><code><span class="k">val</span> <span class="n">fit</span> <span class="o">:</span> <span class="n">x</span><span class="o">:[&gt;`</span><span class="nc">ArrayLike</span><span class="o">]</span> <span class="nn">Np</span><span class="p">.</span><span class="nn">Obj</span><span class="p">.</span><span class="n">t</span> <span class="o">-&gt;</span> <span class="n">y</span><span class="o">:[&gt;`</span><span class="nc">ArrayLike</span><span class="o">]</span> <span class="nn">Np</span><span class="p">.</span><span class="nn">Obj</span><span class="p">.</span><span class="n">t</span> <span class="o">-&gt;</span> <span class="o">[&gt;</span> <span class="n">tag</span><span class="o">]</span> <span class="nn">Obj</span><span class="p">.</span><span class="n">t</span> <span class="o">-&gt;</span> <span class="n">t</span>
</code></pre></div>

<p>Fit the model using X, y as training data.</p>
<h2 id="parameters_127">Parameters<a class="headerlink" href="#parameters_127" title="Permanent link">&para;</a></h2>
<p>X : array-like, shape [n_samples, n_features]
Training data.</p>
<p>y : array-like, shape [n_samples]
Target values. Will be cast to X's dtype if necessary</p>
<h2 id="returns_102">Returns<a class="headerlink" href="#returns_102" title="Permanent link">&para;</a></h2>
<p>self : object
returns an instance of self.</p>
<div class="highlight"><pre><span></span><code><span class="k">val</span> <span class="n">get_params</span> <span class="o">:</span> <span class="o">?</span><span class="n">deep</span><span class="o">:</span><span class="kt">bool</span> <span class="o">-&gt;</span> <span class="o">[&gt;</span> <span class="n">tag</span><span class="o">]</span> <span class="nn">Obj</span><span class="p">.</span><span class="n">t</span> <span class="o">-&gt;</span> <span class="nn">Dict</span><span class="p">.</span><span class="n">t</span>
</code></pre></div>

<p>Get parameters for this estimator.</p>
<h2 id="parameters_128">Parameters<a class="headerlink" href="#parameters_128" title="Permanent link">&para;</a></h2>
<p>deep : bool, default=True
If True, will return the parameters for this estimator and
contained subobjects that are estimators.</p>
<h2 id="returns_103">Returns<a class="headerlink" href="#returns_103" title="Permanent link">&para;</a></h2>
<p>params : mapping of string to any
Parameter names mapped to their values.</p>
<div class="highlight"><pre><span></span><code><span class="k">val</span> <span class="n">predict</span> <span class="o">:</span> <span class="n">x</span><span class="o">:[&gt;`</span><span class="nc">ArrayLike</span><span class="o">]</span> <span class="nn">Np</span><span class="p">.</span><span class="nn">Obj</span><span class="p">.</span><span class="n">t</span> <span class="o">-&gt;</span> <span class="o">[&gt;</span> <span class="n">tag</span><span class="o">]</span> <span class="nn">Obj</span><span class="p">.</span><span class="n">t</span> <span class="o">-&gt;</span> <span class="o">[&gt;`</span><span class="nc">ArrayLike</span><span class="o">]</span> <span class="nn">Np</span><span class="p">.</span><span class="nn">Obj</span><span class="p">.</span><span class="n">t</span>
</code></pre></div>

<p>Predict using the linear model.</p>
<h2 id="parameters_129">Parameters<a class="headerlink" href="#parameters_129" title="Permanent link">&para;</a></h2>
<p>X : array_like or sparse matrix, shape (n_samples, n_features)
Samples.</p>
<h2 id="returns_104">Returns<a class="headerlink" href="#returns_104" title="Permanent link">&para;</a></h2>
<p>C : array, shape (n_samples,)
Returns predicted values.</p>
<div class="highlight"><pre><span></span><code><span class="k">val</span> <span class="n">score</span> <span class="o">:</span> <span class="o">?</span><span class="n">sample_weight</span><span class="o">:[&gt;`</span><span class="nc">ArrayLike</span><span class="o">]</span> <span class="nn">Np</span><span class="p">.</span><span class="nn">Obj</span><span class="p">.</span><span class="n">t</span> <span class="o">-&gt;</span> <span class="n">x</span><span class="o">:[&gt;`</span><span class="nc">ArrayLike</span><span class="o">]</span> <span class="nn">Np</span><span class="p">.</span><span class="nn">Obj</span><span class="p">.</span><span class="n">t</span> <span class="o">-&gt;</span> <span class="n">y</span><span class="o">:[&gt;`</span><span class="nc">ArrayLike</span><span class="o">]</span> <span class="nn">Np</span><span class="p">.</span><span class="nn">Obj</span><span class="p">.</span><span class="n">t</span> <span class="o">-&gt;</span> <span class="o">[&gt;</span> <span class="n">tag</span><span class="o">]</span> <span class="nn">Obj</span><span class="p">.</span><span class="n">t</span> <span class="o">-&gt;</span> <span class="kt">float</span>
</code></pre></div>

<p>Return the coefficient of determination R^2 of the prediction.</p>
<p>The coefficient R^2 is defined as (1 - u/v), where u is the residual
sum of squares ((y_true - y_pred) <strong> 2).sum() and v is the total
sum of squares ((y_true - y_true.mean()) </strong> 2).sum().
The best possible score is 1.0 and it can be negative (because the
model can be arbitrarily worse). A constant model that always
predicts the expected value of y, disregarding the input features,
would get a R^2 score of 0.0.</p>
<h2 id="parameters_130">Parameters<a class="headerlink" href="#parameters_130" title="Permanent link">&para;</a></h2>
<p>X : array-like of shape (n_samples, n_features)
Test samples. For some estimators this may be a
precomputed kernel matrix or a list of generic objects instead,
shape = (n_samples, n_samples_fitted),
where n_samples_fitted is the number of
samples used in the fitting for the estimator.</p>
<p>y : array-like of shape (n_samples,) or (n_samples, n_outputs)
True values for X.</p>
<p>sample_weight : array-like of shape (n_samples,), default=None
Sample weights.</p>
<h2 id="returns_105">Returns<a class="headerlink" href="#returns_105" title="Permanent link">&para;</a></h2>
<p>score : float
R^2 of self.predict(X) wrt. y.</p>
<h2 id="notes_40">Notes<a class="headerlink" href="#notes_40" title="Permanent link">&para;</a></h2>
<p>The R2 score used when calling <code>score</code> on a regressor will use
<code>multioutput='uniform_average'</code> from version 0.23 to keep consistent
with :func:<code>~sklearn.metrics.r2_score</code>. This will influence the
<code>score</code> method of all the multioutput regressors (except for
:class:<code>~sklearn.multioutput.MultiOutputRegressor</code>). To specify the
default value manually and avoid the warning, please either call
:func:<code>~sklearn.metrics.r2_score</code> directly or make a custom scorer with
:func:<code>~sklearn.metrics.make_scorer</code> (the built-in scorer <code>'r2'</code> uses
<code>multioutput='uniform_average'</code>).</p>
<div class="highlight"><pre><span></span><code><span class="k">val</span> <span class="n">set_params</span> <span class="o">:</span> <span class="o">?</span><span class="n">params</span><span class="o">:(</span><span class="kt">string</span> <span class="o">*</span> <span class="nn">Py</span><span class="p">.</span><span class="nn">Object</span><span class="p">.</span><span class="n">t</span><span class="o">)</span> <span class="kt">list</span> <span class="o">-&gt;</span> <span class="o">[&gt;</span> <span class="n">tag</span><span class="o">]</span> <span class="nn">Obj</span><span class="p">.</span><span class="n">t</span> <span class="o">-&gt;</span> <span class="n">t</span>
</code></pre></div>

<p>Set the parameters of this estimator.</p>
<p>The method works on simple estimators as well as on nested objects
(such as pipelines). The latter have parameters of the form
<code>&lt;component&gt;__&lt;parameter&gt;</code> so that it's possible to update each
component of a nested object.</p>
<h2 id="parameters_131">Parameters<a class="headerlink" href="#parameters_131" title="Permanent link">&para;</a></h2>
<p>**params : dict
Estimator parameters.</p>
<h2 id="returns_106">Returns<a class="headerlink" href="#returns_106" title="Permanent link">&para;</a></h2>
<p>self : object
Estimator instance.</p>
<p>Attribute intercept_: get value or raise Not_found if None.</p>
<div class="highlight"><pre><span></span><code><span class="k">val</span> <span class="n">intercept_</span> <span class="o">:</span> <span class="n">t</span> <span class="o">-&gt;</span> <span class="o">[&gt;`</span><span class="nc">ArrayLike</span><span class="o">]</span> <span class="nn">Np</span><span class="p">.</span><span class="nn">Obj</span><span class="p">.</span><span class="n">t</span>
</code></pre></div>

<p>Attribute intercept_: get value as an option.</p>
<div class="highlight"><pre><span></span><code><span class="k">val</span> <span class="n">intercept_opt</span> <span class="o">:</span> <span class="n">t</span> <span class="o">-&gt;</span> <span class="o">([&gt;`</span><span class="nc">ArrayLike</span><span class="o">]</span> <span class="nn">Np</span><span class="p">.</span><span class="nn">Obj</span><span class="p">.</span><span class="n">t</span><span class="o">)</span> <span class="n">option</span>
</code></pre></div>

<p>Attribute coef_: get value or raise Not_found if None.</p>
<div class="highlight"><pre><span></span><code><span class="k">val</span> <span class="n">coef_</span> <span class="o">:</span> <span class="n">t</span> <span class="o">-&gt;</span> <span class="o">[&gt;`</span><span class="nc">ArrayLike</span><span class="o">]</span> <span class="nn">Np</span><span class="p">.</span><span class="nn">Obj</span><span class="p">.</span><span class="n">t</span>
</code></pre></div>

<p>Attribute coef_: get value as an option.</p>
<div class="highlight"><pre><span></span><code><span class="k">val</span> <span class="n">coef_opt</span> <span class="o">:</span> <span class="n">t</span> <span class="o">-&gt;</span> <span class="o">([&gt;`</span><span class="nc">ArrayLike</span><span class="o">]</span> <span class="nn">Np</span><span class="p">.</span><span class="nn">Obj</span><span class="p">.</span><span class="n">t</span><span class="o">)</span> <span class="n">option</span>
</code></pre></div>

<p>Attribute n_nonzero_coefs_: get value or raise Not_found if None.</p>
<div class="highlight"><pre><span></span><code><span class="k">val</span> <span class="n">n_nonzero_coefs_</span> <span class="o">:</span> <span class="n">t</span> <span class="o">-&gt;</span> <span class="kt">int</span>
</code></pre></div>

<p>Attribute n_nonzero_coefs_: get value as an option.</p>
<div class="highlight"><pre><span></span><code><span class="k">val</span> <span class="n">n_nonzero_coefs_opt</span> <span class="o">:</span> <span class="n">t</span> <span class="o">-&gt;</span> <span class="o">(</span><span class="kt">int</span><span class="o">)</span> <span class="n">option</span>
</code></pre></div>

<p>Attribute n_iter_: get value or raise Not_found if None.</p>
<div class="highlight"><pre><span></span><code><span class="k">val</span> <span class="n">n_iter_</span> <span class="o">:</span> <span class="n">t</span> <span class="o">-&gt;</span> <span class="nn">Py</span><span class="p">.</span><span class="nn">Object</span><span class="p">.</span><span class="n">t</span>
</code></pre></div>

<p>Attribute n_iter_: get value as an option.</p>
<div class="highlight"><pre><span></span><code><span class="k">val</span> <span class="n">n_iter_opt</span> <span class="o">:</span> <span class="n">t</span> <span class="o">-&gt;</span> <span class="o">(</span><span class="nn">Py</span><span class="p">.</span><span class="nn">Object</span><span class="p">.</span><span class="n">t</span><span class="o">)</span> <span class="n">option</span>
</code></pre></div>

<p>Print the object to a human-readable representation.</p>
<div class="highlight"><pre><span></span><code><span class="k">val</span> <span class="n">to_string</span> <span class="o">:</span> <span class="n">t</span> <span class="o">-&gt;</span> <span class="kt">string</span>
</code></pre></div>

<p>Print the object to a human-readable representation.</p>
<div class="highlight"><pre><span></span><code><span class="k">val</span> <span class="n">show</span> <span class="o">:</span> <span class="n">t</span> <span class="o">-&gt;</span> <span class="kt">string</span>
</code></pre></div>

<p>Pretty-print the object to a formatter.</p>
<div class="highlight"><pre><span></span><code><span class="k">val</span> <span class="n">pp</span> <span class="o">:</span> <span class="nn">Format</span><span class="p">.</span><span class="n">formatter</span> <span class="o">-&gt;</span> <span class="n">t</span> <span class="o">-&gt;</span> <span class="kt">unit</span> <span class="o">[@@</span><span class="n">ocaml</span><span class="o">.</span><span class="n">toplevel_printer</span><span class="o">]</span>



<span class="k">module</span> <span class="nc">PassiveAggressiveClassifier</span> <span class="o">:</span> <span class="k">sig</span>
<span class="k">type</span> <span class="n">tag</span> <span class="o">=</span> <span class="o">[`</span><span class="nc">PassiveAggressiveClassifier</span><span class="o">]</span>
<span class="k">type</span> <span class="n">t</span> <span class="o">=</span> <span class="o">[`</span><span class="nc">BaseEstimator</span> <span class="o">|</span> <span class="o">`</span><span class="nc">BaseSGD</span> <span class="o">|</span> <span class="o">`</span><span class="nc">BaseSGDClassifier</span> <span class="o">|</span> <span class="o">`</span><span class="nc">ClassifierMixin</span> <span class="o">|</span> <span class="o">`</span><span class="nc">LinearClassifierMixin</span> <span class="o">|</span> <span class="o">`</span><span class="nc">Object</span> <span class="o">|</span> <span class="o">`</span><span class="nc">PassiveAggressiveClassifier</span> <span class="o">|</span> <span class="o">`</span><span class="nc">SparseCoefMixin</span><span class="o">]</span> <span class="nn">Obj</span><span class="p">.</span><span class="n">t</span>
<span class="k">val</span> <span class="n">of_pyobject</span> <span class="o">:</span> <span class="nn">Py</span><span class="p">.</span><span class="nn">Object</span><span class="p">.</span><span class="n">t</span> <span class="o">-&gt;</span> <span class="n">t</span>
<span class="k">val</span> <span class="n">to_pyobject</span> <span class="o">:</span> <span class="o">[&gt;</span> <span class="n">tag</span><span class="o">]</span> <span class="nn">Obj</span><span class="p">.</span><span class="n">t</span> <span class="o">-&gt;</span> <span class="nn">Py</span><span class="p">.</span><span class="nn">Object</span><span class="p">.</span><span class="n">t</span>

<span class="k">val</span> <span class="n">as_linear_classifier</span> <span class="o">:</span> <span class="n">t</span> <span class="o">-&gt;</span> <span class="o">[`</span><span class="nc">LinearClassifierMixin</span><span class="o">]</span> <span class="nn">Obj</span><span class="p">.</span><span class="n">t</span>
<span class="k">val</span> <span class="n">as_sgd_classifier</span> <span class="o">:</span> <span class="n">t</span> <span class="o">-&gt;</span> <span class="o">[`</span><span class="nc">BaseSGDClassifier</span><span class="o">]</span> <span class="nn">Obj</span><span class="p">.</span><span class="n">t</span>
<span class="k">val</span> <span class="n">as_classifier</span> <span class="o">:</span> <span class="n">t</span> <span class="o">-&gt;</span> <span class="o">[`</span><span class="nc">ClassifierMixin</span><span class="o">]</span> <span class="nn">Obj</span><span class="p">.</span><span class="n">t</span>
<span class="k">val</span> <span class="n">as_estimator</span> <span class="o">:</span> <span class="n">t</span> <span class="o">-&gt;</span> <span class="o">[`</span><span class="nc">BaseEstimator</span><span class="o">]</span> <span class="nn">Obj</span><span class="p">.</span><span class="n">t</span>
<span class="k">val</span> <span class="n">as_sparse_coef</span> <span class="o">:</span> <span class="n">t</span> <span class="o">-&gt;</span> <span class="o">[`</span><span class="nc">SparseCoefMixin</span><span class="o">]</span> <span class="nn">Obj</span><span class="p">.</span><span class="n">t</span>
<span class="k">val</span> <span class="n">as_sgd</span> <span class="o">:</span> <span class="n">t</span> <span class="o">-&gt;</span> <span class="o">[`</span><span class="nc">BaseSGD</span><span class="o">]</span> <span class="nn">Obj</span><span class="p">.</span><span class="n">t</span>
<span class="k">val</span> <span class="n">create</span> <span class="o">:</span> <span class="o">?</span><span class="n">c</span><span class="o">:</span><span class="kt">float</span> <span class="o">-&gt;</span> <span class="o">?</span><span class="n">fit_intercept</span><span class="o">:</span><span class="kt">bool</span> <span class="o">-&gt;</span> <span class="o">?</span><span class="n">max_iter</span><span class="o">:</span><span class="kt">int</span> <span class="o">-&gt;</span> <span class="o">?</span><span class="n">tol</span><span class="o">:[`</span><span class="nc">F</span> <span class="k">of</span> <span class="kt">float</span> <span class="o">|</span> <span class="o">`</span><span class="nc">None</span><span class="o">]</span> <span class="o">-&gt;</span> <span class="o">?</span><span class="n">early_stopping</span><span class="o">:</span><span class="kt">bool</span> <span class="o">-&gt;</span> <span class="o">?</span><span class="n">validation_fraction</span><span class="o">:</span><span class="kt">float</span> <span class="o">-&gt;</span> <span class="o">?</span><span class="n">n_iter_no_change</span><span class="o">:</span><span class="kt">int</span> <span class="o">-&gt;</span> <span class="o">?</span><span class="n">shuffle</span><span class="o">:</span><span class="kt">bool</span> <span class="o">-&gt;</span> <span class="o">?</span><span class="n">verbose</span><span class="o">:</span><span class="kt">int</span> <span class="o">-&gt;</span> <span class="o">?</span><span class="n">loss</span><span class="o">:</span><span class="kt">string</span> <span class="o">-&gt;</span> <span class="o">?</span><span class="n">n_jobs</span><span class="o">:</span><span class="kt">int</span> <span class="o">-&gt;</span> <span class="o">?</span><span class="n">random_state</span><span class="o">:</span><span class="kt">int</span> <span class="o">-&gt;</span> <span class="o">?</span><span class="n">warm_start</span><span class="o">:</span><span class="kt">bool</span> <span class="o">-&gt;</span> <span class="o">?</span><span class="n">class_weight</span><span class="o">:</span><span class="nn">Py</span><span class="p">.</span><span class="nn">Object</span><span class="p">.</span><span class="n">t</span> <span class="o">-&gt;</span> <span class="o">?</span><span class="n">average</span><span class="o">:[`</span><span class="nc">I</span> <span class="k">of</span> <span class="kt">int</span> <span class="o">|</span> <span class="o">`</span><span class="nc">Bool</span> <span class="k">of</span> <span class="kt">bool</span><span class="o">]</span> <span class="o">-&gt;</span> <span class="kt">unit</span> <span class="o">-&gt;</span> <span class="n">t</span>
</code></pre></div>

<p>Passive Aggressive Classifier</p>
<p>Read more in the :ref:<code>User Guide &lt;passive_aggressive&gt;</code>.</p>
<h2 id="parameters_132">Parameters<a class="headerlink" href="#parameters_132" title="Permanent link">&para;</a></h2>
<p>C : float
Maximum step size (regularization). Defaults to 1.0.</p>
<p>fit_intercept : bool, default=False
Whether the intercept should be estimated or not. If False, the
data is assumed to be already centered.</p>
<p>max_iter : int, optional (default=1000)
The maximum number of passes over the training data (aka epochs).
It only impacts the behavior in the <code>fit</code> method, and not the
:meth:<code>partial_fit</code> method.</p>
<p>.. versionadded:: 0.19</p>
<p>tol : float or None, optional (default=1e-3)
The stopping criterion. If it is not None, the iterations will stop
when (loss &gt; previous_loss - tol).</p>
<p>.. versionadded:: 0.19</p>
<p>early_stopping : bool, default=False
Whether to use early stopping to terminate training when validation.
score is not improving. If set to True, it will automatically set aside
a stratified fraction of training data as validation and terminate
training when validation score is not improving by at least tol for
n_iter_no_change consecutive epochs.</p>
<p>.. versionadded:: 0.20</p>
<p>validation_fraction : float, default=0.1
The proportion of training data to set aside as validation set for
early stopping. Must be between 0 and 1.
Only used if early_stopping is True.</p>
<p>.. versionadded:: 0.20</p>
<p>n_iter_no_change : int, default=5
Number of iterations with no improvement to wait before early stopping.</p>
<p>.. versionadded:: 0.20</p>
<p>shuffle : bool, default=True
Whether or not the training data should be shuffled after each epoch.</p>
<p>verbose : integer, optional
The verbosity level</p>
<p>loss : string, optional
The loss function to be used:
hinge: equivalent to PA-I in the reference paper.
squared_hinge: equivalent to PA-II in the reference paper.</p>
<p>n_jobs : int or None, optional (default=None)
The number of CPUs to use to do the OVA (One Versus All, for
multi-class problems) computation.
<code>None</code> means 1 unless in a :obj:<code>joblib.parallel_backend</code> context.
<code>-1</code> means using all processors. See :term:<code>Glossary &lt;n_jobs&gt;</code>
for more details.</p>
<p>random_state : int, RandomState instance or None, optional, default=None
The seed of the pseudo random number generator to use when shuffling
the data.  If int, random_state is the seed used by the random number
generator; If RandomState instance, random_state is the random number
generator; If None, the random number generator is the RandomState
instance used by <code>np.random</code>.</p>
<p>warm_start : bool, optional
When set to True, reuse the solution of the previous call to fit as
initialization, otherwise, just erase the previous solution.
See :term:<code>the Glossary &lt;warm_start&gt;</code>.</p>
<p>Repeatedly calling fit or partial_fit when warm_start is True can
result in a different solution than when calling fit a single time
because of the way the data is shuffled.</p>
<p>class_weight : dict, {class_label: weight} or 'balanced' or None, optional
Preset for the class_weight fit parameter.</p>
<p>Weights associated with classes. If not given, all classes
are supposed to have weight one.</p>
<p>The 'balanced' mode uses the values of y to automatically adjust
weights inversely proportional to class frequencies in the input data
as <code>n_samples / (n_classes * np.bincount(y))</code></p>
<p>.. versionadded:: 0.17
parameter <em>class_weight</em> to automatically weight samples.</p>
<p>average : bool or int, optional
When set to True, computes the averaged SGD weights and stores the
result in the <code>coef_</code> attribute. If set to an int greater than 1,
averaging will begin once the total number of samples seen reaches
average. So average=10 will begin averaging after seeing 10 samples.</p>
<p>.. versionadded:: 0.19
parameter <em>average</em> to use weights averaging in SGD</p>
<h2 id="attributes_21">Attributes<a class="headerlink" href="#attributes_21" title="Permanent link">&para;</a></h2>
<p>coef_ : array, shape = [1, n_features] if n_classes == 2 else [n_classes,            n_features]
Weights assigned to the features.</p>
<p>intercept_ : array, shape = [1] if n_classes == 2 else [n_classes]
Constants in decision function.</p>
<p>n_iter_ : int
The actual number of iterations to reach the stopping criterion.
For multiclass fits, it is the maximum over every binary fit.</p>
<p>classes_ : array of shape (n_classes,)
The unique classes labels.</p>
<p>t_ : int
Number of weight updates performed during training.
Same as <code>(n_iter_ * n_samples)</code>.</p>
<h2 id="examples_21">Examples<a class="headerlink" href="#examples_21" title="Permanent link">&para;</a></h2>
<blockquote>
<blockquote>
<blockquote>
<p>from sklearn.linear_model import PassiveAggressiveClassifier
from sklearn.datasets import make_classification</p>
<p>X, y = make_classification(n_features=4, random_state=0)
clf = PassiveAggressiveClassifier(max_iter=1000, random_state=0,
... tol=1e-3)
clf.fit(X, y)
PassiveAggressiveClassifier(random_state=0)
print(clf.coef_)
[[0.26642044 0.45070924 0.67251877 0.64185414]]
print(clf.intercept_)
[1.84127814]
print(clf.predict([[0, 0, 0, 0]]))
[1]</p>
</blockquote>
</blockquote>
</blockquote>
<h2 id="see-also_18">See also<a class="headerlink" href="#see-also_18" title="Permanent link">&para;</a></h2>
<p>SGDClassifier
Perceptron</p>
<h2 id="references_4">References<a class="headerlink" href="#references_4" title="Permanent link">&para;</a></h2>
<p>Online Passive-Aggressive Algorithms
<a href="http://jmlr.csail.mit.edu/papers/volume7/crammer06a/crammer06a.pdf">http://jmlr.csail.mit.edu/papers/volume7/crammer06a/crammer06a.pdf</a>
K. Crammer, O. Dekel, J. Keshat, S. Shalev-Shwartz, Y. Singer - JMLR (2006)</p>
<div class="highlight"><pre><span></span><code><span class="k">val</span> <span class="n">decision_function</span> <span class="o">:</span> <span class="n">x</span><span class="o">:[&gt;`</span><span class="nc">ArrayLike</span><span class="o">]</span> <span class="nn">Np</span><span class="p">.</span><span class="nn">Obj</span><span class="p">.</span><span class="n">t</span> <span class="o">-&gt;</span> <span class="o">[&gt;</span> <span class="n">tag</span><span class="o">]</span> <span class="nn">Obj</span><span class="p">.</span><span class="n">t</span> <span class="o">-&gt;</span> <span class="o">[&gt;`</span><span class="nc">ArrayLike</span><span class="o">]</span> <span class="nn">Np</span><span class="p">.</span><span class="nn">Obj</span><span class="p">.</span><span class="n">t</span>
</code></pre></div>

<p>Predict confidence scores for samples.</p>
<p>The confidence score for a sample is the signed distance of that
sample to the hyperplane.</p>
<h2 id="parameters_133">Parameters<a class="headerlink" href="#parameters_133" title="Permanent link">&para;</a></h2>
<p>X : array_like or sparse matrix, shape (n_samples, n_features)
Samples.</p>
<h2 id="returns_107">Returns<a class="headerlink" href="#returns_107" title="Permanent link">&para;</a></h2>
<p>array, shape=(n_samples,) if n_classes == 2 else (n_samples, n_classes)
Confidence scores per (sample, class) combination. In the binary
case, confidence score for self.classes_[1] where &gt;0 means this
class would be predicted.</p>
<div class="highlight"><pre><span></span><code><span class="k">val</span> <span class="n">densify</span> <span class="o">:</span> <span class="o">[&gt;</span> <span class="n">tag</span><span class="o">]</span> <span class="nn">Obj</span><span class="p">.</span><span class="n">t</span> <span class="o">-&gt;</span> <span class="n">t</span>
</code></pre></div>

<p>Convert coefficient matrix to dense array format.</p>
<p>Converts the <code>coef_</code> member (back) to a numpy.ndarray. This is the
default format of <code>coef_</code> and is required for fitting, so calling
this method is only required on models that have previously been
sparsified; otherwise, it is a no-op.</p>
<h2 id="returns_108">Returns<a class="headerlink" href="#returns_108" title="Permanent link">&para;</a></h2>
<p>self
Fitted estimator.</p>
<div class="highlight"><pre><span></span><code><span class="k">val</span> <span class="n">fit</span> <span class="o">:</span> <span class="o">?</span><span class="n">coef_init</span><span class="o">:[&gt;`</span><span class="nc">ArrayLike</span><span class="o">]</span> <span class="nn">Np</span><span class="p">.</span><span class="nn">Obj</span><span class="p">.</span><span class="n">t</span> <span class="o">-&gt;</span> <span class="o">?</span><span class="n">intercept_init</span><span class="o">:[&gt;`</span><span class="nc">ArrayLike</span><span class="o">]</span> <span class="nn">Np</span><span class="p">.</span><span class="nn">Obj</span><span class="p">.</span><span class="n">t</span> <span class="o">-&gt;</span> <span class="n">x</span><span class="o">:[&gt;`</span><span class="nc">ArrayLike</span><span class="o">]</span> <span class="nn">Np</span><span class="p">.</span><span class="nn">Obj</span><span class="p">.</span><span class="n">t</span> <span class="o">-&gt;</span> <span class="n">y</span><span class="o">:[&gt;`</span><span class="nc">ArrayLike</span><span class="o">]</span> <span class="nn">Np</span><span class="p">.</span><span class="nn">Obj</span><span class="p">.</span><span class="n">t</span> <span class="o">-&gt;</span> <span class="o">[&gt;</span> <span class="n">tag</span><span class="o">]</span> <span class="nn">Obj</span><span class="p">.</span><span class="n">t</span> <span class="o">-&gt;</span> <span class="n">t</span>
</code></pre></div>

<p>Fit linear model with Passive Aggressive algorithm.</p>
<h2 id="parameters_134">Parameters<a class="headerlink" href="#parameters_134" title="Permanent link">&para;</a></h2>
<p>X : {array-like, sparse matrix} of shape (n_samples, n_features)
Training data</p>
<p>y : numpy array of shape [n_samples]
Target values</p>
<p>coef_init : array, shape = [n_classes,n_features]
The initial coefficients to warm-start the optimization.</p>
<p>intercept_init : array, shape = [n_classes]
The initial intercept to warm-start the optimization.</p>
<h2 id="returns_109">Returns<a class="headerlink" href="#returns_109" title="Permanent link">&para;</a></h2>
<p>self : returns an instance of self.</p>
<div class="highlight"><pre><span></span><code><span class="k">val</span> <span class="n">get_params</span> <span class="o">:</span> <span class="o">?</span><span class="n">deep</span><span class="o">:</span><span class="kt">bool</span> <span class="o">-&gt;</span> <span class="o">[&gt;</span> <span class="n">tag</span><span class="o">]</span> <span class="nn">Obj</span><span class="p">.</span><span class="n">t</span> <span class="o">-&gt;</span> <span class="nn">Dict</span><span class="p">.</span><span class="n">t</span>
</code></pre></div>

<p>Get parameters for this estimator.</p>
<h2 id="parameters_135">Parameters<a class="headerlink" href="#parameters_135" title="Permanent link">&para;</a></h2>
<p>deep : bool, default=True
If True, will return the parameters for this estimator and
contained subobjects that are estimators.</p>
<h2 id="returns_110">Returns<a class="headerlink" href="#returns_110" title="Permanent link">&para;</a></h2>
<p>params : mapping of string to any
Parameter names mapped to their values.</p>
<div class="highlight"><pre><span></span><code><span class="k">val</span> <span class="n">partial_fit</span> <span class="o">:</span> <span class="o">?</span><span class="n">classes</span><span class="o">:[&gt;`</span><span class="nc">ArrayLike</span><span class="o">]</span> <span class="nn">Np</span><span class="p">.</span><span class="nn">Obj</span><span class="p">.</span><span class="n">t</span> <span class="o">-&gt;</span> <span class="n">x</span><span class="o">:[&gt;`</span><span class="nc">ArrayLike</span><span class="o">]</span> <span class="nn">Np</span><span class="p">.</span><span class="nn">Obj</span><span class="p">.</span><span class="n">t</span> <span class="o">-&gt;</span> <span class="n">y</span><span class="o">:[&gt;`</span><span class="nc">ArrayLike</span><span class="o">]</span> <span class="nn">Np</span><span class="p">.</span><span class="nn">Obj</span><span class="p">.</span><span class="n">t</span> <span class="o">-&gt;</span> <span class="o">[&gt;</span> <span class="n">tag</span><span class="o">]</span> <span class="nn">Obj</span><span class="p">.</span><span class="n">t</span> <span class="o">-&gt;</span> <span class="n">t</span>
</code></pre></div>

<p>Fit linear model with Passive Aggressive algorithm.</p>
<h2 id="parameters_136">Parameters<a class="headerlink" href="#parameters_136" title="Permanent link">&para;</a></h2>
<p>X : {array-like, sparse matrix} of shape (n_samples, n_features)
Subset of the training data</p>
<p>y : numpy array of shape [n_samples]
Subset of the target values</p>
<p>classes : array, shape = [n_classes]
Classes across all calls to partial_fit.
Can be obtained by via <code>np.unique(y_all)</code>, where y_all is the
target vector of the entire dataset.
This argument is required for the first call to partial_fit
and can be omitted in the subsequent calls.
Note that y doesn't need to contain all labels in <code>classes</code>.</p>
<h2 id="returns_111">Returns<a class="headerlink" href="#returns_111" title="Permanent link">&para;</a></h2>
<p>self : returns an instance of self.</p>
<div class="highlight"><pre><span></span><code><span class="k">val</span> <span class="n">predict</span> <span class="o">:</span> <span class="n">x</span><span class="o">:[&gt;`</span><span class="nc">ArrayLike</span><span class="o">]</span> <span class="nn">Np</span><span class="p">.</span><span class="nn">Obj</span><span class="p">.</span><span class="n">t</span> <span class="o">-&gt;</span> <span class="o">[&gt;</span> <span class="n">tag</span><span class="o">]</span> <span class="nn">Obj</span><span class="p">.</span><span class="n">t</span> <span class="o">-&gt;</span> <span class="o">[&gt;`</span><span class="nc">ArrayLike</span><span class="o">]</span> <span class="nn">Np</span><span class="p">.</span><span class="nn">Obj</span><span class="p">.</span><span class="n">t</span>
</code></pre></div>

<p>Predict class labels for samples in X.</p>
<h2 id="parameters_137">Parameters<a class="headerlink" href="#parameters_137" title="Permanent link">&para;</a></h2>
<p>X : array_like or sparse matrix, shape (n_samples, n_features)
Samples.</p>
<h2 id="returns_112">Returns<a class="headerlink" href="#returns_112" title="Permanent link">&para;</a></h2>
<p>C : array, shape [n_samples]
Predicted class label per sample.</p>
<div class="highlight"><pre><span></span><code><span class="k">val</span> <span class="n">score</span> <span class="o">:</span> <span class="o">?</span><span class="n">sample_weight</span><span class="o">:[&gt;`</span><span class="nc">ArrayLike</span><span class="o">]</span> <span class="nn">Np</span><span class="p">.</span><span class="nn">Obj</span><span class="p">.</span><span class="n">t</span> <span class="o">-&gt;</span> <span class="n">x</span><span class="o">:[&gt;`</span><span class="nc">ArrayLike</span><span class="o">]</span> <span class="nn">Np</span><span class="p">.</span><span class="nn">Obj</span><span class="p">.</span><span class="n">t</span> <span class="o">-&gt;</span> <span class="n">y</span><span class="o">:[&gt;`</span><span class="nc">ArrayLike</span><span class="o">]</span> <span class="nn">Np</span><span class="p">.</span><span class="nn">Obj</span><span class="p">.</span><span class="n">t</span> <span class="o">-&gt;</span> <span class="o">[&gt;</span> <span class="n">tag</span><span class="o">]</span> <span class="nn">Obj</span><span class="p">.</span><span class="n">t</span> <span class="o">-&gt;</span> <span class="kt">float</span>
</code></pre></div>

<p>Return the mean accuracy on the given test data and labels.</p>
<p>In multi-label classification, this is the subset accuracy
which is a harsh metric since you require for each sample that
each label set be correctly predicted.</p>
<h2 id="parameters_138">Parameters<a class="headerlink" href="#parameters_138" title="Permanent link">&para;</a></h2>
<p>X : array-like of shape (n_samples, n_features)
Test samples.</p>
<p>y : array-like of shape (n_samples,) or (n_samples, n_outputs)
True labels for X.</p>
<p>sample_weight : array-like of shape (n_samples,), default=None
Sample weights.</p>
<h2 id="returns_113">Returns<a class="headerlink" href="#returns_113" title="Permanent link">&para;</a></h2>
<p>score : float
Mean accuracy of self.predict(X) wrt. y.</p>
<div class="highlight"><pre><span></span><code><span class="k">val</span> <span class="n">set_params</span> <span class="o">:</span> <span class="o">?</span><span class="n">kwargs</span><span class="o">:(</span><span class="kt">string</span> <span class="o">*</span> <span class="nn">Py</span><span class="p">.</span><span class="nn">Object</span><span class="p">.</span><span class="n">t</span><span class="o">)</span> <span class="kt">list</span> <span class="o">-&gt;</span> <span class="o">[&gt;</span> <span class="n">tag</span><span class="o">]</span> <span class="nn">Obj</span><span class="p">.</span><span class="n">t</span> <span class="o">-&gt;</span> <span class="n">t</span>
</code></pre></div>

<p>Set and validate the parameters of estimator.</p>
<h2 id="parameters_139">Parameters<a class="headerlink" href="#parameters_139" title="Permanent link">&para;</a></h2>
<p>**kwargs : dict
Estimator parameters.</p>
<h2 id="returns_114">Returns<a class="headerlink" href="#returns_114" title="Permanent link">&para;</a></h2>
<p>self : object
Estimator instance.</p>
<div class="highlight"><pre><span></span><code><span class="k">val</span> <span class="n">sparsify</span> <span class="o">:</span> <span class="o">[&gt;</span> <span class="n">tag</span><span class="o">]</span> <span class="nn">Obj</span><span class="p">.</span><span class="n">t</span> <span class="o">-&gt;</span> <span class="n">t</span>
</code></pre></div>

<p>Convert coefficient matrix to sparse format.</p>
<p>Converts the <code>coef_</code> member to a scipy.sparse matrix, which for
L1-regularized models can be much more memory- and storage-efficient
than the usual numpy.ndarray representation.</p>
<p>The <code>intercept_</code> member is not converted.</p>
<h2 id="returns_115">Returns<a class="headerlink" href="#returns_115" title="Permanent link">&para;</a></h2>
<p>self
Fitted estimator.</p>
<h2 id="notes_41">Notes<a class="headerlink" href="#notes_41" title="Permanent link">&para;</a></h2>
<p>For non-sparse models, i.e. when there are not many zeros in <code>coef_</code>,
this may actually <em>increase</em> memory usage, so use this method with
care. A rule of thumb is that the number of zero elements, which can
be computed with <code>(coef_ == 0).sum()</code>, must be more than 50% for this
to provide significant benefits.</p>
<p>After calling this method, further fitting with the partial_fit
method (if any) will not work until you call densify.</p>
<p>Attribute coef_: get value or raise Not_found if None.</p>
<div class="highlight"><pre><span></span><code><span class="k">val</span> <span class="n">coef_</span> <span class="o">:</span> <span class="n">t</span> <span class="o">-&gt;</span> <span class="o">[&gt;`</span><span class="nc">ArrayLike</span><span class="o">]</span> <span class="nn">Np</span><span class="p">.</span><span class="nn">Obj</span><span class="p">.</span><span class="n">t</span>
</code></pre></div>

<p>Attribute coef_: get value as an option.</p>
<div class="highlight"><pre><span></span><code><span class="k">val</span> <span class="n">coef_opt</span> <span class="o">:</span> <span class="n">t</span> <span class="o">-&gt;</span> <span class="o">([&gt;`</span><span class="nc">ArrayLike</span><span class="o">]</span> <span class="nn">Np</span><span class="p">.</span><span class="nn">Obj</span><span class="p">.</span><span class="n">t</span><span class="o">)</span> <span class="n">option</span>
</code></pre></div>

<p>Attribute intercept_: get value or raise Not_found if None.</p>
<div class="highlight"><pre><span></span><code><span class="k">val</span> <span class="n">intercept_</span> <span class="o">:</span> <span class="n">t</span> <span class="o">-&gt;</span> <span class="o">[&gt;`</span><span class="nc">ArrayLike</span><span class="o">]</span> <span class="nn">Np</span><span class="p">.</span><span class="nn">Obj</span><span class="p">.</span><span class="n">t</span>
</code></pre></div>

<p>Attribute intercept_: get value as an option.</p>
<div class="highlight"><pre><span></span><code><span class="k">val</span> <span class="n">intercept_opt</span> <span class="o">:</span> <span class="n">t</span> <span class="o">-&gt;</span> <span class="o">([&gt;`</span><span class="nc">ArrayLike</span><span class="o">]</span> <span class="nn">Np</span><span class="p">.</span><span class="nn">Obj</span><span class="p">.</span><span class="n">t</span><span class="o">)</span> <span class="n">option</span>
</code></pre></div>

<p>Attribute n_iter_: get value or raise Not_found if None.</p>
<div class="highlight"><pre><span></span><code><span class="k">val</span> <span class="n">n_iter_</span> <span class="o">:</span> <span class="n">t</span> <span class="o">-&gt;</span> <span class="kt">int</span>
</code></pre></div>

<p>Attribute n_iter_: get value as an option.</p>
<div class="highlight"><pre><span></span><code><span class="k">val</span> <span class="n">n_iter_opt</span> <span class="o">:</span> <span class="n">t</span> <span class="o">-&gt;</span> <span class="o">(</span><span class="kt">int</span><span class="o">)</span> <span class="n">option</span>
</code></pre></div>

<p>Attribute classes_: get value or raise Not_found if None.</p>
<div class="highlight"><pre><span></span><code><span class="k">val</span> <span class="n">classes_</span> <span class="o">:</span> <span class="n">t</span> <span class="o">-&gt;</span> <span class="o">[&gt;`</span><span class="nc">ArrayLike</span><span class="o">]</span> <span class="nn">Np</span><span class="p">.</span><span class="nn">Obj</span><span class="p">.</span><span class="n">t</span>
</code></pre></div>

<p>Attribute classes_: get value as an option.</p>
<div class="highlight"><pre><span></span><code><span class="k">val</span> <span class="n">classes_opt</span> <span class="o">:</span> <span class="n">t</span> <span class="o">-&gt;</span> <span class="o">([&gt;`</span><span class="nc">ArrayLike</span><span class="o">]</span> <span class="nn">Np</span><span class="p">.</span><span class="nn">Obj</span><span class="p">.</span><span class="n">t</span><span class="o">)</span> <span class="n">option</span>
</code></pre></div>

<p>Attribute t_: get value or raise Not_found if None.</p>
<div class="highlight"><pre><span></span><code><span class="k">val</span> <span class="n">t_</span> <span class="o">:</span> <span class="n">t</span> <span class="o">-&gt;</span> <span class="kt">int</span>
</code></pre></div>

<p>Attribute t_: get value as an option.</p>
<div class="highlight"><pre><span></span><code><span class="k">val</span> <span class="n">t_opt</span> <span class="o">:</span> <span class="n">t</span> <span class="o">-&gt;</span> <span class="o">(</span><span class="kt">int</span><span class="o">)</span> <span class="n">option</span>
</code></pre></div>

<p>Print the object to a human-readable representation.</p>
<div class="highlight"><pre><span></span><code><span class="k">val</span> <span class="n">to_string</span> <span class="o">:</span> <span class="n">t</span> <span class="o">-&gt;</span> <span class="kt">string</span>
</code></pre></div>

<p>Print the object to a human-readable representation.</p>
<div class="highlight"><pre><span></span><code><span class="k">val</span> <span class="n">show</span> <span class="o">:</span> <span class="n">t</span> <span class="o">-&gt;</span> <span class="kt">string</span>
</code></pre></div>

<p>Pretty-print the object to a formatter.</p>
<div class="highlight"><pre><span></span><code><span class="k">val</span> <span class="n">pp</span> <span class="o">:</span> <span class="nn">Format</span><span class="p">.</span><span class="n">formatter</span> <span class="o">-&gt;</span> <span class="n">t</span> <span class="o">-&gt;</span> <span class="kt">unit</span> <span class="o">[@@</span><span class="n">ocaml</span><span class="o">.</span><span class="n">toplevel_printer</span><span class="o">]</span>



<span class="k">module</span> <span class="nc">PassiveAggressiveRegressor</span> <span class="o">:</span> <span class="k">sig</span>
<span class="k">type</span> <span class="n">tag</span> <span class="o">=</span> <span class="o">[`</span><span class="nc">PassiveAggressiveRegressor</span><span class="o">]</span>
<span class="k">type</span> <span class="n">t</span> <span class="o">=</span> <span class="o">[`</span><span class="nc">BaseEstimator</span> <span class="o">|</span> <span class="o">`</span><span class="nc">BaseSGD</span> <span class="o">|</span> <span class="o">`</span><span class="nc">BaseSGDRegressor</span> <span class="o">|</span> <span class="o">`</span><span class="nc">Object</span> <span class="o">|</span> <span class="o">`</span><span class="nc">PassiveAggressiveRegressor</span> <span class="o">|</span> <span class="o">`</span><span class="nc">RegressorMixin</span> <span class="o">|</span> <span class="o">`</span><span class="nc">SparseCoefMixin</span><span class="o">]</span> <span class="nn">Obj</span><span class="p">.</span><span class="n">t</span>
<span class="k">val</span> <span class="n">of_pyobject</span> <span class="o">:</span> <span class="nn">Py</span><span class="p">.</span><span class="nn">Object</span><span class="p">.</span><span class="n">t</span> <span class="o">-&gt;</span> <span class="n">t</span>
<span class="k">val</span> <span class="n">to_pyobject</span> <span class="o">:</span> <span class="o">[&gt;</span> <span class="n">tag</span><span class="o">]</span> <span class="nn">Obj</span><span class="p">.</span><span class="n">t</span> <span class="o">-&gt;</span> <span class="nn">Py</span><span class="p">.</span><span class="nn">Object</span><span class="p">.</span><span class="n">t</span>

<span class="k">val</span> <span class="n">as_regressor</span> <span class="o">:</span> <span class="n">t</span> <span class="o">-&gt;</span> <span class="o">[`</span><span class="nc">RegressorMixin</span><span class="o">]</span> <span class="nn">Obj</span><span class="p">.</span><span class="n">t</span>
<span class="k">val</span> <span class="n">as_estimator</span> <span class="o">:</span> <span class="n">t</span> <span class="o">-&gt;</span> <span class="o">[`</span><span class="nc">BaseEstimator</span><span class="o">]</span> <span class="nn">Obj</span><span class="p">.</span><span class="n">t</span>
<span class="k">val</span> <span class="n">as_sgd_regressor</span> <span class="o">:</span> <span class="n">t</span> <span class="o">-&gt;</span> <span class="o">[`</span><span class="nc">BaseSGDRegressor</span><span class="o">]</span> <span class="nn">Obj</span><span class="p">.</span><span class="n">t</span>
<span class="k">val</span> <span class="n">as_sparse_coef</span> <span class="o">:</span> <span class="n">t</span> <span class="o">-&gt;</span> <span class="o">[`</span><span class="nc">SparseCoefMixin</span><span class="o">]</span> <span class="nn">Obj</span><span class="p">.</span><span class="n">t</span>
<span class="k">val</span> <span class="n">as_sgd</span> <span class="o">:</span> <span class="n">t</span> <span class="o">-&gt;</span> <span class="o">[`</span><span class="nc">BaseSGD</span><span class="o">]</span> <span class="nn">Obj</span><span class="p">.</span><span class="n">t</span>
<span class="k">val</span> <span class="n">create</span> <span class="o">:</span> <span class="o">?</span><span class="n">c</span><span class="o">:</span><span class="kt">float</span> <span class="o">-&gt;</span> <span class="o">?</span><span class="n">fit_intercept</span><span class="o">:</span><span class="kt">bool</span> <span class="o">-&gt;</span> <span class="o">?</span><span class="n">max_iter</span><span class="o">:</span><span class="kt">int</span> <span class="o">-&gt;</span> <span class="o">?</span><span class="n">tol</span><span class="o">:[`</span><span class="nc">F</span> <span class="k">of</span> <span class="kt">float</span> <span class="o">|</span> <span class="o">`</span><span class="nc">None</span><span class="o">]</span> <span class="o">-&gt;</span> <span class="o">?</span><span class="n">early_stopping</span><span class="o">:</span><span class="kt">bool</span> <span class="o">-&gt;</span> <span class="o">?</span><span class="n">validation_fraction</span><span class="o">:</span><span class="kt">float</span> <span class="o">-&gt;</span> <span class="o">?</span><span class="n">n_iter_no_change</span><span class="o">:</span><span class="kt">int</span> <span class="o">-&gt;</span> <span class="o">?</span><span class="n">shuffle</span><span class="o">:</span><span class="kt">bool</span> <span class="o">-&gt;</span> <span class="o">?</span><span class="n">verbose</span><span class="o">:</span><span class="kt">int</span> <span class="o">-&gt;</span> <span class="o">?</span><span class="n">loss</span><span class="o">:</span><span class="kt">string</span> <span class="o">-&gt;</span> <span class="o">?</span><span class="n">epsilon</span><span class="o">:</span><span class="kt">float</span> <span class="o">-&gt;</span> <span class="o">?</span><span class="n">random_state</span><span class="o">:</span><span class="kt">int</span> <span class="o">-&gt;</span> <span class="o">?</span><span class="n">warm_start</span><span class="o">:</span><span class="kt">bool</span> <span class="o">-&gt;</span> <span class="o">?</span><span class="n">average</span><span class="o">:[`</span><span class="nc">I</span> <span class="k">of</span> <span class="kt">int</span> <span class="o">|</span> <span class="o">`</span><span class="nc">Bool</span> <span class="k">of</span> <span class="kt">bool</span><span class="o">]</span> <span class="o">-&gt;</span> <span class="kt">unit</span> <span class="o">-&gt;</span> <span class="n">t</span>
</code></pre></div>

<p>Passive Aggressive Regressor</p>
<p>Read more in the :ref:<code>User Guide &lt;passive_aggressive&gt;</code>.</p>
<h2 id="parameters_140">Parameters<a class="headerlink" href="#parameters_140" title="Permanent link">&para;</a></h2>
<p>C : float
Maximum step size (regularization). Defaults to 1.0.</p>
<p>fit_intercept : bool
Whether the intercept should be estimated or not. If False, the
data is assumed to be already centered. Defaults to True.</p>
<p>max_iter : int, optional (default=1000)
The maximum number of passes over the training data (aka epochs).
It only impacts the behavior in the <code>fit</code> method, and not the
:meth:<code>partial_fit</code> method.</p>
<p>.. versionadded:: 0.19</p>
<p>tol : float or None, optional (default=1e-3)
The stopping criterion. If it is not None, the iterations will stop
when (loss &gt; previous_loss - tol).</p>
<p>.. versionadded:: 0.19</p>
<p>early_stopping : bool, default=False
Whether to use early stopping to terminate training when validation.
score is not improving. If set to True, it will automatically set aside
a fraction of training data as validation and terminate
training when validation score is not improving by at least tol for
n_iter_no_change consecutive epochs.</p>
<p>.. versionadded:: 0.20</p>
<p>validation_fraction : float, default=0.1
The proportion of training data to set aside as validation set for
early stopping. Must be between 0 and 1.
Only used if early_stopping is True.</p>
<p>.. versionadded:: 0.20</p>
<p>n_iter_no_change : int, default=5
Number of iterations with no improvement to wait before early stopping.</p>
<p>.. versionadded:: 0.20</p>
<p>shuffle : bool, default=True
Whether or not the training data should be shuffled after each epoch.</p>
<p>verbose : integer, optional
The verbosity level</p>
<p>loss : string, optional
The loss function to be used:
epsilon_insensitive: equivalent to PA-I in the reference paper.
squared_epsilon_insensitive: equivalent to PA-II in the reference
paper.</p>
<p>epsilon : float
If the difference between the current prediction and the correct label
is below this threshold, the model is not updated.</p>
<p>random_state : int, RandomState instance or None, optional, default=None
The seed of the pseudo random number generator to use when shuffling
the data.  If int, random_state is the seed used by the random number
generator; If RandomState instance, random_state is the random number
generator; If None, the random number generator is the RandomState
instance used by <code>np.random</code>.</p>
<p>warm_start : bool, optional
When set to True, reuse the solution of the previous call to fit as
initialization, otherwise, just erase the previous solution.
See :term:<code>the Glossary &lt;warm_start&gt;</code>.</p>
<p>Repeatedly calling fit or partial_fit when warm_start is True can
result in a different solution than when calling fit a single time
because of the way the data is shuffled.</p>
<p>average : bool or int, optional
When set to True, computes the averaged SGD weights and stores the
result in the <code>coef_</code> attribute. If set to an int greater than 1,
averaging will begin once the total number of samples seen reaches
average. So average=10 will begin averaging after seeing 10 samples.</p>
<p>.. versionadded:: 0.19
parameter <em>average</em> to use weights averaging in SGD</p>
<h2 id="attributes_22">Attributes<a class="headerlink" href="#attributes_22" title="Permanent link">&para;</a></h2>
<p>coef_ : array, shape = [1, n_features] if n_classes == 2 else [n_classes,            n_features]
Weights assigned to the features.</p>
<p>intercept_ : array, shape = [1] if n_classes == 2 else [n_classes]
Constants in decision function.</p>
<p>n_iter_ : int
The actual number of iterations to reach the stopping criterion.</p>
<p>t_ : int
Number of weight updates performed during training.
Same as <code>(n_iter_ * n_samples)</code>.</p>
<h2 id="examples_22">Examples<a class="headerlink" href="#examples_22" title="Permanent link">&para;</a></h2>
<blockquote>
<blockquote>
<blockquote>
<p>from sklearn.linear_model import PassiveAggressiveRegressor
from sklearn.datasets import make_regression</p>
<p>X, y = make_regression(n_features=4, random_state=0)
regr = PassiveAggressiveRegressor(max_iter=100, random_state=0,
... tol=1e-3)
regr.fit(X, y)
PassiveAggressiveRegressor(max_iter=100, random_state=0)
print(regr.coef_)
[20.48736655 34.18818427 67.59122734 87.94731329]
print(regr.intercept_)
[-0.02306214]
print(regr.predict([[0, 0, 0, 0]]))
[-0.02306214]</p>
</blockquote>
</blockquote>
</blockquote>
<h2 id="see-also_19">See also<a class="headerlink" href="#see-also_19" title="Permanent link">&para;</a></h2>
<p>SGDRegressor</p>
<h2 id="references_5">References<a class="headerlink" href="#references_5" title="Permanent link">&para;</a></h2>
<p>Online Passive-Aggressive Algorithms
<a href="http://jmlr.csail.mit.edu/papers/volume7/crammer06a/crammer06a.pdf">http://jmlr.csail.mit.edu/papers/volume7/crammer06a/crammer06a.pdf</a>
K. Crammer, O. Dekel, J. Keshat, S. Shalev-Shwartz, Y. Singer - JMLR (2006)</p>
<div class="highlight"><pre><span></span><code><span class="k">val</span> <span class="n">densify</span> <span class="o">:</span> <span class="o">[&gt;</span> <span class="n">tag</span><span class="o">]</span> <span class="nn">Obj</span><span class="p">.</span><span class="n">t</span> <span class="o">-&gt;</span> <span class="n">t</span>
</code></pre></div>

<p>Convert coefficient matrix to dense array format.</p>
<p>Converts the <code>coef_</code> member (back) to a numpy.ndarray. This is the
default format of <code>coef_</code> and is required for fitting, so calling
this method is only required on models that have previously been
sparsified; otherwise, it is a no-op.</p>
<h2 id="returns_116">Returns<a class="headerlink" href="#returns_116" title="Permanent link">&para;</a></h2>
<p>self
Fitted estimator.</p>
<div class="highlight"><pre><span></span><code><span class="k">val</span> <span class="n">fit</span> <span class="o">:</span> <span class="o">?</span><span class="n">coef_init</span><span class="o">:[&gt;`</span><span class="nc">ArrayLike</span><span class="o">]</span> <span class="nn">Np</span><span class="p">.</span><span class="nn">Obj</span><span class="p">.</span><span class="n">t</span> <span class="o">-&gt;</span> <span class="o">?</span><span class="n">intercept_init</span><span class="o">:[&gt;`</span><span class="nc">ArrayLike</span><span class="o">]</span> <span class="nn">Np</span><span class="p">.</span><span class="nn">Obj</span><span class="p">.</span><span class="n">t</span> <span class="o">-&gt;</span> <span class="n">x</span><span class="o">:[&gt;`</span><span class="nc">ArrayLike</span><span class="o">]</span> <span class="nn">Np</span><span class="p">.</span><span class="nn">Obj</span><span class="p">.</span><span class="n">t</span> <span class="o">-&gt;</span> <span class="n">y</span><span class="o">:[&gt;`</span><span class="nc">ArrayLike</span><span class="o">]</span> <span class="nn">Np</span><span class="p">.</span><span class="nn">Obj</span><span class="p">.</span><span class="n">t</span> <span class="o">-&gt;</span> <span class="o">[&gt;</span> <span class="n">tag</span><span class="o">]</span> <span class="nn">Obj</span><span class="p">.</span><span class="n">t</span> <span class="o">-&gt;</span> <span class="n">t</span>
</code></pre></div>

<p>Fit linear model with Passive Aggressive algorithm.</p>
<h2 id="parameters_141">Parameters<a class="headerlink" href="#parameters_141" title="Permanent link">&para;</a></h2>
<p>X : {array-like, sparse matrix} of shape (n_samples, n_features)
Training data</p>
<p>y : numpy array of shape [n_samples]
Target values</p>
<p>coef_init : array, shape = [n_features]
The initial coefficients to warm-start the optimization.</p>
<p>intercept_init : array, shape = [1]
The initial intercept to warm-start the optimization.</p>
<h2 id="returns_117">Returns<a class="headerlink" href="#returns_117" title="Permanent link">&para;</a></h2>
<p>self : returns an instance of self.</p>
<div class="highlight"><pre><span></span><code><span class="k">val</span> <span class="n">get_params</span> <span class="o">:</span> <span class="o">?</span><span class="n">deep</span><span class="o">:</span><span class="kt">bool</span> <span class="o">-&gt;</span> <span class="o">[&gt;</span> <span class="n">tag</span><span class="o">]</span> <span class="nn">Obj</span><span class="p">.</span><span class="n">t</span> <span class="o">-&gt;</span> <span class="nn">Dict</span><span class="p">.</span><span class="n">t</span>
</code></pre></div>

<p>Get parameters for this estimator.</p>
<h2 id="parameters_142">Parameters<a class="headerlink" href="#parameters_142" title="Permanent link">&para;</a></h2>
<p>deep : bool, default=True
If True, will return the parameters for this estimator and
contained subobjects that are estimators.</p>
<h2 id="returns_118">Returns<a class="headerlink" href="#returns_118" title="Permanent link">&para;</a></h2>
<p>params : mapping of string to any
Parameter names mapped to their values.</p>
<div class="highlight"><pre><span></span><code><span class="k">val</span> <span class="n">partial_fit</span> <span class="o">:</span> <span class="n">x</span><span class="o">:[&gt;`</span><span class="nc">ArrayLike</span><span class="o">]</span> <span class="nn">Np</span><span class="p">.</span><span class="nn">Obj</span><span class="p">.</span><span class="n">t</span> <span class="o">-&gt;</span> <span class="n">y</span><span class="o">:[&gt;`</span><span class="nc">ArrayLike</span><span class="o">]</span> <span class="nn">Np</span><span class="p">.</span><span class="nn">Obj</span><span class="p">.</span><span class="n">t</span> <span class="o">-&gt;</span> <span class="o">[&gt;</span> <span class="n">tag</span><span class="o">]</span> <span class="nn">Obj</span><span class="p">.</span><span class="n">t</span> <span class="o">-&gt;</span> <span class="n">t</span>
</code></pre></div>

<p>Fit linear model with Passive Aggressive algorithm.</p>
<h2 id="parameters_143">Parameters<a class="headerlink" href="#parameters_143" title="Permanent link">&para;</a></h2>
<p>X : {array-like, sparse matrix} of shape (n_samples, n_features)
Subset of training data</p>
<p>y : numpy array of shape [n_samples]
Subset of target values</p>
<h2 id="returns_119">Returns<a class="headerlink" href="#returns_119" title="Permanent link">&para;</a></h2>
<p>self : returns an instance of self.</p>
<div class="highlight"><pre><span></span><code><span class="k">val</span> <span class="n">predict</span> <span class="o">:</span> <span class="n">x</span><span class="o">:[&gt;`</span><span class="nc">ArrayLike</span><span class="o">]</span> <span class="nn">Np</span><span class="p">.</span><span class="nn">Obj</span><span class="p">.</span><span class="n">t</span> <span class="o">-&gt;</span> <span class="o">[&gt;</span> <span class="n">tag</span><span class="o">]</span> <span class="nn">Obj</span><span class="p">.</span><span class="n">t</span> <span class="o">-&gt;</span> <span class="o">[&gt;`</span><span class="nc">ArrayLike</span><span class="o">]</span> <span class="nn">Np</span><span class="p">.</span><span class="nn">Obj</span><span class="p">.</span><span class="n">t</span>
</code></pre></div>

<p>Predict using the linear model</p>
<h2 id="parameters_144">Parameters<a class="headerlink" href="#parameters_144" title="Permanent link">&para;</a></h2>
<p>X : {array-like, sparse matrix}, shape (n_samples, n_features)</p>
<h2 id="returns_120">Returns<a class="headerlink" href="#returns_120" title="Permanent link">&para;</a></h2>
<p>ndarray of shape (n_samples,)
Predicted target values per element in X.</p>
<div class="highlight"><pre><span></span><code><span class="k">val</span> <span class="n">score</span> <span class="o">:</span> <span class="o">?</span><span class="n">sample_weight</span><span class="o">:[&gt;`</span><span class="nc">ArrayLike</span><span class="o">]</span> <span class="nn">Np</span><span class="p">.</span><span class="nn">Obj</span><span class="p">.</span><span class="n">t</span> <span class="o">-&gt;</span> <span class="n">x</span><span class="o">:[&gt;`</span><span class="nc">ArrayLike</span><span class="o">]</span> <span class="nn">Np</span><span class="p">.</span><span class="nn">Obj</span><span class="p">.</span><span class="n">t</span> <span class="o">-&gt;</span> <span class="n">y</span><span class="o">:[&gt;`</span><span class="nc">ArrayLike</span><span class="o">]</span> <span class="nn">Np</span><span class="p">.</span><span class="nn">Obj</span><span class="p">.</span><span class="n">t</span> <span class="o">-&gt;</span> <span class="o">[&gt;</span> <span class="n">tag</span><span class="o">]</span> <span class="nn">Obj</span><span class="p">.</span><span class="n">t</span> <span class="o">-&gt;</span> <span class="kt">float</span>
</code></pre></div>

<p>Return the coefficient of determination R^2 of the prediction.</p>
<p>The coefficient R^2 is defined as (1 - u/v), where u is the residual
sum of squares ((y_true - y_pred) <strong> 2).sum() and v is the total
sum of squares ((y_true - y_true.mean()) </strong> 2).sum().
The best possible score is 1.0 and it can be negative (because the
model can be arbitrarily worse). A constant model that always
predicts the expected value of y, disregarding the input features,
would get a R^2 score of 0.0.</p>
<h2 id="parameters_145">Parameters<a class="headerlink" href="#parameters_145" title="Permanent link">&para;</a></h2>
<p>X : array-like of shape (n_samples, n_features)
Test samples. For some estimators this may be a
precomputed kernel matrix or a list of generic objects instead,
shape = (n_samples, n_samples_fitted),
where n_samples_fitted is the number of
samples used in the fitting for the estimator.</p>
<p>y : array-like of shape (n_samples,) or (n_samples, n_outputs)
True values for X.</p>
<p>sample_weight : array-like of shape (n_samples,), default=None
Sample weights.</p>
<h2 id="returns_121">Returns<a class="headerlink" href="#returns_121" title="Permanent link">&para;</a></h2>
<p>score : float
R^2 of self.predict(X) wrt. y.</p>
<h2 id="notes_42">Notes<a class="headerlink" href="#notes_42" title="Permanent link">&para;</a></h2>
<p>The R2 score used when calling <code>score</code> on a regressor will use
<code>multioutput='uniform_average'</code> from version 0.23 to keep consistent
with :func:<code>~sklearn.metrics.r2_score</code>. This will influence the
<code>score</code> method of all the multioutput regressors (except for
:class:<code>~sklearn.multioutput.MultiOutputRegressor</code>). To specify the
default value manually and avoid the warning, please either call
:func:<code>~sklearn.metrics.r2_score</code> directly or make a custom scorer with
:func:<code>~sklearn.metrics.make_scorer</code> (the built-in scorer <code>'r2'</code> uses
<code>multioutput='uniform_average'</code>).</p>
<div class="highlight"><pre><span></span><code><span class="k">val</span> <span class="n">set_params</span> <span class="o">:</span> <span class="o">?</span><span class="n">kwargs</span><span class="o">:(</span><span class="kt">string</span> <span class="o">*</span> <span class="nn">Py</span><span class="p">.</span><span class="nn">Object</span><span class="p">.</span><span class="n">t</span><span class="o">)</span> <span class="kt">list</span> <span class="o">-&gt;</span> <span class="o">[&gt;</span> <span class="n">tag</span><span class="o">]</span> <span class="nn">Obj</span><span class="p">.</span><span class="n">t</span> <span class="o">-&gt;</span> <span class="n">t</span>
</code></pre></div>

<p>Set and validate the parameters of estimator.</p>
<h2 id="parameters_146">Parameters<a class="headerlink" href="#parameters_146" title="Permanent link">&para;</a></h2>
<p>**kwargs : dict
Estimator parameters.</p>
<h2 id="returns_122">Returns<a class="headerlink" href="#returns_122" title="Permanent link">&para;</a></h2>
<p>self : object
Estimator instance.</p>
<div class="highlight"><pre><span></span><code><span class="k">val</span> <span class="n">sparsify</span> <span class="o">:</span> <span class="o">[&gt;</span> <span class="n">tag</span><span class="o">]</span> <span class="nn">Obj</span><span class="p">.</span><span class="n">t</span> <span class="o">-&gt;</span> <span class="n">t</span>
</code></pre></div>

<p>Convert coefficient matrix to sparse format.</p>
<p>Converts the <code>coef_</code> member to a scipy.sparse matrix, which for
L1-regularized models can be much more memory- and storage-efficient
than the usual numpy.ndarray representation.</p>
<p>The <code>intercept_</code> member is not converted.</p>
<h2 id="returns_123">Returns<a class="headerlink" href="#returns_123" title="Permanent link">&para;</a></h2>
<p>self
Fitted estimator.</p>
<h2 id="notes_43">Notes<a class="headerlink" href="#notes_43" title="Permanent link">&para;</a></h2>
<p>For non-sparse models, i.e. when there are not many zeros in <code>coef_</code>,
this may actually <em>increase</em> memory usage, so use this method with
care. A rule of thumb is that the number of zero elements, which can
be computed with <code>(coef_ == 0).sum()</code>, must be more than 50% for this
to provide significant benefits.</p>
<p>After calling this method, further fitting with the partial_fit
method (if any) will not work until you call densify.</p>
<p>Attribute coef_: get value or raise Not_found if None.</p>
<div class="highlight"><pre><span></span><code><span class="k">val</span> <span class="n">coef_</span> <span class="o">:</span> <span class="n">t</span> <span class="o">-&gt;</span> <span class="o">[&gt;`</span><span class="nc">ArrayLike</span><span class="o">]</span> <span class="nn">Np</span><span class="p">.</span><span class="nn">Obj</span><span class="p">.</span><span class="n">t</span>
</code></pre></div>

<p>Attribute coef_: get value as an option.</p>
<div class="highlight"><pre><span></span><code><span class="k">val</span> <span class="n">coef_opt</span> <span class="o">:</span> <span class="n">t</span> <span class="o">-&gt;</span> <span class="o">([&gt;`</span><span class="nc">ArrayLike</span><span class="o">]</span> <span class="nn">Np</span><span class="p">.</span><span class="nn">Obj</span><span class="p">.</span><span class="n">t</span><span class="o">)</span> <span class="n">option</span>
</code></pre></div>

<p>Attribute intercept_: get value or raise Not_found if None.</p>
<div class="highlight"><pre><span></span><code><span class="k">val</span> <span class="n">intercept_</span> <span class="o">:</span> <span class="n">t</span> <span class="o">-&gt;</span> <span class="o">[&gt;`</span><span class="nc">ArrayLike</span><span class="o">]</span> <span class="nn">Np</span><span class="p">.</span><span class="nn">Obj</span><span class="p">.</span><span class="n">t</span>
</code></pre></div>

<p>Attribute intercept_: get value as an option.</p>
<div class="highlight"><pre><span></span><code><span class="k">val</span> <span class="n">intercept_opt</span> <span class="o">:</span> <span class="n">t</span> <span class="o">-&gt;</span> <span class="o">([&gt;`</span><span class="nc">ArrayLike</span><span class="o">]</span> <span class="nn">Np</span><span class="p">.</span><span class="nn">Obj</span><span class="p">.</span><span class="n">t</span><span class="o">)</span> <span class="n">option</span>
</code></pre></div>

<p>Attribute n_iter_: get value or raise Not_found if None.</p>
<div class="highlight"><pre><span></span><code><span class="k">val</span> <span class="n">n_iter_</span> <span class="o">:</span> <span class="n">t</span> <span class="o">-&gt;</span> <span class="kt">int</span>
</code></pre></div>

<p>Attribute n_iter_: get value as an option.</p>
<div class="highlight"><pre><span></span><code><span class="k">val</span> <span class="n">n_iter_opt</span> <span class="o">:</span> <span class="n">t</span> <span class="o">-&gt;</span> <span class="o">(</span><span class="kt">int</span><span class="o">)</span> <span class="n">option</span>
</code></pre></div>

<p>Attribute t_: get value or raise Not_found if None.</p>
<div class="highlight"><pre><span></span><code><span class="k">val</span> <span class="n">t_</span> <span class="o">:</span> <span class="n">t</span> <span class="o">-&gt;</span> <span class="kt">int</span>
</code></pre></div>

<p>Attribute t_: get value as an option.</p>
<div class="highlight"><pre><span></span><code><span class="k">val</span> <span class="n">t_opt</span> <span class="o">:</span> <span class="n">t</span> <span class="o">-&gt;</span> <span class="o">(</span><span class="kt">int</span><span class="o">)</span> <span class="n">option</span>
</code></pre></div>

<p>Print the object to a human-readable representation.</p>
<div class="highlight"><pre><span></span><code><span class="k">val</span> <span class="n">to_string</span> <span class="o">:</span> <span class="n">t</span> <span class="o">-&gt;</span> <span class="kt">string</span>
</code></pre></div>

<p>Print the object to a human-readable representation.</p>
<div class="highlight"><pre><span></span><code><span class="k">val</span> <span class="n">show</span> <span class="o">:</span> <span class="n">t</span> <span class="o">-&gt;</span> <span class="kt">string</span>
</code></pre></div>

<p>Pretty-print the object to a formatter.</p>
<div class="highlight"><pre><span></span><code><span class="k">val</span> <span class="n">pp</span> <span class="o">:</span> <span class="nn">Format</span><span class="p">.</span><span class="n">formatter</span> <span class="o">-&gt;</span> <span class="n">t</span> <span class="o">-&gt;</span> <span class="kt">unit</span> <span class="o">[@@</span><span class="n">ocaml</span><span class="o">.</span><span class="n">toplevel_printer</span><span class="o">]</span>



<span class="k">module</span> <span class="nc">Perceptron</span> <span class="o">:</span> <span class="k">sig</span>
<span class="k">type</span> <span class="n">tag</span> <span class="o">=</span> <span class="o">[`</span><span class="nc">Perceptron</span><span class="o">]</span>
<span class="k">type</span> <span class="n">t</span> <span class="o">=</span> <span class="o">[`</span><span class="nc">BaseEstimator</span> <span class="o">|</span> <span class="o">`</span><span class="nc">BaseSGD</span> <span class="o">|</span> <span class="o">`</span><span class="nc">BaseSGDClassifier</span> <span class="o">|</span> <span class="o">`</span><span class="nc">ClassifierMixin</span> <span class="o">|</span> <span class="o">`</span><span class="nc">LinearClassifierMixin</span> <span class="o">|</span> <span class="o">`</span><span class="nc">Object</span> <span class="o">|</span> <span class="o">`</span><span class="nc">Perceptron</span> <span class="o">|</span> <span class="o">`</span><span class="nc">SparseCoefMixin</span><span class="o">]</span> <span class="nn">Obj</span><span class="p">.</span><span class="n">t</span>
<span class="k">val</span> <span class="n">of_pyobject</span> <span class="o">:</span> <span class="nn">Py</span><span class="p">.</span><span class="nn">Object</span><span class="p">.</span><span class="n">t</span> <span class="o">-&gt;</span> <span class="n">t</span>
<span class="k">val</span> <span class="n">to_pyobject</span> <span class="o">:</span> <span class="o">[&gt;</span> <span class="n">tag</span><span class="o">]</span> <span class="nn">Obj</span><span class="p">.</span><span class="n">t</span> <span class="o">-&gt;</span> <span class="nn">Py</span><span class="p">.</span><span class="nn">Object</span><span class="p">.</span><span class="n">t</span>

<span class="k">val</span> <span class="n">as_linear_classifier</span> <span class="o">:</span> <span class="n">t</span> <span class="o">-&gt;</span> <span class="o">[`</span><span class="nc">LinearClassifierMixin</span><span class="o">]</span> <span class="nn">Obj</span><span class="p">.</span><span class="n">t</span>
<span class="k">val</span> <span class="n">as_sgd_classifier</span> <span class="o">:</span> <span class="n">t</span> <span class="o">-&gt;</span> <span class="o">[`</span><span class="nc">BaseSGDClassifier</span><span class="o">]</span> <span class="nn">Obj</span><span class="p">.</span><span class="n">t</span>
<span class="k">val</span> <span class="n">as_classifier</span> <span class="o">:</span> <span class="n">t</span> <span class="o">-&gt;</span> <span class="o">[`</span><span class="nc">ClassifierMixin</span><span class="o">]</span> <span class="nn">Obj</span><span class="p">.</span><span class="n">t</span>
<span class="k">val</span> <span class="n">as_estimator</span> <span class="o">:</span> <span class="n">t</span> <span class="o">-&gt;</span> <span class="o">[`</span><span class="nc">BaseEstimator</span><span class="o">]</span> <span class="nn">Obj</span><span class="p">.</span><span class="n">t</span>
<span class="k">val</span> <span class="n">as_sparse_coef</span> <span class="o">:</span> <span class="n">t</span> <span class="o">-&gt;</span> <span class="o">[`</span><span class="nc">SparseCoefMixin</span><span class="o">]</span> <span class="nn">Obj</span><span class="p">.</span><span class="n">t</span>
<span class="k">val</span> <span class="n">as_sgd</span> <span class="o">:</span> <span class="n">t</span> <span class="o">-&gt;</span> <span class="o">[`</span><span class="nc">BaseSGD</span><span class="o">]</span> <span class="nn">Obj</span><span class="p">.</span><span class="n">t</span>
<span class="k">val</span> <span class="n">create</span> <span class="o">:</span> <span class="o">?</span><span class="n">penalty</span><span class="o">:[`</span><span class="nc">L2</span> <span class="o">|</span> <span class="o">`</span><span class="nc">Elasticnet</span> <span class="o">|</span> <span class="o">`</span><span class="nc">L1</span><span class="o">]</span> <span class="o">-&gt;</span> <span class="o">?</span><span class="n">alpha</span><span class="o">:</span><span class="kt">float</span> <span class="o">-&gt;</span> <span class="o">?</span><span class="n">fit_intercept</span><span class="o">:</span><span class="kt">bool</span> <span class="o">-&gt;</span> <span class="o">?</span><span class="n">max_iter</span><span class="o">:</span><span class="kt">int</span> <span class="o">-&gt;</span> <span class="o">?</span><span class="n">tol</span><span class="o">:</span><span class="kt">float</span> <span class="o">-&gt;</span> <span class="o">?</span><span class="n">shuffle</span><span class="o">:</span><span class="kt">bool</span> <span class="o">-&gt;</span> <span class="o">?</span><span class="n">verbose</span><span class="o">:</span><span class="kt">int</span> <span class="o">-&gt;</span> <span class="o">?</span><span class="n">eta0</span><span class="o">:</span><span class="kt">float</span> <span class="o">-&gt;</span> <span class="o">?</span><span class="n">n_jobs</span><span class="o">:</span><span class="kt">int</span> <span class="o">-&gt;</span> <span class="o">?</span><span class="n">random_state</span><span class="o">:</span><span class="kt">int</span> <span class="o">-&gt;</span> <span class="o">?</span><span class="n">early_stopping</span><span class="o">:</span><span class="kt">bool</span> <span class="o">-&gt;</span> <span class="o">?</span><span class="n">validation_fraction</span><span class="o">:</span><span class="kt">float</span> <span class="o">-&gt;</span> <span class="o">?</span><span class="n">n_iter_no_change</span><span class="o">:</span><span class="kt">int</span> <span class="o">-&gt;</span> <span class="o">?</span><span class="n">class_weight</span><span class="o">:[`</span><span class="nc">T_class_label_weight_</span> <span class="k">of</span> <span class="nn">Py</span><span class="p">.</span><span class="nn">Object</span><span class="p">.</span><span class="n">t</span> <span class="o">|</span> <span class="o">`</span><span class="nc">DictIntToFloat</span> <span class="k">of</span> <span class="o">(</span><span class="kt">int</span> <span class="o">*</span> <span class="kt">float</span><span class="o">)</span> <span class="kt">list</span> <span class="o">|</span> <span class="o">`</span><span class="nc">Balanced</span><span class="o">]</span> <span class="o">-&gt;</span> <span class="o">?</span><span class="n">warm_start</span><span class="o">:</span><span class="kt">bool</span> <span class="o">-&gt;</span> <span class="kt">unit</span> <span class="o">-&gt;</span> <span class="n">t</span>
</code></pre></div>

<p>Perceptron</p>
<p>Read more in the :ref:<code>User Guide &lt;perceptron&gt;</code>.</p>
<h2 id="parameters_147">Parameters<a class="headerlink" href="#parameters_147" title="Permanent link">&para;</a></h2>
<p>penalty : {'l2','l1','elasticnet'}, default=None
The penalty (aka regularization term) to be used.</p>
<p>alpha : float, default=0.0001
Constant that multiplies the regularization term if regularization is
used.</p>
<p>fit_intercept : bool, default=True
Whether the intercept should be estimated or not. If False, the
data is assumed to be already centered.</p>
<p>max_iter : int, default=1000
The maximum number of passes over the training data (aka epochs).
It only impacts the behavior in the <code>fit</code> method, and not the
:meth:<code>partial_fit</code> method.</p>
<p>.. versionadded:: 0.19</p>
<p>tol : float, default=1e-3
The stopping criterion. If it is not None, the iterations will stop
when (loss &gt; previous_loss - tol).</p>
<p>.. versionadded:: 0.19</p>
<p>shuffle : bool, default=True
Whether or not the training data should be shuffled after each epoch.</p>
<p>verbose : int, default=0
The verbosity level</p>
<p>eta0 : double, default=1
Constant by which the updates are multiplied.</p>
<p>n_jobs : int, default=None
The number of CPUs to use to do the OVA (One Versus All, for
multi-class problems) computation.
<code>None</code> means 1 unless in a :obj:<code>joblib.parallel_backend</code> context.
<code>-1</code> means using all processors. See :term:<code>Glossary &lt;n_jobs&gt;</code>
for more details.</p>
<p>random_state : int, RandomState instance, default=None
The seed of the pseudo random number generator to use when shuffling
the data.  If int, random_state is the seed used by the random number
generator; If RandomState instance, random_state is the random number
generator; If None, the random number generator is the RandomState
instance used by <code>np.random</code>.</p>
<p>early_stopping : bool, default=False
Whether to use early stopping to terminate training when validation.
score is not improving. If set to True, it will automatically set aside
a stratified fraction of training data as validation and terminate
training when validation score is not improving by at least tol for
n_iter_no_change consecutive epochs.</p>
<p>.. versionadded:: 0.20</p>
<p>validation_fraction : float, default=0.1
The proportion of training data to set aside as validation set for
early stopping. Must be between 0 and 1.
Only used if early_stopping is True.</p>
<p>.. versionadded:: 0.20</p>
<p>n_iter_no_change : int, default=5
Number of iterations with no improvement to wait before early stopping.</p>
<p>.. versionadded:: 0.20</p>
<p>class_weight : dict, {class_label: weight} or 'balanced', default=None
Preset for the class_weight fit parameter.</p>
<p>Weights associated with classes. If not given, all classes
are supposed to have weight one.</p>
<p>The 'balanced' mode uses the values of y to automatically adjust
weights inversely proportional to class frequencies in the input data
as <code>n_samples / (n_classes * np.bincount(y))</code></p>
<p>warm_start : bool, default=False
When set to True, reuse the solution of the previous call to fit as
initialization, otherwise, just erase the previous solution. See
:term:<code>the Glossary &lt;warm_start&gt;</code>.</p>
<h2 id="attributes_23">Attributes<a class="headerlink" href="#attributes_23" title="Permanent link">&para;</a></h2>
<p>coef_ : ndarray of shape = [1, n_features] if n_classes == 2 else         [n_classes, n_features]
Weights assigned to the features.</p>
<p>intercept_ : ndarray of shape = [1] if n_classes == 2 else [n_classes]
Constants in decision function.</p>
<p>n_iter_ : int
The actual number of iterations to reach the stopping criterion.
For multiclass fits, it is the maximum over every binary fit.</p>
<p>classes_ : ndarray of shape (n_classes,)
The unique classes labels.</p>
<p>t_ : int
Number of weight updates performed during training.
Same as <code>(n_iter_ * n_samples)</code>.</p>
<h2 id="notes_44">Notes<a class="headerlink" href="#notes_44" title="Permanent link">&para;</a></h2>
<p><code>Perceptron</code> is a classification algorithm which shares the same
underlying implementation with <code>SGDClassifier</code>. In fact,
<code>Perceptron()</code> is equivalent to <code>SGDClassifier(loss='perceptron',
eta0=1, learning_rate='constant', penalty=None)</code>.</p>
<h2 id="examples_23">Examples<a class="headerlink" href="#examples_23" title="Permanent link">&para;</a></h2>
<blockquote>
<blockquote>
<blockquote>
<p>from sklearn.datasets import load_digits
from sklearn.linear_model import Perceptron
X, y = load_digits(return_X_y=True)
clf = Perceptron(tol=1e-3, random_state=0)
clf.fit(X, y)
Perceptron()
clf.score(X, y)
0.939...</p>
</blockquote>
</blockquote>
</blockquote>
<h2 id="see-also_20">See also<a class="headerlink" href="#see-also_20" title="Permanent link">&para;</a></h2>
<p>SGDClassifier</p>
<h2 id="references_6">References<a class="headerlink" href="#references_6" title="Permanent link">&para;</a></h2>
<p>https://en.wikipedia.org/wiki/Perceptron and references therein.</p>
<div class="highlight"><pre><span></span><code><span class="k">val</span> <span class="n">decision_function</span> <span class="o">:</span> <span class="n">x</span><span class="o">:[&gt;`</span><span class="nc">ArrayLike</span><span class="o">]</span> <span class="nn">Np</span><span class="p">.</span><span class="nn">Obj</span><span class="p">.</span><span class="n">t</span> <span class="o">-&gt;</span> <span class="o">[&gt;</span> <span class="n">tag</span><span class="o">]</span> <span class="nn">Obj</span><span class="p">.</span><span class="n">t</span> <span class="o">-&gt;</span> <span class="o">[&gt;`</span><span class="nc">ArrayLike</span><span class="o">]</span> <span class="nn">Np</span><span class="p">.</span><span class="nn">Obj</span><span class="p">.</span><span class="n">t</span>
</code></pre></div>

<p>Predict confidence scores for samples.</p>
<p>The confidence score for a sample is the signed distance of that
sample to the hyperplane.</p>
<h2 id="parameters_148">Parameters<a class="headerlink" href="#parameters_148" title="Permanent link">&para;</a></h2>
<p>X : array_like or sparse matrix, shape (n_samples, n_features)
Samples.</p>
<h2 id="returns_124">Returns<a class="headerlink" href="#returns_124" title="Permanent link">&para;</a></h2>
<p>array, shape=(n_samples,) if n_classes == 2 else (n_samples, n_classes)
Confidence scores per (sample, class) combination. In the binary
case, confidence score for self.classes_[1] where &gt;0 means this
class would be predicted.</p>
<div class="highlight"><pre><span></span><code><span class="k">val</span> <span class="n">densify</span> <span class="o">:</span> <span class="o">[&gt;</span> <span class="n">tag</span><span class="o">]</span> <span class="nn">Obj</span><span class="p">.</span><span class="n">t</span> <span class="o">-&gt;</span> <span class="n">t</span>
</code></pre></div>

<p>Convert coefficient matrix to dense array format.</p>
<p>Converts the <code>coef_</code> member (back) to a numpy.ndarray. This is the
default format of <code>coef_</code> and is required for fitting, so calling
this method is only required on models that have previously been
sparsified; otherwise, it is a no-op.</p>
<h2 id="returns_125">Returns<a class="headerlink" href="#returns_125" title="Permanent link">&para;</a></h2>
<p>self
Fitted estimator.</p>
<div class="highlight"><pre><span></span><code><span class="k">val</span> <span class="n">fit</span> <span class="o">:</span> <span class="o">?</span><span class="n">coef_init</span><span class="o">:[&gt;`</span><span class="nc">ArrayLike</span><span class="o">]</span> <span class="nn">Np</span><span class="p">.</span><span class="nn">Obj</span><span class="p">.</span><span class="n">t</span> <span class="o">-&gt;</span> <span class="o">?</span><span class="n">intercept_init</span><span class="o">:[&gt;`</span><span class="nc">ArrayLike</span><span class="o">]</span> <span class="nn">Np</span><span class="p">.</span><span class="nn">Obj</span><span class="p">.</span><span class="n">t</span> <span class="o">-&gt;</span> <span class="o">?</span><span class="n">sample_weight</span><span class="o">:[&gt;`</span><span class="nc">ArrayLike</span><span class="o">]</span> <span class="nn">Np</span><span class="p">.</span><span class="nn">Obj</span><span class="p">.</span><span class="n">t</span> <span class="o">-&gt;</span> <span class="n">x</span><span class="o">:[&gt;`</span><span class="nc">ArrayLike</span><span class="o">]</span> <span class="nn">Np</span><span class="p">.</span><span class="nn">Obj</span><span class="p">.</span><span class="n">t</span> <span class="o">-&gt;</span> <span class="n">y</span><span class="o">:[&gt;`</span><span class="nc">ArrayLike</span><span class="o">]</span> <span class="nn">Np</span><span class="p">.</span><span class="nn">Obj</span><span class="p">.</span><span class="n">t</span> <span class="o">-&gt;</span> <span class="o">[&gt;</span> <span class="n">tag</span><span class="o">]</span> <span class="nn">Obj</span><span class="p">.</span><span class="n">t</span> <span class="o">-&gt;</span> <span class="n">t</span>
</code></pre></div>

<p>Fit linear model with Stochastic Gradient Descent.</p>
<h2 id="parameters_149">Parameters<a class="headerlink" href="#parameters_149" title="Permanent link">&para;</a></h2>
<p>X : {array-like, sparse matrix}, shape (n_samples, n_features)
Training data.</p>
<p>y : ndarray of shape (n_samples,)
Target values.</p>
<p>coef_init : ndarray of shape (n_classes, n_features), default=None
The initial coefficients to warm-start the optimization.</p>
<p>intercept_init : ndarray of shape (n_classes,), default=None
The initial intercept to warm-start the optimization.</p>
<p>sample_weight : array-like, shape (n_samples,), default=None
Weights applied to individual samples.
If not provided, uniform weights are assumed. These weights will
be multiplied with class_weight (passed through the
constructor) if class_weight is specified.</p>
<h2 id="returns_126">Returns<a class="headerlink" href="#returns_126" title="Permanent link">&para;</a></h2>
<p>self :
Returns an instance of self.</p>
<div class="highlight"><pre><span></span><code><span class="k">val</span> <span class="n">get_params</span> <span class="o">:</span> <span class="o">?</span><span class="n">deep</span><span class="o">:</span><span class="kt">bool</span> <span class="o">-&gt;</span> <span class="o">[&gt;</span> <span class="n">tag</span><span class="o">]</span> <span class="nn">Obj</span><span class="p">.</span><span class="n">t</span> <span class="o">-&gt;</span> <span class="nn">Dict</span><span class="p">.</span><span class="n">t</span>
</code></pre></div>

<p>Get parameters for this estimator.</p>
<h2 id="parameters_150">Parameters<a class="headerlink" href="#parameters_150" title="Permanent link">&para;</a></h2>
<p>deep : bool, default=True
If True, will return the parameters for this estimator and
contained subobjects that are estimators.</p>
<h2 id="returns_127">Returns<a class="headerlink" href="#returns_127" title="Permanent link">&para;</a></h2>
<p>params : mapping of string to any
Parameter names mapped to their values.</p>
<div class="highlight"><pre><span></span><code><span class="k">val</span> <span class="n">partial_fit</span> <span class="o">:</span> <span class="o">?</span><span class="n">classes</span><span class="o">:[&gt;`</span><span class="nc">ArrayLike</span><span class="o">]</span> <span class="nn">Np</span><span class="p">.</span><span class="nn">Obj</span><span class="p">.</span><span class="n">t</span> <span class="o">-&gt;</span> <span class="o">?</span><span class="n">sample_weight</span><span class="o">:[&gt;`</span><span class="nc">ArrayLike</span><span class="o">]</span> <span class="nn">Np</span><span class="p">.</span><span class="nn">Obj</span><span class="p">.</span><span class="n">t</span> <span class="o">-&gt;</span> <span class="n">x</span><span class="o">:[&gt;`</span><span class="nc">ArrayLike</span><span class="o">]</span> <span class="nn">Np</span><span class="p">.</span><span class="nn">Obj</span><span class="p">.</span><span class="n">t</span> <span class="o">-&gt;</span> <span class="n">y</span><span class="o">:[&gt;`</span><span class="nc">ArrayLike</span><span class="o">]</span> <span class="nn">Np</span><span class="p">.</span><span class="nn">Obj</span><span class="p">.</span><span class="n">t</span> <span class="o">-&gt;</span> <span class="o">[&gt;</span> <span class="n">tag</span><span class="o">]</span> <span class="nn">Obj</span><span class="p">.</span><span class="n">t</span> <span class="o">-&gt;</span> <span class="n">t</span>
</code></pre></div>

<p>Perform one epoch of stochastic gradient descent on given samples.</p>
<p>Internally, this method uses <code>max_iter = 1</code>. Therefore, it is not
guaranteed that a minimum of the cost function is reached after calling
it once. Matters such as objective convergence and early stopping
should be handled by the user.</p>
<h2 id="parameters_151">Parameters<a class="headerlink" href="#parameters_151" title="Permanent link">&para;</a></h2>
<p>X : {array-like, sparse matrix}, shape (n_samples, n_features)
Subset of the training data.</p>
<p>y : ndarray of shape (n_samples,)
Subset of the target values.</p>
<p>classes : ndarray of shape (n_classes,), default=None
Classes across all calls to partial_fit.
Can be obtained by via <code>np.unique(y_all)</code>, where y_all is the
target vector of the entire dataset.
This argument is required for the first call to partial_fit
and can be omitted in the subsequent calls.
Note that y doesn't need to contain all labels in <code>classes</code>.</p>
<p>sample_weight : array-like, shape (n_samples,), default=None
Weights applied to individual samples.
If not provided, uniform weights are assumed.</p>
<h2 id="returns_128">Returns<a class="headerlink" href="#returns_128" title="Permanent link">&para;</a></h2>
<p>self :
Returns an instance of self.</p>
<div class="highlight"><pre><span></span><code><span class="k">val</span> <span class="n">predict</span> <span class="o">:</span> <span class="n">x</span><span class="o">:[&gt;`</span><span class="nc">ArrayLike</span><span class="o">]</span> <span class="nn">Np</span><span class="p">.</span><span class="nn">Obj</span><span class="p">.</span><span class="n">t</span> <span class="o">-&gt;</span> <span class="o">[&gt;</span> <span class="n">tag</span><span class="o">]</span> <span class="nn">Obj</span><span class="p">.</span><span class="n">t</span> <span class="o">-&gt;</span> <span class="o">[&gt;`</span><span class="nc">ArrayLike</span><span class="o">]</span> <span class="nn">Np</span><span class="p">.</span><span class="nn">Obj</span><span class="p">.</span><span class="n">t</span>
</code></pre></div>

<p>Predict class labels for samples in X.</p>
<h2 id="parameters_152">Parameters<a class="headerlink" href="#parameters_152" title="Permanent link">&para;</a></h2>
<p>X : array_like or sparse matrix, shape (n_samples, n_features)
Samples.</p>
<h2 id="returns_129">Returns<a class="headerlink" href="#returns_129" title="Permanent link">&para;</a></h2>
<p>C : array, shape [n_samples]
Predicted class label per sample.</p>
<div class="highlight"><pre><span></span><code><span class="k">val</span> <span class="n">score</span> <span class="o">:</span> <span class="o">?</span><span class="n">sample_weight</span><span class="o">:[&gt;`</span><span class="nc">ArrayLike</span><span class="o">]</span> <span class="nn">Np</span><span class="p">.</span><span class="nn">Obj</span><span class="p">.</span><span class="n">t</span> <span class="o">-&gt;</span> <span class="n">x</span><span class="o">:[&gt;`</span><span class="nc">ArrayLike</span><span class="o">]</span> <span class="nn">Np</span><span class="p">.</span><span class="nn">Obj</span><span class="p">.</span><span class="n">t</span> <span class="o">-&gt;</span> <span class="n">y</span><span class="o">:[&gt;`</span><span class="nc">ArrayLike</span><span class="o">]</span> <span class="nn">Np</span><span class="p">.</span><span class="nn">Obj</span><span class="p">.</span><span class="n">t</span> <span class="o">-&gt;</span> <span class="o">[&gt;</span> <span class="n">tag</span><span class="o">]</span> <span class="nn">Obj</span><span class="p">.</span><span class="n">t</span> <span class="o">-&gt;</span> <span class="kt">float</span>
</code></pre></div>

<p>Return the mean accuracy on the given test data and labels.</p>
<p>In multi-label classification, this is the subset accuracy
which is a harsh metric since you require for each sample that
each label set be correctly predicted.</p>
<h2 id="parameters_153">Parameters<a class="headerlink" href="#parameters_153" title="Permanent link">&para;</a></h2>
<p>X : array-like of shape (n_samples, n_features)
Test samples.</p>
<p>y : array-like of shape (n_samples,) or (n_samples, n_outputs)
True labels for X.</p>
<p>sample_weight : array-like of shape (n_samples,), default=None
Sample weights.</p>
<h2 id="returns_130">Returns<a class="headerlink" href="#returns_130" title="Permanent link">&para;</a></h2>
<p>score : float
Mean accuracy of self.predict(X) wrt. y.</p>
<div class="highlight"><pre><span></span><code><span class="k">val</span> <span class="n">set_params</span> <span class="o">:</span> <span class="o">?</span><span class="n">kwargs</span><span class="o">:(</span><span class="kt">string</span> <span class="o">*</span> <span class="nn">Py</span><span class="p">.</span><span class="nn">Object</span><span class="p">.</span><span class="n">t</span><span class="o">)</span> <span class="kt">list</span> <span class="o">-&gt;</span> <span class="o">[&gt;</span> <span class="n">tag</span><span class="o">]</span> <span class="nn">Obj</span><span class="p">.</span><span class="n">t</span> <span class="o">-&gt;</span> <span class="n">t</span>
</code></pre></div>

<p>Set and validate the parameters of estimator.</p>
<h2 id="parameters_154">Parameters<a class="headerlink" href="#parameters_154" title="Permanent link">&para;</a></h2>
<p>**kwargs : dict
Estimator parameters.</p>
<h2 id="returns_131">Returns<a class="headerlink" href="#returns_131" title="Permanent link">&para;</a></h2>
<p>self : object
Estimator instance.</p>
<div class="highlight"><pre><span></span><code><span class="k">val</span> <span class="n">sparsify</span> <span class="o">:</span> <span class="o">[&gt;</span> <span class="n">tag</span><span class="o">]</span> <span class="nn">Obj</span><span class="p">.</span><span class="n">t</span> <span class="o">-&gt;</span> <span class="n">t</span>
</code></pre></div>

<p>Convert coefficient matrix to sparse format.</p>
<p>Converts the <code>coef_</code> member to a scipy.sparse matrix, which for
L1-regularized models can be much more memory- and storage-efficient
than the usual numpy.ndarray representation.</p>
<p>The <code>intercept_</code> member is not converted.</p>
<h2 id="returns_132">Returns<a class="headerlink" href="#returns_132" title="Permanent link">&para;</a></h2>
<p>self
Fitted estimator.</p>
<h2 id="notes_45">Notes<a class="headerlink" href="#notes_45" title="Permanent link">&para;</a></h2>
<p>For non-sparse models, i.e. when there are not many zeros in <code>coef_</code>,
this may actually <em>increase</em> memory usage, so use this method with
care. A rule of thumb is that the number of zero elements, which can
be computed with <code>(coef_ == 0).sum()</code>, must be more than 50% for this
to provide significant benefits.</p>
<p>After calling this method, further fitting with the partial_fit
method (if any) will not work until you call densify.</p>
<p>Attribute coef_: get value or raise Not_found if None.</p>
<div class="highlight"><pre><span></span><code><span class="k">val</span> <span class="n">coef_</span> <span class="o">:</span> <span class="n">t</span> <span class="o">-&gt;</span> <span class="o">[&gt;`</span><span class="nc">ArrayLike</span><span class="o">]</span> <span class="nn">Np</span><span class="p">.</span><span class="nn">Obj</span><span class="p">.</span><span class="n">t</span>
</code></pre></div>

<p>Attribute coef_: get value as an option.</p>
<div class="highlight"><pre><span></span><code><span class="k">val</span> <span class="n">coef_opt</span> <span class="o">:</span> <span class="n">t</span> <span class="o">-&gt;</span> <span class="o">([&gt;`</span><span class="nc">ArrayLike</span><span class="o">]</span> <span class="nn">Np</span><span class="p">.</span><span class="nn">Obj</span><span class="p">.</span><span class="n">t</span><span class="o">)</span> <span class="n">option</span>
</code></pre></div>

<p>Attribute intercept_: get value or raise Not_found if None.</p>
<div class="highlight"><pre><span></span><code><span class="k">val</span> <span class="n">intercept_</span> <span class="o">:</span> <span class="n">t</span> <span class="o">-&gt;</span> <span class="o">[&gt;`</span><span class="nc">ArrayLike</span><span class="o">]</span> <span class="nn">Np</span><span class="p">.</span><span class="nn">Obj</span><span class="p">.</span><span class="n">t</span>
</code></pre></div>

<p>Attribute intercept_: get value as an option.</p>
<div class="highlight"><pre><span></span><code><span class="k">val</span> <span class="n">intercept_opt</span> <span class="o">:</span> <span class="n">t</span> <span class="o">-&gt;</span> <span class="o">([&gt;`</span><span class="nc">ArrayLike</span><span class="o">]</span> <span class="nn">Np</span><span class="p">.</span><span class="nn">Obj</span><span class="p">.</span><span class="n">t</span><span class="o">)</span> <span class="n">option</span>
</code></pre></div>

<p>Attribute n_iter_: get value or raise Not_found if None.</p>
<div class="highlight"><pre><span></span><code><span class="k">val</span> <span class="n">n_iter_</span> <span class="o">:</span> <span class="n">t</span> <span class="o">-&gt;</span> <span class="kt">int</span>
</code></pre></div>

<p>Attribute n_iter_: get value as an option.</p>
<div class="highlight"><pre><span></span><code><span class="k">val</span> <span class="n">n_iter_opt</span> <span class="o">:</span> <span class="n">t</span> <span class="o">-&gt;</span> <span class="o">(</span><span class="kt">int</span><span class="o">)</span> <span class="n">option</span>
</code></pre></div>

<p>Attribute classes_: get value or raise Not_found if None.</p>
<div class="highlight"><pre><span></span><code><span class="k">val</span> <span class="n">classes_</span> <span class="o">:</span> <span class="n">t</span> <span class="o">-&gt;</span> <span class="o">[&gt;`</span><span class="nc">ArrayLike</span><span class="o">]</span> <span class="nn">Np</span><span class="p">.</span><span class="nn">Obj</span><span class="p">.</span><span class="n">t</span>
</code></pre></div>

<p>Attribute classes_: get value as an option.</p>
<div class="highlight"><pre><span></span><code><span class="k">val</span> <span class="n">classes_opt</span> <span class="o">:</span> <span class="n">t</span> <span class="o">-&gt;</span> <span class="o">([&gt;`</span><span class="nc">ArrayLike</span><span class="o">]</span> <span class="nn">Np</span><span class="p">.</span><span class="nn">Obj</span><span class="p">.</span><span class="n">t</span><span class="o">)</span> <span class="n">option</span>
</code></pre></div>

<p>Attribute t_: get value or raise Not_found if None.</p>
<div class="highlight"><pre><span></span><code><span class="k">val</span> <span class="n">t_</span> <span class="o">:</span> <span class="n">t</span> <span class="o">-&gt;</span> <span class="kt">int</span>
</code></pre></div>

<p>Attribute t_: get value as an option.</p>
<div class="highlight"><pre><span></span><code><span class="k">val</span> <span class="n">t_opt</span> <span class="o">:</span> <span class="n">t</span> <span class="o">-&gt;</span> <span class="o">(</span><span class="kt">int</span><span class="o">)</span> <span class="n">option</span>
</code></pre></div>

<p>Print the object to a human-readable representation.</p>
<div class="highlight"><pre><span></span><code><span class="k">val</span> <span class="n">to_string</span> <span class="o">:</span> <span class="n">t</span> <span class="o">-&gt;</span> <span class="kt">string</span>
</code></pre></div>

<p>Print the object to a human-readable representation.</p>
<div class="highlight"><pre><span></span><code><span class="k">val</span> <span class="n">show</span> <span class="o">:</span> <span class="n">t</span> <span class="o">-&gt;</span> <span class="kt">string</span>
</code></pre></div>

<p>Pretty-print the object to a formatter.</p>
<div class="highlight"><pre><span></span><code><span class="k">val</span> <span class="n">pp</span> <span class="o">:</span> <span class="nn">Format</span><span class="p">.</span><span class="n">formatter</span> <span class="o">-&gt;</span> <span class="n">t</span> <span class="o">-&gt;</span> <span class="kt">unit</span> <span class="o">[@@</span><span class="n">ocaml</span><span class="o">.</span><span class="n">toplevel_printer</span><span class="o">]</span>



<span class="k">module</span> <span class="nc">RANSACRegressor</span> <span class="o">:</span> <span class="k">sig</span>
<span class="k">type</span> <span class="n">tag</span> <span class="o">=</span> <span class="o">[`</span><span class="nc">RANSACRegressor</span><span class="o">]</span>
<span class="k">type</span> <span class="n">t</span> <span class="o">=</span> <span class="o">[`</span><span class="nc">BaseEstimator</span> <span class="o">|</span> <span class="o">`</span><span class="nc">MetaEstimatorMixin</span> <span class="o">|</span> <span class="o">`</span><span class="nc">MultiOutputMixin</span> <span class="o">|</span> <span class="o">`</span><span class="nc">Object</span> <span class="o">|</span> <span class="o">`</span><span class="nc">RANSACRegressor</span> <span class="o">|</span> <span class="o">`</span><span class="nc">RegressorMixin</span><span class="o">]</span> <span class="nn">Obj</span><span class="p">.</span><span class="n">t</span>
<span class="k">val</span> <span class="n">of_pyobject</span> <span class="o">:</span> <span class="nn">Py</span><span class="p">.</span><span class="nn">Object</span><span class="p">.</span><span class="n">t</span> <span class="o">-&gt;</span> <span class="n">t</span>
<span class="k">val</span> <span class="n">to_pyobject</span> <span class="o">:</span> <span class="o">[&gt;</span> <span class="n">tag</span><span class="o">]</span> <span class="nn">Obj</span><span class="p">.</span><span class="n">t</span> <span class="o">-&gt;</span> <span class="nn">Py</span><span class="p">.</span><span class="nn">Object</span><span class="p">.</span><span class="n">t</span>

<span class="k">val</span> <span class="n">as_regressor</span> <span class="o">:</span> <span class="n">t</span> <span class="o">-&gt;</span> <span class="o">[`</span><span class="nc">RegressorMixin</span><span class="o">]</span> <span class="nn">Obj</span><span class="p">.</span><span class="n">t</span>
<span class="k">val</span> <span class="n">as_multi_output</span> <span class="o">:</span> <span class="n">t</span> <span class="o">-&gt;</span> <span class="o">[`</span><span class="nc">MultiOutputMixin</span><span class="o">]</span> <span class="nn">Obj</span><span class="p">.</span><span class="n">t</span>
<span class="k">val</span> <span class="n">as_estimator</span> <span class="o">:</span> <span class="n">t</span> <span class="o">-&gt;</span> <span class="o">[`</span><span class="nc">BaseEstimator</span><span class="o">]</span> <span class="nn">Obj</span><span class="p">.</span><span class="n">t</span>
<span class="k">val</span> <span class="n">as_meta_estimator</span> <span class="o">:</span> <span class="n">t</span> <span class="o">-&gt;</span> <span class="o">[`</span><span class="nc">MetaEstimatorMixin</span><span class="o">]</span> <span class="nn">Obj</span><span class="p">.</span><span class="n">t</span>
<span class="k">val</span> <span class="n">create</span> <span class="o">:</span> <span class="o">?</span><span class="n">base_estimator</span><span class="o">:[&gt;`</span><span class="nc">BaseEstimator</span><span class="o">]</span> <span class="nn">Np</span><span class="p">.</span><span class="nn">Obj</span><span class="p">.</span><span class="n">t</span> <span class="o">-&gt;</span> <span class="o">?</span><span class="n">min_samples</span><span class="o">:[`</span><span class="nc">I</span> <span class="k">of</span> <span class="kt">int</span> <span class="o">|</span> <span class="o">`</span><span class="nc">Float_0_1_</span> <span class="k">of</span> <span class="nn">Py</span><span class="p">.</span><span class="nn">Object</span><span class="p">.</span><span class="n">t</span><span class="o">]</span> <span class="o">-&gt;</span> <span class="o">?</span><span class="n">residual_threshold</span><span class="o">:</span><span class="kt">float</span> <span class="o">-&gt;</span> <span class="o">?</span><span class="n">is_data_valid</span><span class="o">:</span><span class="nn">Py</span><span class="p">.</span><span class="nn">Object</span><span class="p">.</span><span class="n">t</span> <span class="o">-&gt;</span> <span class="o">?</span><span class="n">is_model_valid</span><span class="o">:</span><span class="nn">Py</span><span class="p">.</span><span class="nn">Object</span><span class="p">.</span><span class="n">t</span> <span class="o">-&gt;</span> <span class="o">?</span><span class="n">max_trials</span><span class="o">:</span><span class="kt">int</span> <span class="o">-&gt;</span> <span class="o">?</span><span class="n">max_skips</span><span class="o">:</span><span class="kt">int</span> <span class="o">-&gt;</span> <span class="o">?</span><span class="n">stop_n_inliers</span><span class="o">:</span><span class="kt">int</span> <span class="o">-&gt;</span> <span class="o">?</span><span class="n">stop_score</span><span class="o">:</span><span class="kt">float</span> <span class="o">-&gt;</span> <span class="o">?</span><span class="n">stop_probability</span><span class="o">:</span><span class="kt">float</span> <span class="o">-&gt;</span> <span class="o">?</span><span class="n">loss</span><span class="o">:[`</span><span class="nc">Callable</span> <span class="k">of</span> <span class="nn">Py</span><span class="p">.</span><span class="nn">Object</span><span class="p">.</span><span class="n">t</span> <span class="o">|</span> <span class="o">`</span><span class="nc">S</span> <span class="k">of</span> <span class="kt">string</span><span class="o">]</span> <span class="o">-&gt;</span> <span class="o">?</span><span class="n">random_state</span><span class="o">:</span><span class="kt">int</span> <span class="o">-&gt;</span> <span class="kt">unit</span> <span class="o">-&gt;</span> <span class="n">t</span>
</code></pre></div>

<p>RANSAC (RANdom SAmple Consensus) algorithm.</p>
<p>RANSAC is an iterative algorithm for the robust estimation of parameters
from a subset of inliers from the complete data set.</p>
<p>Read more in the :ref:<code>User Guide &lt;ransac_regression&gt;</code>.</p>
<h2 id="parameters_155">Parameters<a class="headerlink" href="#parameters_155" title="Permanent link">&para;</a></h2>
<p>base_estimator : object, optional
Base estimator object which implements the following methods:</p>
<ul>
<li><code>fit(X, y)</code>: Fit model to given training data and target values.</li>
<li><code>score(X, y)</code>: Returns the mean accuracy on the given test data,
which is used for the stop criterion defined by <code>stop_score</code>.
Additionally, the score is used to decide which of two equally
large consensus sets is chosen as the better one.</li>
<li><code>predict(X)</code>: Returns predicted values using the linear model,
which is used to compute residual error using loss function.</li>
</ul>
<p>If <code>base_estimator</code> is None, then
<code>base_estimator=sklearn.linear_model.LinearRegression()</code> is used for
target values of dtype float.</p>
<p>Note that the current implementation only supports regression
estimators.</p>
<p>min_samples : int (&gt;= 1) or float ([0, 1]), optional
Minimum number of samples chosen randomly from original data. Treated
as an absolute number of samples for <code>min_samples &gt;= 1</code>, treated as a
relative number <code>ceil(min_samples * X.shape[0]</code>) for
<code>min_samples &lt; 1</code>. This is typically chosen as the minimal number of
samples necessary to estimate the given <code>base_estimator</code>. By default a
<code>sklearn.linear_model.LinearRegression()</code> estimator is assumed and
<code>min_samples</code> is chosen as <code>X.shape[1] + 1</code>.</p>
<p>residual_threshold : float, optional
Maximum residual for a data sample to be classified as an inlier.
By default the threshold is chosen as the MAD (median absolute
deviation) of the target values <code>y</code>.</p>
<p>is_data_valid : callable, optional
This function is called with the randomly selected data before the
model is fitted to it: <code>is_data_valid(X, y)</code>. If its return value is
False the current randomly chosen sub-sample is skipped.</p>
<p>is_model_valid : callable, optional
This function is called with the estimated model and the randomly
selected data: <code>is_model_valid(model, X, y)</code>. If its return value is
False the current randomly chosen sub-sample is skipped.
Rejecting samples with this function is computationally costlier than
with <code>is_data_valid</code>. <code>is_model_valid</code> should therefore only be used if
the estimated model is needed for making the rejection decision.</p>
<p>max_trials : int, optional
Maximum number of iterations for random sample selection.</p>
<p>max_skips : int, optional
Maximum number of iterations that can be skipped due to finding zero
inliers or invalid data defined by <code>is_data_valid</code> or invalid models
defined by <code>is_model_valid</code>.</p>
<p>.. versionadded:: 0.19</p>
<p>stop_n_inliers : int, optional
Stop iteration if at least this number of inliers are found.</p>
<p>stop_score : float, optional
Stop iteration if score is greater equal than this threshold.</p>
<p>stop_probability : float in range [0, 1], optional
RANSAC iteration stops if at least one outlier-free set of the training
data is sampled in RANSAC. This requires to generate at least N
samples (iterations)::</p>
<p>N &gt;= log(1 - probability) / log(1 - e**m)</p>
<p>where the probability (confidence) is typically set to high value such
as 0.99 (the default) and e is the current fraction of inliers w.r.t.
the total number of samples.</p>
<p>loss : string, callable, optional, default 'absolute_loss'
String inputs, 'absolute_loss' and 'squared_loss' are supported which
find the absolute loss and squared loss per sample
respectively.</p>
<p>If <code>loss</code> is a callable, then it should be a function that takes
two arrays as inputs, the true and predicted value and returns a 1-D
array with the i-th value of the array corresponding to the loss
on <code>X[i]</code>.</p>
<p>If the loss on a sample is greater than the <code>residual_threshold</code>,
then this sample is classified as an outlier.</p>
<p>random_state : int, RandomState instance or None, optional, default None
The generator used to initialize the centers.  If int, random_state is
the seed used by the random number generator; If RandomState instance,
random_state is the random number generator; If None, the random number
generator is the RandomState instance used by <code>np.random</code>.</p>
<h2 id="attributes_24">Attributes<a class="headerlink" href="#attributes_24" title="Permanent link">&para;</a></h2>
<p>estimator_ : object
Best fitted model (copy of the <code>base_estimator</code> object).</p>
<p>n_trials_ : int
Number of random selection trials until one of the stop criteria is
met. It is always <code>&lt;= max_trials</code>.</p>
<p>inlier_mask_ : bool array of shape [n_samples]
Boolean mask of inliers classified as <code>True</code>.</p>
<p>n_skips_no_inliers_ : int
Number of iterations skipped due to finding zero inliers.</p>
<p>.. versionadded:: 0.19</p>
<p>n_skips_invalid_data_ : int
Number of iterations skipped due to invalid data defined by
<code>is_data_valid</code>.</p>
<p>.. versionadded:: 0.19</p>
<p>n_skips_invalid_model_ : int
Number of iterations skipped due to an invalid model defined by
<code>is_model_valid</code>.</p>
<p>.. versionadded:: 0.19</p>
<h2 id="examples_24">Examples<a class="headerlink" href="#examples_24" title="Permanent link">&para;</a></h2>
<blockquote>
<blockquote>
<blockquote>
<p>from sklearn.linear_model import RANSACRegressor
from sklearn.datasets import make_regression
X, y = make_regression(
...     n_samples=200, n_features=2, noise=4.0, random_state=0)
reg = RANSACRegressor(random_state=0).fit(X, y)
reg.score(X, y)
0.9885...
reg.predict(X[:1,])
array([-31.9417...])</p>
</blockquote>
</blockquote>
</blockquote>
<h2 id="references_7">References<a class="headerlink" href="#references_7" title="Permanent link">&para;</a></h2>
<p>.. [1] https://en.wikipedia.org/wiki/RANSAC
.. [2] https://www.sri.com/sites/default/files/publications/ransac-publication.pdf
.. [3] http://www.bmva.org/bmvc/2009/Papers/Paper355/Paper355.pdf</p>
<div class="highlight"><pre><span></span><code><span class="k">val</span> <span class="n">fit</span> <span class="o">:</span> <span class="o">?</span><span class="n">sample_weight</span><span class="o">:[&gt;`</span><span class="nc">ArrayLike</span><span class="o">]</span> <span class="nn">Np</span><span class="p">.</span><span class="nn">Obj</span><span class="p">.</span><span class="n">t</span> <span class="o">-&gt;</span> <span class="n">x</span><span class="o">:[&gt;`</span><span class="nc">ArrayLike</span><span class="o">]</span> <span class="nn">Np</span><span class="p">.</span><span class="nn">Obj</span><span class="p">.</span><span class="n">t</span> <span class="o">-&gt;</span> <span class="n">y</span><span class="o">:[&gt;`</span><span class="nc">ArrayLike</span><span class="o">]</span> <span class="nn">Np</span><span class="p">.</span><span class="nn">Obj</span><span class="p">.</span><span class="n">t</span> <span class="o">-&gt;</span> <span class="o">[&gt;</span> <span class="n">tag</span><span class="o">]</span> <span class="nn">Obj</span><span class="p">.</span><span class="n">t</span> <span class="o">-&gt;</span> <span class="n">t</span>
</code></pre></div>

<p>Fit estimator using RANSAC algorithm.</p>
<h2 id="parameters_156">Parameters<a class="headerlink" href="#parameters_156" title="Permanent link">&para;</a></h2>
<p>X : array-like or sparse matrix, shape [n_samples, n_features]
Training data.</p>
<p>y : array-like of shape (n_samples,) or (n_samples, n_targets)
Target values.</p>
<p>sample_weight : array-like of shape (n_samples,), default=None
Individual weights for each sample
raises error if sample_weight is passed and base_estimator
fit method does not support it.</p>
<h2 id="raises">Raises<a class="headerlink" href="#raises" title="Permanent link">&para;</a></h2>
<p>ValueError
If no valid consensus set could be found. This occurs if
<code>is_data_valid</code> and <code>is_model_valid</code> return False for all
<code>max_trials</code> randomly chosen sub-samples.</p>
<div class="highlight"><pre><span></span><code><span class="k">val</span> <span class="n">get_params</span> <span class="o">:</span> <span class="o">?</span><span class="n">deep</span><span class="o">:</span><span class="kt">bool</span> <span class="o">-&gt;</span> <span class="o">[&gt;</span> <span class="n">tag</span><span class="o">]</span> <span class="nn">Obj</span><span class="p">.</span><span class="n">t</span> <span class="o">-&gt;</span> <span class="nn">Dict</span><span class="p">.</span><span class="n">t</span>
</code></pre></div>

<p>Get parameters for this estimator.</p>
<h2 id="parameters_157">Parameters<a class="headerlink" href="#parameters_157" title="Permanent link">&para;</a></h2>
<p>deep : bool, default=True
If True, will return the parameters for this estimator and
contained subobjects that are estimators.</p>
<h2 id="returns_133">Returns<a class="headerlink" href="#returns_133" title="Permanent link">&para;</a></h2>
<p>params : mapping of string to any
Parameter names mapped to their values.</p>
<div class="highlight"><pre><span></span><code><span class="k">val</span> <span class="n">predict</span> <span class="o">:</span> <span class="n">x</span><span class="o">:[&gt;`</span><span class="nc">ArrayLike</span><span class="o">]</span> <span class="nn">Np</span><span class="p">.</span><span class="nn">Obj</span><span class="p">.</span><span class="n">t</span> <span class="o">-&gt;</span> <span class="o">[&gt;</span> <span class="n">tag</span><span class="o">]</span> <span class="nn">Obj</span><span class="p">.</span><span class="n">t</span> <span class="o">-&gt;</span> <span class="o">[&gt;`</span><span class="nc">ArrayLike</span><span class="o">]</span> <span class="nn">Np</span><span class="p">.</span><span class="nn">Obj</span><span class="p">.</span><span class="n">t</span>
</code></pre></div>

<p>Predict using the estimated model.</p>
<p>This is a wrapper for <code>estimator_.predict(X)</code>.</p>
<h2 id="parameters_158">Parameters<a class="headerlink" href="#parameters_158" title="Permanent link">&para;</a></h2>
<p>X : numpy array of shape [n_samples, n_features]</p>
<h2 id="returns_134">Returns<a class="headerlink" href="#returns_134" title="Permanent link">&para;</a></h2>
<p>y : array, shape = [n_samples] or [n_samples, n_targets]
Returns predicted values.</p>
<div class="highlight"><pre><span></span><code><span class="k">val</span> <span class="n">score</span> <span class="o">:</span> <span class="n">x</span><span class="o">:[&gt;`</span><span class="nc">ArrayLike</span><span class="o">]</span> <span class="nn">Np</span><span class="p">.</span><span class="nn">Obj</span><span class="p">.</span><span class="n">t</span> <span class="o">-&gt;</span> <span class="n">y</span><span class="o">:[&gt;`</span><span class="nc">ArrayLike</span><span class="o">]</span> <span class="nn">Np</span><span class="p">.</span><span class="nn">Obj</span><span class="p">.</span><span class="n">t</span> <span class="o">-&gt;</span> <span class="o">[&gt;</span> <span class="n">tag</span><span class="o">]</span> <span class="nn">Obj</span><span class="p">.</span><span class="n">t</span> <span class="o">-&gt;</span> <span class="kt">float</span>
</code></pre></div>

<p>Returns the score of the prediction.</p>
<p>This is a wrapper for <code>estimator_.score(X, y)</code>.</p>
<h2 id="parameters_159">Parameters<a class="headerlink" href="#parameters_159" title="Permanent link">&para;</a></h2>
<p>X : numpy array or sparse matrix of shape [n_samples, n_features]
Training data.</p>
<p>y : array, shape = [n_samples] or [n_samples, n_targets]
Target values.</p>
<h2 id="returns_135">Returns<a class="headerlink" href="#returns_135" title="Permanent link">&para;</a></h2>
<p>z : float
Score of the prediction.</p>
<div class="highlight"><pre><span></span><code><span class="k">val</span> <span class="n">set_params</span> <span class="o">:</span> <span class="o">?</span><span class="n">params</span><span class="o">:(</span><span class="kt">string</span> <span class="o">*</span> <span class="nn">Py</span><span class="p">.</span><span class="nn">Object</span><span class="p">.</span><span class="n">t</span><span class="o">)</span> <span class="kt">list</span> <span class="o">-&gt;</span> <span class="o">[&gt;</span> <span class="n">tag</span><span class="o">]</span> <span class="nn">Obj</span><span class="p">.</span><span class="n">t</span> <span class="o">-&gt;</span> <span class="n">t</span>
</code></pre></div>

<p>Set the parameters of this estimator.</p>
<p>The method works on simple estimators as well as on nested objects
(such as pipelines). The latter have parameters of the form
<code>&lt;component&gt;__&lt;parameter&gt;</code> so that it's possible to update each
component of a nested object.</p>
<h2 id="parameters_160">Parameters<a class="headerlink" href="#parameters_160" title="Permanent link">&para;</a></h2>
<p>**params : dict
Estimator parameters.</p>
<h2 id="returns_136">Returns<a class="headerlink" href="#returns_136" title="Permanent link">&para;</a></h2>
<p>self : object
Estimator instance.</p>
<p>Attribute estimator_: get value or raise Not_found if None.</p>
<div class="highlight"><pre><span></span><code><span class="k">val</span> <span class="n">estimator_</span> <span class="o">:</span> <span class="n">t</span> <span class="o">-&gt;</span> <span class="nn">Py</span><span class="p">.</span><span class="nn">Object</span><span class="p">.</span><span class="n">t</span>
</code></pre></div>

<p>Attribute estimator_: get value as an option.</p>
<div class="highlight"><pre><span></span><code><span class="k">val</span> <span class="n">estimator_opt</span> <span class="o">:</span> <span class="n">t</span> <span class="o">-&gt;</span> <span class="o">(</span><span class="nn">Py</span><span class="p">.</span><span class="nn">Object</span><span class="p">.</span><span class="n">t</span><span class="o">)</span> <span class="n">option</span>
</code></pre></div>

<p>Attribute n_trials_: get value or raise Not_found if None.</p>
<div class="highlight"><pre><span></span><code><span class="k">val</span> <span class="n">n_trials_</span> <span class="o">:</span> <span class="n">t</span> <span class="o">-&gt;</span> <span class="kt">int</span>
</code></pre></div>

<p>Attribute n_trials_: get value as an option.</p>
<div class="highlight"><pre><span></span><code><span class="k">val</span> <span class="n">n_trials_opt</span> <span class="o">:</span> <span class="n">t</span> <span class="o">-&gt;</span> <span class="o">(</span><span class="kt">int</span><span class="o">)</span> <span class="n">option</span>
</code></pre></div>

<p>Attribute inlier_mask_: get value or raise Not_found if None.</p>
<div class="highlight"><pre><span></span><code><span class="k">val</span> <span class="n">inlier_mask_</span> <span class="o">:</span> <span class="n">t</span> <span class="o">-&gt;</span> <span class="o">[&gt;`</span><span class="nc">ArrayLike</span><span class="o">]</span> <span class="nn">Np</span><span class="p">.</span><span class="nn">Obj</span><span class="p">.</span><span class="n">t</span>
</code></pre></div>

<p>Attribute inlier_mask_: get value as an option.</p>
<div class="highlight"><pre><span></span><code><span class="k">val</span> <span class="n">inlier_mask_opt</span> <span class="o">:</span> <span class="n">t</span> <span class="o">-&gt;</span> <span class="o">([&gt;`</span><span class="nc">ArrayLike</span><span class="o">]</span> <span class="nn">Np</span><span class="p">.</span><span class="nn">Obj</span><span class="p">.</span><span class="n">t</span><span class="o">)</span> <span class="n">option</span>
</code></pre></div>

<p>Attribute n_skips_no_inliers_: get value or raise Not_found if None.</p>
<div class="highlight"><pre><span></span><code><span class="k">val</span> <span class="n">n_skips_no_inliers_</span> <span class="o">:</span> <span class="n">t</span> <span class="o">-&gt;</span> <span class="kt">int</span>
</code></pre></div>

<p>Attribute n_skips_no_inliers_: get value as an option.</p>
<div class="highlight"><pre><span></span><code><span class="k">val</span> <span class="n">n_skips_no_inliers_opt</span> <span class="o">:</span> <span class="n">t</span> <span class="o">-&gt;</span> <span class="o">(</span><span class="kt">int</span><span class="o">)</span> <span class="n">option</span>
</code></pre></div>

<p>Attribute n_skips_invalid_data_: get value or raise Not_found if None.</p>
<div class="highlight"><pre><span></span><code><span class="k">val</span> <span class="n">n_skips_invalid_data_</span> <span class="o">:</span> <span class="n">t</span> <span class="o">-&gt;</span> <span class="kt">int</span>
</code></pre></div>

<p>Attribute n_skips_invalid_data_: get value as an option.</p>
<div class="highlight"><pre><span></span><code><span class="k">val</span> <span class="n">n_skips_invalid_data_opt</span> <span class="o">:</span> <span class="n">t</span> <span class="o">-&gt;</span> <span class="o">(</span><span class="kt">int</span><span class="o">)</span> <span class="n">option</span>
</code></pre></div>

<p>Attribute n_skips_invalid_model_: get value or raise Not_found if None.</p>
<div class="highlight"><pre><span></span><code><span class="k">val</span> <span class="n">n_skips_invalid_model_</span> <span class="o">:</span> <span class="n">t</span> <span class="o">-&gt;</span> <span class="kt">int</span>
</code></pre></div>

<p>Attribute n_skips_invalid_model_: get value as an option.</p>
<div class="highlight"><pre><span></span><code><span class="k">val</span> <span class="n">n_skips_invalid_model_opt</span> <span class="o">:</span> <span class="n">t</span> <span class="o">-&gt;</span> <span class="o">(</span><span class="kt">int</span><span class="o">)</span> <span class="n">option</span>
</code></pre></div>

<p>Print the object to a human-readable representation.</p>
<div class="highlight"><pre><span></span><code><span class="k">val</span> <span class="n">to_string</span> <span class="o">:</span> <span class="n">t</span> <span class="o">-&gt;</span> <span class="kt">string</span>
</code></pre></div>

<p>Print the object to a human-readable representation.</p>
<div class="highlight"><pre><span></span><code><span class="k">val</span> <span class="n">show</span> <span class="o">:</span> <span class="n">t</span> <span class="o">-&gt;</span> <span class="kt">string</span>
</code></pre></div>

<p>Pretty-print the object to a formatter.</p>
<div class="highlight"><pre><span></span><code><span class="k">val</span> <span class="n">pp</span> <span class="o">:</span> <span class="nn">Format</span><span class="p">.</span><span class="n">formatter</span> <span class="o">-&gt;</span> <span class="n">t</span> <span class="o">-&gt;</span> <span class="kt">unit</span> <span class="o">[@@</span><span class="n">ocaml</span><span class="o">.</span><span class="n">toplevel_printer</span><span class="o">]</span>



<span class="k">module</span> <span class="nc">Ridge</span> <span class="o">:</span> <span class="k">sig</span>
<span class="k">type</span> <span class="n">tag</span> <span class="o">=</span> <span class="o">[`</span><span class="nc">Ridge</span><span class="o">]</span>
<span class="k">type</span> <span class="n">t</span> <span class="o">=</span> <span class="o">[`</span><span class="nc">BaseEstimator</span> <span class="o">|</span> <span class="o">`</span><span class="nc">MultiOutputMixin</span> <span class="o">|</span> <span class="o">`</span><span class="nc">Object</span> <span class="o">|</span> <span class="o">`</span><span class="nc">RegressorMixin</span> <span class="o">|</span> <span class="o">`</span><span class="nc">Ridge</span><span class="o">]</span> <span class="nn">Obj</span><span class="p">.</span><span class="n">t</span>
<span class="k">val</span> <span class="n">of_pyobject</span> <span class="o">:</span> <span class="nn">Py</span><span class="p">.</span><span class="nn">Object</span><span class="p">.</span><span class="n">t</span> <span class="o">-&gt;</span> <span class="n">t</span>
<span class="k">val</span> <span class="n">to_pyobject</span> <span class="o">:</span> <span class="o">[&gt;</span> <span class="n">tag</span><span class="o">]</span> <span class="nn">Obj</span><span class="p">.</span><span class="n">t</span> <span class="o">-&gt;</span> <span class="nn">Py</span><span class="p">.</span><span class="nn">Object</span><span class="p">.</span><span class="n">t</span>

<span class="k">val</span> <span class="n">as_regressor</span> <span class="o">:</span> <span class="n">t</span> <span class="o">-&gt;</span> <span class="o">[`</span><span class="nc">RegressorMixin</span><span class="o">]</span> <span class="nn">Obj</span><span class="p">.</span><span class="n">t</span>
<span class="k">val</span> <span class="n">as_multi_output</span> <span class="o">:</span> <span class="n">t</span> <span class="o">-&gt;</span> <span class="o">[`</span><span class="nc">MultiOutputMixin</span><span class="o">]</span> <span class="nn">Obj</span><span class="p">.</span><span class="n">t</span>
<span class="k">val</span> <span class="n">as_estimator</span> <span class="o">:</span> <span class="n">t</span> <span class="o">-&gt;</span> <span class="o">[`</span><span class="nc">BaseEstimator</span><span class="o">]</span> <span class="nn">Obj</span><span class="p">.</span><span class="n">t</span>
<span class="k">val</span> <span class="n">create</span> <span class="o">:</span> <span class="o">?</span><span class="n">alpha</span><span class="o">:[&gt;`</span><span class="nc">ArrayLike</span><span class="o">]</span> <span class="nn">Np</span><span class="p">.</span><span class="nn">Obj</span><span class="p">.</span><span class="n">t</span> <span class="o">-&gt;</span> <span class="o">?</span><span class="n">fit_intercept</span><span class="o">:</span><span class="kt">bool</span> <span class="o">-&gt;</span> <span class="o">?</span><span class="n">normalize</span><span class="o">:</span><span class="kt">bool</span> <span class="o">-&gt;</span> <span class="o">?</span><span class="n">copy_X</span><span class="o">:</span><span class="kt">bool</span> <span class="o">-&gt;</span> <span class="o">?</span><span class="n">max_iter</span><span class="o">:</span><span class="kt">int</span> <span class="o">-&gt;</span> <span class="o">?</span><span class="n">tol</span><span class="o">:</span><span class="kt">float</span> <span class="o">-&gt;</span> <span class="o">?</span><span class="n">solver</span><span class="o">:[`</span><span class="nc">Auto</span> <span class="o">|</span> <span class="o">`</span><span class="nc">Svd</span> <span class="o">|</span> <span class="o">`</span><span class="nc">Cholesky</span> <span class="o">|</span> <span class="o">`</span><span class="nc">Lsqr</span> <span class="o">|</span> <span class="o">`</span><span class="nc">Sparse_cg</span> <span class="o">|</span> <span class="o">`</span><span class="nc">Sag</span> <span class="o">|</span> <span class="o">`</span><span class="nc">Saga</span><span class="o">]</span> <span class="o">-&gt;</span> <span class="o">?</span><span class="n">random_state</span><span class="o">:</span><span class="kt">int</span> <span class="o">-&gt;</span> <span class="kt">unit</span> <span class="o">-&gt;</span> <span class="n">t</span>
</code></pre></div>

<p>Linear least squares with l2 regularization.</p>
<p>Minimizes the objective function::</p>
<p>||y - Xw||^2_2 + alpha * ||w||^2_2</p>
<p>This model solves a regression model where the loss function is
the linear least squares function and regularization is given by
the l2-norm. Also known as Ridge Regression or Tikhonov regularization.
This estimator has built-in support for multi-variate regression
(i.e., when y is a 2d-array of shape (n_samples, n_targets)).</p>
<p>Read more in the :ref:<code>User Guide &lt;ridge_regression&gt;</code>.</p>
<h2 id="parameters_161">Parameters<a class="headerlink" href="#parameters_161" title="Permanent link">&para;</a></h2>
<p>alpha : {float, ndarray of shape (n_targets,)}, default=1.0
Regularization strength; must be a positive float. Regularization
improves the conditioning of the problem and reduces the variance of
the estimates. Larger values specify stronger regularization.
Alpha corresponds to <code>C^-1</code> in other linear models such as
LogisticRegression or LinearSVC. If an array is passed, penalties are
assumed to be specific to the targets. Hence they must correspond in
number.</p>
<p>fit_intercept : bool, default=True
Whether to calculate the intercept for this model. If set
to false, no intercept will be used in calculations
(i.e. data is expected to be centered).</p>
<p>normalize : bool, default=False
This parameter is ignored when <code>fit_intercept</code> is set to False.
If True, the regressors X will be normalized before regression by
subtracting the mean and dividing by the l2-norm.
If you wish to standardize, please use
:class:<code>sklearn.preprocessing.StandardScaler</code> before calling <code>fit</code>
on an estimator with <code>normalize=False</code>.</p>
<p>copy_X : bool, default=True
If True, X will be copied; else, it may be overwritten.</p>
<p>max_iter : int, default=None
Maximum number of iterations for conjugate gradient solver.
For 'sparse_cg' and 'lsqr' solvers, the default value is determined
by scipy.sparse.linalg. For 'sag' solver, the default value is 1000.</p>
<p>tol : float, default=1e-3
Precision of the solution.</p>
<p>solver : {'auto', 'svd', 'cholesky', 'lsqr', 'sparse_cg', 'sag', 'saga'},         default='auto'
Solver to use in the computational routines:</p>
<ul>
<li>
<p>'auto' chooses the solver automatically based on the type of data.</p>
</li>
<li>
<p>'svd' uses a Singular Value Decomposition of X to compute the Ridge
coefficients. More stable for singular matrices than
'cholesky'.</p>
</li>
<li>
<p>'cholesky' uses the standard scipy.linalg.solve function to
obtain a closed-form solution.</p>
</li>
<li>
<p>'sparse_cg' uses the conjugate gradient solver as found in
scipy.sparse.linalg.cg. As an iterative algorithm, this solver is
more appropriate than 'cholesky' for large-scale data
(possibility to set <code>tol</code> and <code>max_iter</code>).</p>
</li>
<li>
<p>'lsqr' uses the dedicated regularized least-squares routine
scipy.sparse.linalg.lsqr. It is the fastest and uses an iterative
procedure.</p>
</li>
<li>
<p>'sag' uses a Stochastic Average Gradient descent, and 'saga' uses
its improved, unbiased version named SAGA. Both methods also use an
iterative procedure, and are often faster than other solvers when
both n_samples and n_features are large. Note that 'sag' and
'saga' fast convergence is only guaranteed on features with
approximately the same scale. You can preprocess the data with a
scaler from sklearn.preprocessing.</p>
</li>
</ul>
<p>All last five solvers support both dense and sparse data. However, only
'sparse_cg' supports sparse input when <code>fit_intercept</code> is True.</p>
<p>.. versionadded:: 0.17
Stochastic Average Gradient descent solver.
.. versionadded:: 0.19
SAGA solver.</p>
<p>random_state : int, RandomState instance, default=None
The seed of the pseudo random number generator to use when shuffling
the data.  If int, random_state is the seed used by the random number
generator; If RandomState instance, random_state is the random number
generator; If None, the random number generator is the RandomState
instance used by <code>np.random</code>. Used when <code>solver</code> == 'sag'.</p>
<p>.. versionadded:: 0.17
<em>random_state</em> to support Stochastic Average Gradient.</p>
<h2 id="attributes_25">Attributes<a class="headerlink" href="#attributes_25" title="Permanent link">&para;</a></h2>
<p>coef_ : ndarray of shape (n_features,) or (n_targets, n_features)
Weight vector(s).</p>
<p>intercept_ : float or ndarray of shape (n_targets,)
Independent term in decision function. Set to 0.0 if
<code>fit_intercept = False</code>.</p>
<p>n_iter_ : None or ndarray of shape (n_targets,)
Actual number of iterations for each target. Available only for
sag and lsqr solvers. Other solvers will return None.</p>
<p>.. versionadded:: 0.17</p>
<h2 id="see-also_21">See also<a class="headerlink" href="#see-also_21" title="Permanent link">&para;</a></h2>
<p>RidgeClassifier : Ridge classifier
RidgeCV : Ridge regression with built-in cross validation
:class:<code>sklearn.kernel_ridge.KernelRidge</code> : Kernel ridge regression
combines ridge regression with the kernel trick</p>
<h2 id="examples_25">Examples<a class="headerlink" href="#examples_25" title="Permanent link">&para;</a></h2>
<blockquote>
<blockquote>
<blockquote>
<p>from sklearn.linear_model import Ridge
import numpy as np
n_samples, n_features = 10, 5
rng = np.random.RandomState(0)
y = rng.randn(n_samples)
X = rng.randn(n_samples, n_features)
clf = Ridge(alpha=1.0)
clf.fit(X, y)
Ridge()</p>
</blockquote>
</blockquote>
</blockquote>
<div class="highlight"><pre><span></span><code><span class="k">val</span> <span class="n">fit</span> <span class="o">:</span> <span class="o">?</span><span class="n">sample_weight</span><span class="o">:[&gt;`</span><span class="nc">ArrayLike</span><span class="o">]</span> <span class="nn">Np</span><span class="p">.</span><span class="nn">Obj</span><span class="p">.</span><span class="n">t</span> <span class="o">-&gt;</span> <span class="n">x</span><span class="o">:[&gt;`</span><span class="nc">ArrayLike</span><span class="o">]</span> <span class="nn">Np</span><span class="p">.</span><span class="nn">Obj</span><span class="p">.</span><span class="n">t</span> <span class="o">-&gt;</span> <span class="n">y</span><span class="o">:[&gt;`</span><span class="nc">ArrayLike</span><span class="o">]</span> <span class="nn">Np</span><span class="p">.</span><span class="nn">Obj</span><span class="p">.</span><span class="n">t</span> <span class="o">-&gt;</span> <span class="o">[&gt;</span> <span class="n">tag</span><span class="o">]</span> <span class="nn">Obj</span><span class="p">.</span><span class="n">t</span> <span class="o">-&gt;</span> <span class="n">t</span>
</code></pre></div>

<p>Fit Ridge regression model.</p>
<h2 id="parameters_162">Parameters<a class="headerlink" href="#parameters_162" title="Permanent link">&para;</a></h2>
<p>X : {ndarray, sparse matrix} of shape (n_samples, n_features)
Training data</p>
<p>y : ndarray of shape (n_samples,) or (n_samples, n_targets)
Target values</p>
<p>sample_weight : float or ndarray of shape (n_samples,), default=None
Individual weights for each sample. If given a float, every sample
will have the same weight.</p>
<h2 id="returns_137">Returns<a class="headerlink" href="#returns_137" title="Permanent link">&para;</a></h2>
<p>self : returns an instance of self.</p>
<div class="highlight"><pre><span></span><code><span class="k">val</span> <span class="n">get_params</span> <span class="o">:</span> <span class="o">?</span><span class="n">deep</span><span class="o">:</span><span class="kt">bool</span> <span class="o">-&gt;</span> <span class="o">[&gt;</span> <span class="n">tag</span><span class="o">]</span> <span class="nn">Obj</span><span class="p">.</span><span class="n">t</span> <span class="o">-&gt;</span> <span class="nn">Dict</span><span class="p">.</span><span class="n">t</span>
</code></pre></div>

<p>Get parameters for this estimator.</p>
<h2 id="parameters_163">Parameters<a class="headerlink" href="#parameters_163" title="Permanent link">&para;</a></h2>
<p>deep : bool, default=True
If True, will return the parameters for this estimator and
contained subobjects that are estimators.</p>
<h2 id="returns_138">Returns<a class="headerlink" href="#returns_138" title="Permanent link">&para;</a></h2>
<p>params : mapping of string to any
Parameter names mapped to their values.</p>
<div class="highlight"><pre><span></span><code><span class="k">val</span> <span class="n">predict</span> <span class="o">:</span> <span class="n">x</span><span class="o">:[&gt;`</span><span class="nc">ArrayLike</span><span class="o">]</span> <span class="nn">Np</span><span class="p">.</span><span class="nn">Obj</span><span class="p">.</span><span class="n">t</span> <span class="o">-&gt;</span> <span class="o">[&gt;</span> <span class="n">tag</span><span class="o">]</span> <span class="nn">Obj</span><span class="p">.</span><span class="n">t</span> <span class="o">-&gt;</span> <span class="o">[&gt;`</span><span class="nc">ArrayLike</span><span class="o">]</span> <span class="nn">Np</span><span class="p">.</span><span class="nn">Obj</span><span class="p">.</span><span class="n">t</span>
</code></pre></div>

<p>Predict using the linear model.</p>
<h2 id="parameters_164">Parameters<a class="headerlink" href="#parameters_164" title="Permanent link">&para;</a></h2>
<p>X : array_like or sparse matrix, shape (n_samples, n_features)
Samples.</p>
<h2 id="returns_139">Returns<a class="headerlink" href="#returns_139" title="Permanent link">&para;</a></h2>
<p>C : array, shape (n_samples,)
Returns predicted values.</p>
<div class="highlight"><pre><span></span><code><span class="k">val</span> <span class="n">score</span> <span class="o">:</span> <span class="o">?</span><span class="n">sample_weight</span><span class="o">:[&gt;`</span><span class="nc">ArrayLike</span><span class="o">]</span> <span class="nn">Np</span><span class="p">.</span><span class="nn">Obj</span><span class="p">.</span><span class="n">t</span> <span class="o">-&gt;</span> <span class="n">x</span><span class="o">:[&gt;`</span><span class="nc">ArrayLike</span><span class="o">]</span> <span class="nn">Np</span><span class="p">.</span><span class="nn">Obj</span><span class="p">.</span><span class="n">t</span> <span class="o">-&gt;</span> <span class="n">y</span><span class="o">:[&gt;`</span><span class="nc">ArrayLike</span><span class="o">]</span> <span class="nn">Np</span><span class="p">.</span><span class="nn">Obj</span><span class="p">.</span><span class="n">t</span> <span class="o">-&gt;</span> <span class="o">[&gt;</span> <span class="n">tag</span><span class="o">]</span> <span class="nn">Obj</span><span class="p">.</span><span class="n">t</span> <span class="o">-&gt;</span> <span class="kt">float</span>
</code></pre></div>

<p>Return the coefficient of determination R^2 of the prediction.</p>
<p>The coefficient R^2 is defined as (1 - u/v), where u is the residual
sum of squares ((y_true - y_pred) <strong> 2).sum() and v is the total
sum of squares ((y_true - y_true.mean()) </strong> 2).sum().
The best possible score is 1.0 and it can be negative (because the
model can be arbitrarily worse). A constant model that always
predicts the expected value of y, disregarding the input features,
would get a R^2 score of 0.0.</p>
<h2 id="parameters_165">Parameters<a class="headerlink" href="#parameters_165" title="Permanent link">&para;</a></h2>
<p>X : array-like of shape (n_samples, n_features)
Test samples. For some estimators this may be a
precomputed kernel matrix or a list of generic objects instead,
shape = (n_samples, n_samples_fitted),
where n_samples_fitted is the number of
samples used in the fitting for the estimator.</p>
<p>y : array-like of shape (n_samples,) or (n_samples, n_outputs)
True values for X.</p>
<p>sample_weight : array-like of shape (n_samples,), default=None
Sample weights.</p>
<h2 id="returns_140">Returns<a class="headerlink" href="#returns_140" title="Permanent link">&para;</a></h2>
<p>score : float
R^2 of self.predict(X) wrt. y.</p>
<h2 id="notes_46">Notes<a class="headerlink" href="#notes_46" title="Permanent link">&para;</a></h2>
<p>The R2 score used when calling <code>score</code> on a regressor will use
<code>multioutput='uniform_average'</code> from version 0.23 to keep consistent
with :func:<code>~sklearn.metrics.r2_score</code>. This will influence the
<code>score</code> method of all the multioutput regressors (except for
:class:<code>~sklearn.multioutput.MultiOutputRegressor</code>). To specify the
default value manually and avoid the warning, please either call
:func:<code>~sklearn.metrics.r2_score</code> directly or make a custom scorer with
:func:<code>~sklearn.metrics.make_scorer</code> (the built-in scorer <code>'r2'</code> uses
<code>multioutput='uniform_average'</code>).</p>
<div class="highlight"><pre><span></span><code><span class="k">val</span> <span class="n">set_params</span> <span class="o">:</span> <span class="o">?</span><span class="n">params</span><span class="o">:(</span><span class="kt">string</span> <span class="o">*</span> <span class="nn">Py</span><span class="p">.</span><span class="nn">Object</span><span class="p">.</span><span class="n">t</span><span class="o">)</span> <span class="kt">list</span> <span class="o">-&gt;</span> <span class="o">[&gt;</span> <span class="n">tag</span><span class="o">]</span> <span class="nn">Obj</span><span class="p">.</span><span class="n">t</span> <span class="o">-&gt;</span> <span class="n">t</span>
</code></pre></div>

<p>Set the parameters of this estimator.</p>
<p>The method works on simple estimators as well as on nested objects
(such as pipelines). The latter have parameters of the form
<code>&lt;component&gt;__&lt;parameter&gt;</code> so that it's possible to update each
component of a nested object.</p>
<h2 id="parameters_166">Parameters<a class="headerlink" href="#parameters_166" title="Permanent link">&para;</a></h2>
<p>**params : dict
Estimator parameters.</p>
<h2 id="returns_141">Returns<a class="headerlink" href="#returns_141" title="Permanent link">&para;</a></h2>
<p>self : object
Estimator instance.</p>
<p>Attribute coef_: get value or raise Not_found if None.</p>
<div class="highlight"><pre><span></span><code><span class="k">val</span> <span class="n">coef_</span> <span class="o">:</span> <span class="n">t</span> <span class="o">-&gt;</span> <span class="o">[&gt;`</span><span class="nc">ArrayLike</span><span class="o">]</span> <span class="nn">Np</span><span class="p">.</span><span class="nn">Obj</span><span class="p">.</span><span class="n">t</span>
</code></pre></div>

<p>Attribute coef_: get value as an option.</p>
<div class="highlight"><pre><span></span><code><span class="k">val</span> <span class="n">coef_opt</span> <span class="o">:</span> <span class="n">t</span> <span class="o">-&gt;</span> <span class="o">([&gt;`</span><span class="nc">ArrayLike</span><span class="o">]</span> <span class="nn">Np</span><span class="p">.</span><span class="nn">Obj</span><span class="p">.</span><span class="n">t</span><span class="o">)</span> <span class="n">option</span>
</code></pre></div>

<p>Attribute intercept_: get value or raise Not_found if None.</p>
<div class="highlight"><pre><span></span><code><span class="k">val</span> <span class="n">intercept_</span> <span class="o">:</span> <span class="n">t</span> <span class="o">-&gt;</span> <span class="o">[&gt;`</span><span class="nc">ArrayLike</span><span class="o">]</span> <span class="nn">Np</span><span class="p">.</span><span class="nn">Obj</span><span class="p">.</span><span class="n">t</span>
</code></pre></div>

<p>Attribute intercept_: get value as an option.</p>
<div class="highlight"><pre><span></span><code><span class="k">val</span> <span class="n">intercept_opt</span> <span class="o">:</span> <span class="n">t</span> <span class="o">-&gt;</span> <span class="o">([&gt;`</span><span class="nc">ArrayLike</span><span class="o">]</span> <span class="nn">Np</span><span class="p">.</span><span class="nn">Obj</span><span class="p">.</span><span class="n">t</span><span class="o">)</span> <span class="n">option</span>
</code></pre></div>

<p>Attribute n_iter_: get value or raise Not_found if None.</p>
<div class="highlight"><pre><span></span><code><span class="k">val</span> <span class="n">n_iter_</span> <span class="o">:</span> <span class="n">t</span> <span class="o">-&gt;</span> <span class="o">[&gt;`</span><span class="nc">ArrayLike</span><span class="o">]</span> <span class="nn">Np</span><span class="p">.</span><span class="nn">Obj</span><span class="p">.</span><span class="n">t</span>
</code></pre></div>

<p>Attribute n_iter_: get value as an option.</p>
<div class="highlight"><pre><span></span><code><span class="k">val</span> <span class="n">n_iter_opt</span> <span class="o">:</span> <span class="n">t</span> <span class="o">-&gt;</span> <span class="o">([&gt;`</span><span class="nc">ArrayLike</span><span class="o">]</span> <span class="nn">Np</span><span class="p">.</span><span class="nn">Obj</span><span class="p">.</span><span class="n">t</span><span class="o">)</span> <span class="n">option</span>
</code></pre></div>

<p>Print the object to a human-readable representation.</p>
<div class="highlight"><pre><span></span><code><span class="k">val</span> <span class="n">to_string</span> <span class="o">:</span> <span class="n">t</span> <span class="o">-&gt;</span> <span class="kt">string</span>
</code></pre></div>

<p>Print the object to a human-readable representation.</p>
<div class="highlight"><pre><span></span><code><span class="k">val</span> <span class="n">show</span> <span class="o">:</span> <span class="n">t</span> <span class="o">-&gt;</span> <span class="kt">string</span>
</code></pre></div>

<p>Pretty-print the object to a formatter.</p>
<div class="highlight"><pre><span></span><code><span class="k">val</span> <span class="n">pp</span> <span class="o">:</span> <span class="nn">Format</span><span class="p">.</span><span class="n">formatter</span> <span class="o">-&gt;</span> <span class="n">t</span> <span class="o">-&gt;</span> <span class="kt">unit</span> <span class="o">[@@</span><span class="n">ocaml</span><span class="o">.</span><span class="n">toplevel_printer</span><span class="o">]</span>



<span class="k">module</span> <span class="nc">RidgeCV</span> <span class="o">:</span> <span class="k">sig</span>
<span class="k">type</span> <span class="n">tag</span> <span class="o">=</span> <span class="o">[`</span><span class="nc">RidgeCV</span><span class="o">]</span>
<span class="k">type</span> <span class="n">t</span> <span class="o">=</span> <span class="o">[`</span><span class="nc">BaseEstimator</span> <span class="o">|</span> <span class="o">`</span><span class="nc">MultiOutputMixin</span> <span class="o">|</span> <span class="o">`</span><span class="nc">Object</span> <span class="o">|</span> <span class="o">`</span><span class="nc">RegressorMixin</span> <span class="o">|</span> <span class="o">`</span><span class="nc">RidgeCV</span><span class="o">]</span> <span class="nn">Obj</span><span class="p">.</span><span class="n">t</span>
<span class="k">val</span> <span class="n">of_pyobject</span> <span class="o">:</span> <span class="nn">Py</span><span class="p">.</span><span class="nn">Object</span><span class="p">.</span><span class="n">t</span> <span class="o">-&gt;</span> <span class="n">t</span>
<span class="k">val</span> <span class="n">to_pyobject</span> <span class="o">:</span> <span class="o">[&gt;</span> <span class="n">tag</span><span class="o">]</span> <span class="nn">Obj</span><span class="p">.</span><span class="n">t</span> <span class="o">-&gt;</span> <span class="nn">Py</span><span class="p">.</span><span class="nn">Object</span><span class="p">.</span><span class="n">t</span>

<span class="k">val</span> <span class="n">as_regressor</span> <span class="o">:</span> <span class="n">t</span> <span class="o">-&gt;</span> <span class="o">[`</span><span class="nc">RegressorMixin</span><span class="o">]</span> <span class="nn">Obj</span><span class="p">.</span><span class="n">t</span>
<span class="k">val</span> <span class="n">as_multi_output</span> <span class="o">:</span> <span class="n">t</span> <span class="o">-&gt;</span> <span class="o">[`</span><span class="nc">MultiOutputMixin</span><span class="o">]</span> <span class="nn">Obj</span><span class="p">.</span><span class="n">t</span>
<span class="k">val</span> <span class="n">as_estimator</span> <span class="o">:</span> <span class="n">t</span> <span class="o">-&gt;</span> <span class="o">[`</span><span class="nc">BaseEstimator</span><span class="o">]</span> <span class="nn">Obj</span><span class="p">.</span><span class="n">t</span>
<span class="k">val</span> <span class="n">create</span> <span class="o">:</span> <span class="o">?</span><span class="n">alphas</span><span class="o">:[&gt;`</span><span class="nc">ArrayLike</span><span class="o">]</span> <span class="nn">Np</span><span class="p">.</span><span class="nn">Obj</span><span class="p">.</span><span class="n">t</span> <span class="o">-&gt;</span> <span class="o">?</span><span class="n">fit_intercept</span><span class="o">:</span><span class="kt">bool</span> <span class="o">-&gt;</span> <span class="o">?</span><span class="n">normalize</span><span class="o">:</span><span class="kt">bool</span> <span class="o">-&gt;</span> <span class="o">?</span><span class="n">scoring</span><span class="o">:[`</span><span class="nc">Max_error</span> <span class="o">|</span> <span class="o">`</span><span class="nc">Mutual_info_score</span> <span class="o">|</span> <span class="o">`</span><span class="nc">Homogeneity_score</span> <span class="o">|</span> <span class="o">`</span><span class="nc">Roc_auc</span> <span class="o">|</span> <span class="o">`</span><span class="nc">Neg_mean_squared_error</span> <span class="o">|</span> <span class="o">`</span><span class="nc">Recall_micro</span> <span class="o">|</span> <span class="o">`</span><span class="nc">Neg_mean_poisson_deviance</span> <span class="o">|</span> <span class="o">`</span><span class="nc">Neg_log_loss</span> <span class="o">|</span> <span class="o">`</span><span class="nc">F1_macro</span> <span class="o">|</span> <span class="o">`</span><span class="nc">Neg_mean_gamma_deviance</span> <span class="o">|</span> <span class="o">`</span><span class="nc">Neg_median_absolute_error</span> <span class="o">|</span> <span class="o">`</span><span class="nc">Callable</span> <span class="k">of</span> <span class="nn">Py</span><span class="p">.</span><span class="nn">Object</span><span class="p">.</span><span class="n">t</span> <span class="o">|</span> <span class="o">`</span><span class="nc">Neg_brier_score</span> <span class="o">|</span> <span class="o">`</span><span class="nc">Neg_mean_squared_log_error</span> <span class="o">|</span> <span class="o">`</span><span class="nc">Recall_macro</span> <span class="o">|</span> <span class="o">`</span><span class="nc">Explained_variance</span> <span class="o">|</span> <span class="o">`</span><span class="nc">Roc_auc_ovr_weighted</span> <span class="o">|</span> <span class="o">`</span><span class="nc">Adjusted_rand_score</span> <span class="o">|</span> <span class="o">`</span><span class="nc">Precision_macro</span> <span class="o">|</span> <span class="o">`</span><span class="nc">Jaccard_samples</span> <span class="o">|</span> <span class="o">`</span><span class="nc">Roc_auc_ovo_weighted</span> <span class="o">|</span> <span class="o">`</span><span class="nc">Jaccard_macro</span> <span class="o">|</span> <span class="o">`</span><span class="nc">Precision</span> <span class="o">|</span> <span class="o">`</span><span class="nc">Balanced_accuracy</span> <span class="o">|</span> <span class="o">`</span><span class="nc">Precision_micro</span> <span class="o">|</span> <span class="o">`</span><span class="nc">Precision_weighted</span> <span class="o">|</span> <span class="o">`</span><span class="nc">V_measure_score</span> <span class="o">|</span> <span class="o">`</span><span class="nc">Normalized_mutual_info_score</span> <span class="o">|</span> <span class="o">`</span><span class="nc">F1_weighted</span> <span class="o">|</span> <span class="o">`</span><span class="nc">Neg_root_mean_squared_error</span> <span class="o">|</span> <span class="o">`</span><span class="nc">Neg_mean_absolute_error</span> <span class="o">|</span> <span class="o">`</span><span class="nc">F1</span> <span class="o">|</span> <span class="o">`</span><span class="nc">Roc_auc_ovo</span> <span class="o">|</span> <span class="o">`</span><span class="nc">Jaccard_micro</span> <span class="o">|</span> <span class="o">`</span><span class="nc">Average_precision</span> <span class="o">|</span> <span class="o">`</span><span class="nc">Adjusted_mutual_info_score</span> <span class="o">|</span> <span class="o">`</span><span class="nc">R2</span> <span class="o">|</span> <span class="o">`</span><span class="nc">F1_samples</span> <span class="o">|</span> <span class="o">`</span><span class="nc">Fowlkes_mallows_score</span> <span class="o">|</span> <span class="o">`</span><span class="nc">Accuracy</span> <span class="o">|</span> <span class="o">`</span><span class="nc">Recall_weighted</span> <span class="o">|</span> <span class="o">`</span><span class="nc">Jaccard_weighted</span> <span class="o">|</span> <span class="o">`</span><span class="nc">Roc_auc_ovr</span> <span class="o">|</span> <span class="o">`</span><span class="nc">F1_micro</span> <span class="o">|</span> <span class="o">`</span><span class="nc">Precision_samples</span> <span class="o">|</span> <span class="o">`</span><span class="nc">Jaccard</span> <span class="o">|</span> <span class="o">`</span><span class="nc">Completeness_score</span> <span class="o">|</span> <span class="o">`</span><span class="nc">Recall_samples</span> <span class="o">|</span> <span class="o">`</span><span class="nc">Recall</span><span class="o">]</span> <span class="o">-&gt;</span> <span class="o">?</span><span class="n">cv</span><span class="o">:[`</span><span class="nc">Arr</span> <span class="k">of</span> <span class="o">[&gt;`</span><span class="nc">ArrayLike</span><span class="o">]</span> <span class="nn">Np</span><span class="p">.</span><span class="nn">Obj</span><span class="p">.</span><span class="n">t</span> <span class="o">|</span> <span class="o">`</span><span class="nc">BaseCrossValidator</span> <span class="k">of</span> <span class="o">[&gt;`</span><span class="nc">BaseCrossValidator</span><span class="o">]</span> <span class="nn">Np</span><span class="p">.</span><span class="nn">Obj</span><span class="p">.</span><span class="n">t</span> <span class="o">|</span> <span class="o">`</span><span class="nc">I</span> <span class="k">of</span> <span class="kt">int</span><span class="o">]</span> <span class="o">-&gt;</span> <span class="o">?</span><span class="n">gcv_mode</span><span class="o">:[`</span><span class="nc">Svd</span> <span class="o">|</span> <span class="o">`</span><span class="nc">Eigen</span> <span class="o">|</span> <span class="o">`</span><span class="nc">Auto</span><span class="o">]</span> <span class="o">-&gt;</span> <span class="o">?</span><span class="n">store_cv_values</span><span class="o">:</span><span class="kt">bool</span> <span class="o">-&gt;</span> <span class="kt">unit</span> <span class="o">-&gt;</span> <span class="n">t</span>
</code></pre></div>

<p>Ridge regression with built-in cross-validation.</p>
<p>See glossary entry for :term:<code>cross-validation estimator</code>.</p>
<p>By default, it performs Generalized Cross-Validation, which is a form of
efficient Leave-One-Out cross-validation.</p>
<p>Read more in the :ref:<code>User Guide &lt;ridge_regression&gt;</code>.</p>
<h2 id="parameters_167">Parameters<a class="headerlink" href="#parameters_167" title="Permanent link">&para;</a></h2>
<p>alphas : ndarray of shape (n_alphas,), default=(0.1, 1.0, 10.0)
Array of alpha values to try.
Regularization strength; must be a positive float. Regularization
improves the conditioning of the problem and reduces the variance of
the estimates. Larger values specify stronger regularization.
Alpha corresponds to <code>C^-1</code> in other linear models such as
LogisticRegression or LinearSVC.
If using generalized cross-validation, alphas must be positive.</p>
<p>fit_intercept : bool, default=True
Whether to calculate the intercept for this model. If set
to false, no intercept will be used in calculations
(i.e. data is expected to be centered).</p>
<p>normalize : bool, default=False
This parameter is ignored when <code>fit_intercept</code> is set to False.
If True, the regressors X will be normalized before regression by
subtracting the mean and dividing by the l2-norm.
If you wish to standardize, please use
:class:<code>sklearn.preprocessing.StandardScaler</code> before calling <code>fit</code>
on an estimator with <code>normalize=False</code>.</p>
<p>scoring : string, callable, default=None
A string (see model evaluation documentation) or
a scorer callable object / function with signature
<code>scorer(estimator, X, y)</code>.
If None, the negative mean squared error if cv is 'auto' or None
(i.e. when using generalized cross-validation), and r2 score otherwise.</p>
<p>cv : int, cross-validation generator or an iterable, default=None
Determines the cross-validation splitting strategy.
Possible inputs for cv are:</p>
<ul>
<li>None, to use the efficient Leave-One-Out cross-validation
(also known as Generalized Cross-Validation).</li>
<li>integer, to specify the number of folds.</li>
<li>:term:<code>CV splitter</code>,</li>
<li>An iterable yielding (train, test) splits as arrays of indices.</li>
</ul>
<p>For integer/None inputs, if <code>y</code> is binary or multiclass,
:class:<code>sklearn.model_selection.StratifiedKFold</code> is used, else,
:class:<code>sklearn.model_selection.KFold</code> is used.</p>
<p>Refer :ref:<code>User Guide &lt;cross_validation&gt;</code> for the various
cross-validation strategies that can be used here.</p>
<p>gcv_mode : {'auto', 'svd', eigen'}, default='auto'
Flag indicating which strategy to use when performing
Generalized Cross-Validation. Options are::</p>
<p>'auto' : use 'svd' if n_samples &gt; n_features, otherwise use 'eigen'
'svd' : force use of singular value decomposition of X when X is
dense, eigenvalue decomposition of X^T.X when X is sparse.
'eigen' : force computation via eigendecomposition of X.X^T</p>
<p>The 'auto' mode is the default and is intended to pick the cheaper
option of the two depending on the shape of the training data.</p>
<p>store_cv_values : bool, default=False
Flag indicating if the cross-validation values corresponding to
each alpha should be stored in the <code>cv_values_</code> attribute (see
below). This flag is only compatible with <code>cv=None</code> (i.e. using
Generalized Cross-Validation).</p>
<h2 id="attributes_26">Attributes<a class="headerlink" href="#attributes_26" title="Permanent link">&para;</a></h2>
<p>cv_values_ : ndarray of shape (n_samples, n_alphas) or         shape (n_samples, n_targets, n_alphas), optional
Cross-validation values for each alpha (if <code>store_cv_values=True</code>        and <code>cv=None</code>). After <code>fit()</code> has been called, this attribute         will contain the mean squared errors (by default) or the values         of the <code>{loss,score}_func</code> function (if provided in the constructor).</p>
<p>coef_ : ndarray of shape (n_features) or (n_targets, n_features)
Weight vector(s).</p>
<p>intercept_ : float or ndarray of shape (n_targets,)
Independent term in decision function. Set to 0.0 if
<code>fit_intercept = False</code>.</p>
<p>alpha_ : float
Estimated regularization parameter.</p>
<h2 id="examples_26">Examples<a class="headerlink" href="#examples_26" title="Permanent link">&para;</a></h2>
<blockquote>
<blockquote>
<blockquote>
<p>from sklearn.datasets import load_diabetes
from sklearn.linear_model import RidgeCV
X, y = load_diabetes(return_X_y=True)
clf = RidgeCV(alphas=[1e-3, 1e-2, 1e-1, 1]).fit(X, y)
clf.score(X, y)
0.5166...</p>
</blockquote>
</blockquote>
</blockquote>
<h2 id="see-also_22">See also<a class="headerlink" href="#see-also_22" title="Permanent link">&para;</a></h2>
<p>Ridge : Ridge regression
RidgeClassifier : Ridge classifier
RidgeClassifierCV : Ridge classifier with built-in cross validation</p>
<div class="highlight"><pre><span></span><code><span class="k">val</span> <span class="n">fit</span> <span class="o">:</span> <span class="o">?</span><span class="n">sample_weight</span><span class="o">:[&gt;`</span><span class="nc">ArrayLike</span><span class="o">]</span> <span class="nn">Np</span><span class="p">.</span><span class="nn">Obj</span><span class="p">.</span><span class="n">t</span> <span class="o">-&gt;</span> <span class="n">x</span><span class="o">:[&gt;`</span><span class="nc">ArrayLike</span><span class="o">]</span> <span class="nn">Np</span><span class="p">.</span><span class="nn">Obj</span><span class="p">.</span><span class="n">t</span> <span class="o">-&gt;</span> <span class="n">y</span><span class="o">:[&gt;`</span><span class="nc">ArrayLike</span><span class="o">]</span> <span class="nn">Np</span><span class="p">.</span><span class="nn">Obj</span><span class="p">.</span><span class="n">t</span> <span class="o">-&gt;</span> <span class="o">[&gt;</span> <span class="n">tag</span><span class="o">]</span> <span class="nn">Obj</span><span class="p">.</span><span class="n">t</span> <span class="o">-&gt;</span> <span class="n">t</span>
</code></pre></div>

<p>Fit Ridge regression model with cv.</p>
<h2 id="parameters_168">Parameters<a class="headerlink" href="#parameters_168" title="Permanent link">&para;</a></h2>
<p>X : ndarray of shape (n_samples, n_features)
Training data. If using GCV, will be cast to float64
if necessary.</p>
<p>y : ndarray of shape (n_samples,) or (n_samples, n_targets)
Target values. Will be cast to X's dtype if necessary.</p>
<p>sample_weight : float or ndarray of shape (n_samples,), default=None
Individual weights for each sample. If given a float, every sample
will have the same weight.</p>
<h2 id="returns_142">Returns<a class="headerlink" href="#returns_142" title="Permanent link">&para;</a></h2>
<p>self : object</p>
<h2 id="notes_47">Notes<a class="headerlink" href="#notes_47" title="Permanent link">&para;</a></h2>
<p>When sample_weight is provided, the selected hyperparameter may depend
on whether we use generalized cross-validation (cv=None or cv='auto')
or another form of cross-validation, because only generalized
cross-validation takes the sample weights into account when computing
the validation score.</p>
<div class="highlight"><pre><span></span><code><span class="k">val</span> <span class="n">get_params</span> <span class="o">:</span> <span class="o">?</span><span class="n">deep</span><span class="o">:</span><span class="kt">bool</span> <span class="o">-&gt;</span> <span class="o">[&gt;</span> <span class="n">tag</span><span class="o">]</span> <span class="nn">Obj</span><span class="p">.</span><span class="n">t</span> <span class="o">-&gt;</span> <span class="nn">Dict</span><span class="p">.</span><span class="n">t</span>
</code></pre></div>

<p>Get parameters for this estimator.</p>
<h2 id="parameters_169">Parameters<a class="headerlink" href="#parameters_169" title="Permanent link">&para;</a></h2>
<p>deep : bool, default=True
If True, will return the parameters for this estimator and
contained subobjects that are estimators.</p>
<h2 id="returns_143">Returns<a class="headerlink" href="#returns_143" title="Permanent link">&para;</a></h2>
<p>params : mapping of string to any
Parameter names mapped to their values.</p>
<div class="highlight"><pre><span></span><code><span class="k">val</span> <span class="n">predict</span> <span class="o">:</span> <span class="n">x</span><span class="o">:[&gt;`</span><span class="nc">ArrayLike</span><span class="o">]</span> <span class="nn">Np</span><span class="p">.</span><span class="nn">Obj</span><span class="p">.</span><span class="n">t</span> <span class="o">-&gt;</span> <span class="o">[&gt;</span> <span class="n">tag</span><span class="o">]</span> <span class="nn">Obj</span><span class="p">.</span><span class="n">t</span> <span class="o">-&gt;</span> <span class="o">[&gt;`</span><span class="nc">ArrayLike</span><span class="o">]</span> <span class="nn">Np</span><span class="p">.</span><span class="nn">Obj</span><span class="p">.</span><span class="n">t</span>
</code></pre></div>

<p>Predict using the linear model.</p>
<h2 id="parameters_170">Parameters<a class="headerlink" href="#parameters_170" title="Permanent link">&para;</a></h2>
<p>X : array_like or sparse matrix, shape (n_samples, n_features)
Samples.</p>
<h2 id="returns_144">Returns<a class="headerlink" href="#returns_144" title="Permanent link">&para;</a></h2>
<p>C : array, shape (n_samples,)
Returns predicted values.</p>
<div class="highlight"><pre><span></span><code><span class="k">val</span> <span class="n">score</span> <span class="o">:</span> <span class="o">?</span><span class="n">sample_weight</span><span class="o">:[&gt;`</span><span class="nc">ArrayLike</span><span class="o">]</span> <span class="nn">Np</span><span class="p">.</span><span class="nn">Obj</span><span class="p">.</span><span class="n">t</span> <span class="o">-&gt;</span> <span class="n">x</span><span class="o">:[&gt;`</span><span class="nc">ArrayLike</span><span class="o">]</span> <span class="nn">Np</span><span class="p">.</span><span class="nn">Obj</span><span class="p">.</span><span class="n">t</span> <span class="o">-&gt;</span> <span class="n">y</span><span class="o">:[&gt;`</span><span class="nc">ArrayLike</span><span class="o">]</span> <span class="nn">Np</span><span class="p">.</span><span class="nn">Obj</span><span class="p">.</span><span class="n">t</span> <span class="o">-&gt;</span> <span class="o">[&gt;</span> <span class="n">tag</span><span class="o">]</span> <span class="nn">Obj</span><span class="p">.</span><span class="n">t</span> <span class="o">-&gt;</span> <span class="kt">float</span>
</code></pre></div>

<p>Return the coefficient of determination R^2 of the prediction.</p>
<p>The coefficient R^2 is defined as (1 - u/v), where u is the residual
sum of squares ((y_true - y_pred) <strong> 2).sum() and v is the total
sum of squares ((y_true - y_true.mean()) </strong> 2).sum().
The best possible score is 1.0 and it can be negative (because the
model can be arbitrarily worse). A constant model that always
predicts the expected value of y, disregarding the input features,
would get a R^2 score of 0.0.</p>
<h2 id="parameters_171">Parameters<a class="headerlink" href="#parameters_171" title="Permanent link">&para;</a></h2>
<p>X : array-like of shape (n_samples, n_features)
Test samples. For some estimators this may be a
precomputed kernel matrix or a list of generic objects instead,
shape = (n_samples, n_samples_fitted),
where n_samples_fitted is the number of
samples used in the fitting for the estimator.</p>
<p>y : array-like of shape (n_samples,) or (n_samples, n_outputs)
True values for X.</p>
<p>sample_weight : array-like of shape (n_samples,), default=None
Sample weights.</p>
<h2 id="returns_145">Returns<a class="headerlink" href="#returns_145" title="Permanent link">&para;</a></h2>
<p>score : float
R^2 of self.predict(X) wrt. y.</p>
<h2 id="notes_48">Notes<a class="headerlink" href="#notes_48" title="Permanent link">&para;</a></h2>
<p>The R2 score used when calling <code>score</code> on a regressor will use
<code>multioutput='uniform_average'</code> from version 0.23 to keep consistent
with :func:<code>~sklearn.metrics.r2_score</code>. This will influence the
<code>score</code> method of all the multioutput regressors (except for
:class:<code>~sklearn.multioutput.MultiOutputRegressor</code>). To specify the
default value manually and avoid the warning, please either call
:func:<code>~sklearn.metrics.r2_score</code> directly or make a custom scorer with
:func:<code>~sklearn.metrics.make_scorer</code> (the built-in scorer <code>'r2'</code> uses
<code>multioutput='uniform_average'</code>).</p>
<div class="highlight"><pre><span></span><code><span class="k">val</span> <span class="n">set_params</span> <span class="o">:</span> <span class="o">?</span><span class="n">params</span><span class="o">:(</span><span class="kt">string</span> <span class="o">*</span> <span class="nn">Py</span><span class="p">.</span><span class="nn">Object</span><span class="p">.</span><span class="n">t</span><span class="o">)</span> <span class="kt">list</span> <span class="o">-&gt;</span> <span class="o">[&gt;</span> <span class="n">tag</span><span class="o">]</span> <span class="nn">Obj</span><span class="p">.</span><span class="n">t</span> <span class="o">-&gt;</span> <span class="n">t</span>
</code></pre></div>

<p>Set the parameters of this estimator.</p>
<p>The method works on simple estimators as well as on nested objects
(such as pipelines). The latter have parameters of the form
<code>&lt;component&gt;__&lt;parameter&gt;</code> so that it's possible to update each
component of a nested object.</p>
<h2 id="parameters_172">Parameters<a class="headerlink" href="#parameters_172" title="Permanent link">&para;</a></h2>
<p>**params : dict
Estimator parameters.</p>
<h2 id="returns_146">Returns<a class="headerlink" href="#returns_146" title="Permanent link">&para;</a></h2>
<p>self : object
Estimator instance.</p>
<p>Attribute cv_values_: get value or raise Not_found if None.</p>
<div class="highlight"><pre><span></span><code><span class="k">val</span> <span class="n">cv_values_</span> <span class="o">:</span> <span class="n">t</span> <span class="o">-&gt;</span> <span class="nn">Py</span><span class="p">.</span><span class="nn">Object</span><span class="p">.</span><span class="n">t</span>
</code></pre></div>

<p>Attribute cv_values_: get value as an option.</p>
<div class="highlight"><pre><span></span><code><span class="k">val</span> <span class="n">cv_values_opt</span> <span class="o">:</span> <span class="n">t</span> <span class="o">-&gt;</span> <span class="o">(</span><span class="nn">Py</span><span class="p">.</span><span class="nn">Object</span><span class="p">.</span><span class="n">t</span><span class="o">)</span> <span class="n">option</span>
</code></pre></div>

<p>Attribute coef_: get value or raise Not_found if None.</p>
<div class="highlight"><pre><span></span><code><span class="k">val</span> <span class="n">coef_</span> <span class="o">:</span> <span class="n">t</span> <span class="o">-&gt;</span> <span class="o">[&gt;`</span><span class="nc">ArrayLike</span><span class="o">]</span> <span class="nn">Np</span><span class="p">.</span><span class="nn">Obj</span><span class="p">.</span><span class="n">t</span>
</code></pre></div>

<p>Attribute coef_: get value as an option.</p>
<div class="highlight"><pre><span></span><code><span class="k">val</span> <span class="n">coef_opt</span> <span class="o">:</span> <span class="n">t</span> <span class="o">-&gt;</span> <span class="o">([&gt;`</span><span class="nc">ArrayLike</span><span class="o">]</span> <span class="nn">Np</span><span class="p">.</span><span class="nn">Obj</span><span class="p">.</span><span class="n">t</span><span class="o">)</span> <span class="n">option</span>
</code></pre></div>

<p>Attribute intercept_: get value or raise Not_found if None.</p>
<div class="highlight"><pre><span></span><code><span class="k">val</span> <span class="n">intercept_</span> <span class="o">:</span> <span class="n">t</span> <span class="o">-&gt;</span> <span class="o">[&gt;`</span><span class="nc">ArrayLike</span><span class="o">]</span> <span class="nn">Np</span><span class="p">.</span><span class="nn">Obj</span><span class="p">.</span><span class="n">t</span>
</code></pre></div>

<p>Attribute intercept_: get value as an option.</p>
<div class="highlight"><pre><span></span><code><span class="k">val</span> <span class="n">intercept_opt</span> <span class="o">:</span> <span class="n">t</span> <span class="o">-&gt;</span> <span class="o">([&gt;`</span><span class="nc">ArrayLike</span><span class="o">]</span> <span class="nn">Np</span><span class="p">.</span><span class="nn">Obj</span><span class="p">.</span><span class="n">t</span><span class="o">)</span> <span class="n">option</span>
</code></pre></div>

<p>Attribute alpha_: get value or raise Not_found if None.</p>
<div class="highlight"><pre><span></span><code><span class="k">val</span> <span class="n">alpha_</span> <span class="o">:</span> <span class="n">t</span> <span class="o">-&gt;</span> <span class="kt">float</span>
</code></pre></div>

<p>Attribute alpha_: get value as an option.</p>
<div class="highlight"><pre><span></span><code><span class="k">val</span> <span class="n">alpha_opt</span> <span class="o">:</span> <span class="n">t</span> <span class="o">-&gt;</span> <span class="o">(</span><span class="kt">float</span><span class="o">)</span> <span class="n">option</span>
</code></pre></div>

<p>Print the object to a human-readable representation.</p>
<div class="highlight"><pre><span></span><code><span class="k">val</span> <span class="n">to_string</span> <span class="o">:</span> <span class="n">t</span> <span class="o">-&gt;</span> <span class="kt">string</span>
</code></pre></div>

<p>Print the object to a human-readable representation.</p>
<div class="highlight"><pre><span></span><code><span class="k">val</span> <span class="n">show</span> <span class="o">:</span> <span class="n">t</span> <span class="o">-&gt;</span> <span class="kt">string</span>
</code></pre></div>

<p>Pretty-print the object to a formatter.</p>
<div class="highlight"><pre><span></span><code><span class="k">val</span> <span class="n">pp</span> <span class="o">:</span> <span class="nn">Format</span><span class="p">.</span><span class="n">formatter</span> <span class="o">-&gt;</span> <span class="n">t</span> <span class="o">-&gt;</span> <span class="kt">unit</span> <span class="o">[@@</span><span class="n">ocaml</span><span class="o">.</span><span class="n">toplevel_printer</span><span class="o">]</span>



<span class="k">module</span> <span class="nc">RidgeClassifier</span> <span class="o">:</span> <span class="k">sig</span>
<span class="k">type</span> <span class="n">tag</span> <span class="o">=</span> <span class="o">[`</span><span class="nc">RidgeClassifier</span><span class="o">]</span>
<span class="k">type</span> <span class="n">t</span> <span class="o">=</span> <span class="o">[`</span><span class="nc">BaseEstimator</span> <span class="o">|</span> <span class="o">`</span><span class="nc">ClassifierMixin</span> <span class="o">|</span> <span class="o">`</span><span class="nc">LinearClassifierMixin</span> <span class="o">|</span> <span class="o">`</span><span class="nc">Object</span> <span class="o">|</span> <span class="o">`</span><span class="nc">RidgeClassifier</span><span class="o">]</span> <span class="nn">Obj</span><span class="p">.</span><span class="n">t</span>
<span class="k">val</span> <span class="n">of_pyobject</span> <span class="o">:</span> <span class="nn">Py</span><span class="p">.</span><span class="nn">Object</span><span class="p">.</span><span class="n">t</span> <span class="o">-&gt;</span> <span class="n">t</span>
<span class="k">val</span> <span class="n">to_pyobject</span> <span class="o">:</span> <span class="o">[&gt;</span> <span class="n">tag</span><span class="o">]</span> <span class="nn">Obj</span><span class="p">.</span><span class="n">t</span> <span class="o">-&gt;</span> <span class="nn">Py</span><span class="p">.</span><span class="nn">Object</span><span class="p">.</span><span class="n">t</span>

<span class="k">val</span> <span class="n">as_classifier</span> <span class="o">:</span> <span class="n">t</span> <span class="o">-&gt;</span> <span class="o">[`</span><span class="nc">ClassifierMixin</span><span class="o">]</span> <span class="nn">Obj</span><span class="p">.</span><span class="n">t</span>
<span class="k">val</span> <span class="n">as_linear_classifier</span> <span class="o">:</span> <span class="n">t</span> <span class="o">-&gt;</span> <span class="o">[`</span><span class="nc">LinearClassifierMixin</span><span class="o">]</span> <span class="nn">Obj</span><span class="p">.</span><span class="n">t</span>
<span class="k">val</span> <span class="n">as_estimator</span> <span class="o">:</span> <span class="n">t</span> <span class="o">-&gt;</span> <span class="o">[`</span><span class="nc">BaseEstimator</span><span class="o">]</span> <span class="nn">Obj</span><span class="p">.</span><span class="n">t</span>
<span class="k">val</span> <span class="n">create</span> <span class="o">:</span> <span class="o">?</span><span class="n">alpha</span><span class="o">:</span><span class="kt">float</span> <span class="o">-&gt;</span> <span class="o">?</span><span class="n">fit_intercept</span><span class="o">:</span><span class="kt">bool</span> <span class="o">-&gt;</span> <span class="o">?</span><span class="n">normalize</span><span class="o">:</span><span class="kt">bool</span> <span class="o">-&gt;</span> <span class="o">?</span><span class="n">copy_X</span><span class="o">:</span><span class="kt">bool</span> <span class="o">-&gt;</span> <span class="o">?</span><span class="n">max_iter</span><span class="o">:</span><span class="kt">int</span> <span class="o">-&gt;</span> <span class="o">?</span><span class="n">tol</span><span class="o">:</span><span class="kt">float</span> <span class="o">-&gt;</span> <span class="o">?</span><span class="n">class_weight</span><span class="o">:[`</span><span class="nc">DictIntToFloat</span> <span class="k">of</span> <span class="o">(</span><span class="kt">int</span> <span class="o">*</span> <span class="kt">float</span><span class="o">)</span> <span class="kt">list</span> <span class="o">|</span> <span class="o">`</span><span class="nc">Balanced</span><span class="o">]</span> <span class="o">-&gt;</span> <span class="o">?</span><span class="n">solver</span><span class="o">:[`</span><span class="nc">Auto</span> <span class="o">|</span> <span class="o">`</span><span class="nc">Svd</span> <span class="o">|</span> <span class="o">`</span><span class="nc">Cholesky</span> <span class="o">|</span> <span class="o">`</span><span class="nc">Lsqr</span> <span class="o">|</span> <span class="o">`</span><span class="nc">Sparse_cg</span> <span class="o">|</span> <span class="o">`</span><span class="nc">Sag</span> <span class="o">|</span> <span class="o">`</span><span class="nc">Saga</span><span class="o">]</span> <span class="o">-&gt;</span> <span class="o">?</span><span class="n">random_state</span><span class="o">:</span><span class="kt">int</span> <span class="o">-&gt;</span> <span class="kt">unit</span> <span class="o">-&gt;</span> <span class="n">t</span>
</code></pre></div>

<p>Classifier using Ridge regression.</p>
<p>This classifier first converts the target values into <code>{-1, 1}</code> and
then treats the problem as a regression task (multi-output regression in
the multiclass case).</p>
<p>Read more in the :ref:<code>User Guide &lt;ridge_regression&gt;</code>.</p>
<h2 id="parameters_173">Parameters<a class="headerlink" href="#parameters_173" title="Permanent link">&para;</a></h2>
<p>alpha : float, default=1.0
Regularization strength; must be a positive float. Regularization
improves the conditioning of the problem and reduces the variance of
the estimates. Larger values specify stronger regularization.
Alpha corresponds to <code>C^-1</code> in other linear models such as
LogisticRegression or LinearSVC.</p>
<p>fit_intercept : bool, default=True
Whether to calculate the intercept for this model. If set to false, no
intercept will be used in calculations (e.g. data is expected to be
already centered).</p>
<p>normalize : bool, default=False
This parameter is ignored when <code>fit_intercept</code> is set to False.
If True, the regressors X will be normalized before regression by
subtracting the mean and dividing by the l2-norm.
If you wish to standardize, please use
:class:<code>sklearn.preprocessing.StandardScaler</code> before calling <code>fit</code>
on an estimator with <code>normalize=False</code>.</p>
<p>copy_X : bool, default=True
If True, X will be copied; else, it may be overwritten.</p>
<p>max_iter : int, default=None
Maximum number of iterations for conjugate gradient solver.
The default value is determined by scipy.sparse.linalg.</p>
<p>tol : float, default=1e-3
Precision of the solution.</p>
<p>class_weight : dict or 'balanced', default=None
Weights associated with classes in the form <code>{class_label: weight}</code>.
If not given, all classes are supposed to have weight one.</p>
<p>The 'balanced' mode uses the values of y to automatically adjust
weights inversely proportional to class frequencies in the input data
as <code>n_samples / (n_classes * np.bincount(y))</code>.</p>
<p>solver : {'auto', 'svd', 'cholesky', 'lsqr', 'sparse_cg', 'sag', 'saga'},         default='auto'
Solver to use in the computational routines:</p>
<ul>
<li>
<p>'auto' chooses the solver automatically based on the type of data.</p>
</li>
<li>
<p>'svd' uses a Singular Value Decomposition of X to compute the Ridge
coefficients. More stable for singular matrices than
'cholesky'.</p>
</li>
<li>
<p>'cholesky' uses the standard scipy.linalg.solve function to
obtain a closed-form solution.</p>
</li>
<li>
<p>'sparse_cg' uses the conjugate gradient solver as found in
scipy.sparse.linalg.cg. As an iterative algorithm, this solver is
more appropriate than 'cholesky' for large-scale data
(possibility to set <code>tol</code> and <code>max_iter</code>).</p>
</li>
<li>
<p>'lsqr' uses the dedicated regularized least-squares routine
scipy.sparse.linalg.lsqr. It is the fastest and uses an iterative
procedure.</p>
</li>
<li>
<p>'sag' uses a Stochastic Average Gradient descent, and 'saga' uses
its unbiased and more flexible version named SAGA. Both methods
use an iterative procedure, and are often faster than other solvers
when both n_samples and n_features are large. Note that 'sag' and
'saga' fast convergence is only guaranteed on features with
approximately the same scale. You can preprocess the data with a
scaler from sklearn.preprocessing.</p>
</li>
</ul>
<p>.. versionadded:: 0.17
Stochastic Average Gradient descent solver.
.. versionadded:: 0.19
SAGA solver.</p>
<p>random_state : int, RandomState instance, default=None
The seed of the pseudo random number generator to use when shuffling
the data.  If int, random_state is the seed used by the random number
generator; If RandomState instance, random_state is the random number
generator; If None, the random number generator is the RandomState
instance used by <code>np.random</code>. Used when <code>solver</code> == 'sag'.</p>
<h2 id="attributes_27">Attributes<a class="headerlink" href="#attributes_27" title="Permanent link">&para;</a></h2>
<p>coef_ : ndarray of shape (1, n_features) or (n_classes, n_features)
Coefficient of the features in the decision function.</p>
<p><code>coef_</code> is of shape (1, n_features) when the given problem is binary.</p>
<p>intercept_ : float or ndarray of shape (n_targets,)
Independent term in decision function. Set to 0.0 if
<code>fit_intercept = False</code>.</p>
<p>n_iter_ : None or ndarray of shape (n_targets,)
Actual number of iterations for each target. Available only for
sag and lsqr solvers. Other solvers will return None.</p>
<p>classes_ : ndarray of shape (n_classes,)
The classes labels.</p>
<h2 id="see-also_23">See Also<a class="headerlink" href="#see-also_23" title="Permanent link">&para;</a></h2>
<p>Ridge : Ridge regression.
RidgeClassifierCV :  Ridge classifier with built-in cross validation.</p>
<h2 id="notes_49">Notes<a class="headerlink" href="#notes_49" title="Permanent link">&para;</a></h2>
<p>For multi-class classification, n_class classifiers are trained in
a one-versus-all approach. Concretely, this is implemented by taking
advantage of the multi-variate response support in Ridge.</p>
<h2 id="examples_27">Examples<a class="headerlink" href="#examples_27" title="Permanent link">&para;</a></h2>
<blockquote>
<blockquote>
<blockquote>
<p>from sklearn.datasets import load_breast_cancer
from sklearn.linear_model import RidgeClassifier
X, y = load_breast_cancer(return_X_y=True)
clf = RidgeClassifier().fit(X, y)
clf.score(X, y)
0.9595...</p>
</blockquote>
</blockquote>
</blockquote>
<div class="highlight"><pre><span></span><code><span class="k">val</span> <span class="n">decision_function</span> <span class="o">:</span> <span class="n">x</span><span class="o">:[&gt;`</span><span class="nc">ArrayLike</span><span class="o">]</span> <span class="nn">Np</span><span class="p">.</span><span class="nn">Obj</span><span class="p">.</span><span class="n">t</span> <span class="o">-&gt;</span> <span class="o">[&gt;</span> <span class="n">tag</span><span class="o">]</span> <span class="nn">Obj</span><span class="p">.</span><span class="n">t</span> <span class="o">-&gt;</span> <span class="o">[&gt;`</span><span class="nc">ArrayLike</span><span class="o">]</span> <span class="nn">Np</span><span class="p">.</span><span class="nn">Obj</span><span class="p">.</span><span class="n">t</span>
</code></pre></div>

<p>Predict confidence scores for samples.</p>
<p>The confidence score for a sample is the signed distance of that
sample to the hyperplane.</p>
<h2 id="parameters_174">Parameters<a class="headerlink" href="#parameters_174" title="Permanent link">&para;</a></h2>
<p>X : array_like or sparse matrix, shape (n_samples, n_features)
Samples.</p>
<h2 id="returns_147">Returns<a class="headerlink" href="#returns_147" title="Permanent link">&para;</a></h2>
<p>array, shape=(n_samples,) if n_classes == 2 else (n_samples, n_classes)
Confidence scores per (sample, class) combination. In the binary
case, confidence score for self.classes_[1] where &gt;0 means this
class would be predicted.</p>
<div class="highlight"><pre><span></span><code><span class="k">val</span> <span class="n">fit</span> <span class="o">:</span> <span class="o">?</span><span class="n">sample_weight</span><span class="o">:[&gt;`</span><span class="nc">ArrayLike</span><span class="o">]</span> <span class="nn">Np</span><span class="p">.</span><span class="nn">Obj</span><span class="p">.</span><span class="n">t</span> <span class="o">-&gt;</span> <span class="n">x</span><span class="o">:[&gt;`</span><span class="nc">ArrayLike</span><span class="o">]</span> <span class="nn">Np</span><span class="p">.</span><span class="nn">Obj</span><span class="p">.</span><span class="n">t</span> <span class="o">-&gt;</span> <span class="n">y</span><span class="o">:[&gt;`</span><span class="nc">ArrayLike</span><span class="o">]</span> <span class="nn">Np</span><span class="p">.</span><span class="nn">Obj</span><span class="p">.</span><span class="n">t</span> <span class="o">-&gt;</span> <span class="o">[&gt;</span> <span class="n">tag</span><span class="o">]</span> <span class="nn">Obj</span><span class="p">.</span><span class="n">t</span> <span class="o">-&gt;</span> <span class="n">t</span>
</code></pre></div>

<p>Fit Ridge classifier model.</p>
<h2 id="parameters_175">Parameters<a class="headerlink" href="#parameters_175" title="Permanent link">&para;</a></h2>
<p>X : {ndarray, sparse matrix} of shape (n_samples, n_features)
Training data.</p>
<p>y : ndarray of shape (n_samples,)
Target values.</p>
<p>sample_weight : float or ndarray of shape (n_samples,), default=None
Individual weights for each sample. If given a float, every sample
will have the same weight.</p>
<p>.. versionadded:: 0.17
<em>sample_weight</em> support to Classifier.</p>
<h2 id="returns_148">Returns<a class="headerlink" href="#returns_148" title="Permanent link">&para;</a></h2>
<p>self : object
Instance of the estimator.</p>
<div class="highlight"><pre><span></span><code><span class="k">val</span> <span class="n">get_params</span> <span class="o">:</span> <span class="o">?</span><span class="n">deep</span><span class="o">:</span><span class="kt">bool</span> <span class="o">-&gt;</span> <span class="o">[&gt;</span> <span class="n">tag</span><span class="o">]</span> <span class="nn">Obj</span><span class="p">.</span><span class="n">t</span> <span class="o">-&gt;</span> <span class="nn">Dict</span><span class="p">.</span><span class="n">t</span>
</code></pre></div>

<p>Get parameters for this estimator.</p>
<h2 id="parameters_176">Parameters<a class="headerlink" href="#parameters_176" title="Permanent link">&para;</a></h2>
<p>deep : bool, default=True
If True, will return the parameters for this estimator and
contained subobjects that are estimators.</p>
<h2 id="returns_149">Returns<a class="headerlink" href="#returns_149" title="Permanent link">&para;</a></h2>
<p>params : mapping of string to any
Parameter names mapped to their values.</p>
<div class="highlight"><pre><span></span><code><span class="k">val</span> <span class="n">predict</span> <span class="o">:</span> <span class="n">x</span><span class="o">:[&gt;`</span><span class="nc">ArrayLike</span><span class="o">]</span> <span class="nn">Np</span><span class="p">.</span><span class="nn">Obj</span><span class="p">.</span><span class="n">t</span> <span class="o">-&gt;</span> <span class="o">[&gt;</span> <span class="n">tag</span><span class="o">]</span> <span class="nn">Obj</span><span class="p">.</span><span class="n">t</span> <span class="o">-&gt;</span> <span class="o">[&gt;`</span><span class="nc">ArrayLike</span><span class="o">]</span> <span class="nn">Np</span><span class="p">.</span><span class="nn">Obj</span><span class="p">.</span><span class="n">t</span>
</code></pre></div>

<p>Predict class labels for samples in X.</p>
<h2 id="parameters_177">Parameters<a class="headerlink" href="#parameters_177" title="Permanent link">&para;</a></h2>
<p>X : array_like or sparse matrix, shape (n_samples, n_features)
Samples.</p>
<h2 id="returns_150">Returns<a class="headerlink" href="#returns_150" title="Permanent link">&para;</a></h2>
<p>C : array, shape [n_samples]
Predicted class label per sample.</p>
<div class="highlight"><pre><span></span><code><span class="k">val</span> <span class="n">score</span> <span class="o">:</span> <span class="o">?</span><span class="n">sample_weight</span><span class="o">:[&gt;`</span><span class="nc">ArrayLike</span><span class="o">]</span> <span class="nn">Np</span><span class="p">.</span><span class="nn">Obj</span><span class="p">.</span><span class="n">t</span> <span class="o">-&gt;</span> <span class="n">x</span><span class="o">:[&gt;`</span><span class="nc">ArrayLike</span><span class="o">]</span> <span class="nn">Np</span><span class="p">.</span><span class="nn">Obj</span><span class="p">.</span><span class="n">t</span> <span class="o">-&gt;</span> <span class="n">y</span><span class="o">:[&gt;`</span><span class="nc">ArrayLike</span><span class="o">]</span> <span class="nn">Np</span><span class="p">.</span><span class="nn">Obj</span><span class="p">.</span><span class="n">t</span> <span class="o">-&gt;</span> <span class="o">[&gt;</span> <span class="n">tag</span><span class="o">]</span> <span class="nn">Obj</span><span class="p">.</span><span class="n">t</span> <span class="o">-&gt;</span> <span class="kt">float</span>
</code></pre></div>

<p>Return the mean accuracy on the given test data and labels.</p>
<p>In multi-label classification, this is the subset accuracy
which is a harsh metric since you require for each sample that
each label set be correctly predicted.</p>
<h2 id="parameters_178">Parameters<a class="headerlink" href="#parameters_178" title="Permanent link">&para;</a></h2>
<p>X : array-like of shape (n_samples, n_features)
Test samples.</p>
<p>y : array-like of shape (n_samples,) or (n_samples, n_outputs)
True labels for X.</p>
<p>sample_weight : array-like of shape (n_samples,), default=None
Sample weights.</p>
<h2 id="returns_151">Returns<a class="headerlink" href="#returns_151" title="Permanent link">&para;</a></h2>
<p>score : float
Mean accuracy of self.predict(X) wrt. y.</p>
<div class="highlight"><pre><span></span><code><span class="k">val</span> <span class="n">set_params</span> <span class="o">:</span> <span class="o">?</span><span class="n">params</span><span class="o">:(</span><span class="kt">string</span> <span class="o">*</span> <span class="nn">Py</span><span class="p">.</span><span class="nn">Object</span><span class="p">.</span><span class="n">t</span><span class="o">)</span> <span class="kt">list</span> <span class="o">-&gt;</span> <span class="o">[&gt;</span> <span class="n">tag</span><span class="o">]</span> <span class="nn">Obj</span><span class="p">.</span><span class="n">t</span> <span class="o">-&gt;</span> <span class="n">t</span>
</code></pre></div>

<p>Set the parameters of this estimator.</p>
<p>The method works on simple estimators as well as on nested objects
(such as pipelines). The latter have parameters of the form
<code>&lt;component&gt;__&lt;parameter&gt;</code> so that it's possible to update each
component of a nested object.</p>
<h2 id="parameters_179">Parameters<a class="headerlink" href="#parameters_179" title="Permanent link">&para;</a></h2>
<p>**params : dict
Estimator parameters.</p>
<h2 id="returns_152">Returns<a class="headerlink" href="#returns_152" title="Permanent link">&para;</a></h2>
<p>self : object
Estimator instance.</p>
<p>Attribute coef_: get value or raise Not_found if None.</p>
<div class="highlight"><pre><span></span><code><span class="k">val</span> <span class="n">coef_</span> <span class="o">:</span> <span class="n">t</span> <span class="o">-&gt;</span> <span class="o">[&gt;`</span><span class="nc">ArrayLike</span><span class="o">]</span> <span class="nn">Np</span><span class="p">.</span><span class="nn">Obj</span><span class="p">.</span><span class="n">t</span>
</code></pre></div>

<p>Attribute coef_: get value as an option.</p>
<div class="highlight"><pre><span></span><code><span class="k">val</span> <span class="n">coef_opt</span> <span class="o">:</span> <span class="n">t</span> <span class="o">-&gt;</span> <span class="o">([&gt;`</span><span class="nc">ArrayLike</span><span class="o">]</span> <span class="nn">Np</span><span class="p">.</span><span class="nn">Obj</span><span class="p">.</span><span class="n">t</span><span class="o">)</span> <span class="n">option</span>
</code></pre></div>

<p>Attribute intercept_: get value or raise Not_found if None.</p>
<div class="highlight"><pre><span></span><code><span class="k">val</span> <span class="n">intercept_</span> <span class="o">:</span> <span class="n">t</span> <span class="o">-&gt;</span> <span class="o">[&gt;`</span><span class="nc">ArrayLike</span><span class="o">]</span> <span class="nn">Np</span><span class="p">.</span><span class="nn">Obj</span><span class="p">.</span><span class="n">t</span>
</code></pre></div>

<p>Attribute intercept_: get value as an option.</p>
<div class="highlight"><pre><span></span><code><span class="k">val</span> <span class="n">intercept_opt</span> <span class="o">:</span> <span class="n">t</span> <span class="o">-&gt;</span> <span class="o">([&gt;`</span><span class="nc">ArrayLike</span><span class="o">]</span> <span class="nn">Np</span><span class="p">.</span><span class="nn">Obj</span><span class="p">.</span><span class="n">t</span><span class="o">)</span> <span class="n">option</span>
</code></pre></div>

<p>Attribute n_iter_: get value or raise Not_found if None.</p>
<div class="highlight"><pre><span></span><code><span class="k">val</span> <span class="n">n_iter_</span> <span class="o">:</span> <span class="n">t</span> <span class="o">-&gt;</span> <span class="o">[&gt;`</span><span class="nc">ArrayLike</span><span class="o">]</span> <span class="nn">Np</span><span class="p">.</span><span class="nn">Obj</span><span class="p">.</span><span class="n">t</span>
</code></pre></div>

<p>Attribute n_iter_: get value as an option.</p>
<div class="highlight"><pre><span></span><code><span class="k">val</span> <span class="n">n_iter_opt</span> <span class="o">:</span> <span class="n">t</span> <span class="o">-&gt;</span> <span class="o">([&gt;`</span><span class="nc">ArrayLike</span><span class="o">]</span> <span class="nn">Np</span><span class="p">.</span><span class="nn">Obj</span><span class="p">.</span><span class="n">t</span><span class="o">)</span> <span class="n">option</span>
</code></pre></div>

<p>Attribute classes_: get value or raise Not_found if None.</p>
<div class="highlight"><pre><span></span><code><span class="k">val</span> <span class="n">classes_</span> <span class="o">:</span> <span class="n">t</span> <span class="o">-&gt;</span> <span class="o">[&gt;`</span><span class="nc">ArrayLike</span><span class="o">]</span> <span class="nn">Np</span><span class="p">.</span><span class="nn">Obj</span><span class="p">.</span><span class="n">t</span>
</code></pre></div>

<p>Attribute classes_: get value as an option.</p>
<div class="highlight"><pre><span></span><code><span class="k">val</span> <span class="n">classes_opt</span> <span class="o">:</span> <span class="n">t</span> <span class="o">-&gt;</span> <span class="o">([&gt;`</span><span class="nc">ArrayLike</span><span class="o">]</span> <span class="nn">Np</span><span class="p">.</span><span class="nn">Obj</span><span class="p">.</span><span class="n">t</span><span class="o">)</span> <span class="n">option</span>
</code></pre></div>

<p>Print the object to a human-readable representation.</p>
<div class="highlight"><pre><span></span><code><span class="k">val</span> <span class="n">to_string</span> <span class="o">:</span> <span class="n">t</span> <span class="o">-&gt;</span> <span class="kt">string</span>
</code></pre></div>

<p>Print the object to a human-readable representation.</p>
<div class="highlight"><pre><span></span><code><span class="k">val</span> <span class="n">show</span> <span class="o">:</span> <span class="n">t</span> <span class="o">-&gt;</span> <span class="kt">string</span>
</code></pre></div>

<p>Pretty-print the object to a formatter.</p>
<div class="highlight"><pre><span></span><code><span class="k">val</span> <span class="n">pp</span> <span class="o">:</span> <span class="nn">Format</span><span class="p">.</span><span class="n">formatter</span> <span class="o">-&gt;</span> <span class="n">t</span> <span class="o">-&gt;</span> <span class="kt">unit</span> <span class="o">[@@</span><span class="n">ocaml</span><span class="o">.</span><span class="n">toplevel_printer</span><span class="o">]</span>



<span class="k">module</span> <span class="nc">RidgeClassifierCV</span> <span class="o">:</span> <span class="k">sig</span>
<span class="k">type</span> <span class="n">tag</span> <span class="o">=</span> <span class="o">[`</span><span class="nc">RidgeClassifierCV</span><span class="o">]</span>
<span class="k">type</span> <span class="n">t</span> <span class="o">=</span> <span class="o">[`</span><span class="nc">BaseEstimator</span> <span class="o">|</span> <span class="o">`</span><span class="nc">ClassifierMixin</span> <span class="o">|</span> <span class="o">`</span><span class="nc">LinearClassifierMixin</span> <span class="o">|</span> <span class="o">`</span><span class="nc">Object</span> <span class="o">|</span> <span class="o">`</span><span class="nc">RidgeClassifierCV</span><span class="o">]</span> <span class="nn">Obj</span><span class="p">.</span><span class="n">t</span>
<span class="k">val</span> <span class="n">of_pyobject</span> <span class="o">:</span> <span class="nn">Py</span><span class="p">.</span><span class="nn">Object</span><span class="p">.</span><span class="n">t</span> <span class="o">-&gt;</span> <span class="n">t</span>
<span class="k">val</span> <span class="n">to_pyobject</span> <span class="o">:</span> <span class="o">[&gt;</span> <span class="n">tag</span><span class="o">]</span> <span class="nn">Obj</span><span class="p">.</span><span class="n">t</span> <span class="o">-&gt;</span> <span class="nn">Py</span><span class="p">.</span><span class="nn">Object</span><span class="p">.</span><span class="n">t</span>

<span class="k">val</span> <span class="n">as_classifier</span> <span class="o">:</span> <span class="n">t</span> <span class="o">-&gt;</span> <span class="o">[`</span><span class="nc">ClassifierMixin</span><span class="o">]</span> <span class="nn">Obj</span><span class="p">.</span><span class="n">t</span>
<span class="k">val</span> <span class="n">as_linear_classifier</span> <span class="o">:</span> <span class="n">t</span> <span class="o">-&gt;</span> <span class="o">[`</span><span class="nc">LinearClassifierMixin</span><span class="o">]</span> <span class="nn">Obj</span><span class="p">.</span><span class="n">t</span>
<span class="k">val</span> <span class="n">as_estimator</span> <span class="o">:</span> <span class="n">t</span> <span class="o">-&gt;</span> <span class="o">[`</span><span class="nc">BaseEstimator</span><span class="o">]</span> <span class="nn">Obj</span><span class="p">.</span><span class="n">t</span>
<span class="k">val</span> <span class="n">create</span> <span class="o">:</span> <span class="o">?</span><span class="n">alphas</span><span class="o">:[&gt;`</span><span class="nc">ArrayLike</span><span class="o">]</span> <span class="nn">Np</span><span class="p">.</span><span class="nn">Obj</span><span class="p">.</span><span class="n">t</span> <span class="o">-&gt;</span> <span class="o">?</span><span class="n">fit_intercept</span><span class="o">:</span><span class="kt">bool</span> <span class="o">-&gt;</span> <span class="o">?</span><span class="n">normalize</span><span class="o">:</span><span class="kt">bool</span> <span class="o">-&gt;</span> <span class="o">?</span><span class="n">scoring</span><span class="o">:[`</span><span class="nc">Max_error</span> <span class="o">|</span> <span class="o">`</span><span class="nc">Mutual_info_score</span> <span class="o">|</span> <span class="o">`</span><span class="nc">Homogeneity_score</span> <span class="o">|</span> <span class="o">`</span><span class="nc">Roc_auc</span> <span class="o">|</span> <span class="o">`</span><span class="nc">Neg_mean_squared_error</span> <span class="o">|</span> <span class="o">`</span><span class="nc">Recall_micro</span> <span class="o">|</span> <span class="o">`</span><span class="nc">Neg_mean_poisson_deviance</span> <span class="o">|</span> <span class="o">`</span><span class="nc">Neg_log_loss</span> <span class="o">|</span> <span class="o">`</span><span class="nc">F1_macro</span> <span class="o">|</span> <span class="o">`</span><span class="nc">Neg_mean_gamma_deviance</span> <span class="o">|</span> <span class="o">`</span><span class="nc">Neg_median_absolute_error</span> <span class="o">|</span> <span class="o">`</span><span class="nc">Callable</span> <span class="k">of</span> <span class="nn">Py</span><span class="p">.</span><span class="nn">Object</span><span class="p">.</span><span class="n">t</span> <span class="o">|</span> <span class="o">`</span><span class="nc">Neg_brier_score</span> <span class="o">|</span> <span class="o">`</span><span class="nc">Neg_mean_squared_log_error</span> <span class="o">|</span> <span class="o">`</span><span class="nc">Recall_macro</span> <span class="o">|</span> <span class="o">`</span><span class="nc">Explained_variance</span> <span class="o">|</span> <span class="o">`</span><span class="nc">Roc_auc_ovr_weighted</span> <span class="o">|</span> <span class="o">`</span><span class="nc">Adjusted_rand_score</span> <span class="o">|</span> <span class="o">`</span><span class="nc">Precision_macro</span> <span class="o">|</span> <span class="o">`</span><span class="nc">Jaccard_samples</span> <span class="o">|</span> <span class="o">`</span><span class="nc">Roc_auc_ovo_weighted</span> <span class="o">|</span> <span class="o">`</span><span class="nc">Jaccard_macro</span> <span class="o">|</span> <span class="o">`</span><span class="nc">Precision</span> <span class="o">|</span> <span class="o">`</span><span class="nc">Balanced_accuracy</span> <span class="o">|</span> <span class="o">`</span><span class="nc">Precision_micro</span> <span class="o">|</span> <span class="o">`</span><span class="nc">Precision_weighted</span> <span class="o">|</span> <span class="o">`</span><span class="nc">V_measure_score</span> <span class="o">|</span> <span class="o">`</span><span class="nc">Normalized_mutual_info_score</span> <span class="o">|</span> <span class="o">`</span><span class="nc">F1_weighted</span> <span class="o">|</span> <span class="o">`</span><span class="nc">Neg_root_mean_squared_error</span> <span class="o">|</span> <span class="o">`</span><span class="nc">Neg_mean_absolute_error</span> <span class="o">|</span> <span class="o">`</span><span class="nc">F1</span> <span class="o">|</span> <span class="o">`</span><span class="nc">Roc_auc_ovo</span> <span class="o">|</span> <span class="o">`</span><span class="nc">Jaccard_micro</span> <span class="o">|</span> <span class="o">`</span><span class="nc">Average_precision</span> <span class="o">|</span> <span class="o">`</span><span class="nc">Adjusted_mutual_info_score</span> <span class="o">|</span> <span class="o">`</span><span class="nc">R2</span> <span class="o">|</span> <span class="o">`</span><span class="nc">F1_samples</span> <span class="o">|</span> <span class="o">`</span><span class="nc">Fowlkes_mallows_score</span> <span class="o">|</span> <span class="o">`</span><span class="nc">Accuracy</span> <span class="o">|</span> <span class="o">`</span><span class="nc">Recall_weighted</span> <span class="o">|</span> <span class="o">`</span><span class="nc">Jaccard_weighted</span> <span class="o">|</span> <span class="o">`</span><span class="nc">Roc_auc_ovr</span> <span class="o">|</span> <span class="o">`</span><span class="nc">F1_micro</span> <span class="o">|</span> <span class="o">`</span><span class="nc">Precision_samples</span> <span class="o">|</span> <span class="o">`</span><span class="nc">Jaccard</span> <span class="o">|</span> <span class="o">`</span><span class="nc">Completeness_score</span> <span class="o">|</span> <span class="o">`</span><span class="nc">Recall_samples</span> <span class="o">|</span> <span class="o">`</span><span class="nc">Recall</span><span class="o">]</span> <span class="o">-&gt;</span> <span class="o">?</span><span class="n">cv</span><span class="o">:[`</span><span class="nc">Arr</span> <span class="k">of</span> <span class="o">[&gt;`</span><span class="nc">ArrayLike</span><span class="o">]</span> <span class="nn">Np</span><span class="p">.</span><span class="nn">Obj</span><span class="p">.</span><span class="n">t</span> <span class="o">|</span> <span class="o">`</span><span class="nc">BaseCrossValidator</span> <span class="k">of</span> <span class="o">[&gt;`</span><span class="nc">BaseCrossValidator</span><span class="o">]</span> <span class="nn">Np</span><span class="p">.</span><span class="nn">Obj</span><span class="p">.</span><span class="n">t</span> <span class="o">|</span> <span class="o">`</span><span class="nc">I</span> <span class="k">of</span> <span class="kt">int</span><span class="o">]</span> <span class="o">-&gt;</span> <span class="o">?</span><span class="n">class_weight</span><span class="o">:[`</span><span class="nc">DictIntToFloat</span> <span class="k">of</span> <span class="o">(</span><span class="kt">int</span> <span class="o">*</span> <span class="kt">float</span><span class="o">)</span> <span class="kt">list</span> <span class="o">|</span> <span class="o">`</span><span class="nc">Balanced</span><span class="o">]</span> <span class="o">-&gt;</span> <span class="o">?</span><span class="n">store_cv_values</span><span class="o">:</span><span class="kt">bool</span> <span class="o">-&gt;</span> <span class="kt">unit</span> <span class="o">-&gt;</span> <span class="n">t</span>
</code></pre></div>

<p>Ridge classifier with built-in cross-validation.</p>
<p>See glossary entry for :term:<code>cross-validation estimator</code>.</p>
<p>By default, it performs Generalized Cross-Validation, which is a form of
efficient Leave-One-Out cross-validation. Currently, only the n_features &gt;
n_samples case is handled efficiently.</p>
<p>Read more in the :ref:<code>User Guide &lt;ridge_regression&gt;</code>.</p>
<h2 id="parameters_180">Parameters<a class="headerlink" href="#parameters_180" title="Permanent link">&para;</a></h2>
<p>alphas : ndarray of shape (n_alphas,), default=(0.1, 1.0, 10.0)
Array of alpha values to try.
Regularization strength; must be a positive float. Regularization
improves the conditioning of the problem and reduces the variance of
the estimates. Larger values specify stronger regularization.
Alpha corresponds to <code>C^-1</code> in other linear models such as
LogisticRegression or LinearSVC.</p>
<p>fit_intercept : bool, default=True
Whether to calculate the intercept for this model. If set
to false, no intercept will be used in calculations
(i.e. data is expected to be centered).</p>
<p>normalize : bool, default=False
This parameter is ignored when <code>fit_intercept</code> is set to False.
If True, the regressors X will be normalized before regression by
subtracting the mean and dividing by the l2-norm.
If you wish to standardize, please use
:class:<code>sklearn.preprocessing.StandardScaler</code> before calling <code>fit</code>
on an estimator with <code>normalize=False</code>.</p>
<p>scoring : string, callable, default=None
A string (see model evaluation documentation) or
a scorer callable object / function with signature
<code>scorer(estimator, X, y)</code>.</p>
<p>cv : int, cross-validation generator or an iterable, default=None
Determines the cross-validation splitting strategy.
Possible inputs for cv are:</p>
<ul>
<li>None, to use the efficient Leave-One-Out cross-validation</li>
<li>integer, to specify the number of folds.</li>
<li>:term:<code>CV splitter</code>,</li>
<li>An iterable yielding (train, test) splits as arrays of indices.</li>
</ul>
<p>Refer :ref:<code>User Guide &lt;cross_validation&gt;</code> for the various
cross-validation strategies that can be used here.</p>
<p>class_weight : dict or 'balanced', default=None
Weights associated with classes in the form <code>{class_label: weight}</code>.
If not given, all classes are supposed to have weight one.</p>
<p>The 'balanced' mode uses the values of y to automatically adjust
weights inversely proportional to class frequencies in the input data
as <code>n_samples / (n_classes * np.bincount(y))</code></p>
<p>store_cv_values : bool, default=False
Flag indicating if the cross-validation values corresponding to
each alpha should be stored in the <code>cv_values_</code> attribute (see
below). This flag is only compatible with <code>cv=None</code> (i.e. using
Generalized Cross-Validation).</p>
<h2 id="attributes_28">Attributes<a class="headerlink" href="#attributes_28" title="Permanent link">&para;</a></h2>
<p>cv_values_ : ndarray of shape (n_samples, n_targets, n_alphas), optional
Cross-validation values for each alpha (if <code>store_cv_values=True</code> and
<code>cv=None</code>). After <code>fit()</code> has been called, this attribute will
contain the mean squared errors (by default) or the values of the
<code>{loss,score}_func</code> function (if provided in the constructor). This
attribute exists only when <code>store_cv_values</code> is True.</p>
<p>coef_ : ndarray of shape (1, n_features) or (n_targets, n_features)
Coefficient of the features in the decision function.</p>
<p><code>coef_</code> is of shape (1, n_features) when the given problem is binary.</p>
<p>intercept_ : float or ndarray of shape (n_targets,)
Independent term in decision function. Set to 0.0 if
<code>fit_intercept = False</code>.</p>
<p>alpha_ : float
Estimated regularization parameter</p>
<p>classes_ : ndarray of shape (n_classes,)
The classes labels.</p>
<h2 id="examples_28">Examples<a class="headerlink" href="#examples_28" title="Permanent link">&para;</a></h2>
<blockquote>
<blockquote>
<blockquote>
<p>from sklearn.datasets import load_breast_cancer
from sklearn.linear_model import RidgeClassifierCV
X, y = load_breast_cancer(return_X_y=True)
clf = RidgeClassifierCV(alphas=[1e-3, 1e-2, 1e-1, 1]).fit(X, y)
clf.score(X, y)
0.9630...</p>
</blockquote>
</blockquote>
</blockquote>
<h2 id="see-also_24">See also<a class="headerlink" href="#see-also_24" title="Permanent link">&para;</a></h2>
<p>Ridge : Ridge regression
RidgeClassifier : Ridge classifier
RidgeCV : Ridge regression with built-in cross validation</p>
<h2 id="notes_50">Notes<a class="headerlink" href="#notes_50" title="Permanent link">&para;</a></h2>
<p>For multi-class classification, n_class classifiers are trained in
a one-versus-all approach. Concretely, this is implemented by taking
advantage of the multi-variate response support in Ridge.</p>
<div class="highlight"><pre><span></span><code><span class="k">val</span> <span class="n">decision_function</span> <span class="o">:</span> <span class="n">x</span><span class="o">:[&gt;`</span><span class="nc">ArrayLike</span><span class="o">]</span> <span class="nn">Np</span><span class="p">.</span><span class="nn">Obj</span><span class="p">.</span><span class="n">t</span> <span class="o">-&gt;</span> <span class="o">[&gt;</span> <span class="n">tag</span><span class="o">]</span> <span class="nn">Obj</span><span class="p">.</span><span class="n">t</span> <span class="o">-&gt;</span> <span class="o">[&gt;`</span><span class="nc">ArrayLike</span><span class="o">]</span> <span class="nn">Np</span><span class="p">.</span><span class="nn">Obj</span><span class="p">.</span><span class="n">t</span>
</code></pre></div>

<p>Predict confidence scores for samples.</p>
<p>The confidence score for a sample is the signed distance of that
sample to the hyperplane.</p>
<h2 id="parameters_181">Parameters<a class="headerlink" href="#parameters_181" title="Permanent link">&para;</a></h2>
<p>X : array_like or sparse matrix, shape (n_samples, n_features)
Samples.</p>
<h2 id="returns_153">Returns<a class="headerlink" href="#returns_153" title="Permanent link">&para;</a></h2>
<p>array, shape=(n_samples,) if n_classes == 2 else (n_samples, n_classes)
Confidence scores per (sample, class) combination. In the binary
case, confidence score for self.classes_[1] where &gt;0 means this
class would be predicted.</p>
<div class="highlight"><pre><span></span><code><span class="k">val</span> <span class="n">fit</span> <span class="o">:</span> <span class="o">?</span><span class="n">sample_weight</span><span class="o">:[&gt;`</span><span class="nc">ArrayLike</span><span class="o">]</span> <span class="nn">Np</span><span class="p">.</span><span class="nn">Obj</span><span class="p">.</span><span class="n">t</span> <span class="o">-&gt;</span> <span class="n">x</span><span class="o">:[&gt;`</span><span class="nc">ArrayLike</span><span class="o">]</span> <span class="nn">Np</span><span class="p">.</span><span class="nn">Obj</span><span class="p">.</span><span class="n">t</span> <span class="o">-&gt;</span> <span class="n">y</span><span class="o">:[&gt;`</span><span class="nc">ArrayLike</span><span class="o">]</span> <span class="nn">Np</span><span class="p">.</span><span class="nn">Obj</span><span class="p">.</span><span class="n">t</span> <span class="o">-&gt;</span> <span class="o">[&gt;</span> <span class="n">tag</span><span class="o">]</span> <span class="nn">Obj</span><span class="p">.</span><span class="n">t</span> <span class="o">-&gt;</span> <span class="n">t</span>
</code></pre></div>

<p>Fit Ridge classifier with cv.</p>
<h2 id="parameters_182">Parameters<a class="headerlink" href="#parameters_182" title="Permanent link">&para;</a></h2>
<p>X : ndarray of shape (n_samples, n_features)
Training vectors, where n_samples is the number of samples
and n_features is the number of features. When using GCV,
will be cast to float64 if necessary.</p>
<p>y : ndarray of shape (n_samples,)
Target values. Will be cast to X's dtype if necessary.</p>
<p>sample_weight : float or ndarray of shape (n_samples,), default=None
Individual weights for each sample. If given a float, every sample
will have the same weight.</p>
<h2 id="returns_154">Returns<a class="headerlink" href="#returns_154" title="Permanent link">&para;</a></h2>
<p>self : object</p>
<div class="highlight"><pre><span></span><code><span class="k">val</span> <span class="n">get_params</span> <span class="o">:</span> <span class="o">?</span><span class="n">deep</span><span class="o">:</span><span class="kt">bool</span> <span class="o">-&gt;</span> <span class="o">[&gt;</span> <span class="n">tag</span><span class="o">]</span> <span class="nn">Obj</span><span class="p">.</span><span class="n">t</span> <span class="o">-&gt;</span> <span class="nn">Dict</span><span class="p">.</span><span class="n">t</span>
</code></pre></div>

<p>Get parameters for this estimator.</p>
<h2 id="parameters_183">Parameters<a class="headerlink" href="#parameters_183" title="Permanent link">&para;</a></h2>
<p>deep : bool, default=True
If True, will return the parameters for this estimator and
contained subobjects that are estimators.</p>
<h2 id="returns_155">Returns<a class="headerlink" href="#returns_155" title="Permanent link">&para;</a></h2>
<p>params : mapping of string to any
Parameter names mapped to their values.</p>
<div class="highlight"><pre><span></span><code><span class="k">val</span> <span class="n">predict</span> <span class="o">:</span> <span class="n">x</span><span class="o">:[&gt;`</span><span class="nc">ArrayLike</span><span class="o">]</span> <span class="nn">Np</span><span class="p">.</span><span class="nn">Obj</span><span class="p">.</span><span class="n">t</span> <span class="o">-&gt;</span> <span class="o">[&gt;</span> <span class="n">tag</span><span class="o">]</span> <span class="nn">Obj</span><span class="p">.</span><span class="n">t</span> <span class="o">-&gt;</span> <span class="o">[&gt;`</span><span class="nc">ArrayLike</span><span class="o">]</span> <span class="nn">Np</span><span class="p">.</span><span class="nn">Obj</span><span class="p">.</span><span class="n">t</span>
</code></pre></div>

<p>Predict class labels for samples in X.</p>
<h2 id="parameters_184">Parameters<a class="headerlink" href="#parameters_184" title="Permanent link">&para;</a></h2>
<p>X : array_like or sparse matrix, shape (n_samples, n_features)
Samples.</p>
<h2 id="returns_156">Returns<a class="headerlink" href="#returns_156" title="Permanent link">&para;</a></h2>
<p>C : array, shape [n_samples]
Predicted class label per sample.</p>
<div class="highlight"><pre><span></span><code><span class="k">val</span> <span class="n">score</span> <span class="o">:</span> <span class="o">?</span><span class="n">sample_weight</span><span class="o">:[&gt;`</span><span class="nc">ArrayLike</span><span class="o">]</span> <span class="nn">Np</span><span class="p">.</span><span class="nn">Obj</span><span class="p">.</span><span class="n">t</span> <span class="o">-&gt;</span> <span class="n">x</span><span class="o">:[&gt;`</span><span class="nc">ArrayLike</span><span class="o">]</span> <span class="nn">Np</span><span class="p">.</span><span class="nn">Obj</span><span class="p">.</span><span class="n">t</span> <span class="o">-&gt;</span> <span class="n">y</span><span class="o">:[&gt;`</span><span class="nc">ArrayLike</span><span class="o">]</span> <span class="nn">Np</span><span class="p">.</span><span class="nn">Obj</span><span class="p">.</span><span class="n">t</span> <span class="o">-&gt;</span> <span class="o">[&gt;</span> <span class="n">tag</span><span class="o">]</span> <span class="nn">Obj</span><span class="p">.</span><span class="n">t</span> <span class="o">-&gt;</span> <span class="kt">float</span>
</code></pre></div>

<p>Return the mean accuracy on the given test data and labels.</p>
<p>In multi-label classification, this is the subset accuracy
which is a harsh metric since you require for each sample that
each label set be correctly predicted.</p>
<h2 id="parameters_185">Parameters<a class="headerlink" href="#parameters_185" title="Permanent link">&para;</a></h2>
<p>X : array-like of shape (n_samples, n_features)
Test samples.</p>
<p>y : array-like of shape (n_samples,) or (n_samples, n_outputs)
True labels for X.</p>
<p>sample_weight : array-like of shape (n_samples,), default=None
Sample weights.</p>
<h2 id="returns_157">Returns<a class="headerlink" href="#returns_157" title="Permanent link">&para;</a></h2>
<p>score : float
Mean accuracy of self.predict(X) wrt. y.</p>
<div class="highlight"><pre><span></span><code><span class="k">val</span> <span class="n">set_params</span> <span class="o">:</span> <span class="o">?</span><span class="n">params</span><span class="o">:(</span><span class="kt">string</span> <span class="o">*</span> <span class="nn">Py</span><span class="p">.</span><span class="nn">Object</span><span class="p">.</span><span class="n">t</span><span class="o">)</span> <span class="kt">list</span> <span class="o">-&gt;</span> <span class="o">[&gt;</span> <span class="n">tag</span><span class="o">]</span> <span class="nn">Obj</span><span class="p">.</span><span class="n">t</span> <span class="o">-&gt;</span> <span class="n">t</span>
</code></pre></div>

<p>Set the parameters of this estimator.</p>
<p>The method works on simple estimators as well as on nested objects
(such as pipelines). The latter have parameters of the form
<code>&lt;component&gt;__&lt;parameter&gt;</code> so that it's possible to update each
component of a nested object.</p>
<h2 id="parameters_186">Parameters<a class="headerlink" href="#parameters_186" title="Permanent link">&para;</a></h2>
<p>**params : dict
Estimator parameters.</p>
<h2 id="returns_158">Returns<a class="headerlink" href="#returns_158" title="Permanent link">&para;</a></h2>
<p>self : object
Estimator instance.</p>
<p>Attribute cv_values_: get value or raise Not_found if None.</p>
<div class="highlight"><pre><span></span><code><span class="k">val</span> <span class="n">cv_values_</span> <span class="o">:</span> <span class="n">t</span> <span class="o">-&gt;</span> <span class="o">[&gt;`</span><span class="nc">ArrayLike</span><span class="o">]</span> <span class="nn">Np</span><span class="p">.</span><span class="nn">Obj</span><span class="p">.</span><span class="n">t</span>
</code></pre></div>

<p>Attribute cv_values_: get value as an option.</p>
<div class="highlight"><pre><span></span><code><span class="k">val</span> <span class="n">cv_values_opt</span> <span class="o">:</span> <span class="n">t</span> <span class="o">-&gt;</span> <span class="o">([&gt;`</span><span class="nc">ArrayLike</span><span class="o">]</span> <span class="nn">Np</span><span class="p">.</span><span class="nn">Obj</span><span class="p">.</span><span class="n">t</span><span class="o">)</span> <span class="n">option</span>
</code></pre></div>

<p>Attribute coef_: get value or raise Not_found if None.</p>
<div class="highlight"><pre><span></span><code><span class="k">val</span> <span class="n">coef_</span> <span class="o">:</span> <span class="n">t</span> <span class="o">-&gt;</span> <span class="o">[&gt;`</span><span class="nc">ArrayLike</span><span class="o">]</span> <span class="nn">Np</span><span class="p">.</span><span class="nn">Obj</span><span class="p">.</span><span class="n">t</span>
</code></pre></div>

<p>Attribute coef_: get value as an option.</p>
<div class="highlight"><pre><span></span><code><span class="k">val</span> <span class="n">coef_opt</span> <span class="o">:</span> <span class="n">t</span> <span class="o">-&gt;</span> <span class="o">([&gt;`</span><span class="nc">ArrayLike</span><span class="o">]</span> <span class="nn">Np</span><span class="p">.</span><span class="nn">Obj</span><span class="p">.</span><span class="n">t</span><span class="o">)</span> <span class="n">option</span>
</code></pre></div>

<p>Attribute intercept_: get value or raise Not_found if None.</p>
<div class="highlight"><pre><span></span><code><span class="k">val</span> <span class="n">intercept_</span> <span class="o">:</span> <span class="n">t</span> <span class="o">-&gt;</span> <span class="o">[&gt;`</span><span class="nc">ArrayLike</span><span class="o">]</span> <span class="nn">Np</span><span class="p">.</span><span class="nn">Obj</span><span class="p">.</span><span class="n">t</span>
</code></pre></div>

<p>Attribute intercept_: get value as an option.</p>
<div class="highlight"><pre><span></span><code><span class="k">val</span> <span class="n">intercept_opt</span> <span class="o">:</span> <span class="n">t</span> <span class="o">-&gt;</span> <span class="o">([&gt;`</span><span class="nc">ArrayLike</span><span class="o">]</span> <span class="nn">Np</span><span class="p">.</span><span class="nn">Obj</span><span class="p">.</span><span class="n">t</span><span class="o">)</span> <span class="n">option</span>
</code></pre></div>

<p>Attribute alpha_: get value or raise Not_found if None.</p>
<div class="highlight"><pre><span></span><code><span class="k">val</span> <span class="n">alpha_</span> <span class="o">:</span> <span class="n">t</span> <span class="o">-&gt;</span> <span class="kt">float</span>
</code></pre></div>

<p>Attribute alpha_: get value as an option.</p>
<div class="highlight"><pre><span></span><code><span class="k">val</span> <span class="n">alpha_opt</span> <span class="o">:</span> <span class="n">t</span> <span class="o">-&gt;</span> <span class="o">(</span><span class="kt">float</span><span class="o">)</span> <span class="n">option</span>
</code></pre></div>

<p>Attribute classes_: get value or raise Not_found if None.</p>
<div class="highlight"><pre><span></span><code><span class="k">val</span> <span class="n">classes_</span> <span class="o">:</span> <span class="n">t</span> <span class="o">-&gt;</span> <span class="o">[&gt;`</span><span class="nc">ArrayLike</span><span class="o">]</span> <span class="nn">Np</span><span class="p">.</span><span class="nn">Obj</span><span class="p">.</span><span class="n">t</span>
</code></pre></div>

<p>Attribute classes_: get value as an option.</p>
<div class="highlight"><pre><span></span><code><span class="k">val</span> <span class="n">classes_opt</span> <span class="o">:</span> <span class="n">t</span> <span class="o">-&gt;</span> <span class="o">([&gt;`</span><span class="nc">ArrayLike</span><span class="o">]</span> <span class="nn">Np</span><span class="p">.</span><span class="nn">Obj</span><span class="p">.</span><span class="n">t</span><span class="o">)</span> <span class="n">option</span>
</code></pre></div>

<p>Print the object to a human-readable representation.</p>
<div class="highlight"><pre><span></span><code><span class="k">val</span> <span class="n">to_string</span> <span class="o">:</span> <span class="n">t</span> <span class="o">-&gt;</span> <span class="kt">string</span>
</code></pre></div>

<p>Print the object to a human-readable representation.</p>
<div class="highlight"><pre><span></span><code><span class="k">val</span> <span class="n">show</span> <span class="o">:</span> <span class="n">t</span> <span class="o">-&gt;</span> <span class="kt">string</span>
</code></pre></div>

<p>Pretty-print the object to a formatter.</p>
<div class="highlight"><pre><span></span><code><span class="k">val</span> <span class="n">pp</span> <span class="o">:</span> <span class="nn">Format</span><span class="p">.</span><span class="n">formatter</span> <span class="o">-&gt;</span> <span class="n">t</span> <span class="o">-&gt;</span> <span class="kt">unit</span> <span class="o">[@@</span><span class="n">ocaml</span><span class="o">.</span><span class="n">toplevel_printer</span><span class="o">]</span>



<span class="k">module</span> <span class="nc">SGDClassifier</span> <span class="o">:</span> <span class="k">sig</span>
<span class="k">type</span> <span class="n">tag</span> <span class="o">=</span> <span class="o">[`</span><span class="nc">SGDClassifier</span><span class="o">]</span>
<span class="k">type</span> <span class="n">t</span> <span class="o">=</span> <span class="o">[`</span><span class="nc">BaseEstimator</span> <span class="o">|</span> <span class="o">`</span><span class="nc">BaseSGD</span> <span class="o">|</span> <span class="o">`</span><span class="nc">BaseSGDClassifier</span> <span class="o">|</span> <span class="o">`</span><span class="nc">ClassifierMixin</span> <span class="o">|</span> <span class="o">`</span><span class="nc">LinearClassifierMixin</span> <span class="o">|</span> <span class="o">`</span><span class="nc">Object</span> <span class="o">|</span> <span class="o">`</span><span class="nc">SGDClassifier</span> <span class="o">|</span> <span class="o">`</span><span class="nc">SparseCoefMixin</span><span class="o">]</span> <span class="nn">Obj</span><span class="p">.</span><span class="n">t</span>
<span class="k">val</span> <span class="n">of_pyobject</span> <span class="o">:</span> <span class="nn">Py</span><span class="p">.</span><span class="nn">Object</span><span class="p">.</span><span class="n">t</span> <span class="o">-&gt;</span> <span class="n">t</span>
<span class="k">val</span> <span class="n">to_pyobject</span> <span class="o">:</span> <span class="o">[&gt;</span> <span class="n">tag</span><span class="o">]</span> <span class="nn">Obj</span><span class="p">.</span><span class="n">t</span> <span class="o">-&gt;</span> <span class="nn">Py</span><span class="p">.</span><span class="nn">Object</span><span class="p">.</span><span class="n">t</span>

<span class="k">val</span> <span class="n">as_linear_classifier</span> <span class="o">:</span> <span class="n">t</span> <span class="o">-&gt;</span> <span class="o">[`</span><span class="nc">LinearClassifierMixin</span><span class="o">]</span> <span class="nn">Obj</span><span class="p">.</span><span class="n">t</span>
<span class="k">val</span> <span class="n">as_sgd_classifier</span> <span class="o">:</span> <span class="n">t</span> <span class="o">-&gt;</span> <span class="o">[`</span><span class="nc">BaseSGDClassifier</span><span class="o">]</span> <span class="nn">Obj</span><span class="p">.</span><span class="n">t</span>
<span class="k">val</span> <span class="n">as_classifier</span> <span class="o">:</span> <span class="n">t</span> <span class="o">-&gt;</span> <span class="o">[`</span><span class="nc">ClassifierMixin</span><span class="o">]</span> <span class="nn">Obj</span><span class="p">.</span><span class="n">t</span>
<span class="k">val</span> <span class="n">as_estimator</span> <span class="o">:</span> <span class="n">t</span> <span class="o">-&gt;</span> <span class="o">[`</span><span class="nc">BaseEstimator</span><span class="o">]</span> <span class="nn">Obj</span><span class="p">.</span><span class="n">t</span>
<span class="k">val</span> <span class="n">as_sparse_coef</span> <span class="o">:</span> <span class="n">t</span> <span class="o">-&gt;</span> <span class="o">[`</span><span class="nc">SparseCoefMixin</span><span class="o">]</span> <span class="nn">Obj</span><span class="p">.</span><span class="n">t</span>
<span class="k">val</span> <span class="n">as_sgd</span> <span class="o">:</span> <span class="n">t</span> <span class="o">-&gt;</span> <span class="o">[`</span><span class="nc">BaseSGD</span><span class="o">]</span> <span class="nn">Obj</span><span class="p">.</span><span class="n">t</span>
<span class="k">val</span> <span class="n">create</span> <span class="o">:</span> <span class="o">?</span><span class="n">loss</span><span class="o">:</span><span class="kt">string</span> <span class="o">-&gt;</span> <span class="o">?</span><span class="n">penalty</span><span class="o">:[`</span><span class="nc">L2</span> <span class="o">|</span> <span class="o">`</span><span class="nc">L1</span> <span class="o">|</span> <span class="o">`</span><span class="nc">Elasticnet</span><span class="o">]</span> <span class="o">-&gt;</span> <span class="o">?</span><span class="n">alpha</span><span class="o">:</span><span class="kt">float</span> <span class="o">-&gt;</span> <span class="o">?</span><span class="n">l1_ratio</span><span class="o">:</span><span class="kt">float</span> <span class="o">-&gt;</span> <span class="o">?</span><span class="n">fit_intercept</span><span class="o">:</span><span class="kt">bool</span> <span class="o">-&gt;</span> <span class="o">?</span><span class="n">max_iter</span><span class="o">:</span><span class="kt">int</span> <span class="o">-&gt;</span> <span class="o">?</span><span class="n">tol</span><span class="o">:</span><span class="kt">float</span> <span class="o">-&gt;</span> <span class="o">?</span><span class="n">shuffle</span><span class="o">:</span><span class="kt">bool</span> <span class="o">-&gt;</span> <span class="o">?</span><span class="n">verbose</span><span class="o">:</span><span class="kt">int</span> <span class="o">-&gt;</span> <span class="o">?</span><span class="n">epsilon</span><span class="o">:</span><span class="kt">float</span> <span class="o">-&gt;</span> <span class="o">?</span><span class="n">n_jobs</span><span class="o">:</span><span class="kt">int</span> <span class="o">-&gt;</span> <span class="o">?</span><span class="n">random_state</span><span class="o">:</span><span class="kt">int</span> <span class="o">-&gt;</span> <span class="o">?</span><span class="n">learning_rate</span><span class="o">:</span><span class="kt">string</span> <span class="o">-&gt;</span> <span class="o">?</span><span class="n">eta0</span><span class="o">:</span><span class="kt">float</span> <span class="o">-&gt;</span> <span class="o">?</span><span class="n">power_t</span><span class="o">:</span><span class="kt">float</span> <span class="o">-&gt;</span> <span class="o">?</span><span class="n">early_stopping</span><span class="o">:</span><span class="kt">bool</span> <span class="o">-&gt;</span> <span class="o">?</span><span class="n">validation_fraction</span><span class="o">:</span><span class="kt">float</span> <span class="o">-&gt;</span> <span class="o">?</span><span class="n">n_iter_no_change</span><span class="o">:</span><span class="kt">int</span> <span class="o">-&gt;</span> <span class="o">?</span><span class="n">class_weight</span><span class="o">:[`</span><span class="nc">T_class_label_weight_</span> <span class="k">of</span> <span class="nn">Py</span><span class="p">.</span><span class="nn">Object</span><span class="p">.</span><span class="n">t</span> <span class="o">|</span> <span class="o">`</span><span class="nc">DictIntToFloat</span> <span class="k">of</span> <span class="o">(</span><span class="kt">int</span> <span class="o">*</span> <span class="kt">float</span><span class="o">)</span> <span class="kt">list</span> <span class="o">|</span> <span class="o">`</span><span class="nc">Balanced</span><span class="o">]</span> <span class="o">-&gt;</span> <span class="o">?</span><span class="n">warm_start</span><span class="o">:</span><span class="kt">bool</span> <span class="o">-&gt;</span> <span class="o">?</span><span class="n">average</span><span class="o">:[`</span><span class="nc">I</span> <span class="k">of</span> <span class="kt">int</span> <span class="o">|</span> <span class="o">`</span><span class="nc">Bool</span> <span class="k">of</span> <span class="kt">bool</span><span class="o">]</span> <span class="o">-&gt;</span> <span class="kt">unit</span> <span class="o">-&gt;</span> <span class="n">t</span>
</code></pre></div>

<p>Linear classifiers (SVM, logistic regression, a.o.) with SGD training.</p>
<p>This estimator implements regularized linear models with stochastic
gradient descent (SGD) learning: the gradient of the loss is estimated
each sample at a time and the model is updated along the way with a
decreasing strength schedule (aka learning rate). SGD allows minibatch
(online/out-of-core) learning, see the partial_fit method.
For best results using the default learning rate schedule, the data should
have zero mean and unit variance.</p>
<p>This implementation works with data represented as dense or sparse arrays
of floating point values for the features. The model it fits can be
controlled with the loss parameter; by default, it fits a linear support
vector machine (SVM).</p>
<p>The regularizer is a penalty added to the loss function that shrinks model
parameters towards the zero vector using either the squared euclidean norm
L2 or the absolute norm L1 or a combination of both (Elastic Net). If the
parameter update crosses the 0.0 value because of the regularizer, the
update is truncated to 0.0 to allow for learning sparse models and achieve
online feature selection.</p>
<p>Read more in the :ref:<code>User Guide &lt;sgd&gt;</code>.</p>
<h2 id="parameters_187">Parameters<a class="headerlink" href="#parameters_187" title="Permanent link">&para;</a></h2>
<p>loss : str, default='hinge'
The loss function to be used. Defaults to 'hinge', which gives a
linear SVM.</p>
<p>The possible options are 'hinge', 'log', 'modified_huber',
'squared_hinge', 'perceptron', or a regression loss: 'squared_loss',
'huber', 'epsilon_insensitive', or 'squared_epsilon_insensitive'.</p>
<p>The 'log' loss gives logistic regression, a probabilistic classifier.
'modified_huber' is another smooth loss that brings tolerance to
outliers as well as probability estimates.
'squared_hinge' is like hinge but is quadratically penalized.
'perceptron' is the linear loss used by the perceptron algorithm.
The other losses are designed for regression but can be useful in
classification as well; see SGDRegressor for a description.</p>
<p>penalty : {'l2', 'l1', 'elasticnet'}, default='l2'
The penalty (aka regularization term) to be used. Defaults to 'l2'
which is the standard regularizer for linear SVM models. 'l1' and
'elasticnet' might bring sparsity to the model (feature selection)
not achievable with 'l2'.</p>
<p>alpha : float, default=0.0001
Constant that multiplies the regularization term. Defaults to 0.0001.
Also used to compute learning_rate when set to 'optimal'.</p>
<p>l1_ratio : float, default=0.15
The Elastic Net mixing parameter, with 0 &lt;= l1_ratio &lt;= 1.
l1_ratio=0 corresponds to L2 penalty, l1_ratio=1 to L1.
Defaults to 0.15.</p>
<p>fit_intercept : bool, default=True
Whether the intercept should be estimated or not. If False, the
data is assumed to be already centered. Defaults to True.</p>
<p>max_iter : int, default=1000
The maximum number of passes over the training data (aka epochs).
It only impacts the behavior in the <code>fit</code> method, and not the
:meth:<code>partial_fit</code> method.</p>
<p>.. versionadded:: 0.19</p>
<p>tol : float, default=1e-3
The stopping criterion. If it is not None, the iterations will stop
when (loss &gt; best_loss - tol) for <code>n_iter_no_change</code> consecutive
epochs.</p>
<p>.. versionadded:: 0.19</p>
<p>shuffle : bool, default=True
Whether or not the training data should be shuffled after each epoch.</p>
<p>verbose : int, default=0
The verbosity level.</p>
<p>epsilon : float, default=0.1
Epsilon in the epsilon-insensitive loss functions; only if <code>loss</code> is
'huber', 'epsilon_insensitive', or 'squared_epsilon_insensitive'.
For 'huber', determines the threshold at which it becomes less
important to get the prediction exactly right.
For epsilon-insensitive, any differences between the current prediction
and the correct label are ignored if they are less than this threshold.</p>
<p>n_jobs : int, default=None
The number of CPUs to use to do the OVA (One Versus All, for
multi-class problems) computation.
<code>None</code> means 1 unless in a :obj:<code>joblib.parallel_backend</code> context.
<code>-1</code> means using all processors. See :term:<code>Glossary &lt;n_jobs&gt;</code>
for more details.</p>
<p>random_state : int, RandomState instance, default=None
The seed of the pseudo random number generator to use when shuffling
the data.  If int, random_state is the seed used by the random number
generator; If RandomState instance, random_state is the random number
generator; If None, the random number generator is the RandomState
instance used by <code>np.random</code>.</p>
<p>learning_rate : str, default='optimal'
The learning rate schedule:</p>
<p>'constant':
eta = eta0
'optimal': [default]
eta = 1.0 / (alpha * (t + t0))
where t0 is chosen by a heuristic proposed by Leon Bottou.
'invscaling':
eta = eta0 / pow(t, power_t)
'adaptive':
eta = eta0, as long as the training keeps decreasing.
Each time n_iter_no_change consecutive epochs fail to decrease the
training loss by tol or fail to increase validation score by tol if
early_stopping is True, the current learning rate is divided by 5.</p>
<p>eta0 : double, default=0.0
The initial learning rate for the 'constant', 'invscaling' or
'adaptive' schedules. The default value is 0.0 as eta0 is not used by
the default schedule 'optimal'.</p>
<p>power_t : double, default=0.5
The exponent for inverse scaling learning rate [default 0.5].</p>
<p>early_stopping : bool, default=False
Whether to use early stopping to terminate training when validation
score is not improving. If set to True, it will automatically set aside
a stratified fraction of training data as validation and terminate
training when validation score is not improving by at least tol for
n_iter_no_change consecutive epochs.</p>
<p>.. versionadded:: 0.20</p>
<p>validation_fraction : float, default=0.1
The proportion of training data to set aside as validation set for
early stopping. Must be between 0 and 1.
Only used if early_stopping is True.</p>
<p>.. versionadded:: 0.20</p>
<p>n_iter_no_change : int, default=5
Number of iterations with no improvement to wait before early stopping.</p>
<p>.. versionadded:: 0.20</p>
<p>class_weight : dict, {class_label: weight} or 'balanced', default=None
Preset for the class_weight fit parameter.</p>
<p>Weights associated with classes. If not given, all classes
are supposed to have weight one.</p>
<p>The 'balanced' mode uses the values of y to automatically adjust
weights inversely proportional to class frequencies in the input data
as <code>n_samples / (n_classes * np.bincount(y))</code>.</p>
<p>warm_start : bool, default=False
When set to True, reuse the solution of the previous call to fit as
initialization, otherwise, just erase the previous solution.
See :term:<code>the Glossary &lt;warm_start&gt;</code>.</p>
<p>Repeatedly calling fit or partial_fit when warm_start is True can
result in a different solution than when calling fit a single time
because of the way the data is shuffled.
If a dynamic learning rate is used, the learning rate is adapted
depending on the number of samples already seen. Calling <code>fit</code> resets
this counter, while <code>partial_fit</code> will result in increasing the
existing counter.</p>
<p>average : bool or int, default=False
When set to True, computes the averaged SGD weights and stores the
result in the <code>coef_</code> attribute. If set to an int greater than 1,
averaging will begin once the total number of samples seen reaches
average. So <code>average=10</code> will begin averaging after seeing 10
samples.</p>
<h2 id="attributes_29">Attributes<a class="headerlink" href="#attributes_29" title="Permanent link">&para;</a></h2>
<p>coef_ : ndarray of shape (1, n_features) if n_classes == 2 else             (n_classes, n_features)
Weights assigned to the features.</p>
<p>intercept_ : ndarray of shape (1,) if n_classes == 2 else (n_classes,)
Constants in decision function.</p>
<p>n_iter_ : int
The actual number of iterations to reach the stopping criterion.
For multiclass fits, it is the maximum over every binary fit.</p>
<p>loss_function_ : concrete <code>LossFunction</code></p>
<p>classes_ : array of shape (n_classes,)</p>
<p>t_ : int
Number of weight updates performed during training.
Same as <code>(n_iter_ * n_samples)</code>.</p>
<h2 id="see-also_25">See Also<a class="headerlink" href="#see-also_25" title="Permanent link">&para;</a></h2>
<p>sklearn.svm.LinearSVC: Linear support vector classification.
LogisticRegression: Logistic regression.
Perceptron: Inherits from SGDClassifier. <code>Perceptron()</code> is equivalent to
<code>SGDClassifier(loss='perceptron', eta0=1, learning_rate='constant',
penalty=None)</code>.</p>
<h2 id="examples_29">Examples<a class="headerlink" href="#examples_29" title="Permanent link">&para;</a></h2>
<blockquote>
<blockquote>
<blockquote>
<p>import numpy as np
from sklearn import linear_model
X = np.array([[-1, -1], [-2, -1], [1, 1], [2, 1]])
Y = np.array([1, 1, 2, 2])
clf = linear_model.SGDClassifier(max_iter=1000, tol=1e-3)
clf.fit(X, Y)
SGDClassifier()</p>
<p>print(clf.predict([[-0.8, -1]]))
[1]</p>
</blockquote>
</blockquote>
</blockquote>
<div class="highlight"><pre><span></span><code><span class="k">val</span> <span class="n">decision_function</span> <span class="o">:</span> <span class="n">x</span><span class="o">:[&gt;`</span><span class="nc">ArrayLike</span><span class="o">]</span> <span class="nn">Np</span><span class="p">.</span><span class="nn">Obj</span><span class="p">.</span><span class="n">t</span> <span class="o">-&gt;</span> <span class="o">[&gt;</span> <span class="n">tag</span><span class="o">]</span> <span class="nn">Obj</span><span class="p">.</span><span class="n">t</span> <span class="o">-&gt;</span> <span class="o">[&gt;`</span><span class="nc">ArrayLike</span><span class="o">]</span> <span class="nn">Np</span><span class="p">.</span><span class="nn">Obj</span><span class="p">.</span><span class="n">t</span>
</code></pre></div>

<p>Predict confidence scores for samples.</p>
<p>The confidence score for a sample is the signed distance of that
sample to the hyperplane.</p>
<h2 id="parameters_188">Parameters<a class="headerlink" href="#parameters_188" title="Permanent link">&para;</a></h2>
<p>X : array_like or sparse matrix, shape (n_samples, n_features)
Samples.</p>
<h2 id="returns_159">Returns<a class="headerlink" href="#returns_159" title="Permanent link">&para;</a></h2>
<p>array, shape=(n_samples,) if n_classes == 2 else (n_samples, n_classes)
Confidence scores per (sample, class) combination. In the binary
case, confidence score for self.classes_[1] where &gt;0 means this
class would be predicted.</p>
<div class="highlight"><pre><span></span><code><span class="k">val</span> <span class="n">densify</span> <span class="o">:</span> <span class="o">[&gt;</span> <span class="n">tag</span><span class="o">]</span> <span class="nn">Obj</span><span class="p">.</span><span class="n">t</span> <span class="o">-&gt;</span> <span class="n">t</span>
</code></pre></div>

<p>Convert coefficient matrix to dense array format.</p>
<p>Converts the <code>coef_</code> member (back) to a numpy.ndarray. This is the
default format of <code>coef_</code> and is required for fitting, so calling
this method is only required on models that have previously been
sparsified; otherwise, it is a no-op.</p>
<h2 id="returns_160">Returns<a class="headerlink" href="#returns_160" title="Permanent link">&para;</a></h2>
<p>self
Fitted estimator.</p>
<div class="highlight"><pre><span></span><code><span class="k">val</span> <span class="n">fit</span> <span class="o">:</span> <span class="o">?</span><span class="n">coef_init</span><span class="o">:[&gt;`</span><span class="nc">ArrayLike</span><span class="o">]</span> <span class="nn">Np</span><span class="p">.</span><span class="nn">Obj</span><span class="p">.</span><span class="n">t</span> <span class="o">-&gt;</span> <span class="o">?</span><span class="n">intercept_init</span><span class="o">:[&gt;`</span><span class="nc">ArrayLike</span><span class="o">]</span> <span class="nn">Np</span><span class="p">.</span><span class="nn">Obj</span><span class="p">.</span><span class="n">t</span> <span class="o">-&gt;</span> <span class="o">?</span><span class="n">sample_weight</span><span class="o">:[&gt;`</span><span class="nc">ArrayLike</span><span class="o">]</span> <span class="nn">Np</span><span class="p">.</span><span class="nn">Obj</span><span class="p">.</span><span class="n">t</span> <span class="o">-&gt;</span> <span class="n">x</span><span class="o">:[&gt;`</span><span class="nc">ArrayLike</span><span class="o">]</span> <span class="nn">Np</span><span class="p">.</span><span class="nn">Obj</span><span class="p">.</span><span class="n">t</span> <span class="o">-&gt;</span> <span class="n">y</span><span class="o">:[&gt;`</span><span class="nc">ArrayLike</span><span class="o">]</span> <span class="nn">Np</span><span class="p">.</span><span class="nn">Obj</span><span class="p">.</span><span class="n">t</span> <span class="o">-&gt;</span> <span class="o">[&gt;</span> <span class="n">tag</span><span class="o">]</span> <span class="nn">Obj</span><span class="p">.</span><span class="n">t</span> <span class="o">-&gt;</span> <span class="n">t</span>
</code></pre></div>

<p>Fit linear model with Stochastic Gradient Descent.</p>
<h2 id="parameters_189">Parameters<a class="headerlink" href="#parameters_189" title="Permanent link">&para;</a></h2>
<p>X : {array-like, sparse matrix}, shape (n_samples, n_features)
Training data.</p>
<p>y : ndarray of shape (n_samples,)
Target values.</p>
<p>coef_init : ndarray of shape (n_classes, n_features), default=None
The initial coefficients to warm-start the optimization.</p>
<p>intercept_init : ndarray of shape (n_classes,), default=None
The initial intercept to warm-start the optimization.</p>
<p>sample_weight : array-like, shape (n_samples,), default=None
Weights applied to individual samples.
If not provided, uniform weights are assumed. These weights will
be multiplied with class_weight (passed through the
constructor) if class_weight is specified.</p>
<h2 id="returns_161">Returns<a class="headerlink" href="#returns_161" title="Permanent link">&para;</a></h2>
<p>self :
Returns an instance of self.</p>
<div class="highlight"><pre><span></span><code><span class="k">val</span> <span class="n">get_params</span> <span class="o">:</span> <span class="o">?</span><span class="n">deep</span><span class="o">:</span><span class="kt">bool</span> <span class="o">-&gt;</span> <span class="o">[&gt;</span> <span class="n">tag</span><span class="o">]</span> <span class="nn">Obj</span><span class="p">.</span><span class="n">t</span> <span class="o">-&gt;</span> <span class="nn">Dict</span><span class="p">.</span><span class="n">t</span>
</code></pre></div>

<p>Get parameters for this estimator.</p>
<h2 id="parameters_190">Parameters<a class="headerlink" href="#parameters_190" title="Permanent link">&para;</a></h2>
<p>deep : bool, default=True
If True, will return the parameters for this estimator and
contained subobjects that are estimators.</p>
<h2 id="returns_162">Returns<a class="headerlink" href="#returns_162" title="Permanent link">&para;</a></h2>
<p>params : mapping of string to any
Parameter names mapped to their values.</p>
<div class="highlight"><pre><span></span><code><span class="k">val</span> <span class="n">partial_fit</span> <span class="o">:</span> <span class="o">?</span><span class="n">classes</span><span class="o">:[&gt;`</span><span class="nc">ArrayLike</span><span class="o">]</span> <span class="nn">Np</span><span class="p">.</span><span class="nn">Obj</span><span class="p">.</span><span class="n">t</span> <span class="o">-&gt;</span> <span class="o">?</span><span class="n">sample_weight</span><span class="o">:[&gt;`</span><span class="nc">ArrayLike</span><span class="o">]</span> <span class="nn">Np</span><span class="p">.</span><span class="nn">Obj</span><span class="p">.</span><span class="n">t</span> <span class="o">-&gt;</span> <span class="n">x</span><span class="o">:[&gt;`</span><span class="nc">ArrayLike</span><span class="o">]</span> <span class="nn">Np</span><span class="p">.</span><span class="nn">Obj</span><span class="p">.</span><span class="n">t</span> <span class="o">-&gt;</span> <span class="n">y</span><span class="o">:[&gt;`</span><span class="nc">ArrayLike</span><span class="o">]</span> <span class="nn">Np</span><span class="p">.</span><span class="nn">Obj</span><span class="p">.</span><span class="n">t</span> <span class="o">-&gt;</span> <span class="o">[&gt;</span> <span class="n">tag</span><span class="o">]</span> <span class="nn">Obj</span><span class="p">.</span><span class="n">t</span> <span class="o">-&gt;</span> <span class="n">t</span>
</code></pre></div>

<p>Perform one epoch of stochastic gradient descent on given samples.</p>
<p>Internally, this method uses <code>max_iter = 1</code>. Therefore, it is not
guaranteed that a minimum of the cost function is reached after calling
it once. Matters such as objective convergence and early stopping
should be handled by the user.</p>
<h2 id="parameters_191">Parameters<a class="headerlink" href="#parameters_191" title="Permanent link">&para;</a></h2>
<p>X : {array-like, sparse matrix}, shape (n_samples, n_features)
Subset of the training data.</p>
<p>y : ndarray of shape (n_samples,)
Subset of the target values.</p>
<p>classes : ndarray of shape (n_classes,), default=None
Classes across all calls to partial_fit.
Can be obtained by via <code>np.unique(y_all)</code>, where y_all is the
target vector of the entire dataset.
This argument is required for the first call to partial_fit
and can be omitted in the subsequent calls.
Note that y doesn't need to contain all labels in <code>classes</code>.</p>
<p>sample_weight : array-like, shape (n_samples,), default=None
Weights applied to individual samples.
If not provided, uniform weights are assumed.</p>
<h2 id="returns_163">Returns<a class="headerlink" href="#returns_163" title="Permanent link">&para;</a></h2>
<p>self :
Returns an instance of self.</p>
<div class="highlight"><pre><span></span><code><span class="k">val</span> <span class="n">predict</span> <span class="o">:</span> <span class="n">x</span><span class="o">:[&gt;`</span><span class="nc">ArrayLike</span><span class="o">]</span> <span class="nn">Np</span><span class="p">.</span><span class="nn">Obj</span><span class="p">.</span><span class="n">t</span> <span class="o">-&gt;</span> <span class="o">[&gt;</span> <span class="n">tag</span><span class="o">]</span> <span class="nn">Obj</span><span class="p">.</span><span class="n">t</span> <span class="o">-&gt;</span> <span class="o">[&gt;`</span><span class="nc">ArrayLike</span><span class="o">]</span> <span class="nn">Np</span><span class="p">.</span><span class="nn">Obj</span><span class="p">.</span><span class="n">t</span>
</code></pre></div>

<p>Predict class labels for samples in X.</p>
<h2 id="parameters_192">Parameters<a class="headerlink" href="#parameters_192" title="Permanent link">&para;</a></h2>
<p>X : array_like or sparse matrix, shape (n_samples, n_features)
Samples.</p>
<h2 id="returns_164">Returns<a class="headerlink" href="#returns_164" title="Permanent link">&para;</a></h2>
<p>C : array, shape [n_samples]
Predicted class label per sample.</p>
<div class="highlight"><pre><span></span><code><span class="k">val</span> <span class="n">score</span> <span class="o">:</span> <span class="o">?</span><span class="n">sample_weight</span><span class="o">:[&gt;`</span><span class="nc">ArrayLike</span><span class="o">]</span> <span class="nn">Np</span><span class="p">.</span><span class="nn">Obj</span><span class="p">.</span><span class="n">t</span> <span class="o">-&gt;</span> <span class="n">x</span><span class="o">:[&gt;`</span><span class="nc">ArrayLike</span><span class="o">]</span> <span class="nn">Np</span><span class="p">.</span><span class="nn">Obj</span><span class="p">.</span><span class="n">t</span> <span class="o">-&gt;</span> <span class="n">y</span><span class="o">:[&gt;`</span><span class="nc">ArrayLike</span><span class="o">]</span> <span class="nn">Np</span><span class="p">.</span><span class="nn">Obj</span><span class="p">.</span><span class="n">t</span> <span class="o">-&gt;</span> <span class="o">[&gt;</span> <span class="n">tag</span><span class="o">]</span> <span class="nn">Obj</span><span class="p">.</span><span class="n">t</span> <span class="o">-&gt;</span> <span class="kt">float</span>
</code></pre></div>

<p>Return the mean accuracy on the given test data and labels.</p>
<p>In multi-label classification, this is the subset accuracy
which is a harsh metric since you require for each sample that
each label set be correctly predicted.</p>
<h2 id="parameters_193">Parameters<a class="headerlink" href="#parameters_193" title="Permanent link">&para;</a></h2>
<p>X : array-like of shape (n_samples, n_features)
Test samples.</p>
<p>y : array-like of shape (n_samples,) or (n_samples, n_outputs)
True labels for X.</p>
<p>sample_weight : array-like of shape (n_samples,), default=None
Sample weights.</p>
<h2 id="returns_165">Returns<a class="headerlink" href="#returns_165" title="Permanent link">&para;</a></h2>
<p>score : float
Mean accuracy of self.predict(X) wrt. y.</p>
<div class="highlight"><pre><span></span><code><span class="k">val</span> <span class="n">set_params</span> <span class="o">:</span> <span class="o">?</span><span class="n">kwargs</span><span class="o">:(</span><span class="kt">string</span> <span class="o">*</span> <span class="nn">Py</span><span class="p">.</span><span class="nn">Object</span><span class="p">.</span><span class="n">t</span><span class="o">)</span> <span class="kt">list</span> <span class="o">-&gt;</span> <span class="o">[&gt;</span> <span class="n">tag</span><span class="o">]</span> <span class="nn">Obj</span><span class="p">.</span><span class="n">t</span> <span class="o">-&gt;</span> <span class="n">t</span>
</code></pre></div>

<p>Set and validate the parameters of estimator.</p>
<h2 id="parameters_194">Parameters<a class="headerlink" href="#parameters_194" title="Permanent link">&para;</a></h2>
<p>**kwargs : dict
Estimator parameters.</p>
<h2 id="returns_166">Returns<a class="headerlink" href="#returns_166" title="Permanent link">&para;</a></h2>
<p>self : object
Estimator instance.</p>
<div class="highlight"><pre><span></span><code><span class="k">val</span> <span class="n">sparsify</span> <span class="o">:</span> <span class="o">[&gt;</span> <span class="n">tag</span><span class="o">]</span> <span class="nn">Obj</span><span class="p">.</span><span class="n">t</span> <span class="o">-&gt;</span> <span class="n">t</span>
</code></pre></div>

<p>Convert coefficient matrix to sparse format.</p>
<p>Converts the <code>coef_</code> member to a scipy.sparse matrix, which for
L1-regularized models can be much more memory- and storage-efficient
than the usual numpy.ndarray representation.</p>
<p>The <code>intercept_</code> member is not converted.</p>
<h2 id="returns_167">Returns<a class="headerlink" href="#returns_167" title="Permanent link">&para;</a></h2>
<p>self
Fitted estimator.</p>
<h2 id="notes_51">Notes<a class="headerlink" href="#notes_51" title="Permanent link">&para;</a></h2>
<p>For non-sparse models, i.e. when there are not many zeros in <code>coef_</code>,
this may actually <em>increase</em> memory usage, so use this method with
care. A rule of thumb is that the number of zero elements, which can
be computed with <code>(coef_ == 0).sum()</code>, must be more than 50% for this
to provide significant benefits.</p>
<p>After calling this method, further fitting with the partial_fit
method (if any) will not work until you call densify.</p>
<p>Attribute coef_: get value or raise Not_found if None.</p>
<div class="highlight"><pre><span></span><code><span class="k">val</span> <span class="n">coef_</span> <span class="o">:</span> <span class="n">t</span> <span class="o">-&gt;</span> <span class="o">[&gt;`</span><span class="nc">ArrayLike</span><span class="o">]</span> <span class="nn">Np</span><span class="p">.</span><span class="nn">Obj</span><span class="p">.</span><span class="n">t</span>
</code></pre></div>

<p>Attribute coef_: get value as an option.</p>
<div class="highlight"><pre><span></span><code><span class="k">val</span> <span class="n">coef_opt</span> <span class="o">:</span> <span class="n">t</span> <span class="o">-&gt;</span> <span class="o">([&gt;`</span><span class="nc">ArrayLike</span><span class="o">]</span> <span class="nn">Np</span><span class="p">.</span><span class="nn">Obj</span><span class="p">.</span><span class="n">t</span><span class="o">)</span> <span class="n">option</span>
</code></pre></div>

<p>Attribute intercept_: get value or raise Not_found if None.</p>
<div class="highlight"><pre><span></span><code><span class="k">val</span> <span class="n">intercept_</span> <span class="o">:</span> <span class="n">t</span> <span class="o">-&gt;</span> <span class="o">[&gt;`</span><span class="nc">ArrayLike</span><span class="o">]</span> <span class="nn">Np</span><span class="p">.</span><span class="nn">Obj</span><span class="p">.</span><span class="n">t</span>
</code></pre></div>

<p>Attribute intercept_: get value as an option.</p>
<div class="highlight"><pre><span></span><code><span class="k">val</span> <span class="n">intercept_opt</span> <span class="o">:</span> <span class="n">t</span> <span class="o">-&gt;</span> <span class="o">([&gt;`</span><span class="nc">ArrayLike</span><span class="o">]</span> <span class="nn">Np</span><span class="p">.</span><span class="nn">Obj</span><span class="p">.</span><span class="n">t</span><span class="o">)</span> <span class="n">option</span>
</code></pre></div>

<p>Attribute n_iter_: get value or raise Not_found if None.</p>
<div class="highlight"><pre><span></span><code><span class="k">val</span> <span class="n">n_iter_</span> <span class="o">:</span> <span class="n">t</span> <span class="o">-&gt;</span> <span class="kt">int</span>
</code></pre></div>

<p>Attribute n_iter_: get value as an option.</p>
<div class="highlight"><pre><span></span><code><span class="k">val</span> <span class="n">n_iter_opt</span> <span class="o">:</span> <span class="n">t</span> <span class="o">-&gt;</span> <span class="o">(</span><span class="kt">int</span><span class="o">)</span> <span class="n">option</span>
</code></pre></div>

<p>Attribute loss_function_: get value or raise Not_found if None.</p>
<div class="highlight"><pre><span></span><code><span class="k">val</span> <span class="n">loss_function_</span> <span class="o">:</span> <span class="n">t</span> <span class="o">-&gt;</span> <span class="nn">Np</span><span class="p">.</span><span class="nn">NumpyRaw</span><span class="p">.</span><span class="nn">Ndarray</span><span class="p">.</span><span class="n">t</span> <span class="o">-&gt;</span> <span class="nn">Np</span><span class="p">.</span><span class="nn">NumpyRaw</span><span class="p">.</span><span class="nn">Ndarray</span><span class="p">.</span><span class="n">t</span> <span class="o">-&gt;</span> <span class="kt">float</span>
</code></pre></div>

<p>Attribute loss_function_: get value as an option.</p>
<div class="highlight"><pre><span></span><code><span class="k">val</span> <span class="n">loss_function_opt</span> <span class="o">:</span> <span class="n">t</span> <span class="o">-&gt;</span> <span class="o">(</span><span class="nn">Np</span><span class="p">.</span><span class="nn">NumpyRaw</span><span class="p">.</span><span class="nn">Ndarray</span><span class="p">.</span><span class="n">t</span> <span class="o">-&gt;</span> <span class="nn">Np</span><span class="p">.</span><span class="nn">NumpyRaw</span><span class="p">.</span><span class="nn">Ndarray</span><span class="p">.</span><span class="n">t</span> <span class="o">-&gt;</span> <span class="kt">float</span><span class="o">)</span> <span class="n">option</span>
</code></pre></div>

<p>Attribute classes_: get value or raise Not_found if None.</p>
<div class="highlight"><pre><span></span><code><span class="k">val</span> <span class="n">classes_</span> <span class="o">:</span> <span class="n">t</span> <span class="o">-&gt;</span> <span class="o">[&gt;`</span><span class="nc">ArrayLike</span><span class="o">]</span> <span class="nn">Np</span><span class="p">.</span><span class="nn">Obj</span><span class="p">.</span><span class="n">t</span>
</code></pre></div>

<p>Attribute classes_: get value as an option.</p>
<div class="highlight"><pre><span></span><code><span class="k">val</span> <span class="n">classes_opt</span> <span class="o">:</span> <span class="n">t</span> <span class="o">-&gt;</span> <span class="o">([&gt;`</span><span class="nc">ArrayLike</span><span class="o">]</span> <span class="nn">Np</span><span class="p">.</span><span class="nn">Obj</span><span class="p">.</span><span class="n">t</span><span class="o">)</span> <span class="n">option</span>
</code></pre></div>

<p>Attribute t_: get value or raise Not_found if None.</p>
<div class="highlight"><pre><span></span><code><span class="k">val</span> <span class="n">t_</span> <span class="o">:</span> <span class="n">t</span> <span class="o">-&gt;</span> <span class="kt">int</span>
</code></pre></div>

<p>Attribute t_: get value as an option.</p>
<div class="highlight"><pre><span></span><code><span class="k">val</span> <span class="n">t_opt</span> <span class="o">:</span> <span class="n">t</span> <span class="o">-&gt;</span> <span class="o">(</span><span class="kt">int</span><span class="o">)</span> <span class="n">option</span>
</code></pre></div>

<p>Print the object to a human-readable representation.</p>
<div class="highlight"><pre><span></span><code><span class="k">val</span> <span class="n">to_string</span> <span class="o">:</span> <span class="n">t</span> <span class="o">-&gt;</span> <span class="kt">string</span>
</code></pre></div>

<p>Print the object to a human-readable representation.</p>
<div class="highlight"><pre><span></span><code><span class="k">val</span> <span class="n">show</span> <span class="o">:</span> <span class="n">t</span> <span class="o">-&gt;</span> <span class="kt">string</span>
</code></pre></div>

<p>Pretty-print the object to a formatter.</p>
<div class="highlight"><pre><span></span><code><span class="k">val</span> <span class="n">pp</span> <span class="o">:</span> <span class="nn">Format</span><span class="p">.</span><span class="n">formatter</span> <span class="o">-&gt;</span> <span class="n">t</span> <span class="o">-&gt;</span> <span class="kt">unit</span> <span class="o">[@@</span><span class="n">ocaml</span><span class="o">.</span><span class="n">toplevel_printer</span><span class="o">]</span>



<span class="k">module</span> <span class="nc">SGDRegressor</span> <span class="o">:</span> <span class="k">sig</span>
<span class="k">type</span> <span class="n">tag</span> <span class="o">=</span> <span class="o">[`</span><span class="nc">SGDRegressor</span><span class="o">]</span>
<span class="k">type</span> <span class="n">t</span> <span class="o">=</span> <span class="o">[`</span><span class="nc">BaseEstimator</span> <span class="o">|</span> <span class="o">`</span><span class="nc">BaseSGD</span> <span class="o">|</span> <span class="o">`</span><span class="nc">BaseSGDRegressor</span> <span class="o">|</span> <span class="o">`</span><span class="nc">Object</span> <span class="o">|</span> <span class="o">`</span><span class="nc">RegressorMixin</span> <span class="o">|</span> <span class="o">`</span><span class="nc">SGDRegressor</span> <span class="o">|</span> <span class="o">`</span><span class="nc">SparseCoefMixin</span><span class="o">]</span> <span class="nn">Obj</span><span class="p">.</span><span class="n">t</span>
<span class="k">val</span> <span class="n">of_pyobject</span> <span class="o">:</span> <span class="nn">Py</span><span class="p">.</span><span class="nn">Object</span><span class="p">.</span><span class="n">t</span> <span class="o">-&gt;</span> <span class="n">t</span>
<span class="k">val</span> <span class="n">to_pyobject</span> <span class="o">:</span> <span class="o">[&gt;</span> <span class="n">tag</span><span class="o">]</span> <span class="nn">Obj</span><span class="p">.</span><span class="n">t</span> <span class="o">-&gt;</span> <span class="nn">Py</span><span class="p">.</span><span class="nn">Object</span><span class="p">.</span><span class="n">t</span>

<span class="k">val</span> <span class="n">as_regressor</span> <span class="o">:</span> <span class="n">t</span> <span class="o">-&gt;</span> <span class="o">[`</span><span class="nc">RegressorMixin</span><span class="o">]</span> <span class="nn">Obj</span><span class="p">.</span><span class="n">t</span>
<span class="k">val</span> <span class="n">as_estimator</span> <span class="o">:</span> <span class="n">t</span> <span class="o">-&gt;</span> <span class="o">[`</span><span class="nc">BaseEstimator</span><span class="o">]</span> <span class="nn">Obj</span><span class="p">.</span><span class="n">t</span>
<span class="k">val</span> <span class="n">as_sgd_regressor</span> <span class="o">:</span> <span class="n">t</span> <span class="o">-&gt;</span> <span class="o">[`</span><span class="nc">BaseSGDRegressor</span><span class="o">]</span> <span class="nn">Obj</span><span class="p">.</span><span class="n">t</span>
<span class="k">val</span> <span class="n">as_sparse_coef</span> <span class="o">:</span> <span class="n">t</span> <span class="o">-&gt;</span> <span class="o">[`</span><span class="nc">SparseCoefMixin</span><span class="o">]</span> <span class="nn">Obj</span><span class="p">.</span><span class="n">t</span>
<span class="k">val</span> <span class="n">as_sgd</span> <span class="o">:</span> <span class="n">t</span> <span class="o">-&gt;</span> <span class="o">[`</span><span class="nc">BaseSGD</span><span class="o">]</span> <span class="nn">Obj</span><span class="p">.</span><span class="n">t</span>
<span class="k">val</span> <span class="n">create</span> <span class="o">:</span> <span class="o">?</span><span class="n">loss</span><span class="o">:</span><span class="kt">string</span> <span class="o">-&gt;</span> <span class="o">?</span><span class="n">penalty</span><span class="o">:[`</span><span class="nc">L2</span> <span class="o">|</span> <span class="o">`</span><span class="nc">L1</span> <span class="o">|</span> <span class="o">`</span><span class="nc">Elasticnet</span><span class="o">]</span> <span class="o">-&gt;</span> <span class="o">?</span><span class="n">alpha</span><span class="o">:</span><span class="kt">float</span> <span class="o">-&gt;</span> <span class="o">?</span><span class="n">l1_ratio</span><span class="o">:</span><span class="kt">float</span> <span class="o">-&gt;</span> <span class="o">?</span><span class="n">fit_intercept</span><span class="o">:</span><span class="kt">bool</span> <span class="o">-&gt;</span> <span class="o">?</span><span class="n">max_iter</span><span class="o">:</span><span class="kt">int</span> <span class="o">-&gt;</span> <span class="o">?</span><span class="n">tol</span><span class="o">:</span><span class="kt">float</span> <span class="o">-&gt;</span> <span class="o">?</span><span class="n">shuffle</span><span class="o">:</span><span class="kt">bool</span> <span class="o">-&gt;</span> <span class="o">?</span><span class="n">verbose</span><span class="o">:</span><span class="kt">int</span> <span class="o">-&gt;</span> <span class="o">?</span><span class="n">epsilon</span><span class="o">:</span><span class="kt">float</span> <span class="o">-&gt;</span> <span class="o">?</span><span class="n">random_state</span><span class="o">:</span><span class="kt">int</span> <span class="o">-&gt;</span> <span class="o">?</span><span class="n">learning_rate</span><span class="o">:</span><span class="kt">string</span> <span class="o">-&gt;</span> <span class="o">?</span><span class="n">eta0</span><span class="o">:</span><span class="kt">float</span> <span class="o">-&gt;</span> <span class="o">?</span><span class="n">power_t</span><span class="o">:</span><span class="kt">float</span> <span class="o">-&gt;</span> <span class="o">?</span><span class="n">early_stopping</span><span class="o">:</span><span class="kt">bool</span> <span class="o">-&gt;</span> <span class="o">?</span><span class="n">validation_fraction</span><span class="o">:</span><span class="kt">float</span> <span class="o">-&gt;</span> <span class="o">?</span><span class="n">n_iter_no_change</span><span class="o">:</span><span class="kt">int</span> <span class="o">-&gt;</span> <span class="o">?</span><span class="n">warm_start</span><span class="o">:</span><span class="kt">bool</span> <span class="o">-&gt;</span> <span class="o">?</span><span class="n">average</span><span class="o">:[`</span><span class="nc">I</span> <span class="k">of</span> <span class="kt">int</span> <span class="o">|</span> <span class="o">`</span><span class="nc">Bool</span> <span class="k">of</span> <span class="kt">bool</span><span class="o">]</span> <span class="o">-&gt;</span> <span class="kt">unit</span> <span class="o">-&gt;</span> <span class="n">t</span>
</code></pre></div>

<p>Linear model fitted by minimizing a regularized empirical loss with SGD</p>
<p>SGD stands for Stochastic Gradient Descent: the gradient of the loss is
estimated each sample at a time and the model is updated along the way with
a decreasing strength schedule (aka learning rate).</p>
<p>The regularizer is a penalty added to the loss function that shrinks model
parameters towards the zero vector using either the squared euclidean norm
L2 or the absolute norm L1 or a combination of both (Elastic Net). If the
parameter update crosses the 0.0 value because of the regularizer, the
update is truncated to 0.0 to allow for learning sparse models and achieve
online feature selection.</p>
<p>This implementation works with data represented as dense numpy arrays of
floating point values for the features.</p>
<p>Read more in the :ref:<code>User Guide &lt;sgd&gt;</code>.</p>
<h2 id="parameters_195">Parameters<a class="headerlink" href="#parameters_195" title="Permanent link">&para;</a></h2>
<p>loss : str, default='squared_loss'
The loss function to be used. The possible values are 'squared_loss',
'huber', 'epsilon_insensitive', or 'squared_epsilon_insensitive'</p>
<p>The 'squared_loss' refers to the ordinary least squares fit.
'huber' modifies 'squared_loss' to focus less on getting outliers
correct by switching from squared to linear loss past a distance of
epsilon. 'epsilon_insensitive' ignores errors less than epsilon and is
linear past that; this is the loss function used in SVR.
'squared_epsilon_insensitive' is the same but becomes squared loss past
a tolerance of epsilon.</p>
<p>penalty : {'l2', 'l1', 'elasticnet'}, default='l2'
The penalty (aka regularization term) to be used. Defaults to 'l2'
which is the standard regularizer for linear SVM models. 'l1' and
'elasticnet' might bring sparsity to the model (feature selection)
not achievable with 'l2'.</p>
<p>alpha : float, default=0.0001
Constant that multiplies the regularization term.
Also used to compute learning_rate when set to 'optimal'.</p>
<p>l1_ratio : float, default=0.15
The Elastic Net mixing parameter, with 0 &lt;= l1_ratio &lt;= 1.
l1_ratio=0 corresponds to L2 penalty, l1_ratio=1 to L1.</p>
<p>fit_intercept : bool, default=True
Whether the intercept should be estimated or not. If False, the
data is assumed to be already centered.</p>
<p>max_iter : int, default=1000
The maximum number of passes over the training data (aka epochs).
It only impacts the behavior in the <code>fit</code> method, and not the
:meth:<code>partial_fit</code> method.</p>
<p>.. versionadded:: 0.19</p>
<p>tol : float, default=1e-3
The stopping criterion. If it is not None, the iterations will stop
when (loss &gt; best_loss - tol) for <code>n_iter_no_change</code> consecutive
epochs.</p>
<p>.. versionadded:: 0.19</p>
<p>shuffle : bool, default=True
Whether or not the training data should be shuffled after each epoch.</p>
<p>verbose : int, default=0
The verbosity level.</p>
<p>epsilon : float, default=0.1
Epsilon in the epsilon-insensitive loss functions; only if <code>loss</code> is
'huber', 'epsilon_insensitive', or 'squared_epsilon_insensitive'.
For 'huber', determines the threshold at which it becomes less
important to get the prediction exactly right.
For epsilon-insensitive, any differences between the current prediction
and the correct label are ignored if they are less than this threshold.</p>
<p>random_state : int, RandomState instance, default=None
The seed of the pseudo random number generator to use when shuffling
the data.  If int, random_state is the seed used by the random number
generator; If RandomState instance, random_state is the random number
generator; If None, the random number generator is the RandomState
instance used by <code>np.random</code>.</p>
<p>learning_rate : string, default='invscaling'
The learning rate schedule:</p>
<p>'constant':
eta = eta0
'optimal':
eta = 1.0 / (alpha * (t + t0))
where t0 is chosen by a heuristic proposed by Leon Bottou.
'invscaling': [default]
eta = eta0 / pow(t, power_t)
'adaptive':
eta = eta0, as long as the training keeps decreasing.
Each time n_iter_no_change consecutive epochs fail to decrease the
training loss by tol or fail to increase validation score by tol if
early_stopping is True, the current learning rate is divided by 5.</p>
<p>eta0 : double, default=0.01
The initial learning rate for the 'constant', 'invscaling' or
'adaptive' schedules. The default value is 0.01.</p>
<p>power_t : double, default=0.25
The exponent for inverse scaling learning rate.</p>
<p>early_stopping : bool, default=False
Whether to use early stopping to terminate training when validation
score is not improving. If set to True, it will automatically set aside
a fraction of training data as validation and terminate
training when validation score is not improving by at least tol for
n_iter_no_change consecutive epochs.</p>
<p>.. versionadded:: 0.20</p>
<p>validation_fraction : float, default=0.1
The proportion of training data to set aside as validation set for
early stopping. Must be between 0 and 1.
Only used if early_stopping is True.</p>
<p>.. versionadded:: 0.20</p>
<p>n_iter_no_change : int, default=5
Number of iterations with no improvement to wait before early stopping.</p>
<p>.. versionadded:: 0.20</p>
<p>warm_start : bool, default=False
When set to True, reuse the solution of the previous call to fit as
initialization, otherwise, just erase the previous solution.
See :term:<code>the Glossary &lt;warm_start&gt;</code>.</p>
<p>Repeatedly calling fit or partial_fit when warm_start is True can
result in a different solution than when calling fit a single time
because of the way the data is shuffled.
If a dynamic learning rate is used, the learning rate is adapted
depending on the number of samples already seen. Calling <code>fit</code> resets
this counter, while <code>partial_fit</code>  will result in increasing the
existing counter.</p>
<p>average : bool or int, default=False
When set to True, computes the averaged SGD weights and stores the
result in the <code>coef_</code> attribute. If set to an int greater than 1,
averaging will begin once the total number of samples seen reaches
average. So <code>average=10</code> will begin averaging after seeing 10
samples.</p>
<h2 id="attributes_30">Attributes<a class="headerlink" href="#attributes_30" title="Permanent link">&para;</a></h2>
<p>coef_ : ndarray of shape (n_features,)
Weights assigned to the features.</p>
<p>intercept_ : ndarray of shape (1,)
The intercept term.</p>
<p>average_coef_ : ndarray of shape (n_features,)
Averaged weights assigned to the features.</p>
<p>average_intercept_ : ndarray of shape (1,)
The averaged intercept term.</p>
<p>n_iter_ : int
The actual number of iterations to reach the stopping criterion.</p>
<p>t_ : int
Number of weight updates performed during training.
Same as <code>(n_iter_ * n_samples)</code>.</p>
<h2 id="examples_30">Examples<a class="headerlink" href="#examples_30" title="Permanent link">&para;</a></h2>
<blockquote>
<blockquote>
<blockquote>
<p>import numpy as np
from sklearn import linear_model
n_samples, n_features = 10, 5
rng = np.random.RandomState(0)
y = rng.randn(n_samples)
X = rng.randn(n_samples, n_features)
clf = linear_model.SGDRegressor(max_iter=1000, tol=1e-3)
clf.fit(X, y)
SGDRegressor()</p>
</blockquote>
</blockquote>
</blockquote>
<h2 id="see-also_26">See also<a class="headerlink" href="#see-also_26" title="Permanent link">&para;</a></h2>
<p>Ridge, ElasticNet, Lasso, sklearn.svm.SVR</p>
<div class="highlight"><pre><span></span><code><span class="k">val</span> <span class="n">densify</span> <span class="o">:</span> <span class="o">[&gt;</span> <span class="n">tag</span><span class="o">]</span> <span class="nn">Obj</span><span class="p">.</span><span class="n">t</span> <span class="o">-&gt;</span> <span class="n">t</span>
</code></pre></div>

<p>Convert coefficient matrix to dense array format.</p>
<p>Converts the <code>coef_</code> member (back) to a numpy.ndarray. This is the
default format of <code>coef_</code> and is required for fitting, so calling
this method is only required on models that have previously been
sparsified; otherwise, it is a no-op.</p>
<h2 id="returns_168">Returns<a class="headerlink" href="#returns_168" title="Permanent link">&para;</a></h2>
<p>self
Fitted estimator.</p>
<div class="highlight"><pre><span></span><code><span class="k">val</span> <span class="n">fit</span> <span class="o">:</span> <span class="o">?</span><span class="n">coef_init</span><span class="o">:[&gt;`</span><span class="nc">ArrayLike</span><span class="o">]</span> <span class="nn">Np</span><span class="p">.</span><span class="nn">Obj</span><span class="p">.</span><span class="n">t</span> <span class="o">-&gt;</span> <span class="o">?</span><span class="n">intercept_init</span><span class="o">:[&gt;`</span><span class="nc">ArrayLike</span><span class="o">]</span> <span class="nn">Np</span><span class="p">.</span><span class="nn">Obj</span><span class="p">.</span><span class="n">t</span> <span class="o">-&gt;</span> <span class="o">?</span><span class="n">sample_weight</span><span class="o">:[&gt;`</span><span class="nc">ArrayLike</span><span class="o">]</span> <span class="nn">Np</span><span class="p">.</span><span class="nn">Obj</span><span class="p">.</span><span class="n">t</span> <span class="o">-&gt;</span> <span class="n">x</span><span class="o">:[&gt;`</span><span class="nc">ArrayLike</span><span class="o">]</span> <span class="nn">Np</span><span class="p">.</span><span class="nn">Obj</span><span class="p">.</span><span class="n">t</span> <span class="o">-&gt;</span> <span class="n">y</span><span class="o">:[&gt;`</span><span class="nc">ArrayLike</span><span class="o">]</span> <span class="nn">Np</span><span class="p">.</span><span class="nn">Obj</span><span class="p">.</span><span class="n">t</span> <span class="o">-&gt;</span> <span class="o">[&gt;</span> <span class="n">tag</span><span class="o">]</span> <span class="nn">Obj</span><span class="p">.</span><span class="n">t</span> <span class="o">-&gt;</span> <span class="n">t</span>
</code></pre></div>

<p>Fit linear model with Stochastic Gradient Descent.</p>
<h2 id="parameters_196">Parameters<a class="headerlink" href="#parameters_196" title="Permanent link">&para;</a></h2>
<p>X : {array-like, sparse matrix}, shape (n_samples, n_features)
Training data</p>
<p>y : ndarray of shape (n_samples,)
Target values</p>
<p>coef_init : ndarray of shape (n_features,), default=None
The initial coefficients to warm-start the optimization.</p>
<p>intercept_init : ndarray of shape (1,), default=None
The initial intercept to warm-start the optimization.</p>
<p>sample_weight : array-like, shape (n_samples,), default=None
Weights applied to individual samples (1. for unweighted).</p>
<h2 id="returns_169">Returns<a class="headerlink" href="#returns_169" title="Permanent link">&para;</a></h2>
<p>self : returns an instance of self.</p>
<div class="highlight"><pre><span></span><code><span class="k">val</span> <span class="n">get_params</span> <span class="o">:</span> <span class="o">?</span><span class="n">deep</span><span class="o">:</span><span class="kt">bool</span> <span class="o">-&gt;</span> <span class="o">[&gt;</span> <span class="n">tag</span><span class="o">]</span> <span class="nn">Obj</span><span class="p">.</span><span class="n">t</span> <span class="o">-&gt;</span> <span class="nn">Dict</span><span class="p">.</span><span class="n">t</span>
</code></pre></div>

<p>Get parameters for this estimator.</p>
<h2 id="parameters_197">Parameters<a class="headerlink" href="#parameters_197" title="Permanent link">&para;</a></h2>
<p>deep : bool, default=True
If True, will return the parameters for this estimator and
contained subobjects that are estimators.</p>
<h2 id="returns_170">Returns<a class="headerlink" href="#returns_170" title="Permanent link">&para;</a></h2>
<p>params : mapping of string to any
Parameter names mapped to their values.</p>
<div class="highlight"><pre><span></span><code><span class="k">val</span> <span class="n">partial_fit</span> <span class="o">:</span> <span class="o">?</span><span class="n">sample_weight</span><span class="o">:[&gt;`</span><span class="nc">ArrayLike</span><span class="o">]</span> <span class="nn">Np</span><span class="p">.</span><span class="nn">Obj</span><span class="p">.</span><span class="n">t</span> <span class="o">-&gt;</span> <span class="n">x</span><span class="o">:[&gt;`</span><span class="nc">ArrayLike</span><span class="o">]</span> <span class="nn">Np</span><span class="p">.</span><span class="nn">Obj</span><span class="p">.</span><span class="n">t</span> <span class="o">-&gt;</span> <span class="n">y</span><span class="o">:[&gt;`</span><span class="nc">ArrayLike</span><span class="o">]</span> <span class="nn">Np</span><span class="p">.</span><span class="nn">Obj</span><span class="p">.</span><span class="n">t</span> <span class="o">-&gt;</span> <span class="o">[&gt;</span> <span class="n">tag</span><span class="o">]</span> <span class="nn">Obj</span><span class="p">.</span><span class="n">t</span> <span class="o">-&gt;</span> <span class="n">t</span>
</code></pre></div>

<p>Perform one epoch of stochastic gradient descent on given samples.</p>
<p>Internally, this method uses <code>max_iter = 1</code>. Therefore, it is not
guaranteed that a minimum of the cost function is reached after calling
it once. Matters such as objective convergence and early stopping
should be handled by the user.</p>
<h2 id="parameters_198">Parameters<a class="headerlink" href="#parameters_198" title="Permanent link">&para;</a></h2>
<p>X : {array-like, sparse matrix}, shape (n_samples, n_features)
Subset of training data</p>
<p>y : numpy array of shape (n_samples,)
Subset of target values</p>
<p>sample_weight : array-like, shape (n_samples,), default=None
Weights applied to individual samples.
If not provided, uniform weights are assumed.</p>
<h2 id="returns_171">Returns<a class="headerlink" href="#returns_171" title="Permanent link">&para;</a></h2>
<p>self : returns an instance of self.</p>
<div class="highlight"><pre><span></span><code><span class="k">val</span> <span class="n">predict</span> <span class="o">:</span> <span class="n">x</span><span class="o">:[&gt;`</span><span class="nc">ArrayLike</span><span class="o">]</span> <span class="nn">Np</span><span class="p">.</span><span class="nn">Obj</span><span class="p">.</span><span class="n">t</span> <span class="o">-&gt;</span> <span class="o">[&gt;</span> <span class="n">tag</span><span class="o">]</span> <span class="nn">Obj</span><span class="p">.</span><span class="n">t</span> <span class="o">-&gt;</span> <span class="o">[&gt;`</span><span class="nc">ArrayLike</span><span class="o">]</span> <span class="nn">Np</span><span class="p">.</span><span class="nn">Obj</span><span class="p">.</span><span class="n">t</span>
</code></pre></div>

<p>Predict using the linear model</p>
<h2 id="parameters_199">Parameters<a class="headerlink" href="#parameters_199" title="Permanent link">&para;</a></h2>
<p>X : {array-like, sparse matrix}, shape (n_samples, n_features)</p>
<h2 id="returns_172">Returns<a class="headerlink" href="#returns_172" title="Permanent link">&para;</a></h2>
<p>ndarray of shape (n_samples,)
Predicted target values per element in X.</p>
<div class="highlight"><pre><span></span><code><span class="k">val</span> <span class="n">score</span> <span class="o">:</span> <span class="o">?</span><span class="n">sample_weight</span><span class="o">:[&gt;`</span><span class="nc">ArrayLike</span><span class="o">]</span> <span class="nn">Np</span><span class="p">.</span><span class="nn">Obj</span><span class="p">.</span><span class="n">t</span> <span class="o">-&gt;</span> <span class="n">x</span><span class="o">:[&gt;`</span><span class="nc">ArrayLike</span><span class="o">]</span> <span class="nn">Np</span><span class="p">.</span><span class="nn">Obj</span><span class="p">.</span><span class="n">t</span> <span class="o">-&gt;</span> <span class="n">y</span><span class="o">:[&gt;`</span><span class="nc">ArrayLike</span><span class="o">]</span> <span class="nn">Np</span><span class="p">.</span><span class="nn">Obj</span><span class="p">.</span><span class="n">t</span> <span class="o">-&gt;</span> <span class="o">[&gt;</span> <span class="n">tag</span><span class="o">]</span> <span class="nn">Obj</span><span class="p">.</span><span class="n">t</span> <span class="o">-&gt;</span> <span class="kt">float</span>
</code></pre></div>

<p>Return the coefficient of determination R^2 of the prediction.</p>
<p>The coefficient R^2 is defined as (1 - u/v), where u is the residual
sum of squares ((y_true - y_pred) <strong> 2).sum() and v is the total
sum of squares ((y_true - y_true.mean()) </strong> 2).sum().
The best possible score is 1.0 and it can be negative (because the
model can be arbitrarily worse). A constant model that always
predicts the expected value of y, disregarding the input features,
would get a R^2 score of 0.0.</p>
<h2 id="parameters_200">Parameters<a class="headerlink" href="#parameters_200" title="Permanent link">&para;</a></h2>
<p>X : array-like of shape (n_samples, n_features)
Test samples. For some estimators this may be a
precomputed kernel matrix or a list of generic objects instead,
shape = (n_samples, n_samples_fitted),
where n_samples_fitted is the number of
samples used in the fitting for the estimator.</p>
<p>y : array-like of shape (n_samples,) or (n_samples, n_outputs)
True values for X.</p>
<p>sample_weight : array-like of shape (n_samples,), default=None
Sample weights.</p>
<h2 id="returns_173">Returns<a class="headerlink" href="#returns_173" title="Permanent link">&para;</a></h2>
<p>score : float
R^2 of self.predict(X) wrt. y.</p>
<h2 id="notes_52">Notes<a class="headerlink" href="#notes_52" title="Permanent link">&para;</a></h2>
<p>The R2 score used when calling <code>score</code> on a regressor will use
<code>multioutput='uniform_average'</code> from version 0.23 to keep consistent
with :func:<code>~sklearn.metrics.r2_score</code>. This will influence the
<code>score</code> method of all the multioutput regressors (except for
:class:<code>~sklearn.multioutput.MultiOutputRegressor</code>). To specify the
default value manually and avoid the warning, please either call
:func:<code>~sklearn.metrics.r2_score</code> directly or make a custom scorer with
:func:<code>~sklearn.metrics.make_scorer</code> (the built-in scorer <code>'r2'</code> uses
<code>multioutput='uniform_average'</code>).</p>
<div class="highlight"><pre><span></span><code><span class="k">val</span> <span class="n">set_params</span> <span class="o">:</span> <span class="o">?</span><span class="n">kwargs</span><span class="o">:(</span><span class="kt">string</span> <span class="o">*</span> <span class="nn">Py</span><span class="p">.</span><span class="nn">Object</span><span class="p">.</span><span class="n">t</span><span class="o">)</span> <span class="kt">list</span> <span class="o">-&gt;</span> <span class="o">[&gt;</span> <span class="n">tag</span><span class="o">]</span> <span class="nn">Obj</span><span class="p">.</span><span class="n">t</span> <span class="o">-&gt;</span> <span class="n">t</span>
</code></pre></div>

<p>Set and validate the parameters of estimator.</p>
<h2 id="parameters_201">Parameters<a class="headerlink" href="#parameters_201" title="Permanent link">&para;</a></h2>
<p>**kwargs : dict
Estimator parameters.</p>
<h2 id="returns_174">Returns<a class="headerlink" href="#returns_174" title="Permanent link">&para;</a></h2>
<p>self : object
Estimator instance.</p>
<div class="highlight"><pre><span></span><code><span class="k">val</span> <span class="n">sparsify</span> <span class="o">:</span> <span class="o">[&gt;</span> <span class="n">tag</span><span class="o">]</span> <span class="nn">Obj</span><span class="p">.</span><span class="n">t</span> <span class="o">-&gt;</span> <span class="n">t</span>
</code></pre></div>

<p>Convert coefficient matrix to sparse format.</p>
<p>Converts the <code>coef_</code> member to a scipy.sparse matrix, which for
L1-regularized models can be much more memory- and storage-efficient
than the usual numpy.ndarray representation.</p>
<p>The <code>intercept_</code> member is not converted.</p>
<h2 id="returns_175">Returns<a class="headerlink" href="#returns_175" title="Permanent link">&para;</a></h2>
<p>self
Fitted estimator.</p>
<h2 id="notes_53">Notes<a class="headerlink" href="#notes_53" title="Permanent link">&para;</a></h2>
<p>For non-sparse models, i.e. when there are not many zeros in <code>coef_</code>,
this may actually <em>increase</em> memory usage, so use this method with
care. A rule of thumb is that the number of zero elements, which can
be computed with <code>(coef_ == 0).sum()</code>, must be more than 50% for this
to provide significant benefits.</p>
<p>After calling this method, further fitting with the partial_fit
method (if any) will not work until you call densify.</p>
<p>Attribute coef_: get value or raise Not_found if None.</p>
<div class="highlight"><pre><span></span><code><span class="k">val</span> <span class="n">coef_</span> <span class="o">:</span> <span class="n">t</span> <span class="o">-&gt;</span> <span class="o">[&gt;`</span><span class="nc">ArrayLike</span><span class="o">]</span> <span class="nn">Np</span><span class="p">.</span><span class="nn">Obj</span><span class="p">.</span><span class="n">t</span>
</code></pre></div>

<p>Attribute coef_: get value as an option.</p>
<div class="highlight"><pre><span></span><code><span class="k">val</span> <span class="n">coef_opt</span> <span class="o">:</span> <span class="n">t</span> <span class="o">-&gt;</span> <span class="o">([&gt;`</span><span class="nc">ArrayLike</span><span class="o">]</span> <span class="nn">Np</span><span class="p">.</span><span class="nn">Obj</span><span class="p">.</span><span class="n">t</span><span class="o">)</span> <span class="n">option</span>
</code></pre></div>

<p>Attribute intercept_: get value or raise Not_found if None.</p>
<div class="highlight"><pre><span></span><code><span class="k">val</span> <span class="n">intercept_</span> <span class="o">:</span> <span class="n">t</span> <span class="o">-&gt;</span> <span class="o">[&gt;`</span><span class="nc">ArrayLike</span><span class="o">]</span> <span class="nn">Np</span><span class="p">.</span><span class="nn">Obj</span><span class="p">.</span><span class="n">t</span>
</code></pre></div>

<p>Attribute intercept_: get value as an option.</p>
<div class="highlight"><pre><span></span><code><span class="k">val</span> <span class="n">intercept_opt</span> <span class="o">:</span> <span class="n">t</span> <span class="o">-&gt;</span> <span class="o">([&gt;`</span><span class="nc">ArrayLike</span><span class="o">]</span> <span class="nn">Np</span><span class="p">.</span><span class="nn">Obj</span><span class="p">.</span><span class="n">t</span><span class="o">)</span> <span class="n">option</span>
</code></pre></div>

<p>Attribute average_coef_: get value or raise Not_found if None.</p>
<div class="highlight"><pre><span></span><code><span class="k">val</span> <span class="n">average_coef_</span> <span class="o">:</span> <span class="n">t</span> <span class="o">-&gt;</span> <span class="o">[&gt;`</span><span class="nc">ArrayLike</span><span class="o">]</span> <span class="nn">Np</span><span class="p">.</span><span class="nn">Obj</span><span class="p">.</span><span class="n">t</span>
</code></pre></div>

<p>Attribute average_coef_: get value as an option.</p>
<div class="highlight"><pre><span></span><code><span class="k">val</span> <span class="n">average_coef_opt</span> <span class="o">:</span> <span class="n">t</span> <span class="o">-&gt;</span> <span class="o">([&gt;`</span><span class="nc">ArrayLike</span><span class="o">]</span> <span class="nn">Np</span><span class="p">.</span><span class="nn">Obj</span><span class="p">.</span><span class="n">t</span><span class="o">)</span> <span class="n">option</span>
</code></pre></div>

<p>Attribute average_intercept_: get value or raise Not_found if None.</p>
<div class="highlight"><pre><span></span><code><span class="k">val</span> <span class="n">average_intercept_</span> <span class="o">:</span> <span class="n">t</span> <span class="o">-&gt;</span> <span class="o">[&gt;`</span><span class="nc">ArrayLike</span><span class="o">]</span> <span class="nn">Np</span><span class="p">.</span><span class="nn">Obj</span><span class="p">.</span><span class="n">t</span>
</code></pre></div>

<p>Attribute average_intercept_: get value as an option.</p>
<div class="highlight"><pre><span></span><code><span class="k">val</span> <span class="n">average_intercept_opt</span> <span class="o">:</span> <span class="n">t</span> <span class="o">-&gt;</span> <span class="o">([&gt;`</span><span class="nc">ArrayLike</span><span class="o">]</span> <span class="nn">Np</span><span class="p">.</span><span class="nn">Obj</span><span class="p">.</span><span class="n">t</span><span class="o">)</span> <span class="n">option</span>
</code></pre></div>

<p>Attribute n_iter_: get value or raise Not_found if None.</p>
<div class="highlight"><pre><span></span><code><span class="k">val</span> <span class="n">n_iter_</span> <span class="o">:</span> <span class="n">t</span> <span class="o">-&gt;</span> <span class="kt">int</span>
</code></pre></div>

<p>Attribute n_iter_: get value as an option.</p>
<div class="highlight"><pre><span></span><code><span class="k">val</span> <span class="n">n_iter_opt</span> <span class="o">:</span> <span class="n">t</span> <span class="o">-&gt;</span> <span class="o">(</span><span class="kt">int</span><span class="o">)</span> <span class="n">option</span>
</code></pre></div>

<p>Attribute t_: get value or raise Not_found if None.</p>
<div class="highlight"><pre><span></span><code><span class="k">val</span> <span class="n">t_</span> <span class="o">:</span> <span class="n">t</span> <span class="o">-&gt;</span> <span class="kt">int</span>
</code></pre></div>

<p>Attribute t_: get value as an option.</p>
<div class="highlight"><pre><span></span><code><span class="k">val</span> <span class="n">t_opt</span> <span class="o">:</span> <span class="n">t</span> <span class="o">-&gt;</span> <span class="o">(</span><span class="kt">int</span><span class="o">)</span> <span class="n">option</span>
</code></pre></div>

<p>Print the object to a human-readable representation.</p>
<div class="highlight"><pre><span></span><code><span class="k">val</span> <span class="n">to_string</span> <span class="o">:</span> <span class="n">t</span> <span class="o">-&gt;</span> <span class="kt">string</span>
</code></pre></div>

<p>Print the object to a human-readable representation.</p>
<div class="highlight"><pre><span></span><code><span class="k">val</span> <span class="n">show</span> <span class="o">:</span> <span class="n">t</span> <span class="o">-&gt;</span> <span class="kt">string</span>
</code></pre></div>

<p>Pretty-print the object to a formatter.</p>
<div class="highlight"><pre><span></span><code><span class="k">val</span> <span class="n">pp</span> <span class="o">:</span> <span class="nn">Format</span><span class="p">.</span><span class="n">formatter</span> <span class="o">-&gt;</span> <span class="n">t</span> <span class="o">-&gt;</span> <span class="kt">unit</span> <span class="o">[@@</span><span class="n">ocaml</span><span class="o">.</span><span class="n">toplevel_printer</span><span class="o">]</span>



<span class="k">module</span> <span class="nc">SquaredLoss</span> <span class="o">:</span> <span class="k">sig</span>
<span class="k">type</span> <span class="n">tag</span> <span class="o">=</span> <span class="o">[`</span><span class="nc">SquaredLoss</span><span class="o">]</span>
<span class="k">type</span> <span class="n">t</span> <span class="o">=</span> <span class="o">[`</span><span class="nc">Object</span> <span class="o">|</span> <span class="o">`</span><span class="nc">SquaredLoss</span><span class="o">]</span> <span class="nn">Obj</span><span class="p">.</span><span class="n">t</span>
<span class="k">val</span> <span class="n">of_pyobject</span> <span class="o">:</span> <span class="nn">Py</span><span class="p">.</span><span class="nn">Object</span><span class="p">.</span><span class="n">t</span> <span class="o">-&gt;</span> <span class="n">t</span>
<span class="k">val</span> <span class="n">to_pyobject</span> <span class="o">:</span> <span class="o">[&gt;</span> <span class="n">tag</span><span class="o">]</span> <span class="nn">Obj</span><span class="p">.</span><span class="n">t</span> <span class="o">-&gt;</span> <span class="nn">Py</span><span class="p">.</span><span class="nn">Object</span><span class="p">.</span><span class="n">t</span>
</code></pre></div>

<p>Print the object to a human-readable representation.</p>
<div class="highlight"><pre><span></span><code><span class="k">val</span> <span class="n">to_string</span> <span class="o">:</span> <span class="n">t</span> <span class="o">-&gt;</span> <span class="kt">string</span>
</code></pre></div>

<p>Print the object to a human-readable representation.</p>
<div class="highlight"><pre><span></span><code><span class="k">val</span> <span class="n">show</span> <span class="o">:</span> <span class="n">t</span> <span class="o">-&gt;</span> <span class="kt">string</span>
</code></pre></div>

<p>Pretty-print the object to a formatter.</p>
<div class="highlight"><pre><span></span><code><span class="k">val</span> <span class="n">pp</span> <span class="o">:</span> <span class="nn">Format</span><span class="p">.</span><span class="n">formatter</span> <span class="o">-&gt;</span> <span class="n">t</span> <span class="o">-&gt;</span> <span class="kt">unit</span> <span class="o">[@@</span><span class="n">ocaml</span><span class="o">.</span><span class="n">toplevel_printer</span><span class="o">]</span>



<span class="k">module</span> <span class="nc">TheilSenRegressor</span> <span class="o">:</span> <span class="k">sig</span>
<span class="k">type</span> <span class="n">tag</span> <span class="o">=</span> <span class="o">[`</span><span class="nc">TheilSenRegressor</span><span class="o">]</span>
<span class="k">type</span> <span class="n">t</span> <span class="o">=</span> <span class="o">[`</span><span class="nc">BaseEstimator</span> <span class="o">|</span> <span class="o">`</span><span class="nc">Object</span> <span class="o">|</span> <span class="o">`</span><span class="nc">RegressorMixin</span> <span class="o">|</span> <span class="o">`</span><span class="nc">TheilSenRegressor</span><span class="o">]</span> <span class="nn">Obj</span><span class="p">.</span><span class="n">t</span>
<span class="k">val</span> <span class="n">of_pyobject</span> <span class="o">:</span> <span class="nn">Py</span><span class="p">.</span><span class="nn">Object</span><span class="p">.</span><span class="n">t</span> <span class="o">-&gt;</span> <span class="n">t</span>
<span class="k">val</span> <span class="n">to_pyobject</span> <span class="o">:</span> <span class="o">[&gt;</span> <span class="n">tag</span><span class="o">]</span> <span class="nn">Obj</span><span class="p">.</span><span class="n">t</span> <span class="o">-&gt;</span> <span class="nn">Py</span><span class="p">.</span><span class="nn">Object</span><span class="p">.</span><span class="n">t</span>

<span class="k">val</span> <span class="n">as_regressor</span> <span class="o">:</span> <span class="n">t</span> <span class="o">-&gt;</span> <span class="o">[`</span><span class="nc">RegressorMixin</span><span class="o">]</span> <span class="nn">Obj</span><span class="p">.</span><span class="n">t</span>
<span class="k">val</span> <span class="n">as_estimator</span> <span class="o">:</span> <span class="n">t</span> <span class="o">-&gt;</span> <span class="o">[`</span><span class="nc">BaseEstimator</span><span class="o">]</span> <span class="nn">Obj</span><span class="p">.</span><span class="n">t</span>
<span class="k">val</span> <span class="n">create</span> <span class="o">:</span> <span class="o">?</span><span class="n">fit_intercept</span><span class="o">:</span><span class="kt">bool</span> <span class="o">-&gt;</span> <span class="o">?</span><span class="n">copy_X</span><span class="o">:</span><span class="kt">bool</span> <span class="o">-&gt;</span> <span class="o">?</span><span class="n">max_subpopulation</span><span class="o">:</span><span class="kt">int</span> <span class="o">-&gt;</span> <span class="o">?</span><span class="n">n_subsamples</span><span class="o">:</span><span class="kt">int</span> <span class="o">-&gt;</span> <span class="o">?</span><span class="n">max_iter</span><span class="o">:</span><span class="kt">int</span> <span class="o">-&gt;</span> <span class="o">?</span><span class="n">tol</span><span class="o">:</span><span class="kt">float</span> <span class="o">-&gt;</span> <span class="o">?</span><span class="n">random_state</span><span class="o">:</span><span class="kt">int</span> <span class="o">-&gt;</span> <span class="o">?</span><span class="n">n_jobs</span><span class="o">:</span><span class="kt">int</span> <span class="o">-&gt;</span> <span class="o">?</span><span class="n">verbose</span><span class="o">:</span><span class="kt">int</span> <span class="o">-&gt;</span> <span class="kt">unit</span> <span class="o">-&gt;</span> <span class="n">t</span>
</code></pre></div>

<p>Theil-Sen Estimator: robust multivariate regression model.</p>
<p>The algorithm calculates least square solutions on subsets with size
n_subsamples of the samples in X. Any value of n_subsamples between the
number of features and samples leads to an estimator with a compromise
between robustness and efficiency. Since the number of least square
solutions is 'n_samples choose n_subsamples', it can be extremely large
and can therefore be limited with max_subpopulation. If this limit is
reached, the subsets are chosen randomly. In a final step, the spatial
median (or L1 median) is calculated of all least square solutions.</p>
<p>Read more in the :ref:<code>User Guide &lt;theil_sen_regression&gt;</code>.</p>
<h2 id="parameters_202">Parameters<a class="headerlink" href="#parameters_202" title="Permanent link">&para;</a></h2>
<p>fit_intercept : boolean, optional, default True
Whether to calculate the intercept for this model. If set
to false, no intercept will be used in calculations.</p>
<p>copy_X : boolean, optional, default True
If True, X will be copied; else, it may be overwritten.</p>
<p>max_subpopulation : int, optional, default 1e4
Instead of computing with a set of cardinality 'n choose k', where n is
the number of samples and k is the number of subsamples (at least
number of features), consider only a stochastic subpopulation of a
given maximal size if 'n choose k' is larger than max_subpopulation.
For other than small problem sizes this parameter will determine
memory usage and runtime if n_subsamples is not changed.</p>
<p>n_subsamples : int, optional, default None
Number of samples to calculate the parameters. This is at least the
number of features (plus 1 if fit_intercept=True) and the number of
samples as a maximum. A lower number leads to a higher breakdown
point and a low efficiency while a high number leads to a low
breakdown point and a high efficiency. If None, take the
minimum number of subsamples leading to maximal robustness.
If n_subsamples is set to n_samples, Theil-Sen is identical to least
squares.</p>
<p>max_iter : int, optional, default 300
Maximum number of iterations for the calculation of spatial median.</p>
<p>tol : float, optional, default 1.e-3
Tolerance when calculating spatial median.</p>
<p>random_state : int, RandomState instance or None, optional, default None
A random number generator instance to define the state of the random
permutations generator.  If int, random_state is the seed used by the
random number generator; If RandomState instance, random_state is the
random number generator; If None, the random number generator is the
RandomState instance used by <code>np.random</code>.</p>
<p>n_jobs : int or None, optional (default=None)
Number of CPUs to use during the cross validation.
<code>None</code> means 1 unless in a :obj:<code>joblib.parallel_backend</code> context.
<code>-1</code> means using all processors. See :term:<code>Glossary &lt;n_jobs&gt;</code>
for more details.</p>
<p>verbose : boolean, optional, default False
Verbose mode when fitting the model.</p>
<h2 id="attributes_31">Attributes<a class="headerlink" href="#attributes_31" title="Permanent link">&para;</a></h2>
<p>coef_ : array, shape = (n_features)
Coefficients of the regression model (median of distribution).</p>
<p>intercept_ : float
Estimated intercept of regression model.</p>
<p>breakdown_ : float
Approximated breakdown point.</p>
<p>n_iter_ : int
Number of iterations needed for the spatial median.</p>
<p>n_subpopulation_ : int
Number of combinations taken into account from 'n choose k', where n is
the number of samples and k is the number of subsamples.</p>
<h2 id="examples_31">Examples<a class="headerlink" href="#examples_31" title="Permanent link">&para;</a></h2>
<blockquote>
<blockquote>
<blockquote>
<p>from sklearn.linear_model import TheilSenRegressor
from sklearn.datasets import make_regression
X, y = make_regression(
...     n_samples=200, n_features=2, noise=4.0, random_state=0)
reg = TheilSenRegressor(random_state=0).fit(X, y)
reg.score(X, y)
0.9884...
reg.predict(X[:1,])
array([-31.5871...])</p>
</blockquote>
</blockquote>
</blockquote>
<h2 id="references_8">References<a class="headerlink" href="#references_8" title="Permanent link">&para;</a></h2>
<ul>
<li>Theil-Sen Estimators in a Multiple Linear Regression Model, 2009
Xin Dang, Hanxiang Peng, Xueqin Wang and Heping Zhang
http://home.olemiss.edu/~xdang/papers/MTSE.pdf</li>
</ul>
<div class="highlight"><pre><span></span><code><span class="k">val</span> <span class="n">fit</span> <span class="o">:</span> <span class="n">x</span><span class="o">:[&gt;`</span><span class="nc">ArrayLike</span><span class="o">]</span> <span class="nn">Np</span><span class="p">.</span><span class="nn">Obj</span><span class="p">.</span><span class="n">t</span> <span class="o">-&gt;</span> <span class="n">y</span><span class="o">:[&gt;`</span><span class="nc">ArrayLike</span><span class="o">]</span> <span class="nn">Np</span><span class="p">.</span><span class="nn">Obj</span><span class="p">.</span><span class="n">t</span> <span class="o">-&gt;</span> <span class="o">[&gt;</span> <span class="n">tag</span><span class="o">]</span> <span class="nn">Obj</span><span class="p">.</span><span class="n">t</span> <span class="o">-&gt;</span> <span class="n">t</span>
</code></pre></div>

<p>Fit linear model.</p>
<h2 id="parameters_203">Parameters<a class="headerlink" href="#parameters_203" title="Permanent link">&para;</a></h2>
<p>X : numpy array of shape [n_samples, n_features]
Training data
y : numpy array of shape [n_samples]
Target values</p>
<h2 id="returns_176">Returns<a class="headerlink" href="#returns_176" title="Permanent link">&para;</a></h2>
<p>self : returns an instance of self.</p>
<div class="highlight"><pre><span></span><code><span class="k">val</span> <span class="n">get_params</span> <span class="o">:</span> <span class="o">?</span><span class="n">deep</span><span class="o">:</span><span class="kt">bool</span> <span class="o">-&gt;</span> <span class="o">[&gt;</span> <span class="n">tag</span><span class="o">]</span> <span class="nn">Obj</span><span class="p">.</span><span class="n">t</span> <span class="o">-&gt;</span> <span class="nn">Dict</span><span class="p">.</span><span class="n">t</span>
</code></pre></div>

<p>Get parameters for this estimator.</p>
<h2 id="parameters_204">Parameters<a class="headerlink" href="#parameters_204" title="Permanent link">&para;</a></h2>
<p>deep : bool, default=True
If True, will return the parameters for this estimator and
contained subobjects that are estimators.</p>
<h2 id="returns_177">Returns<a class="headerlink" href="#returns_177" title="Permanent link">&para;</a></h2>
<p>params : mapping of string to any
Parameter names mapped to their values.</p>
<div class="highlight"><pre><span></span><code><span class="k">val</span> <span class="n">predict</span> <span class="o">:</span> <span class="n">x</span><span class="o">:[&gt;`</span><span class="nc">ArrayLike</span><span class="o">]</span> <span class="nn">Np</span><span class="p">.</span><span class="nn">Obj</span><span class="p">.</span><span class="n">t</span> <span class="o">-&gt;</span> <span class="o">[&gt;</span> <span class="n">tag</span><span class="o">]</span> <span class="nn">Obj</span><span class="p">.</span><span class="n">t</span> <span class="o">-&gt;</span> <span class="o">[&gt;`</span><span class="nc">ArrayLike</span><span class="o">]</span> <span class="nn">Np</span><span class="p">.</span><span class="nn">Obj</span><span class="p">.</span><span class="n">t</span>
</code></pre></div>

<p>Predict using the linear model.</p>
<h2 id="parameters_205">Parameters<a class="headerlink" href="#parameters_205" title="Permanent link">&para;</a></h2>
<p>X : array_like or sparse matrix, shape (n_samples, n_features)
Samples.</p>
<h2 id="returns_178">Returns<a class="headerlink" href="#returns_178" title="Permanent link">&para;</a></h2>
<p>C : array, shape (n_samples,)
Returns predicted values.</p>
<div class="highlight"><pre><span></span><code><span class="k">val</span> <span class="n">score</span> <span class="o">:</span> <span class="o">?</span><span class="n">sample_weight</span><span class="o">:[&gt;`</span><span class="nc">ArrayLike</span><span class="o">]</span> <span class="nn">Np</span><span class="p">.</span><span class="nn">Obj</span><span class="p">.</span><span class="n">t</span> <span class="o">-&gt;</span> <span class="n">x</span><span class="o">:[&gt;`</span><span class="nc">ArrayLike</span><span class="o">]</span> <span class="nn">Np</span><span class="p">.</span><span class="nn">Obj</span><span class="p">.</span><span class="n">t</span> <span class="o">-&gt;</span> <span class="n">y</span><span class="o">:[&gt;`</span><span class="nc">ArrayLike</span><span class="o">]</span> <span class="nn">Np</span><span class="p">.</span><span class="nn">Obj</span><span class="p">.</span><span class="n">t</span> <span class="o">-&gt;</span> <span class="o">[&gt;</span> <span class="n">tag</span><span class="o">]</span> <span class="nn">Obj</span><span class="p">.</span><span class="n">t</span> <span class="o">-&gt;</span> <span class="kt">float</span>
</code></pre></div>

<p>Return the coefficient of determination R^2 of the prediction.</p>
<p>The coefficient R^2 is defined as (1 - u/v), where u is the residual
sum of squares ((y_true - y_pred) <strong> 2).sum() and v is the total
sum of squares ((y_true - y_true.mean()) </strong> 2).sum().
The best possible score is 1.0 and it can be negative (because the
model can be arbitrarily worse). A constant model that always
predicts the expected value of y, disregarding the input features,
would get a R^2 score of 0.0.</p>
<h2 id="parameters_206">Parameters<a class="headerlink" href="#parameters_206" title="Permanent link">&para;</a></h2>
<p>X : array-like of shape (n_samples, n_features)
Test samples. For some estimators this may be a
precomputed kernel matrix or a list of generic objects instead,
shape = (n_samples, n_samples_fitted),
where n_samples_fitted is the number of
samples used in the fitting for the estimator.</p>
<p>y : array-like of shape (n_samples,) or (n_samples, n_outputs)
True values for X.</p>
<p>sample_weight : array-like of shape (n_samples,), default=None
Sample weights.</p>
<h2 id="returns_179">Returns<a class="headerlink" href="#returns_179" title="Permanent link">&para;</a></h2>
<p>score : float
R^2 of self.predict(X) wrt. y.</p>
<h2 id="notes_54">Notes<a class="headerlink" href="#notes_54" title="Permanent link">&para;</a></h2>
<p>The R2 score used when calling <code>score</code> on a regressor will use
<code>multioutput='uniform_average'</code> from version 0.23 to keep consistent
with :func:<code>~sklearn.metrics.r2_score</code>. This will influence the
<code>score</code> method of all the multioutput regressors (except for
:class:<code>~sklearn.multioutput.MultiOutputRegressor</code>). To specify the
default value manually and avoid the warning, please either call
:func:<code>~sklearn.metrics.r2_score</code> directly or make a custom scorer with
:func:<code>~sklearn.metrics.make_scorer</code> (the built-in scorer <code>'r2'</code> uses
<code>multioutput='uniform_average'</code>).</p>
<div class="highlight"><pre><span></span><code><span class="k">val</span> <span class="n">set_params</span> <span class="o">:</span> <span class="o">?</span><span class="n">params</span><span class="o">:(</span><span class="kt">string</span> <span class="o">*</span> <span class="nn">Py</span><span class="p">.</span><span class="nn">Object</span><span class="p">.</span><span class="n">t</span><span class="o">)</span> <span class="kt">list</span> <span class="o">-&gt;</span> <span class="o">[&gt;</span> <span class="n">tag</span><span class="o">]</span> <span class="nn">Obj</span><span class="p">.</span><span class="n">t</span> <span class="o">-&gt;</span> <span class="n">t</span>
</code></pre></div>

<p>Set the parameters of this estimator.</p>
<p>The method works on simple estimators as well as on nested objects
(such as pipelines). The latter have parameters of the form
<code>&lt;component&gt;__&lt;parameter&gt;</code> so that it's possible to update each
component of a nested object.</p>
<h2 id="parameters_207">Parameters<a class="headerlink" href="#parameters_207" title="Permanent link">&para;</a></h2>
<p>**params : dict
Estimator parameters.</p>
<h2 id="returns_180">Returns<a class="headerlink" href="#returns_180" title="Permanent link">&para;</a></h2>
<p>self : object
Estimator instance.</p>
<p>Attribute coef_: get value or raise Not_found if None.</p>
<div class="highlight"><pre><span></span><code><span class="k">val</span> <span class="n">coef_</span> <span class="o">:</span> <span class="n">t</span> <span class="o">-&gt;</span> <span class="o">[&gt;`</span><span class="nc">ArrayLike</span><span class="o">]</span> <span class="nn">Np</span><span class="p">.</span><span class="nn">Obj</span><span class="p">.</span><span class="n">t</span>
</code></pre></div>

<p>Attribute coef_: get value as an option.</p>
<div class="highlight"><pre><span></span><code><span class="k">val</span> <span class="n">coef_opt</span> <span class="o">:</span> <span class="n">t</span> <span class="o">-&gt;</span> <span class="o">([&gt;`</span><span class="nc">ArrayLike</span><span class="o">]</span> <span class="nn">Np</span><span class="p">.</span><span class="nn">Obj</span><span class="p">.</span><span class="n">t</span><span class="o">)</span> <span class="n">option</span>
</code></pre></div>

<p>Attribute intercept_: get value or raise Not_found if None.</p>
<div class="highlight"><pre><span></span><code><span class="k">val</span> <span class="n">intercept_</span> <span class="o">:</span> <span class="n">t</span> <span class="o">-&gt;</span> <span class="o">[&gt;`</span><span class="nc">ArrayLike</span><span class="o">]</span> <span class="nn">Np</span><span class="p">.</span><span class="nn">Obj</span><span class="p">.</span><span class="n">t</span>
</code></pre></div>

<p>Attribute intercept_: get value as an option.</p>
<div class="highlight"><pre><span></span><code><span class="k">val</span> <span class="n">intercept_opt</span> <span class="o">:</span> <span class="n">t</span> <span class="o">-&gt;</span> <span class="o">([&gt;`</span><span class="nc">ArrayLike</span><span class="o">]</span> <span class="nn">Np</span><span class="p">.</span><span class="nn">Obj</span><span class="p">.</span><span class="n">t</span><span class="o">)</span> <span class="n">option</span>
</code></pre></div>

<p>Attribute breakdown_: get value or raise Not_found if None.</p>
<div class="highlight"><pre><span></span><code><span class="k">val</span> <span class="n">breakdown_</span> <span class="o">:</span> <span class="n">t</span> <span class="o">-&gt;</span> <span class="kt">float</span>
</code></pre></div>

<p>Attribute breakdown_: get value as an option.</p>
<div class="highlight"><pre><span></span><code><span class="k">val</span> <span class="n">breakdown_opt</span> <span class="o">:</span> <span class="n">t</span> <span class="o">-&gt;</span> <span class="o">(</span><span class="kt">float</span><span class="o">)</span> <span class="n">option</span>
</code></pre></div>

<p>Attribute n_iter_: get value or raise Not_found if None.</p>
<div class="highlight"><pre><span></span><code><span class="k">val</span> <span class="n">n_iter_</span> <span class="o">:</span> <span class="n">t</span> <span class="o">-&gt;</span> <span class="kt">int</span>
</code></pre></div>

<p>Attribute n_iter_: get value as an option.</p>
<div class="highlight"><pre><span></span><code><span class="k">val</span> <span class="n">n_iter_opt</span> <span class="o">:</span> <span class="n">t</span> <span class="o">-&gt;</span> <span class="o">(</span><span class="kt">int</span><span class="o">)</span> <span class="n">option</span>
</code></pre></div>

<p>Attribute n_subpopulation_: get value or raise Not_found if None.</p>
<div class="highlight"><pre><span></span><code><span class="k">val</span> <span class="n">n_subpopulation_</span> <span class="o">:</span> <span class="n">t</span> <span class="o">-&gt;</span> <span class="kt">int</span>
</code></pre></div>

<p>Attribute n_subpopulation_: get value as an option.</p>
<div class="highlight"><pre><span></span><code><span class="k">val</span> <span class="n">n_subpopulation_opt</span> <span class="o">:</span> <span class="n">t</span> <span class="o">-&gt;</span> <span class="o">(</span><span class="kt">int</span><span class="o">)</span> <span class="n">option</span>
</code></pre></div>

<p>Print the object to a human-readable representation.</p>
<div class="highlight"><pre><span></span><code><span class="k">val</span> <span class="n">to_string</span> <span class="o">:</span> <span class="n">t</span> <span class="o">-&gt;</span> <span class="kt">string</span>
</code></pre></div>

<p>Print the object to a human-readable representation.</p>
<div class="highlight"><pre><span></span><code><span class="k">val</span> <span class="n">show</span> <span class="o">:</span> <span class="n">t</span> <span class="o">-&gt;</span> <span class="kt">string</span>
</code></pre></div>

<p>Pretty-print the object to a formatter.</p>
<div class="highlight"><pre><span></span><code><span class="k">val</span> <span class="n">pp</span> <span class="o">:</span> <span class="nn">Format</span><span class="p">.</span><span class="n">formatter</span> <span class="o">-&gt;</span> <span class="n">t</span> <span class="o">-&gt;</span> <span class="kt">unit</span> <span class="o">[@@</span><span class="n">ocaml</span><span class="o">.</span><span class="n">toplevel_printer</span><span class="o">]</span>



<span class="k">val</span> <span class="n">enet_path</span> <span class="o">:</span> <span class="o">?</span><span class="n">l1_ratio</span><span class="o">:</span><span class="kt">float</span> <span class="o">-&gt;</span> <span class="o">?</span><span class="n">eps</span><span class="o">:</span><span class="kt">float</span> <span class="o">-&gt;</span> <span class="o">?</span><span class="n">n_alphas</span><span class="o">:</span><span class="kt">int</span> <span class="o">-&gt;</span> <span class="o">?</span><span class="n">alphas</span><span class="o">:[&gt;`</span><span class="nc">ArrayLike</span><span class="o">]</span> <span class="nn">Np</span><span class="p">.</span><span class="nn">Obj</span><span class="p">.</span><span class="n">t</span> <span class="o">-&gt;</span> <span class="o">?</span><span class="n">precompute</span><span class="o">:[`</span><span class="nc">Arr</span> <span class="k">of</span> <span class="o">[&gt;`</span><span class="nc">ArrayLike</span><span class="o">]</span> <span class="nn">Np</span><span class="p">.</span><span class="nn">Obj</span><span class="p">.</span><span class="n">t</span> <span class="o">|</span> <span class="o">`</span><span class="nc">Auto</span> <span class="o">|</span> <span class="o">`</span><span class="nc">Bool</span> <span class="k">of</span> <span class="kt">bool</span><span class="o">]</span> <span class="o">-&gt;</span> <span class="o">?</span><span class="n">xy</span><span class="o">:[&gt;`</span><span class="nc">ArrayLike</span><span class="o">]</span> <span class="nn">Np</span><span class="p">.</span><span class="nn">Obj</span><span class="p">.</span><span class="n">t</span> <span class="o">-&gt;</span> <span class="o">?</span><span class="n">copy_X</span><span class="o">:</span><span class="kt">bool</span> <span class="o">-&gt;</span> <span class="o">?</span><span class="n">coef_init</span><span class="o">:[&gt;`</span><span class="nc">ArrayLike</span><span class="o">]</span> <span class="nn">Np</span><span class="p">.</span><span class="nn">Obj</span><span class="p">.</span><span class="n">t</span> <span class="o">-&gt;</span> <span class="o">?</span><span class="n">verbose</span><span class="o">:</span><span class="kt">int</span> <span class="o">-&gt;</span> <span class="o">?</span><span class="n">return_n_iter</span><span class="o">:</span><span class="kt">bool</span> <span class="o">-&gt;</span> <span class="o">?</span><span class="n">positive</span><span class="o">:</span><span class="kt">bool</span> <span class="o">-&gt;</span> <span class="o">?</span><span class="n">check_input</span><span class="o">:</span><span class="kt">bool</span> <span class="o">-&gt;</span> <span class="o">?</span><span class="n">params</span><span class="o">:(</span><span class="kt">string</span> <span class="o">*</span> <span class="nn">Py</span><span class="p">.</span><span class="nn">Object</span><span class="p">.</span><span class="n">t</span><span class="o">)</span> <span class="kt">list</span> <span class="o">-&gt;</span> <span class="n">x</span><span class="o">:</span><span class="nn">Py</span><span class="p">.</span><span class="nn">Object</span><span class="p">.</span><span class="n">t</span> <span class="o">-&gt;</span> <span class="n">y</span><span class="o">:[&gt;`</span><span class="nc">ArrayLike</span><span class="o">]</span> <span class="nn">Np</span><span class="p">.</span><span class="nn">Obj</span><span class="p">.</span><span class="n">t</span> <span class="o">-&gt;</span> <span class="kt">unit</span> <span class="o">-&gt;</span> <span class="o">([&gt;`</span><span class="nc">ArrayLike</span><span class="o">]</span> <span class="nn">Np</span><span class="p">.</span><span class="nn">Obj</span><span class="p">.</span><span class="n">t</span> <span class="o">*</span> <span class="o">[&gt;`</span><span class="nc">ArrayLike</span><span class="o">]</span> <span class="nn">Np</span><span class="p">.</span><span class="nn">Obj</span><span class="p">.</span><span class="n">t</span> <span class="o">*</span> <span class="o">[&gt;`</span><span class="nc">ArrayLike</span><span class="o">]</span> <span class="nn">Np</span><span class="p">.</span><span class="nn">Obj</span><span class="p">.</span><span class="n">t</span> <span class="o">*</span> <span class="o">[&gt;`</span><span class="nc">ArrayLike</span><span class="o">]</span> <span class="nn">Np</span><span class="p">.</span><span class="nn">Obj</span><span class="p">.</span><span class="n">t</span><span class="o">)</span>
</code></pre></div>

<p>Compute elastic net path with coordinate descent.</p>
<p>The elastic net optimization function varies for mono and multi-outputs.</p>
<p>For mono-output tasks it is::</p>
<p>1 / (2 * n_samples) * ||y - Xw||^2_2
+ alpha * l1_ratio * ||w||_1
+ 0.5 * alpha * (1 - l1_ratio) * ||w||^2_2</p>
<p>For multi-output tasks it is::</p>
<p>(1 / (2 * n_samples)) * ||Y - XW||^Fro_2
+ alpha * l1_ratio * ||W||_21
+ 0.5 * alpha * (1 - l1_ratio) * ||W||_Fro^2</p>
<p>Where::</p>
<p>||W||<em>21 = \sum_i \sqrt{\sum_j w</em>{ij}^2}</p>
<p>i.e. the sum of norm of each row.</p>
<p>Read more in the :ref:<code>User Guide &lt;elastic_net&gt;</code>.</p>
<h2 id="parameters_208">Parameters<a class="headerlink" href="#parameters_208" title="Permanent link">&para;</a></h2>
<p>X : {array-like}, shape (n_samples, n_features)
Training data. Pass directly as Fortran-contiguous data to avoid
unnecessary memory duplication. If <code>y</code> is mono-output then <code>X</code>
can be sparse.</p>
<p>y : ndarray, shape (n_samples,) or (n_samples, n_outputs)
Target values.</p>
<p>l1_ratio : float, optional
Number between 0 and 1 passed to elastic net (scaling between
l1 and l2 penalties). <code>l1_ratio=1</code> corresponds to the Lasso.</p>
<p>eps : float
Length of the path. <code>eps=1e-3</code> means that
<code>alpha_min / alpha_max = 1e-3</code>.</p>
<p>n_alphas : int, optional
Number of alphas along the regularization path.</p>
<p>alphas : ndarray, optional
List of alphas where to compute the models.
If None alphas are set automatically.</p>
<p>precompute : True | False | 'auto' | array-like
Whether to use a precomputed Gram matrix to speed up
calculations. If set to <code>'auto'</code> let us decide. The Gram
matrix can also be passed as argument.</p>
<p>Xy : array-like, optional
Xy = np.dot(X.T, y) that can be precomputed. It is useful
only when the Gram matrix is precomputed.</p>
<p>copy_X : bool, optional, default True
If <code>True</code>, X will be copied; else, it may be overwritten.</p>
<p>coef_init : array, shape (n_features, ) | None
The initial values of the coefficients.</p>
<p>verbose : bool or int
Amount of verbosity.</p>
<p>return_n_iter : bool
Whether to return the number of iterations or not.</p>
<p>positive : bool, default False
If set to True, forces coefficients to be positive.
(Only allowed when <code>y.ndim == 1</code>).</p>
<p>check_input : bool, default True
Skip input validation checks, including the Gram matrix when provided
assuming there are handled by the caller when check_input=False.</p>
<p>**params : kwargs
Keyword arguments passed to the coordinate descent solver.</p>
<h2 id="returns_181">Returns<a class="headerlink" href="#returns_181" title="Permanent link">&para;</a></h2>
<p>alphas : array, shape (n_alphas,)
The alphas along the path where models are computed.</p>
<p>coefs : array, shape (n_features, n_alphas) or             (n_outputs, n_features, n_alphas)
Coefficients along the path.</p>
<p>dual_gaps : array, shape (n_alphas,)
The dual gaps at the end of the optimization for each alpha.</p>
<p>n_iters : array-like, shape (n_alphas,)
The number of iterations taken by the coordinate descent optimizer to
reach the specified tolerance for each alpha.
(Is returned when <code>return_n_iter</code> is set to True).</p>
<h2 id="see-also_27">See Also<a class="headerlink" href="#see-also_27" title="Permanent link">&para;</a></h2>
<p>MultiTaskElasticNet
MultiTaskElasticNetCV
ElasticNet
ElasticNetCV</p>
<h2 id="notes_55">Notes<a class="headerlink" href="#notes_55" title="Permanent link">&para;</a></h2>
<p>For an example, see
:ref:<code>examples/linear_model/plot_lasso_coordinate_descent_path.py
&lt;sphx_glr_auto_examples_linear_model_plot_lasso_coordinate_descent_path.py&gt;</code>.</p>
<div class="highlight"><pre><span></span><code><span class="k">val</span> <span class="n">lars_path</span> <span class="o">:</span> <span class="o">?</span><span class="n">xy</span><span class="o">:[&gt;`</span><span class="nc">ArrayLike</span><span class="o">]</span> <span class="nn">Np</span><span class="p">.</span><span class="nn">Obj</span><span class="p">.</span><span class="n">t</span> <span class="o">-&gt;</span> <span class="o">?</span><span class="n">gram</span><span class="o">:[`</span><span class="nc">Arr</span> <span class="k">of</span> <span class="o">[&gt;`</span><span class="nc">ArrayLike</span><span class="o">]</span> <span class="nn">Np</span><span class="p">.</span><span class="nn">Obj</span><span class="p">.</span><span class="n">t</span> <span class="o">|</span> <span class="o">`</span><span class="nc">Auto</span><span class="o">]</span> <span class="o">-&gt;</span> <span class="o">?</span><span class="n">max_iter</span><span class="o">:</span><span class="kt">int</span> <span class="o">-&gt;</span> <span class="o">?</span><span class="n">alpha_min</span><span class="o">:</span><span class="kt">float</span> <span class="o">-&gt;</span> <span class="o">?</span><span class="n">method_</span><span class="o">:[`</span><span class="nc">Lar</span> <span class="o">|</span> <span class="o">`</span><span class="nc">Lasso</span><span class="o">]</span> <span class="o">-&gt;</span> <span class="o">?</span><span class="n">copy_X</span><span class="o">:</span><span class="kt">bool</span> <span class="o">-&gt;</span> <span class="o">?</span><span class="n">eps</span><span class="o">:</span><span class="kt">float</span> <span class="o">-&gt;</span> <span class="o">?</span><span class="n">copy_Gram</span><span class="o">:</span><span class="kt">bool</span> <span class="o">-&gt;</span> <span class="o">?</span><span class="n">verbose</span><span class="o">:</span><span class="kt">int</span> <span class="o">-&gt;</span> <span class="o">?</span><span class="n">return_path</span><span class="o">:</span><span class="kt">bool</span> <span class="o">-&gt;</span> <span class="o">?</span><span class="n">return_n_iter</span><span class="o">:</span><span class="kt">bool</span> <span class="o">-&gt;</span> <span class="o">?</span><span class="n">positive</span><span class="o">:</span><span class="kt">bool</span> <span class="o">-&gt;</span> <span class="n">x</span><span class="o">:[`</span><span class="nc">Arr</span> <span class="k">of</span> <span class="o">[&gt;`</span><span class="nc">ArrayLike</span><span class="o">]</span> <span class="nn">Np</span><span class="p">.</span><span class="nn">Obj</span><span class="p">.</span><span class="n">t</span> <span class="o">|</span> <span class="o">`</span><span class="nc">None</span><span class="o">]</span> <span class="o">-&gt;</span> <span class="n">y</span><span class="o">:[`</span><span class="nc">Arr</span> <span class="k">of</span> <span class="o">[&gt;`</span><span class="nc">ArrayLike</span><span class="o">]</span> <span class="nn">Np</span><span class="p">.</span><span class="nn">Obj</span><span class="p">.</span><span class="n">t</span> <span class="o">|</span> <span class="o">`</span><span class="nc">None</span><span class="o">]</span> <span class="o">-&gt;</span> <span class="kt">unit</span> <span class="o">-&gt;</span> <span class="o">([&gt;`</span><span class="nc">ArrayLike</span><span class="o">]</span> <span class="nn">Np</span><span class="p">.</span><span class="nn">Obj</span><span class="p">.</span><span class="n">t</span> <span class="o">*</span> <span class="o">[&gt;`</span><span class="nc">ArrayLike</span><span class="o">]</span> <span class="nn">Np</span><span class="p">.</span><span class="nn">Obj</span><span class="p">.</span><span class="n">t</span> <span class="o">*</span> <span class="o">[&gt;`</span><span class="nc">ArrayLike</span><span class="o">]</span> <span class="nn">Np</span><span class="p">.</span><span class="nn">Obj</span><span class="p">.</span><span class="n">t</span> <span class="o">*</span> <span class="kt">int</span><span class="o">)</span>
</code></pre></div>

<p>Compute Least Angle Regression or Lasso path using LARS algorithm [1]</p>
<p>The optimization objective for the case method='lasso' is::</p>
<p>(1 / (2 * n_samples)) * ||y - Xw||^2_2 + alpha * ||w||_1</p>
<p>in the case of method='lars', the objective function is only known in
the form of an implicit equation (see discussion in [1])</p>
<p>Read more in the :ref:<code>User Guide &lt;least_angle_regression&gt;</code>.</p>
<h2 id="parameters_209">Parameters<a class="headerlink" href="#parameters_209" title="Permanent link">&para;</a></h2>
<p>X : None or array-like of shape (n_samples, n_features)
Input data. Note that if X is None then the Gram matrix must be
specified, i.e., cannot be None or False.</p>
<p>.. deprecated:: 0.21</p>
<p>The use of <code>X</code> is <code>None</code> in combination with <code>Gram</code> is not
<code>None</code> will be removed in v0.23. Use :func:<code>lars_path_gram</code>
instead.</p>
<p>y : None or array-like of shape (n_samples,)
Input targets.</p>
<p>Xy : array-like of shape (n_samples,) or (n_samples, n_targets),             default=None
Xy = np.dot(X.T, y) that can be precomputed. It is useful
only when the Gram matrix is precomputed.</p>
<p>Gram : None, 'auto', array-like of shape (n_features, n_features),             default=None
Precomputed Gram matrix (X' * X), if <code>'auto'</code>, the Gram
matrix is precomputed from the given X, if there are more samples
than features.</p>
<p>.. deprecated:: 0.21</p>
<p>The use of <code>X</code> is <code>None</code> in combination with <code>Gram</code> is not
None will be removed in v0.23. Use :func:<code>lars_path_gram</code> instead.</p>
<p>max_iter : int, default=500
Maximum number of iterations to perform, set to infinity for no limit.</p>
<p>alpha_min : float, default=0
Minimum correlation along the path. It corresponds to the
regularization parameter alpha parameter in the Lasso.</p>
<p>method : {'lar', 'lasso'}, default='lar'
Specifies the returned model. Select <code>'lar'</code> for Least Angle
Regression, <code>'lasso'</code> for the Lasso.</p>
<p>copy_X : bool, default=True
If <code>False</code>, <code>X</code> is overwritten.</p>
<p>eps : float, optional
The machine-precision regularization in the computation of the
Cholesky diagonal factors. Increase this for very ill-conditioned
systems. By default, <code>np.finfo(np.float).eps</code> is used.</p>
<p>copy_Gram : bool, default=True
If <code>False</code>, <code>Gram</code> is overwritten.</p>
<p>verbose : int, default=0
Controls output verbosity.</p>
<p>return_path : bool, default=True
If <code>return_path==True</code> returns the entire path, else returns only the
last point of the path.</p>
<p>return_n_iter : bool, default=False
Whether to return the number of iterations.</p>
<p>positive : bool, default=False
Restrict coefficients to be &gt;= 0.
This option is only allowed with method 'lasso'. Note that the model
coefficients will not converge to the ordinary-least-squares solution
for small values of alpha. Only coefficients up to the smallest alpha
value (<code>alphas_[alphas_ &gt; 0.].min()</code> when fit_path=True) reached by
the stepwise Lars-Lasso algorithm are typically in congruence with the
solution of the coordinate descent lasso_path function.</p>
<h2 id="returns_182">Returns<a class="headerlink" href="#returns_182" title="Permanent link">&para;</a></h2>
<p>alphas : array-like of shape (n_alphas + 1,)
Maximum of covariances (in absolute value) at each iteration.
<code>n_alphas</code> is either <code>max_iter</code>, <code>n_features</code> or the
number of nodes in the path with <code>alpha &gt;= alpha_min</code>, whichever
is smaller.</p>
<p>active : array-like of shape (n_alphas,)
Indices of active variables at the end of the path.</p>
<p>coefs : array-like of shape (n_features, n_alphas + 1)
Coefficients along the path</p>
<p>n_iter : int
Number of iterations run. Returned only if return_n_iter is set
to True.</p>
<h2 id="see-also_28">See also<a class="headerlink" href="#see-also_28" title="Permanent link">&para;</a></h2>
<p>lars_path_gram
lasso_path
lasso_path_gram
LassoLars
Lars
LassoLarsCV
LarsCV
sklearn.decomposition.sparse_encode</p>
<h2 id="references_9">References<a class="headerlink" href="#references_9" title="Permanent link">&para;</a></h2>
<p>.. [1] 'Least Angle Regression', Efron et al.
http://statweb.stanford.edu/~tibs/ftp/lars.pdf</p>
<p>.. [2] <code>Wikipedia entry on the Least-angle regression
&lt;https://en.wikipedia.org/wiki/Least-angle_regression&gt;</code>_</p>
<p>.. [3] <code>Wikipedia entry on the Lasso
&lt;https://en.wikipedia.org/wiki/Lasso_(statistics)&gt;</code>_</p>
<div class="highlight"><pre><span></span><code><span class="k">val</span> <span class="n">lars_path_gram</span> <span class="o">:</span> <span class="o">?</span><span class="n">max_iter</span><span class="o">:</span><span class="kt">int</span> <span class="o">-&gt;</span> <span class="o">?</span><span class="n">alpha_min</span><span class="o">:</span><span class="kt">float</span> <span class="o">-&gt;</span> <span class="o">?</span><span class="n">method_</span><span class="o">:[`</span><span class="nc">Lar</span> <span class="o">|</span> <span class="o">`</span><span class="nc">Lasso</span><span class="o">]</span> <span class="o">-&gt;</span> <span class="o">?</span><span class="n">copy_X</span><span class="o">:</span><span class="kt">bool</span> <span class="o">-&gt;</span> <span class="o">?</span><span class="n">eps</span><span class="o">:</span><span class="kt">float</span> <span class="o">-&gt;</span> <span class="o">?</span><span class="n">copy_Gram</span><span class="o">:</span><span class="kt">bool</span> <span class="o">-&gt;</span> <span class="o">?</span><span class="n">verbose</span><span class="o">:</span><span class="kt">int</span> <span class="o">-&gt;</span> <span class="o">?</span><span class="n">return_path</span><span class="o">:</span><span class="kt">bool</span> <span class="o">-&gt;</span> <span class="o">?</span><span class="n">return_n_iter</span><span class="o">:</span><span class="kt">bool</span> <span class="o">-&gt;</span> <span class="o">?</span><span class="n">positive</span><span class="o">:</span><span class="kt">bool</span> <span class="o">-&gt;</span> <span class="n">xy</span><span class="o">:[&gt;`</span><span class="nc">ArrayLike</span><span class="o">]</span> <span class="nn">Np</span><span class="p">.</span><span class="nn">Obj</span><span class="p">.</span><span class="n">t</span> <span class="o">-&gt;</span> <span class="n">gram</span><span class="o">:[&gt;`</span><span class="nc">ArrayLike</span><span class="o">]</span> <span class="nn">Np</span><span class="p">.</span><span class="nn">Obj</span><span class="p">.</span><span class="n">t</span> <span class="o">-&gt;</span> <span class="n">n_samples</span><span class="o">:[`</span><span class="nc">F</span> <span class="k">of</span> <span class="kt">float</span> <span class="o">|</span> <span class="o">`</span><span class="nc">I</span> <span class="k">of</span> <span class="kt">int</span><span class="o">]</span> <span class="o">-&gt;</span> <span class="kt">unit</span> <span class="o">-&gt;</span> <span class="o">([&gt;`</span><span class="nc">ArrayLike</span><span class="o">]</span> <span class="nn">Np</span><span class="p">.</span><span class="nn">Obj</span><span class="p">.</span><span class="n">t</span> <span class="o">*</span> <span class="o">[&gt;`</span><span class="nc">ArrayLike</span><span class="o">]</span> <span class="nn">Np</span><span class="p">.</span><span class="nn">Obj</span><span class="p">.</span><span class="n">t</span> <span class="o">*</span> <span class="o">[&gt;`</span><span class="nc">ArrayLike</span><span class="o">]</span> <span class="nn">Np</span><span class="p">.</span><span class="nn">Obj</span><span class="p">.</span><span class="n">t</span> <span class="o">*</span> <span class="kt">int</span><span class="o">)</span>
</code></pre></div>

<p>lars_path in the sufficient stats mode [1]</p>
<p>The optimization objective for the case method='lasso' is::</p>
<p>(1 / (2 * n_samples)) * ||y - Xw||^2_2 + alpha * ||w||_1</p>
<p>in the case of method='lars', the objective function is only known in
the form of an implicit equation (see discussion in [1])</p>
<p>Read more in the :ref:<code>User Guide &lt;least_angle_regression&gt;</code>.</p>
<h2 id="parameters_210">Parameters<a class="headerlink" href="#parameters_210" title="Permanent link">&para;</a></h2>
<p>Xy : array-like of shape (n_samples,) or (n_samples, n_targets)
Xy = np.dot(X.T, y).</p>
<p>Gram : array-like of shape (n_features, n_features)
Gram = np.dot(X.T * X).</p>
<p>n_samples : int or float
Equivalent size of sample.</p>
<p>max_iter : int, default=500
Maximum number of iterations to perform, set to infinity for no limit.</p>
<p>alpha_min : float, default=0
Minimum correlation along the path. It corresponds to the
regularization parameter alpha parameter in the Lasso.</p>
<p>method : {'lar', 'lasso'}, default='lar'
Specifies the returned model. Select <code>'lar'</code> for Least Angle
Regression, <code>'lasso'</code> for the Lasso.</p>
<p>copy_X : bool, default=True
If <code>False</code>, <code>X</code> is overwritten.</p>
<p>eps : float, optional
The machine-precision regularization in the computation of the
Cholesky diagonal factors. Increase this for very ill-conditioned
systems. By default, <code>np.finfo(np.float).eps</code> is used.</p>
<p>copy_Gram : bool, default=True
If <code>False</code>, <code>Gram</code> is overwritten.</p>
<p>verbose : int, default=0
Controls output verbosity.</p>
<p>return_path : bool, default=True
If <code>return_path==True</code> returns the entire path, else returns only the
last point of the path.</p>
<p>return_n_iter : bool, default=False
Whether to return the number of iterations.</p>
<p>positive : bool, default=False
Restrict coefficients to be &gt;= 0.
This option is only allowed with method 'lasso'. Note that the model
coefficients will not converge to the ordinary-least-squares solution
for small values of alpha. Only coefficients up to the smallest alpha
value (<code>alphas_[alphas_ &gt; 0.].min()</code> when fit_path=True) reached by
the stepwise Lars-Lasso algorithm are typically in congruence with the
solution of the coordinate descent lasso_path function.</p>
<h2 id="returns_183">Returns<a class="headerlink" href="#returns_183" title="Permanent link">&para;</a></h2>
<p>alphas : array-like of shape (n_alphas + 1,)
Maximum of covariances (in absolute value) at each iteration.
<code>n_alphas</code> is either <code>max_iter</code>, <code>n_features</code> or the
number of nodes in the path with <code>alpha &gt;= alpha_min</code>, whichever
is smaller.</p>
<p>active : array-like of shape (n_alphas,)
Indices of active variables at the end of the path.</p>
<p>coefs : array-like of shape (n_features, n_alphas + 1)
Coefficients along the path</p>
<p>n_iter : int
Number of iterations run. Returned only if return_n_iter is set
to True.</p>
<h2 id="see-also_29">See also<a class="headerlink" href="#see-also_29" title="Permanent link">&para;</a></h2>
<p>lars_path
lasso_path
lasso_path_gram
LassoLars
Lars
LassoLarsCV
LarsCV
sklearn.decomposition.sparse_encode</p>
<h2 id="references_10">References<a class="headerlink" href="#references_10" title="Permanent link">&para;</a></h2>
<p>.. [1] 'Least Angle Regression', Efron et al.
http://statweb.stanford.edu/~tibs/ftp/lars.pdf</p>
<p>.. [2] <code>Wikipedia entry on the Least-angle regression
&lt;https://en.wikipedia.org/wiki/Least-angle_regression&gt;</code>_</p>
<p>.. [3] <code>Wikipedia entry on the Lasso
&lt;https://en.wikipedia.org/wiki/Lasso_(statistics)&gt;</code>_</p>
<div class="highlight"><pre><span></span><code><span class="k">val</span> <span class="n">lasso_path</span> <span class="o">:</span> <span class="o">?</span><span class="n">eps</span><span class="o">:</span><span class="kt">float</span> <span class="o">-&gt;</span> <span class="o">?</span><span class="n">n_alphas</span><span class="o">:</span><span class="kt">int</span> <span class="o">-&gt;</span> <span class="o">?</span><span class="n">alphas</span><span class="o">:[&gt;`</span><span class="nc">ArrayLike</span><span class="o">]</span> <span class="nn">Np</span><span class="p">.</span><span class="nn">Obj</span><span class="p">.</span><span class="n">t</span> <span class="o">-&gt;</span> <span class="o">?</span><span class="n">precompute</span><span class="o">:[`</span><span class="nc">Arr</span> <span class="k">of</span> <span class="o">[&gt;`</span><span class="nc">ArrayLike</span><span class="o">]</span> <span class="nn">Np</span><span class="p">.</span><span class="nn">Obj</span><span class="p">.</span><span class="n">t</span> <span class="o">|</span> <span class="o">`</span><span class="nc">Auto</span> <span class="o">|</span> <span class="o">`</span><span class="nc">Bool</span> <span class="k">of</span> <span class="kt">bool</span><span class="o">]</span> <span class="o">-&gt;</span> <span class="o">?</span><span class="n">xy</span><span class="o">:[&gt;`</span><span class="nc">ArrayLike</span><span class="o">]</span> <span class="nn">Np</span><span class="p">.</span><span class="nn">Obj</span><span class="p">.</span><span class="n">t</span> <span class="o">-&gt;</span> <span class="o">?</span><span class="n">copy_X</span><span class="o">:</span><span class="kt">bool</span> <span class="o">-&gt;</span> <span class="o">?</span><span class="n">coef_init</span><span class="o">:[&gt;`</span><span class="nc">ArrayLike</span><span class="o">]</span> <span class="nn">Np</span><span class="p">.</span><span class="nn">Obj</span><span class="p">.</span><span class="n">t</span> <span class="o">-&gt;</span> <span class="o">?</span><span class="n">verbose</span><span class="o">:</span><span class="kt">int</span> <span class="o">-&gt;</span> <span class="o">?</span><span class="n">return_n_iter</span><span class="o">:</span><span class="kt">bool</span> <span class="o">-&gt;</span> <span class="o">?</span><span class="n">positive</span><span class="o">:</span><span class="kt">bool</span> <span class="o">-&gt;</span> <span class="o">?</span><span class="n">params</span><span class="o">:(</span><span class="kt">string</span> <span class="o">*</span> <span class="nn">Py</span><span class="p">.</span><span class="nn">Object</span><span class="p">.</span><span class="n">t</span><span class="o">)</span> <span class="kt">list</span> <span class="o">-&gt;</span> <span class="n">x</span><span class="o">:[&gt;`</span><span class="nc">ArrayLike</span><span class="o">]</span> <span class="nn">Np</span><span class="p">.</span><span class="nn">Obj</span><span class="p">.</span><span class="n">t</span> <span class="o">-&gt;</span> <span class="n">y</span><span class="o">:[&gt;`</span><span class="nc">ArrayLike</span><span class="o">]</span> <span class="nn">Np</span><span class="p">.</span><span class="nn">Obj</span><span class="p">.</span><span class="n">t</span> <span class="o">-&gt;</span> <span class="kt">unit</span> <span class="o">-&gt;</span> <span class="o">([&gt;`</span><span class="nc">ArrayLike</span><span class="o">]</span> <span class="nn">Np</span><span class="p">.</span><span class="nn">Obj</span><span class="p">.</span><span class="n">t</span> <span class="o">*</span> <span class="o">[&gt;`</span><span class="nc">ArrayLike</span><span class="o">]</span> <span class="nn">Np</span><span class="p">.</span><span class="nn">Obj</span><span class="p">.</span><span class="n">t</span> <span class="o">*</span> <span class="o">[&gt;`</span><span class="nc">ArrayLike</span><span class="o">]</span> <span class="nn">Np</span><span class="p">.</span><span class="nn">Obj</span><span class="p">.</span><span class="n">t</span> <span class="o">*</span> <span class="o">[&gt;`</span><span class="nc">ArrayLike</span><span class="o">]</span> <span class="nn">Np</span><span class="p">.</span><span class="nn">Obj</span><span class="p">.</span><span class="n">t</span><span class="o">)</span>
</code></pre></div>

<p>Compute Lasso path with coordinate descent</p>
<p>The Lasso optimization function varies for mono and multi-outputs.</p>
<p>For mono-output tasks it is::</p>
<p>(1 / (2 * n_samples)) * ||y - Xw||^2_2 + alpha * ||w||_1</p>
<p>For multi-output tasks it is::</p>
<p>(1 / (2 * n_samples)) * ||Y - XW||^2_Fro + alpha * ||W||_21</p>
<p>Where::</p>
<p>||W||<em>21 = \sum_i \sqrt{\sum_j w</em>{ij}^2}</p>
<p>i.e. the sum of norm of each row.</p>
<p>Read more in the :ref:<code>User Guide &lt;lasso&gt;</code>.</p>
<h2 id="parameters_211">Parameters<a class="headerlink" href="#parameters_211" title="Permanent link">&para;</a></h2>
<p>X : {array-like, sparse matrix}, shape (n_samples, n_features)
Training data. Pass directly as Fortran-contiguous data to avoid
unnecessary memory duplication. If <code>y</code> is mono-output then <code>X</code>
can be sparse.</p>
<p>y : ndarray, shape (n_samples,), or (n_samples, n_outputs)
Target values</p>
<p>eps : float, optional
Length of the path. <code>eps=1e-3</code> means that
<code>alpha_min / alpha_max = 1e-3</code></p>
<p>n_alphas : int, optional
Number of alphas along the regularization path</p>
<p>alphas : ndarray, optional
List of alphas where to compute the models.
If <code>None</code> alphas are set automatically</p>
<p>precompute : True | False | 'auto' | array-like
Whether to use a precomputed Gram matrix to speed up
calculations. If set to <code>'auto'</code> let us decide. The Gram
matrix can also be passed as argument.</p>
<p>Xy : array-like, optional
Xy = np.dot(X.T, y) that can be precomputed. It is useful
only when the Gram matrix is precomputed.</p>
<p>copy_X : boolean, optional, default True
If <code>True</code>, X will be copied; else, it may be overwritten.</p>
<p>coef_init : array, shape (n_features, ) | None
The initial values of the coefficients.</p>
<p>verbose : bool or integer
Amount of verbosity.</p>
<p>return_n_iter : bool
whether to return the number of iterations or not.</p>
<p>positive : bool, default False
If set to True, forces coefficients to be positive.
(Only allowed when <code>y.ndim == 1</code>).</p>
<p>**params : kwargs
keyword arguments passed to the coordinate descent solver.</p>
<h2 id="returns_184">Returns<a class="headerlink" href="#returns_184" title="Permanent link">&para;</a></h2>
<p>alphas : array, shape (n_alphas,)
The alphas along the path where models are computed.</p>
<p>coefs : array, shape (n_features, n_alphas) or             (n_outputs, n_features, n_alphas)
Coefficients along the path.</p>
<p>dual_gaps : array, shape (n_alphas,)
The dual gaps at the end of the optimization for each alpha.</p>
<p>n_iters : array-like, shape (n_alphas,)
The number of iterations taken by the coordinate descent optimizer to
reach the specified tolerance for each alpha.</p>
<h2 id="notes_56">Notes<a class="headerlink" href="#notes_56" title="Permanent link">&para;</a></h2>
<p>For an example, see
:ref:<code>examples/linear_model/plot_lasso_coordinate_descent_path.py
&lt;sphx_glr_auto_examples_linear_model_plot_lasso_coordinate_descent_path.py&gt;</code>.</p>
<p>To avoid unnecessary memory duplication the X argument of the fit method
should be directly passed as a Fortran-contiguous numpy array.</p>
<p>Note that in certain cases, the Lars solver may be significantly
faster to implement this functionality. In particular, linear
interpolation can be used to retrieve model coefficients between the
values output by lars_path</p>
<h2 id="examples_32">Examples<a class="headerlink" href="#examples_32" title="Permanent link">&para;</a></h2>
<p>Comparing lasso_path and lars_path with interpolation:</p>
<blockquote>
<blockquote>
<blockquote>
<p>X = np.array([[1, 2, 3.1], [2.3, 5.4, 4.3]]).T
y = np.array([1, 2, 3.1])</p>
<h1 id="use-lasso_path-to-compute-a-coefficient-path">Use lasso_path to compute a coefficient path<a class="headerlink" href="#use-lasso_path-to-compute-a-coefficient-path" title="Permanent link">&para;</a></h1>
<p>_, coef_path, _ = lasso_path(X, y, alphas=[5., 1., .5])
print(coef_path)
[[0.         0.         0.46874778]
[0.2159048  0.4425765  0.23689075]]</p>
<h1 id="now-use-lars_path-and-1d-linear-interpolation-to-compute-the">Now use lars_path and 1D linear interpolation to compute the<a class="headerlink" href="#now-use-lars_path-and-1d-linear-interpolation-to-compute-the" title="Permanent link">&para;</a></h1>
<h1 id="same-path">same path<a class="headerlink" href="#same-path" title="Permanent link">&para;</a></h1>
<p>from sklearn.linear_model import lars_path
alphas, active, coef_path_lars = lars_path(X, y, method='lasso')
from scipy import interpolate
coef_path_continuous = interpolate.interp1d(alphas[::-1],
...                                             coef_path_lars[:, ::-1])
print(coef_path_continuous([5., 1., .5]))
[[0.         0.         0.46915237]
[0.2159048  0.4425765  0.23668876]]</p>
</blockquote>
</blockquote>
</blockquote>
<h2 id="see-also_30">See also<a class="headerlink" href="#see-also_30" title="Permanent link">&para;</a></h2>
<p>lars_path
Lasso
LassoLars
LassoCV
LassoLarsCV
sklearn.decomposition.sparse_encode</p>
<div class="highlight"><pre><span></span><code><span class="k">val</span> <span class="n">logistic_regression_path</span> <span class="o">:</span> <span class="o">?</span><span class="n">pos_class</span><span class="o">:</span><span class="kt">int</span> <span class="o">-&gt;</span> <span class="o">?</span><span class="n">cs</span><span class="o">:[`</span><span class="nc">Arr</span> <span class="k">of</span> <span class="o">[&gt;`</span><span class="nc">ArrayLike</span><span class="o">]</span> <span class="nn">Np</span><span class="p">.</span><span class="nn">Obj</span><span class="p">.</span><span class="n">t</span> <span class="o">|</span> <span class="o">`</span><span class="nc">I</span> <span class="k">of</span> <span class="kt">int</span><span class="o">]</span> <span class="o">-&gt;</span> <span class="o">?</span><span class="n">fit_intercept</span><span class="o">:</span><span class="kt">bool</span> <span class="o">-&gt;</span> <span class="o">?</span><span class="n">max_iter</span><span class="o">:</span><span class="kt">int</span> <span class="o">-&gt;</span> <span class="o">?</span><span class="n">tol</span><span class="o">:</span><span class="kt">float</span> <span class="o">-&gt;</span> <span class="o">?</span><span class="n">verbose</span><span class="o">:</span><span class="kt">int</span> <span class="o">-&gt;</span> <span class="o">?</span><span class="n">solver</span><span class="o">:[`</span><span class="nc">Lbfgs</span> <span class="o">|</span> <span class="o">`</span><span class="nc">Newton_cg</span> <span class="o">|</span> <span class="o">`</span><span class="nc">Liblinear</span> <span class="o">|</span> <span class="o">`</span><span class="nc">Sag</span> <span class="o">|</span> <span class="o">`</span><span class="nc">Saga</span><span class="o">]</span> <span class="o">-&gt;</span> <span class="o">?</span><span class="n">coef</span><span class="o">:[&gt;`</span><span class="nc">ArrayLike</span><span class="o">]</span> <span class="nn">Np</span><span class="p">.</span><span class="nn">Obj</span><span class="p">.</span><span class="n">t</span> <span class="o">-&gt;</span> <span class="o">?</span><span class="n">class_weight</span><span class="o">:[`</span><span class="nc">DictIntToFloat</span> <span class="k">of</span> <span class="o">(</span><span class="kt">int</span> <span class="o">*</span> <span class="kt">float</span><span class="o">)</span> <span class="kt">list</span> <span class="o">|</span> <span class="o">`</span><span class="nc">Balanced</span><span class="o">]</span> <span class="o">-&gt;</span> <span class="o">?</span><span class="n">dual</span><span class="o">:</span><span class="kt">bool</span> <span class="o">-&gt;</span> <span class="o">?</span><span class="n">penalty</span><span class="o">:[`</span><span class="nc">L2</span> <span class="o">|</span> <span class="o">`</span><span class="nc">Elasticnet</span> <span class="o">|</span> <span class="o">`</span><span class="nc">L1</span><span class="o">]</span> <span class="o">-&gt;</span> <span class="o">?</span><span class="n">intercept_scaling</span><span class="o">:</span><span class="kt">float</span> <span class="o">-&gt;</span> <span class="o">?</span><span class="n">multi_class</span><span class="o">:[`</span><span class="nc">Ovr</span> <span class="o">|</span> <span class="o">`</span><span class="nc">Multinomial</span> <span class="o">|</span> <span class="o">`</span><span class="nc">Auto</span><span class="o">]</span> <span class="o">-&gt;</span> <span class="o">?</span><span class="n">random_state</span><span class="o">:</span><span class="kt">int</span> <span class="o">-&gt;</span> <span class="o">?</span><span class="n">check_input</span><span class="o">:</span><span class="kt">bool</span> <span class="o">-&gt;</span> <span class="o">?</span><span class="n">max_squared_sum</span><span class="o">:</span><span class="kt">float</span> <span class="o">-&gt;</span> <span class="o">?</span><span class="n">sample_weight</span><span class="o">:[&gt;`</span><span class="nc">ArrayLike</span><span class="o">]</span> <span class="nn">Np</span><span class="p">.</span><span class="nn">Obj</span><span class="p">.</span><span class="n">t</span> <span class="o">-&gt;</span> <span class="o">?</span><span class="n">l1_ratio</span><span class="o">:</span><span class="kt">float</span> <span class="o">-&gt;</span> <span class="n">x</span><span class="o">:[&gt;`</span><span class="nc">ArrayLike</span><span class="o">]</span> <span class="nn">Np</span><span class="p">.</span><span class="nn">Obj</span><span class="p">.</span><span class="n">t</span> <span class="o">-&gt;</span> <span class="n">y</span><span class="o">:[&gt;`</span><span class="nc">ArrayLike</span><span class="o">]</span> <span class="nn">Np</span><span class="p">.</span><span class="nn">Obj</span><span class="p">.</span><span class="n">t</span> <span class="o">-&gt;</span> <span class="kt">unit</span> <span class="o">-&gt;</span> <span class="o">([&gt;`</span><span class="nc">ArrayLike</span><span class="o">]</span> <span class="nn">Np</span><span class="p">.</span><span class="nn">Obj</span><span class="p">.</span><span class="n">t</span> <span class="o">*</span> <span class="o">[&gt;`</span><span class="nc">ArrayLike</span><span class="o">]</span> <span class="nn">Np</span><span class="p">.</span><span class="nn">Obj</span><span class="p">.</span><span class="n">t</span> <span class="o">*</span> <span class="o">[&gt;`</span><span class="nc">ArrayLike</span><span class="o">]</span> <span class="nn">Np</span><span class="p">.</span><span class="nn">Obj</span><span class="p">.</span><span class="n">t</span><span class="o">)</span>
</code></pre></div>

<p>DEPRECATED: logistic_regression_path was deprecated in version 0.21 and will be removed in version 0.23.0</p>
<p>Compute a Logistic Regression model for a list of regularization
parameters.</p>
<p>This is an implementation that uses the result of the previous model
to speed up computations along the set of solutions, making it faster
than sequentially calling LogisticRegression for the different parameters.
Note that there will be no speedup with liblinear solver, since it does
not handle warm-starting.</p>
<p>.. deprecated:: 0.21
<code>logistic_regression_path</code> was deprecated in version 0.21 and will
be removed in 0.23.</p>
<p>Read more in the :ref:<code>User Guide &lt;logistic_regression&gt;</code>.</p>
<h2 id="parameters_212">Parameters<a class="headerlink" href="#parameters_212" title="Permanent link">&para;</a></h2>
<p>X : array-like or sparse matrix, shape (n_samples, n_features)
Input data.</p>
<p>y : array-like, shape (n_samples,) or (n_samples, n_targets)
Input data, target values.</p>
<p>pos_class : int, None
The class with respect to which we perform a one-vs-all fit.
If None, then it is assumed that the given problem is binary.</p>
<p>Cs : int | array-like, shape (n_cs,)
List of values for the regularization parameter or integer specifying
the number of regularization parameters that should be used. In this
case, the parameters will be chosen in a logarithmic scale between
1e-4 and 1e4.</p>
<p>fit_intercept : bool
Whether to fit an intercept for the model. In this case the shape of
the returned array is (n_cs, n_features + 1).</p>
<p>max_iter : int
Maximum number of iterations for the solver.</p>
<p>tol : float
Stopping criterion. For the newton-cg and lbfgs solvers, the iteration
will stop when <code>max{ |g_i | i = 1, ..., n} &lt;= tol</code>
where <code>g_i</code> is the i-th component of the gradient.</p>
<p>verbose : int
For the liblinear and lbfgs solvers set verbose to any positive
number for verbosity.</p>
<p>solver : {'lbfgs', 'newton-cg', 'liblinear', 'sag', 'saga'}
Numerical solver to use.</p>
<p>coef : array-like, shape (n_features,), default None
Initialization value for coefficients of logistic regression.
Useless for liblinear solver.</p>
<p>class_weight : dict or 'balanced', optional
Weights associated with classes in the form <code>{class_label: weight}</code>.
If not given, all classes are supposed to have weight one.</p>
<p>The 'balanced' mode uses the values of y to automatically adjust
weights inversely proportional to class frequencies in the input data
as <code>n_samples / (n_classes * np.bincount(y))</code>.</p>
<p>Note that these weights will be multiplied with sample_weight (passed
through the fit method) if sample_weight is specified.</p>
<p>dual : bool
Dual or primal formulation. Dual formulation is only implemented for
l2 penalty with liblinear solver. Prefer dual=False when
n_samples &gt; n_features.</p>
<p>penalty : str, 'l1', 'l2', or 'elasticnet'
Used to specify the norm used in the penalization. The 'newton-cg',
'sag' and 'lbfgs' solvers support only l2 penalties. 'elasticnet' is
only supported by the 'saga' solver.</p>
<p>intercept_scaling : float, default 1.
Useful only when the solver 'liblinear' is used
and self.fit_intercept is set to True. In this case, x becomes
[x, self.intercept_scaling],
i.e. a 'synthetic' feature with constant value equal to
intercept_scaling is appended to the instance vector.
The intercept becomes <code>intercept_scaling * synthetic_feature_weight</code>.</p>
<p>Note! the synthetic feature weight is subject to l1/l2 regularization
as all other features.
To lessen the effect of regularization on synthetic feature weight
(and therefore on the intercept) intercept_scaling has to be increased.</p>
<p>multi_class : {'ovr', 'multinomial', 'auto'}, default='auto'
If the option chosen is 'ovr', then a binary problem is fit for each
label. For 'multinomial' the loss minimised is the multinomial loss fit
across the entire probability distribution, <em>even when the data is
binary</em>. 'multinomial' is unavailable when solver='liblinear'.
'auto' selects 'ovr' if the data is binary, or if solver='liblinear',
and otherwise selects 'multinomial'.</p>
<p>.. versionadded:: 0.18
Stochastic Average Gradient descent solver for 'multinomial' case.
.. versionchanged:: 0.22
Default changed from 'ovr' to 'auto' in 0.22.</p>
<p>random_state : int, RandomState instance or None, optional, default None
The seed of the pseudo random number generator to use when shuffling
the data.  If int, random_state is the seed used by the random number
generator; If RandomState instance, random_state is the random number
generator; If None, the random number generator is the RandomState
instance used by <code>np.random</code>. Used when <code>solver</code> == 'sag' or
'liblinear'.</p>
<p>check_input : bool, default True
If False, the input arrays X and y will not be checked.</p>
<p>max_squared_sum : float, default None
Maximum squared sum of X over samples. Used only in SAG solver.
If None, it will be computed, going through all the samples.
The value should be precomputed to speed up cross validation.</p>
<p>sample_weight : array-like, shape(n_samples,) optional
Array of weights that are assigned to individual samples.
If not provided, then each sample is given unit weight.</p>
<p>l1_ratio : float or None, optional (default=None)
The Elastic-Net mixing parameter, with <code>0 &lt;= l1_ratio &lt;= 1</code>. Only
used if <code>penalty='elasticnet'</code>. Setting <code>l1_ratio=0</code> is equivalent
to using <code>penalty='l2'</code>, while setting <code>l1_ratio=1</code> is equivalent
to using <code>penalty='l1'</code>. For <code>0 &lt; l1_ratio &lt;1</code>, the penalty is a
combination of L1 and L2.</p>
<h2 id="returns_185">Returns<a class="headerlink" href="#returns_185" title="Permanent link">&para;</a></h2>
<p>coefs : ndarray, shape (n_cs, n_features) or (n_cs, n_features + 1)
List of coefficients for the Logistic Regression model. If
fit_intercept is set to True then the second dimension will be
n_features + 1, where the last item represents the intercept. For
<code>multiclass='multinomial'</code>, the shape is (n_classes, n_cs,
n_features) or (n_classes, n_cs, n_features + 1).</p>
<p>Cs : ndarray
Grid of Cs used for cross-validation.</p>
<p>n_iter : array, shape (n_cs,)
Actual number of iteration for each Cs.</p>
<h2 id="notes_57">Notes<a class="headerlink" href="#notes_57" title="Permanent link">&para;</a></h2>
<p>You might get slightly different results with the solver liblinear than
with the others since this uses LIBLINEAR which penalizes the intercept.</p>
<p>.. versionchanged:: 0.19
The 'copy' parameter was removed.</p>
<div class="highlight"><pre><span></span><code><span class="k">val</span> <span class="n">orthogonal_mp</span> <span class="o">:</span> <span class="o">?</span><span class="n">n_nonzero_coefs</span><span class="o">:</span><span class="kt">int</span> <span class="o">-&gt;</span> <span class="o">?</span><span class="n">tol</span><span class="o">:</span><span class="kt">float</span> <span class="o">-&gt;</span> <span class="o">?</span><span class="n">precompute</span><span class="o">:[`</span><span class="nc">Auto</span> <span class="o">|</span> <span class="o">`</span><span class="nc">Bool</span> <span class="k">of</span> <span class="kt">bool</span><span class="o">]</span> <span class="o">-&gt;</span> <span class="o">?</span><span class="n">copy_X</span><span class="o">:</span><span class="kt">bool</span> <span class="o">-&gt;</span> <span class="o">?</span><span class="n">return_path</span><span class="o">:</span><span class="kt">bool</span> <span class="o">-&gt;</span> <span class="o">?</span><span class="n">return_n_iter</span><span class="o">:</span><span class="kt">bool</span> <span class="o">-&gt;</span> <span class="n">x</span><span class="o">:[&gt;`</span><span class="nc">ArrayLike</span><span class="o">]</span> <span class="nn">Np</span><span class="p">.</span><span class="nn">Obj</span><span class="p">.</span><span class="n">t</span> <span class="o">-&gt;</span> <span class="n">y</span><span class="o">:[&gt;`</span><span class="nc">ArrayLike</span><span class="o">]</span> <span class="nn">Np</span><span class="p">.</span><span class="nn">Obj</span><span class="p">.</span><span class="n">t</span> <span class="o">-&gt;</span> <span class="kt">unit</span> <span class="o">-&gt;</span> <span class="o">([&gt;`</span><span class="nc">ArrayLike</span><span class="o">]</span> <span class="nn">Np</span><span class="p">.</span><span class="nn">Obj</span><span class="p">.</span><span class="n">t</span> <span class="o">*</span> <span class="nn">Py</span><span class="p">.</span><span class="nn">Object</span><span class="p">.</span><span class="n">t</span><span class="o">)</span>
</code></pre></div>

<p>Orthogonal Matching Pursuit (OMP)</p>
<p>Solves n_targets Orthogonal Matching Pursuit problems.
An instance of the problem has the form:</p>
<p>When parametrized by the number of non-zero coefficients using
<code>n_nonzero_coefs</code>:
argmin ||y - X\gamma||^2 subject to ||\gamma||<em>0 &lt;= n</em>{nonzero coefs}</p>
<p>When parametrized by error using the parameter <code>tol</code>:
argmin ||\gamma||_0 subject to ||y - X\gamma||^2 &lt;= tol</p>
<p>Read more in the :ref:<code>User Guide &lt;omp&gt;</code>.</p>
<h2 id="parameters_213">Parameters<a class="headerlink" href="#parameters_213" title="Permanent link">&para;</a></h2>
<p>X : array, shape (n_samples, n_features)
Input data. Columns are assumed to have unit norm.</p>
<p>y : array, shape (n_samples,) or (n_samples, n_targets)
Input targets</p>
<p>n_nonzero_coefs : int
Desired number of non-zero entries in the solution. If None (by
default) this value is set to 10% of n_features.</p>
<p>tol : float
Maximum norm of the residual. If not None, overrides n_nonzero_coefs.</p>
<p>precompute : {True, False, 'auto'},
Whether to perform precomputations. Improves performance when n_targets
or n_samples is very large.</p>
<p>copy_X : bool, optional
Whether the design matrix X must be copied by the algorithm. A false
value is only helpful if X is already Fortran-ordered, otherwise a
copy is made anyway.</p>
<p>return_path : bool, optional. Default: False
Whether to return every value of the nonzero coefficients along the
forward path. Useful for cross-validation.</p>
<p>return_n_iter : bool, optional default False
Whether or not to return the number of iterations.</p>
<h2 id="returns_186">Returns<a class="headerlink" href="#returns_186" title="Permanent link">&para;</a></h2>
<p>coef : array, shape (n_features,) or (n_features, n_targets)
Coefficients of the OMP solution. If <code>return_path=True</code>, this contains
the whole coefficient path. In this case its shape is
(n_features, n_features) or (n_features, n_targets, n_features) and
iterating over the last axis yields coefficients in increasing order
of active features.</p>
<p>n_iters : array-like or int
Number of active features across every target. Returned only if
<code>return_n_iter</code> is set to True.</p>
<h2 id="see-also_31">See also<a class="headerlink" href="#see-also_31" title="Permanent link">&para;</a></h2>
<p>OrthogonalMatchingPursuit
orthogonal_mp_gram
lars_path
decomposition.sparse_encode</p>
<h2 id="notes_58">Notes<a class="headerlink" href="#notes_58" title="Permanent link">&para;</a></h2>
<p>Orthogonal matching pursuit was introduced in S. Mallat, Z. Zhang,
Matching pursuits with time-frequency dictionaries, IEEE Transactions on
Signal Processing, Vol. 41, No. 12. (December 1993), pp. 3397-3415.
(http://blanche.polytechnique.fr/~mallat/papiers/MallatPursuit93.pdf)</p>
<p>This implementation is based on Rubinstein, R., Zibulevsky, M. and Elad,
M., Efficient Implementation of the K-SVD Algorithm using Batch Orthogonal
Matching Pursuit Technical Report - CS Technion, April 2008.
https://www.cs.technion.ac.il/~ronrubin/Publications/KSVD-OMP-v2.pdf</p>
<div class="highlight"><pre><span></span><code><span class="k">val</span> <span class="n">orthogonal_mp_gram</span> <span class="o">:</span> <span class="o">?</span><span class="n">n_nonzero_coefs</span><span class="o">:</span><span class="kt">int</span> <span class="o">-&gt;</span> <span class="o">?</span><span class="n">tol</span><span class="o">:</span><span class="kt">float</span> <span class="o">-&gt;</span> <span class="o">?</span><span class="n">norms_squared</span><span class="o">:[&gt;`</span><span class="nc">ArrayLike</span><span class="o">]</span> <span class="nn">Np</span><span class="p">.</span><span class="nn">Obj</span><span class="p">.</span><span class="n">t</span> <span class="o">-&gt;</span> <span class="o">?</span><span class="n">copy_Gram</span><span class="o">:</span><span class="kt">bool</span> <span class="o">-&gt;</span> <span class="o">?</span><span class="n">copy_Xy</span><span class="o">:</span><span class="kt">bool</span> <span class="o">-&gt;</span> <span class="o">?</span><span class="n">return_path</span><span class="o">:</span><span class="kt">bool</span> <span class="o">-&gt;</span> <span class="o">?</span><span class="n">return_n_iter</span><span class="o">:</span><span class="kt">bool</span> <span class="o">-&gt;</span> <span class="n">gram</span><span class="o">:[&gt;`</span><span class="nc">ArrayLike</span><span class="o">]</span> <span class="nn">Np</span><span class="p">.</span><span class="nn">Obj</span><span class="p">.</span><span class="n">t</span> <span class="o">-&gt;</span> <span class="n">xy</span><span class="o">:[&gt;`</span><span class="nc">ArrayLike</span><span class="o">]</span> <span class="nn">Np</span><span class="p">.</span><span class="nn">Obj</span><span class="p">.</span><span class="n">t</span> <span class="o">-&gt;</span> <span class="kt">unit</span> <span class="o">-&gt;</span> <span class="o">([&gt;`</span><span class="nc">ArrayLike</span><span class="o">]</span> <span class="nn">Np</span><span class="p">.</span><span class="nn">Obj</span><span class="p">.</span><span class="n">t</span> <span class="o">*</span> <span class="nn">Py</span><span class="p">.</span><span class="nn">Object</span><span class="p">.</span><span class="n">t</span><span class="o">)</span>
</code></pre></div>

<p>Gram Orthogonal Matching Pursuit (OMP)</p>
<p>Solves n_targets Orthogonal Matching Pursuit problems using only
the Gram matrix X.T * X and the product X.T * y.</p>
<p>Read more in the :ref:<code>User Guide &lt;omp&gt;</code>.</p>
<h2 id="parameters_214">Parameters<a class="headerlink" href="#parameters_214" title="Permanent link">&para;</a></h2>
<p>Gram : array, shape (n_features, n_features)
Gram matrix of the input data: X.T * X</p>
<p>Xy : array, shape (n_features,) or (n_features, n_targets)
Input targets multiplied by X: X.T * y</p>
<p>n_nonzero_coefs : int
Desired number of non-zero entries in the solution. If None (by
default) this value is set to 10% of n_features.</p>
<p>tol : float
Maximum norm of the residual. If not None, overrides n_nonzero_coefs.</p>
<p>norms_squared : array-like, shape (n_targets,)
Squared L2 norms of the lines of y. Required if tol is not None.</p>
<p>copy_Gram : bool, optional
Whether the gram matrix must be copied by the algorithm. A false
value is only helpful if it is already Fortran-ordered, otherwise a
copy is made anyway.</p>
<p>copy_Xy : bool, optional
Whether the covariance vector Xy must be copied by the algorithm.
If False, it may be overwritten.</p>
<p>return_path : bool, optional. Default: False
Whether to return every value of the nonzero coefficients along the
forward path. Useful for cross-validation.</p>
<p>return_n_iter : bool, optional default False
Whether or not to return the number of iterations.</p>
<h2 id="returns_187">Returns<a class="headerlink" href="#returns_187" title="Permanent link">&para;</a></h2>
<p>coef : array, shape (n_features,) or (n_features, n_targets)
Coefficients of the OMP solution. If <code>return_path=True</code>, this contains
the whole coefficient path. In this case its shape is
(n_features, n_features) or (n_features, n_targets, n_features) and
iterating over the last axis yields coefficients in increasing order
of active features.</p>
<p>n_iters : array-like or int
Number of active features across every target. Returned only if
<code>return_n_iter</code> is set to True.</p>
<h2 id="see-also_32">See also<a class="headerlink" href="#see-also_32" title="Permanent link">&para;</a></h2>
<p>OrthogonalMatchingPursuit
orthogonal_mp
lars_path
decomposition.sparse_encode</p>
<h2 id="notes_59">Notes<a class="headerlink" href="#notes_59" title="Permanent link">&para;</a></h2>
<p>Orthogonal matching pursuit was introduced in G. Mallat, Z. Zhang,
Matching pursuits with time-frequency dictionaries, IEEE Transactions on
Signal Processing, Vol. 41, No. 12. (December 1993), pp. 3397-3415.
(http://blanche.polytechnique.fr/~mallat/papiers/MallatPursuit93.pdf)</p>
<p>This implementation is based on Rubinstein, R., Zibulevsky, M. and Elad,
M., Efficient Implementation of the K-SVD Algorithm using Batch Orthogonal
Matching Pursuit Technical Report - CS Technion, April 2008.
https://www.cs.technion.ac.il/~ronrubin/Publications/KSVD-OMP-v2.pdf</p>
<div class="highlight"><pre><span></span><code><span class="k">val</span> <span class="n">ridge_regression</span> <span class="o">:</span> <span class="o">?</span><span class="n">sample_weight</span><span class="o">:[&gt;`</span><span class="nc">ArrayLike</span><span class="o">]</span> <span class="nn">Np</span><span class="p">.</span><span class="nn">Obj</span><span class="p">.</span><span class="n">t</span> <span class="o">-&gt;</span> <span class="o">?</span><span class="n">solver</span><span class="o">:[`</span><span class="nc">Auto</span> <span class="o">|</span> <span class="o">`</span><span class="nc">Svd</span> <span class="o">|</span> <span class="o">`</span><span class="nc">Cholesky</span> <span class="o">|</span> <span class="o">`</span><span class="nc">Lsqr</span> <span class="o">|</span> <span class="o">`</span><span class="nc">Sparse_cg</span> <span class="o">|</span> <span class="o">`</span><span class="nc">Sag</span> <span class="o">|</span> <span class="o">`</span><span class="nc">Saga</span><span class="o">]</span> <span class="o">-&gt;</span> <span class="o">?</span><span class="n">max_iter</span><span class="o">:</span><span class="kt">int</span> <span class="o">-&gt;</span> <span class="o">?</span><span class="n">tol</span><span class="o">:</span><span class="kt">float</span> <span class="o">-&gt;</span> <span class="o">?</span><span class="n">verbose</span><span class="o">:</span><span class="kt">int</span> <span class="o">-&gt;</span> <span class="o">?</span><span class="n">random_state</span><span class="o">:</span><span class="kt">int</span> <span class="o">-&gt;</span> <span class="o">?</span><span class="n">return_n_iter</span><span class="o">:</span><span class="kt">bool</span> <span class="o">-&gt;</span> <span class="o">?</span><span class="n">return_intercept</span><span class="o">:</span><span class="kt">bool</span> <span class="o">-&gt;</span> <span class="o">?</span><span class="n">check_input</span><span class="o">:</span><span class="kt">bool</span> <span class="o">-&gt;</span> <span class="n">x</span><span class="o">:[`</span><span class="nc">Arr</span> <span class="k">of</span> <span class="o">[&gt;`</span><span class="nc">ArrayLike</span><span class="o">]</span> <span class="nn">Np</span><span class="p">.</span><span class="nn">Obj</span><span class="p">.</span><span class="n">t</span> <span class="o">|</span> <span class="o">`</span><span class="nc">LinearOperator</span> <span class="k">of</span> <span class="nn">Py</span><span class="p">.</span><span class="nn">Object</span><span class="p">.</span><span class="n">t</span><span class="o">]</span> <span class="o">-&gt;</span> <span class="n">y</span><span class="o">:[&gt;`</span><span class="nc">ArrayLike</span><span class="o">]</span> <span class="nn">Np</span><span class="p">.</span><span class="nn">Obj</span><span class="p">.</span><span class="n">t</span> <span class="o">-&gt;</span> <span class="n">alpha</span><span class="o">:[&gt;`</span><span class="nc">ArrayLike</span><span class="o">]</span> <span class="nn">Np</span><span class="p">.</span><span class="nn">Obj</span><span class="p">.</span><span class="n">t</span> <span class="o">-&gt;</span> <span class="kt">unit</span> <span class="o">-&gt;</span> <span class="o">([&gt;`</span><span class="nc">ArrayLike</span><span class="o">]</span> <span class="nn">Np</span><span class="p">.</span><span class="nn">Obj</span><span class="p">.</span><span class="n">t</span> <span class="o">*</span> <span class="kt">int</span> <span class="o">*</span> <span class="o">[&gt;`</span><span class="nc">ArrayLike</span><span class="o">]</span> <span class="nn">Np</span><span class="p">.</span><span class="nn">Obj</span><span class="p">.</span><span class="n">t</span><span class="o">)</span>
</code></pre></div>

<p>Solve the ridge equation by the method of normal equations.</p>
<p>Read more in the :ref:<code>User Guide &lt;ridge_regression&gt;</code>.</p>
<h2 id="parameters_215">Parameters<a class="headerlink" href="#parameters_215" title="Permanent link">&para;</a></h2>
<p>X : {ndarray, sparse matrix, LinearOperator} of shape         (n_samples, n_features)
Training data</p>
<p>y : ndarray of shape (n_samples,) or (n_samples, n_targets)
Target values</p>
<p>alpha : float or array-like of shape (n_targets,)
Regularization strength; must be a positive float. Regularization
improves the conditioning of the problem and reduces the variance of
the estimates. Larger values specify stronger regularization.
Alpha corresponds to <code>C^-1</code> in other linear models such as
LogisticRegression or LinearSVC. If an array is passed, penalties are
assumed to be specific to the targets. Hence they must correspond in
number.</p>
<p>sample_weight : float or array-like of shape (n_samples,), default=None
Individual weights for each sample. If given a float, every sample
will have the same weight. If sample_weight is not None and
solver='auto', the solver will be set to 'cholesky'.</p>
<p>.. versionadded:: 0.17</p>
<p>solver : {'auto', 'svd', 'cholesky', 'lsqr', 'sparse_cg', 'sag', 'saga'},         default='auto'
Solver to use in the computational routines:</p>
<ul>
<li>
<p>'auto' chooses the solver automatically based on the type of data.</p>
</li>
<li>
<p>'svd' uses a Singular Value Decomposition of X to compute the Ridge
coefficients. More stable for singular matrices than
'cholesky'.</p>
</li>
<li>
<p>'cholesky' uses the standard scipy.linalg.solve function to
obtain a closed-form solution via a Cholesky decomposition of
dot(X.T, X)</p>
</li>
<li>
<p>'sparse_cg' uses the conjugate gradient solver as found in
scipy.sparse.linalg.cg. As an iterative algorithm, this solver is
more appropriate than 'cholesky' for large-scale data
(possibility to set <code>tol</code> and <code>max_iter</code>).</p>
</li>
<li>
<p>'lsqr' uses the dedicated regularized least-squares routine
scipy.sparse.linalg.lsqr. It is the fastest and uses an iterative
procedure.</p>
</li>
<li>
<p>'sag' uses a Stochastic Average Gradient descent, and 'saga' uses
its improved, unbiased version named SAGA. Both methods also use an
iterative procedure, and are often faster than other solvers when
both n_samples and n_features are large. Note that 'sag' and
'saga' fast convergence is only guaranteed on features with
approximately the same scale. You can preprocess the data with a
scaler from sklearn.preprocessing.</p>
</li>
</ul>
<p>All last five solvers support both dense and sparse data. However, only
'sag' and 'sparse_cg' supports sparse input when<code>fit_intercept</code> is
True.</p>
<p>.. versionadded:: 0.17
Stochastic Average Gradient descent solver.
.. versionadded:: 0.19
SAGA solver.</p>
<p>max_iter : int, default=None
Maximum number of iterations for conjugate gradient solver.
For the 'sparse_cg' and 'lsqr' solvers, the default value is determined
by scipy.sparse.linalg. For 'sag' and saga solver, the default value is
1000.</p>
<p>tol : float, default=1e-3
Precision of the solution.</p>
<p>verbose : int, default=0
Verbosity level. Setting verbose &gt; 0 will display additional
information depending on the solver used.</p>
<p>random_state : int, RandomState instance, default=None
The seed of the pseudo random number generator to use when shuffling
the data.  If int, random_state is the seed used by the random number
generator; If RandomState instance, random_state is the random number
generator; If None, the random number generator is the RandomState
instance used by <code>np.random</code>. Used when <code>solver</code> == 'sag'.</p>
<p>return_n_iter : bool, default=False
If True, the method also returns <code>n_iter</code>, the actual number of
iteration performed by the solver.</p>
<p>.. versionadded:: 0.17</p>
<p>return_intercept : bool, default=False
If True and if X is sparse, the method also returns the intercept,
and the solver is automatically changed to 'sag'. This is only a
temporary fix for fitting the intercept with sparse data. For dense
data, use sklearn.linear_model._preprocess_data before your regression.</p>
<p>.. versionadded:: 0.17</p>
<p>check_input : bool, default=True
If False, the input arrays X and y will not be checked.</p>
<p>.. versionadded:: 0.21</p>
<h2 id="returns_188">Returns<a class="headerlink" href="#returns_188" title="Permanent link">&para;</a></h2>
<p>coef : ndarray of shape (n_features,) or (n_targets, n_features)
Weight vector(s).</p>
<p>n_iter : int, optional
The actual number of iteration performed by the solver.
Only returned if <code>return_n_iter</code> is True.</p>
<p>intercept : float or ndarray of shape (n_targets,)
The intercept of the model. Only returned if <code>return_intercept</code>
is True and if X is a scipy sparse array.</p>
<h2 id="notes_60">Notes<a class="headerlink" href="#notes_60" title="Permanent link">&para;</a></h2>
<p>This function won't compute the intercept.</p>
                
              
              
                


              
            </article>
          </div>
        </div>
      </main>
      
        
<footer class="md-footer">
  
    <div class="md-footer-nav">
      <nav class="md-footer-nav__inner md-grid" aria-label="Footer">
        
          <a href="../Kernel_ridge/" title="Kernel ridge" class="md-footer-nav__link md-footer-nav__link--prev" rel="prev">
            <div class="md-footer-nav__button md-icon">
              <svg xmlns="http://www.w3.org/2000/svg" viewBox="0 0 24 24"><path d="M20 11v2H8l5.5 5.5-1.42 1.42L4.16 12l7.92-7.92L13.5 5.5 8 11h12z"/></svg>
            </div>
            <div class="md-footer-nav__title">
              <div class="md-ellipsis">
                <span class="md-footer-nav__direction">
                  Previous
                </span>
                Kernel ridge
              </div>
            </div>
          </a>
        
        
          <a href="../Manifold/" title="Manifold" class="md-footer-nav__link md-footer-nav__link--next" rel="next">
            <div class="md-footer-nav__title">
              <div class="md-ellipsis">
                <span class="md-footer-nav__direction">
                  Next
                </span>
                Manifold
              </div>
            </div>
            <div class="md-footer-nav__button md-icon">
              <svg xmlns="http://www.w3.org/2000/svg" viewBox="0 0 24 24"><path d="M4 11v2h12l-5.5 5.5 1.42 1.42L19.84 12l-7.92-7.92L10.5 5.5 16 11H4z"/></svg>
            </div>
          </a>
        
      </nav>
    </div>
  
  <div class="md-footer-meta md-typeset">
    <div class="md-footer-meta__inner md-grid">
      <div class="md-footer-copyright">
        
        Made with
        <a href="https://squidfunk.github.io/mkdocs-material/" target="_blank" rel="noopener">
          Material for MkDocs
        </a>
      </div>
      
    </div>
  </div>
</footer>
      
    </div>
    
      <script src="../../assets/javascripts/vendor.d710d30a.min.js"></script>
      <script src="../../assets/javascripts/bundle.a45f732b.min.js"></script><script id="__lang" type="application/json">{"clipboard.copy": "Copy to clipboard", "clipboard.copied": "Copied to clipboard", "search.config.lang": "en", "search.config.pipeline": "trimmer, stopWordFilter", "search.config.separator": "[\\s\\-]+", "search.result.placeholder": "Type to start searching", "search.result.none": "No matching documents", "search.result.one": "1 matching document", "search.result.other": "# matching documents"}</script>
      
      <script>
        app = initialize({
          base: "../..",
          features: ["instant", "tabs"],
          search: Object.assign({
            worker: "../../assets/javascripts/worker/search.c03f0417.min.js"
          }, typeof search !== "undefined" && search)
        })
      </script>
      
        <script src="https://cdnjs.cloudflare.com/ajax/libs/mathjax/2.7.0/MathJax.js?config=TeX-MML-AM_CHTML"></script>
      
    
  </body>
</html>