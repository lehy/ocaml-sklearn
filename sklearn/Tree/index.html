
<!doctype html>
<html lang="en" class="no-js">
  <head>
    
      <meta charset="utf-8">
      <meta name="viewport" content="width=device-width,initial-scale=1">
      
      
      
      
      <link rel="shortcut icon" href="../../assets/images/favicon.png">
      <meta name="generator" content="mkdocs-1.1.2, mkdocs-material-6.1.7">
    
    
      
        <title>Tree - OCaml scikit-learn interface</title>
      
    
    
      <link rel="stylesheet" href="../../assets/stylesheets/main.19753c6b.min.css">
      
        
        <link rel="stylesheet" href="../../assets/stylesheets/palette.196e0c26.min.css">
        
          
          
          <meta name="theme-color" content="#4051b5">
        
      
    
    
    
      
        
        <link href="https://fonts.gstatic.com" rel="preconnect" crossorigin>
        <link rel="stylesheet" href="https://fonts.googleapis.com/css?family=Roboto:300,400,400i,700%7CRoboto+Mono&display=fallback">
        <style>body,input{font-family:"Roboto",-apple-system,BlinkMacSystemFont,Helvetica,Arial,sans-serif}code,kbd,pre{font-family:"Roboto Mono",SFMono-Regular,Consolas,Menlo,monospace}</style>
      
    
    
    
    
      
    
    
  </head>
  
  
    
    
    
    
    
    <body dir="ltr" data-md-color-scheme="" data-md-color-primary="indigo" data-md-color-accent="indigo">
      
  
    <input class="md-toggle" data-md-toggle="drawer" type="checkbox" id="__drawer" autocomplete="off">
    <input class="md-toggle" data-md-toggle="search" type="checkbox" id="__search" autocomplete="off">
    <label class="md-overlay" for="__drawer"></label>
    <div data-md-component="skip">
      
        
        <a href="#basedecisiontree" class="md-skip">
          Skip to content
        </a>
      
    </div>
    <div data-md-component="announce">
      
    </div>
    
      

<header class="md-header" data-md-component="header">
  <nav class="md-header-nav md-grid" aria-label="Header">
    <a href="../.." title="OCaml scikit-learn interface" class="md-header-nav__button md-logo" aria-label="OCaml scikit-learn interface">
      
  
  <svg xmlns="http://www.w3.org/2000/svg" viewBox="0 0 24 24"><path d="M12 8a3 3 0 003-3 3 3 0 00-3-3 3 3 0 00-3 3 3 3 0 003 3m0 3.54C9.64 9.35 6.5 8 3 8v11c3.5 0 6.64 1.35 9 3.54 2.36-2.19 5.5-3.54 9-3.54V8c-3.5 0-6.64 1.35-9 3.54z"/></svg>

    </a>
    <label class="md-header-nav__button md-icon" for="__drawer">
      <svg xmlns="http://www.w3.org/2000/svg" viewBox="0 0 24 24"><path d="M3 6h18v2H3V6m0 5h18v2H3v-2m0 5h18v2H3v-2z"/></svg>
    </label>
    <div class="md-header-nav__title" data-md-component="header-title">
      
        <div class="md-header-nav__ellipsis">
          <span class="md-header-nav__topic md-ellipsis">
            OCaml scikit-learn interface
          </span>
          <span class="md-header-nav__topic md-ellipsis">
            
              Tree
            
          </span>
        </div>
      
    </div>
    
      <label class="md-header-nav__button md-icon" for="__search">
        <svg xmlns="http://www.w3.org/2000/svg" viewBox="0 0 24 24"><path d="M9.5 3A6.5 6.5 0 0116 9.5c0 1.61-.59 3.09-1.56 4.23l.27.27h.79l5 5-1.5 1.5-5-5v-.79l-.27-.27A6.516 6.516 0 019.5 16 6.5 6.5 0 013 9.5 6.5 6.5 0 019.5 3m0 2C7 5 5 7 5 9.5S7 14 9.5 14 14 12 14 9.5 12 5 9.5 5z"/></svg>
      </label>
      
<div class="md-search" data-md-component="search" role="dialog">
  <label class="md-search__overlay" for="__search"></label>
  <div class="md-search__inner" role="search">
    <form class="md-search__form" name="search">
      <input type="text" class="md-search__input" name="query" aria-label="Search" placeholder="Search" autocapitalize="off" autocorrect="off" autocomplete="off" spellcheck="false" data-md-component="search-query" data-md-state="active" required>
      <label class="md-search__icon md-icon" for="__search">
        <svg xmlns="http://www.w3.org/2000/svg" viewBox="0 0 24 24"><path d="M9.5 3A6.5 6.5 0 0116 9.5c0 1.61-.59 3.09-1.56 4.23l.27.27h.79l5 5-1.5 1.5-5-5v-.79l-.27-.27A6.516 6.516 0 019.5 16 6.5 6.5 0 013 9.5 6.5 6.5 0 019.5 3m0 2C7 5 5 7 5 9.5S7 14 9.5 14 14 12 14 9.5 12 5 9.5 5z"/></svg>
        <svg xmlns="http://www.w3.org/2000/svg" viewBox="0 0 24 24"><path d="M20 11v2H8l5.5 5.5-1.42 1.42L4.16 12l7.92-7.92L13.5 5.5 8 11h12z"/></svg>
      </label>
      <button type="reset" class="md-search__icon md-icon" aria-label="Clear" data-md-component="search-reset" tabindex="-1">
        <svg xmlns="http://www.w3.org/2000/svg" viewBox="0 0 24 24"><path d="M19 6.41L17.59 5 12 10.59 6.41 5 5 6.41 10.59 12 5 17.59 6.41 19 12 13.41 17.59 19 19 17.59 13.41 12 19 6.41z"/></svg>
      </button>
    </form>
    <div class="md-search__output">
      <div class="md-search__scrollwrap" data-md-scrollfix>
        <div class="md-search-result" data-md-component="search-result">
          <div class="md-search-result__meta">
            Initializing search
          </div>
          <ol class="md-search-result__list"></ol>
        </div>
      </div>
    </div>
  </div>
</div>
    
    
      <div class="md-header-nav__source">
        
<a href="https://github.com/lehy/ocaml-sklearn/" title="Go to repository" class="md-source">
  <div class="md-source__icon md-icon">
    
    <svg xmlns="http://www.w3.org/2000/svg" viewBox="0 0 448 512"><path d="M439.55 236.05L244 40.45a28.87 28.87 0 00-40.81 0l-40.66 40.63 51.52 51.52c27.06-9.14 52.68 16.77 43.39 43.68l49.66 49.66c34.23-11.8 61.18 31 35.47 56.69-26.49 26.49-70.21-2.87-56-37.34L240.22 199v121.85c25.3 12.54 22.26 41.85 9.08 55a34.34 34.34 0 01-48.55 0c-17.57-17.6-11.07-46.91 11.25-56v-123c-20.8-8.51-24.6-30.74-18.64-45L142.57 101 8.45 235.14a28.86 28.86 0 000 40.81l195.61 195.6a28.86 28.86 0 0040.8 0l194.69-194.69a28.86 28.86 0 000-40.81z"/></svg>
  </div>
  <div class="md-source__repository">
    lehy/ocaml-sklearn
  </div>
</a>
      </div>
    
  </nav>
</header>
    
    <div class="md-container" data-md-component="container">
      
      
        
      
      <main class="md-main" data-md-component="main">
        <div class="md-main__inner md-grid">
          
            
              <div class="md-sidebar md-sidebar--primary" data-md-component="navigation">
                <div class="md-sidebar__scrollwrap">
                  <div class="md-sidebar__inner">
                    

<nav class="md-nav md-nav--primary" aria-label="Navigation" data-md-level="0">
  <label class="md-nav__title" for="__drawer">
    <a href="../.." title="OCaml scikit-learn interface" class="md-nav__button md-logo" aria-label="OCaml scikit-learn interface">
      
  
  <svg xmlns="http://www.w3.org/2000/svg" viewBox="0 0 24 24"><path d="M12 8a3 3 0 003-3 3 3 0 00-3-3 3 3 0 00-3 3 3 3 0 003 3m0 3.54C9.64 9.35 6.5 8 3 8v11c3.5 0 6.64 1.35 9 3.54 2.36-2.19 5.5-3.54 9-3.54V8c-3.5 0-6.64 1.35-9 3.54z"/></svg>

    </a>
    OCaml scikit-learn interface
  </label>
  
    <div class="md-nav__source">
      
<a href="https://github.com/lehy/ocaml-sklearn/" title="Go to repository" class="md-source">
  <div class="md-source__icon md-icon">
    
    <svg xmlns="http://www.w3.org/2000/svg" viewBox="0 0 448 512"><path d="M439.55 236.05L244 40.45a28.87 28.87 0 00-40.81 0l-40.66 40.63 51.52 51.52c27.06-9.14 52.68 16.77 43.39 43.68l49.66 49.66c34.23-11.8 61.18 31 35.47 56.69-26.49 26.49-70.21-2.87-56-37.34L240.22 199v121.85c25.3 12.54 22.26 41.85 9.08 55a34.34 34.34 0 01-48.55 0c-17.57-17.6-11.07-46.91 11.25-56v-123c-20.8-8.51-24.6-30.74-18.64-45L142.57 101 8.45 235.14a28.86 28.86 0 000 40.81l195.61 195.6a28.86 28.86 0 0040.8 0l194.69-194.69a28.86 28.86 0 000-40.81z"/></svg>
  </div>
  <div class="md-source__repository">
    lehy/ocaml-sklearn
  </div>
</a>
    </div>
  
  <ul class="md-nav__list" data-md-scrollfix>
    
      
      
      


  <li class="md-nav__item">
    <a href="../.." class="md-nav__link">
      Home
    </a>
  </li>

    
      
      
      


  <li class="md-nav__item md-nav__item--nested">
    
    <input class="md-nav__toggle md-toggle" data-md-toggle="nav-2" type="checkbox" id="nav-2" >
    <label class="md-nav__link" for="nav-2">
      Np
      <span class="md-nav__icon md-icon"></span>
    </label>
    <nav class="md-nav" aria-label="Np" data-md-level="1">
      <label class="md-nav__title" for="nav-2">
        <span class="md-nav__icon md-icon"></span>
        Np
      </label>
      <ul class="md-nav__list" data-md-scrollfix>
        
        
          
          
          


  <li class="md-nav__item">
    <a href="../../np/" class="md-nav__link">
      Numpy for OCaml
    </a>
  </li>

        
          
          
          


  <li class="md-nav__item">
    <a href="../../np/Numpy/" class="md-nav__link">
      Numpy
    </a>
  </li>

        
          
          
          


  <li class="md-nav__item">
    <a href="../../np/NumpyRaw/" class="md-nav__link">
      NumpyRaw
    </a>
  </li>

        
          
          
          


  <li class="md-nav__item">
    <a href="../../np/PyList/" class="md-nav__link">
      PyList
    </a>
  </li>

        
          
          
          


  <li class="md-nav__item">
    <a href="../../np/dtype/" class="md-nav__link">
      Dtype
    </a>
  </li>

        
          
          
          


  <li class="md-nav__item">
    <a href="../../np/obj/" class="md-nav__link">
      Obj
    </a>
  </li>

        
      </ul>
    </nav>
  </li>

    
      
      
      


  <li class="md-nav__item md-nav__item--nested">
    
    <input class="md-nav__toggle md-toggle" data-md-toggle="nav-3" type="checkbox" id="nav-3" >
    <label class="md-nav__link" for="nav-3">
      Scipy
      <span class="md-nav__icon md-icon"></span>
    </label>
    <nav class="md-nav" aria-label="Scipy" data-md-level="1">
      <label class="md-nav__title" for="nav-3">
        <span class="md-nav__icon md-icon"></span>
        Scipy
      </label>
      <ul class="md-nav__list" data-md-scrollfix>
        
        
          
          
          


  <li class="md-nav__item">
    <a href="../../scipy/" class="md-nav__link">
      SciPy library for OCaml
    </a>
  </li>

        
          
          
          


  <li class="md-nav__item">
    <a href="../../scipy/Cluster/" class="md-nav__link">
      Cluster
    </a>
  </li>

        
          
          
          


  <li class="md-nav__item">
    <a href="../../scipy/Conftest/" class="md-nav__link">
      Conftest
    </a>
  </li>

        
          
          
          


  <li class="md-nav__item">
    <a href="../../scipy/Constants/" class="md-nav__link">
      Constants
    </a>
  </li>

        
          
          
          


  <li class="md-nav__item">
    <a href="../../scipy/Fft/" class="md-nav__link">
      Fft
    </a>
  </li>

        
          
          
          


  <li class="md-nav__item">
    <a href="../../scipy/Fftpack/" class="md-nav__link">
      Fftpack
    </a>
  </li>

        
          
          
          


  <li class="md-nav__item">
    <a href="../../scipy/Integrate/" class="md-nav__link">
      Integrate
    </a>
  </li>

        
          
          
          


  <li class="md-nav__item">
    <a href="../../scipy/Interpolate/" class="md-nav__link">
      Interpolate
    </a>
  </li>

        
          
          
          


  <li class="md-nav__item">
    <a href="../../scipy/Io/" class="md-nav__link">
      Io
    </a>
  </li>

        
          
          
          


  <li class="md-nav__item">
    <a href="../../scipy/Linalg/" class="md-nav__link">
      Linalg
    </a>
  </li>

        
          
          
          


  <li class="md-nav__item">
    <a href="../../scipy/Misc/" class="md-nav__link">
      Misc
    </a>
  </li>

        
          
          
          


  <li class="md-nav__item">
    <a href="../../scipy/Ndimage/" class="md-nav__link">
      Ndimage
    </a>
  </li>

        
          
          
          


  <li class="md-nav__item">
    <a href="../../scipy/Odr/" class="md-nav__link">
      Odr
    </a>
  </li>

        
          
          
          


  <li class="md-nav__item">
    <a href="../../scipy/Optimize/" class="md-nav__link">
      Optimize
    </a>
  </li>

        
          
          
          


  <li class="md-nav__item">
    <a href="../../scipy/Setup/" class="md-nav__link">
      Setup
    </a>
  </li>

        
          
          
          


  <li class="md-nav__item">
    <a href="../../scipy/Signal/" class="md-nav__link">
      Signal
    </a>
  </li>

        
          
          
          


  <li class="md-nav__item">
    <a href="../../scipy/Sparse/" class="md-nav__link">
      Sparse
    </a>
  </li>

        
          
          
          


  <li class="md-nav__item">
    <a href="../../scipy/Spatial/" class="md-nav__link">
      Spatial
    </a>
  </li>

        
          
          
          


  <li class="md-nav__item">
    <a href="../../scipy/Special/" class="md-nav__link">
      Special
    </a>
  </li>

        
          
          
          


  <li class="md-nav__item">
    <a href="../../scipy/Stats/" class="md-nav__link">
      Stats
    </a>
  </li>

        
          
          
          


  <li class="md-nav__item">
    <a href="../../scipy/Version/" class="md-nav__link">
      Version
    </a>
  </li>

        
          
          
          


  <li class="md-nav__item">
    <a href="../../scipy/wrap_version/" class="md-nav__link">
      Wrap version
    </a>
  </li>

        
      </ul>
    </nav>
  </li>

    
      
      
      

  


  <li class="md-nav__item md-nav__item--active md-nav__item--nested">
    
    <input class="md-nav__toggle md-toggle" data-md-toggle="nav-4" type="checkbox" id="nav-4" checked>
    <label class="md-nav__link" for="nav-4">
      Sklearn
      <span class="md-nav__icon md-icon"></span>
    </label>
    <nav class="md-nav" aria-label="Sklearn" data-md-level="1">
      <label class="md-nav__title" for="nav-4">
        <span class="md-nav__icon md-icon"></span>
        Sklearn
      </label>
      <ul class="md-nav__list" data-md-scrollfix>
        
        
          
          
          


  <li class="md-nav__item">
    <a href="../Base/" class="md-nav__link">
      Base
    </a>
  </li>

        
          
          
          


  <li class="md-nav__item">
    <a href="../Calibration/" class="md-nav__link">
      Calibration
    </a>
  </li>

        
          
          
          


  <li class="md-nav__item">
    <a href="../Cluster/" class="md-nav__link">
      Cluster
    </a>
  </li>

        
          
          
          


  <li class="md-nav__item">
    <a href="../Compose/" class="md-nav__link">
      Compose
    </a>
  </li>

        
          
          
          


  <li class="md-nav__item">
    <a href="../Conftest/" class="md-nav__link">
      Conftest
    </a>
  </li>

        
          
          
          


  <li class="md-nav__item">
    <a href="../Covariance/" class="md-nav__link">
      Covariance
    </a>
  </li>

        
          
          
          


  <li class="md-nav__item">
    <a href="../Cross_decomposition/" class="md-nav__link">
      Cross decomposition
    </a>
  </li>

        
          
          
          


  <li class="md-nav__item">
    <a href="../Datasets/" class="md-nav__link">
      Datasets
    </a>
  </li>

        
          
          
          


  <li class="md-nav__item">
    <a href="../Decomposition/" class="md-nav__link">
      Decomposition
    </a>
  </li>

        
          
          
          


  <li class="md-nav__item">
    <a href="../Discriminant_analysis/" class="md-nav__link">
      Discriminant analysis
    </a>
  </li>

        
          
          
          


  <li class="md-nav__item">
    <a href="../Dummy/" class="md-nav__link">
      Dummy
    </a>
  </li>

        
          
          
          


  <li class="md-nav__item">
    <a href="../Ensemble/" class="md-nav__link">
      Ensemble
    </a>
  </li>

        
          
          
          


  <li class="md-nav__item">
    <a href="../Exceptions/" class="md-nav__link">
      Exceptions
    </a>
  </li>

        
          
          
          


  <li class="md-nav__item">
    <a href="../Experimental/" class="md-nav__link">
      Experimental
    </a>
  </li>

        
          
          
          


  <li class="md-nav__item">
    <a href="../Externals/" class="md-nav__link">
      Externals
    </a>
  </li>

        
          
          
          


  <li class="md-nav__item">
    <a href="../Feature_extraction/" class="md-nav__link">
      Feature extraction
    </a>
  </li>

        
          
          
          


  <li class="md-nav__item">
    <a href="../Feature_selection/" class="md-nav__link">
      Feature selection
    </a>
  </li>

        
          
          
          


  <li class="md-nav__item">
    <a href="../Gaussian_process/" class="md-nav__link">
      Gaussian process
    </a>
  </li>

        
          
          
          


  <li class="md-nav__item">
    <a href="../Impute/" class="md-nav__link">
      Impute
    </a>
  </li>

        
          
          
          


  <li class="md-nav__item">
    <a href="../Inspection/" class="md-nav__link">
      Inspection
    </a>
  </li>

        
          
          
          


  <li class="md-nav__item">
    <a href="../Isotonic/" class="md-nav__link">
      Isotonic
    </a>
  </li>

        
          
          
          


  <li class="md-nav__item">
    <a href="../Kernel_approximation/" class="md-nav__link">
      Kernel approximation
    </a>
  </li>

        
          
          
          


  <li class="md-nav__item">
    <a href="../Kernel_ridge/" class="md-nav__link">
      Kernel ridge
    </a>
  </li>

        
          
          
          


  <li class="md-nav__item">
    <a href="../Linear_model/" class="md-nav__link">
      Linear model
    </a>
  </li>

        
          
          
          


  <li class="md-nav__item">
    <a href="../Manifold/" class="md-nav__link">
      Manifold
    </a>
  </li>

        
          
          
          


  <li class="md-nav__item">
    <a href="../Metrics/" class="md-nav__link">
      Metrics
    </a>
  </li>

        
          
          
          


  <li class="md-nav__item">
    <a href="../Mixture/" class="md-nav__link">
      Mixture
    </a>
  </li>

        
          
          
          


  <li class="md-nav__item">
    <a href="../Model_selection/" class="md-nav__link">
      Model selection
    </a>
  </li>

        
          
          
          


  <li class="md-nav__item">
    <a href="../Multiclass/" class="md-nav__link">
      Multiclass
    </a>
  </li>

        
          
          
          


  <li class="md-nav__item">
    <a href="../Multioutput/" class="md-nav__link">
      Multioutput
    </a>
  </li>

        
          
          
          


  <li class="md-nav__item">
    <a href="../Naive_bayes/" class="md-nav__link">
      Naive bayes
    </a>
  </li>

        
          
          
          


  <li class="md-nav__item">
    <a href="../Neighbors/" class="md-nav__link">
      Neighbors
    </a>
  </li>

        
          
          
          


  <li class="md-nav__item">
    <a href="../Neural_network/" class="md-nav__link">
      Neural network
    </a>
  </li>

        
          
          
          


  <li class="md-nav__item">
    <a href="../Pipeline/" class="md-nav__link">
      Pipeline
    </a>
  </li>

        
          
          
          


  <li class="md-nav__item">
    <a href="../Preprocessing/" class="md-nav__link">
      Preprocessing
    </a>
  </li>

        
          
          
          


  <li class="md-nav__item">
    <a href="../Random_projection/" class="md-nav__link">
      Random projection
    </a>
  </li>

        
          
          
          


  <li class="md-nav__item">
    <a href="../Semi_supervised/" class="md-nav__link">
      Semi supervised
    </a>
  </li>

        
          
          
          


  <li class="md-nav__item">
    <a href="../Setup/" class="md-nav__link">
      Setup
    </a>
  </li>

        
          
          
          


  <li class="md-nav__item">
    <a href="../Svm/" class="md-nav__link">
      Svm
    </a>
  </li>

        
          
          
          


  <li class="md-nav__item">
    <a href="../Tests/" class="md-nav__link">
      Tests
    </a>
  </li>

        
          
          
          

  


  <li class="md-nav__item md-nav__item--active">
    
    <input class="md-nav__toggle md-toggle" data-md-toggle="toc" type="checkbox" id="__toc">
    
    
      <label class="md-nav__link md-nav__link--active" for="__toc">
        Tree
        <span class="md-nav__icon md-icon"></span>
      </label>
    
    <a href="./" class="md-nav__link md-nav__link--active">
      Tree
    </a>
    
      
<nav class="md-nav md-nav--secondary" aria-label="Table of contents">
  
  
  
    <label class="md-nav__title" for="__toc">
      <span class="md-nav__icon md-icon"></span>
      Table of contents
    </label>
    <ul class="md-nav__list" data-md-scrollfix>
      
        <li class="md-nav__item">
  <a href="#basedecisiontree" class="md-nav__link">
    BaseDecisionTree
  </a>
  
    <nav class="md-nav" aria-label="BaseDecisionTree">
      <ul class="md-nav__list">
        
          <li class="md-nav__item">
  <a href="#apply" class="md-nav__link">
    apply
  </a>
  
</li>
        
          <li class="md-nav__item">
  <a href="#cost_complexity_pruning_path" class="md-nav__link">
    cost_complexity_pruning_path
  </a>
  
</li>
        
          <li class="md-nav__item">
  <a href="#decision_path" class="md-nav__link">
    decision_path
  </a>
  
</li>
        
          <li class="md-nav__item">
  <a href="#fit" class="md-nav__link">
    fit
  </a>
  
</li>
        
          <li class="md-nav__item">
  <a href="#get_depth" class="md-nav__link">
    get_depth
  </a>
  
</li>
        
          <li class="md-nav__item">
  <a href="#get_n_leaves" class="md-nav__link">
    get_n_leaves
  </a>
  
</li>
        
          <li class="md-nav__item">
  <a href="#get_params" class="md-nav__link">
    get_params
  </a>
  
</li>
        
          <li class="md-nav__item">
  <a href="#predict" class="md-nav__link">
    predict
  </a>
  
</li>
        
          <li class="md-nav__item">
  <a href="#set_params" class="md-nav__link">
    set_params
  </a>
  
</li>
        
          <li class="md-nav__item">
  <a href="#to_string" class="md-nav__link">
    to_string
  </a>
  
</li>
        
          <li class="md-nav__item">
  <a href="#show" class="md-nav__link">
    show
  </a>
  
</li>
        
          <li class="md-nav__item">
  <a href="#pp" class="md-nav__link">
    pp
  </a>
  
</li>
        
      </ul>
    </nav>
  
</li>
      
        <li class="md-nav__item">
  <a href="#decisiontreeclassifier" class="md-nav__link">
    DecisionTreeClassifier
  </a>
  
    <nav class="md-nav" aria-label="DecisionTreeClassifier">
      <ul class="md-nav__list">
        
          <li class="md-nav__item">
  <a href="#create" class="md-nav__link">
    create
  </a>
  
</li>
        
          <li class="md-nav__item">
  <a href="#apply_1" class="md-nav__link">
    apply
  </a>
  
</li>
        
          <li class="md-nav__item">
  <a href="#cost_complexity_pruning_path_1" class="md-nav__link">
    cost_complexity_pruning_path
  </a>
  
</li>
        
          <li class="md-nav__item">
  <a href="#decision_path_1" class="md-nav__link">
    decision_path
  </a>
  
</li>
        
          <li class="md-nav__item">
  <a href="#fit_1" class="md-nav__link">
    fit
  </a>
  
</li>
        
          <li class="md-nav__item">
  <a href="#get_depth_1" class="md-nav__link">
    get_depth
  </a>
  
</li>
        
          <li class="md-nav__item">
  <a href="#get_n_leaves_1" class="md-nav__link">
    get_n_leaves
  </a>
  
</li>
        
          <li class="md-nav__item">
  <a href="#get_params_1" class="md-nav__link">
    get_params
  </a>
  
</li>
        
          <li class="md-nav__item">
  <a href="#predict_1" class="md-nav__link">
    predict
  </a>
  
</li>
        
          <li class="md-nav__item">
  <a href="#predict_log_proba" class="md-nav__link">
    predict_log_proba
  </a>
  
</li>
        
          <li class="md-nav__item">
  <a href="#predict_proba" class="md-nav__link">
    predict_proba
  </a>
  
</li>
        
          <li class="md-nav__item">
  <a href="#score" class="md-nav__link">
    score
  </a>
  
</li>
        
          <li class="md-nav__item">
  <a href="#set_params_1" class="md-nav__link">
    set_params
  </a>
  
</li>
        
          <li class="md-nav__item">
  <a href="#classes_" class="md-nav__link">
    classes_
  </a>
  
</li>
        
          <li class="md-nav__item">
  <a href="#feature_importances_" class="md-nav__link">
    feature_importances_
  </a>
  
</li>
        
          <li class="md-nav__item">
  <a href="#warning" class="md-nav__link">
    warning
  </a>
  
</li>
        
          <li class="md-nav__item">
  <a href="#max_features_" class="md-nav__link">
    max_features_
  </a>
  
</li>
        
          <li class="md-nav__item">
  <a href="#n_classes_" class="md-nav__link">
    n_classes_
  </a>
  
</li>
        
          <li class="md-nav__item">
  <a href="#n_features_" class="md-nav__link">
    n_features_
  </a>
  
</li>
        
          <li class="md-nav__item">
  <a href="#n_outputs_" class="md-nav__link">
    n_outputs_
  </a>
  
</li>
        
          <li class="md-nav__item">
  <a href="#tree_" class="md-nav__link">
    tree_
  </a>
  
</li>
        
          <li class="md-nav__item">
  <a href="#to_string_1" class="md-nav__link">
    to_string
  </a>
  
</li>
        
          <li class="md-nav__item">
  <a href="#show_1" class="md-nav__link">
    show
  </a>
  
</li>
        
          <li class="md-nav__item">
  <a href="#pp_1" class="md-nav__link">
    pp
  </a>
  
</li>
        
      </ul>
    </nav>
  
</li>
      
        <li class="md-nav__item">
  <a href="#decisiontreeregressor" class="md-nav__link">
    DecisionTreeRegressor
  </a>
  
    <nav class="md-nav" aria-label="DecisionTreeRegressor">
      <ul class="md-nav__list">
        
          <li class="md-nav__item">
  <a href="#create_1" class="md-nav__link">
    create
  </a>
  
</li>
        
          <li class="md-nav__item">
  <a href="#apply_2" class="md-nav__link">
    apply
  </a>
  
</li>
        
          <li class="md-nav__item">
  <a href="#cost_complexity_pruning_path_2" class="md-nav__link">
    cost_complexity_pruning_path
  </a>
  
</li>
        
          <li class="md-nav__item">
  <a href="#decision_path_2" class="md-nav__link">
    decision_path
  </a>
  
</li>
        
          <li class="md-nav__item">
  <a href="#fit_2" class="md-nav__link">
    fit
  </a>
  
</li>
        
          <li class="md-nav__item">
  <a href="#get_depth_2" class="md-nav__link">
    get_depth
  </a>
  
</li>
        
          <li class="md-nav__item">
  <a href="#get_n_leaves_2" class="md-nav__link">
    get_n_leaves
  </a>
  
</li>
        
          <li class="md-nav__item">
  <a href="#get_params_2" class="md-nav__link">
    get_params
  </a>
  
</li>
        
          <li class="md-nav__item">
  <a href="#predict_2" class="md-nav__link">
    predict
  </a>
  
</li>
        
          <li class="md-nav__item">
  <a href="#score_1" class="md-nav__link">
    score
  </a>
  
</li>
        
          <li class="md-nav__item">
  <a href="#set_params_2" class="md-nav__link">
    set_params
  </a>
  
</li>
        
          <li class="md-nav__item">
  <a href="#feature_importances__1" class="md-nav__link">
    feature_importances_
  </a>
  
</li>
        
          <li class="md-nav__item">
  <a href="#warning_1" class="md-nav__link">
    warning
  </a>
  
</li>
        
          <li class="md-nav__item">
  <a href="#max_features__1" class="md-nav__link">
    max_features_
  </a>
  
</li>
        
          <li class="md-nav__item">
  <a href="#n_features__1" class="md-nav__link">
    n_features_
  </a>
  
</li>
        
          <li class="md-nav__item">
  <a href="#n_outputs__1" class="md-nav__link">
    n_outputs_
  </a>
  
</li>
        
          <li class="md-nav__item">
  <a href="#tree__1" class="md-nav__link">
    tree_
  </a>
  
</li>
        
          <li class="md-nav__item">
  <a href="#to_string_2" class="md-nav__link">
    to_string
  </a>
  
</li>
        
          <li class="md-nav__item">
  <a href="#show_2" class="md-nav__link">
    show
  </a>
  
</li>
        
          <li class="md-nav__item">
  <a href="#pp_2" class="md-nav__link">
    pp
  </a>
  
</li>
        
      </ul>
    </nav>
  
</li>
      
        <li class="md-nav__item">
  <a href="#extratreeclassifier" class="md-nav__link">
    ExtraTreeClassifier
  </a>
  
    <nav class="md-nav" aria-label="ExtraTreeClassifier">
      <ul class="md-nav__list">
        
          <li class="md-nav__item">
  <a href="#create_2" class="md-nav__link">
    create
  </a>
  
</li>
        
          <li class="md-nav__item">
  <a href="#apply_3" class="md-nav__link">
    apply
  </a>
  
</li>
        
          <li class="md-nav__item">
  <a href="#cost_complexity_pruning_path_3" class="md-nav__link">
    cost_complexity_pruning_path
  </a>
  
</li>
        
          <li class="md-nav__item">
  <a href="#decision_path_3" class="md-nav__link">
    decision_path
  </a>
  
</li>
        
          <li class="md-nav__item">
  <a href="#fit_3" class="md-nav__link">
    fit
  </a>
  
</li>
        
          <li class="md-nav__item">
  <a href="#get_depth_3" class="md-nav__link">
    get_depth
  </a>
  
</li>
        
          <li class="md-nav__item">
  <a href="#get_n_leaves_3" class="md-nav__link">
    get_n_leaves
  </a>
  
</li>
        
          <li class="md-nav__item">
  <a href="#get_params_3" class="md-nav__link">
    get_params
  </a>
  
</li>
        
          <li class="md-nav__item">
  <a href="#predict_3" class="md-nav__link">
    predict
  </a>
  
</li>
        
          <li class="md-nav__item">
  <a href="#predict_log_proba_1" class="md-nav__link">
    predict_log_proba
  </a>
  
</li>
        
          <li class="md-nav__item">
  <a href="#predict_proba_1" class="md-nav__link">
    predict_proba
  </a>
  
</li>
        
          <li class="md-nav__item">
  <a href="#score_2" class="md-nav__link">
    score
  </a>
  
</li>
        
          <li class="md-nav__item">
  <a href="#set_params_3" class="md-nav__link">
    set_params
  </a>
  
</li>
        
          <li class="md-nav__item">
  <a href="#classes__1" class="md-nav__link">
    classes_
  </a>
  
</li>
        
          <li class="md-nav__item">
  <a href="#max_features__2" class="md-nav__link">
    max_features_
  </a>
  
</li>
        
          <li class="md-nav__item">
  <a href="#n_classes__1" class="md-nav__link">
    n_classes_
  </a>
  
</li>
        
          <li class="md-nav__item">
  <a href="#feature_importances__2" class="md-nav__link">
    feature_importances_
  </a>
  
</li>
        
          <li class="md-nav__item">
  <a href="#warning_2" class="md-nav__link">
    warning
  </a>
  
</li>
        
          <li class="md-nav__item">
  <a href="#n_features__2" class="md-nav__link">
    n_features_
  </a>
  
</li>
        
          <li class="md-nav__item">
  <a href="#n_outputs__2" class="md-nav__link">
    n_outputs_
  </a>
  
</li>
        
          <li class="md-nav__item">
  <a href="#tree__2" class="md-nav__link">
    tree_
  </a>
  
</li>
        
          <li class="md-nav__item">
  <a href="#to_string_3" class="md-nav__link">
    to_string
  </a>
  
</li>
        
          <li class="md-nav__item">
  <a href="#show_3" class="md-nav__link">
    show
  </a>
  
</li>
        
          <li class="md-nav__item">
  <a href="#pp_3" class="md-nav__link">
    pp
  </a>
  
</li>
        
      </ul>
    </nav>
  
</li>
      
        <li class="md-nav__item">
  <a href="#extratreeregressor" class="md-nav__link">
    ExtraTreeRegressor
  </a>
  
    <nav class="md-nav" aria-label="ExtraTreeRegressor">
      <ul class="md-nav__list">
        
          <li class="md-nav__item">
  <a href="#create_3" class="md-nav__link">
    create
  </a>
  
</li>
        
          <li class="md-nav__item">
  <a href="#apply_4" class="md-nav__link">
    apply
  </a>
  
</li>
        
          <li class="md-nav__item">
  <a href="#cost_complexity_pruning_path_4" class="md-nav__link">
    cost_complexity_pruning_path
  </a>
  
</li>
        
          <li class="md-nav__item">
  <a href="#decision_path_4" class="md-nav__link">
    decision_path
  </a>
  
</li>
        
          <li class="md-nav__item">
  <a href="#fit_4" class="md-nav__link">
    fit
  </a>
  
</li>
        
          <li class="md-nav__item">
  <a href="#get_depth_4" class="md-nav__link">
    get_depth
  </a>
  
</li>
        
          <li class="md-nav__item">
  <a href="#get_n_leaves_4" class="md-nav__link">
    get_n_leaves
  </a>
  
</li>
        
          <li class="md-nav__item">
  <a href="#get_params_4" class="md-nav__link">
    get_params
  </a>
  
</li>
        
          <li class="md-nav__item">
  <a href="#predict_4" class="md-nav__link">
    predict
  </a>
  
</li>
        
          <li class="md-nav__item">
  <a href="#score_3" class="md-nav__link">
    score
  </a>
  
</li>
        
          <li class="md-nav__item">
  <a href="#set_params_4" class="md-nav__link">
    set_params
  </a>
  
</li>
        
          <li class="md-nav__item">
  <a href="#max_features__3" class="md-nav__link">
    max_features_
  </a>
  
</li>
        
          <li class="md-nav__item">
  <a href="#n_features__3" class="md-nav__link">
    n_features_
  </a>
  
</li>
        
          <li class="md-nav__item">
  <a href="#feature_importances__3" class="md-nav__link">
    feature_importances_
  </a>
  
</li>
        
          <li class="md-nav__item">
  <a href="#warning_3" class="md-nav__link">
    warning
  </a>
  
</li>
        
          <li class="md-nav__item">
  <a href="#n_outputs__3" class="md-nav__link">
    n_outputs_
  </a>
  
</li>
        
          <li class="md-nav__item">
  <a href="#tree__3" class="md-nav__link">
    tree_
  </a>
  
</li>
        
          <li class="md-nav__item">
  <a href="#to_string_4" class="md-nav__link">
    to_string
  </a>
  
</li>
        
          <li class="md-nav__item">
  <a href="#show_4" class="md-nav__link">
    show
  </a>
  
</li>
        
          <li class="md-nav__item">
  <a href="#pp_4" class="md-nav__link">
    pp
  </a>
  
</li>
        
          <li class="md-nav__item">
  <a href="#export_graphviz" class="md-nav__link">
    export_graphviz
  </a>
  
</li>
        
          <li class="md-nav__item">
  <a href="#export_text" class="md-nav__link">
    export_text
  </a>
  
</li>
        
          <li class="md-nav__item">
  <a href="#plot_tree" class="md-nav__link">
    plot_tree
  </a>
  
</li>
        
      </ul>
    </nav>
  
</li>
      
    </ul>
  
</nav>
    
  </li>

        
          
          
          


  <li class="md-nav__item">
    <a href="../Utils/" class="md-nav__link">
      Utils
    </a>
  </li>

        
          
          
          


  <li class="md-nav__item">
    <a href="../arr/" class="md-nav__link">
      Arr
    </a>
  </li>

        
          
          
          


  <li class="md-nav__item">
    <a href="../dict/" class="md-nav__link">
      Dict
    </a>
  </li>

        
          
          
          


  <li class="md-nav__item">
    <a href="../wrap_version/" class="md-nav__link">
      Wrap version
    </a>
  </li>

        
      </ul>
    </nav>
  </li>

    
  </ul>
</nav>
                  </div>
                </div>
              </div>
            
            
              <div class="md-sidebar md-sidebar--secondary" data-md-component="toc">
                <div class="md-sidebar__scrollwrap">
                  <div class="md-sidebar__inner">
                    
<nav class="md-nav md-nav--secondary" aria-label="Table of contents">
  
  
  
    <label class="md-nav__title" for="__toc">
      <span class="md-nav__icon md-icon"></span>
      Table of contents
    </label>
    <ul class="md-nav__list" data-md-scrollfix>
      
        <li class="md-nav__item">
  <a href="#basedecisiontree" class="md-nav__link">
    BaseDecisionTree
  </a>
  
    <nav class="md-nav" aria-label="BaseDecisionTree">
      <ul class="md-nav__list">
        
          <li class="md-nav__item">
  <a href="#apply" class="md-nav__link">
    apply
  </a>
  
</li>
        
          <li class="md-nav__item">
  <a href="#cost_complexity_pruning_path" class="md-nav__link">
    cost_complexity_pruning_path
  </a>
  
</li>
        
          <li class="md-nav__item">
  <a href="#decision_path" class="md-nav__link">
    decision_path
  </a>
  
</li>
        
          <li class="md-nav__item">
  <a href="#fit" class="md-nav__link">
    fit
  </a>
  
</li>
        
          <li class="md-nav__item">
  <a href="#get_depth" class="md-nav__link">
    get_depth
  </a>
  
</li>
        
          <li class="md-nav__item">
  <a href="#get_n_leaves" class="md-nav__link">
    get_n_leaves
  </a>
  
</li>
        
          <li class="md-nav__item">
  <a href="#get_params" class="md-nav__link">
    get_params
  </a>
  
</li>
        
          <li class="md-nav__item">
  <a href="#predict" class="md-nav__link">
    predict
  </a>
  
</li>
        
          <li class="md-nav__item">
  <a href="#set_params" class="md-nav__link">
    set_params
  </a>
  
</li>
        
          <li class="md-nav__item">
  <a href="#to_string" class="md-nav__link">
    to_string
  </a>
  
</li>
        
          <li class="md-nav__item">
  <a href="#show" class="md-nav__link">
    show
  </a>
  
</li>
        
          <li class="md-nav__item">
  <a href="#pp" class="md-nav__link">
    pp
  </a>
  
</li>
        
      </ul>
    </nav>
  
</li>
      
        <li class="md-nav__item">
  <a href="#decisiontreeclassifier" class="md-nav__link">
    DecisionTreeClassifier
  </a>
  
    <nav class="md-nav" aria-label="DecisionTreeClassifier">
      <ul class="md-nav__list">
        
          <li class="md-nav__item">
  <a href="#create" class="md-nav__link">
    create
  </a>
  
</li>
        
          <li class="md-nav__item">
  <a href="#apply_1" class="md-nav__link">
    apply
  </a>
  
</li>
        
          <li class="md-nav__item">
  <a href="#cost_complexity_pruning_path_1" class="md-nav__link">
    cost_complexity_pruning_path
  </a>
  
</li>
        
          <li class="md-nav__item">
  <a href="#decision_path_1" class="md-nav__link">
    decision_path
  </a>
  
</li>
        
          <li class="md-nav__item">
  <a href="#fit_1" class="md-nav__link">
    fit
  </a>
  
</li>
        
          <li class="md-nav__item">
  <a href="#get_depth_1" class="md-nav__link">
    get_depth
  </a>
  
</li>
        
          <li class="md-nav__item">
  <a href="#get_n_leaves_1" class="md-nav__link">
    get_n_leaves
  </a>
  
</li>
        
          <li class="md-nav__item">
  <a href="#get_params_1" class="md-nav__link">
    get_params
  </a>
  
</li>
        
          <li class="md-nav__item">
  <a href="#predict_1" class="md-nav__link">
    predict
  </a>
  
</li>
        
          <li class="md-nav__item">
  <a href="#predict_log_proba" class="md-nav__link">
    predict_log_proba
  </a>
  
</li>
        
          <li class="md-nav__item">
  <a href="#predict_proba" class="md-nav__link">
    predict_proba
  </a>
  
</li>
        
          <li class="md-nav__item">
  <a href="#score" class="md-nav__link">
    score
  </a>
  
</li>
        
          <li class="md-nav__item">
  <a href="#set_params_1" class="md-nav__link">
    set_params
  </a>
  
</li>
        
          <li class="md-nav__item">
  <a href="#classes_" class="md-nav__link">
    classes_
  </a>
  
</li>
        
          <li class="md-nav__item">
  <a href="#feature_importances_" class="md-nav__link">
    feature_importances_
  </a>
  
</li>
        
          <li class="md-nav__item">
  <a href="#warning" class="md-nav__link">
    warning
  </a>
  
</li>
        
          <li class="md-nav__item">
  <a href="#max_features_" class="md-nav__link">
    max_features_
  </a>
  
</li>
        
          <li class="md-nav__item">
  <a href="#n_classes_" class="md-nav__link">
    n_classes_
  </a>
  
</li>
        
          <li class="md-nav__item">
  <a href="#n_features_" class="md-nav__link">
    n_features_
  </a>
  
</li>
        
          <li class="md-nav__item">
  <a href="#n_outputs_" class="md-nav__link">
    n_outputs_
  </a>
  
</li>
        
          <li class="md-nav__item">
  <a href="#tree_" class="md-nav__link">
    tree_
  </a>
  
</li>
        
          <li class="md-nav__item">
  <a href="#to_string_1" class="md-nav__link">
    to_string
  </a>
  
</li>
        
          <li class="md-nav__item">
  <a href="#show_1" class="md-nav__link">
    show
  </a>
  
</li>
        
          <li class="md-nav__item">
  <a href="#pp_1" class="md-nav__link">
    pp
  </a>
  
</li>
        
      </ul>
    </nav>
  
</li>
      
        <li class="md-nav__item">
  <a href="#decisiontreeregressor" class="md-nav__link">
    DecisionTreeRegressor
  </a>
  
    <nav class="md-nav" aria-label="DecisionTreeRegressor">
      <ul class="md-nav__list">
        
          <li class="md-nav__item">
  <a href="#create_1" class="md-nav__link">
    create
  </a>
  
</li>
        
          <li class="md-nav__item">
  <a href="#apply_2" class="md-nav__link">
    apply
  </a>
  
</li>
        
          <li class="md-nav__item">
  <a href="#cost_complexity_pruning_path_2" class="md-nav__link">
    cost_complexity_pruning_path
  </a>
  
</li>
        
          <li class="md-nav__item">
  <a href="#decision_path_2" class="md-nav__link">
    decision_path
  </a>
  
</li>
        
          <li class="md-nav__item">
  <a href="#fit_2" class="md-nav__link">
    fit
  </a>
  
</li>
        
          <li class="md-nav__item">
  <a href="#get_depth_2" class="md-nav__link">
    get_depth
  </a>
  
</li>
        
          <li class="md-nav__item">
  <a href="#get_n_leaves_2" class="md-nav__link">
    get_n_leaves
  </a>
  
</li>
        
          <li class="md-nav__item">
  <a href="#get_params_2" class="md-nav__link">
    get_params
  </a>
  
</li>
        
          <li class="md-nav__item">
  <a href="#predict_2" class="md-nav__link">
    predict
  </a>
  
</li>
        
          <li class="md-nav__item">
  <a href="#score_1" class="md-nav__link">
    score
  </a>
  
</li>
        
          <li class="md-nav__item">
  <a href="#set_params_2" class="md-nav__link">
    set_params
  </a>
  
</li>
        
          <li class="md-nav__item">
  <a href="#feature_importances__1" class="md-nav__link">
    feature_importances_
  </a>
  
</li>
        
          <li class="md-nav__item">
  <a href="#warning_1" class="md-nav__link">
    warning
  </a>
  
</li>
        
          <li class="md-nav__item">
  <a href="#max_features__1" class="md-nav__link">
    max_features_
  </a>
  
</li>
        
          <li class="md-nav__item">
  <a href="#n_features__1" class="md-nav__link">
    n_features_
  </a>
  
</li>
        
          <li class="md-nav__item">
  <a href="#n_outputs__1" class="md-nav__link">
    n_outputs_
  </a>
  
</li>
        
          <li class="md-nav__item">
  <a href="#tree__1" class="md-nav__link">
    tree_
  </a>
  
</li>
        
          <li class="md-nav__item">
  <a href="#to_string_2" class="md-nav__link">
    to_string
  </a>
  
</li>
        
          <li class="md-nav__item">
  <a href="#show_2" class="md-nav__link">
    show
  </a>
  
</li>
        
          <li class="md-nav__item">
  <a href="#pp_2" class="md-nav__link">
    pp
  </a>
  
</li>
        
      </ul>
    </nav>
  
</li>
      
        <li class="md-nav__item">
  <a href="#extratreeclassifier" class="md-nav__link">
    ExtraTreeClassifier
  </a>
  
    <nav class="md-nav" aria-label="ExtraTreeClassifier">
      <ul class="md-nav__list">
        
          <li class="md-nav__item">
  <a href="#create_2" class="md-nav__link">
    create
  </a>
  
</li>
        
          <li class="md-nav__item">
  <a href="#apply_3" class="md-nav__link">
    apply
  </a>
  
</li>
        
          <li class="md-nav__item">
  <a href="#cost_complexity_pruning_path_3" class="md-nav__link">
    cost_complexity_pruning_path
  </a>
  
</li>
        
          <li class="md-nav__item">
  <a href="#decision_path_3" class="md-nav__link">
    decision_path
  </a>
  
</li>
        
          <li class="md-nav__item">
  <a href="#fit_3" class="md-nav__link">
    fit
  </a>
  
</li>
        
          <li class="md-nav__item">
  <a href="#get_depth_3" class="md-nav__link">
    get_depth
  </a>
  
</li>
        
          <li class="md-nav__item">
  <a href="#get_n_leaves_3" class="md-nav__link">
    get_n_leaves
  </a>
  
</li>
        
          <li class="md-nav__item">
  <a href="#get_params_3" class="md-nav__link">
    get_params
  </a>
  
</li>
        
          <li class="md-nav__item">
  <a href="#predict_3" class="md-nav__link">
    predict
  </a>
  
</li>
        
          <li class="md-nav__item">
  <a href="#predict_log_proba_1" class="md-nav__link">
    predict_log_proba
  </a>
  
</li>
        
          <li class="md-nav__item">
  <a href="#predict_proba_1" class="md-nav__link">
    predict_proba
  </a>
  
</li>
        
          <li class="md-nav__item">
  <a href="#score_2" class="md-nav__link">
    score
  </a>
  
</li>
        
          <li class="md-nav__item">
  <a href="#set_params_3" class="md-nav__link">
    set_params
  </a>
  
</li>
        
          <li class="md-nav__item">
  <a href="#classes__1" class="md-nav__link">
    classes_
  </a>
  
</li>
        
          <li class="md-nav__item">
  <a href="#max_features__2" class="md-nav__link">
    max_features_
  </a>
  
</li>
        
          <li class="md-nav__item">
  <a href="#n_classes__1" class="md-nav__link">
    n_classes_
  </a>
  
</li>
        
          <li class="md-nav__item">
  <a href="#feature_importances__2" class="md-nav__link">
    feature_importances_
  </a>
  
</li>
        
          <li class="md-nav__item">
  <a href="#warning_2" class="md-nav__link">
    warning
  </a>
  
</li>
        
          <li class="md-nav__item">
  <a href="#n_features__2" class="md-nav__link">
    n_features_
  </a>
  
</li>
        
          <li class="md-nav__item">
  <a href="#n_outputs__2" class="md-nav__link">
    n_outputs_
  </a>
  
</li>
        
          <li class="md-nav__item">
  <a href="#tree__2" class="md-nav__link">
    tree_
  </a>
  
</li>
        
          <li class="md-nav__item">
  <a href="#to_string_3" class="md-nav__link">
    to_string
  </a>
  
</li>
        
          <li class="md-nav__item">
  <a href="#show_3" class="md-nav__link">
    show
  </a>
  
</li>
        
          <li class="md-nav__item">
  <a href="#pp_3" class="md-nav__link">
    pp
  </a>
  
</li>
        
      </ul>
    </nav>
  
</li>
      
        <li class="md-nav__item">
  <a href="#extratreeregressor" class="md-nav__link">
    ExtraTreeRegressor
  </a>
  
    <nav class="md-nav" aria-label="ExtraTreeRegressor">
      <ul class="md-nav__list">
        
          <li class="md-nav__item">
  <a href="#create_3" class="md-nav__link">
    create
  </a>
  
</li>
        
          <li class="md-nav__item">
  <a href="#apply_4" class="md-nav__link">
    apply
  </a>
  
</li>
        
          <li class="md-nav__item">
  <a href="#cost_complexity_pruning_path_4" class="md-nav__link">
    cost_complexity_pruning_path
  </a>
  
</li>
        
          <li class="md-nav__item">
  <a href="#decision_path_4" class="md-nav__link">
    decision_path
  </a>
  
</li>
        
          <li class="md-nav__item">
  <a href="#fit_4" class="md-nav__link">
    fit
  </a>
  
</li>
        
          <li class="md-nav__item">
  <a href="#get_depth_4" class="md-nav__link">
    get_depth
  </a>
  
</li>
        
          <li class="md-nav__item">
  <a href="#get_n_leaves_4" class="md-nav__link">
    get_n_leaves
  </a>
  
</li>
        
          <li class="md-nav__item">
  <a href="#get_params_4" class="md-nav__link">
    get_params
  </a>
  
</li>
        
          <li class="md-nav__item">
  <a href="#predict_4" class="md-nav__link">
    predict
  </a>
  
</li>
        
          <li class="md-nav__item">
  <a href="#score_3" class="md-nav__link">
    score
  </a>
  
</li>
        
          <li class="md-nav__item">
  <a href="#set_params_4" class="md-nav__link">
    set_params
  </a>
  
</li>
        
          <li class="md-nav__item">
  <a href="#max_features__3" class="md-nav__link">
    max_features_
  </a>
  
</li>
        
          <li class="md-nav__item">
  <a href="#n_features__3" class="md-nav__link">
    n_features_
  </a>
  
</li>
        
          <li class="md-nav__item">
  <a href="#feature_importances__3" class="md-nav__link">
    feature_importances_
  </a>
  
</li>
        
          <li class="md-nav__item">
  <a href="#warning_3" class="md-nav__link">
    warning
  </a>
  
</li>
        
          <li class="md-nav__item">
  <a href="#n_outputs__3" class="md-nav__link">
    n_outputs_
  </a>
  
</li>
        
          <li class="md-nav__item">
  <a href="#tree__3" class="md-nav__link">
    tree_
  </a>
  
</li>
        
          <li class="md-nav__item">
  <a href="#to_string_4" class="md-nav__link">
    to_string
  </a>
  
</li>
        
          <li class="md-nav__item">
  <a href="#show_4" class="md-nav__link">
    show
  </a>
  
</li>
        
          <li class="md-nav__item">
  <a href="#pp_4" class="md-nav__link">
    pp
  </a>
  
</li>
        
          <li class="md-nav__item">
  <a href="#export_graphviz" class="md-nav__link">
    export_graphviz
  </a>
  
</li>
        
          <li class="md-nav__item">
  <a href="#export_text" class="md-nav__link">
    export_text
  </a>
  
</li>
        
          <li class="md-nav__item">
  <a href="#plot_tree" class="md-nav__link">
    plot_tree
  </a>
  
</li>
        
      </ul>
    </nav>
  
</li>
      
    </ul>
  
</nav>
                  </div>
                </div>
              </div>
            
          
          <div class="md-content">
            <article class="md-content__inner md-typeset">
              
                
                  <a href="https://github.com/lehy/ocaml-sklearn/edit/master/docs/sklearn/Tree.md" title="Edit this page" class="md-content__button md-icon">
                    <svg xmlns="http://www.w3.org/2000/svg" viewBox="0 0 24 24"><path d="M20.71 7.04c.39-.39.39-1.04 0-1.41l-2.34-2.34c-.37-.39-1.02-.39-1.41 0l-1.84 1.83 3.75 3.75M3 17.25V21h3.75L17.81 9.93l-3.75-3.75L3 17.25z"/></svg>
                  </a>
                
                
                  <h1>Tree</h1>
                
                <h2 id="basedecisiontree">BaseDecisionTree<a class="headerlink" href="#basedecisiontree" title="Permanent link">&para;</a></h2>
<p>Module <code>Sklearn.Tree.BaseDecisionTree</code> wraps Python class <a href="https://scikit-learn.org/stable/modules/generated/sklearn.tree.BaseDecisionTree.html"><code>sklearn.tree.BaseDecisionTree</code></a>.</p>
<div class="highlight"><pre><span></span><code><span class="k">type</span> <span class="n">t</span>
</code></pre></div>

<h3 id="apply">apply<a class="headerlink" href="#apply" title="Permanent link">&para;</a></h3>
<details class="note" open="open"><summary>method</summary><div class="highlight"><pre><span></span><code><span class="k">val</span> <span class="n">apply</span> <span class="o">:</span>
  <span class="o">?</span><span class="n">check_input</span><span class="o">:</span><span class="kt">bool</span> <span class="o">-&gt;</span>
  <span class="n">x</span><span class="o">:[&gt;`</span><span class="nc">ArrayLike</span><span class="o">]</span> <span class="nn">Np</span><span class="p">.</span><span class="nn">Obj</span><span class="p">.</span><span class="n">t</span> <span class="o">-&gt;</span>
  <span class="o">[&gt;</span> <span class="n">tag</span><span class="o">]</span> <span class="nn">Obj</span><span class="p">.</span><span class="n">t</span> <span class="o">-&gt;</span>
  <span class="o">[&gt;`</span><span class="nc">ArrayLike</span><span class="o">]</span> <span class="nn">Np</span><span class="p">.</span><span class="nn">Obj</span><span class="p">.</span><span class="n">t</span>
</code></pre></div>

<p>Return the index of the leaf that each sample is predicted as.</p>
<p>.. versionadded:: 0.17</p>
<h4>Parameters</h4>
<details class="info" open="open"><summary>X : {array-like, sparse matrix} of shape (n_samples, n_features)</summary><p>The input samples. Internally, it will be converted to
<code>dtype=np.float32</code> and if a sparse matrix is provided
to a sparse <code>csr_matrix</code>.</p>
</details>
<details class="info" open="open"><summary>check_input : bool, default=True</summary><p>Allow to bypass several input checking.
Don't use this parameter unless you know what you do.</p>
</details>
<h4>Returns</h4>
<details class="info" open="open"><summary>X_leaves : array-like of shape (n_samples,)</summary><p>For each datapoint x in X, return the index of the leaf x
ends up in. Leaves are numbered within
<code>[0; self.tree_.node_count)</code>, possibly with gaps in the
numbering.</p>
</details>
</details>
<h3 id="cost_complexity_pruning_path">cost_complexity_pruning_path<a class="headerlink" href="#cost_complexity_pruning_path" title="Permanent link">&para;</a></h3>
<details class="note" open="open"><summary>method</summary><div class="highlight"><pre><span></span><code><span class="k">val</span> <span class="n">cost_complexity_pruning_path</span> <span class="o">:</span>
  <span class="o">?</span><span class="n">sample_weight</span><span class="o">:[&gt;`</span><span class="nc">ArrayLike</span><span class="o">]</span> <span class="nn">Np</span><span class="p">.</span><span class="nn">Obj</span><span class="p">.</span><span class="n">t</span> <span class="o">-&gt;</span>
  <span class="n">x</span><span class="o">:[&gt;`</span><span class="nc">ArrayLike</span><span class="o">]</span> <span class="nn">Np</span><span class="p">.</span><span class="nn">Obj</span><span class="p">.</span><span class="n">t</span> <span class="o">-&gt;</span>
  <span class="n">y</span><span class="o">:[&gt;`</span><span class="nc">ArrayLike</span><span class="o">]</span> <span class="nn">Np</span><span class="p">.</span><span class="nn">Obj</span><span class="p">.</span><span class="n">t</span> <span class="o">-&gt;</span>
  <span class="o">[&gt;</span> <span class="n">tag</span><span class="o">]</span> <span class="nn">Obj</span><span class="p">.</span><span class="n">t</span> <span class="o">-&gt;</span>
  <span class="o">(</span><span class="nn">Py</span><span class="p">.</span><span class="nn">Object</span><span class="p">.</span><span class="n">t</span> <span class="o">*</span> <span class="o">[&gt;`</span><span class="nc">ArrayLike</span><span class="o">]</span> <span class="nn">Np</span><span class="p">.</span><span class="nn">Obj</span><span class="p">.</span><span class="n">t</span> <span class="o">*</span> <span class="o">[&gt;`</span><span class="nc">ArrayLike</span><span class="o">]</span> <span class="nn">Np</span><span class="p">.</span><span class="nn">Obj</span><span class="p">.</span><span class="n">t</span><span class="o">)</span>
</code></pre></div>

<p>Compute the pruning path during Minimal Cost-Complexity Pruning.</p>
<details class="info" open="open"><summary>See :ref:<code>minimal_cost_complexity_pruning</code> for details on the pruning</summary></details>
<p>process.</p>
<h4>Parameters</h4>
<details class="info" open="open"><summary>X : {array-like, sparse matrix} of shape (n_samples, n_features)</summary><p>The training input samples. Internally, it will be converted to
<code>dtype=np.float32</code> and if a sparse matrix is provided
to a sparse <code>csc_matrix</code>.</p>
</details>
<details class="info" open="open"><summary>y : array-like of shape (n_samples,) or (n_samples, n_outputs)</summary><p>The target values (class labels) as integers or strings.</p>
</details>
<details class="info" open="open"><summary>sample_weight : array-like of shape (n_samples,), default=None</summary><p>Sample weights. If None, then samples are equally weighted. Splits
that would create child nodes with net zero or negative weight are
ignored while searching for a split in each node. Splits are also
ignored if they would result in any single class carrying a
negative weight in either child node.</p>
</details>
<h4>Returns</h4>
<details class="info" open="open"><summary>ccp_path : :class:<code>~sklearn.utils.Bunch</code></summary><p>Dictionary-like object, with the following attributes.</p>
</details>
<details class="info" open="open"><summary>ccp_alphas : ndarray</summary><div class="codehilite"><pre><span></span><code>Effective alphas of subtree during pruning.
</code></pre></div>


</details>
<details class="info" open="open"><summary>impurities : ndarray</summary><div class="codehilite"><pre><span></span><code>Sum of the impurities of the subtree leaves for the
corresponding alpha value in ``ccp_alphas``.
</code></pre></div>


</details>
</details>
<h3 id="decision_path">decision_path<a class="headerlink" href="#decision_path" title="Permanent link">&para;</a></h3>
<details class="note" open="open"><summary>method</summary><div class="highlight"><pre><span></span><code><span class="k">val</span> <span class="n">decision_path</span> <span class="o">:</span>
  <span class="o">?</span><span class="n">check_input</span><span class="o">:</span><span class="kt">bool</span> <span class="o">-&gt;</span>
  <span class="n">x</span><span class="o">:[&gt;`</span><span class="nc">ArrayLike</span><span class="o">]</span> <span class="nn">Np</span><span class="p">.</span><span class="nn">Obj</span><span class="p">.</span><span class="n">t</span> <span class="o">-&gt;</span>
  <span class="o">[&gt;</span> <span class="n">tag</span><span class="o">]</span> <span class="nn">Obj</span><span class="p">.</span><span class="n">t</span> <span class="o">-&gt;</span>
  <span class="o">[`</span><span class="nc">ArrayLike</span><span class="o">|`</span><span class="nc">Object</span><span class="o">|`</span><span class="nc">Spmatrix</span><span class="o">]</span> <span class="nn">Np</span><span class="p">.</span><span class="nn">Obj</span><span class="p">.</span><span class="n">t</span>
</code></pre></div>

<p>Return the decision path in the tree.</p>
<p>.. versionadded:: 0.18</p>
<h4>Parameters</h4>
<details class="info" open="open"><summary>X : {array-like, sparse matrix} of shape (n_samples, n_features)</summary><p>The input samples. Internally, it will be converted to
<code>dtype=np.float32</code> and if a sparse matrix is provided
to a sparse <code>csr_matrix</code>.</p>
</details>
<details class="info" open="open"><summary>check_input : bool, default=True</summary><p>Allow to bypass several input checking.
Don't use this parameter unless you know what you do.</p>
</details>
<h4>Returns</h4>
<details class="info" open="open"><summary>indicator : sparse matrix of shape (n_samples, n_nodes)</summary><p>Return a node indicator CSR matrix where non zero elements
indicates that the samples goes through the nodes.</p>
</details>
</details>
<h3 id="fit">fit<a class="headerlink" href="#fit" title="Permanent link">&para;</a></h3>
<details class="note" open="open"><summary>method</summary><div class="highlight"><pre><span></span><code><span class="k">val</span> <span class="n">fit</span> <span class="o">:</span>
  <span class="o">?</span><span class="n">sample_weight</span><span class="o">:</span><span class="nn">Py</span><span class="p">.</span><span class="nn">Object</span><span class="p">.</span><span class="n">t</span> <span class="o">-&gt;</span>
  <span class="o">?</span><span class="n">check_input</span><span class="o">:</span><span class="nn">Py</span><span class="p">.</span><span class="nn">Object</span><span class="p">.</span><span class="n">t</span> <span class="o">-&gt;</span>
  <span class="o">?</span><span class="n">x_idx_sorted</span><span class="o">:</span><span class="nn">Py</span><span class="p">.</span><span class="nn">Object</span><span class="p">.</span><span class="n">t</span> <span class="o">-&gt;</span>
  <span class="n">x</span><span class="o">:</span><span class="nn">Py</span><span class="p">.</span><span class="nn">Object</span><span class="p">.</span><span class="n">t</span> <span class="o">-&gt;</span>
  <span class="n">y</span><span class="o">:</span><span class="nn">Py</span><span class="p">.</span><span class="nn">Object</span><span class="p">.</span><span class="n">t</span> <span class="o">-&gt;</span>
  <span class="o">[&gt;</span> <span class="n">tag</span><span class="o">]</span> <span class="nn">Obj</span><span class="p">.</span><span class="n">t</span> <span class="o">-&gt;</span>
  <span class="n">t</span>
</code></pre></div>

</details>
<h3 id="get_depth">get_depth<a class="headerlink" href="#get_depth" title="Permanent link">&para;</a></h3>
<details class="note" open="open"><summary>method</summary><div class="highlight"><pre><span></span><code><span class="k">val</span> <span class="n">get_depth</span> <span class="o">:</span>
  <span class="o">[&gt;</span> <span class="n">tag</span><span class="o">]</span> <span class="nn">Obj</span><span class="p">.</span><span class="n">t</span> <span class="o">-&gt;</span>
  <span class="nn">Py</span><span class="p">.</span><span class="nn">Object</span><span class="p">.</span><span class="n">t</span>
</code></pre></div>

<p>Return the depth of the decision tree.</p>
<p>The depth of a tree is the maximum distance between the root
and any leaf.</p>
<h4>Returns</h4>
<details class="info" open="open"><summary>self.tree_.max_depth : int</summary><p>The maximum depth of the tree.</p>
</details>
</details>
<h3 id="get_n_leaves">get_n_leaves<a class="headerlink" href="#get_n_leaves" title="Permanent link">&para;</a></h3>
<details class="note" open="open"><summary>method</summary><div class="highlight"><pre><span></span><code><span class="k">val</span> <span class="n">get_n_leaves</span> <span class="o">:</span>
  <span class="o">[&gt;</span> <span class="n">tag</span><span class="o">]</span> <span class="nn">Obj</span><span class="p">.</span><span class="n">t</span> <span class="o">-&gt;</span>
  <span class="nn">Py</span><span class="p">.</span><span class="nn">Object</span><span class="p">.</span><span class="n">t</span>
</code></pre></div>

<p>Return the number of leaves of the decision tree.</p>
<h4>Returns</h4>
<details class="info" open="open"><summary>self.tree_.n_leaves : int</summary><p>Number of leaves.</p>
</details>
</details>
<h3 id="get_params">get_params<a class="headerlink" href="#get_params" title="Permanent link">&para;</a></h3>
<details class="note" open="open"><summary>method</summary><div class="highlight"><pre><span></span><code><span class="k">val</span> <span class="n">get_params</span> <span class="o">:</span>
  <span class="o">?</span><span class="n">deep</span><span class="o">:</span><span class="kt">bool</span> <span class="o">-&gt;</span>
  <span class="o">[&gt;</span> <span class="n">tag</span><span class="o">]</span> <span class="nn">Obj</span><span class="p">.</span><span class="n">t</span> <span class="o">-&gt;</span>
  <span class="nn">Dict</span><span class="p">.</span><span class="n">t</span>
</code></pre></div>

<p>Get parameters for this estimator.</p>
<h4>Parameters</h4>
<details class="info" open="open"><summary>deep : bool, default=True</summary><p>If True, will return the parameters for this estimator and
contained subobjects that are estimators.</p>
</details>
<h4>Returns</h4>
<details class="info" open="open"><summary>params : mapping of string to any</summary><p>Parameter names mapped to their values.</p>
</details>
</details>
<h3 id="predict">predict<a class="headerlink" href="#predict" title="Permanent link">&para;</a></h3>
<details class="note" open="open"><summary>method</summary><div class="highlight"><pre><span></span><code><span class="k">val</span> <span class="n">predict</span> <span class="o">:</span>
  <span class="o">?</span><span class="n">check_input</span><span class="o">:</span><span class="kt">bool</span> <span class="o">-&gt;</span>
  <span class="n">x</span><span class="o">:[&gt;`</span><span class="nc">ArrayLike</span><span class="o">]</span> <span class="nn">Np</span><span class="p">.</span><span class="nn">Obj</span><span class="p">.</span><span class="n">t</span> <span class="o">-&gt;</span>
  <span class="o">[&gt;</span> <span class="n">tag</span><span class="o">]</span> <span class="nn">Obj</span><span class="p">.</span><span class="n">t</span> <span class="o">-&gt;</span>
  <span class="o">[&gt;`</span><span class="nc">ArrayLike</span><span class="o">]</span> <span class="nn">Np</span><span class="p">.</span><span class="nn">Obj</span><span class="p">.</span><span class="n">t</span>
</code></pre></div>

<p>Predict class or regression value for X.</p>
<p>For a classification model, the predicted class for each sample in X is
returned. For a regression model, the predicted value based on X is
returned.</p>
<h4>Parameters</h4>
<details class="info" open="open"><summary>X : {array-like, sparse matrix} of shape (n_samples, n_features)</summary><p>The input samples. Internally, it will be converted to
<code>dtype=np.float32</code> and if a sparse matrix is provided
to a sparse <code>csr_matrix</code>.</p>
</details>
<details class="info" open="open"><summary>check_input : bool, default=True</summary><p>Allow to bypass several input checking.
Don't use this parameter unless you know what you do.</p>
</details>
<h4>Returns</h4>
<details class="info" open="open"><summary>y : array-like of shape (n_samples,) or (n_samples, n_outputs)</summary><p>The predicted classes, or the predict values.</p>
</details>
</details>
<h3 id="set_params">set_params<a class="headerlink" href="#set_params" title="Permanent link">&para;</a></h3>
<details class="note" open="open"><summary>method</summary><div class="highlight"><pre><span></span><code><span class="k">val</span> <span class="n">set_params</span> <span class="o">:</span>
  <span class="o">?</span><span class="n">params</span><span class="o">:(</span><span class="kt">string</span> <span class="o">*</span> <span class="nn">Py</span><span class="p">.</span><span class="nn">Object</span><span class="p">.</span><span class="n">t</span><span class="o">)</span> <span class="kt">list</span> <span class="o">-&gt;</span>
  <span class="o">[&gt;</span> <span class="n">tag</span><span class="o">]</span> <span class="nn">Obj</span><span class="p">.</span><span class="n">t</span> <span class="o">-&gt;</span>
  <span class="n">t</span>
</code></pre></div>

<p>Set the parameters of this estimator.</p>
<p>The method works on simple estimators as well as on nested objects
(such as pipelines). The latter have parameters of the form
<code>&lt;component&gt;__&lt;parameter&gt;</code> so that it's possible to update each
component of a nested object.</p>
<h4>Parameters</h4>
<details class="info" open="open"><summary>**params : dict</summary><p>Estimator parameters.</p>
</details>
<h4>Returns</h4>
<details class="info" open="open"><summary>self : object</summary><p>Estimator instance.</p>
</details>
</details>
<h3 id="to_string">to_string<a class="headerlink" href="#to_string" title="Permanent link">&para;</a></h3>
<details class="note" open="open"><summary>method</summary><div class="highlight"><pre><span></span><code><span class="k">val</span> <span class="n">to_string</span><span class="o">:</span> <span class="n">t</span> <span class="o">-&gt;</span> <span class="kt">string</span>
</code></pre></div>

<p>Print the object to a human-readable representation.</p>
</details>
<h3 id="show">show<a class="headerlink" href="#show" title="Permanent link">&para;</a></h3>
<details class="note" open="open"><summary>method</summary><div class="highlight"><pre><span></span><code><span class="k">val</span> <span class="n">show</span><span class="o">:</span> <span class="n">t</span> <span class="o">-&gt;</span> <span class="kt">string</span>
</code></pre></div>

<p>Print the object to a human-readable representation.</p>
</details>
<h3 id="pp">pp<a class="headerlink" href="#pp" title="Permanent link">&para;</a></h3>
<details class="note" open="open"><summary>method</summary><div class="highlight"><pre><span></span><code><span class="k">val</span> <span class="n">pp</span><span class="o">:</span> <span class="nn">Format</span><span class="p">.</span><span class="n">formatter</span> <span class="o">-&gt;</span> <span class="n">t</span> <span class="o">-&gt;</span> <span class="kt">unit</span>
</code></pre></div>

<p>Pretty-print the object to a formatter.</p>
</details>
<h2 id="decisiontreeclassifier">DecisionTreeClassifier<a class="headerlink" href="#decisiontreeclassifier" title="Permanent link">&para;</a></h2>
<p>Module <code>Sklearn.Tree.DecisionTreeClassifier</code> wraps Python class <a href="https://scikit-learn.org/stable/modules/generated/sklearn.tree.DecisionTreeClassifier.html"><code>sklearn.tree.DecisionTreeClassifier</code></a>.</p>
<div class="highlight"><pre><span></span><code><span class="k">type</span> <span class="n">t</span>
</code></pre></div>

<h3 id="create">create<a class="headerlink" href="#create" title="Permanent link">&para;</a></h3>
<details class="note" open="open"><summary>constructor and attributes</summary><div class="highlight"><pre><span></span><code><span class="k">val</span> <span class="n">create</span> <span class="o">:</span>
  <span class="o">?</span><span class="n">criterion</span><span class="o">:[`</span><span class="nc">Gini</span> <span class="o">|</span> <span class="o">`</span><span class="nc">Entropy</span><span class="o">]</span> <span class="o">-&gt;</span>
  <span class="o">?</span><span class="n">splitter</span><span class="o">:[`</span><span class="nc">Best</span> <span class="o">|</span> <span class="o">`</span><span class="nc">Random</span><span class="o">]</span> <span class="o">-&gt;</span>
  <span class="o">?</span><span class="n">max_depth</span><span class="o">:</span><span class="kt">int</span> <span class="o">-&gt;</span>
  <span class="o">?</span><span class="n">min_samples_split</span><span class="o">:[`</span><span class="nc">I</span> <span class="k">of</span> <span class="kt">int</span> <span class="o">|</span> <span class="o">`</span><span class="nc">F</span> <span class="k">of</span> <span class="kt">float</span><span class="o">]</span> <span class="o">-&gt;</span>
  <span class="o">?</span><span class="n">min_samples_leaf</span><span class="o">:[`</span><span class="nc">I</span> <span class="k">of</span> <span class="kt">int</span> <span class="o">|</span> <span class="o">`</span><span class="nc">F</span> <span class="k">of</span> <span class="kt">float</span><span class="o">]</span> <span class="o">-&gt;</span>
  <span class="o">?</span><span class="n">min_weight_fraction_leaf</span><span class="o">:</span><span class="kt">float</span> <span class="o">-&gt;</span>
  <span class="o">?</span><span class="n">max_features</span><span class="o">:[`</span><span class="nc">F</span> <span class="k">of</span> <span class="kt">float</span> <span class="o">|</span> <span class="o">`</span><span class="nc">Auto</span> <span class="o">|</span> <span class="o">`</span><span class="nc">Sqrt</span> <span class="o">|</span> <span class="o">`</span><span class="nc">Log2</span> <span class="o">|</span> <span class="o">`</span><span class="nc">I</span> <span class="k">of</span> <span class="kt">int</span><span class="o">]</span> <span class="o">-&gt;</span>
  <span class="o">?</span><span class="n">random_state</span><span class="o">:</span><span class="kt">int</span> <span class="o">-&gt;</span>
  <span class="o">?</span><span class="n">max_leaf_nodes</span><span class="o">:</span><span class="kt">int</span> <span class="o">-&gt;</span>
  <span class="o">?</span><span class="n">min_impurity_decrease</span><span class="o">:</span><span class="kt">float</span> <span class="o">-&gt;</span>
  <span class="o">?</span><span class="n">min_impurity_split</span><span class="o">:</span><span class="kt">float</span> <span class="o">-&gt;</span>
  <span class="o">?</span><span class="n">class_weight</span><span class="o">:[`</span><span class="nc">List_of_dict</span> <span class="k">of</span> <span class="nn">Py</span><span class="p">.</span><span class="nn">Object</span><span class="p">.</span><span class="n">t</span> <span class="o">|</span> <span class="o">`</span><span class="nc">Balanced</span> <span class="o">|</span> <span class="o">`</span><span class="nc">DictIntToFloat</span> <span class="k">of</span> <span class="o">(</span><span class="kt">int</span> <span class="o">*</span> <span class="kt">float</span><span class="o">)</span> <span class="kt">list</span><span class="o">]</span> <span class="o">-&gt;</span>
  <span class="o">?</span><span class="n">presort</span><span class="o">:</span><span class="nn">Py</span><span class="p">.</span><span class="nn">Object</span><span class="p">.</span><span class="n">t</span> <span class="o">-&gt;</span>
  <span class="o">?</span><span class="n">ccp_alpha</span><span class="o">:</span><span class="kt">float</span> <span class="o">-&gt;</span>
  <span class="kt">unit</span> <span class="o">-&gt;</span>
  <span class="n">t</span>
</code></pre></div>

<p>A decision tree classifier.</p>
<p>Read more in the :ref:<code>User Guide &lt;tree&gt;</code>.</p>
<h4>Parameters</h4>
<details class="info" open="open"><summary>criterion : {'gini', 'entropy'}, default='gini'</summary><p>The function to measure the quality of a split. Supported criteria are
'gini' for the Gini impurity and 'entropy' for the information gain.</p>
</details>
<details class="info" open="open"><summary>splitter : {'best', 'random'}, default='best'</summary><p>The strategy used to choose the split at each node. Supported
strategies are 'best' to choose the best split and 'random' to choose
the best random split.</p>
</details>
<details class="info" open="open"><summary>max_depth : int, default=None</summary><p>The maximum depth of the tree. If None, then nodes are expanded until
all leaves are pure or until all leaves contain less than
min_samples_split samples.</p>
</details>
<details class="info" open="open"><summary>min_samples_split : int or float, default=2</summary><p>The minimum number of samples required to split an internal node:</p>
<ul>
<li>If int, then consider <code>min_samples_split</code> as the minimum number.</li>
<li>If float, then <code>min_samples_split</code> is a fraction and
  <code>ceil(min_samples_split * n_samples)</code> are the minimum
  number of samples for each split.</li>
</ul>
<p>.. versionchanged:: 0.18
   Added float values for fractions.</p>
</details>
<details class="info" open="open"><summary>min_samples_leaf : int or float, default=1</summary><p>The minimum number of samples required to be at a leaf node.
A split point at any depth will only be considered if it leaves at
least <code>min_samples_leaf</code> training samples in each of the left and
right branches.  This may have the effect of smoothing the model,
especially in regression.</p>
<ul>
<li>If int, then consider <code>min_samples_leaf</code> as the minimum number.</li>
<li>If float, then <code>min_samples_leaf</code> is a fraction and
  <code>ceil(min_samples_leaf * n_samples)</code> are the minimum
  number of samples for each node.</li>
</ul>
<p>.. versionchanged:: 0.18
   Added float values for fractions.</p>
</details>
<details class="info" open="open"><summary>min_weight_fraction_leaf : float, default=0.0</summary><p>The minimum weighted fraction of the sum total of weights (of all
the input samples) required to be at a leaf node. Samples have
equal weight when sample_weight is not provided.</p>
</details>
<details class="info" open="open"><summary>max_features : int, float or {'auto', 'sqrt', 'log2'}, default=None</summary><p>The number of features to consider when looking for the best split:</p>
<div class="codehilite"><pre><span></span><code>- If int, then consider `max_features` features at each split.
- If float, then `max_features` is a fraction and
  `int(max_features * n_features)` features are considered at each
  split.
- If &#39;auto&#39;, then `max_features=sqrt(n_features)`.
- If &#39;sqrt&#39;, then `max_features=sqrt(n_features)`.
- If &#39;log2&#39;, then `max_features=log2(n_features)`.
- If None, then `max_features=n_features`.
</code></pre></div>


</details>
<details class="info" open="open"><summary>Note: the search for a split does not stop until at least one</summary><p>valid partition of the node samples is found, even if it requires to
effectively inspect more than <code>max_features</code> features.</p>
</details>
<details class="info" open="open"><summary>random_state : int, RandomState instance, default=None</summary><p>Controls the randomness of the estimator. The features are always
randomly permuted at each split, even if <code>splitter</code> is set to
<code>'best'</code>. When <code>max_features &lt; n_features</code>, the algorithm will
select <code>max_features</code> at random at each split before finding the best
split among them. But the best found split may vary across different
runs, even if <code>max_features=n_features</code>. That is the case, if the
improvement of the criterion is identical for several splits and one
split has to be selected at random. To obtain a deterministic behaviour
during fitting, <code>random_state</code> has to be fixed to an integer.</p>
</details>
<details class="info" open="open"><summary>See :term:<code>Glossary &lt;random_state&gt;</code> for details.</summary></details>
<details class="info" open="open"><summary>max_leaf_nodes : int, default=None</summary><p>Grow a tree with <code>max_leaf_nodes</code> in best-first fashion.
Best nodes are defined as relative reduction in impurity.
If None then unlimited number of leaf nodes.</p>
</details>
<details class="info" open="open"><summary>min_impurity_decrease : float, default=0.0</summary><p>A node will be split if this split induces a decrease of the impurity
greater than or equal to this value.</p>
<p>The weighted impurity decrease equation is the following::</p>
<div class="codehilite"><pre><span></span><code>N_t / N * (impurity - N_t_R / N_t * right_impurity
                    - N_t_L / N_t * left_impurity)
</code></pre></div>


<p>where <code>N</code> is the total number of samples, <code>N_t</code> is the number of
samples at the current node, <code>N_t_L</code> is the number of samples in the
left child, and <code>N_t_R</code> is the number of samples in the right child.</p>
<p><code>N</code>, <code>N_t</code>, <code>N_t_R</code> and <code>N_t_L</code> all refer to the weighted sum,
if <code>sample_weight</code> is passed.</p>
<p>.. versionadded:: 0.19</p>
</details>
<details class="info" open="open"><summary>min_impurity_split : float, default=0</summary><p>Threshold for early stopping in tree growth. A node will split
if its impurity is above the threshold, otherwise it is a leaf.</p>
<p>.. deprecated:: 0.19
   <code>min_impurity_split</code> has been deprecated in favor of
   <code>min_impurity_decrease</code> in 0.19. The default value of
   <code>min_impurity_split</code> has changed from 1e-7 to 0 in 0.23 and it
   will be removed in 0.25. Use <code>min_impurity_decrease</code> instead.</p>
</details>
<details class="info" open="open"><summary>class_weight : dict, list of dict or 'balanced', default=None</summary><p>Weights associated with classes in the form <code>{class_label: weight}</code>.
If None, all classes are supposed to have weight one. For
multi-output problems, a list of dicts can be provided in the same
order as the columns of y.</p>
<p>Note that for multioutput (including multilabel) weights should be
defined for each class of every column in its own dict. For example,
for four-class multilabel classification weights should be
[{0: 1, 1: 1}, {0: 1, 1: 5}, {0: 1, 1: 1}, {0: 1, 1: 1}] instead of
[{1:1}, {2:5}, {3:1}, {4:1}].</p>
<p>The 'balanced' mode uses the values of y to automatically adjust
weights inversely proportional to class frequencies in the input data
as <code>n_samples / (n_classes * np.bincount(y))</code></p>
<p>For multi-output, the weights of each column of y will be multiplied.</p>
<p>Note that these weights will be multiplied with sample_weight (passed
through the fit method) if sample_weight is specified.</p>
</details>
<details class="info" open="open"><summary>presort : deprecated, default='deprecated'</summary><p>This parameter is deprecated and will be removed in v0.24.</p>
<p>.. deprecated:: 0.22</p>
</details>
<details class="info" open="open"><summary>ccp_alpha : non-negative float, default=0.0</summary><p>Complexity parameter used for Minimal Cost-Complexity Pruning. The
subtree with the largest cost complexity that is smaller than
<code>ccp_alpha</code> will be chosen. By default, no pruning is performed. See
:ref:<code>minimal_cost_complexity_pruning</code> for details.</p>
<p>.. versionadded:: 0.22</p>
</details>
<h4>Attributes</h4>
<details class="info" open="open"><summary>classes_ : ndarray of shape (n_classes,) or list of ndarray</summary><p>The classes labels (single output problem),
or a list of arrays of class labels (multi-output problem).</p>
</details>
<details class="info" open="open"><summary>feature_importances_ : ndarray of shape (n_features,)</summary><p>The impurity-based feature importances.
The higher, the more important the feature.
The importance of a feature is computed as the (normalized)
total reduction of the criterion brought by that feature.  It is also
known as the Gini importance [4]_.</p>
</details>
<details class="info" open="open"><summary>Warning: impurity-based feature importances can be misleading for</summary><p>high cardinality features (many unique values). See
:func:<code>sklearn.inspection.permutation_importance</code> as an alternative.</p>
</details>
<details class="info" open="open"><summary>max_features_ : int</summary><p>The inferred value of max_features.</p>
</details>
<details class="info" open="open"><summary>n_classes_ : int or list of int</summary><p>The number of classes (for single output problems),
or a list containing the number of classes for each
output (for multi-output problems).</p>
</details>
<details class="info" open="open"><summary>n_features_ : int</summary><p>The number of features when <code>fit</code> is performed.</p>
</details>
<details class="info" open="open"><summary>n_outputs_ : int</summary><p>The number of outputs when <code>fit</code> is performed.</p>
</details>
<details class="info" open="open"><summary>tree_ : Tree</summary><p>The underlying Tree object. Please refer to
<code>help(sklearn.tree._tree.Tree)</code> for attributes of Tree object and
:ref:<code>sphx_glr_auto_examples_tree_plot_unveil_tree_structure.py</code>
for basic usage of these attributes.</p>
</details>
<h4>See Also</h4>
<details class="info" open="open"><summary>DecisionTreeRegressor : A decision tree regressor.</summary></details>
<h4>Notes</h4>
<p>The default values for the parameters controlling the size of the trees
(e.g. <code>max_depth</code>, <code>min_samples_leaf</code>, etc.) lead to fully grown and
unpruned trees which can potentially be very large on some data sets. To
reduce memory consumption, the complexity and size of the trees should be
controlled by setting those parameter values.</p>
<h4>References</h4>
<p>.. [1] https://en.wikipedia.org/wiki/Decision_tree_learning</p>
<p>.. [2] L. Breiman, J. Friedman, R. Olshen, and C. Stone, 'Classification
       and Regression Trees', Wadsworth, Belmont, CA, 1984.</p>
<p>.. [3] T. Hastie, R. Tibshirani and J. Friedman. 'Elements of Statistical
       Learning', Springer, 2009.</p>
<p>.. [4] L. Breiman, and A. Cutler, 'Random Forests',</p>
<details class="info" open="open"><summary>https://www.stat.berkeley.edu/~breiman/RandomForests/cc_home.htm</summary></details>
<h4>Examples</h4>
<div class="highlight"><pre><span></span><code><span class="o">&gt;&gt;&gt;</span> <span class="kn">from</span> <span class="nn">sklearn.datasets</span> <span class="kn">import</span> <span class="n">load_iris</span>
<span class="o">&gt;&gt;&gt;</span> <span class="kn">from</span> <span class="nn">sklearn.model_selection</span> <span class="kn">import</span> <span class="n">cross_val_score</span>
<span class="o">&gt;&gt;&gt;</span> <span class="kn">from</span> <span class="nn">sklearn.tree</span> <span class="kn">import</span> <span class="n">DecisionTreeClassifier</span>
<span class="o">&gt;&gt;&gt;</span> <span class="n">clf</span> <span class="o">=</span> <span class="n">DecisionTreeClassifier</span><span class="p">(</span><span class="n">random_state</span><span class="o">=</span><span class="mi">0</span><span class="p">)</span>
<span class="o">&gt;&gt;&gt;</span> <span class="n">iris</span> <span class="o">=</span> <span class="n">load_iris</span><span class="p">()</span>
<span class="o">&gt;&gt;&gt;</span> <span class="n">cross_val_score</span><span class="p">(</span><span class="n">clf</span><span class="p">,</span> <span class="n">iris</span><span class="o">.</span><span class="n">data</span><span class="p">,</span> <span class="n">iris</span><span class="o">.</span><span class="n">target</span><span class="p">,</span> <span class="n">cv</span><span class="o">=</span><span class="mi">10</span><span class="p">)</span>
<span class="o">...</span>                             <span class="c1"># doctest: +SKIP</span>
<span class="o">...</span>
<span class="n">array</span><span class="p">([</span> <span class="mf">1.</span>     <span class="p">,</span>  <span class="mf">0.93</span><span class="o">...</span><span class="p">,</span>  <span class="mf">0.86</span><span class="o">...</span><span class="p">,</span>  <span class="mf">0.93</span><span class="o">...</span><span class="p">,</span>  <span class="mf">0.93</span><span class="o">...</span><span class="p">,</span>
        <span class="mf">0.93</span><span class="o">...</span><span class="p">,</span>  <span class="mf">0.93</span><span class="o">...</span><span class="p">,</span>  <span class="mf">1.</span>     <span class="p">,</span>  <span class="mf">0.93</span><span class="o">...</span><span class="p">,</span>  <span class="mf">1.</span>      <span class="p">])</span>
</code></pre></div>

</details>
<h3 id="apply_1">apply<a class="headerlink" href="#apply_1" title="Permanent link">&para;</a></h3>
<details class="note" open="open"><summary>method</summary><div class="highlight"><pre><span></span><code><span class="k">val</span> <span class="n">apply</span> <span class="o">:</span>
  <span class="o">?</span><span class="n">check_input</span><span class="o">:</span><span class="kt">bool</span> <span class="o">-&gt;</span>
  <span class="n">x</span><span class="o">:[&gt;`</span><span class="nc">ArrayLike</span><span class="o">]</span> <span class="nn">Np</span><span class="p">.</span><span class="nn">Obj</span><span class="p">.</span><span class="n">t</span> <span class="o">-&gt;</span>
  <span class="o">[&gt;</span> <span class="n">tag</span><span class="o">]</span> <span class="nn">Obj</span><span class="p">.</span><span class="n">t</span> <span class="o">-&gt;</span>
  <span class="o">[&gt;`</span><span class="nc">ArrayLike</span><span class="o">]</span> <span class="nn">Np</span><span class="p">.</span><span class="nn">Obj</span><span class="p">.</span><span class="n">t</span>
</code></pre></div>

<p>Return the index of the leaf that each sample is predicted as.</p>
<p>.. versionadded:: 0.17</p>
<h4>Parameters</h4>
<details class="info" open="open"><summary>X : {array-like, sparse matrix} of shape (n_samples, n_features)</summary><p>The input samples. Internally, it will be converted to
<code>dtype=np.float32</code> and if a sparse matrix is provided
to a sparse <code>csr_matrix</code>.</p>
</details>
<details class="info" open="open"><summary>check_input : bool, default=True</summary><p>Allow to bypass several input checking.
Don't use this parameter unless you know what you do.</p>
</details>
<h4>Returns</h4>
<details class="info" open="open"><summary>X_leaves : array-like of shape (n_samples,)</summary><p>For each datapoint x in X, return the index of the leaf x
ends up in. Leaves are numbered within
<code>[0; self.tree_.node_count)</code>, possibly with gaps in the
numbering.</p>
</details>
</details>
<h3 id="cost_complexity_pruning_path_1">cost_complexity_pruning_path<a class="headerlink" href="#cost_complexity_pruning_path_1" title="Permanent link">&para;</a></h3>
<details class="note" open="open"><summary>method</summary><div class="highlight"><pre><span></span><code><span class="k">val</span> <span class="n">cost_complexity_pruning_path</span> <span class="o">:</span>
  <span class="o">?</span><span class="n">sample_weight</span><span class="o">:[&gt;`</span><span class="nc">ArrayLike</span><span class="o">]</span> <span class="nn">Np</span><span class="p">.</span><span class="nn">Obj</span><span class="p">.</span><span class="n">t</span> <span class="o">-&gt;</span>
  <span class="n">x</span><span class="o">:[&gt;`</span><span class="nc">ArrayLike</span><span class="o">]</span> <span class="nn">Np</span><span class="p">.</span><span class="nn">Obj</span><span class="p">.</span><span class="n">t</span> <span class="o">-&gt;</span>
  <span class="n">y</span><span class="o">:[&gt;`</span><span class="nc">ArrayLike</span><span class="o">]</span> <span class="nn">Np</span><span class="p">.</span><span class="nn">Obj</span><span class="p">.</span><span class="n">t</span> <span class="o">-&gt;</span>
  <span class="o">[&gt;</span> <span class="n">tag</span><span class="o">]</span> <span class="nn">Obj</span><span class="p">.</span><span class="n">t</span> <span class="o">-&gt;</span>
  <span class="o">(</span><span class="nn">Py</span><span class="p">.</span><span class="nn">Object</span><span class="p">.</span><span class="n">t</span> <span class="o">*</span> <span class="o">[&gt;`</span><span class="nc">ArrayLike</span><span class="o">]</span> <span class="nn">Np</span><span class="p">.</span><span class="nn">Obj</span><span class="p">.</span><span class="n">t</span> <span class="o">*</span> <span class="o">[&gt;`</span><span class="nc">ArrayLike</span><span class="o">]</span> <span class="nn">Np</span><span class="p">.</span><span class="nn">Obj</span><span class="p">.</span><span class="n">t</span><span class="o">)</span>
</code></pre></div>

<p>Compute the pruning path during Minimal Cost-Complexity Pruning.</p>
<details class="info" open="open"><summary>See :ref:<code>minimal_cost_complexity_pruning</code> for details on the pruning</summary></details>
<p>process.</p>
<h4>Parameters</h4>
<details class="info" open="open"><summary>X : {array-like, sparse matrix} of shape (n_samples, n_features)</summary><p>The training input samples. Internally, it will be converted to
<code>dtype=np.float32</code> and if a sparse matrix is provided
to a sparse <code>csc_matrix</code>.</p>
</details>
<details class="info" open="open"><summary>y : array-like of shape (n_samples,) or (n_samples, n_outputs)</summary><p>The target values (class labels) as integers or strings.</p>
</details>
<details class="info" open="open"><summary>sample_weight : array-like of shape (n_samples,), default=None</summary><p>Sample weights. If None, then samples are equally weighted. Splits
that would create child nodes with net zero or negative weight are
ignored while searching for a split in each node. Splits are also
ignored if they would result in any single class carrying a
negative weight in either child node.</p>
</details>
<h4>Returns</h4>
<details class="info" open="open"><summary>ccp_path : :class:<code>~sklearn.utils.Bunch</code></summary><p>Dictionary-like object, with the following attributes.</p>
</details>
<details class="info" open="open"><summary>ccp_alphas : ndarray</summary><div class="codehilite"><pre><span></span><code>Effective alphas of subtree during pruning.
</code></pre></div>


</details>
<details class="info" open="open"><summary>impurities : ndarray</summary><div class="codehilite"><pre><span></span><code>Sum of the impurities of the subtree leaves for the
corresponding alpha value in ``ccp_alphas``.
</code></pre></div>


</details>
</details>
<h3 id="decision_path_1">decision_path<a class="headerlink" href="#decision_path_1" title="Permanent link">&para;</a></h3>
<details class="note" open="open"><summary>method</summary><div class="highlight"><pre><span></span><code><span class="k">val</span> <span class="n">decision_path</span> <span class="o">:</span>
  <span class="o">?</span><span class="n">check_input</span><span class="o">:</span><span class="kt">bool</span> <span class="o">-&gt;</span>
  <span class="n">x</span><span class="o">:[&gt;`</span><span class="nc">ArrayLike</span><span class="o">]</span> <span class="nn">Np</span><span class="p">.</span><span class="nn">Obj</span><span class="p">.</span><span class="n">t</span> <span class="o">-&gt;</span>
  <span class="o">[&gt;</span> <span class="n">tag</span><span class="o">]</span> <span class="nn">Obj</span><span class="p">.</span><span class="n">t</span> <span class="o">-&gt;</span>
  <span class="o">[`</span><span class="nc">ArrayLike</span><span class="o">|`</span><span class="nc">Object</span><span class="o">|`</span><span class="nc">Spmatrix</span><span class="o">]</span> <span class="nn">Np</span><span class="p">.</span><span class="nn">Obj</span><span class="p">.</span><span class="n">t</span>
</code></pre></div>

<p>Return the decision path in the tree.</p>
<p>.. versionadded:: 0.18</p>
<h4>Parameters</h4>
<details class="info" open="open"><summary>X : {array-like, sparse matrix} of shape (n_samples, n_features)</summary><p>The input samples. Internally, it will be converted to
<code>dtype=np.float32</code> and if a sparse matrix is provided
to a sparse <code>csr_matrix</code>.</p>
</details>
<details class="info" open="open"><summary>check_input : bool, default=True</summary><p>Allow to bypass several input checking.
Don't use this parameter unless you know what you do.</p>
</details>
<h4>Returns</h4>
<details class="info" open="open"><summary>indicator : sparse matrix of shape (n_samples, n_nodes)</summary><p>Return a node indicator CSR matrix where non zero elements
indicates that the samples goes through the nodes.</p>
</details>
</details>
<h3 id="fit_1">fit<a class="headerlink" href="#fit_1" title="Permanent link">&para;</a></h3>
<details class="note" open="open"><summary>method</summary><div class="highlight"><pre><span></span><code><span class="k">val</span> <span class="n">fit</span> <span class="o">:</span>
  <span class="o">?</span><span class="n">sample_weight</span><span class="o">:[&gt;`</span><span class="nc">ArrayLike</span><span class="o">]</span> <span class="nn">Np</span><span class="p">.</span><span class="nn">Obj</span><span class="p">.</span><span class="n">t</span> <span class="o">-&gt;</span>
  <span class="o">?</span><span class="n">check_input</span><span class="o">:</span><span class="kt">bool</span> <span class="o">-&gt;</span>
  <span class="o">?</span><span class="n">x_idx_sorted</span><span class="o">:[&gt;`</span><span class="nc">ArrayLike</span><span class="o">]</span> <span class="nn">Np</span><span class="p">.</span><span class="nn">Obj</span><span class="p">.</span><span class="n">t</span> <span class="o">-&gt;</span>
  <span class="n">x</span><span class="o">:[&gt;`</span><span class="nc">ArrayLike</span><span class="o">]</span> <span class="nn">Np</span><span class="p">.</span><span class="nn">Obj</span><span class="p">.</span><span class="n">t</span> <span class="o">-&gt;</span>
  <span class="n">y</span><span class="o">:[&gt;`</span><span class="nc">ArrayLike</span><span class="o">]</span> <span class="nn">Np</span><span class="p">.</span><span class="nn">Obj</span><span class="p">.</span><span class="n">t</span> <span class="o">-&gt;</span>
  <span class="o">[&gt;</span> <span class="n">tag</span><span class="o">]</span> <span class="nn">Obj</span><span class="p">.</span><span class="n">t</span> <span class="o">-&gt;</span>
  <span class="n">t</span>
</code></pre></div>

<p>Build a decision tree classifier from the training set (X, y).</p>
<h4>Parameters</h4>
<details class="info" open="open"><summary>X : {array-like, sparse matrix} of shape (n_samples, n_features)</summary><p>The training input samples. Internally, it will be converted to
<code>dtype=np.float32</code> and if a sparse matrix is provided
to a sparse <code>csc_matrix</code>.</p>
</details>
<details class="info" open="open"><summary>y : array-like of shape (n_samples,) or (n_samples, n_outputs)</summary><p>The target values (class labels) as integers or strings.</p>
</details>
<details class="info" open="open"><summary>sample_weight : array-like of shape (n_samples,), default=None</summary><p>Sample weights. If None, then samples are equally weighted. Splits
that would create child nodes with net zero or negative weight are
ignored while searching for a split in each node. Splits are also
ignored if they would result in any single class carrying a
negative weight in either child node.</p>
</details>
<details class="info" open="open"><summary>check_input : bool, default=True</summary><p>Allow to bypass several input checking.
Don't use this parameter unless you know what you do.</p>
</details>
<details class="info" open="open"><summary>X_idx_sorted : array-like of shape (n_samples, n_features),                 default=None</summary><p>The indexes of the sorted training input samples. If many tree
are grown on the same dataset, this allows the ordering to be
cached between trees. If None, the data will be sorted here.
Don't use this parameter unless you know what to do.</p>
</details>
<h4>Returns</h4>
<details class="info" open="open"><summary>self : DecisionTreeClassifier</summary><p>Fitted estimator.</p>
</details>
</details>
<h3 id="get_depth_1">get_depth<a class="headerlink" href="#get_depth_1" title="Permanent link">&para;</a></h3>
<details class="note" open="open"><summary>method</summary><div class="highlight"><pre><span></span><code><span class="k">val</span> <span class="n">get_depth</span> <span class="o">:</span>
  <span class="o">[&gt;</span> <span class="n">tag</span><span class="o">]</span> <span class="nn">Obj</span><span class="p">.</span><span class="n">t</span> <span class="o">-&gt;</span>
  <span class="nn">Py</span><span class="p">.</span><span class="nn">Object</span><span class="p">.</span><span class="n">t</span>
</code></pre></div>

<p>Return the depth of the decision tree.</p>
<p>The depth of a tree is the maximum distance between the root
and any leaf.</p>
<h4>Returns</h4>
<details class="info" open="open"><summary>self.tree_.max_depth : int</summary><p>The maximum depth of the tree.</p>
</details>
</details>
<h3 id="get_n_leaves_1">get_n_leaves<a class="headerlink" href="#get_n_leaves_1" title="Permanent link">&para;</a></h3>
<details class="note" open="open"><summary>method</summary><div class="highlight"><pre><span></span><code><span class="k">val</span> <span class="n">get_n_leaves</span> <span class="o">:</span>
  <span class="o">[&gt;</span> <span class="n">tag</span><span class="o">]</span> <span class="nn">Obj</span><span class="p">.</span><span class="n">t</span> <span class="o">-&gt;</span>
  <span class="nn">Py</span><span class="p">.</span><span class="nn">Object</span><span class="p">.</span><span class="n">t</span>
</code></pre></div>

<p>Return the number of leaves of the decision tree.</p>
<h4>Returns</h4>
<details class="info" open="open"><summary>self.tree_.n_leaves : int</summary><p>Number of leaves.</p>
</details>
</details>
<h3 id="get_params_1">get_params<a class="headerlink" href="#get_params_1" title="Permanent link">&para;</a></h3>
<details class="note" open="open"><summary>method</summary><div class="highlight"><pre><span></span><code><span class="k">val</span> <span class="n">get_params</span> <span class="o">:</span>
  <span class="o">?</span><span class="n">deep</span><span class="o">:</span><span class="kt">bool</span> <span class="o">-&gt;</span>
  <span class="o">[&gt;</span> <span class="n">tag</span><span class="o">]</span> <span class="nn">Obj</span><span class="p">.</span><span class="n">t</span> <span class="o">-&gt;</span>
  <span class="nn">Dict</span><span class="p">.</span><span class="n">t</span>
</code></pre></div>

<p>Get parameters for this estimator.</p>
<h4>Parameters</h4>
<details class="info" open="open"><summary>deep : bool, default=True</summary><p>If True, will return the parameters for this estimator and
contained subobjects that are estimators.</p>
</details>
<h4>Returns</h4>
<details class="info" open="open"><summary>params : mapping of string to any</summary><p>Parameter names mapped to their values.</p>
</details>
</details>
<h3 id="predict_1">predict<a class="headerlink" href="#predict_1" title="Permanent link">&para;</a></h3>
<details class="note" open="open"><summary>method</summary><div class="highlight"><pre><span></span><code><span class="k">val</span> <span class="n">predict</span> <span class="o">:</span>
  <span class="o">?</span><span class="n">check_input</span><span class="o">:</span><span class="kt">bool</span> <span class="o">-&gt;</span>
  <span class="n">x</span><span class="o">:[&gt;`</span><span class="nc">ArrayLike</span><span class="o">]</span> <span class="nn">Np</span><span class="p">.</span><span class="nn">Obj</span><span class="p">.</span><span class="n">t</span> <span class="o">-&gt;</span>
  <span class="o">[&gt;</span> <span class="n">tag</span><span class="o">]</span> <span class="nn">Obj</span><span class="p">.</span><span class="n">t</span> <span class="o">-&gt;</span>
  <span class="o">[&gt;`</span><span class="nc">ArrayLike</span><span class="o">]</span> <span class="nn">Np</span><span class="p">.</span><span class="nn">Obj</span><span class="p">.</span><span class="n">t</span>
</code></pre></div>

<p>Predict class or regression value for X.</p>
<p>For a classification model, the predicted class for each sample in X is
returned. For a regression model, the predicted value based on X is
returned.</p>
<h4>Parameters</h4>
<details class="info" open="open"><summary>X : {array-like, sparse matrix} of shape (n_samples, n_features)</summary><p>The input samples. Internally, it will be converted to
<code>dtype=np.float32</code> and if a sparse matrix is provided
to a sparse <code>csr_matrix</code>.</p>
</details>
<details class="info" open="open"><summary>check_input : bool, default=True</summary><p>Allow to bypass several input checking.
Don't use this parameter unless you know what you do.</p>
</details>
<h4>Returns</h4>
<details class="info" open="open"><summary>y : array-like of shape (n_samples,) or (n_samples, n_outputs)</summary><p>The predicted classes, or the predict values.</p>
</details>
</details>
<h3 id="predict_log_proba">predict_log_proba<a class="headerlink" href="#predict_log_proba" title="Permanent link">&para;</a></h3>
<details class="note" open="open"><summary>method</summary><div class="highlight"><pre><span></span><code><span class="k">val</span> <span class="n">predict_log_proba</span> <span class="o">:</span>
  <span class="n">x</span><span class="o">:[&gt;`</span><span class="nc">ArrayLike</span><span class="o">]</span> <span class="nn">Np</span><span class="p">.</span><span class="nn">Obj</span><span class="p">.</span><span class="n">t</span> <span class="o">-&gt;</span>
  <span class="o">[&gt;</span> <span class="n">tag</span><span class="o">]</span> <span class="nn">Obj</span><span class="p">.</span><span class="n">t</span> <span class="o">-&gt;</span>
  <span class="nn">Py</span><span class="p">.</span><span class="nn">Object</span><span class="p">.</span><span class="n">t</span>
</code></pre></div>

<p>Predict class log-probabilities of the input samples X.</p>
<h4>Parameters</h4>
<details class="info" open="open"><summary>X : {array-like, sparse matrix} of shape (n_samples, n_features)</summary><p>The input samples. Internally, it will be converted to
<code>dtype=np.float32</code> and if a sparse matrix is provided
to a sparse <code>csr_matrix</code>.</p>
</details>
<h4>Returns</h4>
<details class="info" open="open"><summary>proba : ndarray of shape (n_samples, n_classes) or list of n_outputs             such arrays if n_outputs &gt; 1</summary><p>The class log-probabilities of the input samples. The order of the
classes corresponds to that in the attribute :term:<code>classes_</code>.</p>
</details>
</details>
<h3 id="predict_proba">predict_proba<a class="headerlink" href="#predict_proba" title="Permanent link">&para;</a></h3>
<details class="note" open="open"><summary>method</summary><div class="highlight"><pre><span></span><code><span class="k">val</span> <span class="n">predict_proba</span> <span class="o">:</span>
  <span class="o">?</span><span class="n">check_input</span><span class="o">:</span><span class="kt">bool</span> <span class="o">-&gt;</span>
  <span class="n">x</span><span class="o">:[&gt;`</span><span class="nc">ArrayLike</span><span class="o">]</span> <span class="nn">Np</span><span class="p">.</span><span class="nn">Obj</span><span class="p">.</span><span class="n">t</span> <span class="o">-&gt;</span>
  <span class="o">[&gt;</span> <span class="n">tag</span><span class="o">]</span> <span class="nn">Obj</span><span class="p">.</span><span class="n">t</span> <span class="o">-&gt;</span>
  <span class="o">[&gt;`</span><span class="nc">ArrayLike</span><span class="o">]</span> <span class="nn">Np</span><span class="p">.</span><span class="nn">Obj</span><span class="p">.</span><span class="n">t</span>
</code></pre></div>

<p>Predict class probabilities of the input samples X.</p>
<p>The predicted class probability is the fraction of samples of the same
class in a leaf.</p>
<h4>Parameters</h4>
<details class="info" open="open"><summary>X : {array-like, sparse matrix} of shape (n_samples, n_features)</summary><p>The input samples. Internally, it will be converted to
<code>dtype=np.float32</code> and if a sparse matrix is provided
to a sparse <code>csr_matrix</code>.</p>
</details>
<details class="info" open="open"><summary>check_input : bool, default=True</summary><p>Allow to bypass several input checking.
Don't use this parameter unless you know what you do.</p>
</details>
<h4>Returns</h4>
<details class="info" open="open"><summary>proba : ndarray of shape (n_samples, n_classes) or list of n_outputs             such arrays if n_outputs &gt; 1</summary><p>The class probabilities of the input samples. The order of the
classes corresponds to that in the attribute :term:<code>classes_</code>.</p>
</details>
</details>
<h3 id="score">score<a class="headerlink" href="#score" title="Permanent link">&para;</a></h3>
<details class="note" open="open"><summary>method</summary><div class="highlight"><pre><span></span><code><span class="k">val</span> <span class="n">score</span> <span class="o">:</span>
  <span class="o">?</span><span class="n">sample_weight</span><span class="o">:[&gt;`</span><span class="nc">ArrayLike</span><span class="o">]</span> <span class="nn">Np</span><span class="p">.</span><span class="nn">Obj</span><span class="p">.</span><span class="n">t</span> <span class="o">-&gt;</span>
  <span class="n">x</span><span class="o">:[&gt;`</span><span class="nc">ArrayLike</span><span class="o">]</span> <span class="nn">Np</span><span class="p">.</span><span class="nn">Obj</span><span class="p">.</span><span class="n">t</span> <span class="o">-&gt;</span>
  <span class="n">y</span><span class="o">:[&gt;`</span><span class="nc">ArrayLike</span><span class="o">]</span> <span class="nn">Np</span><span class="p">.</span><span class="nn">Obj</span><span class="p">.</span><span class="n">t</span> <span class="o">-&gt;</span>
  <span class="o">[&gt;</span> <span class="n">tag</span><span class="o">]</span> <span class="nn">Obj</span><span class="p">.</span><span class="n">t</span> <span class="o">-&gt;</span>
  <span class="kt">float</span>
</code></pre></div>

<p>Return the mean accuracy on the given test data and labels.</p>
<p>In multi-label classification, this is the subset accuracy
which is a harsh metric since you require for each sample that
each label set be correctly predicted.</p>
<h4>Parameters</h4>
<details class="info" open="open"><summary>X : array-like of shape (n_samples, n_features)</summary><p>Test samples.</p>
</details>
<details class="info" open="open"><summary>y : array-like of shape (n_samples,) or (n_samples, n_outputs)</summary><p>True labels for X.</p>
</details>
<details class="info" open="open"><summary>sample_weight : array-like of shape (n_samples,), default=None</summary><p>Sample weights.</p>
</details>
<h4>Returns</h4>
<details class="info" open="open"><summary>score : float</summary><p>Mean accuracy of self.predict(X) wrt. y.</p>
</details>
</details>
<h3 id="set_params_1">set_params<a class="headerlink" href="#set_params_1" title="Permanent link">&para;</a></h3>
<details class="note" open="open"><summary>method</summary><div class="highlight"><pre><span></span><code><span class="k">val</span> <span class="n">set_params</span> <span class="o">:</span>
  <span class="o">?</span><span class="n">params</span><span class="o">:(</span><span class="kt">string</span> <span class="o">*</span> <span class="nn">Py</span><span class="p">.</span><span class="nn">Object</span><span class="p">.</span><span class="n">t</span><span class="o">)</span> <span class="kt">list</span> <span class="o">-&gt;</span>
  <span class="o">[&gt;</span> <span class="n">tag</span><span class="o">]</span> <span class="nn">Obj</span><span class="p">.</span><span class="n">t</span> <span class="o">-&gt;</span>
  <span class="n">t</span>
</code></pre></div>

<p>Set the parameters of this estimator.</p>
<p>The method works on simple estimators as well as on nested objects
(such as pipelines). The latter have parameters of the form
<code>&lt;component&gt;__&lt;parameter&gt;</code> so that it's possible to update each
component of a nested object.</p>
<h4>Parameters</h4>
<details class="info" open="open"><summary>**params : dict</summary><p>Estimator parameters.</p>
</details>
<h4>Returns</h4>
<details class="info" open="open"><summary>self : object</summary><p>Estimator instance.</p>
</details>
</details>
<h3 id="classes_">classes_<a class="headerlink" href="#classes_" title="Permanent link">&para;</a></h3>
<details class="note" open="open"><summary>attribute</summary><div class="highlight"><pre><span></span><code><span class="k">val</span> <span class="n">classes_</span> <span class="o">:</span> <span class="n">t</span> <span class="o">-&gt;</span> <span class="o">[&gt;`</span><span class="nc">ArrayLike</span><span class="o">]</span> <span class="nn">Np</span><span class="p">.</span><span class="nn">Obj</span><span class="p">.</span><span class="n">t</span>
<span class="k">val</span> <span class="n">classes_opt</span> <span class="o">:</span> <span class="n">t</span> <span class="o">-&gt;</span> <span class="o">([&gt;`</span><span class="nc">ArrayLike</span><span class="o">]</span> <span class="nn">Np</span><span class="p">.</span><span class="nn">Obj</span><span class="p">.</span><span class="n">t</span><span class="o">)</span> <span class="n">option</span>
</code></pre></div>

<p>This attribute is documented in <code>create</code> above. The first version raises Not_found
if the attribute is None. The _opt version returns an option.</p>
</details>
<h3 id="feature_importances_">feature_importances_<a class="headerlink" href="#feature_importances_" title="Permanent link">&para;</a></h3>
<details class="note" open="open"><summary>attribute</summary><div class="highlight"><pre><span></span><code><span class="k">val</span> <span class="n">feature_importances_</span> <span class="o">:</span> <span class="n">t</span> <span class="o">-&gt;</span> <span class="o">[&gt;`</span><span class="nc">ArrayLike</span><span class="o">]</span> <span class="nn">Np</span><span class="p">.</span><span class="nn">Obj</span><span class="p">.</span><span class="n">t</span>
<span class="k">val</span> <span class="n">feature_importances_opt</span> <span class="o">:</span> <span class="n">t</span> <span class="o">-&gt;</span> <span class="o">([&gt;`</span><span class="nc">ArrayLike</span><span class="o">]</span> <span class="nn">Np</span><span class="p">.</span><span class="nn">Obj</span><span class="p">.</span><span class="n">t</span><span class="o">)</span> <span class="n">option</span>
</code></pre></div>

<p>This attribute is documented in <code>create</code> above. The first version raises Not_found
if the attribute is None. The _opt version returns an option.</p>
</details>
<h3 id="warning">warning<a class="headerlink" href="#warning" title="Permanent link">&para;</a></h3>
<details class="note" open="open"><summary>attribute</summary><div class="highlight"><pre><span></span><code><span class="k">val</span> <span class="n">warning</span> <span class="o">:</span> <span class="n">t</span> <span class="o">-&gt;</span> <span class="nn">Py</span><span class="p">.</span><span class="nn">Object</span><span class="p">.</span><span class="n">t</span>
<span class="k">val</span> <span class="n">warning_opt</span> <span class="o">:</span> <span class="n">t</span> <span class="o">-&gt;</span> <span class="o">(</span><span class="nn">Py</span><span class="p">.</span><span class="nn">Object</span><span class="p">.</span><span class="n">t</span><span class="o">)</span> <span class="n">option</span>
</code></pre></div>

<p>This attribute is documented in <code>create</code> above. The first version raises Not_found
if the attribute is None. The _opt version returns an option.</p>
</details>
<h3 id="max_features_">max_features_<a class="headerlink" href="#max_features_" title="Permanent link">&para;</a></h3>
<details class="note" open="open"><summary>attribute</summary><div class="highlight"><pre><span></span><code><span class="k">val</span> <span class="n">max_features_</span> <span class="o">:</span> <span class="n">t</span> <span class="o">-&gt;</span> <span class="kt">int</span>
<span class="k">val</span> <span class="n">max_features_opt</span> <span class="o">:</span> <span class="n">t</span> <span class="o">-&gt;</span> <span class="o">(</span><span class="kt">int</span><span class="o">)</span> <span class="n">option</span>
</code></pre></div>

<p>This attribute is documented in <code>create</code> above. The first version raises Not_found
if the attribute is None. The _opt version returns an option.</p>
</details>
<h3 id="n_classes_">n_classes_<a class="headerlink" href="#n_classes_" title="Permanent link">&para;</a></h3>
<details class="note" open="open"><summary>attribute</summary><div class="highlight"><pre><span></span><code><span class="k">val</span> <span class="n">n_classes_</span> <span class="o">:</span> <span class="n">t</span> <span class="o">-&gt;</span> <span class="nn">Py</span><span class="p">.</span><span class="nn">Object</span><span class="p">.</span><span class="n">t</span>
<span class="k">val</span> <span class="n">n_classes_opt</span> <span class="o">:</span> <span class="n">t</span> <span class="o">-&gt;</span> <span class="o">(</span><span class="nn">Py</span><span class="p">.</span><span class="nn">Object</span><span class="p">.</span><span class="n">t</span><span class="o">)</span> <span class="n">option</span>
</code></pre></div>

<p>This attribute is documented in <code>create</code> above. The first version raises Not_found
if the attribute is None. The _opt version returns an option.</p>
</details>
<h3 id="n_features_">n_features_<a class="headerlink" href="#n_features_" title="Permanent link">&para;</a></h3>
<details class="note" open="open"><summary>attribute</summary><div class="highlight"><pre><span></span><code><span class="k">val</span> <span class="n">n_features_</span> <span class="o">:</span> <span class="n">t</span> <span class="o">-&gt;</span> <span class="kt">int</span>
<span class="k">val</span> <span class="n">n_features_opt</span> <span class="o">:</span> <span class="n">t</span> <span class="o">-&gt;</span> <span class="o">(</span><span class="kt">int</span><span class="o">)</span> <span class="n">option</span>
</code></pre></div>

<p>This attribute is documented in <code>create</code> above. The first version raises Not_found
if the attribute is None. The _opt version returns an option.</p>
</details>
<h3 id="n_outputs_">n_outputs_<a class="headerlink" href="#n_outputs_" title="Permanent link">&para;</a></h3>
<details class="note" open="open"><summary>attribute</summary><div class="highlight"><pre><span></span><code><span class="k">val</span> <span class="n">n_outputs_</span> <span class="o">:</span> <span class="n">t</span> <span class="o">-&gt;</span> <span class="kt">int</span>
<span class="k">val</span> <span class="n">n_outputs_opt</span> <span class="o">:</span> <span class="n">t</span> <span class="o">-&gt;</span> <span class="o">(</span><span class="kt">int</span><span class="o">)</span> <span class="n">option</span>
</code></pre></div>

<p>This attribute is documented in <code>create</code> above. The first version raises Not_found
if the attribute is None. The _opt version returns an option.</p>
</details>
<h3 id="tree_">tree_<a class="headerlink" href="#tree_" title="Permanent link">&para;</a></h3>
<details class="note" open="open"><summary>attribute</summary><div class="highlight"><pre><span></span><code><span class="k">val</span> <span class="n">tree_</span> <span class="o">:</span> <span class="n">t</span> <span class="o">-&gt;</span> <span class="nn">Py</span><span class="p">.</span><span class="nn">Object</span><span class="p">.</span><span class="n">t</span>
<span class="k">val</span> <span class="n">tree_opt</span> <span class="o">:</span> <span class="n">t</span> <span class="o">-&gt;</span> <span class="o">(</span><span class="nn">Py</span><span class="p">.</span><span class="nn">Object</span><span class="p">.</span><span class="n">t</span><span class="o">)</span> <span class="n">option</span>
</code></pre></div>

<p>This attribute is documented in <code>create</code> above. The first version raises Not_found
if the attribute is None. The _opt version returns an option.</p>
</details>
<h3 id="to_string_1">to_string<a class="headerlink" href="#to_string_1" title="Permanent link">&para;</a></h3>
<details class="note" open="open"><summary>method</summary><div class="highlight"><pre><span></span><code><span class="k">val</span> <span class="n">to_string</span><span class="o">:</span> <span class="n">t</span> <span class="o">-&gt;</span> <span class="kt">string</span>
</code></pre></div>

<p>Print the object to a human-readable representation.</p>
</details>
<h3 id="show_1">show<a class="headerlink" href="#show_1" title="Permanent link">&para;</a></h3>
<details class="note" open="open"><summary>method</summary><div class="highlight"><pre><span></span><code><span class="k">val</span> <span class="n">show</span><span class="o">:</span> <span class="n">t</span> <span class="o">-&gt;</span> <span class="kt">string</span>
</code></pre></div>

<p>Print the object to a human-readable representation.</p>
</details>
<h3 id="pp_1">pp<a class="headerlink" href="#pp_1" title="Permanent link">&para;</a></h3>
<details class="note" open="open"><summary>method</summary><div class="highlight"><pre><span></span><code><span class="k">val</span> <span class="n">pp</span><span class="o">:</span> <span class="nn">Format</span><span class="p">.</span><span class="n">formatter</span> <span class="o">-&gt;</span> <span class="n">t</span> <span class="o">-&gt;</span> <span class="kt">unit</span>
</code></pre></div>

<p>Pretty-print the object to a formatter.</p>
</details>
<h2 id="decisiontreeregressor">DecisionTreeRegressor<a class="headerlink" href="#decisiontreeregressor" title="Permanent link">&para;</a></h2>
<p>Module <code>Sklearn.Tree.DecisionTreeRegressor</code> wraps Python class <a href="https://scikit-learn.org/stable/modules/generated/sklearn.tree.DecisionTreeRegressor.html"><code>sklearn.tree.DecisionTreeRegressor</code></a>.</p>
<div class="highlight"><pre><span></span><code><span class="k">type</span> <span class="n">t</span>
</code></pre></div>

<h3 id="create_1">create<a class="headerlink" href="#create_1" title="Permanent link">&para;</a></h3>
<details class="note" open="open"><summary>constructor and attributes</summary><div class="highlight"><pre><span></span><code><span class="k">val</span> <span class="n">create</span> <span class="o">:</span>
  <span class="o">?</span><span class="n">criterion</span><span class="o">:[`</span><span class="nc">Mse</span> <span class="o">|</span> <span class="o">`</span><span class="nc">Friedman_mse</span> <span class="o">|</span> <span class="o">`</span><span class="nc">Mae</span><span class="o">]</span> <span class="o">-&gt;</span>
  <span class="o">?</span><span class="n">splitter</span><span class="o">:[`</span><span class="nc">Best</span> <span class="o">|</span> <span class="o">`</span><span class="nc">Random</span><span class="o">]</span> <span class="o">-&gt;</span>
  <span class="o">?</span><span class="n">max_depth</span><span class="o">:</span><span class="kt">int</span> <span class="o">-&gt;</span>
  <span class="o">?</span><span class="n">min_samples_split</span><span class="o">:[`</span><span class="nc">I</span> <span class="k">of</span> <span class="kt">int</span> <span class="o">|</span> <span class="o">`</span><span class="nc">F</span> <span class="k">of</span> <span class="kt">float</span><span class="o">]</span> <span class="o">-&gt;</span>
  <span class="o">?</span><span class="n">min_samples_leaf</span><span class="o">:[`</span><span class="nc">I</span> <span class="k">of</span> <span class="kt">int</span> <span class="o">|</span> <span class="o">`</span><span class="nc">F</span> <span class="k">of</span> <span class="kt">float</span><span class="o">]</span> <span class="o">-&gt;</span>
  <span class="o">?</span><span class="n">min_weight_fraction_leaf</span><span class="o">:</span><span class="kt">float</span> <span class="o">-&gt;</span>
  <span class="o">?</span><span class="n">max_features</span><span class="o">:[`</span><span class="nc">F</span> <span class="k">of</span> <span class="kt">float</span> <span class="o">|</span> <span class="o">`</span><span class="nc">Auto</span> <span class="o">|</span> <span class="o">`</span><span class="nc">Sqrt</span> <span class="o">|</span> <span class="o">`</span><span class="nc">Log2</span> <span class="o">|</span> <span class="o">`</span><span class="nc">I</span> <span class="k">of</span> <span class="kt">int</span><span class="o">]</span> <span class="o">-&gt;</span>
  <span class="o">?</span><span class="n">random_state</span><span class="o">:</span><span class="kt">int</span> <span class="o">-&gt;</span>
  <span class="o">?</span><span class="n">max_leaf_nodes</span><span class="o">:</span><span class="kt">int</span> <span class="o">-&gt;</span>
  <span class="o">?</span><span class="n">min_impurity_decrease</span><span class="o">:</span><span class="kt">float</span> <span class="o">-&gt;</span>
  <span class="o">?</span><span class="n">min_impurity_split</span><span class="o">:</span><span class="kt">float</span> <span class="o">-&gt;</span>
  <span class="o">?</span><span class="n">presort</span><span class="o">:</span><span class="nn">Py</span><span class="p">.</span><span class="nn">Object</span><span class="p">.</span><span class="n">t</span> <span class="o">-&gt;</span>
  <span class="o">?</span><span class="n">ccp_alpha</span><span class="o">:</span><span class="kt">float</span> <span class="o">-&gt;</span>
  <span class="kt">unit</span> <span class="o">-&gt;</span>
  <span class="n">t</span>
</code></pre></div>

<p>A decision tree regressor.</p>
<p>Read more in the :ref:<code>User Guide &lt;tree&gt;</code>.</p>
<h4>Parameters</h4>
<details class="info" open="open"><summary>criterion : {'mse', 'friedman_mse', 'mae'}, default='mse'</summary><p>The function to measure the quality of a split. Supported criteria
are 'mse' for the mean squared error, which is equal to variance
reduction as feature selection criterion and minimizes the L2 loss
using the mean of each terminal node, 'friedman_mse', which uses mean
squared error with Friedman's improvement score for potential splits,
and 'mae' for the mean absolute error, which minimizes the L1 loss
using the median of each terminal node.</p>
<p>.. versionadded:: 0.18
   Mean Absolute Error (MAE) criterion.</p>
</details>
<details class="info" open="open"><summary>splitter : {'best', 'random'}, default='best'</summary><p>The strategy used to choose the split at each node. Supported
strategies are 'best' to choose the best split and 'random' to choose
the best random split.</p>
</details>
<details class="info" open="open"><summary>max_depth : int, default=None</summary><p>The maximum depth of the tree. If None, then nodes are expanded until
all leaves are pure or until all leaves contain less than
min_samples_split samples.</p>
</details>
<details class="info" open="open"><summary>min_samples_split : int or float, default=2</summary><p>The minimum number of samples required to split an internal node:</p>
<ul>
<li>If int, then consider <code>min_samples_split</code> as the minimum number.</li>
<li>If float, then <code>min_samples_split</code> is a fraction and
  <code>ceil(min_samples_split * n_samples)</code> are the minimum
  number of samples for each split.</li>
</ul>
<p>.. versionchanged:: 0.18
   Added float values for fractions.</p>
</details>
<details class="info" open="open"><summary>min_samples_leaf : int or float, default=1</summary><p>The minimum number of samples required to be at a leaf node.
A split point at any depth will only be considered if it leaves at
least <code>min_samples_leaf</code> training samples in each of the left and
right branches.  This may have the effect of smoothing the model,
especially in regression.</p>
<ul>
<li>If int, then consider <code>min_samples_leaf</code> as the minimum number.</li>
<li>If float, then <code>min_samples_leaf</code> is a fraction and
  <code>ceil(min_samples_leaf * n_samples)</code> are the minimum
  number of samples for each node.</li>
</ul>
<p>.. versionchanged:: 0.18
   Added float values for fractions.</p>
</details>
<details class="info" open="open"><summary>min_weight_fraction_leaf : float, default=0.0</summary><p>The minimum weighted fraction of the sum total of weights (of all
the input samples) required to be at a leaf node. Samples have
equal weight when sample_weight is not provided.</p>
</details>
<details class="info" open="open"><summary>max_features : int, float or {'auto', 'sqrt', 'log2'}, default=None</summary><p>The number of features to consider when looking for the best split:</p>
<ul>
<li>If int, then consider <code>max_features</code> features at each split.</li>
<li>If float, then <code>max_features</code> is a fraction and
  <code>int(max_features * n_features)</code> features are considered at each
  split.</li>
<li>If 'auto', then <code>max_features=n_features</code>.</li>
<li>If 'sqrt', then <code>max_features=sqrt(n_features)</code>.</li>
<li>If 'log2', then <code>max_features=log2(n_features)</code>.</li>
<li>If None, then <code>max_features=n_features</code>.</li>
</ul>
</details>
<details class="info" open="open"><summary>Note: the search for a split does not stop until at least one</summary><p>valid partition of the node samples is found, even if it requires to
effectively inspect more than <code>max_features</code> features.</p>
</details>
<details class="info" open="open"><summary>random_state : int, RandomState instance, default=None</summary><p>Controls the randomness of the estimator. The features are always
randomly permuted at each split, even if <code>splitter</code> is set to
<code>'best'</code>. When <code>max_features &lt; n_features</code>, the algorithm will
select <code>max_features</code> at random at each split before finding the best
split among them. But the best found split may vary across different
runs, even if <code>max_features=n_features</code>. That is the case, if the
improvement of the criterion is identical for several splits and one
split has to be selected at random. To obtain a deterministic behaviour
during fitting, <code>random_state</code> has to be fixed to an integer.</p>
</details>
<details class="info" open="open"><summary>See :term:<code>Glossary &lt;random_state&gt;</code> for details.</summary></details>
<details class="info" open="open"><summary>max_leaf_nodes : int, default=None</summary><p>Grow a tree with <code>max_leaf_nodes</code> in best-first fashion.
Best nodes are defined as relative reduction in impurity.
If None then unlimited number of leaf nodes.</p>
</details>
<details class="info" open="open"><summary>min_impurity_decrease : float, default=0.0</summary><p>A node will be split if this split induces a decrease of the impurity
greater than or equal to this value.</p>
<p>The weighted impurity decrease equation is the following::</p>
<div class="codehilite"><pre><span></span><code>N_t / N * (impurity - N_t_R / N_t * right_impurity
                    - N_t_L / N_t * left_impurity)
</code></pre></div>


<p>where <code>N</code> is the total number of samples, <code>N_t</code> is the number of
samples at the current node, <code>N_t_L</code> is the number of samples in the
left child, and <code>N_t_R</code> is the number of samples in the right child.</p>
<p><code>N</code>, <code>N_t</code>, <code>N_t_R</code> and <code>N_t_L</code> all refer to the weighted sum,
if <code>sample_weight</code> is passed.</p>
<p>.. versionadded:: 0.19</p>
</details>
<details class="info" open="open"><summary>min_impurity_split : float, (default=0)</summary><p>Threshold for early stopping in tree growth. A node will split
if its impurity is above the threshold, otherwise it is a leaf.</p>
<p>.. deprecated:: 0.19
   <code>min_impurity_split</code> has been deprecated in favor of
   <code>min_impurity_decrease</code> in 0.19. The default value of
   <code>min_impurity_split</code> has changed from 1e-7 to 0 in 0.23 and it
   will be removed in 0.25. Use <code>min_impurity_decrease</code> instead.</p>
</details>
<details class="info" open="open"><summary>presort : deprecated, default='deprecated'</summary><p>This parameter is deprecated and will be removed in v0.24.</p>
<p>.. deprecated:: 0.22</p>
</details>
<details class="info" open="open"><summary>ccp_alpha : non-negative float, default=0.0</summary><p>Complexity parameter used for Minimal Cost-Complexity Pruning. The
subtree with the largest cost complexity that is smaller than
<code>ccp_alpha</code> will be chosen. By default, no pruning is performed. See
:ref:<code>minimal_cost_complexity_pruning</code> for details.</p>
<p>.. versionadded:: 0.22</p>
</details>
<h4>Attributes</h4>
<details class="info" open="open"><summary>feature_importances_ : ndarray of shape (n_features,)</summary><p>The feature importances.
The higher, the more important the feature.
The importance of a feature is computed as the
(normalized) total reduction of the criterion brought
by that feature. It is also known as the Gini importance [4]_.</p>
</details>
<details class="info" open="open"><summary>Warning: impurity-based feature importances can be misleading for</summary><p>high cardinality features (many unique values). See
:func:<code>sklearn.inspection.permutation_importance</code> as an alternative.</p>
</details>
<details class="info" open="open"><summary>max_features_ : int</summary><p>The inferred value of max_features.</p>
</details>
<details class="info" open="open"><summary>n_features_ : int</summary><p>The number of features when <code>fit</code> is performed.</p>
</details>
<details class="info" open="open"><summary>n_outputs_ : int</summary><p>The number of outputs when <code>fit</code> is performed.</p>
</details>
<details class="info" open="open"><summary>tree_ : Tree</summary><p>The underlying Tree object. Please refer to
<code>help(sklearn.tree._tree.Tree)</code> for attributes of Tree object and
:ref:<code>sphx_glr_auto_examples_tree_plot_unveil_tree_structure.py</code>
for basic usage of these attributes.</p>
</details>
<h4>See Also</h4>
<details class="info" open="open"><summary>DecisionTreeClassifier : A decision tree classifier.</summary></details>
<h4>Notes</h4>
<p>The default values for the parameters controlling the size of the trees
(e.g. <code>max_depth</code>, <code>min_samples_leaf</code>, etc.) lead to fully grown and
unpruned trees which can potentially be very large on some data sets. To
reduce memory consumption, the complexity and size of the trees should be
controlled by setting those parameter values.</p>
<h4>References</h4>
<p>.. [1] https://en.wikipedia.org/wiki/Decision_tree_learning</p>
<p>.. [2] L. Breiman, J. Friedman, R. Olshen, and C. Stone, 'Classification
       and Regression Trees', Wadsworth, Belmont, CA, 1984.</p>
<p>.. [3] T. Hastie, R. Tibshirani and J. Friedman. 'Elements of Statistical
       Learning', Springer, 2009.</p>
<p>.. [4] L. Breiman, and A. Cutler, 'Random Forests',</p>
<details class="info" open="open"><summary>https://www.stat.berkeley.edu/~breiman/RandomForests/cc_home.htm</summary></details>
<h4>Examples</h4>
<div class="highlight"><pre><span></span><code><span class="o">&gt;&gt;&gt;</span> <span class="kn">from</span> <span class="nn">sklearn.datasets</span> <span class="kn">import</span> <span class="n">load_diabetes</span>
<span class="o">&gt;&gt;&gt;</span> <span class="kn">from</span> <span class="nn">sklearn.model_selection</span> <span class="kn">import</span> <span class="n">cross_val_score</span>
<span class="o">&gt;&gt;&gt;</span> <span class="kn">from</span> <span class="nn">sklearn.tree</span> <span class="kn">import</span> <span class="n">DecisionTreeRegressor</span>
<span class="o">&gt;&gt;&gt;</span> <span class="n">X</span><span class="p">,</span> <span class="n">y</span> <span class="o">=</span> <span class="n">load_diabetes</span><span class="p">(</span><span class="n">return_X_y</span><span class="o">=</span><span class="kc">True</span><span class="p">)</span>
<span class="o">&gt;&gt;&gt;</span> <span class="n">regressor</span> <span class="o">=</span> <span class="n">DecisionTreeRegressor</span><span class="p">(</span><span class="n">random_state</span><span class="o">=</span><span class="mi">0</span><span class="p">)</span>
<span class="o">&gt;&gt;&gt;</span> <span class="n">cross_val_score</span><span class="p">(</span><span class="n">regressor</span><span class="p">,</span> <span class="n">X</span><span class="p">,</span> <span class="n">y</span><span class="p">,</span> <span class="n">cv</span><span class="o">=</span><span class="mi">10</span><span class="p">)</span>
<span class="o">...</span>                    <span class="c1"># doctest: +SKIP</span>
<span class="o">...</span>
<span class="n">array</span><span class="p">([</span><span class="o">-</span><span class="mf">0.39</span><span class="o">...</span><span class="p">,</span> <span class="o">-</span><span class="mf">0.46</span><span class="o">...</span><span class="p">,</span>  <span class="mf">0.02</span><span class="o">...</span><span class="p">,</span>  <span class="mf">0.06</span><span class="o">...</span><span class="p">,</span> <span class="o">-</span><span class="mf">0.50</span><span class="o">...</span><span class="p">,</span>
       <span class="mf">0.16</span><span class="o">...</span><span class="p">,</span>  <span class="mf">0.11</span><span class="o">...</span><span class="p">,</span> <span class="o">-</span><span class="mf">0.73</span><span class="o">...</span><span class="p">,</span> <span class="o">-</span><span class="mf">0.30</span><span class="o">...</span><span class="p">,</span> <span class="o">-</span><span class="mf">0.00</span><span class="o">...</span><span class="p">])</span>
</code></pre></div>

</details>
<h3 id="apply_2">apply<a class="headerlink" href="#apply_2" title="Permanent link">&para;</a></h3>
<details class="note" open="open"><summary>method</summary><div class="highlight"><pre><span></span><code><span class="k">val</span> <span class="n">apply</span> <span class="o">:</span>
  <span class="o">?</span><span class="n">check_input</span><span class="o">:</span><span class="kt">bool</span> <span class="o">-&gt;</span>
  <span class="n">x</span><span class="o">:[&gt;`</span><span class="nc">ArrayLike</span><span class="o">]</span> <span class="nn">Np</span><span class="p">.</span><span class="nn">Obj</span><span class="p">.</span><span class="n">t</span> <span class="o">-&gt;</span>
  <span class="o">[&gt;</span> <span class="n">tag</span><span class="o">]</span> <span class="nn">Obj</span><span class="p">.</span><span class="n">t</span> <span class="o">-&gt;</span>
  <span class="o">[&gt;`</span><span class="nc">ArrayLike</span><span class="o">]</span> <span class="nn">Np</span><span class="p">.</span><span class="nn">Obj</span><span class="p">.</span><span class="n">t</span>
</code></pre></div>

<p>Return the index of the leaf that each sample is predicted as.</p>
<p>.. versionadded:: 0.17</p>
<h4>Parameters</h4>
<details class="info" open="open"><summary>X : {array-like, sparse matrix} of shape (n_samples, n_features)</summary><p>The input samples. Internally, it will be converted to
<code>dtype=np.float32</code> and if a sparse matrix is provided
to a sparse <code>csr_matrix</code>.</p>
</details>
<details class="info" open="open"><summary>check_input : bool, default=True</summary><p>Allow to bypass several input checking.
Don't use this parameter unless you know what you do.</p>
</details>
<h4>Returns</h4>
<details class="info" open="open"><summary>X_leaves : array-like of shape (n_samples,)</summary><p>For each datapoint x in X, return the index of the leaf x
ends up in. Leaves are numbered within
<code>[0; self.tree_.node_count)</code>, possibly with gaps in the
numbering.</p>
</details>
</details>
<h3 id="cost_complexity_pruning_path_2">cost_complexity_pruning_path<a class="headerlink" href="#cost_complexity_pruning_path_2" title="Permanent link">&para;</a></h3>
<details class="note" open="open"><summary>method</summary><div class="highlight"><pre><span></span><code><span class="k">val</span> <span class="n">cost_complexity_pruning_path</span> <span class="o">:</span>
  <span class="o">?</span><span class="n">sample_weight</span><span class="o">:[&gt;`</span><span class="nc">ArrayLike</span><span class="o">]</span> <span class="nn">Np</span><span class="p">.</span><span class="nn">Obj</span><span class="p">.</span><span class="n">t</span> <span class="o">-&gt;</span>
  <span class="n">x</span><span class="o">:[&gt;`</span><span class="nc">ArrayLike</span><span class="o">]</span> <span class="nn">Np</span><span class="p">.</span><span class="nn">Obj</span><span class="p">.</span><span class="n">t</span> <span class="o">-&gt;</span>
  <span class="n">y</span><span class="o">:[&gt;`</span><span class="nc">ArrayLike</span><span class="o">]</span> <span class="nn">Np</span><span class="p">.</span><span class="nn">Obj</span><span class="p">.</span><span class="n">t</span> <span class="o">-&gt;</span>
  <span class="o">[&gt;</span> <span class="n">tag</span><span class="o">]</span> <span class="nn">Obj</span><span class="p">.</span><span class="n">t</span> <span class="o">-&gt;</span>
  <span class="o">(</span><span class="nn">Py</span><span class="p">.</span><span class="nn">Object</span><span class="p">.</span><span class="n">t</span> <span class="o">*</span> <span class="o">[&gt;`</span><span class="nc">ArrayLike</span><span class="o">]</span> <span class="nn">Np</span><span class="p">.</span><span class="nn">Obj</span><span class="p">.</span><span class="n">t</span> <span class="o">*</span> <span class="o">[&gt;`</span><span class="nc">ArrayLike</span><span class="o">]</span> <span class="nn">Np</span><span class="p">.</span><span class="nn">Obj</span><span class="p">.</span><span class="n">t</span><span class="o">)</span>
</code></pre></div>

<p>Compute the pruning path during Minimal Cost-Complexity Pruning.</p>
<details class="info" open="open"><summary>See :ref:<code>minimal_cost_complexity_pruning</code> for details on the pruning</summary></details>
<p>process.</p>
<h4>Parameters</h4>
<details class="info" open="open"><summary>X : {array-like, sparse matrix} of shape (n_samples, n_features)</summary><p>The training input samples. Internally, it will be converted to
<code>dtype=np.float32</code> and if a sparse matrix is provided
to a sparse <code>csc_matrix</code>.</p>
</details>
<details class="info" open="open"><summary>y : array-like of shape (n_samples,) or (n_samples, n_outputs)</summary><p>The target values (class labels) as integers or strings.</p>
</details>
<details class="info" open="open"><summary>sample_weight : array-like of shape (n_samples,), default=None</summary><p>Sample weights. If None, then samples are equally weighted. Splits
that would create child nodes with net zero or negative weight are
ignored while searching for a split in each node. Splits are also
ignored if they would result in any single class carrying a
negative weight in either child node.</p>
</details>
<h4>Returns</h4>
<details class="info" open="open"><summary>ccp_path : :class:<code>~sklearn.utils.Bunch</code></summary><p>Dictionary-like object, with the following attributes.</p>
</details>
<details class="info" open="open"><summary>ccp_alphas : ndarray</summary><div class="codehilite"><pre><span></span><code>Effective alphas of subtree during pruning.
</code></pre></div>


</details>
<details class="info" open="open"><summary>impurities : ndarray</summary><div class="codehilite"><pre><span></span><code>Sum of the impurities of the subtree leaves for the
corresponding alpha value in ``ccp_alphas``.
</code></pre></div>


</details>
</details>
<h3 id="decision_path_2">decision_path<a class="headerlink" href="#decision_path_2" title="Permanent link">&para;</a></h3>
<details class="note" open="open"><summary>method</summary><div class="highlight"><pre><span></span><code><span class="k">val</span> <span class="n">decision_path</span> <span class="o">:</span>
  <span class="o">?</span><span class="n">check_input</span><span class="o">:</span><span class="kt">bool</span> <span class="o">-&gt;</span>
  <span class="n">x</span><span class="o">:[&gt;`</span><span class="nc">ArrayLike</span><span class="o">]</span> <span class="nn">Np</span><span class="p">.</span><span class="nn">Obj</span><span class="p">.</span><span class="n">t</span> <span class="o">-&gt;</span>
  <span class="o">[&gt;</span> <span class="n">tag</span><span class="o">]</span> <span class="nn">Obj</span><span class="p">.</span><span class="n">t</span> <span class="o">-&gt;</span>
  <span class="o">[`</span><span class="nc">ArrayLike</span><span class="o">|`</span><span class="nc">Object</span><span class="o">|`</span><span class="nc">Spmatrix</span><span class="o">]</span> <span class="nn">Np</span><span class="p">.</span><span class="nn">Obj</span><span class="p">.</span><span class="n">t</span>
</code></pre></div>

<p>Return the decision path in the tree.</p>
<p>.. versionadded:: 0.18</p>
<h4>Parameters</h4>
<details class="info" open="open"><summary>X : {array-like, sparse matrix} of shape (n_samples, n_features)</summary><p>The input samples. Internally, it will be converted to
<code>dtype=np.float32</code> and if a sparse matrix is provided
to a sparse <code>csr_matrix</code>.</p>
</details>
<details class="info" open="open"><summary>check_input : bool, default=True</summary><p>Allow to bypass several input checking.
Don't use this parameter unless you know what you do.</p>
</details>
<h4>Returns</h4>
<details class="info" open="open"><summary>indicator : sparse matrix of shape (n_samples, n_nodes)</summary><p>Return a node indicator CSR matrix where non zero elements
indicates that the samples goes through the nodes.</p>
</details>
</details>
<h3 id="fit_2">fit<a class="headerlink" href="#fit_2" title="Permanent link">&para;</a></h3>
<details class="note" open="open"><summary>method</summary><div class="highlight"><pre><span></span><code><span class="k">val</span> <span class="n">fit</span> <span class="o">:</span>
  <span class="o">?</span><span class="n">sample_weight</span><span class="o">:[&gt;`</span><span class="nc">ArrayLike</span><span class="o">]</span> <span class="nn">Np</span><span class="p">.</span><span class="nn">Obj</span><span class="p">.</span><span class="n">t</span> <span class="o">-&gt;</span>
  <span class="o">?</span><span class="n">check_input</span><span class="o">:</span><span class="kt">bool</span> <span class="o">-&gt;</span>
  <span class="o">?</span><span class="n">x_idx_sorted</span><span class="o">:[&gt;`</span><span class="nc">ArrayLike</span><span class="o">]</span> <span class="nn">Np</span><span class="p">.</span><span class="nn">Obj</span><span class="p">.</span><span class="n">t</span> <span class="o">-&gt;</span>
  <span class="n">x</span><span class="o">:[&gt;`</span><span class="nc">ArrayLike</span><span class="o">]</span> <span class="nn">Np</span><span class="p">.</span><span class="nn">Obj</span><span class="p">.</span><span class="n">t</span> <span class="o">-&gt;</span>
  <span class="n">y</span><span class="o">:[&gt;`</span><span class="nc">ArrayLike</span><span class="o">]</span> <span class="nn">Np</span><span class="p">.</span><span class="nn">Obj</span><span class="p">.</span><span class="n">t</span> <span class="o">-&gt;</span>
  <span class="o">[&gt;</span> <span class="n">tag</span><span class="o">]</span> <span class="nn">Obj</span><span class="p">.</span><span class="n">t</span> <span class="o">-&gt;</span>
  <span class="n">t</span>
</code></pre></div>

<p>Build a decision tree regressor from the training set (X, y).</p>
<h4>Parameters</h4>
<details class="info" open="open"><summary>X : {array-like, sparse matrix} of shape (n_samples, n_features)</summary><p>The training input samples. Internally, it will be converted to
<code>dtype=np.float32</code> and if a sparse matrix is provided
to a sparse <code>csc_matrix</code>.</p>
</details>
<details class="info" open="open"><summary>y : array-like of shape (n_samples,) or (n_samples, n_outputs)</summary><p>The target values (real numbers). Use <code>dtype=np.float64</code> and
<code>order='C'</code> for maximum efficiency.</p>
</details>
<details class="info" open="open"><summary>sample_weight : array-like of shape (n_samples,), default=None</summary><p>Sample weights. If None, then samples are equally weighted. Splits
that would create child nodes with net zero or negative weight are
ignored while searching for a split in each node.</p>
</details>
<details class="info" open="open"><summary>check_input : bool, default=True</summary><p>Allow to bypass several input checking.
Don't use this parameter unless you know what you do.</p>
</details>
<details class="info" open="open"><summary>X_idx_sorted : array-like of shape (n_samples, n_features),             default=None</summary><p>The indexes of the sorted training input samples. If many tree
are grown on the same dataset, this allows the ordering to be
cached between trees. If None, the data will be sorted here.
Don't use this parameter unless you know what to do.</p>
</details>
<h4>Returns</h4>
<details class="info" open="open"><summary>self : DecisionTreeRegressor</summary><p>Fitted estimator.</p>
</details>
</details>
<h3 id="get_depth_2">get_depth<a class="headerlink" href="#get_depth_2" title="Permanent link">&para;</a></h3>
<details class="note" open="open"><summary>method</summary><div class="highlight"><pre><span></span><code><span class="k">val</span> <span class="n">get_depth</span> <span class="o">:</span>
  <span class="o">[&gt;</span> <span class="n">tag</span><span class="o">]</span> <span class="nn">Obj</span><span class="p">.</span><span class="n">t</span> <span class="o">-&gt;</span>
  <span class="nn">Py</span><span class="p">.</span><span class="nn">Object</span><span class="p">.</span><span class="n">t</span>
</code></pre></div>

<p>Return the depth of the decision tree.</p>
<p>The depth of a tree is the maximum distance between the root
and any leaf.</p>
<h4>Returns</h4>
<details class="info" open="open"><summary>self.tree_.max_depth : int</summary><p>The maximum depth of the tree.</p>
</details>
</details>
<h3 id="get_n_leaves_2">get_n_leaves<a class="headerlink" href="#get_n_leaves_2" title="Permanent link">&para;</a></h3>
<details class="note" open="open"><summary>method</summary><div class="highlight"><pre><span></span><code><span class="k">val</span> <span class="n">get_n_leaves</span> <span class="o">:</span>
  <span class="o">[&gt;</span> <span class="n">tag</span><span class="o">]</span> <span class="nn">Obj</span><span class="p">.</span><span class="n">t</span> <span class="o">-&gt;</span>
  <span class="nn">Py</span><span class="p">.</span><span class="nn">Object</span><span class="p">.</span><span class="n">t</span>
</code></pre></div>

<p>Return the number of leaves of the decision tree.</p>
<h4>Returns</h4>
<details class="info" open="open"><summary>self.tree_.n_leaves : int</summary><p>Number of leaves.</p>
</details>
</details>
<h3 id="get_params_2">get_params<a class="headerlink" href="#get_params_2" title="Permanent link">&para;</a></h3>
<details class="note" open="open"><summary>method</summary><div class="highlight"><pre><span></span><code><span class="k">val</span> <span class="n">get_params</span> <span class="o">:</span>
  <span class="o">?</span><span class="n">deep</span><span class="o">:</span><span class="kt">bool</span> <span class="o">-&gt;</span>
  <span class="o">[&gt;</span> <span class="n">tag</span><span class="o">]</span> <span class="nn">Obj</span><span class="p">.</span><span class="n">t</span> <span class="o">-&gt;</span>
  <span class="nn">Dict</span><span class="p">.</span><span class="n">t</span>
</code></pre></div>

<p>Get parameters for this estimator.</p>
<h4>Parameters</h4>
<details class="info" open="open"><summary>deep : bool, default=True</summary><p>If True, will return the parameters for this estimator and
contained subobjects that are estimators.</p>
</details>
<h4>Returns</h4>
<details class="info" open="open"><summary>params : mapping of string to any</summary><p>Parameter names mapped to their values.</p>
</details>
</details>
<h3 id="predict_2">predict<a class="headerlink" href="#predict_2" title="Permanent link">&para;</a></h3>
<details class="note" open="open"><summary>method</summary><div class="highlight"><pre><span></span><code><span class="k">val</span> <span class="n">predict</span> <span class="o">:</span>
  <span class="o">?</span><span class="n">check_input</span><span class="o">:</span><span class="kt">bool</span> <span class="o">-&gt;</span>
  <span class="n">x</span><span class="o">:[&gt;`</span><span class="nc">ArrayLike</span><span class="o">]</span> <span class="nn">Np</span><span class="p">.</span><span class="nn">Obj</span><span class="p">.</span><span class="n">t</span> <span class="o">-&gt;</span>
  <span class="o">[&gt;</span> <span class="n">tag</span><span class="o">]</span> <span class="nn">Obj</span><span class="p">.</span><span class="n">t</span> <span class="o">-&gt;</span>
  <span class="o">[&gt;`</span><span class="nc">ArrayLike</span><span class="o">]</span> <span class="nn">Np</span><span class="p">.</span><span class="nn">Obj</span><span class="p">.</span><span class="n">t</span>
</code></pre></div>

<p>Predict class or regression value for X.</p>
<p>For a classification model, the predicted class for each sample in X is
returned. For a regression model, the predicted value based on X is
returned.</p>
<h4>Parameters</h4>
<details class="info" open="open"><summary>X : {array-like, sparse matrix} of shape (n_samples, n_features)</summary><p>The input samples. Internally, it will be converted to
<code>dtype=np.float32</code> and if a sparse matrix is provided
to a sparse <code>csr_matrix</code>.</p>
</details>
<details class="info" open="open"><summary>check_input : bool, default=True</summary><p>Allow to bypass several input checking.
Don't use this parameter unless you know what you do.</p>
</details>
<h4>Returns</h4>
<details class="info" open="open"><summary>y : array-like of shape (n_samples,) or (n_samples, n_outputs)</summary><p>The predicted classes, or the predict values.</p>
</details>
</details>
<h3 id="score_1">score<a class="headerlink" href="#score_1" title="Permanent link">&para;</a></h3>
<details class="note" open="open"><summary>method</summary><div class="highlight"><pre><span></span><code><span class="k">val</span> <span class="n">score</span> <span class="o">:</span>
  <span class="o">?</span><span class="n">sample_weight</span><span class="o">:[&gt;`</span><span class="nc">ArrayLike</span><span class="o">]</span> <span class="nn">Np</span><span class="p">.</span><span class="nn">Obj</span><span class="p">.</span><span class="n">t</span> <span class="o">-&gt;</span>
  <span class="n">x</span><span class="o">:[&gt;`</span><span class="nc">ArrayLike</span><span class="o">]</span> <span class="nn">Np</span><span class="p">.</span><span class="nn">Obj</span><span class="p">.</span><span class="n">t</span> <span class="o">-&gt;</span>
  <span class="n">y</span><span class="o">:[&gt;`</span><span class="nc">ArrayLike</span><span class="o">]</span> <span class="nn">Np</span><span class="p">.</span><span class="nn">Obj</span><span class="p">.</span><span class="n">t</span> <span class="o">-&gt;</span>
  <span class="o">[&gt;</span> <span class="n">tag</span><span class="o">]</span> <span class="nn">Obj</span><span class="p">.</span><span class="n">t</span> <span class="o">-&gt;</span>
  <span class="kt">float</span>
</code></pre></div>

<p>Return the coefficient of determination R^2 of the prediction.</p>
<p>The coefficient R^2 is defined as (1 - u/v), where u is the residual
sum of squares ((y_true - y_pred) <strong> 2).sum() and v is the total
sum of squares ((y_true - y_true.mean()) </strong> 2).sum().
The best possible score is 1.0 and it can be negative (because the
model can be arbitrarily worse). A constant model that always
predicts the expected value of y, disregarding the input features,
would get a R^2 score of 0.0.</p>
<h4>Parameters</h4>
<details class="info" open="open"><summary>X : array-like of shape (n_samples, n_features)</summary><p>Test samples. For some estimators this may be a
precomputed kernel matrix or a list of generic objects instead,
shape = (n_samples, n_samples_fitted),
where n_samples_fitted is the number of
samples used in the fitting for the estimator.</p>
</details>
<details class="info" open="open"><summary>y : array-like of shape (n_samples,) or (n_samples, n_outputs)</summary><p>True values for X.</p>
</details>
<details class="info" open="open"><summary>sample_weight : array-like of shape (n_samples,), default=None</summary><p>Sample weights.</p>
</details>
<h4>Returns</h4>
<details class="info" open="open"><summary>score : float</summary><p>R^2 of self.predict(X) wrt. y.</p>
</details>
<h4>Notes</h4>
<p>The R2 score used when calling <code>score</code> on a regressor uses
<code>multioutput='uniform_average'</code> from version 0.23 to keep consistent
with default value of :func:<code>~sklearn.metrics.r2_score</code>.
This influences the <code>score</code> method of all the multioutput
regressors (except for
:class:<code>~sklearn.multioutput.MultiOutputRegressor</code>).</p>
</details>
<h3 id="set_params_2">set_params<a class="headerlink" href="#set_params_2" title="Permanent link">&para;</a></h3>
<details class="note" open="open"><summary>method</summary><div class="highlight"><pre><span></span><code><span class="k">val</span> <span class="n">set_params</span> <span class="o">:</span>
  <span class="o">?</span><span class="n">params</span><span class="o">:(</span><span class="kt">string</span> <span class="o">*</span> <span class="nn">Py</span><span class="p">.</span><span class="nn">Object</span><span class="p">.</span><span class="n">t</span><span class="o">)</span> <span class="kt">list</span> <span class="o">-&gt;</span>
  <span class="o">[&gt;</span> <span class="n">tag</span><span class="o">]</span> <span class="nn">Obj</span><span class="p">.</span><span class="n">t</span> <span class="o">-&gt;</span>
  <span class="n">t</span>
</code></pre></div>

<p>Set the parameters of this estimator.</p>
<p>The method works on simple estimators as well as on nested objects
(such as pipelines). The latter have parameters of the form
<code>&lt;component&gt;__&lt;parameter&gt;</code> so that it's possible to update each
component of a nested object.</p>
<h4>Parameters</h4>
<details class="info" open="open"><summary>**params : dict</summary><p>Estimator parameters.</p>
</details>
<h4>Returns</h4>
<details class="info" open="open"><summary>self : object</summary><p>Estimator instance.</p>
</details>
</details>
<h3 id="feature_importances__1">feature_importances_<a class="headerlink" href="#feature_importances__1" title="Permanent link">&para;</a></h3>
<details class="note" open="open"><summary>attribute</summary><div class="highlight"><pre><span></span><code><span class="k">val</span> <span class="n">feature_importances_</span> <span class="o">:</span> <span class="n">t</span> <span class="o">-&gt;</span> <span class="o">[&gt;`</span><span class="nc">ArrayLike</span><span class="o">]</span> <span class="nn">Np</span><span class="p">.</span><span class="nn">Obj</span><span class="p">.</span><span class="n">t</span>
<span class="k">val</span> <span class="n">feature_importances_opt</span> <span class="o">:</span> <span class="n">t</span> <span class="o">-&gt;</span> <span class="o">([&gt;`</span><span class="nc">ArrayLike</span><span class="o">]</span> <span class="nn">Np</span><span class="p">.</span><span class="nn">Obj</span><span class="p">.</span><span class="n">t</span><span class="o">)</span> <span class="n">option</span>
</code></pre></div>

<p>This attribute is documented in <code>create</code> above. The first version raises Not_found
if the attribute is None. The _opt version returns an option.</p>
</details>
<h3 id="warning_1">warning<a class="headerlink" href="#warning_1" title="Permanent link">&para;</a></h3>
<details class="note" open="open"><summary>attribute</summary><div class="highlight"><pre><span></span><code><span class="k">val</span> <span class="n">warning</span> <span class="o">:</span> <span class="n">t</span> <span class="o">-&gt;</span> <span class="nn">Py</span><span class="p">.</span><span class="nn">Object</span><span class="p">.</span><span class="n">t</span>
<span class="k">val</span> <span class="n">warning_opt</span> <span class="o">:</span> <span class="n">t</span> <span class="o">-&gt;</span> <span class="o">(</span><span class="nn">Py</span><span class="p">.</span><span class="nn">Object</span><span class="p">.</span><span class="n">t</span><span class="o">)</span> <span class="n">option</span>
</code></pre></div>

<p>This attribute is documented in <code>create</code> above. The first version raises Not_found
if the attribute is None. The _opt version returns an option.</p>
</details>
<h3 id="max_features__1">max_features_<a class="headerlink" href="#max_features__1" title="Permanent link">&para;</a></h3>
<details class="note" open="open"><summary>attribute</summary><div class="highlight"><pre><span></span><code><span class="k">val</span> <span class="n">max_features_</span> <span class="o">:</span> <span class="n">t</span> <span class="o">-&gt;</span> <span class="kt">int</span>
<span class="k">val</span> <span class="n">max_features_opt</span> <span class="o">:</span> <span class="n">t</span> <span class="o">-&gt;</span> <span class="o">(</span><span class="kt">int</span><span class="o">)</span> <span class="n">option</span>
</code></pre></div>

<p>This attribute is documented in <code>create</code> above. The first version raises Not_found
if the attribute is None. The _opt version returns an option.</p>
</details>
<h3 id="n_features__1">n_features_<a class="headerlink" href="#n_features__1" title="Permanent link">&para;</a></h3>
<details class="note" open="open"><summary>attribute</summary><div class="highlight"><pre><span></span><code><span class="k">val</span> <span class="n">n_features_</span> <span class="o">:</span> <span class="n">t</span> <span class="o">-&gt;</span> <span class="kt">int</span>
<span class="k">val</span> <span class="n">n_features_opt</span> <span class="o">:</span> <span class="n">t</span> <span class="o">-&gt;</span> <span class="o">(</span><span class="kt">int</span><span class="o">)</span> <span class="n">option</span>
</code></pre></div>

<p>This attribute is documented in <code>create</code> above. The first version raises Not_found
if the attribute is None. The _opt version returns an option.</p>
</details>
<h3 id="n_outputs__1">n_outputs_<a class="headerlink" href="#n_outputs__1" title="Permanent link">&para;</a></h3>
<details class="note" open="open"><summary>attribute</summary><div class="highlight"><pre><span></span><code><span class="k">val</span> <span class="n">n_outputs_</span> <span class="o">:</span> <span class="n">t</span> <span class="o">-&gt;</span> <span class="kt">int</span>
<span class="k">val</span> <span class="n">n_outputs_opt</span> <span class="o">:</span> <span class="n">t</span> <span class="o">-&gt;</span> <span class="o">(</span><span class="kt">int</span><span class="o">)</span> <span class="n">option</span>
</code></pre></div>

<p>This attribute is documented in <code>create</code> above. The first version raises Not_found
if the attribute is None. The _opt version returns an option.</p>
</details>
<h3 id="tree__1">tree_<a class="headerlink" href="#tree__1" title="Permanent link">&para;</a></h3>
<details class="note" open="open"><summary>attribute</summary><div class="highlight"><pre><span></span><code><span class="k">val</span> <span class="n">tree_</span> <span class="o">:</span> <span class="n">t</span> <span class="o">-&gt;</span> <span class="nn">Py</span><span class="p">.</span><span class="nn">Object</span><span class="p">.</span><span class="n">t</span>
<span class="k">val</span> <span class="n">tree_opt</span> <span class="o">:</span> <span class="n">t</span> <span class="o">-&gt;</span> <span class="o">(</span><span class="nn">Py</span><span class="p">.</span><span class="nn">Object</span><span class="p">.</span><span class="n">t</span><span class="o">)</span> <span class="n">option</span>
</code></pre></div>

<p>This attribute is documented in <code>create</code> above. The first version raises Not_found
if the attribute is None. The _opt version returns an option.</p>
</details>
<h3 id="to_string_2">to_string<a class="headerlink" href="#to_string_2" title="Permanent link">&para;</a></h3>
<details class="note" open="open"><summary>method</summary><div class="highlight"><pre><span></span><code><span class="k">val</span> <span class="n">to_string</span><span class="o">:</span> <span class="n">t</span> <span class="o">-&gt;</span> <span class="kt">string</span>
</code></pre></div>

<p>Print the object to a human-readable representation.</p>
</details>
<h3 id="show_2">show<a class="headerlink" href="#show_2" title="Permanent link">&para;</a></h3>
<details class="note" open="open"><summary>method</summary><div class="highlight"><pre><span></span><code><span class="k">val</span> <span class="n">show</span><span class="o">:</span> <span class="n">t</span> <span class="o">-&gt;</span> <span class="kt">string</span>
</code></pre></div>

<p>Print the object to a human-readable representation.</p>
</details>
<h3 id="pp_2">pp<a class="headerlink" href="#pp_2" title="Permanent link">&para;</a></h3>
<details class="note" open="open"><summary>method</summary><div class="highlight"><pre><span></span><code><span class="k">val</span> <span class="n">pp</span><span class="o">:</span> <span class="nn">Format</span><span class="p">.</span><span class="n">formatter</span> <span class="o">-&gt;</span> <span class="n">t</span> <span class="o">-&gt;</span> <span class="kt">unit</span>
</code></pre></div>

<p>Pretty-print the object to a formatter.</p>
</details>
<h2 id="extratreeclassifier">ExtraTreeClassifier<a class="headerlink" href="#extratreeclassifier" title="Permanent link">&para;</a></h2>
<p>Module <code>Sklearn.Tree.ExtraTreeClassifier</code> wraps Python class <a href="https://scikit-learn.org/stable/modules/generated/sklearn.tree.ExtraTreeClassifier.html"><code>sklearn.tree.ExtraTreeClassifier</code></a>.</p>
<div class="highlight"><pre><span></span><code><span class="k">type</span> <span class="n">t</span>
</code></pre></div>

<h3 id="create_2">create<a class="headerlink" href="#create_2" title="Permanent link">&para;</a></h3>
<details class="note" open="open"><summary>constructor and attributes</summary><div class="highlight"><pre><span></span><code><span class="k">val</span> <span class="n">create</span> <span class="o">:</span>
  <span class="o">?</span><span class="n">criterion</span><span class="o">:[`</span><span class="nc">Gini</span> <span class="o">|</span> <span class="o">`</span><span class="nc">Entropy</span><span class="o">]</span> <span class="o">-&gt;</span>
  <span class="o">?</span><span class="n">splitter</span><span class="o">:[`</span><span class="nc">Random</span> <span class="o">|</span> <span class="o">`</span><span class="nc">Best</span><span class="o">]</span> <span class="o">-&gt;</span>
  <span class="o">?</span><span class="n">max_depth</span><span class="o">:</span><span class="kt">int</span> <span class="o">-&gt;</span>
  <span class="o">?</span><span class="n">min_samples_split</span><span class="o">:[`</span><span class="nc">I</span> <span class="k">of</span> <span class="kt">int</span> <span class="o">|</span> <span class="o">`</span><span class="nc">F</span> <span class="k">of</span> <span class="kt">float</span><span class="o">]</span> <span class="o">-&gt;</span>
  <span class="o">?</span><span class="n">min_samples_leaf</span><span class="o">:[`</span><span class="nc">I</span> <span class="k">of</span> <span class="kt">int</span> <span class="o">|</span> <span class="o">`</span><span class="nc">F</span> <span class="k">of</span> <span class="kt">float</span><span class="o">]</span> <span class="o">-&gt;</span>
  <span class="o">?</span><span class="n">min_weight_fraction_leaf</span><span class="o">:</span><span class="kt">float</span> <span class="o">-&gt;</span>
  <span class="o">?</span><span class="n">max_features</span><span class="o">:[`</span><span class="nc">F</span> <span class="k">of</span> <span class="kt">float</span> <span class="o">|</span> <span class="o">`</span><span class="nc">Sqrt</span> <span class="o">|</span> <span class="o">`</span><span class="nc">I</span> <span class="k">of</span> <span class="kt">int</span> <span class="o">|</span> <span class="o">`</span><span class="nc">PyObject</span> <span class="k">of</span> <span class="nn">Py</span><span class="p">.</span><span class="nn">Object</span><span class="p">.</span><span class="n">t</span> <span class="o">|</span> <span class="o">`</span><span class="nc">None</span><span class="o">]</span> <span class="o">-&gt;</span>
  <span class="o">?</span><span class="n">random_state</span><span class="o">:</span><span class="kt">int</span> <span class="o">-&gt;</span>
  <span class="o">?</span><span class="n">max_leaf_nodes</span><span class="o">:</span><span class="kt">int</span> <span class="o">-&gt;</span>
  <span class="o">?</span><span class="n">min_impurity_decrease</span><span class="o">:</span><span class="kt">float</span> <span class="o">-&gt;</span>
  <span class="o">?</span><span class="n">min_impurity_split</span><span class="o">:</span><span class="kt">float</span> <span class="o">-&gt;</span>
  <span class="o">?</span><span class="n">class_weight</span><span class="o">:[`</span><span class="nc">List_of_dict</span> <span class="k">of</span> <span class="nn">Py</span><span class="p">.</span><span class="nn">Object</span><span class="p">.</span><span class="n">t</span> <span class="o">|</span> <span class="o">`</span><span class="nc">Balanced</span> <span class="o">|</span> <span class="o">`</span><span class="nc">DictIntToFloat</span> <span class="k">of</span> <span class="o">(</span><span class="kt">int</span> <span class="o">*</span> <span class="kt">float</span><span class="o">)</span> <span class="kt">list</span><span class="o">]</span> <span class="o">-&gt;</span>
  <span class="o">?</span><span class="n">ccp_alpha</span><span class="o">:</span><span class="kt">float</span> <span class="o">-&gt;</span>
  <span class="kt">unit</span> <span class="o">-&gt;</span>
  <span class="n">t</span>
</code></pre></div>

<p>An extremely randomized tree classifier.</p>
<p>Extra-trees differ from classic decision trees in the way they are built.
When looking for the best split to separate the samples of a node into two
groups, random splits are drawn for each of the <code>max_features</code> randomly
selected features and the best split among those is chosen. When
<code>max_features</code> is set 1, this amounts to building a totally random
decision tree.</p>
<details class="info" open="open"><summary>Warning: Extra-trees should only be used within ensemble methods.</summary></details>
<p>Read more in the :ref:<code>User Guide &lt;tree&gt;</code>.</p>
<h4>Parameters</h4>
<details class="info" open="open"><summary>criterion : {'gini', 'entropy'}, default='gini'</summary><p>The function to measure the quality of a split. Supported criteria are
'gini' for the Gini impurity and 'entropy' for the information gain.</p>
</details>
<details class="info" open="open"><summary>splitter : {'random', 'best'}, default='random'</summary><p>The strategy used to choose the split at each node. Supported
strategies are 'best' to choose the best split and 'random' to choose
the best random split.</p>
</details>
<details class="info" open="open"><summary>max_depth : int, default=None</summary><p>The maximum depth of the tree. If None, then nodes are expanded until
all leaves are pure or until all leaves contain less than
min_samples_split samples.</p>
</details>
<details class="info" open="open"><summary>min_samples_split : int or float, default=2</summary><p>The minimum number of samples required to split an internal node:</p>
<ul>
<li>If int, then consider <code>min_samples_split</code> as the minimum number.</li>
<li>If float, then <code>min_samples_split</code> is a fraction and
  <code>ceil(min_samples_split * n_samples)</code> are the minimum
  number of samples for each split.</li>
</ul>
<p>.. versionchanged:: 0.18
   Added float values for fractions.</p>
</details>
<details class="info" open="open"><summary>min_samples_leaf : int or float, default=1</summary><p>The minimum number of samples required to be at a leaf node.
A split point at any depth will only be considered if it leaves at
least <code>min_samples_leaf</code> training samples in each of the left and
right branches.  This may have the effect of smoothing the model,
especially in regression.</p>
<ul>
<li>If int, then consider <code>min_samples_leaf</code> as the minimum number.</li>
<li>If float, then <code>min_samples_leaf</code> is a fraction and
  <code>ceil(min_samples_leaf * n_samples)</code> are the minimum
  number of samples for each node.</li>
</ul>
<p>.. versionchanged:: 0.18
   Added float values for fractions.</p>
</details>
<details class="info" open="open"><summary>min_weight_fraction_leaf : float, default=0.0</summary><p>The minimum weighted fraction of the sum total of weights (of all
the input samples) required to be at a leaf node. Samples have
equal weight when sample_weight is not provided.</p>
</details>
<details class="info" open="open"><summary>max_features : int, float, {'auto', 'sqrt', 'log2'} or None, default='auto'</summary><p>The number of features to consider when looking for the best split:</p>
<div class="codehilite"><pre><span></span><code>- If int, then consider `max_features` features at each split.
- If float, then `max_features` is a fraction and
  `int(max_features * n_features)` features are considered at each
  split.
- If &#39;auto&#39;, then `max_features=sqrt(n_features)`.
- If &#39;sqrt&#39;, then `max_features=sqrt(n_features)`.
- If &#39;log2&#39;, then `max_features=log2(n_features)`.
- If None, then `max_features=n_features`.
</code></pre></div>


</details>
<details class="info" open="open"><summary>Note: the search for a split does not stop until at least one</summary><p>valid partition of the node samples is found, even if it requires to
effectively inspect more than <code>max_features</code> features.</p>
</details>
<details class="info" open="open"><summary>random_state : int, RandomState instance, default=None</summary><p>Used to pick randomly the <code>max_features</code> used at each split.</p>
</details>
<details class="info" open="open"><summary>See :term:<code>Glossary &lt;random_state&gt;</code> for details.</summary></details>
<details class="info" open="open"><summary>max_leaf_nodes : int, default=None</summary><p>Grow a tree with <code>max_leaf_nodes</code> in best-first fashion.
Best nodes are defined as relative reduction in impurity.
If None then unlimited number of leaf nodes.</p>
</details>
<details class="info" open="open"><summary>min_impurity_decrease : float, default=0.0</summary><p>A node will be split if this split induces a decrease of the impurity
greater than or equal to this value.</p>
<p>The weighted impurity decrease equation is the following::</p>
<div class="codehilite"><pre><span></span><code>N_t / N * (impurity - N_t_R / N_t * right_impurity
                    - N_t_L / N_t * left_impurity)
</code></pre></div>


<p>where <code>N</code> is the total number of samples, <code>N_t</code> is the number of
samples at the current node, <code>N_t_L</code> is the number of samples in the
left child, and <code>N_t_R</code> is the number of samples in the right child.</p>
<p><code>N</code>, <code>N_t</code>, <code>N_t_R</code> and <code>N_t_L</code> all refer to the weighted sum,
if <code>sample_weight</code> is passed.</p>
<p>.. versionadded:: 0.19</p>
</details>
<details class="info" open="open"><summary>min_impurity_split : float, (default=0)</summary><p>Threshold for early stopping in tree growth. A node will split
if its impurity is above the threshold, otherwise it is a leaf.</p>
<p>.. deprecated:: 0.19
   <code>min_impurity_split</code> has been deprecated in favor of
   <code>min_impurity_decrease</code> in 0.19. The default value of
   <code>min_impurity_split</code> has changed from 1e-7 to 0 in 0.23 and it
   will be removed in 0.25. Use <code>min_impurity_decrease</code> instead.</p>
</details>
<details class="info" open="open"><summary>class_weight : dict, list of dict or 'balanced', default=None</summary><p>Weights associated with classes in the form <code>{class_label: weight}</code>.
If None, all classes are supposed to have weight one. For
multi-output problems, a list of dicts can be provided in the same
order as the columns of y.</p>
<p>Note that for multioutput (including multilabel) weights should be
defined for each class of every column in its own dict. For example,
for four-class multilabel classification weights should be
[{0: 1, 1: 1}, {0: 1, 1: 5}, {0: 1, 1: 1}, {0: 1, 1: 1}] instead of
[{1:1}, {2:5}, {3:1}, {4:1}].</p>
<p>The 'balanced' mode uses the values of y to automatically adjust
weights inversely proportional to class frequencies in the input data
as <code>n_samples / (n_classes * np.bincount(y))</code></p>
<p>For multi-output, the weights of each column of y will be multiplied.</p>
<p>Note that these weights will be multiplied with sample_weight (passed
through the fit method) if sample_weight is specified.</p>
</details>
<details class="info" open="open"><summary>ccp_alpha : non-negative float, default=0.0</summary><p>Complexity parameter used for Minimal Cost-Complexity Pruning. The
subtree with the largest cost complexity that is smaller than
<code>ccp_alpha</code> will be chosen. By default, no pruning is performed. See
:ref:<code>minimal_cost_complexity_pruning</code> for details.</p>
<p>.. versionadded:: 0.22</p>
</details>
<h4>Attributes</h4>
<details class="info" open="open"><summary>classes_ : ndarray of shape (n_classes,) or list of ndarray</summary><p>The classes labels (single output problem),
or a list of arrays of class labels (multi-output problem).</p>
</details>
<details class="info" open="open"><summary>max_features_ : int</summary><p>The inferred value of max_features.</p>
</details>
<details class="info" open="open"><summary>n_classes_ : int or list of int</summary><p>The number of classes (for single output problems),
or a list containing the number of classes for each
output (for multi-output problems).</p>
</details>
<details class="info" open="open"><summary>feature_importances_ : ndarray of shape (n_features,)</summary><p>The impurity-based feature importances.
The higher, the more important the feature.
The importance of a feature is computed as the (normalized)
total reduction of the criterion brought by that feature.  It is also
known as the Gini importance.</p>
</details>
<details class="info" open="open"><summary>Warning: impurity-based feature importances can be misleading for</summary><p>high cardinality features (many unique values). See
:func:<code>sklearn.inspection.permutation_importance</code> as an alternative.</p>
</details>
<details class="info" open="open"><summary>n_features_ : int</summary><p>The number of features when <code>fit</code> is performed.</p>
</details>
<details class="info" open="open"><summary>n_outputs_ : int</summary><p>The number of outputs when <code>fit</code> is performed.</p>
</details>
<details class="info" open="open"><summary>tree_ : Tree</summary><p>The underlying Tree object. Please refer to
<code>help(sklearn.tree._tree.Tree)</code> for attributes of Tree object and
:ref:<code>sphx_glr_auto_examples_tree_plot_unveil_tree_structure.py</code>
for basic usage of these attributes.</p>
</details>
<h4>See Also</h4>
<details class="info" open="open"><summary>ExtraTreeRegressor : An extremely randomized tree regressor.</summary></details>
<details class="info" open="open"><summary>sklearn.ensemble.ExtraTreesClassifier : An extra-trees classifier.</summary></details>
<details class="info" open="open"><summary>sklearn.ensemble.ExtraTreesRegressor : An extra-trees regressor.</summary></details>
<h4>Notes</h4>
<p>The default values for the parameters controlling the size of the trees
(e.g. <code>max_depth</code>, <code>min_samples_leaf</code>, etc.) lead to fully grown and
unpruned trees which can potentially be very large on some data sets. To
reduce memory consumption, the complexity and size of the trees should be
controlled by setting those parameter values.</p>
<h4>References</h4>
<p>.. [1] P. Geurts, D. Ernst., and L. Wehenkel, 'Extremely randomized trees',
       Machine Learning, 63(1), 3-42, 2006.</p>
<h4>Examples</h4>
<div class="highlight"><pre><span></span><code><span class="o">&gt;&gt;&gt;</span> <span class="kn">from</span> <span class="nn">sklearn.datasets</span> <span class="kn">import</span> <span class="n">load_iris</span>
<span class="o">&gt;&gt;&gt;</span> <span class="kn">from</span> <span class="nn">sklearn.model_selection</span> <span class="kn">import</span> <span class="n">train_test_split</span>
<span class="o">&gt;&gt;&gt;</span> <span class="kn">from</span> <span class="nn">sklearn.ensemble</span> <span class="kn">import</span> <span class="n">BaggingClassifier</span>
<span class="o">&gt;&gt;&gt;</span> <span class="kn">from</span> <span class="nn">sklearn.tree</span> <span class="kn">import</span> <span class="n">ExtraTreeClassifier</span>
<span class="o">&gt;&gt;&gt;</span> <span class="n">X</span><span class="p">,</span> <span class="n">y</span> <span class="o">=</span> <span class="n">load_iris</span><span class="p">(</span><span class="n">return_X_y</span><span class="o">=</span><span class="kc">True</span><span class="p">)</span>
<span class="o">&gt;&gt;&gt;</span> <span class="n">X_train</span><span class="p">,</span> <span class="n">X_test</span><span class="p">,</span> <span class="n">y_train</span><span class="p">,</span> <span class="n">y_test</span> <span class="o">=</span> <span class="n">train_test_split</span><span class="p">(</span>
<span class="o">...</span>    <span class="n">X</span><span class="p">,</span> <span class="n">y</span><span class="p">,</span> <span class="n">random_state</span><span class="o">=</span><span class="mi">0</span><span class="p">)</span>
<span class="o">&gt;&gt;&gt;</span> <span class="n">extra_tree</span> <span class="o">=</span> <span class="n">ExtraTreeClassifier</span><span class="p">(</span><span class="n">random_state</span><span class="o">=</span><span class="mi">0</span><span class="p">)</span>
<span class="o">&gt;&gt;&gt;</span> <span class="bp">cls</span> <span class="o">=</span> <span class="n">BaggingClassifier</span><span class="p">(</span><span class="n">extra_tree</span><span class="p">,</span> <span class="n">random_state</span><span class="o">=</span><span class="mi">0</span><span class="p">)</span><span class="o">.</span><span class="n">fit</span><span class="p">(</span>
<span class="o">...</span>    <span class="n">X_train</span><span class="p">,</span> <span class="n">y_train</span><span class="p">)</span>
<span class="o">&gt;&gt;&gt;</span> <span class="bp">cls</span><span class="o">.</span><span class="n">score</span><span class="p">(</span><span class="n">X_test</span><span class="p">,</span> <span class="n">y_test</span><span class="p">)</span>
<span class="mf">0.8947</span><span class="o">...</span>
</code></pre></div>

</details>
<h3 id="apply_3">apply<a class="headerlink" href="#apply_3" title="Permanent link">&para;</a></h3>
<details class="note" open="open"><summary>method</summary><div class="highlight"><pre><span></span><code><span class="k">val</span> <span class="n">apply</span> <span class="o">:</span>
  <span class="o">?</span><span class="n">check_input</span><span class="o">:</span><span class="kt">bool</span> <span class="o">-&gt;</span>
  <span class="n">x</span><span class="o">:[&gt;`</span><span class="nc">ArrayLike</span><span class="o">]</span> <span class="nn">Np</span><span class="p">.</span><span class="nn">Obj</span><span class="p">.</span><span class="n">t</span> <span class="o">-&gt;</span>
  <span class="o">[&gt;</span> <span class="n">tag</span><span class="o">]</span> <span class="nn">Obj</span><span class="p">.</span><span class="n">t</span> <span class="o">-&gt;</span>
  <span class="o">[&gt;`</span><span class="nc">ArrayLike</span><span class="o">]</span> <span class="nn">Np</span><span class="p">.</span><span class="nn">Obj</span><span class="p">.</span><span class="n">t</span>
</code></pre></div>

<p>Return the index of the leaf that each sample is predicted as.</p>
<p>.. versionadded:: 0.17</p>
<h4>Parameters</h4>
<details class="info" open="open"><summary>X : {array-like, sparse matrix} of shape (n_samples, n_features)</summary><p>The input samples. Internally, it will be converted to
<code>dtype=np.float32</code> and if a sparse matrix is provided
to a sparse <code>csr_matrix</code>.</p>
</details>
<details class="info" open="open"><summary>check_input : bool, default=True</summary><p>Allow to bypass several input checking.
Don't use this parameter unless you know what you do.</p>
</details>
<h4>Returns</h4>
<details class="info" open="open"><summary>X_leaves : array-like of shape (n_samples,)</summary><p>For each datapoint x in X, return the index of the leaf x
ends up in. Leaves are numbered within
<code>[0; self.tree_.node_count)</code>, possibly with gaps in the
numbering.</p>
</details>
</details>
<h3 id="cost_complexity_pruning_path_3">cost_complexity_pruning_path<a class="headerlink" href="#cost_complexity_pruning_path_3" title="Permanent link">&para;</a></h3>
<details class="note" open="open"><summary>method</summary><div class="highlight"><pre><span></span><code><span class="k">val</span> <span class="n">cost_complexity_pruning_path</span> <span class="o">:</span>
  <span class="o">?</span><span class="n">sample_weight</span><span class="o">:[&gt;`</span><span class="nc">ArrayLike</span><span class="o">]</span> <span class="nn">Np</span><span class="p">.</span><span class="nn">Obj</span><span class="p">.</span><span class="n">t</span> <span class="o">-&gt;</span>
  <span class="n">x</span><span class="o">:[&gt;`</span><span class="nc">ArrayLike</span><span class="o">]</span> <span class="nn">Np</span><span class="p">.</span><span class="nn">Obj</span><span class="p">.</span><span class="n">t</span> <span class="o">-&gt;</span>
  <span class="n">y</span><span class="o">:[&gt;`</span><span class="nc">ArrayLike</span><span class="o">]</span> <span class="nn">Np</span><span class="p">.</span><span class="nn">Obj</span><span class="p">.</span><span class="n">t</span> <span class="o">-&gt;</span>
  <span class="o">[&gt;</span> <span class="n">tag</span><span class="o">]</span> <span class="nn">Obj</span><span class="p">.</span><span class="n">t</span> <span class="o">-&gt;</span>
  <span class="o">(</span><span class="nn">Py</span><span class="p">.</span><span class="nn">Object</span><span class="p">.</span><span class="n">t</span> <span class="o">*</span> <span class="o">[&gt;`</span><span class="nc">ArrayLike</span><span class="o">]</span> <span class="nn">Np</span><span class="p">.</span><span class="nn">Obj</span><span class="p">.</span><span class="n">t</span> <span class="o">*</span> <span class="o">[&gt;`</span><span class="nc">ArrayLike</span><span class="o">]</span> <span class="nn">Np</span><span class="p">.</span><span class="nn">Obj</span><span class="p">.</span><span class="n">t</span><span class="o">)</span>
</code></pre></div>

<p>Compute the pruning path during Minimal Cost-Complexity Pruning.</p>
<details class="info" open="open"><summary>See :ref:<code>minimal_cost_complexity_pruning</code> for details on the pruning</summary></details>
<p>process.</p>
<h4>Parameters</h4>
<details class="info" open="open"><summary>X : {array-like, sparse matrix} of shape (n_samples, n_features)</summary><p>The training input samples. Internally, it will be converted to
<code>dtype=np.float32</code> and if a sparse matrix is provided
to a sparse <code>csc_matrix</code>.</p>
</details>
<details class="info" open="open"><summary>y : array-like of shape (n_samples,) or (n_samples, n_outputs)</summary><p>The target values (class labels) as integers or strings.</p>
</details>
<details class="info" open="open"><summary>sample_weight : array-like of shape (n_samples,), default=None</summary><p>Sample weights. If None, then samples are equally weighted. Splits
that would create child nodes with net zero or negative weight are
ignored while searching for a split in each node. Splits are also
ignored if they would result in any single class carrying a
negative weight in either child node.</p>
</details>
<h4>Returns</h4>
<details class="info" open="open"><summary>ccp_path : :class:<code>~sklearn.utils.Bunch</code></summary><p>Dictionary-like object, with the following attributes.</p>
</details>
<details class="info" open="open"><summary>ccp_alphas : ndarray</summary><div class="codehilite"><pre><span></span><code>Effective alphas of subtree during pruning.
</code></pre></div>


</details>
<details class="info" open="open"><summary>impurities : ndarray</summary><div class="codehilite"><pre><span></span><code>Sum of the impurities of the subtree leaves for the
corresponding alpha value in ``ccp_alphas``.
</code></pre></div>


</details>
</details>
<h3 id="decision_path_3">decision_path<a class="headerlink" href="#decision_path_3" title="Permanent link">&para;</a></h3>
<details class="note" open="open"><summary>method</summary><div class="highlight"><pre><span></span><code><span class="k">val</span> <span class="n">decision_path</span> <span class="o">:</span>
  <span class="o">?</span><span class="n">check_input</span><span class="o">:</span><span class="kt">bool</span> <span class="o">-&gt;</span>
  <span class="n">x</span><span class="o">:[&gt;`</span><span class="nc">ArrayLike</span><span class="o">]</span> <span class="nn">Np</span><span class="p">.</span><span class="nn">Obj</span><span class="p">.</span><span class="n">t</span> <span class="o">-&gt;</span>
  <span class="o">[&gt;</span> <span class="n">tag</span><span class="o">]</span> <span class="nn">Obj</span><span class="p">.</span><span class="n">t</span> <span class="o">-&gt;</span>
  <span class="o">[`</span><span class="nc">ArrayLike</span><span class="o">|`</span><span class="nc">Object</span><span class="o">|`</span><span class="nc">Spmatrix</span><span class="o">]</span> <span class="nn">Np</span><span class="p">.</span><span class="nn">Obj</span><span class="p">.</span><span class="n">t</span>
</code></pre></div>

<p>Return the decision path in the tree.</p>
<p>.. versionadded:: 0.18</p>
<h4>Parameters</h4>
<details class="info" open="open"><summary>X : {array-like, sparse matrix} of shape (n_samples, n_features)</summary><p>The input samples. Internally, it will be converted to
<code>dtype=np.float32</code> and if a sparse matrix is provided
to a sparse <code>csr_matrix</code>.</p>
</details>
<details class="info" open="open"><summary>check_input : bool, default=True</summary><p>Allow to bypass several input checking.
Don't use this parameter unless you know what you do.</p>
</details>
<h4>Returns</h4>
<details class="info" open="open"><summary>indicator : sparse matrix of shape (n_samples, n_nodes)</summary><p>Return a node indicator CSR matrix where non zero elements
indicates that the samples goes through the nodes.</p>
</details>
</details>
<h3 id="fit_3">fit<a class="headerlink" href="#fit_3" title="Permanent link">&para;</a></h3>
<details class="note" open="open"><summary>method</summary><div class="highlight"><pre><span></span><code><span class="k">val</span> <span class="n">fit</span> <span class="o">:</span>
  <span class="o">?</span><span class="n">sample_weight</span><span class="o">:[&gt;`</span><span class="nc">ArrayLike</span><span class="o">]</span> <span class="nn">Np</span><span class="p">.</span><span class="nn">Obj</span><span class="p">.</span><span class="n">t</span> <span class="o">-&gt;</span>
  <span class="o">?</span><span class="n">check_input</span><span class="o">:</span><span class="kt">bool</span> <span class="o">-&gt;</span>
  <span class="o">?</span><span class="n">x_idx_sorted</span><span class="o">:[&gt;`</span><span class="nc">ArrayLike</span><span class="o">]</span> <span class="nn">Np</span><span class="p">.</span><span class="nn">Obj</span><span class="p">.</span><span class="n">t</span> <span class="o">-&gt;</span>
  <span class="n">x</span><span class="o">:[&gt;`</span><span class="nc">ArrayLike</span><span class="o">]</span> <span class="nn">Np</span><span class="p">.</span><span class="nn">Obj</span><span class="p">.</span><span class="n">t</span> <span class="o">-&gt;</span>
  <span class="n">y</span><span class="o">:[&gt;`</span><span class="nc">ArrayLike</span><span class="o">]</span> <span class="nn">Np</span><span class="p">.</span><span class="nn">Obj</span><span class="p">.</span><span class="n">t</span> <span class="o">-&gt;</span>
  <span class="o">[&gt;</span> <span class="n">tag</span><span class="o">]</span> <span class="nn">Obj</span><span class="p">.</span><span class="n">t</span> <span class="o">-&gt;</span>
  <span class="n">t</span>
</code></pre></div>

<p>Build a decision tree classifier from the training set (X, y).</p>
<h4>Parameters</h4>
<details class="info" open="open"><summary>X : {array-like, sparse matrix} of shape (n_samples, n_features)</summary><p>The training input samples. Internally, it will be converted to
<code>dtype=np.float32</code> and if a sparse matrix is provided
to a sparse <code>csc_matrix</code>.</p>
</details>
<details class="info" open="open"><summary>y : array-like of shape (n_samples,) or (n_samples, n_outputs)</summary><p>The target values (class labels) as integers or strings.</p>
</details>
<details class="info" open="open"><summary>sample_weight : array-like of shape (n_samples,), default=None</summary><p>Sample weights. If None, then samples are equally weighted. Splits
that would create child nodes with net zero or negative weight are
ignored while searching for a split in each node. Splits are also
ignored if they would result in any single class carrying a
negative weight in either child node.</p>
</details>
<details class="info" open="open"><summary>check_input : bool, default=True</summary><p>Allow to bypass several input checking.
Don't use this parameter unless you know what you do.</p>
</details>
<details class="info" open="open"><summary>X_idx_sorted : array-like of shape (n_samples, n_features),                 default=None</summary><p>The indexes of the sorted training input samples. If many tree
are grown on the same dataset, this allows the ordering to be
cached between trees. If None, the data will be sorted here.
Don't use this parameter unless you know what to do.</p>
</details>
<h4>Returns</h4>
<details class="info" open="open"><summary>self : DecisionTreeClassifier</summary><p>Fitted estimator.</p>
</details>
</details>
<h3 id="get_depth_3">get_depth<a class="headerlink" href="#get_depth_3" title="Permanent link">&para;</a></h3>
<details class="note" open="open"><summary>method</summary><div class="highlight"><pre><span></span><code><span class="k">val</span> <span class="n">get_depth</span> <span class="o">:</span>
  <span class="o">[&gt;</span> <span class="n">tag</span><span class="o">]</span> <span class="nn">Obj</span><span class="p">.</span><span class="n">t</span> <span class="o">-&gt;</span>
  <span class="nn">Py</span><span class="p">.</span><span class="nn">Object</span><span class="p">.</span><span class="n">t</span>
</code></pre></div>

<p>Return the depth of the decision tree.</p>
<p>The depth of a tree is the maximum distance between the root
and any leaf.</p>
<h4>Returns</h4>
<details class="info" open="open"><summary>self.tree_.max_depth : int</summary><p>The maximum depth of the tree.</p>
</details>
</details>
<h3 id="get_n_leaves_3">get_n_leaves<a class="headerlink" href="#get_n_leaves_3" title="Permanent link">&para;</a></h3>
<details class="note" open="open"><summary>method</summary><div class="highlight"><pre><span></span><code><span class="k">val</span> <span class="n">get_n_leaves</span> <span class="o">:</span>
  <span class="o">[&gt;</span> <span class="n">tag</span><span class="o">]</span> <span class="nn">Obj</span><span class="p">.</span><span class="n">t</span> <span class="o">-&gt;</span>
  <span class="nn">Py</span><span class="p">.</span><span class="nn">Object</span><span class="p">.</span><span class="n">t</span>
</code></pre></div>

<p>Return the number of leaves of the decision tree.</p>
<h4>Returns</h4>
<details class="info" open="open"><summary>self.tree_.n_leaves : int</summary><p>Number of leaves.</p>
</details>
</details>
<h3 id="get_params_3">get_params<a class="headerlink" href="#get_params_3" title="Permanent link">&para;</a></h3>
<details class="note" open="open"><summary>method</summary><div class="highlight"><pre><span></span><code><span class="k">val</span> <span class="n">get_params</span> <span class="o">:</span>
  <span class="o">?</span><span class="n">deep</span><span class="o">:</span><span class="kt">bool</span> <span class="o">-&gt;</span>
  <span class="o">[&gt;</span> <span class="n">tag</span><span class="o">]</span> <span class="nn">Obj</span><span class="p">.</span><span class="n">t</span> <span class="o">-&gt;</span>
  <span class="nn">Dict</span><span class="p">.</span><span class="n">t</span>
</code></pre></div>

<p>Get parameters for this estimator.</p>
<h4>Parameters</h4>
<details class="info" open="open"><summary>deep : bool, default=True</summary><p>If True, will return the parameters for this estimator and
contained subobjects that are estimators.</p>
</details>
<h4>Returns</h4>
<details class="info" open="open"><summary>params : mapping of string to any</summary><p>Parameter names mapped to their values.</p>
</details>
</details>
<h3 id="predict_3">predict<a class="headerlink" href="#predict_3" title="Permanent link">&para;</a></h3>
<details class="note" open="open"><summary>method</summary><div class="highlight"><pre><span></span><code><span class="k">val</span> <span class="n">predict</span> <span class="o">:</span>
  <span class="o">?</span><span class="n">check_input</span><span class="o">:</span><span class="kt">bool</span> <span class="o">-&gt;</span>
  <span class="n">x</span><span class="o">:[&gt;`</span><span class="nc">ArrayLike</span><span class="o">]</span> <span class="nn">Np</span><span class="p">.</span><span class="nn">Obj</span><span class="p">.</span><span class="n">t</span> <span class="o">-&gt;</span>
  <span class="o">[&gt;</span> <span class="n">tag</span><span class="o">]</span> <span class="nn">Obj</span><span class="p">.</span><span class="n">t</span> <span class="o">-&gt;</span>
  <span class="o">[&gt;`</span><span class="nc">ArrayLike</span><span class="o">]</span> <span class="nn">Np</span><span class="p">.</span><span class="nn">Obj</span><span class="p">.</span><span class="n">t</span>
</code></pre></div>

<p>Predict class or regression value for X.</p>
<p>For a classification model, the predicted class for each sample in X is
returned. For a regression model, the predicted value based on X is
returned.</p>
<h4>Parameters</h4>
<details class="info" open="open"><summary>X : {array-like, sparse matrix} of shape (n_samples, n_features)</summary><p>The input samples. Internally, it will be converted to
<code>dtype=np.float32</code> and if a sparse matrix is provided
to a sparse <code>csr_matrix</code>.</p>
</details>
<details class="info" open="open"><summary>check_input : bool, default=True</summary><p>Allow to bypass several input checking.
Don't use this parameter unless you know what you do.</p>
</details>
<h4>Returns</h4>
<details class="info" open="open"><summary>y : array-like of shape (n_samples,) or (n_samples, n_outputs)</summary><p>The predicted classes, or the predict values.</p>
</details>
</details>
<h3 id="predict_log_proba_1">predict_log_proba<a class="headerlink" href="#predict_log_proba_1" title="Permanent link">&para;</a></h3>
<details class="note" open="open"><summary>method</summary><div class="highlight"><pre><span></span><code><span class="k">val</span> <span class="n">predict_log_proba</span> <span class="o">:</span>
  <span class="n">x</span><span class="o">:[&gt;`</span><span class="nc">ArrayLike</span><span class="o">]</span> <span class="nn">Np</span><span class="p">.</span><span class="nn">Obj</span><span class="p">.</span><span class="n">t</span> <span class="o">-&gt;</span>
  <span class="o">[&gt;</span> <span class="n">tag</span><span class="o">]</span> <span class="nn">Obj</span><span class="p">.</span><span class="n">t</span> <span class="o">-&gt;</span>
  <span class="nn">Py</span><span class="p">.</span><span class="nn">Object</span><span class="p">.</span><span class="n">t</span>
</code></pre></div>

<p>Predict class log-probabilities of the input samples X.</p>
<h4>Parameters</h4>
<details class="info" open="open"><summary>X : {array-like, sparse matrix} of shape (n_samples, n_features)</summary><p>The input samples. Internally, it will be converted to
<code>dtype=np.float32</code> and if a sparse matrix is provided
to a sparse <code>csr_matrix</code>.</p>
</details>
<h4>Returns</h4>
<details class="info" open="open"><summary>proba : ndarray of shape (n_samples, n_classes) or list of n_outputs             such arrays if n_outputs &gt; 1</summary><p>The class log-probabilities of the input samples. The order of the
classes corresponds to that in the attribute :term:<code>classes_</code>.</p>
</details>
</details>
<h3 id="predict_proba_1">predict_proba<a class="headerlink" href="#predict_proba_1" title="Permanent link">&para;</a></h3>
<details class="note" open="open"><summary>method</summary><div class="highlight"><pre><span></span><code><span class="k">val</span> <span class="n">predict_proba</span> <span class="o">:</span>
  <span class="o">?</span><span class="n">check_input</span><span class="o">:</span><span class="kt">bool</span> <span class="o">-&gt;</span>
  <span class="n">x</span><span class="o">:[&gt;`</span><span class="nc">ArrayLike</span><span class="o">]</span> <span class="nn">Np</span><span class="p">.</span><span class="nn">Obj</span><span class="p">.</span><span class="n">t</span> <span class="o">-&gt;</span>
  <span class="o">[&gt;</span> <span class="n">tag</span><span class="o">]</span> <span class="nn">Obj</span><span class="p">.</span><span class="n">t</span> <span class="o">-&gt;</span>
  <span class="o">[&gt;`</span><span class="nc">ArrayLike</span><span class="o">]</span> <span class="nn">Np</span><span class="p">.</span><span class="nn">Obj</span><span class="p">.</span><span class="n">t</span>
</code></pre></div>

<p>Predict class probabilities of the input samples X.</p>
<p>The predicted class probability is the fraction of samples of the same
class in a leaf.</p>
<h4>Parameters</h4>
<details class="info" open="open"><summary>X : {array-like, sparse matrix} of shape (n_samples, n_features)</summary><p>The input samples. Internally, it will be converted to
<code>dtype=np.float32</code> and if a sparse matrix is provided
to a sparse <code>csr_matrix</code>.</p>
</details>
<details class="info" open="open"><summary>check_input : bool, default=True</summary><p>Allow to bypass several input checking.
Don't use this parameter unless you know what you do.</p>
</details>
<h4>Returns</h4>
<details class="info" open="open"><summary>proba : ndarray of shape (n_samples, n_classes) or list of n_outputs             such arrays if n_outputs &gt; 1</summary><p>The class probabilities of the input samples. The order of the
classes corresponds to that in the attribute :term:<code>classes_</code>.</p>
</details>
</details>
<h3 id="score_2">score<a class="headerlink" href="#score_2" title="Permanent link">&para;</a></h3>
<details class="note" open="open"><summary>method</summary><div class="highlight"><pre><span></span><code><span class="k">val</span> <span class="n">score</span> <span class="o">:</span>
  <span class="o">?</span><span class="n">sample_weight</span><span class="o">:[&gt;`</span><span class="nc">ArrayLike</span><span class="o">]</span> <span class="nn">Np</span><span class="p">.</span><span class="nn">Obj</span><span class="p">.</span><span class="n">t</span> <span class="o">-&gt;</span>
  <span class="n">x</span><span class="o">:[&gt;`</span><span class="nc">ArrayLike</span><span class="o">]</span> <span class="nn">Np</span><span class="p">.</span><span class="nn">Obj</span><span class="p">.</span><span class="n">t</span> <span class="o">-&gt;</span>
  <span class="n">y</span><span class="o">:[&gt;`</span><span class="nc">ArrayLike</span><span class="o">]</span> <span class="nn">Np</span><span class="p">.</span><span class="nn">Obj</span><span class="p">.</span><span class="n">t</span> <span class="o">-&gt;</span>
  <span class="o">[&gt;</span> <span class="n">tag</span><span class="o">]</span> <span class="nn">Obj</span><span class="p">.</span><span class="n">t</span> <span class="o">-&gt;</span>
  <span class="kt">float</span>
</code></pre></div>

<p>Return the mean accuracy on the given test data and labels.</p>
<p>In multi-label classification, this is the subset accuracy
which is a harsh metric since you require for each sample that
each label set be correctly predicted.</p>
<h4>Parameters</h4>
<details class="info" open="open"><summary>X : array-like of shape (n_samples, n_features)</summary><p>Test samples.</p>
</details>
<details class="info" open="open"><summary>y : array-like of shape (n_samples,) or (n_samples, n_outputs)</summary><p>True labels for X.</p>
</details>
<details class="info" open="open"><summary>sample_weight : array-like of shape (n_samples,), default=None</summary><p>Sample weights.</p>
</details>
<h4>Returns</h4>
<details class="info" open="open"><summary>score : float</summary><p>Mean accuracy of self.predict(X) wrt. y.</p>
</details>
</details>
<h3 id="set_params_3">set_params<a class="headerlink" href="#set_params_3" title="Permanent link">&para;</a></h3>
<details class="note" open="open"><summary>method</summary><div class="highlight"><pre><span></span><code><span class="k">val</span> <span class="n">set_params</span> <span class="o">:</span>
  <span class="o">?</span><span class="n">params</span><span class="o">:(</span><span class="kt">string</span> <span class="o">*</span> <span class="nn">Py</span><span class="p">.</span><span class="nn">Object</span><span class="p">.</span><span class="n">t</span><span class="o">)</span> <span class="kt">list</span> <span class="o">-&gt;</span>
  <span class="o">[&gt;</span> <span class="n">tag</span><span class="o">]</span> <span class="nn">Obj</span><span class="p">.</span><span class="n">t</span> <span class="o">-&gt;</span>
  <span class="n">t</span>
</code></pre></div>

<p>Set the parameters of this estimator.</p>
<p>The method works on simple estimators as well as on nested objects
(such as pipelines). The latter have parameters of the form
<code>&lt;component&gt;__&lt;parameter&gt;</code> so that it's possible to update each
component of a nested object.</p>
<h4>Parameters</h4>
<details class="info" open="open"><summary>**params : dict</summary><p>Estimator parameters.</p>
</details>
<h4>Returns</h4>
<details class="info" open="open"><summary>self : object</summary><p>Estimator instance.</p>
</details>
</details>
<h3 id="classes__1">classes_<a class="headerlink" href="#classes__1" title="Permanent link">&para;</a></h3>
<details class="note" open="open"><summary>attribute</summary><div class="highlight"><pre><span></span><code><span class="k">val</span> <span class="n">classes_</span> <span class="o">:</span> <span class="n">t</span> <span class="o">-&gt;</span> <span class="o">[&gt;`</span><span class="nc">ArrayLike</span><span class="o">]</span> <span class="nn">Np</span><span class="p">.</span><span class="nn">Obj</span><span class="p">.</span><span class="n">t</span>
<span class="k">val</span> <span class="n">classes_opt</span> <span class="o">:</span> <span class="n">t</span> <span class="o">-&gt;</span> <span class="o">([&gt;`</span><span class="nc">ArrayLike</span><span class="o">]</span> <span class="nn">Np</span><span class="p">.</span><span class="nn">Obj</span><span class="p">.</span><span class="n">t</span><span class="o">)</span> <span class="n">option</span>
</code></pre></div>

<p>This attribute is documented in <code>create</code> above. The first version raises Not_found
if the attribute is None. The _opt version returns an option.</p>
</details>
<h3 id="max_features__2">max_features_<a class="headerlink" href="#max_features__2" title="Permanent link">&para;</a></h3>
<details class="note" open="open"><summary>attribute</summary><div class="highlight"><pre><span></span><code><span class="k">val</span> <span class="n">max_features_</span> <span class="o">:</span> <span class="n">t</span> <span class="o">-&gt;</span> <span class="kt">int</span>
<span class="k">val</span> <span class="n">max_features_opt</span> <span class="o">:</span> <span class="n">t</span> <span class="o">-&gt;</span> <span class="o">(</span><span class="kt">int</span><span class="o">)</span> <span class="n">option</span>
</code></pre></div>

<p>This attribute is documented in <code>create</code> above. The first version raises Not_found
if the attribute is None. The _opt version returns an option.</p>
</details>
<h3 id="n_classes__1">n_classes_<a class="headerlink" href="#n_classes__1" title="Permanent link">&para;</a></h3>
<details class="note" open="open"><summary>attribute</summary><div class="highlight"><pre><span></span><code><span class="k">val</span> <span class="n">n_classes_</span> <span class="o">:</span> <span class="n">t</span> <span class="o">-&gt;</span> <span class="nn">Py</span><span class="p">.</span><span class="nn">Object</span><span class="p">.</span><span class="n">t</span>
<span class="k">val</span> <span class="n">n_classes_opt</span> <span class="o">:</span> <span class="n">t</span> <span class="o">-&gt;</span> <span class="o">(</span><span class="nn">Py</span><span class="p">.</span><span class="nn">Object</span><span class="p">.</span><span class="n">t</span><span class="o">)</span> <span class="n">option</span>
</code></pre></div>

<p>This attribute is documented in <code>create</code> above. The first version raises Not_found
if the attribute is None. The _opt version returns an option.</p>
</details>
<h3 id="feature_importances__2">feature_importances_<a class="headerlink" href="#feature_importances__2" title="Permanent link">&para;</a></h3>
<details class="note" open="open"><summary>attribute</summary><div class="highlight"><pre><span></span><code><span class="k">val</span> <span class="n">feature_importances_</span> <span class="o">:</span> <span class="n">t</span> <span class="o">-&gt;</span> <span class="o">[&gt;`</span><span class="nc">ArrayLike</span><span class="o">]</span> <span class="nn">Np</span><span class="p">.</span><span class="nn">Obj</span><span class="p">.</span><span class="n">t</span>
<span class="k">val</span> <span class="n">feature_importances_opt</span> <span class="o">:</span> <span class="n">t</span> <span class="o">-&gt;</span> <span class="o">([&gt;`</span><span class="nc">ArrayLike</span><span class="o">]</span> <span class="nn">Np</span><span class="p">.</span><span class="nn">Obj</span><span class="p">.</span><span class="n">t</span><span class="o">)</span> <span class="n">option</span>
</code></pre></div>

<p>This attribute is documented in <code>create</code> above. The first version raises Not_found
if the attribute is None. The _opt version returns an option.</p>
</details>
<h3 id="warning_2">warning<a class="headerlink" href="#warning_2" title="Permanent link">&para;</a></h3>
<details class="note" open="open"><summary>attribute</summary><div class="highlight"><pre><span></span><code><span class="k">val</span> <span class="n">warning</span> <span class="o">:</span> <span class="n">t</span> <span class="o">-&gt;</span> <span class="nn">Py</span><span class="p">.</span><span class="nn">Object</span><span class="p">.</span><span class="n">t</span>
<span class="k">val</span> <span class="n">warning_opt</span> <span class="o">:</span> <span class="n">t</span> <span class="o">-&gt;</span> <span class="o">(</span><span class="nn">Py</span><span class="p">.</span><span class="nn">Object</span><span class="p">.</span><span class="n">t</span><span class="o">)</span> <span class="n">option</span>
</code></pre></div>

<p>This attribute is documented in <code>create</code> above. The first version raises Not_found
if the attribute is None. The _opt version returns an option.</p>
</details>
<h3 id="n_features__2">n_features_<a class="headerlink" href="#n_features__2" title="Permanent link">&para;</a></h3>
<details class="note" open="open"><summary>attribute</summary><div class="highlight"><pre><span></span><code><span class="k">val</span> <span class="n">n_features_</span> <span class="o">:</span> <span class="n">t</span> <span class="o">-&gt;</span> <span class="kt">int</span>
<span class="k">val</span> <span class="n">n_features_opt</span> <span class="o">:</span> <span class="n">t</span> <span class="o">-&gt;</span> <span class="o">(</span><span class="kt">int</span><span class="o">)</span> <span class="n">option</span>
</code></pre></div>

<p>This attribute is documented in <code>create</code> above. The first version raises Not_found
if the attribute is None. The _opt version returns an option.</p>
</details>
<h3 id="n_outputs__2">n_outputs_<a class="headerlink" href="#n_outputs__2" title="Permanent link">&para;</a></h3>
<details class="note" open="open"><summary>attribute</summary><div class="highlight"><pre><span></span><code><span class="k">val</span> <span class="n">n_outputs_</span> <span class="o">:</span> <span class="n">t</span> <span class="o">-&gt;</span> <span class="kt">int</span>
<span class="k">val</span> <span class="n">n_outputs_opt</span> <span class="o">:</span> <span class="n">t</span> <span class="o">-&gt;</span> <span class="o">(</span><span class="kt">int</span><span class="o">)</span> <span class="n">option</span>
</code></pre></div>

<p>This attribute is documented in <code>create</code> above. The first version raises Not_found
if the attribute is None. The _opt version returns an option.</p>
</details>
<h3 id="tree__2">tree_<a class="headerlink" href="#tree__2" title="Permanent link">&para;</a></h3>
<details class="note" open="open"><summary>attribute</summary><div class="highlight"><pre><span></span><code><span class="k">val</span> <span class="n">tree_</span> <span class="o">:</span> <span class="n">t</span> <span class="o">-&gt;</span> <span class="nn">Py</span><span class="p">.</span><span class="nn">Object</span><span class="p">.</span><span class="n">t</span>
<span class="k">val</span> <span class="n">tree_opt</span> <span class="o">:</span> <span class="n">t</span> <span class="o">-&gt;</span> <span class="o">(</span><span class="nn">Py</span><span class="p">.</span><span class="nn">Object</span><span class="p">.</span><span class="n">t</span><span class="o">)</span> <span class="n">option</span>
</code></pre></div>

<p>This attribute is documented in <code>create</code> above. The first version raises Not_found
if the attribute is None. The _opt version returns an option.</p>
</details>
<h3 id="to_string_3">to_string<a class="headerlink" href="#to_string_3" title="Permanent link">&para;</a></h3>
<details class="note" open="open"><summary>method</summary><div class="highlight"><pre><span></span><code><span class="k">val</span> <span class="n">to_string</span><span class="o">:</span> <span class="n">t</span> <span class="o">-&gt;</span> <span class="kt">string</span>
</code></pre></div>

<p>Print the object to a human-readable representation.</p>
</details>
<h3 id="show_3">show<a class="headerlink" href="#show_3" title="Permanent link">&para;</a></h3>
<details class="note" open="open"><summary>method</summary><div class="highlight"><pre><span></span><code><span class="k">val</span> <span class="n">show</span><span class="o">:</span> <span class="n">t</span> <span class="o">-&gt;</span> <span class="kt">string</span>
</code></pre></div>

<p>Print the object to a human-readable representation.</p>
</details>
<h3 id="pp_3">pp<a class="headerlink" href="#pp_3" title="Permanent link">&para;</a></h3>
<details class="note" open="open"><summary>method</summary><div class="highlight"><pre><span></span><code><span class="k">val</span> <span class="n">pp</span><span class="o">:</span> <span class="nn">Format</span><span class="p">.</span><span class="n">formatter</span> <span class="o">-&gt;</span> <span class="n">t</span> <span class="o">-&gt;</span> <span class="kt">unit</span>
</code></pre></div>

<p>Pretty-print the object to a formatter.</p>
</details>
<h2 id="extratreeregressor">ExtraTreeRegressor<a class="headerlink" href="#extratreeregressor" title="Permanent link">&para;</a></h2>
<p>Module <code>Sklearn.Tree.ExtraTreeRegressor</code> wraps Python class <a href="https://scikit-learn.org/stable/modules/generated/sklearn.tree.ExtraTreeRegressor.html"><code>sklearn.tree.ExtraTreeRegressor</code></a>.</p>
<div class="highlight"><pre><span></span><code><span class="k">type</span> <span class="n">t</span>
</code></pre></div>

<h3 id="create_3">create<a class="headerlink" href="#create_3" title="Permanent link">&para;</a></h3>
<details class="note" open="open"><summary>constructor and attributes</summary><div class="highlight"><pre><span></span><code><span class="k">val</span> <span class="n">create</span> <span class="o">:</span>
  <span class="o">?</span><span class="n">criterion</span><span class="o">:[`</span><span class="nc">Mse</span> <span class="o">|</span> <span class="o">`</span><span class="nc">Friedman_mse</span> <span class="o">|</span> <span class="o">`</span><span class="nc">Mae</span><span class="o">]</span> <span class="o">-&gt;</span>
  <span class="o">?</span><span class="n">splitter</span><span class="o">:[`</span><span class="nc">Random</span> <span class="o">|</span> <span class="o">`</span><span class="nc">Best</span><span class="o">]</span> <span class="o">-&gt;</span>
  <span class="o">?</span><span class="n">max_depth</span><span class="o">:</span><span class="kt">int</span> <span class="o">-&gt;</span>
  <span class="o">?</span><span class="n">min_samples_split</span><span class="o">:[`</span><span class="nc">I</span> <span class="k">of</span> <span class="kt">int</span> <span class="o">|</span> <span class="o">`</span><span class="nc">F</span> <span class="k">of</span> <span class="kt">float</span><span class="o">]</span> <span class="o">-&gt;</span>
  <span class="o">?</span><span class="n">min_samples_leaf</span><span class="o">:[`</span><span class="nc">I</span> <span class="k">of</span> <span class="kt">int</span> <span class="o">|</span> <span class="o">`</span><span class="nc">F</span> <span class="k">of</span> <span class="kt">float</span><span class="o">]</span> <span class="o">-&gt;</span>
  <span class="o">?</span><span class="n">min_weight_fraction_leaf</span><span class="o">:</span><span class="kt">float</span> <span class="o">-&gt;</span>
  <span class="o">?</span><span class="n">max_features</span><span class="o">:[`</span><span class="nc">F</span> <span class="k">of</span> <span class="kt">float</span> <span class="o">|</span> <span class="o">`</span><span class="nc">Sqrt</span> <span class="o">|</span> <span class="o">`</span><span class="nc">I</span> <span class="k">of</span> <span class="kt">int</span> <span class="o">|</span> <span class="o">`</span><span class="nc">PyObject</span> <span class="k">of</span> <span class="nn">Py</span><span class="p">.</span><span class="nn">Object</span><span class="p">.</span><span class="n">t</span> <span class="o">|</span> <span class="o">`</span><span class="nc">None</span><span class="o">]</span> <span class="o">-&gt;</span>
  <span class="o">?</span><span class="n">random_state</span><span class="o">:</span><span class="kt">int</span> <span class="o">-&gt;</span>
  <span class="o">?</span><span class="n">min_impurity_decrease</span><span class="o">:</span><span class="kt">float</span> <span class="o">-&gt;</span>
  <span class="o">?</span><span class="n">min_impurity_split</span><span class="o">:</span><span class="kt">float</span> <span class="o">-&gt;</span>
  <span class="o">?</span><span class="n">max_leaf_nodes</span><span class="o">:</span><span class="kt">int</span> <span class="o">-&gt;</span>
  <span class="o">?</span><span class="n">ccp_alpha</span><span class="o">:</span><span class="kt">float</span> <span class="o">-&gt;</span>
  <span class="kt">unit</span> <span class="o">-&gt;</span>
  <span class="n">t</span>
</code></pre></div>

<p>An extremely randomized tree regressor.</p>
<p>Extra-trees differ from classic decision trees in the way they are built.
When looking for the best split to separate the samples of a node into two
groups, random splits are drawn for each of the <code>max_features</code> randomly
selected features and the best split among those is chosen. When
<code>max_features</code> is set 1, this amounts to building a totally random
decision tree.</p>
<details class="info" open="open"><summary>Warning: Extra-trees should only be used within ensemble methods.</summary></details>
<p>Read more in the :ref:<code>User Guide &lt;tree&gt;</code>.</p>
<h4>Parameters</h4>
<details class="info" open="open"><summary>criterion : {'mse', 'friedman_mse', 'mae'}, default='mse'</summary><p>The function to measure the quality of a split. Supported criteria
are 'mse' for the mean squared error, which is equal to variance
reduction as feature selection criterion, and 'mae' for the mean
absolute error.</p>
<p>.. versionadded:: 0.18
   Mean Absolute Error (MAE) criterion.</p>
</details>
<details class="info" open="open"><summary>splitter : {'random', 'best'}, default='random'</summary><p>The strategy used to choose the split at each node. Supported
strategies are 'best' to choose the best split and 'random' to choose
the best random split.</p>
</details>
<details class="info" open="open"><summary>max_depth : int, default=None</summary><p>The maximum depth of the tree. If None, then nodes are expanded until
all leaves are pure or until all leaves contain less than
min_samples_split samples.</p>
</details>
<details class="info" open="open"><summary>min_samples_split : int or float, default=2</summary><p>The minimum number of samples required to split an internal node:</p>
<ul>
<li>If int, then consider <code>min_samples_split</code> as the minimum number.</li>
<li>If float, then <code>min_samples_split</code> is a fraction and
  <code>ceil(min_samples_split * n_samples)</code> are the minimum
  number of samples for each split.</li>
</ul>
<p>.. versionchanged:: 0.18
   Added float values for fractions.</p>
</details>
<details class="info" open="open"><summary>min_samples_leaf : int or float, default=1</summary><p>The minimum number of samples required to be at a leaf node.
A split point at any depth will only be considered if it leaves at
least <code>min_samples_leaf</code> training samples in each of the left and
right branches.  This may have the effect of smoothing the model,
especially in regression.</p>
<ul>
<li>If int, then consider <code>min_samples_leaf</code> as the minimum number.</li>
<li>If float, then <code>min_samples_leaf</code> is a fraction and
  <code>ceil(min_samples_leaf * n_samples)</code> are the minimum
  number of samples for each node.</li>
</ul>
<p>.. versionchanged:: 0.18
   Added float values for fractions.</p>
</details>
<details class="info" open="open"><summary>min_weight_fraction_leaf : float, default=0.0</summary><p>The minimum weighted fraction of the sum total of weights (of all
the input samples) required to be at a leaf node. Samples have
equal weight when sample_weight is not provided.</p>
</details>
<details class="info" open="open"><summary>max_features : int, float, {'auto', 'sqrt', 'log2'} or None, default='auto'</summary><p>The number of features to consider when looking for the best split:</p>
<ul>
<li>If int, then consider <code>max_features</code> features at each split.</li>
<li>If float, then <code>max_features</code> is a fraction and
  <code>int(max_features * n_features)</code> features are considered at each
  split.</li>
<li>If 'auto', then <code>max_features=n_features</code>.</li>
<li>If 'sqrt', then <code>max_features=sqrt(n_features)</code>.</li>
<li>If 'log2', then <code>max_features=log2(n_features)</code>.</li>
<li>If None, then <code>max_features=n_features</code>.</li>
</ul>
</details>
<details class="info" open="open"><summary>Note: the search for a split does not stop until at least one</summary><p>valid partition of the node samples is found, even if it requires to
effectively inspect more than <code>max_features</code> features.</p>
</details>
<details class="info" open="open"><summary>random_state : int, RandomState instance, default=None</summary><p>Used to pick randomly the <code>max_features</code> used at each split.</p>
</details>
<details class="info" open="open"><summary>See :term:<code>Glossary &lt;random_state&gt;</code> for details.</summary></details>
<details class="info" open="open"><summary>min_impurity_decrease : float, default=0.0</summary><p>A node will be split if this split induces a decrease of the impurity
greater than or equal to this value.</p>
<p>The weighted impurity decrease equation is the following::</p>
<div class="codehilite"><pre><span></span><code>N_t / N * (impurity - N_t_R / N_t * right_impurity
                    - N_t_L / N_t * left_impurity)
</code></pre></div>


<p>where <code>N</code> is the total number of samples, <code>N_t</code> is the number of
samples at the current node, <code>N_t_L</code> is the number of samples in the
left child, and <code>N_t_R</code> is the number of samples in the right child.</p>
<p><code>N</code>, <code>N_t</code>, <code>N_t_R</code> and <code>N_t_L</code> all refer to the weighted sum,
if <code>sample_weight</code> is passed.</p>
<p>.. versionadded:: 0.19</p>
</details>
<details class="info" open="open"><summary>min_impurity_split : float, (default=0)</summary><p>Threshold for early stopping in tree growth. A node will split
if its impurity is above the threshold, otherwise it is a leaf.</p>
<p>.. deprecated:: 0.19
   <code>min_impurity_split</code> has been deprecated in favor of
   <code>min_impurity_decrease</code> in 0.19. The default value of
   <code>min_impurity_split</code> has changed from 1e-7 to 0 in 0.23 and it
   will be removed in 0.25. Use <code>min_impurity_decrease</code> instead.</p>
</details>
<details class="info" open="open"><summary>max_leaf_nodes : int, default=None</summary><p>Grow a tree with <code>max_leaf_nodes</code> in best-first fashion.
Best nodes are defined as relative reduction in impurity.
If None then unlimited number of leaf nodes.</p>
</details>
<details class="info" open="open"><summary>ccp_alpha : non-negative float, default=0.0</summary><p>Complexity parameter used for Minimal Cost-Complexity Pruning. The
subtree with the largest cost complexity that is smaller than
<code>ccp_alpha</code> will be chosen. By default, no pruning is performed. See
:ref:<code>minimal_cost_complexity_pruning</code> for details.</p>
<p>.. versionadded:: 0.22</p>
</details>
<h4>Attributes</h4>
<details class="info" open="open"><summary>max_features_ : int</summary><p>The inferred value of max_features.</p>
</details>
<details class="info" open="open"><summary>n_features_ : int</summary><p>The number of features when <code>fit</code> is performed.</p>
</details>
<details class="info" open="open"><summary>feature_importances_ : ndarray of shape (n_features,)</summary><p>Return impurity-based feature importances (the higher, the more
important the feature).</p>
</details>
<details class="info" open="open"><summary>Warning: impurity-based feature importances can be misleading for</summary><p>high cardinality features (many unique values). See
:func:<code>sklearn.inspection.permutation_importance</code> as an alternative.</p>
</details>
<details class="info" open="open"><summary>n_outputs_ : int</summary><p>The number of outputs when <code>fit</code> is performed.</p>
</details>
<details class="info" open="open"><summary>tree_ : Tree</summary><p>The underlying Tree object. Please refer to
<code>help(sklearn.tree._tree.Tree)</code> for attributes of Tree object and
:ref:<code>sphx_glr_auto_examples_tree_plot_unveil_tree_structure.py</code>
for basic usage of these attributes.</p>
</details>
<h4>See Also</h4>
<details class="info" open="open"><summary>ExtraTreeClassifier : An extremely randomized tree classifier.</summary></details>
<details class="info" open="open"><summary>sklearn.ensemble.ExtraTreesClassifier : An extra-trees classifier.</summary></details>
<details class="info" open="open"><summary>sklearn.ensemble.ExtraTreesRegressor : An extra-trees regressor.</summary></details>
<h4>Notes</h4>
<p>The default values for the parameters controlling the size of the trees
(e.g. <code>max_depth</code>, <code>min_samples_leaf</code>, etc.) lead to fully grown and
unpruned trees which can potentially be very large on some data sets. To
reduce memory consumption, the complexity and size of the trees should be
controlled by setting those parameter values.</p>
<h4>References</h4>
<p>.. [1] P. Geurts, D. Ernst., and L. Wehenkel, 'Extremely randomized trees',
       Machine Learning, 63(1), 3-42, 2006.</p>
<h4>Examples</h4>
<div class="highlight"><pre><span></span><code><span class="o">&gt;&gt;&gt;</span> <span class="kn">from</span> <span class="nn">sklearn.datasets</span> <span class="kn">import</span> <span class="n">load_diabetes</span>
<span class="o">&gt;&gt;&gt;</span> <span class="kn">from</span> <span class="nn">sklearn.model_selection</span> <span class="kn">import</span> <span class="n">train_test_split</span>
<span class="o">&gt;&gt;&gt;</span> <span class="kn">from</span> <span class="nn">sklearn.ensemble</span> <span class="kn">import</span> <span class="n">BaggingRegressor</span>
<span class="o">&gt;&gt;&gt;</span> <span class="kn">from</span> <span class="nn">sklearn.tree</span> <span class="kn">import</span> <span class="n">ExtraTreeRegressor</span>
<span class="o">&gt;&gt;&gt;</span> <span class="n">X</span><span class="p">,</span> <span class="n">y</span> <span class="o">=</span> <span class="n">load_diabetes</span><span class="p">(</span><span class="n">return_X_y</span><span class="o">=</span><span class="kc">True</span><span class="p">)</span>
<span class="o">&gt;&gt;&gt;</span> <span class="n">X_train</span><span class="p">,</span> <span class="n">X_test</span><span class="p">,</span> <span class="n">y_train</span><span class="p">,</span> <span class="n">y_test</span> <span class="o">=</span> <span class="n">train_test_split</span><span class="p">(</span>
<span class="o">...</span>     <span class="n">X</span><span class="p">,</span> <span class="n">y</span><span class="p">,</span> <span class="n">random_state</span><span class="o">=</span><span class="mi">0</span><span class="p">)</span>
<span class="o">&gt;&gt;&gt;</span> <span class="n">extra_tree</span> <span class="o">=</span> <span class="n">ExtraTreeRegressor</span><span class="p">(</span><span class="n">random_state</span><span class="o">=</span><span class="mi">0</span><span class="p">)</span>
<span class="o">&gt;&gt;&gt;</span> <span class="n">reg</span> <span class="o">=</span> <span class="n">BaggingRegressor</span><span class="p">(</span><span class="n">extra_tree</span><span class="p">,</span> <span class="n">random_state</span><span class="o">=</span><span class="mi">0</span><span class="p">)</span><span class="o">.</span><span class="n">fit</span><span class="p">(</span>
<span class="o">...</span>     <span class="n">X_train</span><span class="p">,</span> <span class="n">y_train</span><span class="p">)</span>
<span class="o">&gt;&gt;&gt;</span> <span class="n">reg</span><span class="o">.</span><span class="n">score</span><span class="p">(</span><span class="n">X_test</span><span class="p">,</span> <span class="n">y_test</span><span class="p">)</span>
<span class="mf">0.33</span><span class="o">...</span>
</code></pre></div>

</details>
<h3 id="apply_4">apply<a class="headerlink" href="#apply_4" title="Permanent link">&para;</a></h3>
<details class="note" open="open"><summary>method</summary><div class="highlight"><pre><span></span><code><span class="k">val</span> <span class="n">apply</span> <span class="o">:</span>
  <span class="o">?</span><span class="n">check_input</span><span class="o">:</span><span class="kt">bool</span> <span class="o">-&gt;</span>
  <span class="n">x</span><span class="o">:[&gt;`</span><span class="nc">ArrayLike</span><span class="o">]</span> <span class="nn">Np</span><span class="p">.</span><span class="nn">Obj</span><span class="p">.</span><span class="n">t</span> <span class="o">-&gt;</span>
  <span class="o">[&gt;</span> <span class="n">tag</span><span class="o">]</span> <span class="nn">Obj</span><span class="p">.</span><span class="n">t</span> <span class="o">-&gt;</span>
  <span class="o">[&gt;`</span><span class="nc">ArrayLike</span><span class="o">]</span> <span class="nn">Np</span><span class="p">.</span><span class="nn">Obj</span><span class="p">.</span><span class="n">t</span>
</code></pre></div>

<p>Return the index of the leaf that each sample is predicted as.</p>
<p>.. versionadded:: 0.17</p>
<h4>Parameters</h4>
<details class="info" open="open"><summary>X : {array-like, sparse matrix} of shape (n_samples, n_features)</summary><p>The input samples. Internally, it will be converted to
<code>dtype=np.float32</code> and if a sparse matrix is provided
to a sparse <code>csr_matrix</code>.</p>
</details>
<details class="info" open="open"><summary>check_input : bool, default=True</summary><p>Allow to bypass several input checking.
Don't use this parameter unless you know what you do.</p>
</details>
<h4>Returns</h4>
<details class="info" open="open"><summary>X_leaves : array-like of shape (n_samples,)</summary><p>For each datapoint x in X, return the index of the leaf x
ends up in. Leaves are numbered within
<code>[0; self.tree_.node_count)</code>, possibly with gaps in the
numbering.</p>
</details>
</details>
<h3 id="cost_complexity_pruning_path_4">cost_complexity_pruning_path<a class="headerlink" href="#cost_complexity_pruning_path_4" title="Permanent link">&para;</a></h3>
<details class="note" open="open"><summary>method</summary><div class="highlight"><pre><span></span><code><span class="k">val</span> <span class="n">cost_complexity_pruning_path</span> <span class="o">:</span>
  <span class="o">?</span><span class="n">sample_weight</span><span class="o">:[&gt;`</span><span class="nc">ArrayLike</span><span class="o">]</span> <span class="nn">Np</span><span class="p">.</span><span class="nn">Obj</span><span class="p">.</span><span class="n">t</span> <span class="o">-&gt;</span>
  <span class="n">x</span><span class="o">:[&gt;`</span><span class="nc">ArrayLike</span><span class="o">]</span> <span class="nn">Np</span><span class="p">.</span><span class="nn">Obj</span><span class="p">.</span><span class="n">t</span> <span class="o">-&gt;</span>
  <span class="n">y</span><span class="o">:[&gt;`</span><span class="nc">ArrayLike</span><span class="o">]</span> <span class="nn">Np</span><span class="p">.</span><span class="nn">Obj</span><span class="p">.</span><span class="n">t</span> <span class="o">-&gt;</span>
  <span class="o">[&gt;</span> <span class="n">tag</span><span class="o">]</span> <span class="nn">Obj</span><span class="p">.</span><span class="n">t</span> <span class="o">-&gt;</span>
  <span class="o">(</span><span class="nn">Py</span><span class="p">.</span><span class="nn">Object</span><span class="p">.</span><span class="n">t</span> <span class="o">*</span> <span class="o">[&gt;`</span><span class="nc">ArrayLike</span><span class="o">]</span> <span class="nn">Np</span><span class="p">.</span><span class="nn">Obj</span><span class="p">.</span><span class="n">t</span> <span class="o">*</span> <span class="o">[&gt;`</span><span class="nc">ArrayLike</span><span class="o">]</span> <span class="nn">Np</span><span class="p">.</span><span class="nn">Obj</span><span class="p">.</span><span class="n">t</span><span class="o">)</span>
</code></pre></div>

<p>Compute the pruning path during Minimal Cost-Complexity Pruning.</p>
<details class="info" open="open"><summary>See :ref:<code>minimal_cost_complexity_pruning</code> for details on the pruning</summary></details>
<p>process.</p>
<h4>Parameters</h4>
<details class="info" open="open"><summary>X : {array-like, sparse matrix} of shape (n_samples, n_features)</summary><p>The training input samples. Internally, it will be converted to
<code>dtype=np.float32</code> and if a sparse matrix is provided
to a sparse <code>csc_matrix</code>.</p>
</details>
<details class="info" open="open"><summary>y : array-like of shape (n_samples,) or (n_samples, n_outputs)</summary><p>The target values (class labels) as integers or strings.</p>
</details>
<details class="info" open="open"><summary>sample_weight : array-like of shape (n_samples,), default=None</summary><p>Sample weights. If None, then samples are equally weighted. Splits
that would create child nodes with net zero or negative weight are
ignored while searching for a split in each node. Splits are also
ignored if they would result in any single class carrying a
negative weight in either child node.</p>
</details>
<h4>Returns</h4>
<details class="info" open="open"><summary>ccp_path : :class:<code>~sklearn.utils.Bunch</code></summary><p>Dictionary-like object, with the following attributes.</p>
</details>
<details class="info" open="open"><summary>ccp_alphas : ndarray</summary><div class="codehilite"><pre><span></span><code>Effective alphas of subtree during pruning.
</code></pre></div>


</details>
<details class="info" open="open"><summary>impurities : ndarray</summary><div class="codehilite"><pre><span></span><code>Sum of the impurities of the subtree leaves for the
corresponding alpha value in ``ccp_alphas``.
</code></pre></div>


</details>
</details>
<h3 id="decision_path_4">decision_path<a class="headerlink" href="#decision_path_4" title="Permanent link">&para;</a></h3>
<details class="note" open="open"><summary>method</summary><div class="highlight"><pre><span></span><code><span class="k">val</span> <span class="n">decision_path</span> <span class="o">:</span>
  <span class="o">?</span><span class="n">check_input</span><span class="o">:</span><span class="kt">bool</span> <span class="o">-&gt;</span>
  <span class="n">x</span><span class="o">:[&gt;`</span><span class="nc">ArrayLike</span><span class="o">]</span> <span class="nn">Np</span><span class="p">.</span><span class="nn">Obj</span><span class="p">.</span><span class="n">t</span> <span class="o">-&gt;</span>
  <span class="o">[&gt;</span> <span class="n">tag</span><span class="o">]</span> <span class="nn">Obj</span><span class="p">.</span><span class="n">t</span> <span class="o">-&gt;</span>
  <span class="o">[`</span><span class="nc">ArrayLike</span><span class="o">|`</span><span class="nc">Object</span><span class="o">|`</span><span class="nc">Spmatrix</span><span class="o">]</span> <span class="nn">Np</span><span class="p">.</span><span class="nn">Obj</span><span class="p">.</span><span class="n">t</span>
</code></pre></div>

<p>Return the decision path in the tree.</p>
<p>.. versionadded:: 0.18</p>
<h4>Parameters</h4>
<details class="info" open="open"><summary>X : {array-like, sparse matrix} of shape (n_samples, n_features)</summary><p>The input samples. Internally, it will be converted to
<code>dtype=np.float32</code> and if a sparse matrix is provided
to a sparse <code>csr_matrix</code>.</p>
</details>
<details class="info" open="open"><summary>check_input : bool, default=True</summary><p>Allow to bypass several input checking.
Don't use this parameter unless you know what you do.</p>
</details>
<h4>Returns</h4>
<details class="info" open="open"><summary>indicator : sparse matrix of shape (n_samples, n_nodes)</summary><p>Return a node indicator CSR matrix where non zero elements
indicates that the samples goes through the nodes.</p>
</details>
</details>
<h3 id="fit_4">fit<a class="headerlink" href="#fit_4" title="Permanent link">&para;</a></h3>
<details class="note" open="open"><summary>method</summary><div class="highlight"><pre><span></span><code><span class="k">val</span> <span class="n">fit</span> <span class="o">:</span>
  <span class="o">?</span><span class="n">sample_weight</span><span class="o">:[&gt;`</span><span class="nc">ArrayLike</span><span class="o">]</span> <span class="nn">Np</span><span class="p">.</span><span class="nn">Obj</span><span class="p">.</span><span class="n">t</span> <span class="o">-&gt;</span>
  <span class="o">?</span><span class="n">check_input</span><span class="o">:</span><span class="kt">bool</span> <span class="o">-&gt;</span>
  <span class="o">?</span><span class="n">x_idx_sorted</span><span class="o">:[&gt;`</span><span class="nc">ArrayLike</span><span class="o">]</span> <span class="nn">Np</span><span class="p">.</span><span class="nn">Obj</span><span class="p">.</span><span class="n">t</span> <span class="o">-&gt;</span>
  <span class="n">x</span><span class="o">:[&gt;`</span><span class="nc">ArrayLike</span><span class="o">]</span> <span class="nn">Np</span><span class="p">.</span><span class="nn">Obj</span><span class="p">.</span><span class="n">t</span> <span class="o">-&gt;</span>
  <span class="n">y</span><span class="o">:[&gt;`</span><span class="nc">ArrayLike</span><span class="o">]</span> <span class="nn">Np</span><span class="p">.</span><span class="nn">Obj</span><span class="p">.</span><span class="n">t</span> <span class="o">-&gt;</span>
  <span class="o">[&gt;</span> <span class="n">tag</span><span class="o">]</span> <span class="nn">Obj</span><span class="p">.</span><span class="n">t</span> <span class="o">-&gt;</span>
  <span class="n">t</span>
</code></pre></div>

<p>Build a decision tree regressor from the training set (X, y).</p>
<h4>Parameters</h4>
<details class="info" open="open"><summary>X : {array-like, sparse matrix} of shape (n_samples, n_features)</summary><p>The training input samples. Internally, it will be converted to
<code>dtype=np.float32</code> and if a sparse matrix is provided
to a sparse <code>csc_matrix</code>.</p>
</details>
<details class="info" open="open"><summary>y : array-like of shape (n_samples,) or (n_samples, n_outputs)</summary><p>The target values (real numbers). Use <code>dtype=np.float64</code> and
<code>order='C'</code> for maximum efficiency.</p>
</details>
<details class="info" open="open"><summary>sample_weight : array-like of shape (n_samples,), default=None</summary><p>Sample weights. If None, then samples are equally weighted. Splits
that would create child nodes with net zero or negative weight are
ignored while searching for a split in each node.</p>
</details>
<details class="info" open="open"><summary>check_input : bool, default=True</summary><p>Allow to bypass several input checking.
Don't use this parameter unless you know what you do.</p>
</details>
<details class="info" open="open"><summary>X_idx_sorted : array-like of shape (n_samples, n_features),             default=None</summary><p>The indexes of the sorted training input samples. If many tree
are grown on the same dataset, this allows the ordering to be
cached between trees. If None, the data will be sorted here.
Don't use this parameter unless you know what to do.</p>
</details>
<h4>Returns</h4>
<details class="info" open="open"><summary>self : DecisionTreeRegressor</summary><p>Fitted estimator.</p>
</details>
</details>
<h3 id="get_depth_4">get_depth<a class="headerlink" href="#get_depth_4" title="Permanent link">&para;</a></h3>
<details class="note" open="open"><summary>method</summary><div class="highlight"><pre><span></span><code><span class="k">val</span> <span class="n">get_depth</span> <span class="o">:</span>
  <span class="o">[&gt;</span> <span class="n">tag</span><span class="o">]</span> <span class="nn">Obj</span><span class="p">.</span><span class="n">t</span> <span class="o">-&gt;</span>
  <span class="nn">Py</span><span class="p">.</span><span class="nn">Object</span><span class="p">.</span><span class="n">t</span>
</code></pre></div>

<p>Return the depth of the decision tree.</p>
<p>The depth of a tree is the maximum distance between the root
and any leaf.</p>
<h4>Returns</h4>
<details class="info" open="open"><summary>self.tree_.max_depth : int</summary><p>The maximum depth of the tree.</p>
</details>
</details>
<h3 id="get_n_leaves_4">get_n_leaves<a class="headerlink" href="#get_n_leaves_4" title="Permanent link">&para;</a></h3>
<details class="note" open="open"><summary>method</summary><div class="highlight"><pre><span></span><code><span class="k">val</span> <span class="n">get_n_leaves</span> <span class="o">:</span>
  <span class="o">[&gt;</span> <span class="n">tag</span><span class="o">]</span> <span class="nn">Obj</span><span class="p">.</span><span class="n">t</span> <span class="o">-&gt;</span>
  <span class="nn">Py</span><span class="p">.</span><span class="nn">Object</span><span class="p">.</span><span class="n">t</span>
</code></pre></div>

<p>Return the number of leaves of the decision tree.</p>
<h4>Returns</h4>
<details class="info" open="open"><summary>self.tree_.n_leaves : int</summary><p>Number of leaves.</p>
</details>
</details>
<h3 id="get_params_4">get_params<a class="headerlink" href="#get_params_4" title="Permanent link">&para;</a></h3>
<details class="note" open="open"><summary>method</summary><div class="highlight"><pre><span></span><code><span class="k">val</span> <span class="n">get_params</span> <span class="o">:</span>
  <span class="o">?</span><span class="n">deep</span><span class="o">:</span><span class="kt">bool</span> <span class="o">-&gt;</span>
  <span class="o">[&gt;</span> <span class="n">tag</span><span class="o">]</span> <span class="nn">Obj</span><span class="p">.</span><span class="n">t</span> <span class="o">-&gt;</span>
  <span class="nn">Dict</span><span class="p">.</span><span class="n">t</span>
</code></pre></div>

<p>Get parameters for this estimator.</p>
<h4>Parameters</h4>
<details class="info" open="open"><summary>deep : bool, default=True</summary><p>If True, will return the parameters for this estimator and
contained subobjects that are estimators.</p>
</details>
<h4>Returns</h4>
<details class="info" open="open"><summary>params : mapping of string to any</summary><p>Parameter names mapped to their values.</p>
</details>
</details>
<h3 id="predict_4">predict<a class="headerlink" href="#predict_4" title="Permanent link">&para;</a></h3>
<details class="note" open="open"><summary>method</summary><div class="highlight"><pre><span></span><code><span class="k">val</span> <span class="n">predict</span> <span class="o">:</span>
  <span class="o">?</span><span class="n">check_input</span><span class="o">:</span><span class="kt">bool</span> <span class="o">-&gt;</span>
  <span class="n">x</span><span class="o">:[&gt;`</span><span class="nc">ArrayLike</span><span class="o">]</span> <span class="nn">Np</span><span class="p">.</span><span class="nn">Obj</span><span class="p">.</span><span class="n">t</span> <span class="o">-&gt;</span>
  <span class="o">[&gt;</span> <span class="n">tag</span><span class="o">]</span> <span class="nn">Obj</span><span class="p">.</span><span class="n">t</span> <span class="o">-&gt;</span>
  <span class="o">[&gt;`</span><span class="nc">ArrayLike</span><span class="o">]</span> <span class="nn">Np</span><span class="p">.</span><span class="nn">Obj</span><span class="p">.</span><span class="n">t</span>
</code></pre></div>

<p>Predict class or regression value for X.</p>
<p>For a classification model, the predicted class for each sample in X is
returned. For a regression model, the predicted value based on X is
returned.</p>
<h4>Parameters</h4>
<details class="info" open="open"><summary>X : {array-like, sparse matrix} of shape (n_samples, n_features)</summary><p>The input samples. Internally, it will be converted to
<code>dtype=np.float32</code> and if a sparse matrix is provided
to a sparse <code>csr_matrix</code>.</p>
</details>
<details class="info" open="open"><summary>check_input : bool, default=True</summary><p>Allow to bypass several input checking.
Don't use this parameter unless you know what you do.</p>
</details>
<h4>Returns</h4>
<details class="info" open="open"><summary>y : array-like of shape (n_samples,) or (n_samples, n_outputs)</summary><p>The predicted classes, or the predict values.</p>
</details>
</details>
<h3 id="score_3">score<a class="headerlink" href="#score_3" title="Permanent link">&para;</a></h3>
<details class="note" open="open"><summary>method</summary><div class="highlight"><pre><span></span><code><span class="k">val</span> <span class="n">score</span> <span class="o">:</span>
  <span class="o">?</span><span class="n">sample_weight</span><span class="o">:[&gt;`</span><span class="nc">ArrayLike</span><span class="o">]</span> <span class="nn">Np</span><span class="p">.</span><span class="nn">Obj</span><span class="p">.</span><span class="n">t</span> <span class="o">-&gt;</span>
  <span class="n">x</span><span class="o">:[&gt;`</span><span class="nc">ArrayLike</span><span class="o">]</span> <span class="nn">Np</span><span class="p">.</span><span class="nn">Obj</span><span class="p">.</span><span class="n">t</span> <span class="o">-&gt;</span>
  <span class="n">y</span><span class="o">:[&gt;`</span><span class="nc">ArrayLike</span><span class="o">]</span> <span class="nn">Np</span><span class="p">.</span><span class="nn">Obj</span><span class="p">.</span><span class="n">t</span> <span class="o">-&gt;</span>
  <span class="o">[&gt;</span> <span class="n">tag</span><span class="o">]</span> <span class="nn">Obj</span><span class="p">.</span><span class="n">t</span> <span class="o">-&gt;</span>
  <span class="kt">float</span>
</code></pre></div>

<p>Return the coefficient of determination R^2 of the prediction.</p>
<p>The coefficient R^2 is defined as (1 - u/v), where u is the residual
sum of squares ((y_true - y_pred) <strong> 2).sum() and v is the total
sum of squares ((y_true - y_true.mean()) </strong> 2).sum().
The best possible score is 1.0 and it can be negative (because the
model can be arbitrarily worse). A constant model that always
predicts the expected value of y, disregarding the input features,
would get a R^2 score of 0.0.</p>
<h4>Parameters</h4>
<details class="info" open="open"><summary>X : array-like of shape (n_samples, n_features)</summary><p>Test samples. For some estimators this may be a
precomputed kernel matrix or a list of generic objects instead,
shape = (n_samples, n_samples_fitted),
where n_samples_fitted is the number of
samples used in the fitting for the estimator.</p>
</details>
<details class="info" open="open"><summary>y : array-like of shape (n_samples,) or (n_samples, n_outputs)</summary><p>True values for X.</p>
</details>
<details class="info" open="open"><summary>sample_weight : array-like of shape (n_samples,), default=None</summary><p>Sample weights.</p>
</details>
<h4>Returns</h4>
<details class="info" open="open"><summary>score : float</summary><p>R^2 of self.predict(X) wrt. y.</p>
</details>
<h4>Notes</h4>
<p>The R2 score used when calling <code>score</code> on a regressor uses
<code>multioutput='uniform_average'</code> from version 0.23 to keep consistent
with default value of :func:<code>~sklearn.metrics.r2_score</code>.
This influences the <code>score</code> method of all the multioutput
regressors (except for
:class:<code>~sklearn.multioutput.MultiOutputRegressor</code>).</p>
</details>
<h3 id="set_params_4">set_params<a class="headerlink" href="#set_params_4" title="Permanent link">&para;</a></h3>
<details class="note" open="open"><summary>method</summary><div class="highlight"><pre><span></span><code><span class="k">val</span> <span class="n">set_params</span> <span class="o">:</span>
  <span class="o">?</span><span class="n">params</span><span class="o">:(</span><span class="kt">string</span> <span class="o">*</span> <span class="nn">Py</span><span class="p">.</span><span class="nn">Object</span><span class="p">.</span><span class="n">t</span><span class="o">)</span> <span class="kt">list</span> <span class="o">-&gt;</span>
  <span class="o">[&gt;</span> <span class="n">tag</span><span class="o">]</span> <span class="nn">Obj</span><span class="p">.</span><span class="n">t</span> <span class="o">-&gt;</span>
  <span class="n">t</span>
</code></pre></div>

<p>Set the parameters of this estimator.</p>
<p>The method works on simple estimators as well as on nested objects
(such as pipelines). The latter have parameters of the form
<code>&lt;component&gt;__&lt;parameter&gt;</code> so that it's possible to update each
component of a nested object.</p>
<h4>Parameters</h4>
<details class="info" open="open"><summary>**params : dict</summary><p>Estimator parameters.</p>
</details>
<h4>Returns</h4>
<details class="info" open="open"><summary>self : object</summary><p>Estimator instance.</p>
</details>
</details>
<h3 id="max_features__3">max_features_<a class="headerlink" href="#max_features__3" title="Permanent link">&para;</a></h3>
<details class="note" open="open"><summary>attribute</summary><div class="highlight"><pre><span></span><code><span class="k">val</span> <span class="n">max_features_</span> <span class="o">:</span> <span class="n">t</span> <span class="o">-&gt;</span> <span class="kt">int</span>
<span class="k">val</span> <span class="n">max_features_opt</span> <span class="o">:</span> <span class="n">t</span> <span class="o">-&gt;</span> <span class="o">(</span><span class="kt">int</span><span class="o">)</span> <span class="n">option</span>
</code></pre></div>

<p>This attribute is documented in <code>create</code> above. The first version raises Not_found
if the attribute is None. The _opt version returns an option.</p>
</details>
<h3 id="n_features__3">n_features_<a class="headerlink" href="#n_features__3" title="Permanent link">&para;</a></h3>
<details class="note" open="open"><summary>attribute</summary><div class="highlight"><pre><span></span><code><span class="k">val</span> <span class="n">n_features_</span> <span class="o">:</span> <span class="n">t</span> <span class="o">-&gt;</span> <span class="kt">int</span>
<span class="k">val</span> <span class="n">n_features_opt</span> <span class="o">:</span> <span class="n">t</span> <span class="o">-&gt;</span> <span class="o">(</span><span class="kt">int</span><span class="o">)</span> <span class="n">option</span>
</code></pre></div>

<p>This attribute is documented in <code>create</code> above. The first version raises Not_found
if the attribute is None. The _opt version returns an option.</p>
</details>
<h3 id="feature_importances__3">feature_importances_<a class="headerlink" href="#feature_importances__3" title="Permanent link">&para;</a></h3>
<details class="note" open="open"><summary>attribute</summary><div class="highlight"><pre><span></span><code><span class="k">val</span> <span class="n">feature_importances_</span> <span class="o">:</span> <span class="n">t</span> <span class="o">-&gt;</span> <span class="o">[&gt;`</span><span class="nc">ArrayLike</span><span class="o">]</span> <span class="nn">Np</span><span class="p">.</span><span class="nn">Obj</span><span class="p">.</span><span class="n">t</span>
<span class="k">val</span> <span class="n">feature_importances_opt</span> <span class="o">:</span> <span class="n">t</span> <span class="o">-&gt;</span> <span class="o">([&gt;`</span><span class="nc">ArrayLike</span><span class="o">]</span> <span class="nn">Np</span><span class="p">.</span><span class="nn">Obj</span><span class="p">.</span><span class="n">t</span><span class="o">)</span> <span class="n">option</span>
</code></pre></div>

<p>This attribute is documented in <code>create</code> above. The first version raises Not_found
if the attribute is None. The _opt version returns an option.</p>
</details>
<h3 id="warning_3">warning<a class="headerlink" href="#warning_3" title="Permanent link">&para;</a></h3>
<details class="note" open="open"><summary>attribute</summary><div class="highlight"><pre><span></span><code><span class="k">val</span> <span class="n">warning</span> <span class="o">:</span> <span class="n">t</span> <span class="o">-&gt;</span> <span class="nn">Py</span><span class="p">.</span><span class="nn">Object</span><span class="p">.</span><span class="n">t</span>
<span class="k">val</span> <span class="n">warning_opt</span> <span class="o">:</span> <span class="n">t</span> <span class="o">-&gt;</span> <span class="o">(</span><span class="nn">Py</span><span class="p">.</span><span class="nn">Object</span><span class="p">.</span><span class="n">t</span><span class="o">)</span> <span class="n">option</span>
</code></pre></div>

<p>This attribute is documented in <code>create</code> above. The first version raises Not_found
if the attribute is None. The _opt version returns an option.</p>
</details>
<h3 id="n_outputs__3">n_outputs_<a class="headerlink" href="#n_outputs__3" title="Permanent link">&para;</a></h3>
<details class="note" open="open"><summary>attribute</summary><div class="highlight"><pre><span></span><code><span class="k">val</span> <span class="n">n_outputs_</span> <span class="o">:</span> <span class="n">t</span> <span class="o">-&gt;</span> <span class="kt">int</span>
<span class="k">val</span> <span class="n">n_outputs_opt</span> <span class="o">:</span> <span class="n">t</span> <span class="o">-&gt;</span> <span class="o">(</span><span class="kt">int</span><span class="o">)</span> <span class="n">option</span>
</code></pre></div>

<p>This attribute is documented in <code>create</code> above. The first version raises Not_found
if the attribute is None. The _opt version returns an option.</p>
</details>
<h3 id="tree__3">tree_<a class="headerlink" href="#tree__3" title="Permanent link">&para;</a></h3>
<details class="note" open="open"><summary>attribute</summary><div class="highlight"><pre><span></span><code><span class="k">val</span> <span class="n">tree_</span> <span class="o">:</span> <span class="n">t</span> <span class="o">-&gt;</span> <span class="nn">Py</span><span class="p">.</span><span class="nn">Object</span><span class="p">.</span><span class="n">t</span>
<span class="k">val</span> <span class="n">tree_opt</span> <span class="o">:</span> <span class="n">t</span> <span class="o">-&gt;</span> <span class="o">(</span><span class="nn">Py</span><span class="p">.</span><span class="nn">Object</span><span class="p">.</span><span class="n">t</span><span class="o">)</span> <span class="n">option</span>
</code></pre></div>

<p>This attribute is documented in <code>create</code> above. The first version raises Not_found
if the attribute is None. The _opt version returns an option.</p>
</details>
<h3 id="to_string_4">to_string<a class="headerlink" href="#to_string_4" title="Permanent link">&para;</a></h3>
<details class="note" open="open"><summary>method</summary><div class="highlight"><pre><span></span><code><span class="k">val</span> <span class="n">to_string</span><span class="o">:</span> <span class="n">t</span> <span class="o">-&gt;</span> <span class="kt">string</span>
</code></pre></div>

<p>Print the object to a human-readable representation.</p>
</details>
<h3 id="show_4">show<a class="headerlink" href="#show_4" title="Permanent link">&para;</a></h3>
<details class="note" open="open"><summary>method</summary><div class="highlight"><pre><span></span><code><span class="k">val</span> <span class="n">show</span><span class="o">:</span> <span class="n">t</span> <span class="o">-&gt;</span> <span class="kt">string</span>
</code></pre></div>

<p>Print the object to a human-readable representation.</p>
</details>
<h3 id="pp_4">pp<a class="headerlink" href="#pp_4" title="Permanent link">&para;</a></h3>
<details class="note" open="open"><summary>method</summary><div class="highlight"><pre><span></span><code><span class="k">val</span> <span class="n">pp</span><span class="o">:</span> <span class="nn">Format</span><span class="p">.</span><span class="n">formatter</span> <span class="o">-&gt;</span> <span class="n">t</span> <span class="o">-&gt;</span> <span class="kt">unit</span>
</code></pre></div>

<p>Pretty-print the object to a formatter.</p>
</details>
<h3 id="export_graphviz">export_graphviz<a class="headerlink" href="#export_graphviz" title="Permanent link">&para;</a></h3>
<details class="note" open="open"><summary>function</summary><div class="highlight"><pre><span></span><code><span class="k">val</span> <span class="n">export_graphviz</span> <span class="o">:</span>
  <span class="o">?</span><span class="n">out_file</span><span class="o">:[`</span><span class="nc">File_object</span> <span class="k">of</span> <span class="nn">Py</span><span class="p">.</span><span class="nn">Object</span><span class="p">.</span><span class="n">t</span> <span class="o">|</span> <span class="o">`</span><span class="nc">S</span> <span class="k">of</span> <span class="kt">string</span><span class="o">]</span> <span class="o">-&gt;</span>
  <span class="o">?</span><span class="n">max_depth</span><span class="o">:</span><span class="kt">int</span> <span class="o">-&gt;</span>
  <span class="o">?</span><span class="n">feature_names</span><span class="o">:</span><span class="kt">string</span> <span class="kt">list</span> <span class="o">-&gt;</span>
  <span class="o">?</span><span class="n">class_names</span><span class="o">:[`</span><span class="nc">StringList</span> <span class="k">of</span> <span class="kt">string</span> <span class="kt">list</span> <span class="o">|</span> <span class="o">`</span><span class="nc">Bool</span> <span class="k">of</span> <span class="kt">bool</span><span class="o">]</span> <span class="o">-&gt;</span>
  <span class="o">?</span><span class="n">label</span><span class="o">:[`</span><span class="nc">All</span> <span class="o">|</span> <span class="o">`</span><span class="nc">Root</span> <span class="o">|</span> <span class="o">`</span><span class="nc">None</span><span class="o">]</span> <span class="o">-&gt;</span>
  <span class="o">?</span><span class="n">filled</span><span class="o">:</span><span class="kt">bool</span> <span class="o">-&gt;</span>
  <span class="o">?</span><span class="n">leaves_parallel</span><span class="o">:</span><span class="kt">bool</span> <span class="o">-&gt;</span>
  <span class="o">?</span><span class="n">impurity</span><span class="o">:</span><span class="kt">bool</span> <span class="o">-&gt;</span>
  <span class="o">?</span><span class="n">node_ids</span><span class="o">:</span><span class="kt">bool</span> <span class="o">-&gt;</span>
  <span class="o">?</span><span class="n">proportion</span><span class="o">:</span><span class="kt">bool</span> <span class="o">-&gt;</span>
  <span class="o">?</span><span class="n">rotate</span><span class="o">:</span><span class="kt">bool</span> <span class="o">-&gt;</span>
  <span class="o">?</span><span class="n">rounded</span><span class="o">:</span><span class="kt">bool</span> <span class="o">-&gt;</span>
  <span class="o">?</span><span class="n">special_characters</span><span class="o">:</span><span class="kt">bool</span> <span class="o">-&gt;</span>
  <span class="o">?</span><span class="n">precision</span><span class="o">:</span><span class="kt">int</span> <span class="o">-&gt;</span>
  <span class="n">decision_tree</span><span class="o">:[&gt;`</span><span class="nc">DecisionTreeClassifier</span><span class="o">]</span> <span class="nn">Np</span><span class="p">.</span><span class="nn">Obj</span><span class="p">.</span><span class="n">t</span> <span class="o">-&gt;</span>
  <span class="kt">unit</span> <span class="o">-&gt;</span>
  <span class="kt">string</span> <span class="n">option</span>
</code></pre></div>

<p>Export a decision tree in DOT format.</p>
<p>This function generates a GraphViz representation of the decision tree,
which is then written into <code>out_file</code>. Once exported, graphical renderings
can be generated using, for example::</p>
<div class="codehilite"><pre><span></span><code>$ dot -Tps tree.dot -o tree.ps      (PostScript format)
$ dot -Tpng tree.dot -o tree.png    (PNG format)
</code></pre></div>


<p>The sample counts that are shown are weighted with any sample_weights that
might be present.</p>
<p>Read more in the :ref:<code>User Guide &lt;tree&gt;</code>.</p>
<h4>Parameters</h4>
<details class="info" open="open"><summary>decision_tree : decision tree classifier</summary><p>The decision tree to be exported to GraphViz.</p>
</details>
<details class="info" open="open"><summary>out_file : file object or string, optional (default=None)</summary><p>Handle or name of the output file. If <code>None</code>, the result is
returned as a string.</p>
<p>.. versionchanged:: 0.20
    Default of out_file changed from 'tree.dot' to None.</p>
</details>
<details class="info" open="open"><summary>max_depth : int, optional (default=None)</summary><p>The maximum depth of the representation. If None, the tree is fully
generated.</p>
</details>
<details class="info" open="open"><summary>feature_names : list of strings, optional (default=None)</summary><p>Names of each of the features.</p>
</details>
<details class="info" open="open"><summary>class_names : list of strings, bool or None, optional (default=None)</summary><p>Names of each of the target classes in ascending numerical order.
Only relevant for classification and not supported for multi-output.
If <code>True</code>, shows a symbolic representation of the class name.</p>
</details>
<details class="info" open="open"><summary>label : {'all', 'root', 'none'}, optional (default='all')</summary><p>Whether to show informative labels for impurity, etc.
Options include 'all' to show at every node, 'root' to show only at
the top root node, or 'none' to not show at any node.</p>
</details>
<details class="info" open="open"><summary>filled : bool, optional (default=False)</summary><p>When set to <code>True</code>, paint nodes to indicate majority class for
classification, extremity of values for regression, or purity of node
for multi-output.</p>
</details>
<details class="info" open="open"><summary>leaves_parallel : bool, optional (default=False)</summary><p>When set to <code>True</code>, draw all leaf nodes at the bottom of the tree.</p>
</details>
<details class="info" open="open"><summary>impurity : bool, optional (default=True)</summary><p>When set to <code>True</code>, show the impurity at each node.</p>
</details>
<details class="info" open="open"><summary>node_ids : bool, optional (default=False)</summary><p>When set to <code>True</code>, show the ID number on each node.</p>
</details>
<details class="info" open="open"><summary>proportion : bool, optional (default=False)</summary><p>When set to <code>True</code>, change the display of 'values' and/or 'samples'
to be proportions and percentages respectively.</p>
</details>
<details class="info" open="open"><summary>rotate : bool, optional (default=False)</summary><p>When set to <code>True</code>, orient tree left to right rather than top-down.</p>
</details>
<details class="info" open="open"><summary>rounded : bool, optional (default=False)</summary><p>When set to <code>True</code>, draw node boxes with rounded corners and use
Helvetica fonts instead of Times-Roman.</p>
</details>
<details class="info" open="open"><summary>special_characters : bool, optional (default=False)</summary><p>When set to <code>False</code>, ignore special characters for PostScript
compatibility.</p>
</details>
<details class="info" open="open"><summary>precision : int, optional (default=3)</summary><p>Number of digits of precision for floating point in the values of
impurity, threshold and value attributes of each node.</p>
</details>
<h4>Returns</h4>
<details class="info" open="open"><summary>dot_data : string</summary><p>String representation of the input tree in GraphViz dot format.
Only returned if <code>out_file</code> is None.</p>
<p>.. versionadded:: 0.18</p>
</details>
<h4>Examples</h4>
<div class="highlight"><pre><span></span><code><span class="o">&gt;&gt;&gt;</span> <span class="kn">from</span> <span class="nn">sklearn.datasets</span> <span class="kn">import</span> <span class="n">load_iris</span>
<span class="o">&gt;&gt;&gt;</span> <span class="kn">from</span> <span class="nn">sklearn</span> <span class="kn">import</span> <span class="n">tree</span>
</code></pre></div>

<div class="highlight"><pre><span></span><code><span class="o">&gt;&gt;&gt;</span> <span class="n">clf</span> <span class="o">=</span> <span class="n">tree</span><span class="o">.</span><span class="n">DecisionTreeClassifier</span><span class="p">()</span>
<span class="o">&gt;&gt;&gt;</span> <span class="n">iris</span> <span class="o">=</span> <span class="n">load_iris</span><span class="p">()</span>
</code></pre></div>

<div class="highlight"><pre><span></span><code><span class="o">&gt;&gt;&gt;</span> <span class="n">clf</span> <span class="o">=</span> <span class="n">clf</span><span class="o">.</span><span class="n">fit</span><span class="p">(</span><span class="n">iris</span><span class="o">.</span><span class="n">data</span><span class="p">,</span> <span class="n">iris</span><span class="o">.</span><span class="n">target</span><span class="p">)</span>
<span class="o">&gt;&gt;&gt;</span> <span class="n">tree</span><span class="o">.</span><span class="n">export_graphviz</span><span class="p">(</span><span class="n">clf</span><span class="p">)</span>
<span class="s1">&#39;digraph Tree {...</span>
</code></pre></div>

</details>
<h3 id="export_text">export_text<a class="headerlink" href="#export_text" title="Permanent link">&para;</a></h3>
<details class="note" open="open"><summary>function</summary><div class="highlight"><pre><span></span><code><span class="k">val</span> <span class="n">export_text</span> <span class="o">:</span>
  <span class="o">?</span><span class="n">feature_names</span><span class="o">:</span><span class="kt">string</span> <span class="kt">list</span> <span class="o">-&gt;</span>
  <span class="o">?</span><span class="n">max_depth</span><span class="o">:</span><span class="kt">int</span> <span class="o">-&gt;</span>
  <span class="o">?</span><span class="n">spacing</span><span class="o">:</span><span class="kt">int</span> <span class="o">-&gt;</span>
  <span class="o">?</span><span class="n">decimals</span><span class="o">:</span><span class="kt">int</span> <span class="o">-&gt;</span>
  <span class="o">?</span><span class="n">show_weights</span><span class="o">:</span><span class="kt">bool</span> <span class="o">-&gt;</span>
  <span class="n">decision_tree</span><span class="o">:[&gt;`</span><span class="nc">BaseDecisionTree</span><span class="o">]</span> <span class="nn">Np</span><span class="p">.</span><span class="nn">Obj</span><span class="p">.</span><span class="n">t</span> <span class="o">-&gt;</span>
  <span class="kt">unit</span> <span class="o">-&gt;</span>
  <span class="kt">string</span>
</code></pre></div>

<p>Build a text report showing the rules of a decision tree.</p>
<p>Note that backwards compatibility may not be supported.</p>
<h4>Parameters</h4>
<details class="info" open="open"><summary>decision_tree : object</summary><p>The decision tree estimator to be exported.
It can be an instance of
DecisionTreeClassifier or DecisionTreeRegressor.</p>
</details>
<details class="info" open="open"><summary>feature_names : list, optional (default=None)</summary><p>A list of length n_features containing the feature names.
If None generic names will be used ('feature_0', 'feature_1', ...).</p>
</details>
<details class="info" open="open"><summary>max_depth : int, optional (default=10)</summary><p>Only the first max_depth levels of the tree are exported.
Truncated branches will be marked with '...'.</p>
</details>
<details class="info" open="open"><summary>spacing : int, optional (default=3)</summary><p>Number of spaces between edges. The higher it is, the wider the result.</p>
</details>
<details class="info" open="open"><summary>decimals : int, optional (default=2)</summary><p>Number of decimal digits to display.</p>
</details>
<details class="info" open="open"><summary>show_weights : bool, optional (default=False)</summary><p>If true the classification weights will be exported on each leaf.
The classification weights are the number of samples each class.</p>
</details>
<h4>Returns</h4>
<details class="info" open="open"><summary>report : string</summary><p>Text summary of all the rules in the decision tree.</p>
</details>
<h4>Examples</h4>
<div class="highlight"><pre><span></span><code><span class="o">&gt;&gt;&gt;</span> <span class="kn">from</span> <span class="nn">sklearn.datasets</span> <span class="kn">import</span> <span class="n">load_iris</span>
<span class="o">&gt;&gt;&gt;</span> <span class="kn">from</span> <span class="nn">sklearn.tree</span> <span class="kn">import</span> <span class="n">DecisionTreeClassifier</span>
<span class="o">&gt;&gt;&gt;</span> <span class="kn">from</span> <span class="nn">sklearn.tree</span> <span class="kn">import</span> <span class="n">export_text</span>
<span class="o">&gt;&gt;&gt;</span> <span class="n">iris</span> <span class="o">=</span> <span class="n">load_iris</span><span class="p">()</span>
<span class="o">&gt;&gt;&gt;</span> <span class="n">X</span> <span class="o">=</span> <span class="n">iris</span><span class="p">[</span><span class="s1">&#39;data&#39;</span><span class="p">]</span>
<span class="o">&gt;&gt;&gt;</span> <span class="n">y</span> <span class="o">=</span> <span class="n">iris</span><span class="p">[</span><span class="s1">&#39;target&#39;</span><span class="p">]</span>
<span class="o">&gt;&gt;&gt;</span> <span class="n">decision_tree</span> <span class="o">=</span> <span class="n">DecisionTreeClassifier</span><span class="p">(</span><span class="n">random_state</span><span class="o">=</span><span class="mi">0</span><span class="p">,</span> <span class="n">max_depth</span><span class="o">=</span><span class="mi">2</span><span class="p">)</span>
<span class="o">&gt;&gt;&gt;</span> <span class="n">decision_tree</span> <span class="o">=</span> <span class="n">decision_tree</span><span class="o">.</span><span class="n">fit</span><span class="p">(</span><span class="n">X</span><span class="p">,</span> <span class="n">y</span><span class="p">)</span>
<span class="o">&gt;&gt;&gt;</span> <span class="n">r</span> <span class="o">=</span> <span class="n">export_text</span><span class="p">(</span><span class="n">decision_tree</span><span class="p">,</span> <span class="n">feature_names</span><span class="o">=</span><span class="n">iris</span><span class="p">[</span><span class="s1">&#39;feature_names&#39;</span><span class="p">])</span>
<span class="o">&gt;&gt;&gt;</span> <span class="nb">print</span><span class="p">(</span><span class="n">r</span><span class="p">)</span>
<span class="o">|---</span> <span class="n">petal</span> <span class="n">width</span> <span class="p">(</span><span class="n">cm</span><span class="p">)</span> <span class="o">&lt;=</span> <span class="mf">0.80</span>
<span class="o">|</span>   <span class="o">|---</span> <span class="n">class</span><span class="p">:</span> <span class="mi">0</span>
<span class="o">|---</span> <span class="n">petal</span> <span class="n">width</span> <span class="p">(</span><span class="n">cm</span><span class="p">)</span> <span class="o">&gt;</span>  <span class="mf">0.80</span>
<span class="o">|</span>   <span class="o">|---</span> <span class="n">petal</span> <span class="n">width</span> <span class="p">(</span><span class="n">cm</span><span class="p">)</span> <span class="o">&lt;=</span> <span class="mf">1.75</span>
<span class="o">|</span>   <span class="o">|</span>   <span class="o">|---</span> <span class="n">class</span><span class="p">:</span> <span class="mi">1</span>
<span class="o">|</span>   <span class="o">|---</span> <span class="n">petal</span> <span class="n">width</span> <span class="p">(</span><span class="n">cm</span><span class="p">)</span> <span class="o">&gt;</span>  <span class="mf">1.75</span>
<span class="o">|</span>   <span class="o">|</span>   <span class="o">|---</span> <span class="n">class</span><span class="p">:</span> <span class="mi">2</span>
</code></pre></div>

</details>
<h3 id="plot_tree">plot_tree<a class="headerlink" href="#plot_tree" title="Permanent link">&para;</a></h3>
<details class="note" open="open"><summary>function</summary><div class="highlight"><pre><span></span><code><span class="k">val</span> <span class="n">plot_tree</span> <span class="o">:</span>
  <span class="o">?</span><span class="n">max_depth</span><span class="o">:</span><span class="kt">int</span> <span class="o">-&gt;</span>
  <span class="o">?</span><span class="n">feature_names</span><span class="o">:</span><span class="kt">string</span> <span class="kt">list</span> <span class="o">-&gt;</span>
  <span class="o">?</span><span class="n">class_names</span><span class="o">:[`</span><span class="nc">StringList</span> <span class="k">of</span> <span class="kt">string</span> <span class="kt">list</span> <span class="o">|</span> <span class="o">`</span><span class="nc">Bool</span> <span class="k">of</span> <span class="kt">bool</span><span class="o">]</span> <span class="o">-&gt;</span>
  <span class="o">?</span><span class="n">label</span><span class="o">:[`</span><span class="nc">All</span> <span class="o">|</span> <span class="o">`</span><span class="nc">Root</span> <span class="o">|</span> <span class="o">`</span><span class="nc">None</span><span class="o">]</span> <span class="o">-&gt;</span>
  <span class="o">?</span><span class="n">filled</span><span class="o">:</span><span class="kt">bool</span> <span class="o">-&gt;</span>
  <span class="o">?</span><span class="n">impurity</span><span class="o">:</span><span class="kt">bool</span> <span class="o">-&gt;</span>
  <span class="o">?</span><span class="n">node_ids</span><span class="o">:</span><span class="kt">bool</span> <span class="o">-&gt;</span>
  <span class="o">?</span><span class="n">proportion</span><span class="o">:</span><span class="kt">bool</span> <span class="o">-&gt;</span>
  <span class="o">?</span><span class="n">rotate</span><span class="o">:</span><span class="kt">bool</span> <span class="o">-&gt;</span>
  <span class="o">?</span><span class="n">rounded</span><span class="o">:</span><span class="kt">bool</span> <span class="o">-&gt;</span>
  <span class="o">?</span><span class="n">precision</span><span class="o">:</span><span class="kt">int</span> <span class="o">-&gt;</span>
  <span class="o">?</span><span class="n">ax</span><span class="o">:</span><span class="nn">Py</span><span class="p">.</span><span class="nn">Object</span><span class="p">.</span><span class="n">t</span> <span class="o">-&gt;</span>
  <span class="o">?</span><span class="n">fontsize</span><span class="o">:</span><span class="kt">int</span> <span class="o">-&gt;</span>
  <span class="n">decision_tree</span><span class="o">:[&gt;`</span><span class="nc">BaseDecisionTree</span><span class="o">]</span> <span class="nn">Np</span><span class="p">.</span><span class="nn">Obj</span><span class="p">.</span><span class="n">t</span> <span class="o">-&gt;</span>
  <span class="kt">unit</span> <span class="o">-&gt;</span>
  <span class="nn">Py</span><span class="p">.</span><span class="nn">Object</span><span class="p">.</span><span class="n">t</span>
</code></pre></div>

<p>Plot a decision tree.</p>
<p>The sample counts that are shown are weighted with any sample_weights that
might be present.</p>
<p>The visualization is fit automatically to the size of the axis.
Use the <code>figsize</code> or <code>dpi</code> arguments of <code>plt.figure</code>  to control
the size of the rendering.</p>
<p>Read more in the :ref:<code>User Guide &lt;tree&gt;</code>.</p>
<p>.. versionadded:: 0.21</p>
<h4>Parameters</h4>
<details class="info" open="open"><summary>decision_tree : decision tree regressor or classifier</summary><p>The decision tree to be plotted.</p>
</details>
<details class="info" open="open"><summary>max_depth : int, optional (default=None)</summary><p>The maximum depth of the representation. If None, the tree is fully
generated.</p>
</details>
<details class="info" open="open"><summary>feature_names : list of strings, optional (default=None)</summary><p>Names of each of the features.</p>
</details>
<details class="info" open="open"><summary>class_names : list of strings, bool or None, optional (default=None)</summary><p>Names of each of the target classes in ascending numerical order.
Only relevant for classification and not supported for multi-output.
If <code>True</code>, shows a symbolic representation of the class name.</p>
</details>
<details class="info" open="open"><summary>label : {'all', 'root', 'none'}, optional (default='all')</summary><p>Whether to show informative labels for impurity, etc.
Options include 'all' to show at every node, 'root' to show only at
the top root node, or 'none' to not show at any node.</p>
</details>
<details class="info" open="open"><summary>filled : bool, optional (default=False)</summary><p>When set to <code>True</code>, paint nodes to indicate majority class for
classification, extremity of values for regression, or purity of node
for multi-output.</p>
</details>
<details class="info" open="open"><summary>impurity : bool, optional (default=True)</summary><p>When set to <code>True</code>, show the impurity at each node.</p>
</details>
<details class="info" open="open"><summary>node_ids : bool, optional (default=False)</summary><p>When set to <code>True</code>, show the ID number on each node.</p>
</details>
<details class="info" open="open"><summary>proportion : bool, optional (default=False)</summary><p>When set to <code>True</code>, change the display of 'values' and/or 'samples'
to be proportions and percentages respectively.</p>
</details>
<details class="info" open="open"><summary>rotate : bool, optional (default=False)</summary><p>This parameter has no effect on the matplotlib tree visualisation and
it is kept here for backward compatibility.</p>
<p>.. deprecated:: 0.23
   <code>rotate</code> is deprecated in 0.23 and will be removed in 0.25.</p>
</details>
<details class="info" open="open"><summary>rounded : bool, optional (default=False)</summary><p>When set to <code>True</code>, draw node boxes with rounded corners and use
Helvetica fonts instead of Times-Roman.</p>
</details>
<details class="info" open="open"><summary>precision : int, optional (default=3)</summary><p>Number of digits of precision for floating point in the values of
impurity, threshold and value attributes of each node.</p>
</details>
<details class="info" open="open"><summary>ax : matplotlib axis, optional (default=None)</summary><p>Axes to plot to. If None, use current axis. Any previous content
is cleared.</p>
</details>
<details class="info" open="open"><summary>fontsize : int, optional (default=None)</summary><p>Size of text font. If None, determined automatically to fit figure.</p>
</details>
<h4>Returns</h4>
<details class="info" open="open"><summary>annotations : list of artists</summary><p>List containing the artists for the annotation boxes making up the
tree.</p>
</details>
<h4>Examples</h4>
<div class="highlight"><pre><span></span><code><span class="o">&gt;&gt;&gt;</span> <span class="kn">from</span> <span class="nn">sklearn.datasets</span> <span class="kn">import</span> <span class="n">load_iris</span>
<span class="o">&gt;&gt;&gt;</span> <span class="kn">from</span> <span class="nn">sklearn</span> <span class="kn">import</span> <span class="n">tree</span>
</code></pre></div>

<div class="highlight"><pre><span></span><code><span class="o">&gt;&gt;&gt;</span> <span class="n">clf</span> <span class="o">=</span> <span class="n">tree</span><span class="o">.</span><span class="n">DecisionTreeClassifier</span><span class="p">(</span><span class="n">random_state</span><span class="o">=</span><span class="mi">0</span><span class="p">)</span>
<span class="o">&gt;&gt;&gt;</span> <span class="n">iris</span> <span class="o">=</span> <span class="n">load_iris</span><span class="p">()</span>
</code></pre></div>

<div class="highlight"><pre><span></span><code><span class="o">&gt;&gt;&gt;</span> <span class="n">clf</span> <span class="o">=</span> <span class="n">clf</span><span class="o">.</span><span class="n">fit</span><span class="p">(</span><span class="n">iris</span><span class="o">.</span><span class="n">data</span><span class="p">,</span> <span class="n">iris</span><span class="o">.</span><span class="n">target</span><span class="p">)</span>
<span class="o">&gt;&gt;&gt;</span> <span class="n">tree</span><span class="o">.</span><span class="n">plot_tree</span><span class="p">(</span><span class="n">clf</span><span class="p">)</span>  <span class="c1"># doctest: +SKIP</span>
<span class="p">[</span><span class="n">Text</span><span class="p">(</span><span class="mf">251.5</span><span class="p">,</span><span class="mf">345.217</span><span class="p">,</span><span class="s1">&#39;X[3] &lt;= 0.8...</span>
</code></pre></div>

</details>
                
              
              
                


              
            </article>
          </div>
        </div>
      </main>
      
        
<footer class="md-footer">
  
    <div class="md-footer-nav">
      <nav class="md-footer-nav__inner md-grid" aria-label="Footer">
        
          <a href="../Tests/" class="md-footer-nav__link md-footer-nav__link--prev" rel="prev">
            <div class="md-footer-nav__button md-icon">
              <svg xmlns="http://www.w3.org/2000/svg" viewBox="0 0 24 24"><path d="M20 11v2H8l5.5 5.5-1.42 1.42L4.16 12l7.92-7.92L13.5 5.5 8 11h12z"/></svg>
            </div>
            <div class="md-footer-nav__title">
              <div class="md-ellipsis">
                <span class="md-footer-nav__direction">
                  Previous
                </span>
                Tests
              </div>
            </div>
          </a>
        
        
          <a href="../Utils/" class="md-footer-nav__link md-footer-nav__link--next" rel="next">
            <div class="md-footer-nav__title">
              <div class="md-ellipsis">
                <span class="md-footer-nav__direction">
                  Next
                </span>
                Utils
              </div>
            </div>
            <div class="md-footer-nav__button md-icon">
              <svg xmlns="http://www.w3.org/2000/svg" viewBox="0 0 24 24"><path d="M4 11v2h12l-5.5 5.5 1.42 1.42L19.84 12l-7.92-7.92L10.5 5.5 16 11H4z"/></svg>
            </div>
          </a>
        
      </nav>
    </div>
  
  <div class="md-footer-meta md-typeset">
    <div class="md-footer-meta__inner md-grid">
      <div class="md-footer-copyright">
        
        Made with
        <a href="https://squidfunk.github.io/mkdocs-material/" target="_blank" rel="noopener">
          Material for MkDocs
        </a>
      </div>
      
    </div>
  </div>
</footer>
      
    </div>
    
      <script src="../../assets/javascripts/vendor.0ac82a11.min.js"></script>
      <script src="../../assets/javascripts/bundle.f81dfb4d.min.js"></script><script id="__lang" type="application/json">{"clipboard.copy": "Copy to clipboard", "clipboard.copied": "Copied to clipboard", "search.config.lang": "en", "search.config.pipeline": "trimmer, stopWordFilter", "search.config.separator": "[\\s\\-]+", "search.placeholder": "Search", "search.result.placeholder": "Type to start searching", "search.result.none": "No matching documents", "search.result.one": "1 matching document", "search.result.other": "# matching documents", "search.result.more.one": "1 more on this page", "search.result.more.other": "# more on this page", "search.result.term.missing": "Missing"}</script>
      
      <script>
        app = initialize({
          base: "../..",
          features: ['instant', 'tabs'],
          search: Object.assign({
            worker: "../../assets/javascripts/worker/search.4ac00218.min.js"
          }, typeof search !== "undefined" && search)
        })
      </script>
      
        <script src="https://cdnjs.cloudflare.com/ajax/libs/mathjax/2.7.0/MathJax.js?config=TeX-MML-AM_CHTML"></script>
      
    
  </body>
</html>